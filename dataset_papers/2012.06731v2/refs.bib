@inproceedings{grover2019stochastic,
  title={Stochastic optimization of sorting networks via continuous relaxations},
  author={Grover, Aditya and Wang, Eric and Zweig, Aaron and Ermon, Stefano},
  booktitle={ICLR},
  year={2019}
}

@article{liu2009learning,
  title={Learning to rank for information retrieval},
  author={Liu, Tie-Yan and others},
  journal={Foundations and Trends{\textregistered} in Information Retrieval},
  volume={3},
  number={3},
  pages={225--331},
  year={2009},
  publisher={Now Publishers, Inc.}
}

@article{burges2010ranknet,
  title={From ranknet to lambdarank to lambdamart: An overview},
  author={Burges, Christopher JC},
  journal={Learning},
  volume={11},
  number={23-581},
  pages={81},
  year={2010}
}

@article{Bengio2013,
archivePrefix = {arXiv},
arxivId = {1308.3432},
author = {Bengio, Yoshua and L{\'{e}}onard, Nicholas and Courville, Aaron},
eprint = {1308.3432},
title = {{Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation}},
url = {http://arxiv.org/abs/1308.3432},
year = {2013}
}
@article{Yin2019,
abstract = {Training activation quantized neural networks involves minimizing a piecewise constant function whose gradient vanishes almost everywhere, which is undesirable for the standard back-propagation or chain rule. An empirical way around this issue is to use a straight-through estimator (STE) (Bengio et al., 2013) in the backward pass only, so that the "gradient" through the modified chain rule becomes non-trivial. Since this unusual "gradient" is certainly not the gradient of loss function, the following question arises: why searching in its negative direction minimizes the training loss? In this paper, we provide the theoretical justification of the concept of STE by answering this question. We consider the problem of learning a two-linear-layer network with binarized ReLU activation and Gaussian input data. We shall refer to the unusual "gradient" given by the STE-modifed chain rule as coarse gradient. The choice of STE is not unique. We prove that if the STE is properly chosen, the expected coarse gradient correlates positively with the population gradient (not available for the training), and its negation is a descent direction for minimizing the population loss. We further show the associated coarse gradient descent algorithm converges to a critical point of the population loss minimization problem. Moreover, we show that a poor choice of STE leads to instability of the training algorithm near certain local minima, which is verified with CIFAR-10 experiments.},
archivePrefix = {arXiv},
arxivId = {1903.05662},
author = {Yin, Penghang and Lyu, Jiancheng and Zhang, Shuai and Osher, Stanley and Qi, Yingyong and Xin, Jack},
eprint = {1903.05662},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Yin et al. - 2019 - Understanding Straight-Through Estimator in Training Activation Quantized Neural Nets.pdf:pdf},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/Deep Nets},
pages = {1--30},
title = {{Understanding Straight-Through Estimator in Training Activation Quantized Neural Nets}},
url = {http://arxiv.org/abs/1903.05662},
year = {2019}
}



@inproceedings{wu2009smoothing,
  title={Smoothing {DCG} for learning to rank: A novel approach using smoothed hinge functions},
  author={Wu, Mingrui and Chang, Yi and Zheng, Zhaohui and Zha, Hongyuan},
  booktitle={CIKM},
  year={2009}
}


@article{chapelle2010gradient,
  title={Gradient descent optimization of smoothed information retrieval metrics},
  author={Chapelle, Olivier and Wu, Mingrui},
  journal={Information retrieval},
  volume={13},
  number={3},
  pages={216--235},
  year={2010},
  publisher={Springer}
}

@inproceedings{taylor2008softrank,
  title={Softrank: optimizing non-smooth rank metrics},
  author={Taylor, Michael and Guiver, John and Robertson, Stephen and Minka, Tom},
  booktitle={WSDM},
  year={2008}
}

@article{Mcfee2010,
author = {Mcfee, Brian and Lanckriet, Gert},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Mcfee, Lanckriet - 2010 - Metric Learning to Rank.pdf:pdf},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R},
title = {{Metric Learning to Rank}},
year = {2010}
}
@article{Zaheer2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1703.06114v3},
author = {Zaheer, Manzil and Kottur, Satwik and Ravanbhakhsh, Siamak},
eprint = {arXiv:1703.06114v3},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Zaheer, Kottur, Ravanbhakhsh - 2017 - Deep Sets.pdf:pdf},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/Deep Nets},
number = {ii},
title = {{Deep Sets}},
year = {2017}
}
@article{Adams,
archivePrefix = {arXiv},
arxivId = {arXiv:1106.1925v2},
author = {Adams, Ryan Prescott and Zemel, Richard S},
eprint = {arXiv:1106.1925v2},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Adams, Zemel - Unknown - Ranking via Sinkhorn Propagation.pdf:pdf},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R},
pages = {1--12},
title = {{Ranking via Sinkhorn Propagation}}
}
@article{Wang,
author = {Wang, Xuanhui and Golbandi, Nadav and Bendersky, Michael and Metzler, Donald and Najork, Marc},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Wang et al. - Unknown - Position Bias Estimation for Unbiased Learning to Rank in Personal Search.pdf:pdf},
isbn = {9781450355810},
keywords = {expectation-,inverse propensity weighting,position bias estimation},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R},
title = {{Position Bias Estimation for Unbiased Learning to Rank in Personal Search}}
}
@article{Vartak2017,
author = {Vartak, Manasi and Miranda, Conrado},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Vartak, Miranda - 2017 - A Meta-Learning Perspective on Cold-Start Recommendations for Items.pdf:pdf},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,400 By Application/Recommendation,300 By Theory/Deep Nets},
number = {Nips},
title = {{A Meta-Learning Perspective on Cold-Start Recommendations for Items}},
year = {2017}
}
@article{Wagstaff2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1901.09006v1},
author = {Wagstaff, Edward and Fuchs, Fabian B and Engelcke, Martin and Posner, Ingmar and Osborne, Michael},
eprint = {arXiv:1901.09006v1},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Wagstaff et al. - 2019 - On the Limitations of Representing Functions on Sets.pdf:pdf},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/Deep Nets},
title = {{On the Limitations of Representing Functions on Sets}},
year = {2019}
}

@article{Qin2013,
archivePrefix = {arXiv},
arxivId = {1306.2597},
author = {Qin, Tao and Liu, Tie-Yan},
eprint = {1306.2597},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Qin, Liu - 2013 - Introducing LETOR 4.0 Datasets.pdf:pdf},
isbn = {1409813566007},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R},
title = {{Introducing LETOR 4.0 Datasets}},
url = {http://arxiv.org/abs/1306.2597},
year = {2013}
}

@article{Metzler,
author = {Metzler, Donald},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Metzler - Unknown - Direct Maximization of Rank-based Metrics DRAFT IN PROGRESS.pdf:pdf},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R},
pages = {1--17},
title = {{Direct Maximization of Rank-based Metrics}}
}

@article{Qin2010,
author = {Qin, Tao and Liu, Tie Yan and Li, Hang},
doi = {10.1007/s10791-009-9124-x},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Qin, Liu, Li - 2010 - A general approximation framework for direct optimization of information retrieval measures.pdf:pdf},
issn = {13864564},
journal = {Information Retrieval},
keywords = {Accuracy analysis,Direct optimization of IR measures,Learning to rank,Position function approximation,Truncation function approximation},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R},
number = {4},
pages = {375--397},
title = {{A general approximation framework for direct optimization of information retrieval measures}},
volume = {13},
year = {2010}
}
@article{Chen2009,
abstract = {Learning to rank has become an important research topic in machine learning. While most learning-to-rank methods learn the ranking functions by minimizing loss functions, it is the ranking measures (such as NDCG and MAP) that are used to evaluate the performance of the learned ranking functions. In this work, we reveal the relationship between ranking measures and loss functions in learningto-rank methods, such as Ranking SVM, RankBoost, RankNet, and ListMLE. We show that the loss functions of these methods are upper bounds of the measurebased ranking errors. As a result, the minimization of these loss functions will lead to the maximization of the ranking measures. The key to obtaining this result is to model ranking as a sequence of classification tasks, and define a so-called essential loss for ranking as the weighted sum of the classification errors of individual tasks in the sequence. We have proved that the essential loss is both an upper bound of the measure-based ranking errors, and a lower bound of the loss functions in the aforementioned methods. Our proof technique also suggests a way to modify existing loss functions to make them tighter bounds of the measure-based ranking errors. Experimental results on benchmark datasets show that the modifications can lead to better ranking performances, demonstrating the correctness of our theoretical analysis.},
author = {Chen, Wei},
doi = {10.1016/S0008-6215(01)00024-6},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Chen - 2009 - Ranking Measures and Loss Function in Learning To Rank.pdf:pdf},
isbn = {9781615679119},
issn = {00086215},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R,400 By Application/Recommendation},
title = {{Ranking Measures and Loss Function in Learning To Rank}},
url = {http://repositorio.ug.edu.ec/bitstream/redug/3012/1/Tesina Cristina Veliz.pdf},
year = {2009}
}
@article{Chapelle2009,
author = {Chapelle, Olivier and Metlzer, Donald and Zhang, Ya and Grinspan, Pierre},
doi = {10.1145/1645953.1646033},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Chapelle et al. - 2009 - Expected reciprocal rank for graded relevance.pdf:pdf},
isbn = {9781605585123},
keywords = {evaluation,non-binary relevance,user model,web search},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R,400 By Application/Recommendation},
pages = {621},
title = {{Expected reciprocal rank for graded relevance}},
year = {2009}
}
@article{Zhang2014,
author = {Zhang, Mi and Tang, Jie and Zhang, Xuchen and Xue, Xiangyang},
doi = {10.1145/2600428.2609599},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Zhang et al. - 2014 - Addressing Cold Start in Recommender Systems A Semi-supervised Co-training Algorithm.pdf:pdf},
isbn = {9781450322577},
journal = {SIGIR},
keywords = {cold-start,recommendation,semi-supervised learning},
mendeley-groups = {200 By Provenance/Suggested By/Colleagues,100 By Project/{\_}{\_}NEURALSORT,400 By Application/Recommendation},
pages = {73--82},
title = {{Addressing Cold Start in Recommender Systems: A Semi-supervised Co-training Algorithm}},
url = {http://dl.acm.org/citation.cfm?doid=2600428.2609599},
year = {2014}
}
@article{Grover2018,
arxivId = {1803.10459},
author = {Grover, Aditya and Zweig, Aaron and Ermon, Stefano},
eprint = {1803.10459},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Grover, Zweig, Ermon - 2018 - Graphite Iterative Generative Modeling of Graphs.pdf:pdf},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,200 By Provenance/Institutions/Stanford,200 By Provenance/Institutions/Stanford/Stefano,300 By Theory/Graphs,300 By Theory/Deep Nets/GraphNNs},
title = {{Graphite: Iterative Generative Modeling of Graphs}},
url = {http://arxiv.org/abs/1803.10459},
year = {2018}
}
@article{Chen,
author = {Chen, Jingyuan and He, Xiangnan},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Chen, He - Unknown - Attentive Collaborative Filtering Multimedia Recommendation with Item- and Component-Level A ention.pdf:pdf},
isbn = {9781450350228},
keywords = {a ention,collaborative filtering,implicit feedback,multimedia},
mendeley-groups = {200 By Provenance/Suggested By/Colleagues,200 By Provenance/Suggested By/RIT-SM List,100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R},
title = {{Attentive Collaborative Filtering : Multimedia Recommendation with Item- and Component-Level A ention}}
}
@article{Williams1992,
author = {Williams},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Williams - 1992 - Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning.pdf:pdf},
mendeley-groups = {300 By Theory/Deep Nets/Gumbel,300 By Theory/RL,100 By Project/{\_}{\_}NEURALSORT,100 By Project/{\_}{\_}Coursera/Advanced Bayesian ML},
title = {{Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning}},
year = {1992}
}
@article{Oosterhuis2018,
archivePrefix = {arXiv},
arxivId = {1805.02404},
author = {Oosterhuis, Harrie and de Rijke, Maarten},
doi = {10.1145/3209978.3209992},
eprint = {1805.02404},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Oosterhuis, de Rijke - 2018 - Ranking for Relevance and Display Preferences in Complex Presentation Layouts.pdf:pdf},
isbn = {9781450356572},
keywords = {2018,acm reference format,complex ranking,de rijke,deep reinforcement learning,harrie oosterhuis and maarten,learning to rank,ranking for relevance and},
mendeley-groups = {100 By Project/{\_}{\_}STANFORD,100 By Project/{\_}{\_}NEURALSORT},
title = {{Ranking for Relevance and Display Preferences in Complex Presentation Layouts}},
url = {http://arxiv.org/abs/1805.02404{\%}0Ahttp://dx.doi.org/10.1145/3209978.3209992},
year = {2018}
}
@article{Wang2009,
author = {Wang, Jun and Zhu, Jianhan},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Wang, Zhu - 2009 - Portfolio Theory of Information Retrieval.pdf:pdf},
isbn = {9781605584836},
journal = {SIGIR},
keywords = {bility ranking principle,mean-variance analysis,modern portfolio theory,proba-,ranking under uncertainty},
mendeley-groups = {100 By Project/{\_}{\_}STANFORD,100 By Project/{\_}{\_}NEURALSORT},
pages = {115--122},
title = {{Portfolio Theory of Information Retrieval}},
year = {2009}
}
@article{Rendle2009,
archivePrefix = {arXiv},
arxivId = {1205.2618},
author = {Rendle, Steffen and Freudenthaler, Christoph and Gantner, Zeno and Schmidt-Thieme, Lars},
doi = {10.1145/1772690.1772773},
eprint = {1205.2618},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop//Rendle et al. - 2009 - BPR Bayesian Personalized Ranking from Implicit Feedback.pdf:pdf;:Users/robin.swezey/Library/Application Support/Mendeley Desktop/Downloaded/Rendle et al. - 2009 - BPR Bayesian Personalized Ranking from Implicit Feedback.pdf:pdf},
isbn = {978-0-9749039-5-8},
issn = {1469493X},
mendeley-groups = {400 By Application/Recommendation,100 By Project/{\_}{\_}NEURALSORT,200 By Provenance/Suggested By/Colleagues},
pages = {452--461},
pmid = {21975771},
title = {{BPR: Bayesian Personalized Ranking from Implicit Feedback}},
url = {http://arxiv.org/abs/1205.2618 https://arxiv.org/pdf/1205.2618.pdf},
year = {2009}
}
@book{hooper1996oxford,
  title={The Oxford companion to chess},
  author={Hooper, David and Whyld, Kenneth},
  year={1996},
  publisher={Oxford University Press, USA}
}
@inproceedings{Mena2018,
archivePrefix = {arXiv},
arxivId = {1802.08665},
author = {Mena, Gonzalo and Belanger, David and Linderman, Scott and Snoek, Jasper},
eprint = {1802.08665},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Mena et al. - 2018 - Learning Latent Permutations with Gumbel-Sinkhorn Networks.pdf:pdf},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/Deep Nets,300 By Theory/LETOR L2R},
title = {{Learning Latent Permutations with Gumbel-Sinkhorn Networks}},
url = {http://arxiv.org/abs/1802.08665},
booktitle={ICLR},
year = {2018}
}

@article{Mcfee2010,
author = {Mcfee, Brian and Lanckriet, Gert},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Mcfee, Lanckriet - 2010 - Metric Learning to Rank.pdf:pdf},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R},
title = {{Metric Learning to Rank}},
year = {2010}
}
@article{Wang,
author = {Wang, Xuanhui and Golbandi, Nadav and Bendersky, Michael and Metzler, Donald and Najork, Marc},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Wang et al. - Unknown - Position Bias Estimation for Unbiased Learning to Rank in Personal Search.pdf:pdf},
isbn = {9781450355810},
keywords = {expectation-,inverse propensity weighting,position bias estimation},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R},
title = {{Position Bias Estimation for Unbiased Learning to Rank in Personal Search}}
}
@article{Qin2010,
doi = {10.1007/s10791-009-9124-x},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Qin, Liu, Li - 2010 - A general approximation framework for direct optimization of information retrieval measures.pdf:pdf},
issn = {13864564},
journal = {Information Retrieval},
keywords = {Accuracy analysis,Direct optimization of IR measures,Learning to rank,Position function approximation,Truncation function approximation},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R},
number = {4},
pages = {375--397},
title = {{A general approximation framework for direct optimization of information retrieval measures}},
volume = {13},
year = {2010}
}
@article{Chapelle2009,
author = {Chapelle, Olivier and Metlzer, Donald and Zhang, Ya and Grinspan, Pierre},
doi = {10.1145/1645953.1646033},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Chapelle et al. - 2009 - Expected reciprocal rank for graded relevance.pdf:pdf},
isbn = {9781605585123},
keywords = {evaluation,non-binary relevance,user model,web search},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R,400 By Application/Recommendation},
pages = {621},
title = {{Expected reciprocal rank for graded relevance}},
year = {2009}
}
@article{Wang2017,
abstract = {In information retrieval, learning to rank constructs a machine-based ranking model which given a query, sorts the search results by their degree of relevance or importance to the query. Neural networks have been successfully applied to this problem, and in this paper, we propose an attention-based deep neural network which better incorporates different embeddings of the queries and search results with an attention-based mechanism. This model also applies a decoder mechanism to learn the ranks of the search results in a listwise fashion. The embeddings are trained with convolutional neural networks or the word2vec model. We demonstrate the performance of this model with image retrieval and text querying data sets.},
archivePrefix = {arXiv},
arxivId = {1702.06106},
author = {Wang, Baiyang and Klabjan, Diego},
eprint = {1702.06106},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Wang, Klabjan - 2017 - An Attention-Based Deep Net for Learning to Rank.pdf:pdf},
mendeley-groups = {300 By Theory/LETOR L2R,300 By Theory/Deep Nets},
title = {{An Attention-Based Deep Net for Learning to Rank}},
url = {http://arxiv.org/abs/1702.06106},
year = {2017}
}
@article{Wasilewski,
abstract = {Regularisation is typically applied to the optimisation objec-tive of matrix factorisation methods in order to avoid over-fitting. In this paper, we explore the use of regularisation to enhance the diversity of the recommendations produced by these methods. Given a matrix of pairwise item distances, we add regularisation terms dependent on the item distances to the accuracy objective of a learning to rank matrix factorisa-tion formulation. We examine the impact of these regularisers on the latent factors produced by the algorithm and show that such regularisation does indeed promote diversity. The regu-larisation comes at a cost of performance in terms of accuracy and ultimately the approach cannot greatly enhance diversity without a consequent fall-off in accuracy.},
author = {Wasilewski, Jacek and Hurley, Neil},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Wasilewski, Hurley - Unknown - Incorporating Diversity in a Learning to Rank Recommender System.pdf:pdf},
keywords = {Special Track on Recommender Systems},
mendeley-groups = {300 By Theory/LETOR L2R,100 By Project/{\_}{\_}STANFORD},
title = {{Incorporating Diversity in a Learning to Rank Recommender System}}
}
@article{Severyn2015,
abstract = {SIGIR '14},
author = {Severyn, Aliaksei and Moschitti, Alessandro},
doi = {10.1145/2766462.2767738},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop//Severyn, Moschitti - 2015 - Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks.pdf:pdf},
isbn = {9781450336215},
issn = {9781450336215},
journal = {SIGIR},
keywords = {H.3 [Information Storage and Retrieval],convolutional neural networks,ing,learning to rank,microblog search,question answer-},
mendeley-groups = {300 By Theory/LETOR L2R,300 By Theory/Deep Nets},
pages = {373--382},
title = {{Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks}},
url = {http://dl.acm.org/citation.cfm?doid=2766462.2767738 http://dx.doi.org/10.1145/2766462.2767738.},
year = {2015}
}
@article{Severyn,
abstract = {Learning a similarity function between pairs of objects is at the core of learning to rank approaches. In information retrieval tasks we typically deal with query-document pairs, in question answering â€“ question-answer pairs. However, before learning can take place, such pairs needs to be mapped from the original space of symbolic words into some feature space encoding various aspects of their relatedness, e.g. lexical, syntactic and semantic. Feature engineer-ing is often a laborious task and may require external knowledge sources that are not always available or difficult to obtain. Recently, deep learning approaches have gained a lot of attention from the research community and industry for their ability to automatically learn optimal feature representation for a given task, while claim-ing state-of-the-art performance in many tasks in computer vision, speech recognition and natural language processing. In this paper, we present a convolutional neural network architecture for rerank-ing pairs of short texts, where we learn the optimal representation of text pairs and a similarity function to relate them in a supervised way from the available training data. Our network takes only words in the input, thus requiring minimal preprocessing. In particular, we consider the task of reranking short text pairs where elements of the pair are sentences. We test our deep learning system on two popular retrieval tasks from TREC: Question Answering and Mi-croblog Retrieval. Our model demonstrates strong performance on the first task beating previous state-of-the-art systems by about 3{\%} absolute points in both MAP and MRR and shows comparable re-sults on tweet reranking, while enjoying the benefits of no manual feature engineering and no additional syntactic parsers.},
author = {Severyn, Aliaksei and Moschitti, Alessandro},
doi = {10.1145/2766462.2767738},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop//Severyn, Moschitti - 2015 - Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks.pdf:pdf},
keywords = {H.3 [Information Storage and Retrieval]},
mendeley-groups = {300 By Theory/LETOR L2R,300 By Theory/Deep Nets},
title = {{Learning to Rank Short Text Pairs with Convolutional Deep Neural Networks}},
url = {http://dx.doi.org/10.1145/2766462.2767738.}
}
@article{Rigutini2008,
author = {Rigutini, Leonardo},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop//Rigutini - 2008 - A neural network approach for learning object ranking.pdf:pdf},
mendeley-groups = {300 By Theory/LETOR L2R},
number = {March},
title = {{A neural network approach for learning object ranking}},
year = {2008}
}
@article{Yuan2014,
abstract = {The current trend in social media analysis and application is to use the pre-defined features and devoted to the later model development modules to meet the end tasks. Representation learning has been a fundamental problem in machine learning, and widely recognized as critical to the performance of end tasks. In this paper, we provide evidence that specially learned features will addresses the diverse, heterogeneous, and collective characteristics of social media data. Therefore, we propose to transfer the focus from the model development to latent feature learning, and present a unified framework of latent feature learning on social media. To address the noisy, diverse, heterogeneous, and interconnected characteristics of social media data, the popular deep learning is employed due to its excellent abstract abilities. In particular, we instantiate the proposed framework by (1) designing a novel relational generative deep learning model to solve the social media link analysis task, and (2) developing a multimodal deep learning to lambda rank model towards the social image retrieval task. We show that the derived latent features lead to improvement in both of the social media tasks.},
author = {Yuan, Zhaoquan and Sang, Jitao and Xu, Changsheng and Liu, Yan},
doi = {10.1109/TMM.2014.2322338},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Yuan et al. - 2014 - AUnified Framework of Latent Feature Learning in Social Media.pdf:pdf},
isbn = {1520-9210 VO - 16},
issn = {1520-9210},
journal = {IEEE Transactions on Multimedia},
keywords = {Analytical models,Bayes methods,Data models,Deep learning,Image retrieval,Media,Multimedia communication,Semantics,feature learning,image retrieval,india buffet process,information analysis,lambda rank model,latent feature learning,learning (artificial intelligence),model development,multimodal deep learning,relational generative deep learning model,representation learning,social image retrieval task,social media,social media analysis,social media application,social media data characteristics,social media link analysis task,social networking (online)},
mendeley-groups = {300 By Theory/LETOR L2R},
number = {6},
pages = {1624--1635},
title = {{AUnified Framework of Latent Feature Learning in Social Media}},
url = {http://ieeexplore.ieee.org/document/6810890/},
volume = {16},
year = {2014}
}
@article{Santos2014,
abstract = {In this paper we describe a Deep Convo-lutional Neural Network (DNN) approach to perform two sentiment detection tasks: message polarity classification and con-textual polarity disambiguation. We apply the proposed approach for the SemEval-2014 Task 9: Sentiment Analysis in Twit-ter. Despite not using any handcrafted feature or sentiment lexicons, our system achieves very competitive results for Twit-ter data.},
author = {dos Santos, Cicero Nogueira},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Santos - 2014 - Think Positive Towards Twitter Sentiment Analysis from Scratch.pdf:pdf},
journal = {Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014)},
mendeley-groups = {300 By Theory/LETOR L2R},
number = {SemEval},
pages = {647--651},
title = {{Think Positive: Towards Twitter Sentiment Analysis from Scratch}},
year = {2014}
}
@article{Dong2014,
abstract = {Learning to rank has received great attentions in the field of text retrieval for several years. However, a few researchers introduce the topic into visual reranking due to the special nature of image presentation. In this paper, a novel unsupervised visual reranking is proposed, termed rank via the convolutional neural networks (RankCNN). This approach integrates deep learning with pseudo preference feedback. The optimal set of pseudo preference pairs is first detected from initial list by a modified graph-based method. Ranking is then reduced to pairwise classification in the architecture of CNN. In addition, Accelerated Mini-Batch Stochastic Dual Coordinate Ascent (ASDCA) is introduced to the framework to accelerate the training. The experiments indicate the competitive performance on the LETOR 4.0, the Paris and the Francelandmark dataset. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
author = {Dong, Yuan and Huang, Chong and Liu, Wei},
doi = {10.1016/j.csi.2013.10.007},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Dong, Huang, Liu - 2014 - RankCNN When learning to rank encounters the pseudo preference feedback.pdf:pdf},
issn = {09205489},
journal = {Computer Standards and Interfaces},
keywords = {Convolutional neural networks,Learning to rank,Pseudo preference feedback,RankCNN},
mendeley-groups = {300 By Theory/LETOR L2R},
number = {3},
pages = {554--562},
title = {{RankCNN: When learning to rank encounters the pseudo preference feedback}},
volume = {36},
year = {2014}
}
@inproceedings{Cao2015,
abstract = {We develop a Ranking framework upon Recursive Neural Networks (R2N2) to rank sentences for multi-document sum- marization. It formulates the sentence ranking task as a hi- erarchical regression process, which simultaneously mea- sures the salience of a sentence and its constituents (e.g., phrases) in the parsing tree. This enables us to draw on word-level to sentence-level supervisions derived from refer- ence summaries. In addition, recursive neural networks are used to automatically learn ranking features over the tree, with hand-crafted feature vectors of words as inputs. Hier- archical regressions are then conducted with learned features concatenating raw features. Ranking scores of sentences and words are utilized to effectively select informative and non- redundant sentences to generate summaries. Experiments on the DUC 2001, 2002 and 2004 multi-document summariza- tion datasets show that R2N2 outperforms state-of-the-art ex- tractive summarization approaches. Introduction},
archivePrefix = {arXiv},
arxivId = {1509.00685},
author = {Cao, Ziqiang and Wei, Furu and Dong, Li and Li, Sujian and Zhou, Ming},
doi = {10.1162/153244303322533223},
eprint = {1509.00685},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Cao et al. - 2015 - Ranking with recursive neural networks and its application to multi-document summarization.pdf:pdf},
isbn = {9781577357018},
issn = {19909772},
booktitle = {AAAI},
keywords = {NLP and Knowledge Representation Track},
mendeley-groups = {300 By Theory/LETOR L2R},
pmid = {18244602},
title = {{Ranking with recursive neural networks and its application to multi-document summarization}},
year = {2015}
}
@article{Zhao2015,
abstract = {Many existing learning-to-rank approaches are incapable of effectively modeling the intrinsic interaction relationships between the feature-level and ranking-level components of a ranking model. To address this problem, we propose a novel joint learning-to-rank approach called Deep Latent Structural SVM (DL-SSVM), which jointly learns deep neural networks and latent structural SVM (connected by a set of latent feature grouping variables) to effectively model the interaction relationships at two levels (i.e., feature-level and ranking-level). To make the joint learning problem easier to optimize, we present an effective auxiliary variable-based alternating optimization approach with respect to deep neural network learning and structural latent SVM learning. Experimental results on several challenging datasets have demonstrated the effectiveness of the proposed learning to rank approach in real-world information retrieval.},
author = {Zhao, Xueyi and Li, Xi and Zhang, Zhongfei},
doi = {10.1109/LSP.2015.2410134},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Zhao, Li, Zhang - 2015 - Multimedia Retrieval via Deep Learning to Rank.pdf:pdf},
isbn = {1070-9908 VO  - PP},
issn = {1070-9908},
journal = {Icip},
keywords = {Adaptation models,DL-SSVM approach,Data models,Deep neural network,Feature extraction,Joints,Neural networks,Support vector machines,Vectors,auxiliary variable-based alternating optimization,deep latent structural SVM,deep learning-to-rank approach,deep neural network learning,feature-level component,information retrieval,joint learning,latent variable,learning (artificial intelligence),learning to rank,multimedia retrieval,multimedia systems,neural nets,ranking-level component,structural SVM,structural latent SVM learning,support vector machines},
mendeley-groups = {300 By Theory/LETOR L2R},
number = {9},
pages = {1487--1491},
title = {{Multimedia Retrieval via Deep Learning to Rank}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7054452},
volume = {22},
year = {2015}
}
@article{Chaudhuri2014,
abstract = {Learning to rank is a supervised learning problem where the output space is the space of rankings but the supervision space is the space of relevance scores. We make theoretical contributions to the learning to rank problem both in the online and batch settings. First, we propose a perceptron-like algorithm for learning a ranking function in an online setting. Our algorithm is an extension of the classic perceptron algorithm for the classification problem. Second, in the setting of batch learning, we introduce a sufficient condition for convex ranking surrogates to ensure a generalization bound that is independent of number of objects per query. Our bound holds when linear ranking functions are used: a common practice in many learning to rank algorithms. En route to developing the online algorithm and generalization bound, we propose a novel family of listwise large margin ranking surrogates. Our novel surrogate family is obtained by modifying a well-known pairwise large margin ranking surrogate and is distinct from the listwise large margin surrogates developed using the structured prediction framework. Using the proposed family, we provide a guaranteed upper bound on the cumulative NDCG (or MAP) induced loss under the perceptron-like algorithm. We also show that the novel surrogates satisfy the generalization bound condition.},
archivePrefix = {arXiv},
arxivId = {1405.0591},
author = {Chaudhuri, Sougata and Tewari, Ambuj},
eprint = {1405.0591},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Chaudhuri, Tewari - 2014 - Perceptron-like Algorithms and Generalization Bounds for Learning to Rank.pdf:pdf},
mendeley-groups = {300 By Theory/LETOR L2R},
title = {{Perceptron-like Algorithms and Generalization Bounds for Learning to Rank}},
url = {http://arxiv.org/abs/1405.0591},
year = {2014}
}
@inproceedings{Burges2005,
abstract = {We investigate using gradient descent methods for learning ranking functions; we propose a simple probabilistic cost function, and we introduce RankNet, an implementation of these ideas using a neural network to model the underlying ranking function. We present test results on toy data and on data from a commercial internet search engine.},
author = {Burges, Chris and Shaked, Tal and Renshaw, Erin and Lazier, Ari and Deeds, Matt and Hamilton, Nicole and Hullender, Greg},
doi = {10.1145/1102351.1102363},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Burges et al. - 2005 - Learning to rank using gradient descent.pdf:pdf},
isbn = {1595931805},
issn = {00243205},
booktitle = {ICML},
keywords = {gradient descent,internet search,neural networks,probabilistic cost functions,ranking},
mendeley-groups = {300 By Theory/LETOR L2R},
title = {{Learning to rank using gradient descent}},
year = {2005}
}
@article{Gao2014,
abstract = {This paper presents a deep semantic simi- larity model (DSSM), a special type of deep neural networks designed for text analysis, for recommending target docu- ments to be of interest to a user based on a source document that she is reading. We observe, identify, and detect naturally oc- curring signals of interestingness in click transitions on the Web between source and target documents, which we collect from commercial Web browser logs. The DSSM is trained on millions of Web transitions, and maps source-target document pairs to feature vectors in a latent space in such a way that the distance between source doc- uments and their corresponding interesting targets in that space is minimized. The ef- fectiveness of the DSSM is demonstrated using two interestingness tasks: automatic highlighting and contextual entity search. The results on large-scale, real-world da- tasets show that the semantics of docu- ments are important for modeling interest- ingness and that the DSSM leads to signif- icant quality improvement on both tasks, outperforming not only the classic docu- ment models that do not use semantics but also state-of-the-art topic models. 1},
author = {Gao, Jianfeng and Pantel, Patrick and Gamon, Michael and He, Xiaodong and Deng, Li},
doi = {10.3115/v1/D14-1002},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Gao et al. - 2014 - Modeling Interestingness with Deep Neural Networks.pdf:pdf},
journal = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
mendeley-groups = {300 By Theory/LETOR L2R},
pages = {2--13},
title = {{Modeling Interestingness with Deep Neural Networks}},
url = {http://aclweb.org/anthology/D14-1002},
year = {2014}
}
@article{Wang2014,
abstract = {Learning fine-grained image similarity is a challenging task. It needs to capture between-class and within-class image differences. This paper proposes a deep ranking model that employs deep learning techniques to learn similarity metric directly from images.It has higher learning capability than models based on hand-crafted features. A novel multiscale network structure has been developed to describe the images effectively. An efficient triplet sampling algorithm is proposed to learn the model with distributed asynchronized stochastic gradient. Extensive experiments show that the proposed algorithm outperforms models based on hand-crafted visual features and deep classification models.},
archivePrefix = {arXiv},
arxivId = {1404.4661},
author = {Wang, Jiang and Song, Yang and Leung, Thomas and Rosenberg, Chuck and Wang, Jingbin and Philbin, James and Chen, Bo and Wu, Ying},
doi = {10.1109/CVPR.2014.180},
eprint = {1404.4661},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Wang et al. - 2014 - Learning fine-grained image similarity with deep ranking.pdf:pdf},
isbn = {9781479951178},
issn = {10636919},
journal = {CVPR},
mendeley-groups = {300 By Theory/LETOR L2R},
pages = {1386--1393},
title = {{Learning fine-grained image similarity with deep ranking}},
year = {2014}
}
@article{Collobert2009,
abstract = {Abstract: This tutorial will describe recent advances in deep learning techniques for Natural Language Processing (NLP). Traditional NLP approaches favour shallow systems, possibly cascaded, with adequate hand-crafted features. In constrast, we are interested in end-to-end architectures: these systems include several feature layers, with increasing abstraction at each layer. Compared to shallow systems, these feature layers are learnt for the task of interest, and do not require any engineering. We will show how neural networks are naturally well suited for end-to-end learning in NLP tasks. We will study multi-tasking different tasks, new semi-supervised learning techniques adapted to these deep architectures, and review end-to-end structured output learning. Finally, we will highlight how some of these advances can be applied to other fields of research, like computer vision, as well.},
author = {Collobert, Ronan},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Collobert - 2009 - Deep Learning for Natural Language Processing Deep Learning for Natural Language Processing.pdf:pdf},
journal = {Language},
mendeley-groups = {300 By Theory/LETOR L2R},
number = {Winter},
pages = {1--5},
title = {{Deep Learning for Natural Language Processing Deep Learning for Natural Language Processing}},
url = {http://nips.cc/Conferences/2009/Program/event.php?ID=1495},
volume = {571},
year = {2009}
}
@article{Zhao2015a,
abstract = {With the rapid growth of web images, hashing has received increasing interests in large scale image retrieval. Research efforts have been devoted to learning compact binary codes that preserve semantic similarity based on labels. However, most of these hashing methods are designed to handle simple binary similarity. The complex multilevel semantic structure of images associated with multiple labels have not yet been well explored. Here we propose a deep semantic ranking based method for learning hash functions that preserve multilevel semantic similarity between multi-label images. In our approach, deep convolutional neural network is incorporated into hash functions to jointly learn feature representations and mappings from them to hash codes, which avoids the limitation of semantic representation power of hand-crafted features. Meanwhile, a ranking list that encodes the multilevel similarity information is employed to guide the learning of such deep hash functions. An effective scheme based on surrogate loss is used to solve the intractable optimization problem of nonsmooth and multivariate ranking measures involved in the learning procedure. Experimental results show the superiority of our proposed approach over several state-of-the-art hashing methods in term of ranking evaluation metrics when tested on multi-label image datasets.},
archivePrefix = {arXiv},
arxivId = {1501.06272},
author = {Zhao, Fang and Huang, Yongzhen and Wang, Liang and Tan, Tieniu},
doi = {10.1109/CVPR.2015.7298763},
eprint = {1501.06272},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Zhao et al. - 2015 - Deep semantic ranking based hashing for multi-label image retrieval.pdf:pdf},
isbn = {9781467369640},
issn = {10636919},
journal = {CVPR},
mendeley-groups = {300 By Theory/LETOR L2R},
pages = {1556--1564},
title = {{Deep semantic ranking based hashing for multi-label image retrieval}},
volume = {07-12-June},
year = {2015}
}
@article{Li2014,
abstract = {User interactions with search engines provide many cues that can be leveraged to improve the relevance of search results through personalization. The context information (history of queries, clicked documents, etc.) provides strong signals about users' search intent, which can be used to personalize the search experience and improve a web search engine. We demonstrate how to generate the semantic features from in-session contextual information with deep learning models, and incorporate these semantic features into the current ranking model to re-rank the results. We evaluate our approach using a large, real-world search log data from a major commercial web search engine, and the experimental results show our ap-proach can significantly improve the performance of the search engine. Further-more, we also find that the domain-specific, click-based features can effectively decrease the unsatisfied clicks for the current ranking model to improve the search experience.},
author = {Li, Xiujun and Guo, Chenlei and Chu, Wei and Wang, Yy and Shavlik, Jude},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Li et al. - 2014 - Deep Learning Powered In-Session Contextual Ranking using Clickthrough Data.pdf:pdf},
isbn = {0316119709},
journal = {NIPS workshop, Personalization: Theory and Application},
mendeley-groups = {300 By Theory/LETOR L2R},
pages = {1--9},
title = {{Deep Learning Powered In-Session Contextual Ranking using Clickthrough Data}},
url = {http://ftp.cs.wisc.edu/machine-learning/shavlik-group/li.nips14.pdf},
year = {2014}
}
@article{Gong2013,
abstract = {Multilabel image annotation is one of the most important challenges in computer vision with many real-world applications. While existing work usually use conventional visual features for multilabel annotation, features based on Deep Neural Networks have shown potential to significantly boost performance. In this work, we propose to leverage the advantage of such features and analyze key components that lead to better performances. Specifically, we show that a significant performance gain could be obtained by combining convolutional architectures with approximate top-{\$}k{\$} ranking objectives, as thye naturally fit the multilabel tagging problem. Our experiments on the NUS-WIDE dataset outperforms the conventional visual features by about 10{\%}, obtaining the best reported performance in the literature.},
archivePrefix = {arXiv},
arxivId = {1312.4894},
author = {Gong, Yunchao and Jia, Yangqing and Leung, Thomas and Toshev, Alexander and Ioffe, Sergey},
eprint = {1312.4894},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Gong et al. - 2013 - Deep Convolutional Ranking for Multilabel Image Annotation.pdf:pdf},
mendeley-groups = {300 By Theory/LETOR L2R},
pages = {1--9},
pmid = {2094121},
title = {{Deep Convolutional Ranking for Multilabel Image Annotation}},
url = {http://arxiv.org/abs/1312.4894},
year = {2013}
}
@article{Adams,
archivePrefix = {arXiv},
arxivId = {arXiv:1106.1925v2},
author = {Adams, Ryan Prescott and Zemel, Richard S},
eprint = {arXiv:1106.1925v2},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Adams, Zemel - Unknown - Ranking via Sinkhorn Propagation.pdf:pdf},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R},
pages = {1--12},
title = {{Ranking via Sinkhorn Propagation}}
}
@article{Chen2009,
abstract = {Learning to rank has become an important research topic in machine learning. While most learning-to-rank methods learn the ranking functions by minimizing loss functions, it is the ranking measures (such as NDCG and MAP) that are used to evaluate the performance of the learned ranking functions. In this work, we reveal the relationship between ranking measures and loss functions in learningto-rank methods, such as Ranking SVM, RankBoost, RankNet, and ListMLE. We show that the loss functions of these methods are upper bounds of the measurebased ranking errors. As a result, the minimization of these loss functions will lead to the maximization of the ranking measures. The key to obtaining this result is to model ranking as a sequence of classification tasks, and define a so-called essential loss for ranking as the weighted sum of the classification errors of individual tasks in the sequence. We have proved that the essential loss is both an upper bound of the measure-based ranking errors, and a lower bound of the loss functions in the aforementioned methods. Our proof technique also suggests a way to modify existing loss functions to make them tighter bounds of the measure-based ranking errors. Experimental results on benchmark datasets show that the modifications can lead to better ranking performances, demonstrating the correctness of our theoretical analysis.},
author = {Chen, Wei},
doi = {10.1016/S0008-6215(01)00024-6},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Chen - 2009 - Ranking Measures and Loss Function in Learning To Rank.pdf:pdf},
isbn = {9781615679119},
issn = {00086215},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R,400 By Application/Recommendation},
title = {{Ranking Measures and Loss Function in Learning To Rank}},
url = {http://repositorio.ug.edu.ec/bitstream/redug/3012/1/Tesina Cristina Veliz.pdf},
year = {2009}
}

@article{Metzler,
author = {Metzler, Donald},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Metzler - Unknown - Direct Maximization of Rank-based Metrics DRAFT IN PROGRESS.pdf:pdf},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R},
pages = {1--17},
title = {{Direct Maximization of Rank-based Metrics ** DRAFT IN PROGRESS **}}
}
@article{Chen,
author = {Chen, Jingyuan and He, Xiangnan},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Chen, He - Unknown - Attentive Collaborative Filtering Multimedia Recommendation with Item- and Component-Level A ention.pdf:pdf},
isbn = {9781450350228},
keywords = {a ention,collaborative filtering,implicit feedback,multimedia},
mendeley-groups = {200 By Provenance/Suggested By/Colleagues,200 By Provenance/Suggested By/RIT-SM List,100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R},
title = {{Attentive Collaborative Filtering : Multimedia Recommendation with Item- and Component-Level A ention}}
}
@article{Burges2010,
abstract = {LambdaMART is the boosted tree version of LambdaRank, which is based on RankNet. RankNet, LambdaRank, and LambdaMART have proven to be very suc- cessful algorithms for solving real world ranking problems: for example an ensem- ble of LambdaMART rankers won Track 1 of the 2010 Yahoo! Learning To Rank Challenge. The details of these algorithms are spread across several papers and re- ports, and so here we give a self-contained, detailed and complete description of them.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Burges, Chris},
doi = {10.1111/j.1467-8535.2010.01085.x},
eprint = {arXiv:1011.1669v3},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Burges - 2010 - From RankNet to LambdaRank to LambdaMART An Overview.pdf:pdf},
isbn = {0007-1013},
issn = {00071013},
journal = {JMLR},
mendeley-groups = {100 By Project/{\_}{\_}STANFORD,300 By Theory/LETOR L2R},
number = {4},
pages = {574--581},
pmid = {16748998},
title = {{From RankNet to LambdaRank to LambdaMART: An Overview}},
volume = {41},
year = {2010}
}
@article{LI2011,
abstract = {SUMMARY Learning to rank refers to machine learning techniques for training the model in a ranking task. Learning to rank is useful for many applications in Information Retrieval, Natural Language Processing, and Data Mining. Intensive stud-ies have been conducted on the problem and significant progress has been made [1], [2]. This short paper gives an introduction to learning to rank, and it specifically explains the fundamen-tal problems, existing approaches, and future work of learning to rank. Several learning to rank methods using SVM techniques are described in details.},
author = {LI, Hang},
doi = {10.1587/transinf.E94.D.1},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/LI - 2011 - A Short Introduction to Learning to Rank.pdf:pdf},
issn = {0916-8532},
journal = {IEICE Transactions on Information and Systems},
keywords = {information retrieval,language processing,learning to rank,natural,svm},
mendeley-groups = {300 By Theory/LETOR L2R,100 By Project/{\_}{\_}STANFORD},
number = {1},
pages = {1--2},
title = {{A Short Introduction to Learning to Rank}},
url = {http://joi.jlc.jst.go.jp/JST.JSTAGE/transinf/E94.D.1?from=CrossRef},
volume = {E94-D},
year = {2011}
}
@article{KarmakerSantu2017,
abstract = {E-Commerce (E-Com) search is an emerging important new application of information retrieval. Learning to Rank (LETOR) is a general effective strategy for optimizing search engines, and is thus also a key technology for E-Com search. While the use of LETOR for web search has been well studied, its use for E-Com search has not yet been well explored. In this paper, we discuss the practical challenges in applying learning to rank methods to E-Com search, including the challenges in feature representation, obtaining reliable relevance judgments, and optimally exploiting multiple user feedback signals such as click rates, add-to-cart ratios, order rates, and revenue. We study these new challenges using experiments on industry data sets and report several interesting ndings that can provide guidance on how to optimally apply LETOR to E-Com search: First, popularity-based features defined solely on product items are very useful and LETOR methods were able to effectively optimize their combination with relevance-based features. Second, query attribute sparsity raises challenges for LETOR, and selecting features to reduce/avoid sparsity is beneficial. Third, while crowdsourcing is often useful for obtaining relevance judgments for Web search, it does not work as well for E-Com search due to difficulty in eliciting sufficiently fine grained relevance judgments. Finally, among the multiple feedback signals, the order rate is found to be the most robust training objective, followed by click rate, while add-to-cart ratio seems least robust, suggesting that an effective practical strategy may be to initially use click rates for training and gradually shift to using order rates as they become available.},
archivePrefix = {arXiv},
arxivId = {arXiv:1605.08479},
author = {{Karmaker Santu}, Shubhra Kanti and Sondhi, Parikshit and Zhai, ChengXiang},
doi = {10.1145/3077136.3080838},
eprint = {arXiv:1605.08479},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Karmaker Santu, Sondhi, Zhai - 2017 - On Application of Learning to Rank for E-Commerce Search.pdf:pdf},
isbn = {9781450350228},
issn = {15252027},
journal = {SIGIR},
mendeley-groups = {300 By Theory/LETOR L2R,400 By Application/EC,100 By Project/{\_}{\_}{\_}Algo-ITW},
number = {August},
pages = {475--484},
pmid = {6681020133893787756},
title = {{On Application of Learning to Rank for E-Commerce Search}},
url = {http://dl.acm.org/citation.cfm?doid=3077136.3080838},
year = {2017}
}
@inproceedings{Burges2007,
abstract = {The quality measures used in information retrieval are particularly difficult to optimize$\backslash$ndirectly, since they depend on the model scores only through the sorted$\backslash$norder of the documents returned for a given query. Thus, the derivatives of the$\backslash$ncost with respect to the model parameters are either zero, or are undefined. In$\backslash$nthis paper, we propose a class of simple, flexible algorithms, called LambdaRank,$\backslash$nwhich avoids these difficulties by working with implicit cost functions. We describe$\backslash$nLambdaRank using neural network models, although the idea applies to$\backslash$nany differentiable function class. We give necessary and sufficient conditions for$\backslash$nthe resulting implicit cost function to be convex, and we show that the general$\backslash$nmethod has a simple mechanical interpretation. We demonstrate significantly improved$\backslash$naccuracy, over a state-of-the-art ranking algorithm, on several datasets. We$\backslash$nalso show that LambdaRank provides a method for significantly speeding up the$\backslash$ntraining phase of that ranking algorithm. Although this paper is directed towards$\backslash$nranking, the proposed method can be extended to any non-smooth and multivariate$\backslash$ncost functions.},
author = {Burges, Christopher J.C. and Ragno, Robert and {Viet Le}, Quoc},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Burges, Ragno, Viet Le - 2007 - Learning to rank with nonsmooth cost functions.pdf:pdf},
isbn = {9780262195683},
issn = {10495258},
booktitle = {NeurIPS},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R LTR},
title = {{Learning to rank with nonsmooth cost functions}},
year = {2007}
}

@inproceedings{pasumarthi2019tf,
  title={TF-Ranking: Scalable tensorflow library for learning-to-rank},
  author={Pasumarthi, Rama Kumar and Bruch, Sebastian and Wang, Xuanhui and Li, Cheng and Bendersky, Michael and others},
  booktitle={KDD},
  year={2019}
}
% and Najork, Marc and Pfeifer, Jan and Golbandi, Nadav and Anil, Rohan and Wolf, Stephan

@article{qin2010general,
  title={A general approximation framework for direct optimization of information retrieval measures},
  author={Qin, Tao and Liu, Tie-Yan and Li, Hang},
  journal={Information retrieval},
  volume={13},
  number={4},
  pages={375--397},
  year={2010},
  publisher={Springer}
}

@article{rigutini2011sortnet,
  title={SortNet: Learning to rank by a neural preference function},
  author={Rigutini, Leonardo and Papini, Tiziano and Maggini, Marco and Scarselli, Franco},
  journal={IEEE transactions on neural networks},
  volume={22},
  number={9},
  pages={1368--1380},
  year={2011},
  publisher={IEEE}
}

@article{adams2011ranking,
  title={Ranking via sinkhorn propagation},
  author={Adams, Ryan Prescott and Zemel, Richard S},
  journal={arXiv preprint arXiv:1106.1925},
  year={2011}
}

@article{bengio2013estimating,
  title={Estimating or propagating gradients through stochastic neurons for conditional computation},
  author={Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
  journal={arXiv preprint arXiv:1308.3432},
  year={2013}
}

@book{liu2011learning,
  title={Learning to rank for information retrieval},
  author={Liu, Tie-Yan},
  year={2011},
  publisher={Springer Science \& Business Media}
}
@article{Chapelle2011,
abstract = {Learning to rank for information retrieval has gained a lot of interest in the recent years but there is a lack for large real-world datasets to benchmark algorithms. That led us to publicly release two datasets used internally at Yahoo! for learning the web search ranking function. To promote these datasets and foster the development of state-of-the-art learning to rank algorithms, we organized the Yahoo! Learning to Rank Challenge in spring 2010. This paper provides an overview and an analysis of this challenge, along with a detailed description of the released datasets.},
author = {Chapelle, Olivier and Labs, Yahoo},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/chapelle11a.pdf:pdf},
journal = {Challenge},
mendeley-groups = {100 By Project/{\_}{\_}NEURALSORT,300 By Theory/LETOR L2R LTR},
pages = {4--5},
title = {{Yahoo ! Learning to Rank Challenge - Workshop Organizers Yahoo ! Learning to Rank Challenge - Workshop}},
url = {http://proceedings.mlr.press/v14/chapelle11a/chapelle11a.pdf},
volume = {14},
year = {2011}
}

@inproceedings{xiong2017end,
  title={End-to-end neural ad-hoc ranking with kernel pooling},
  author={Xiong, Chenyan and Dai, Zhuyun and Callan, Jamie and Liu, Zhiyuan and Power, Russell},
  booktitle={SIGIR},
  year={2017}
}

@book{luce2012individual,
  title={Individual choice behavior: A theoretical analysis},
  author={Luce, R Duncan},
  year={1959},
  publisher={Courier Corporation}
}


@article{plackett1975analysis,
  title={The analysis of permutations},
  author={Plackett, Robin L},
  journal={Applied Statistics},
  pages={193--202},
  year={1975},
  publisher={JSTOR}
}

@article{zhu2004recall,
  title={Recall, precision and average precision},
  author={Zhu, Mu},
  journal={Department of Statistics and Actuarial Science, University of Waterloo, Waterloo},
  volume={2},
  pages={30},
  year={2004}
}

@article{jarvelin2002cumulated,
  title={Cumulated gain-based evaluation of IR techniques},
  author={J{\"a}rvelin, Kalervo and Kek{\"a}l{\"a}inen, Jaana},
  journal={ACM Transactions on Information Systems},
  volume={20},
  number={4},
  pages={422--446},
  year={2002},
  publisher={ACM}
}

@article{Tange2011a,
  title = {GNU Parallel - The Command-Line Power Tool},
  author = {O. Tange},
  address = {Frederiksberg, Denmark},
  journal = {;login: The USENIX Magazine},
  month = {Feb},
  number = {1},
  volume = {36},
  url = {http://www.gnu.org/s/parallel},
  year = {2011},
  pages = {42-47},
  doi = {http://dx.doi.org/10.5281/zenodo.16303}
}
@inproceedings{cossock2006subset,
  title={Subset ranking using regression},
  author={Cossock, David and Zhang, Tong},
  booktitle={COLT},
  year={2006}
}
@inproceedings{li2008mcrank,
  title={Mcrank: Learning to rank using multiple classification and gradient boosting},
  author={Li, Ping and Wu, Qiang and Burges, Christopher J},
  booktitle={NeurIPS},
  year={2008}
}
@inproceedings{crammer2002pranking,
  title={Pranking with ranking},
  author={Crammer, Koby and Singer, Yoram},
  booktitle={NeurIPS},
  year={2002}
}
@inproceedings{shashua2003ranking,
  title={Ranking with large margin principle: Two approaches},
  author={Shashua, Amnon and Levin, Anat},
  booktitle={NeurIPS},
  year={2003}
}

@article{herbrich2000large,
  title={Large margin rank boundaries for ordinal regression},
  author={Herbrich, Ralf},
  journal={Advances in large margin classifiers},
  pages={115--132},
  year={2000}
}

@article{freund2003efficient,
  title={An efficient boosting algorithm for combining preferences},
  author={Freund, Yoav and Iyer, Raj and Schapire, Robert E and Singer, Yoram},
  journal={JMLR},
  volume={4},
  number={Nov},
  pages={933--969},
  year={2003}
}


@inproceedings{zheng2008general,
  title={A general boosting method and its application to learning ranking functions for web search},
  author={Zheng, Zhaohui and Zha, Hongyuan and Zhang, Tong and Chapelle, Olivier and Chen, Keke and Sun, Gordon},
  booktitle={NeurIPS},
  year={2008}
}


@inproceedings{cao2006adapting,
  title={Adapting ranking SVM to document retrieval},
  author={Cao, Yunbo and Xu, Jun and Liu, Tie-Yan and Li, Hang and Huang, Yalou and Hon, Hsiao-Wuen},
  booktitle={SIGIR},
  year={2006}
}


@inproceedings{cao2007learning,
  title={Learning to rank: from pairwise approach to listwise approach},
  author={Cao, Zhe and Qin, Tao and Liu, Tie-Yan and Tsai, Ming-Feng and Li, Hang},
  booktitle={ICML},
  year={2007}
}

@article{Covington2016,
abstract = {YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous userfacing impact.},
author = {Covington, Paul and Adams, Jay and Sargin, Emre},
doi = {10.1145/2959100.2959190},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Covington, Adams, Sargin - 2016 - Deep neural networks for youtube recommendations.pdf:pdf},
isbn = {9781450340359},
journal = {RecSys 2016 - Proceedings of the 10th ACM Conference on Recommender Systems},
keywords = {Deep learning,Recommender system,Scalability},
pages = {191--198},
title = {{Deep neural networks for youtube recommendations}},
year = {2016}
}


@inproceedings{xia2008listwise,
  title={Listwise approach to learning to rank: theory and algorithm},
  author={Xia, Fen and Liu, Tie-Yan and Wang, Jue and Zhang, Wensheng and Li, Hang},
  booktitle={ICML},
  year={2008}
}



@inproceedings{duchi2010consistency,
  title={On the Consistency of Ranking Algorithms.},
  author={Duchi, John C and Mackey, Lester W and Jordan, Michael I},
  booktitle={ICML},
  year={2010}
}

@inproceedings{xu2007adarank,
  title={Adarank: a boosting algorithm for information retrieval},
  author={Xu, Jun and Li, Hang},
  booktitle={SIGIR},
  year={2007}
}


@inproceedings{yue2007support,
  title={A support vector method for optimizing average precision},
  author={Yue, Yisong and Finley, Thomas and Radlinski, Filip and Joachims, Thorsten},
  booktitle={SIGIR},
  year={2007}
}

@inproceedings{joachims2016counterfactual,
  title={Counterfactual evaluation and learning for search, recommendation and ad placement},
  author={Joachims, Thorsten and Swaminathan, Adith},
  booktitle={SIGIR},
  organization={ACM}
}




@article{Vahdat2018,
abstract = {Training of discrete latent variable models remains challenging because passing gradient information through discrete units is difficult. We propose a new class of smoothing transformations based on a mixture of two overlapping distributions, and show that the proposed transformation can be used for training binary latent models with either directed or undirected priors. We derive a new variational bound to efficiently train with Boltzmann machine priors. Using this bound, we develop DVAE++, a generative model with a global discrete prior and a hierarchy of convo-lutional continuous variables. Experiments on several benchmarks show that overlapping transformations outperform other recent continuous relaxations of discrete latent variables including Gumbel-Softmax (Maddison et al., 2016; Jang et al., 2016), and discrete variational autoencoders (Rolfe, 2016). Copyright 2018 by the author(s).},
archivePrefix = {arXiv},
arxivId = {1802.04920},
author = {Vahdat, Arash and Macready, William G. and Bian, Zhengbing and Khoshaman, Amir and Andriyash, Evgeny},
eprint = {1802.04920},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Vahdat et al. - 2018 - DVAE Discrete variational autoencoders with overlapping transformations.pdf:pdf},
isbn = {9781510867963},
journal = {ICML},
mendeley-groups = {300 By Theory/LETOR L2R LTR},
pages = {8008--8023},
title = {{DVAE++: Discrete variational autoencoders with overlapping transformations}},
volume = {11},
year = {2018}
}
@article{Rolfe2019,
abstract = {Probabilistic models with discrete latent variables naturally capture datasets composed of discrete classes. However, they are difficult to train efficiently, since backpropagation through discrete variables is generally not possible. We present a novel method to train a class of probabilistic models with discrete latent variables using the variational autoencoder framework, including backpropagation through the discrete latent variables. The associated class of probabilistic models comprises an undirected discrete component and a directed hierarchical continuous component. The discrete component captures the distribution over the disconnected smooth manifolds induced by the continuous component. As a result, this class of models efficiently learns both the class of objects in an image, and their specific realization in pixels, from unsupervised data; and outperforms state-of-the-art methods on the permutation-invariant MNIST, Omniglot, and Caltech-101 Silhouettes datasets.},
archivePrefix = {arXiv},
arxivId = {1609.02200},
author = {Rolfe, Jason Tyler},
eprint = {1609.02200},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Rolfe - 2019 - Discrete variational autoencoders.pdf:pdf},
journal = {ICLR},
mendeley-groups = {300 By Theory/LETOR L2R LTR},
title = {{Discrete variational autoencoders}},
year = {2019}
}
@article{Donmez2009,
abstract = {A machine learning approach to learning to rank trains a model to optimize a target evaluation measure with repect to training data. Currently, existing information retrieval measures are impossible to optimize directly except for models with a very small number of parameters. The IR community thus faces a major challenge: how to optimize IR measures of interest directly. In this paper, we present a solution. Specifically, we show that LambdaRank, which smoothly approximates the gradient of the target measure, can be adapted to work with four popular IR target evaluation measures using the same underlying gradient construction. It is likely, therefore, that this construction is extendable to other evaluation measures. We empirically show that LambdaRank finds a locally optimal solution for mean NDCG@10, mean NDCG, MAP and MRR with a 99{\%} confidence rate. We also show that the amount of effective training data varies with IR measure and that with a sufficiently large training set size, matching the training optimization measure to the target evaluation measure yields the best accuracy. Copyright 2009 ACM.},
author = {Donmez, Pinar and Svore, Krysta M. and Burges, Christopher J.C.},
doi = {10.1145/1571941.1572021},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Donmez, Svore, Burges - 2009 - On the local optimality of LambdaRank.pdf:pdf},
isbn = {9781605584836},
journal = {SIGIR},
keywords = {Learning to rank,Web search},
mendeley-groups = {300 By Theory/LETOR L2R LTR},
pages = {460--467},
title = {{On the local optimality of LambdaRank}},
year = {2009}
}
@article{Cho2015,
abstract = {Graphical Model (GM) has provided a popular framework for big data analytics because it often lends itself to distributed and parallel processing by utilizing graph-based 'local' structures. It models correlated random variables where in particular, the max-product Belief Propagation (BP) is the most popular heuristic to compute the most-likely assignment in GMs. In the past years, it has been proven that BP can solve a few classes of combinatorial optimization problems under certain conditions. Motivated by this, we explore the prospect of using BP to solve generic combinatorial optimization problems. The challenge is that, in practice, BP may converge very slowly and even if it does converge, the BP decision often violates the constraints of the original problem. This paper proposes a generic framework that enables us to apply BP-based algorithms to compute an approximate feasible solution for an arbitrary combinatorial optimization task. The main novel ingredients include (a) careful initialization of BP messages, (b) hybrid damping on BP updates, and (c) post-processing using BP beliefs. Utilizing the framework, we develop parallel algorithms for several large-scale combinatorial optimization problems including maximum weight matching, vertex cover and independent set. We demonstrate that our framework delivers high approximation ratio, speeds up the process by parallelization, and allows large-scale processing involving billions of variables.},
author = {Cho, Inho and Park, Soya and Park, Sejun and Han, Dongsu and Shin, Jinwoo},
doi = {10.1109/BigData.2015.7363737},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Cho et al. - 2015 - Practical message-passing framework for large-scale combinatorial optimization.pdf:pdf},
isbn = {9781479999255},
journal = {Proceedings - 2015 IEEE International Conference on Big Data, IEEE Big Data 2015},
keywords = {Belief propagation,Combinatorial optimization,Maximum weighted matching,Parallel algorithm},
mendeley-groups = {300 By Theory/LETOR L2R LTR},
pages = {24--31},
title = {{Practical message-passing framework for large-scale combinatorial optimization}},
year = {2015}
}
@article{Singh2019,
abstract = {Conventional Learning-to-Rank (LTR) methods optimize the utility of the rankings to the users, but they are oblivious to their impact on the ranked items. However, there has been a growing understanding that the latter is important to consider for a wide range of ranking applications (e.g. online marketplaces, job placement, admissions). To address this need, we propose a general LTR framework that can optimize a wide range of utility metrics (e.g. NDCG) while satisfying fairness of exposure constraints with respect to the items. This framework expands the class of learnable ranking functions to stochastic ranking policies, which provides a language for rigorously expressing fairness specifications. Furthermore, we provide a new LTR algorithm called Fair-PG-Rank for directly searching the space of fair ranking policies via a policy-gradient approach. Beyond the theoretical evidence in deriving the framework and the algorithm, we provide empirical results on simulated and real-world datasets verifying the effectiveness of the approach in individual and group-fairness settings.},
archivePrefix = {arXiv},
arxivId = {1902.04056},
author = {Singh, Ashudeep and Joachims, Thorsten},
eprint = {1902.04056},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Singh, Joachims - 2019 - Policy Learning for Fairness in Ranking.pdf:pdf},
mendeley-groups = {300 By Theory/LETOR L2R LTR},
pages = {1--16},
title = {{Policy Learning for Fairness in Ranking}},
url = {http://arxiv.org/abs/1902.04056},
year = {2019}
}
@article{Wang2013,
abstract = {A central problem in ranking is to design a measure for evaluation of ranking functions. In this paper we study, from a theoretical perspective, the Normalized Discounted Cumulative Gain (NDCG) which is a family of ranking measures widely used in practice. Although there are extensive empirical studies of the NDCG family, little is known about its theoretical properties. We first show that, whatever the ranking function is, the standard NDCG which adopts a logarithmic discount, converges to 1 as the number of items to rank goes to infinity. On the first sight, this result seems to imply that the standard NDCG cannot differentiate good and bad ranking functions on large datasets, contradicting to its empirical success in many applications. In order to have a deeper understanding of the general NDCG ranking measures, we propose a notion referred to as consistent distin-guishability. This notion captures the intuition that a ranking measure should have such a property: For every pair of substantially different ranking functions, the ranking measure can decide which one is better in a consistent manner on almost all datasets. We show that standard NDCG has consistent distinguishability although it converges to the same limit for all ranking functions. We next characterize the set of all feasible discount functions for NDCG according to the concept of consistent distinguishability. Specifically we show that whether an NDCG measure has consistent distinguishability depends on how fast the discount decays; and r-1 is a critical point. We then turn to the cut-off version of NDCG, i.e., NDCG@k. We analyze the distinguishability of NDCG@k for various choices of k and the discount functions. Experimental results on real Web search datasets agree well with the theory. {\textcopyright} 2013 Y. Wang, L. Wang, Y. Li, D. He, W. Chen {\&} T.-Y. Liu.},
archivePrefix = {arXiv},
arxivId = {1304.6480},
author = {Wang, Yining and Wang, Liwei and Li, Yuanzhi and He, Di and Chen, Wei and Liu, Tie Yan},
eprint = {1304.6480},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Wang et al. - 2013 - A theoretical analysis of NDCG ranking measures.pdf:pdf},
issn = {15337928},
journal = {JMLR},
keywords = {Consistent Distinguishability,NDCG,Ranking,Ranking measures},
mendeley-groups = {300 By Theory/LETOR L2R LTR},
pages = {25--54},
title = {{A theoretical analysis of NDCG ranking measures}},
volume = {30},
year = {2013}
}
@article{Wu2011,
abstract = {Learning to rank has received great attention in recent years as it plays a crucial role in information retrieval. The existing concept of learning to rank assumes that each training sample is associated with an instance and a reliable label. However, in practice, this assumption does not necessarily hold true. This study focuses on the learning to rank when each training instance is labeled by multiple annotators that may be unreliable. In such a scenario, no accurate labels can be obtained. This study proposes two learning approaches. One is to simply estimate the ground truth first and then to learn a ranking model with it. The second approach is a maximum likelihood learning approach which estimates the ground truth and learns the ranking model iteratively. The two approaches have been tested on both synthetic and real-world data. The results reveal that the maximum likelihood approach outperforms the first approach significantly and is comparable of achieving results with the learning model considering reliable labels. Further more, both the approaches have been applied for ranking the Web visual clutter.},
author = {Wu, Ou and Hu, Weiming and Gao, Jun},
doi = {10.5591/978-1-57735-516-8/IJCAI11-264},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Wu, Hu, Gao - 2011 - Learning to rank under multiple annotators.pdf:pdf},
isbn = {9781577355120},
issn = {10450823},
journal = {IJCAI},
mendeley-groups = {300 By Theory/LETOR L2R LTR},
pages = {1571--1576},
title = {{Learning to rank under multiple annotators}},
year = {2011}
}
@article{Liang2019,
abstract = {We propose Top-N-Rank, a novel family of list-wise Learning-to-Rank models for reliably recommending the N top-ranked items. The proposed models optimize a variant of the widely used cumulative discounted gain (DCG) objective function which differs from DCG in two important aspects: (i) It limits the evaluation of DCG only on the top N items in the ranked lists, thereby eliminating the impact of low-ranked items on the learned ranking function; and (ii) it incorporates weights that allow the model to leverage multiple types of implicit feedback with differing levels of reliability or trustworthiness. Because the resulting objective function is non-smooth and hence challenging to optimize, we consider two smooth approximations of the objective function, using the traditional sigmoid function and the rectified linear unit (ReLU). We propose a family of learning-to-rank algorithms (Top-N-Rank) that work with any smooth objective function. Then, a more efficient variant, Top-N-Rank.ReLU, is introduced, which effectively exploits the properties of ReLU function to reduce the computational complexity of Top-N-Rank from quadratic to linear in the average number of items rated by users. The results of our experiments using two widely used benchmarks, namely, the MovieLens data set and the Amazon Video Games data set demonstrate that: (i) The Â»top-N truncationÂ» of the objective function substantially improves the ranking quality of the top N recommendations; (ii) using the ReLU for smoothing the objective function yields significant improvement in both ranking quality as well as runtime as compared to using the sigmoid; and (iii) Top-N-Rank.ReLU substantially outperforms the well-performing list-wise ranking methods in terms of ranking quality.},
archivePrefix = {arXiv},
arxivId = {1812.04109},
author = {Liang, Junjie and Hu, Jinlong and Dong, Shoubin and Honavar, Vasant},
doi = {10.1109/BigData.2018.8621994},
eprint = {1812.04109},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Liang et al. - 2019 - Top-N-Rank A Scalable List-wise Ranking Method for Recommender Systems.pdf:pdf},
isbn = {9781538650356},
journal = {Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018},
keywords = {latent factor model,learning to rank,list-wise ranking,rectifier function,top n recommendation},
mendeley-groups = {300 By Theory/LETOR L2R LTR},
pages = {1052--1058},
title = {{Top-N-Rank: A Scalable List-wise Ranking Method for Recommender Systems}},
year = {2019}
}
@article{Wang2018,
abstract = {How to optimize ranking metrics such as Normalized Discounted Cumulative Gain (NDCG) is an important but challenging problem, because ranking metrics are either flat or discontinuous everywhere, which makes them hard to be optimized directly. Among existing approaches, LambdaRank is a novel algorithm that incorporates ranking metrics into its learning procedure. Though empirically effective, it still lacks theoretical justification. For example, the underlying loss that LambdaRank optimizes for remains unknown until now. Due to this, there is no principled way to advance the LambdaRank algorithm further. In this paper, we present LambdaLoss, a probabilistic framework for ranking metric optimization. We show that LambdaRank is a special configuration with a well-defined loss in the LambdaLoss framework, and thus provide theoretical justification for it. More importantly, the LambdaLoss framework allows us to define metric-driven loss functions that have clear connection to different ranking metrics. We show a few cases in this paper and evaluate them on three publicly available data sets. Experimental results show that our metric-driven loss functions can significantly improve the state-of-the-art learning-to-rank algorithms.},
author = {Wang, Xuanhui and Li, Cheng and Golbandi, Nadav and Bendersky, Michael and Najork, Marc},
doi = {10.1145/3269206.3271784},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Wang et al. - 2018 - The LambdaLoss framework for ranking metric optimization.pdf:pdf},
isbn = {9781450360142},
journal = {CIKM},
keywords = {LambdaLoss,LambdaRank,Ranking metric optimization},
mendeley-groups = {300 By Theory/LETOR L2R LTR},
title = {{The LambdaLoss framework for ranking metric optimization}},
year = {2018}
}
@article{Pang2019,
abstract = {In learning-to-rank for information retrieval, a ranking model is automatically learned from the data and then utilized to rank the sets of retrieved documents. Therefore, an ideal ranking model would be a mapping from a document set to a permutation on the set, and should satisfy two critical requirements: (1){\~{}}it should have the ability to model cross-document interactions so as to capture local context information in a query; (2){\~{}}it should be permutation-invariant, which means that any permutation of the inputted documents would not change the output ranking. Previous studies on learning-to-rank either design uni-variate scoring functions that score each document separately, and thus failed to model the cross-document interactions; or construct multivariate scoring functions that score documents sequentially, which inevitably sacrifice the permutation invariance requirement. In this paper, we propose a neural learning-to-rank model called SetRank which directly learns a permutation-invariant ranking model defined on document sets of any size. SetRank employs a stack of (induced) multi-head self attention blocks as its key component for learning the embeddings for all of the retrieved documents jointly. The self-attention mechanism not only helps SetRank to capture the local context information from cross-document interactions, but also to learn permutation-equivariant representations for the inputted documents, which therefore achieving a permutation-invariant ranking model. Experimental results on three large scale benchmarks showed that the SetRank significantly outperformed the baselines include the traditional learning-to-rank models and state-of-the-art Neural IR models.},
archivePrefix = {arXiv},
arxivId = {1912.05891},
author = {Pang, Liang and Xu, Jun and Ai, Qingyao and Lan, Yanyan and Cheng, Xueqi and Wen, Jirong},
eprint = {1912.05891},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Pang et al. - 2019 - SetRank Learning a Permutation-Invariant Ranking Model for Information Retrieval.pdf:pdf},
mendeley-groups = {300 By Theory/LETOR L2R LTR},
title = {{SetRank: Learning a Permutation-Invariant Ranking Model for Information Retrieval}},
url = {http://arxiv.org/abs/1912.05891},
year = {2019}
}
@article{Weston2013,
abstract = {We consider the case of ranking a very large set of labels, items, or documents, which is common to information retrieval, recommendation, and large-scale annotation tasks. We present a general approach for converting an algorithm which has linear time in the size of the set to a sublinear one via label partitioning. Our method consists of learning an input partition and a label assignment to each partition of the space such that precision at k is optimized, which is the loss function of interest in this setting. Experiments on large-scale ranking and recommendation tasks show that our method not only makes the original linear time algorithm computationally tractable, but can also improve its performance. Copyright 2013 by the author(s).},
author = {Weston, Jason and Makadia, Ameesh and Yee, Hector},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Weston, Makadia, Yee - 2013 - Label partitioning for sublinear ranking.pdf:pdf},
journal = {ICML},
mendeley-groups = {300 By Theory/LETOR L2R LTR},
number = {PART 1},
pages = {840--848},
title = {{Label partitioning for sublinear ranking}},
volume = {28},
year = {2013}
}
@inproceedings{Cuturi2019,
archivePrefix = {arXiv},
arxivId = {1905.11885},
author = {Cuturi, Marco and Teboul, Olivier and Vert, Jean-Philippe},
eprint = {1905.11885},
file = {:Users/robin.swezey/Google Drive/ALL/Lecture/Mendeley Desktop/Cuturi, Teboul, Vert - 2019 - Differentiable Ranks and Sorting using Optimal Transport.pdf:pdf},
mendeley-groups = {300 By Theory/LETOR L2R LTR},
booktitle = {NeurIPS},
title = {{Differentiable Ranks and Sorting using Optimal Transport}},
url = {http://arxiv.org/abs/1905.11885},
year = {2019}
}

@inproceedings{blondel2020fast,
  title={Fast Differentiable Sorting and Ranking},
  author={Blondel, Mathieu and Teboul, Olivier and Berthet, Quentin and Djolonga, Josip},
  booktitle={ICML},
  year={2020}
}

@inproceedings{prillo2020softsort,
  title={SoftSort: A continuous relaxation for the argsort operator},
  author={Prillo, Sebastian and Eisenschlos, Julian},
  booktitle={ICML},
  year={2020}
}

@article{xie2020differentiable,
  title={Differentiable Top-k Operator with Optimal Transport},
  author={Xie, Yujia and Dai, Hanjun and Chen, Minshuo and Dai, Bo and Zhao, Tuo and others},
  journal={arXiv preprint arXiv:2002.06504},
  year={2020}
}

% Zha, Hongyuan and Wei, Wei and Pfister, Tomas

@inproceedings{Reddi2021RankDistilKD,
  title={RankDistil: Knowledge Distillation for Ranking},
  author={Sashank J. Reddi and Rama Kumar Pasumarthi and Aditya Krishna Menon and Ankit Singh Rawat and Felix X. Yu and Seungyeon Kim and Andreas Veit and Sanjiv Kumar},
  booktitle={AISTATS},
  year={2021}
}