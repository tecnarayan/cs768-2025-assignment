

@book {meckes,
    AUTHOR = {Meckes, E.},
     TITLE = {\href{https://doi.org/10.1017/9781108303453.009}{The random matrix theory of the classical compact groups}},
    SERIES = {Cambridge Tracts in Mathematics},
    VOLUME = {218},
 PUBLISHER = {Cambridge University Press, Cambridge},
      YEAR = {2019},
     PAGES = {xi+212}
}

@misc{mccandlish18,
  journal = {arXiv preprint arXiv:1812.06162},
  author = {McCandlish, S. and Kaplan, J. and Amodei, D. and Team, OpenAI Dota},
  title = {\href{https://arxiv.org/abs/1812.06162}{An Empirical Model of Large-Batch Training}},
  year = {2018}
}

@InProceedings{paquette21a,
  title = 	 {SGD in the Large: Average-case Analysis, Asymptotics, and Stepsize Criticality},
  author =      {Paquette, C. and Lee, K. and Pedregosa, F. and Paquette, E.},
  booktitle = 	 {Proceedings of Thirty Fourth Conference on Learning Theory (COLT)},
  pages = 	 {3548--3626},
  year = 	 {2021},
  volume = 	 {134},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v134/paquette21a/paquette21a.pdf},
  url = 	 {https://proceedings.mlr.press/v134/paquette21a.html},
}

@article{bardenet15,
author = {R. Bardenet and Odalric-Ambrym M.},
title = {{Concentration inequalities for sampling without replacement}},
volume = {21},
journal = {Bernoulli},
number = {3},
publisher = {Bernoulli Society for Mathematical Statistics and Probability},
pages = {1361 -- 1385},
keywords = {Bernstein, Concentration bounds, sampling without replacement, Serfling},
year = {2015},
doi = {10.3150/14-BEJ605},
URL = {https://doi.org/10.3150/14-BEJ605}
}

@inproceedings{ma2018,
  title={The power of interpolation: Understanding the effectiveness of SGD in modern over-parametrized learning},
  author={Ma, S. and Bassily, R. and Belkin, M.},
  booktitle={International Conference on Machine Learning},
  pages={3325--3334},
  year={2018},
  organization={PMLR}
}

@book{vershynin18, 
place={Cambridge}, series={Cambridge Series in Statistical and Probabilistic Mathematics}, title={High-Dimensional Probability: An Introduction with Applications in Data Science}, DOI={10.1017/9781108231596}, publisher={Cambridge University Press}, author={Vershynin, R.}, year={2018}, collection={Cambridge Series in Statistical and Probabilistic Mathematics}}

@article{adamczak15,
author = {R. Adamczak},
title = {{A note on the Hanson-Wright inequality for random vectors with dependencies}},
volume = {20},
journal = {Electronic Communications in Probability},
number = {none},
publisher = {Institute of Mathematical Statistics and Bernoulli Society},
pages = {1 -- 13},
keywords = {concentration of measure, empirical covariance operator, Hanson-Wright inequality, Quadratic forms},
year = {2015},
doi = {10.1214/ECP.v20-3829},
URL = {https://doi.org/10.1214/ECP.v20-3829}
}

@InProceedings{sutskever13,
  title = 	 {On the importance of initialization and momentum in deep learning},
  author = 	 {Sutskever, I. and Martens, J. and Dahl, G. and Hinton, G.},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning (ICML)},
  pages = 	 {1139--1147},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/sutskever13.pdf},
  url = 	 {https://proceedings.mlr.press/v28/sutskever13.html},
}


@InProceedings{flammarion15,
  title = 	 {From Averaging to Acceleration, There is Only a Step-size},
  author = 	 {Flammarion, N. and Bach, F.},
  booktitle = 	 {Proceedings of The 28th Conference on Learning Theory},
  pages = 	 {658--695},
  year = 	 {2015},
  editor = 	 {Gr√ºnwald, Peter and Hazan, Elad and Kale, Satyen},
  volume = 	 {40},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Paris, France},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v40/Flammarion15.pdf},
  url = 	 {https://proceedings.mlr.press/v40/Flammarion15.html},
}

@article{gadat18,
author = {S. Gadat and F. Panloup and S. Saadane},
title = {{Stochastic heavy ball}},
volume = {12},
journal = {Electronic Journal of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics and Bernoulli Society},
pages = {461 -- 529},
keywords = {Random dynamical systems, second-order methods, Stochastic optimization algorithms},
year = {2018},
doi = {10.1214/18-EJS1395},
URL = {https://doi.org/10.1214/18-EJS1395}
}

@INPROCEEDINGS{kidambi2018,  author={Kidambi, R. and Netrapalli, P. and Jain, P. and Kakade, S.},  booktitle={2018 Information Theory and Applications Workshop (ITA)},   title={On the Insufficiency of Existing Momentum Schemes for Stochastic Optimization},   year={2018},  volume={},  number={},  pages={1-9},  doi={10.1109/ITA.2018.8503173}}

@article{loizou20,
author = {Loizou, N. and Richtarik, P.},
title = {Momentum and stochastic momentum for stochastic gradient, Newton, proximal point and subspace descent methods},
journal = {Comput Optim Appl},
year = {2020},
URL = {https://doi.org/10.1007/s10589-020-00220-z},
volume = {77},
pages = {653--710}
}


@InProceedings{sebbouh21,
  title = 	 {Almost sure convergence rates for Stochastic Gradient Descent and Stochastic Heavy Ball},
  author =       {Sebbouh, O. and Gower, R. and Defazio, A.},
  booktitle = 	 {Proceedings of Thirty Fourth Conference on Learning Theory (COLT)},
  pages = 	 {3935--3971},
  year = 	 {2021},
  volume = 	 {134},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v134/sebbouh21a/sebbouh21a.pdf},
  url = 	 {https://proceedings.mlr.press/v134/sebbouh21a.html},
  
}



@InProceedings{orvieto20,
  title = 	 {The Role of Memory in Stochastic Optimization},
  author =       {Orvieto, A. and Kohler, J. and Lucchi, A.},
  booktitle = 	 {Proceedings of The 35th Uncertainty in Artificial Intelligence Conference},
  pages = 	 {356--366},
  year = 	 {2020},
  editor = 	 {Adams, Ryan P. and Gogate, Vibhav},
  volume = 	 {115},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v115/orvieto20a/orvieto20a.pdf},
  url = 	 {https://proceedings.mlr.press/v115/orvieto20a.html},
}

@inproceedings{zhang19,
 author = {Zhang, G. and Li, L. and Nado, Z. and Martens, J. and Sachdeva, S. and Dahl, G. and Shallue, C. and Grosse, R.},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 pages = {},
 title = {Which Algorithmic Choices Matter at Which Batch Sizes?  Insights From a Noisy Quadratic Model},
 url = {https://proceedings.neurips.cc/paper/2019/file/e0eacd983971634327ae1819ea8b6214-Paper.pdf},
 volume = {32},
 year = {2019}
}

@inproceedings{de17,
  title={\href{http://proceedings.mlr.press/v54/de17a/de17a.pdf}{Big Batch SGD: Automated Inference using Adaptive Batch Sizes}},
  author={De, S. and Yadav, A. and Jacobs, D. and  Goldstein, T.},
  booktitle={Proceedings of the 20th International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year={2017}
}

@inproceedings{smith18,
title={\href{https://openreview.net/forum?id=B1Yy1BxCZ}{Don't Decay the Learning Rate, Increase the Batch Size}},
author={Smith, S.L. and Kindermans, P.-J. and Ying, C. and Le, Q. V.},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018}
}


@book {asmussen03,
    AUTHOR = {Asmussen, S.},
     TITLE = {\href{https://link.springer.com/book/10.1007/b97236}{Applied probability and queues}},
    SERIES = {Applications of Mathematics (New York)},
    VOLUME = {51},
   EDITION = {Second},
      NOTE = {Stochastic Modelling and Applied Probability},
 PUBLISHER = {Springer-Verlag, New York},
      YEAR = {2003},
     PAGES = {xii+438}
}



@article {adamczak,
    AUTHOR = {Adamczak, Rados\l aw},
     TITLE = {A note on the {H}anson-{W}right inequality for random vectors
              with dependencies},
   JOURNAL = {Electron. Commun. Probab.},
  FJOURNAL = {Electronic Communications in Probability},
    VOLUME = {20},
      YEAR = {2015},
     PAGES = {no. 72, 13},
   MRCLASS = {60E15 (60B11)},
  MRNUMBER = {3407216},
MRREVIEWER = {Deli Li},
       DOI = {10.1214/ECP.v20-3829},
       URL = {https://doi-org.proxy3.library.mcgill.ca/10.1214/ECP.v20-3829},
}

@inproceedings{adlam2020understanding,
 author = {Adlam, Ben and Pennington, Jeffrey},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {11022--11032},
 publisher = {Curran Associates, Inc.},
 title = {\href{https://proceedings.neurips.cc/paper/2020/file/7d420e2b2939762031eed0447a9be19f-Paper.pdf}{Understanding Double Descent Requires A Fine-Grained Bias-Variance Decomposition}},
 volume = {33},
 year = {2020}
}

@article{zou2022risk,
  title={\href{ https://arxiv.org/abs/2203.03159}{Risk Bounds of Multi-Pass SGD for Least Squares in the Interpolation Regime}},
  author={Zou, Difan and Wu, Jingfeng and Braverman, Vladimir and Gu, Quanquan and Kakade, Sham M.},
  journal={arXiv preprint arXiv:2203.03159},
  year={2022}
}

  
@article {ginsburg1959regined,
    AUTHOR = {Engeli, M. and Ginsburg, Th. and Rutishauser, H. and Stiefel,
              E.},
     TITLE = {Refined iterative methods for computation of the solution and
              the eigenvalues of self-adjoint boundary value problems},
   JOURNAL = {Mitt. Inst. Angew. Math. Z\"{u}rich},
  FJOURNAL = {Mitteilungen aus dem Institut f\"{u}r Angewandte Mathematik an der
              Eidgen\"{o}ssischen Technischen Hochschule in Z\"{u}rich},
    VOLUME = {8},
      YEAR = {1959},
     PAGES = {107},
}

@article{kale2021sgd,
  title={Sgd: The role of implicit regularization, batch-size and multiple-epochs},
  author={Kale, Satyen and Sekhari, Ayush and Sridharan, Karthik},
  journal={arXiv preprint arXiv:2107.05074},
  year={2021}
}

@article{amir2021never,
  title={Never go full batch (in stochastic convex optimization)},
  author={Amir, Idan and Carmon, Yair and Koren, Tomer and Livni, Roi},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{amir2021sgd,
  title={SGD generalizes better than GD (and regularization doesn‚Äôt help)},
  author={Amir, Idan and Koren, Tomer and Livni, Roi},
  booktitle={Conference on Learning Theory},
  pages={63--92},
  year={2021},
  organization={PMLR}
}


@article{kunin2021rethinking,
  title={Rethinking the limiting dynamics of SGD: modified loss, phase space oscillations, and anomalous diffusion},
  author={Kunin, Daniel and Sagastuy-Brena, Javier and Gillespie, Lauren and Margalit, Eshed and Tanaka, Hidenori and Ganguli, Surya and Yamins, Daniel LK},
  journal={arXiv preprint arXiv:2107.09133},
  year={2021}
}

@article{smith2021origin,
  title={On the origin of implicit regularization in stochastic gradient descent},
  author={Smith, Samuel L and Dherin, Benoit and Barrett, David GT and De, Soham},
  journal={arXiv preprint arXiv:2101.12176},
  year={2021}
}

@article{lewkowycz2020large,
  title={The large learning rate phase of deep learning: the catapult mechanism},
  author={Lewkowycz, Aitor and Bahri, Yasaman and Dyer, Ethan and Sohl-Dickstein, Jascha and Gur-Ari, Guy},
  journal={arXiv preprint arXiv:2003.02218},
  year={2020}
}

@article{hochreiter1997flat,
  title={Flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={1},
  pages={1--42},
  year={1997},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~‚Ä¶}
}

@article{zhu2018anisotropic,
  title={The anisotropic noise in stochastic gradient descent: Its behavior of escaping from sharp minima and regularization effects},
  author={Zhu, Zhanxing and Wu, Jingfeng and Yu, Bing and Wu, Lei and Ma, Jinwen},
  journal={arXiv preprint arXiv:1803.00195},
  year={2018}
}

@article{bouchaud1990anomalous,
  title={Anomalous diffusion in disordered media: statistical mechanisms, models and physical applications},
  author={Bouchaud, Jean-Philippe and Georges, Antoine},
  journal={Physics reports},
  volume={195},
  number={4-5},
  pages={127--293},
  year={1990},
  publisher={Elsevier}
}

@article{keskar2016large,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1609.04836},
  year={2016}
}

@article{hoffer2017train,
  title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  author={Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@InProceedings{adlam2020neural,
  title = 	 {\href{http://proceedings.mlr.press/v119/adlam20a/adlam20a.pdf}{The Neural Tangent Kernel in High Dimensions: Triple Descent and a Multi-Scale Theory of Generalization}},
  author =       {Adlam, B. and Pennington, J.},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning (ICML)},
  pages = 	 {74--84},
  year = 	 {2020},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
}


@inproceedings{paquette2021dynamics,
 author = {Paquette, C. and Paquette, E.},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 pages = {},
 title = {\href{https://papers.nips.cc/paper/2021/hash/4cf0ed8641cfcbbf46784e620a0316fb-Abstract.html}{Dynamics of Stochastic Momentum Methods on
Large-scale, Quadratic Models}},
 volume = {34},
 year = {2021}
}

@book {revuz1999continuous,
    AUTHOR = {Revuz, D. and Yor, M.},
     TITLE = {Continuous martingales and {B}rownian motion},
    SERIES = {Grundlehren der mathematischen Wissenschaften [Fundamental
              Principles of Mathematical Sciences]},
    VOLUME = {293},
   EDITION = {Third},
 PUBLISHER = {Springer-Verlag, Berlin},
      YEAR = {1999},
     PAGES = {xiv+602},
       DOI = {10.1007/978-3-662-06400-9},
}
	

@article{li2019stochastic,
  author  = {Li, Q. and Tai, C. and E, W.},
  title   = {\href{http://jmlr.org/papers/v20/17-526.html}{Stochastic Modified Equations and Dynamics of Stochastic Gradient Algorithms I: Mathematical Foundations}},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {40},
  pages   = {1-47}
}

@misc{lecun2010mnist,
  title={"MNIST" handwritten digit database},
  author={LeCun, Y. and Cortes, C. and Burges, C.},
  year={2010},
  url={http://yann. lecun. com/exdb/mnist},
  publisher={Florham Park, NJ, USA}
}

@article{allen2017katyusha,
  title={\href{https://jmlr.org/papers/volume18/16-410/16-410.pdf}{Katyusha: The first direct acceleration of stochastic gradient methods}},
  author={Allen-Zhu, Z.},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={8194--8244},
  year={2017},
  publisher={JMLR.org}
}

@InProceedings{pennington2017geometry,
  title = 	 {\href{http://proceedings.mlr.press/v70/pennington17a/pennington17a.pdf}{Geometry of Neural Network Loss Surfaces via Random Matrix Theory}},
  author =       {J. Pennington and Yasaman B.},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning (ICML)},
  pages = 	 {2798--2806},
  year = 	 {2017},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research}
}
}


@book {korevaar2004tauberian,
    AUTHOR = {Korevaar, J.},
     TITLE = {Tauberian theory},
    SERIES = {Grundlehren der Mathematischen Wissenschaften [Fundamental
              Principles of Mathematical Sciences]},
    VOLUME = {329},
 PUBLISHER = {Springer-Verlag, Berlin},
      YEAR = {2004},
     PAGES = {xvi+483},
       DOI = {10.1007/978-3-662-10225-1},
}

@ARTICLE{granziol2020learning,
       author = {{Granziol}, D. and {Zohren}, S. and {Roberts}, S.},
        title = {\href{https://arxiv.org/pdf/2006.09092.pdf}{Learning Rates as a Function of Batch Size: A Random Matrix Theory Approach to Neural Network Training}},
      journal = {arXiv preprint arXiv:2006.09092},
      year={2020},
}



@ARTICLE{liao2020Random,
       author = {{Liao}, Z. and {Couillet}, R. and {Mahoney}, M.},
        title = {\href{https://arxiv.org/pdf/2006.05013.pdf}{A Random Matrix Analysis of Random Fourier Features: Beyond the Gaussian Kernel, a Precise Phase Transition, and the Corresponding Double Descent}},
      journal = {arXiv preprint arXiv:2006.05013},
      year={2020},
}



@inproceedings{ghorbani2019investigation,
  title={An investigation into neural net optimization via hessian eigenvalue density},
  author={Ghorbani, B. and Krishnan, S. and Xiao, Y.},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={2232--2241},
  year={2019},
  organization={PMLR}
}

@article{li2018measuring,
  title={\href{https://arxiv.org/pdf/1804.08838.pdf}{Measuring the intrinsic dimension of objective landscapes}},
  author={Li, C. and Farkhoor, H. and Liu, R. and Yosinski, J.},
  journal={arXiv preprint arXiv:1804.08838},
  year={2018}
}

@article {gripenberg1980volterra,
    AUTHOR = {Gripenberg, G.},
     TITLE = {\href{http://www.math.kobe-u.ac.jp/~fe/xml/mr0586277.xml}{On the resolvents of nonconvolution {V}olterra kernels}},
   JOURNAL = {Funkcial. Ekvac.},
  FJOURNAL = {Funkcialaj Ekvacioj. Serio Internacia},
    VOLUME = {23},
      YEAR = {1980},
    NUMBER = {1},
     PAGES = {83--95},
      ISSN = {0532-8721},
   MRCLASS = {45D05 (45A05)},
  MRNUMBER = {586277},
MRREVIEWER = {G. S. Jordan},
       URL = {http://www.math.kobe-u.ac.jp/~fe/xml/mr0586277.xml},
}

@InProceedings{vaswani2019fast,
  title = 	 {\href{http://proceedings.mlr.press/v89/vaswani19a.html}{Fast and Faster Convergence of SGD for Over-Parameterized Models and an Accelerated Perceptron}},
  author =       {Vaswani, S. and Bach, F. and Schmidt, M.},
  booktitle = 	 {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics (ICML)},
  pages = 	 {1195--1204},
  year = 	 {2019},
  volume = 	 {89},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
}

@ARTICLE{laborde2019nesterov,
       author = {{Laborde}, M. and {Oberman}, A.},
        title = "{\href{https://arxiv.org/pdf/1908.07861.pdf}{Nesterov's method with decreasing learning rate leads to accelerated stochastic gradient descent}}",
      journal = {arXiv preprints arXiv:1908.07861},
     keywords = {Mathematics - Optimization and Control},
         year = 2019
}

@ARTICLE{aybat2018robust,
       author = {Aybat, N. and {Fallah}, A. and {Gurbuzbalaban}, M. and {Ozdaglar}, A.},
        title = "{\href{https://arxiv.org/abs/1805.10579}{Robust Accelerated Gradient Methods for Smooth Strongly Convex Functions}}",
      journal = {arXiv preprints arXiv:1805.10579},
     keywords = {Mathematics - Optimization and Control, Computer Science - Machine Learning, Statistics - Machine Learning},
         year = 2018
}

@ARTICLE{can2019accelerated,
       author = {{Can}, B. and {Gurbuzbalaban}, M. and {Zhu}, L.},
        title = "{\href{https://arxiv.org/abs/1901.07445}{Accelerated Linear Convergence of Stochastic Momentum Methods in Wasserstein Distances}}",
      journal = {arXiv preprints arXiv:1901.07445},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning, Mathematics - Optimization and Control},
         year = 2019
}

@inproceedings{orvieto2019role,
  title     = "{\href{http://auai.org/uai2019/proceedings/papers/128.pdf}{The Role of Memory in Stochastic Optimization}}",
  author    = {{Orvieto}, A. and {Kohler}, J. and {Lucchi}, A.},
  booktitle = {Conference on Uncertainty in Artificial Intelligence (UAI 2019)},
  year      = {2019}
}

@ARTICLE{gadat2016stochastic,
       author = {{Gadat}, S. and {Panloup}, F. and {Saadane}, S.},
        title = "{\href{https://arxiv.org/abs/1609.04228}{Stochastic Heavy Ball}}",
      journal = {arXiv preprints arXiv:1609.04228},
     keywords = {Mathematics - Statistics Theory, Mathematics - Probability, Statistics - Machine Learning},
         year = 2016
}

@inproceedings{yan2018unified,
  title     = {\href{https://doi.org/10.24963/ijcai.2018/410}{A Unified Analysis of Stochastic Momentum Methods for Deep Learning}},
  author    = {Yan, Y. and Yang, T and Li, Z. and Lin, Q. and Yang, Yi},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence, {IJCAI-18}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {2955--2961},
  year      = {2018},
  month     = {7},
  doi       = {10.24963/ijcai.2018/410}
}

@ARTICLE{loizou2017momentum,
       author = {{Loizou}, N. and {Richt{\'a}rik}, P.},
        title = "{\href{https://arxiv.org/abs/1712.09677}{Momentum and Stochastic Momentum for Stochastic Gradient, Newton, Proximal Point and Subspace Descent Methods}}",
      journal = {arXiv preprint arXiv:1712.09677},
     keywords = {Mathematics - Optimization and Control, Computer Science - Machine Learning, Computer Science - Numerical Analysis, Mathematics - Numerical Analysis, Statistics - Machine Learning},
         year = 2017
}

@InProceedings{flammarion2015from,
  title = 	 {\href{http://proceedings.mlr.press/v40/Flammarion15.html}{From Averaging to Acceleration, There is Only a Step-size}},
  author = 	 {Flammarion, N. and Bach, F.},
  booktitle = 	 {Proceedings of The 28th Conference on Learning Theory (COLT)},
  pages = 	 {658--695},
  year = 	 {2015},
  volume = 	 {40},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {03--06 Jul},
  publisher =    {PMLR}
}

@ARTICLE{zhang2019which,
       author = {{Zhang}, G. and {Li}, L. and {Nado}, Z. and {Martens}, J. and {Sachdeva}, S. and {Dahl}, G. and {Shallue}, C. and {Grosse}, R.},
        title = "{\href{https://arxiv.org/abs/1907.04164}{Which Algorithmic Choices Matter at Which Batch Sizes? Insights From a Noisy Quadratic Model}}",
      journal = {arXiv preprint arXiv:1907.04164},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = 2019,
}

@article {ghadimi2013optimal,
    AUTHOR = {Ghadimi, S. and Lan, G.},
     TITLE = {\href{https://epubs.siam.org/doi/abs/10.1137/110848876?journalCode=sjope8}{Optimal stochastic approximation algorithms for strongly
              convex stochastic composite optimization, {II}: {S}hrinking
              procedures and optimal algorithms}},
   JOURNAL = {SIAM J. Optim.},
  FJOURNAL = {SIAM Journal on Optimization},
    VOLUME = {23},
      YEAR = {2013},
    NUMBER = {4},
     PAGES = {2061--2089},
   MRCLASS = {62L20 (68Q25 68W25 90C25)},
  MRNUMBER = {3118261},
MRREVIEWER = {Vlasta Ka\v{n}kov\'{a}},
       DOI = {10.1137/110848876},
}

@article {ghadimi2012optimal,
    AUTHOR = {Ghadimi, S. and Lan, G.},
     TITLE = {\href{https://epubs.siam.org/doi/10.1137/110848864}{Optimal stochastic approximation algorithms for strongly
              convex stochastic composite optimization {I}: {A} generic
              algorithmic framework}},
   JOURNAL = {SIAM J. Optim.},
  FJOURNAL = {SIAM Journal on Optimization},
    VOLUME = {22},
      YEAR = {2012},
    NUMBER = {4},
     PAGES = {1469--1492},
      ISSN = {1052-6234},
   MRCLASS = {62L20 (68W25 90C15 90C25)},
  MRNUMBER = {3023780},
MRREVIEWER = {Vlasta Ka\v{n}kov\'{a}},
       DOI = {10.1137/110848864},
}

@inproceedings{kulunchakov2019generic,
 author = {Kulunchakov, A. and Mairal, J.},
 booktitle = {\href{https://proceedings.neurips.cc/paper/2019/file/4a1c2f4dcf2bf76b6b278ae40875d536-Paper.pdf}{Advances in Neural Information Processing Systems (NeurIPS)}},
 title = {A Generic Acceleration Framework for Stochastic Composite Optimization},
 volume = {32},
 year = {2019}
}

@ARTICLE{sebbouh2020almost,
       author = {{Sebbouh}, O. and {Gower}, R. and {Defazio}, A.},
        title = "\href{https://arxiv.org/pdf/2006.07867.pdf}{Almost sure convergence rates for Stochastic Gradient Descent and Stochastic Heavy Ball}",
     journal = {arXiv preprint arXiv:2006.07867},
     keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
         year = 2020,
}

@InProceedings{jain2018accelerating,
  title = 	 {\href{http://proceedings.mlr.press/v75/jain18a/jain18a.pdf}{Accelerating Stochastic Gradient Descent for Least Squares Regression}},
  author =       {Jain, P. and Kakade, S. and Kidambi, R. and Netrapalli, P. and Sidford, A.},
  booktitle = 	 {Proceedings of the 31st  Conference On Learning Theory (COLT)},
  pages = 	 {545--604},
  year = 	 {2018},
  volume = 	 {75},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v75/jain18a/jain18a.pdf}
  }

@INPROCEEDINGS{kidambi2018on,
  author={Kidambi, R. and Netrapalli, P. and Jain, P. and Kakade, S.},
  booktitle={\href{https://ieeexplore.ieee.org/document/8503173}{2018 Information Theory and Applications Workshop (ITA)}}, 
  title={On the Insufficiency of Existing Momentum Schemes for Stochastic Optimization}, 
  year={2018},
  volume={},
  number={},
  pages={1-9},
  doi={10.1109/ITA.2018.8503173}}

@InProceedings{Liu2020accelerating,
  title = 	 {\href{https://arxiv.org/pdf/1810.13395.pdf}{Accelerating SGD with momentum for over-parameterized learning}},
  author = 	 {{Liu}, C. and {Belkin}, M.},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning (ICML)},
  year = 	 {2020}
}

@InProceedings{assran2020on,
  title = 	 {\href{https://arxiv.org/abs/2002.12414}{On the Convergence of Nesterov's Accelerated Gradient Method in Stochastic Settings}},
  author =       {{Assran}, M. and {Rabbat}, M.},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning (ICML)},
  year = 	 {2020}
}


@book {coddington1955theory,
    AUTHOR = {Coddington, E. and Levinson, N.},
     TITLE = {\href{https://books.google.ca/books/about/Theory_of_Ordinary_Differential_Equation.html?id=LvNQAAAAMAAJ&redir_esc=y}{Theory of ordinary differential equations}},
 PUBLISHER = {McGraw-Hill Book Company, Inc., New York-Toronto-London},
      YEAR = {1955},
     PAGES = {xii+429},
   MRCLASS = {36.0X},
  MRNUMBER = {0069338},
MRREVIEWER = {M. Zl\'{a}mal},
}


@article {bertsekas1997new,
    AUTHOR = {Bertsekas, D.},
     TITLE = {\href{https://doi.org/10.1137/S1052623495287022}{A new class of incremental gradient methods for least squares
              problems}},
   JOURNAL = {SIAM J. Optim.},
  FJOURNAL = {SIAM Journal on Optimization},
    VOLUME = {7},
      YEAR = {1997},
    NUMBER = {4},
     PAGES = {913--926}
}

@InProceedings{gerbelot2020asymptotic,
  title = 	 {\href{http://proceedings.mlr.press/v125/gerbelot20a/gerbelot20a.pdf}{Asymptotic Errors for High-Dimensional Convex Penalized Linear Regression beyond Gaussian Matrices}},
  author =       {Gerbelot, C. and Abbara, A. and Krzakala, F.},
  booktitle = 	 {Proceedings of Thirty Third Conference on Learning Theory (COLT)},
  pages = 	 {1682--1713},
  year = 	 {2020},
  volume = 	 {125},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR}
}



@article{Derrida,
  title = {\href{https://link.aps.org/doi/10.1103/PhysRevB.24.2613}{Random-energy model: An exactly solvable model of disordered systems}},
  author = {Derrida, B},
  journal = {Phys. Rev. B},
  volume = {24},
  issue = {5},
  pages = {2613--2626},
  numpages = {0},
  year = {1981},
  month = {Sep},
  publisher = {American Physical Society},
}

@ARTICLE{saxe2013exact,
       author = {{Saxe}, A. and {McClelland}, J. and {Ganguli}, S.},
        title = "{\href{https://arxiv.org/pdf/1312.6120.pdf}{Exact solutions to the nonlinear dynamics of learning in deep linear neural networks}}",
      journal = {arXiv preprint arXiv:1312.6120},
         year = 2013
}

@article {LiuSongWang,
    AUTHOR = {Liu, D. and Song, C. and Wang, Z.},
     TITLE = {\href{https://doi.org/10.1090/S0002-9939-2011-11015-3}{On explicit probability densities associated with
              {F}uss-{C}atalan numbers}},
   JOURNAL = {Proc. Amer. Math. Soc.},
  FJOURNAL = {Proceedings of the American Mathematical Society},
    VOLUME = {139},
      YEAR = {2011},
    NUMBER = {10},
     PAGES = {3735--3738}
}

@article {Alexeev,
    AUTHOR = {Alexeev, N. and G\"{o}tze, F. and Tikhomirov, A.},
     TITLE = {\href{https://doi.org/10.1007/s10986-010-9074-4}{Asymptotic distribution of singular values of powers of random
              matrices}},
   JOURNAL = {Lith. Math. J.},
  FJOURNAL = {Lithuanian Mathematical Journal},
    VOLUME = {50},
      YEAR = {2010},
    NUMBER = {2},
     PAGES = {121--132}
}


@ARTICLE{CES2020,
       author = {{Cipolloni}, G. and {Erd{\H{o}}s}, L. and {Schr{\"o}der}, D.},
        title = "\href{https://arxiv.org/pdf/2012.13215.pdf}{Eigenstate Thermalization Hypothesis for Wigner Matrices}",
      journal = {arXiv e-prints},
     keywords = {Mathematics - Probability, Mathematical Physics, 60B20, 15B52, 58J51, 81Q50},
         year = 2020,
          eid = {arXiv:2012.13215},
        pages = {arXiv:2012.13215},
archivePrefix = {arXiv},
       eprint = {2012.13215},
 primaryClass = {math.PR},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020arXiv201213215C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article {sirignano2020mean,
    AUTHOR = {Sirignano, J. and Spiliopoulos, K.},
     TITLE = {\href{{https://doi.org/10.1137/18M1192184}}{Mean field analysis of neural networks: a law of large
              numbers}},
   JOURNAL = {SIAM J. Appl. Math.},
  FJOURNAL = {SIAM Journal on Applied Mathematics},
    VOLUME = {80},
      YEAR = {2020},
    NUMBER = {2},
     PAGES = {725--752}
}

@InProceedings{mei2019mean,
  title = 	 {\href{{http://proceedings.mlr.press/v99/mei19a/mei19a.pdf}}{Mean-field theory of two-layers neural networks: dimension-free bounds and kernel limit}},
  author =       {Mei, S. and Misiakiewicz, T. and Montanari, A.},
  booktitle = 	 {Proceedings of the Thirty-Second Conference on Learning Theory (COLT)},
  pages = 	 {2388--2464},
  year = 	 {2019},
  editor = 	 {Alina Beygelzimer and Daniel Hsu},
  volume = 	 {99}
}

@article {mei2018mean,
    AUTHOR = {Mei, S. and Montanari, A. and Nguyen, P.},
     TITLE = {\href{https://doi.org/10.1073/pnas.1806579115}{A mean field view of the landscape of two-layer neural
              networks}},
   JOURNAL = {Proc. Natl. Acad. Sci. USA},
  FJOURNAL = {Proceedings of the National Academy of Sciences of the United
              States of America},
    VOLUME = {115},
      YEAR = {2018},
    NUMBER = {33},
     PAGES = {E7665--E7671}
}

@InProceedings{sutskever2013on,
  title = 	 {\href{http://proceedings.mlr.press/v28/sutskever13.pdf}{On the importance of initialization and momentum in deep learning}},
  author = 	 {I. Sutskever and J. Martens and G. Dahl and G. Hinton},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning (ICML)},
  pages = 	 {1139--1147},
  year = 	 {2013},
  volume = 	 {28}
}


@ARTICLE{keskar2016on,
       author = {{Keskar}, N. and {Mudigere}, D. and {Nocedal}, J. and {Smelyanskiy}, M. and {Tang}, P.},
        title = "\href{https://openreview.net/pdf?id=H1oyRlYgg}{On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima}",
      journal = {arXiv preprint arXiv:1609.04836},
     keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
         year = 2016,
}

@article {bollapragada2018adaptive,
    AUTHOR = {Bollapragada, R. and Byrd, R. and Nocedal, J.},
     TITLE = {\href{https://doi.org/10.1137/17M1154679}{Adaptive sampling strategies for stochastic optimization}},
   JOURNAL = {SIAM J. Optim.},
  FJOURNAL = {SIAM Journal on Optimization},
    VOLUME = {28},
      YEAR = {2018},
    NUMBER = {4},
     PAGES = {3312--3343}
}
	

@article {paquette2020stochastic,
    AUTHOR = {Paquette, Courtney and Scheinberg, Katya},
     TITLE = {A stochastic line search method with expected complexity
              analysis},
   JOURNAL = {SIAM J. Optim.},
  FJOURNAL = {SIAM Journal on Optimization},
    VOLUME = {30},
      YEAR = {2020},
    NUMBER = {1},
     PAGES = {349--376},
      ISSN = {1052-6234},
   MRCLASS = {90C30 (90C15)},
  MRNUMBER = {4060460},
       DOI = {10.1137/18M1216250},
       URL = {https://doi.org/10.1137/18M1216250},
}

@article {friedlander2012hybrid,
    AUTHOR = {Friedlander, M. and Schmidt, M.},
     TITLE = {\href{https://doi.org/10.1137/110830629}{Hybrid deterministic-stochastic methods for data fitting}},
   JOURNAL = {SIAM J. Sci. Comput.},
  FJOURNAL = {SIAM Journal on Scientific Computing},
    VOLUME = {34},
      YEAR = {2012},
    NUMBER = {3},
     PAGES = {A1380--A1405}
}
	

@InProceedings{schaul2013no,
  title = 	 {\href{http://proceedings.mlr.press/v28/schaul13.pdf}{No more pesky learning rates}},
  author = 	 {T. Schaul and S. Zhang and Y. LeCun},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning (ICML)},
  pages = 	 {343--351},
  year = 	 {2013},
  volume = 	 {28},
  series = 	 {Proceedings of Machine Learning Research}
}

@article{mahsereci2017probablistic,
  author  = {M. Mahsereci and P. Hennig},
  title   = {\href{http://jmlr.org/papers/v18/17-049.html}{Probabilistic Line Searches for Stochastic Optimization}},
  journal = {Journal of Machine Learning Research},
  year    = {2017},
  volume  = {18},
  number  = {119},
  pages   = {1-59}
}

@inproceedings{vaswani2019painless,
 author = {Vaswani, S. and Mishkin, A. and Laradji, I. and Schmidt, M. and Gidel, G. and Lacoste-Julien, S.},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 pages = {3732--3745},
 title = {\href{https://proceedings.neurips.cc/paper/2019/file/2557911c1bf75c2b643afb4ecbfc8ec2-Paper.pdf}{Painless Stochastic Gradient: Interpolation, Line-Search, and Convergence Rates}},
 volume = {32},
 year = {2019}
}

@ARTICLE{an2018stochastic,
       author = {{An}, J. and {Lu}, J. and {Ying}, L.},
        title = "{\href{https://ui.adsabs.harvard.edu/abs/2018arXiv180508244A}{Stochastic modified equations for the asynchronous stochastic gradient descent}}",
      journal = {arXiv preprint arXiv:1805.08244},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = 2018
}

@InProceedings{zhu2019anisotropic,
  title = 	 {\href{http://proceedings.mlr.press/v97/zhu19e.html}{The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Sharp Minima and Regularization Effects}},
  author =       {Zhu, Z. and Wu, J. and Yu, B. and Wu, L. and Ma, J.},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning (ICML)},
  pages = 	 {7654--7663},
  year = 	 {2019},
  volume = 	 {97}
}
}


@ARTICLE{kunin2020neural,
       author = {{Kunin}, D. and {Sagastuy-Brena}, J. and {Ganguli}, S. and {Yamins}, D.L.~K. and {Tanaka}, H.},
        title = "\href{https://arxiv.org/pdf/2012.04728.pdf}{Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics}",
      journal = {arXiv preprint arXiv:2012.04728},
         year = 2020
}



@inproceedings{
chaudhari2018stochastic,
title={\href{https://openreview.net/forum?id=HyWrIgW0W}{Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks}},
author={Chaudhari, P. and Soatto, S.},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018}
}

@misc{goyal17,
  journal = {arXiv preprint arXiv:1706.02677},
  author = {Goyal, P. and Doll√°r, P. and Girshick, R. and Noordhuis, P. and Wesolowski, L. and Kyrola, A. and Tulloch, A. and Jia, Y. and He, K.},
  title = {\href{https://arxiv.org/abs/1706.02677}{Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour}},
  year = {2017}
}



@ARTICLE{hu2017on,
       author = {{Hu}, W. and {Junchi Li}, C. and {Li}, L. and {Liu}, J.},
        title = "\href{https://arxiv.org/pdf/1705.07562.pdf}{On the diffusion approximation of nonconvex stochastic gradient descent}",
      journal = {arXiv preprint arXiv:1705.07562},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = 2017
}

@inproceedings{
yaida2018fluctuationdissipation,
title={\href{https://openreview.net/forum?id=SkNksoRctQ}{Fluctuation-dissipation relations for stochastic gradient descent}},
author={S. Yaida},
booktitle={International Conference on Learning Representations(ICLR)},
year={2019},
}


@article {ljung1977,
    AUTHOR = {Ljung, L.},
     TITLE = {\href{https://doi.org/10.1109/tac.1977.1101561}{Analysis of recursive stochastic algorithms}},
   JOURNAL = {IEEE Trans. Automatic Control},
  FJOURNAL = {Institute of Electrical and Electronics Engineers.
              Transactions on Automatic Control},
    VOLUME = {AC-22},
      YEAR = {1977},
    NUMBER = {4},
     PAGES = {551--575}
}

@inproceedings{gower2019sgd,
  title={\href{https://arxiv.org/pdf/1901.09401.pdf}{SGD: General analysis and improved rates}},
  author={Gower, R. and Loizou, N. and Qian, X. and Sailanbayev, A. and Shulgin, E. and Richt{\'a}rik, P.},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2019},
  organization={PMLR}
}
@InProceedings{li2017stochastic,
  title = 	 {\href{http://proceedings.mlr.press/v70/li17f/li17f.pdf}{Stochastic Modified Equations and Adaptive Stochastic Gradient Algorithms}},
  author =       {Q. Li and C. Tai and W. E},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning (ICLR)},
  pages = 	 {2101--2110},
  year = 	 {2017},
  volume = 	 {70}
}

@article {pflug1986stochastic,
    AUTHOR = {Pflug, G. C.},
     TITLE = {\href{https://doi.org/10.1137/0324039}{Stochastic minimization with constant step-size: asymptotic
              laws}},
   JOURNAL = {SIAM J. Control Optim.},
  FJOURNAL = {SIAM Journal on Control and Optimization},
    VOLUME = {24},
      YEAR = {1986},
    NUMBER = {4},
     PAGES = {655--666}
}

@article {bertsekas2000gradient,
    AUTHOR = {Bertsekas, D. and Tsitsiklis, J.},
     TITLE = {\href{https://doi.org/10.1137/S1052623497331063}{Gradient convergence in gradient methods with errors}},
   JOURNAL = {SIAM J. Optim.},
  FJOURNAL = {SIAM Journal on Optimization},
    VOLUME = {10},
      YEAR = {2000},
    NUMBER = {3},
     PAGES = {627--642}
}


@article {ghadimi2013stochastic,
    AUTHOR = {Ghadimi, S. and Lan, G.},
     TITLE = {\href{https://arxiv.org/pdf/1309.5549.pdf}{Stochastic first- and zeroth-order methods for nonconvex
              stochastic programming}},
   JOURNAL = {SIAM J. Optim.},
  FJOURNAL = {SIAM Journal on Optimization},
    VOLUME = {23},
      YEAR = {2013},
    NUMBER = {4},
     PAGES = {2341--2368}
}

@article{vaswani2018fast,
  title={\href{https://arxiv.org/pdf/1810.07288.pdf}{Fast and Faster Convergence of SGD for Over-Parameterized Models
(and an Accelerated Perceptron)}},
  author={Vaswani, Sharan and Bach, Francis and Schmidt, Mark},
  journal={arXiv preprint
arXiv:1810.07288},
  year={2018}
}


@article{schmidt2018first,
  title={\href{https://arxiv.org/abs/1308.6370}{Fast
convergence of stochastic gradient descent under a strong growth condition}},
  author={Schmidt, Mark and Le Roux, Nicolas},
  journal={arXiv preprint
arXiv:1308.6370},
  year={2013}
}

@article{bassily2018first,
  title={\href{https://arxiv.org/pdf/1811.02564.pdf}{On exponential convergence of sgd in non-convex
over-parametrized learning}},
  author={Bassily, Raef and Belkin, Mikhail and Ma, Siyuan},
  journal={arXiv preprints arXiv:1811.02564},
  year={2018}
}

@article {FyodorovBouchaud,
    AUTHOR = {Fyodorov, Y. and Bouchaud, J.},
     TITLE = {\href{https://doi.org/10.1088/1751-8113/41/37/372001}{Freezing and extreme-value statistics in a random energy model
              with logarithmically correlated potential}},
   JOURNAL = {J. Phys. A},
  FJOURNAL = {Journal of Physics. A. Mathematical and Theoretical},
    VOLUME = {41},
      YEAR = {2008},
    NUMBER = {37},
     PAGES = {372001, 12}
}

@book {Resnick,
    AUTHOR = {Resnick, S.},
     TITLE = {\href{https://link.springer.com/book/10.1007/978-1-4612-0387-2}{Adventures in stochastic processes}},
 PUBLISHER = {Birkh\"{a}user Boston, Inc., Boston, MA},
      YEAR = {1992},
     PAGES = {xii+626},
   MRCLASS = {60-01 (60J10 60J27 60K05)},
  MRNUMBER = {1181423},
MRREVIEWER = {Richard F. Serfozo},
}

@article {Asmussen2003,
    AUTHOR = {Asmussen, S. and Foss, S. and Korshunov, D.},
     TITLE = {\href{https://doi.org/10.1023/A:1023535030388}{Asymptotics for sums of random variables with local
              subexponential behaviour}},
   JOURNAL = {J. Theoret. Probab.},
  FJOURNAL = {Journal of Theoretical Probability},
    VOLUME = {16},
      YEAR = {2003},
    NUMBER = {2},
     PAGES = {489--518}
}

@book {Asmussen,
    AUTHOR = {Asmussen, S.},
     TITLE = {\href{https://link.springer.com/book/10.1007/b97236}{Applied probability and queues}},
    SERIES = {Applications of Mathematics (New York)},
    VOLUME = {51},
   EDITION = {Second},
      NOTE = {Stochastic Modelling and Applied Probability},
 PUBLISHER = {Springer-Verlag, New York},
      YEAR = {2003},
     PAGES = {xii+438}
}

@incollection {Lepingle,
    AUTHOR = {L\'{e}pingle, D.},
     TITLE = {\href{https://link.springer.com/chapter/10.1007/BFb0064603}{Sur le comportement asymptotique des martingales locales}},
 BOOKTITLE = {S\'{e}minaire de {P}robabilit\'{e}s, {XII} ({U}niv. {S}trasbourg,
              {S}trasbourg, 1976/1977)},
    SERIES = {Lecture Notes in Math.},
    VOLUME = {649},
     PAGES = {148--161},
      YEAR = {1978},
      PUBLISHER = {Springer, Berlin, Heidelberg}
}

@article {Yor,
     author = {Yor, M.},
     title = {\href{http://www.numdam.org/item/SPS_1976__10__481_0/}{On optional stochastic integrals and a remarkable series of exponential formulas}},
     journal = {Strasbourg probability seminar},
     pages = {481--500},
     publisher = {Springer - Lecture Notes in Mathematics},
     volume = {10},
     year = {1976},
     zbl = {0393.60057},
     mrnumber = {440699},
     language = {fr},
}

@book {ShorackWellner,
    AUTHOR = {Shorack, G. and Wellner, J.},
     TITLE = {\href{https://locus.siam.org/doi/book/10.1137/1.9780898719017?mobileUi=0}{Empirical processes with applications to statistics}},
    SERIES = {Wiley Series in Probability and Mathematical Statistics:
              Probability and Mathematical Statistics},
 PUBLISHER = {John Wiley \& Sons, Inc., New York},
      YEAR = {1986},
     PAGES = {xxxviii+938}
}

@book {protter2005stochastic,
    AUTHOR = {Protter, P.E.},
     TITLE = {\href{https://doi.org/10.1007/978-3-662-10061-5}{Stochastic integration and differential equations}},
    SERIES = {Stochastic Modelling and Applied Probability},
    VOLUME = {21},
 PUBLISHER = {Springer-Verlag, Berlin},
      YEAR = {2005},
}

@article {strohmer2009randomized,
    AUTHOR = {Strohmer, T. and Vershynin, R.},
     TITLE = {\href{https://doi.org/10.1007/s00041-008-9030-4}{A randomized {K}aczmarz algorithm with exponential
              convergence}},
   JOURNAL = {J. Fourier Anal. Appl.},
  FJOURNAL = {The Journal of Fourier Analysis and Applications},
    VOLUME = {15},
      YEAR = {2009},
    NUMBER = {2},
     PAGES = {262--278}
}

@ARTICLE{steinerberger2020randomized,
       author = {{Steinerberger}, S.},
        title = "\href{https://arxiv.org/pdf/2006.16978.pdf}{Randomized Kaczmarz converges along small singular vectors}",
      journal = {arXiv preprint arXiv:2006.16978},
     keywords = {Mathematics - Numerical Analysis, Mathematics - Functional Analysis, Mathematics - Optimization and Control},
         year = 2020,
}

@InProceedings{mert2019tail,
  title = 	 {\href{http://proceedings.mlr.press/v97/simsekli19a/simsekli19a.pdf}{A Tail-Index Analysis of Stochastic Gradient Noise in Deep Neural Networks}},
  author =       {Simsekli, U. and Sagun, L. and Gurbuzbalaban, M.},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning (ICML)},
  pages = 	 {5827--5837},
  year = 	 {2019},
  volume = 	 {97}
}


@ARTICLE{mert2020heavy-tail,
       author = {{Gurbuzbalaban}, M. and {Simsekli}, U. and {Zhu}, L.},
        title = "\href{https://arxiv.org/pdf/2006.04740.pdf}{The Heavy-Tail Phenomenon in SGD}",
      journal = {arXiv preprint arXiv:2006.04740},
     keywords = {Mathematics - Optimization and Control, Computer Science - Machine Learning, Mathematics - Statistics Theory},
         year = 2020
}

@ARTICLE{ward2020,
       author = {{Huang}, D. and {Niles-Weed}, J. and {Tropp}, J. and {Ward}, R.},
        title = "\href{https://arxiv.org/pdf/2003.05437.pdf}{Matrix Concentration for Products}",
      journal = {arXiv preprints arXiv:2003.05437},
         year = 2020
}



@book{Kushner,
  title={\href{https://link.springer.com/book/10.1007/b97441}{Stochastic approximation and recursive algorithms and applications}},
  author={Kushner, H. and Yin, G.G.},
  volume={35},
  year={2003},
  publisher={Springer Science \& Business Media}
}

@book{gripenberg1990volterra,
  title={\href{https://books.google.ca/books?id=FxZgYfkAA48C}{Volterra Integral and Functional Equations}},
  author={Gripenberg, G. and Londen, S.O. and Staffans, O.},
  series={Encyclopedia of Mathematics and its Applications},
  year={1990},
  publisher={Cambridge University Press}
}
@inproceedings{brosse2018promises,
  title={\href{https://arxiv.org/pdf/1811.10072.pdf}{The promises and pitfalls of stochastic gradient Langevin dynamics}},
  author={Brosse, Nicolas and Durmus, Alain and Moulines, Eric},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}
@inproceedings{nguyen2019first,
  title={\href{https://arxiv.org/pdf/1906.09069.pdf}{First exit time analysis of stochastic gradient descent under heavy-tailed gradient noise}},
  author={Nguyen, T. and Simsekli, U. and Gurbuzbalaban, M. and Richard, G.},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}
@article{jastrzkebski2017three,
  title={\href{https://arxiv.org/pdf/1711.04623.pdf}{Three Factors Influencing Minima in SGD}},
  author={Jastrzebski, S. and Kenton, Z. and Arpit, D. and Ballas, N. and Fischer, A. and Bengio, Y. and Storkey, A.},
  journal={arXiv preprint arXiv:1711.04623},
  year={2017}
}
@article {Bai1999a,
    AUTHOR = {Bai, Z. D. and Silverstein, Jack W.},
     TITLE = {\href{https://doi.org/10.1214/aop/1022677458}{Exact separation of eigenvalues of large-dimensional sample
              covariance matrices}},
   JOURNAL = {Ann. Probab.},
  FJOURNAL = {The Annals of Probability},
    VOLUME = {27},
      YEAR = {1999},
    NUMBER = {3},
     PAGES = {1536--1555}
}
@inproceedings{welling2011bayesian,
  title={Bayesian learning via stochastic gradient Langevin dynamics},
  author={Welling, Max and Teh, Yee W},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  year={2011}
}
@inproceedings{mandt2016variational,
  title={\href{https://arxiv.org/pdf/1602.02666.pdf}{A variational analysis of stochastic gradient algorithms}},
  author={Mandt, S. and Hoffman, M. and Blei, D.},
  booktitle={International conference on machine learning (ICML)},
  year={2016}
}
@article {Bai1999b,
    AUTHOR = {Bai, Z. D. and Silverstein, Jack W.},
     TITLE = {\href{https://doi.org/aop/1022855421}{No eigenvalues outside the support of the limiting spectral
              distribution of large-dimensional sample covariance matrices}},
   JOURNAL = {Ann. Probab.},
  FJOURNAL = {The Annals of Probability},
    VOLUME = {26},
      YEAR = {1998},
    NUMBER = {1},
     PAGES = {316--345}
}

@article {SilversteinChoi,
    AUTHOR = {Silverstein, Jack W. and Choi, Sang-Il},
     TITLE = {Analysis of the limiting spectral distribution of
              large-dimensional random matrices},
   JOURNAL = {J. Multivariate Anal.},
  FJOURNAL = {Journal of Multivariate Analysis},
    VOLUME = {54},
      YEAR = {1995},
    NUMBER = {2},
     PAGES = {295--309},
      ISSN = {0047-259X},
   MRCLASS = {62H99 (62E20)},
  MRNUMBER = {1345541},
MRREVIEWER = {Franz Streit},
       DOI = {10.1006/jmva.1995.1058},
       URL = {https://doi.org/10.1006/jmva.1995.1058},
}

@article {HachemHardyNajim,
    AUTHOR = {Hachem, W. and Hardy, A. and Najim, J.},
     TITLE = {\href{https://doi.org/10.1214/15-AOP1022}{Large complex correlated {W}ishart matrices: fluctuations and
              asymptotic independence at the edges}},
   JOURNAL = {Ann. Probab.},
  FJOURNAL = {The Annals of Probability},
    VOLUME = {44},
      YEAR = {2016},
    NUMBER = {3},
     PAGES = {2264--2348}
}

@article{tao2010random,
author = "Tao, T. and Vu, V.",
journal = "Geom. Funct. Anal.",
number = "1",
pages = "260--297",
title = "\href{https://link.springer.com/article/10.1007/s00039-010-0057-8}{Random Matrices: the Distribution of the Smallest Singular Values}",
volume = "20",
year = "2010"
}
@InProceedings{jain2017,
  title = 	 {\href{http://proceedings.mlr.press/v75/jain18a/jain18a.pdf}{Accelerating Stochastic Gradient Descent for Least Squares Regression}},
  author =       {Jain, P. and Kakade, S. and Kidambi, R. and Netrapalli, P. and Sidford, A.},
  booktitle = 	 {Proceedings of the 31st  Conference On Learning Theory (COLT)},
  pages = 	 {545--604},
  year = 	 {2018},
  volume = 	 {75}
}

@article{livshytz2019smallest,
  title={The smallest singular value of inhomogeneous square random matrices},
  author={Livshyts, G.V. and Tikhomirov, K. and Vershynin, R.},
  journal={arXiv preprint arXiv:1909.04219},
  year={2019}
}

@article {KnowlesYin,
    AUTHOR = {Knowles, A. and Yin, J.},
     TITLE = {\href{https://doi.org/10.1007/s00440-016-0730-4}{Anisotropic local laws for random matrices}},
   JOURNAL = {Probab. Theory Related Fields},
    VOLUME = {169},
      YEAR = {2017},
    NUMBER = {1-2},
     PAGES = {257--352},
}

@book{walpole1989probability,
  title={Probability and Statistics for Engineers and Scientists},
  author={Walpole, R. and Myers, R.},
  year={1989},
  publisher={Macmill}
}

@incollection{rutishauser1959refined,
  title={Theory of Gradient Methods},
  author={Rutishauser, H.},
  booktitle={\href{https://www.springer.com/gp/book/9783034872263}{Refined Iterative Methods for Computation of the Solution and the Eigenvalues of Self-Adjoint Boundary Value Problems}},
  pages={24--49},
  year={1959},
  publisher={Springer}
}

@article{nesterov2012how,
  author  = {Nesterov, Y.},
  title   = {\href{http://www.mathopt.org/Optima-Issues/optima88.pdf}{How to make the gradients small}},
  journal = {Optima 88},
  year    = {2012},
  pages = {10-11}
}

@article{liao2018dynamics,
  title={\href{http://proceedings.mlr.press/v80/liao18b.html}{The Dynamics of Learning: A Random Matrix Approach}},
  author={Liao, Z. and Couillet, R.},
  journal={Proceedings of the 35th International Conference on Machine Learning (ICML)},
  year={2018}
  }

@article{sagun2016eigenvalues,
  title={\href{https://arxiv.org/abs/1611.07476}{Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond}},
  author={Sagun, L. and Bottou, L. and LeCun, Y.},
  journal={arXiv preprint arXiv:1611.07476},
  year={2016}
}

@article{behrooz2019investigation,
  title={\href{http://proceedings.mlr.press/v97/ghorbani19b.html}{An Investigation into Neural Net Optimization via Hessian Eigenvalue Density}},
  author={Behrooz, G. and Krishnan, S. and Xiao, Y.},
  journal={Proceedings of the 36th International Conference on Machine Learning (ICML)},
  year={2019}
}

@article{papyan2018the,
  title={\href{https://arxiv.org/pdf/1811.07062.pdf}{The full spectrum of deepnet hessians at scale: Dynamics with SGD Training and Sample Size}},
  author={Papyan, V.},
  journal={arXiv preprint arXiv:1811.07062},
  year={2018}
}

@inproceedings{dauphin2014identifying,
title = {\href{https://papers.nips.cc/paper/5486-identifying-and-attacking-the-saddle-point-problem-in-high-dimensional-non-convex-optimization}{Identifying and attacking the saddle point problem in high-dimensional non-convex optimization}},
author = {Dauphin, Y.N. and Pascanu, R. and Gulcehre, C. and Cho, K. and Ganguli, S. and Bengio, Y.},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2014}
}

@article{deift2018universality,
  author  = {Deift, P.A. and Trogdon, T.},
  title   = {\href{https://link.springer.com/chapter/10.1007/978-3-030-01593-0_8}{Universality in numerical computation with random data: Case Studies, Analytical Results, and Some Speculations}},
  journal = {Abel Symposia},
  year    = {2018},
  volume  = {13},
  number  = {3},
  pages = {221-231}
}

@book{borgwardt1986probabilistic,
author = {Borgwardt, K.},
title = {\href{https://www.springer.com/gp/book/9783540170969}{A Probabilistic Analysis of the Simplex Method}},
year = {1986},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}

@article{smale1983on,
  author  = {Smale, S.},
  title   = {\href{https://link.springer.com/article/10.1007/BF02591902}{On the average number of steps of the simplex method of linear programming}},
  journal = {Mathematical Programming},
  year    = {1983},
  volume  = {27},
  number  = {3},
  pages = {241-262}
}

@article{paquette2020universality,
  title={\href{https://arxiv.org/abs/2007.00640}{Universality for the conjugate gradient and MINRES algorithms on sample covariance matrices}},
  author={Paquette, E. and Trogdon, T.},
  journal={arXiv preprint arXiv:2007.00640},
  year={2020}
}

@inproceedings{scieur2020universal,
  title={Universal Average-Case Optimality of Polyak Momentum},
  author={Scieur, D. and Pedregosa, F.},
  booktitle={Proceedings of the 37th International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{varga1957comparison,
  author  = {R.S. Varga},
  title   = {A comparision of the successive overrelaxation method and semi-iterative methods using Chebyshev},
  journal = {J. Soc. INDUST. A:PPL. MATH.},
  year    = {1957},
  volume  = {5},
  number  = {2}
}

@article{su2016differential,
  author  = {Su, W. and Boyd, S. and Cand{{\`e}}s, E.J.},
  title   = {\href{http://jmlr.org/papers/v17/15-084.html}{A Differential Equation for Modeling Nesterov's Accelerated Gradient Method: Theory and Insights}},
  journal = {Journal of Machine Learning Research},
  year    = {2016},
  volume  = {17},
  number  = {153},
  pages   = {1-43},
}

@article{gunasekar2018characterizing,
  title={\href{http://proceedings.mlr.press/v80/gunasekar18a/gunasekar18a.pdf}{Characterizing Implicit Bias
in Terms of Optimization Geometry}},
  author={Gunasekar, S. and Lee, J. and Soudry, D. and Srebro, N.},
  journal={Proceedings of the 35th International Conference on Machine Learning (ICML)},
  year={2018}
  }
  
@inproceedings{wilson2017marginal,
  title={\href{https://papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning}{The marginal value of adaptive gradient methods in
machine learning}},
  author={Wilson, A.C. and Roelofs, R. and Stern, M. and Srebro, N. and Recht, B.},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2017}
}

@article{edelman1988eigenvalues,
  title={\href{https://epubs.siam.org/doi/abs/10.1137/0609045?journalCode=sjmael}{Eigenvalues and condition numbers of random matrices}},
  author={Edelman, A.},
  journal={SIAM J. Matrix Anal. Appl},
  year={1988},
  volume = {9},
  number = {4},
  publisher={SIAM}
}

@article{louart2018random,
author = "Louart, C. and Liao, Z. and Couillet, R.",
journal = "Ann. Appl. Probab.",
number = "2",
pages = "1190--1248",
title = "\href{https://arxiv.org/abs/1702.05419}{A random matrix approach to neural networks}",
volume = "28",
year = "2018"
}

@inproceedings{Rahimi2008Random,
title = {\href{https://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines}{Random features for large-scale kernel machines}},
author = {Rahimi, A. and Recht, B.},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
pages = {1177--1184},
year = {2008}
}

@article{tao2012random,
author = "Tao, T. and Vu, V.",
fjournal = "The Annals of Probability",
journal = "Ann. Probab.",
month = "05",
number = "3",
pages = "1285--1315",
publisher = "The Institute of Mathematical Statistics",
title = "Random covariance matrices: Universality of local statistics of eigenvalues",
volume = "40",
year = "2012"
}

@article{marvcenko1967distribution,
  title={\href{https://iopscience.iop.org/article/10.1070/SM1967v001n04ABEH001994/meta}{Distribution of eigenvalues for some sets of random matrices}},
  author={Mar{\v{c}}enko, V.A. and Pastur, L.A.},
  journal={Mathematics of the USSR-Sbornik},
  year={1967},
  publisher={IOP Publishing}
}
@book{vershynin2018high,
  title={\href{https://www.cambridge.org/core/books/highdimensional-probability/797C466DA29743D2C8213493BD2D2102}{High-dimensional probability: An introduction with applications in data science}},
  author={Vershynin, R.},
  year={2018},
  publisher={Cambridge University Press}
}

@article{benigni2019eigenvalue,
  title={\href{https://arxiv.org/abs/1904.03090}{Eigenvalue distribution of nonlinear models of random matrices}},
  author={Benigni, L. and P{\'e}ch{\'e}, S.},
  journal={arXiv preprint arXiv:1904.03090},
  year={2019}
}

@book{durrett2010probability,
  title={\href{https://services.math.duke.edu/~rtd/PTE/PTE5_011119.pdf}{Probability: theory and examples}},
  author={Durrett, R.},
  edition = {Fourth},
  year={2010},
  publisher={Cambridge University Press}
}

@book{fischer1996Polynomial,
  title={\href{https://epubs.siam.org/doi/book/10.1137/1.9781611971927?mobileUi=0}{Polynomial based iteration methods for symmetric linear systems}},
  author={Fischer, B.},
  year={1996},
  publisher={Springer}
}

@article{Spielman2004Smooth,
author = {Spielman, D. and Teng, S.},
title = {\href{https://dl.acm.org/doi/10.1145/990308.990310}{Smoothed Analysis of Algorithms: Why the Simplex Algorithm Usually Takes Polynomial Time}},
year = {2004},
issue_date = {May 2004},
publisher = {Association for Computing Machinery},
volume = {51},
number = {3},
journal = {J. ACM},
pages = {385‚Äì463}
}

@article{Hoare1962Quicksort,
    author = {Hoare, C.A.R.},
    title = "{\href{https://doi.org/10.1093/comjnl/5.1.10}{Quicksort}}",
    journal = {The Computer Journal},
    volume = {5},
    number = {1},
    pages = {10-16},
    year = {1962},
    month = {01},
}

@article{Venturi2019Spurious,
  title={Spurious Valleys in One-hidden-layer Neural Network Optimization Landscapes},
  author={Venturi, L. and Bandeira, A. and Bruna, J.},
  journal={Journal of Machine Learning Research},
  year={2019}
}

@inproceedings{Ge2016Matrix,
title = {Matrix Completion has No Spurious Local Minimum},
author = {Ge, R. and Lee, J. and Ma, T.},
booktitle = {Advances in Neural Information Processing Systems 29},
pages = {2973--2981},
year = {2016}
}

@inproceedings{Kawaguchi2016Deep,
title = {Deep Learning without Poor Local Minima},
author = {Kawaguchi, K.},
booktitle = {Advances in Neural Information Processing Systems 29},
pages = {586--594},
year = {2016}
}

@article{Chi2019Nonconvex,
author = {Chi, Y. and Lu, Y. and Chen, Y.},
year = {2019},
month = {08},
title = {Nonconvex Optimization Meets Low-Rank Matrix Factorization: An Overview},
journal = {IEEE Transactions on Signal Processing}
}

@article{Sagun2017Universal,
author = {Sagun, L. and Trogdon, T. and LeCun, Y.},
year = {2017},
month = {09},
pages = {1},
title = {\href{https://www.ams.org/journals/qam/2018-76-02/S0033-569X-2017-01483-5/}{Universal halting times in optimization and machine learning}},
volume = {76},
journal = {Quarterly of Applied Mathematics}
}

@article{Flanders1950Numerical,
author = {Flanders, D.A. and Shortley, G.},
journal = {Journal of Applied Physics},
title = {\href{https://doi.org/10.1063/1.1699598}{Numerical determination of fundamental modes}},
year = {1950}
}

@article{Beck2009Fast,
	Author = {Beck, A. and Teboulle, M.},
	Journal = {SIAM J. Imaging Sci.},
	Number = {1},
	Pages = {183--202},
	Title = {\href{https://epubs.siam.org/doi/abs/10.1137/080716542}{A fast iterative shrinkage-thresholding algorithm for linear inverse problems}},
	Volume = {2},
	Year = {2009}
}
	
@article{bellec2019concentration,
  title={Concentration of quadratic forms under a Bernstein moment assumption},
  author={Bellec, Pierre C},
  journal={arXiv preprint arXiv:1901.08736},
  year={2019}
}

@article{Nesterov1988On,
	Author = {Nesterov, Yu.},
	Journal = {Ekonom. i. Mat. Metody},
	Pages = {509--517},
	Title = {On an approach to the construction of optimal methods of minimization of smooth convex functions},
	Volume = {24},
	Year = {1988}}

@article{Polyak1962Some,
author = {Polyak, B.T.},
year = {1964},
pages = {},
title = {\href{https://doi.org/10.1016/0041-5553(64)90137-5}{Some methods of speeding up the convergence of iteration methods}},
volume = {04},
journal = {USSR Computational Mathematics and Mathematical Physics}
}

@article{bai2004CLT,
author = {Bai, Z. and Silverstein, J.},
year = {2004},
month = {01},
pages = {},
title = {\href{https://projecteuclid.org/download/pdf_1/euclid.aop/1078415845}{CLT for Linear Spectral Statistics of Large-Dimensional Sample Covariance Matrices}},
volume = {32},
journal = {The Annals of Probability}
}

@article{dumitriu2018Spectra,
author = {Dumitriu, I. and Paquette, E.},
year = {2018},
pages = {},
title = {Spectra of overlapping Wishart matrices and the Gaussian free field},
volume = {07},
journal = {Random Matrices: Theory and Applications}
}

@article{golub1961chebyshev,
  title={\href{https://doi.org/10.1007/BF01386013}{Chebyshev semi-iterative methods, successive overrelaxation iterative methods, and second order Richardson iterative methods}},
  author={Golub, G. and Varga, R.},
  journal = {Numerische Mathematik},
  year={1961}
}

@article{Hestenes&Stiefel:1952,
  author = {Hestenes, M.R. and Stiefel, E.},
  journal = {Journal of research of the National Bureau of Standards},
  pages = {409--436},
  title = {\href{https://nvlpubs.nist.gov/nistpubs/jres/049/jresv49n6p409_A1b.pdf}{Methods of conjugate gradients for solving linear systems}},
  volume = 49,
  year = 1952
}

@article{orourke2011Fluctuations,
author = {O'Rourke, Sean and Renfrew, David and Soshnikov, Alexander},
year = {2011},
month = {06},
pages = {},
title = {Fluctuations of Matrix Entries of Regular Functions of Sample Covariance
Random Matrices},
volume = {58},
journal = {Theory of Probability and Its Applications}
}
@book{olver1997asymptotics,
  title={Asymptotics and Special Functions},
  author={Olver, F.},
  series={AKP classics},
  year={1997},
  publisher={Taylor \& Francis}
}

@book{bai2010spectral,
  title={\href{https://link.springer.com/book/10.1007\%2F978-1-4419-0661-8}{Spectral analysis of large dimensional random matrices}},
  author={Bai, Z. and Silverstein, J.},
  volume={20},
  year={2010},
  publisher={Springer}
}

@article{mena2019statistical,
  title={Statistical bounds for entropic optimal transport: sample complexity and the central limit theorem},
  author={Mena, Gonzalo and Weed, Jonathan},
  journal={arXiv preprint arXiv:1905.11882},
  year={2019}
}
@article{jonsson1982some,
  title={Some limit theorems for the eigenvalues of a sample covariance matrix},
  author={Jonsson, Dag},
  journal={Journal of Multivariate Analysis},
  volume={12},
  number={1},
  pages={1--38},
  year={1982},
  publisher={Elsevier}
}
@article{speicher2009free,
  title={Free probability theory},
  author={Speicher, Roland},
  journal={arXiv preprint arXiv:0911.0087},
  year={2009}
}
@article{bishop2017matrix,
  title={Matrix product moments in normal variables},
  author={Bishop, Adrian and Del Moral, Pierre},
  journal={arXiv preprint arXiv:1703.00353},
  year={2017}
}
@article{hutchinson1990stochastic,
  title={A stochastic estimator of the trace of the influence matrix for laplacian smoothing splines},
  author={Hutchinson, Michael F},
  journal={Communications in Statistics-Simulation and Computation},
  volume={19},
  year={1990},
  publisher={Taylor \& Francis}
}
@book{anderson2010introduction,
  title={An introduction to random matrices},
  author={Anderson, Greg W and Guionnet, Alice and Zeitouni, Ofer},
  volume={118},
  year={2010},
  publisher={Cambridge university press}
}
@article{simchowitz2018randomized,
  title={On the randomized complexity of minimizing a convex quadratic function},
  author={Simchowitz, Max},
  journal={arXiv preprint arXiv:1807.09386},
  year={2018}
}
@article{bloemendal2014isotropic,
  title={Isotropic local laws for sample covariance and generalized Wigner matrices},
  author={Bloemendal, Alex and Erdos, L{\'a}szl{\'o} and Knowles, Antti and Yau, Horng-Tzer and Yin, Jun},
  journal={Electron. J. Probab},
  year={2014}
}
@article{hastie2019surprises,
  title={\href{https://arxiv.org/abs/1903.08560}{Surprises in high-dimensional ridgeless least squares interpolation}},
  author={Hastie, T. and Montanari, A. and Rosset, S. and Tibshirani, R.J.},
  journal={arXiv preprint arXiv:1903.08560},
  year={2019}
}
@article{mei2019generalization,
  title={\href{https://arxiv.org/pdf/1908.05355.pdf}{The generalization error of random features regression: Precise asymptotics and double descent curve}},
  author={Mei, S. and Montanari, A.},
  journal={arXiv preprint arXiv:1908.05355},
  year={2019}
}
@article{peche2019note,
  title={A note on the Pennington-Worah distribution},
  author={P{\'e}ch{\'e}, S and others},
  journal={Electronic Communications in Probability},
  volume={24},
  year={2019},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}
@article{nemirovski1995information,
  title={\href{https://www2.isye.gatech.edu/~nemirovs/Lec_EMCO.pdf}{Information-based complexity of convex programming}},
  author={Nemirovski, A.},
  journal={Lecture Notes},
  year={1995}
}
@inproceedings{pennington2017nonlinear,
  title={\href{http://papers.nips.cc/paper/6857-nonlinear-random-matrix-theory-for-deep-learning}{Nonlinear random matrix theory for deep learning}},
  author={Pennington, J. and Worah, P.},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2017}
}
@article{pillai2014universality,
  title={Universality of covariance matrices},
  author={Pillai, Natesh S and Yin, Jun and others},
  journal={The Annals of Applied Probability},
  year={2014},
  publisher={Institute of Mathematical Statistics}
}
@article{deift2019conjugate,
  title={\href{https://doi.org/10.1090/qam/1574
}{The conjugate gradient algorithm on well-conditioned Wishart matrices is almost deteriministic}},
  author={Deift, P.A. and Trogdon, T.},
  journal={Quarterly of Applied Mathematics},
  year={2020}
}
@inproceedings{pedregosa2020average,
  title={\href{https://proceedings.icml.cc/static/paper_files/icml/2020/195-Paper.pdf}{Average-case Acceleration Through Spectral Density Estimation}},
  author={Pedregosa, F. and Scieur, D.},
  booktitle={Proceedings of the 37th International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{lacotte2020optimal,
  title={\href{https://arxiv.org/pdf/2002.09488.pdf}{Optimal Randomized First-Order Methods for Least-Squares Problems}},
  author={Lacotte, J. and Pilanci, M.},
  journal={arXiv preprint arXiv:2002.09488},
  year={2020}
}
@article{hayou2019mean,
  title={Mean-field Behaviour of Neural Tangent Kernel for Deep Neural Networks},
  author={Hayou, Soufiane and Doucet, Arnaud and Rousseau, Judith},
  journal={arXiv preprint arXiv:1905.13654},
  year={2019}
}
@inproceedings{arora2019exact,
  title={\href{https://papers.nips.cc/paper/9025-on-exact-computation-with-an-infinitely-wide-neural-net.pdf}{On exact computation with an infinitely wide neural net}},
  author={Arora, S. and Du, S. S. and Hu, W. and Li, Z. and Salakhutdinov, R. R. and Wang, R.},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}
@inproceedings{chizat2019lazy,
  title={\href{https://papers.nips.cc/paper/8559-on-lazy-training-in-differentiable-programming.pdf}{On lazy training in differentiable programming}},
  author={Chizat, L. and Oyallon, E. and Bach, F.},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}
@inproceedings{jacot2018neural,
  title={\href{https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf}{Neural tangent kernel: Convergence and generalization in neural networks}},
  author={Jacot, A. and Gabriel, F. and Hongler, C.},
  booktitle={Advances in neural information processing systems (NeurIPS)},
  year={2018}
}
@inproceedings{novak2018bayesian,
  title={\href{https://arxiv.org/pdf/1810.05148.pdf}{Bayesian deep convolutional networks with many channels are Gaussian processes}},
  author={Novak, R. and Xiao, L. and Lee, J. and Bahri, Y. and Yang, G. and Hron, J. and Abolafia, D.A. and Pennington, J. and Sohl-Dickstein, J.},
  booktitle = {Proceedings of the 7th International Conference on Learning Representations (ICLR)},
  year={2019}
}
@Article{Lee2019,
author="Lee, Jason D.
and Panageas, Ioannis
and Piliouras, Georgios
and Simchowitz, Max
and Jordan, Michael I.
and Recht, Benjamin",
title="First-order methods almost always avoid strict saddle points",
journal="Mathematical Programming",
year="2019",
month="Feb",
day="18",
abstract="We establish that first-order methods avoid strict saddle points for almost all initializations. Our results apply to a wide variety of first-order methods, including (manifold) gradient descent, block coordinate descent, mirror descent and variants thereof. The connecting thread is that such algorithms can be studied from a dynamical systems perspective in which appropriate instantiations of the Stable Manifold Theorem allow for a global stability analysis. Thus, neither access to second-order derivative information nor randomness beyond initialization is necessary to provably avoid strict saddle points.",
issn="1436-4646",
doi="10.1007/s10107-019-01374-3",
url="https://doi.org/10.1007/s10107-019-01374-3"
}

@article{erdos2017dynamical,
  title={\href{http://www.math.harvard.edu/~htyau/RM-Aug-2016.pdf}{Dynamical approach to random matrix theory}},
  author={Erdos, L{\'a}szl{\'o} and Yau, Horng-Tzer},
  journal={Courant Lecture Notes in Mathematics},
  volume={28},
  year={2017}
}
@article{bloemendal2016principal,
  title={On the principal components of sample covariance matrices},
  author={Bloemendal, Alex and Knowles, Antti and Yau, Horng-Tzer and Yin, Jun},
  journal={Probability theory and related fields},
  year={2016},
  publisher={Springer}
}
@inproceedings{pennington2018emergence,
  title={The emergence of spectral universality in deep networks},
  author={Pennington, Jeffrey and Schoenholz, Samuel and Ganguli, Surya},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1924--1932},
  year={2018}
}
@article{martin2018implicit,
  title={\href{https://arxiv.org/pdf/1810.01075.pdf}{Implicit self-regularization in deep neural networks: Evidence from random matrix theory and implications for learning}},
  author={Martin, C.H. and Mahoney, M.W.},
  journal={arXiv preprint arXiv:1810.01075},
  year={2018}
}
@article{bourgade2017eigenvector,
  title={The eigenvector moment flow and local quantum unique ergodicity},
  author={Bourgade, Paul and Yau, H-T},
  journal={Communications in Mathematical Physics},
  year={2017},
  publisher={Springer}
}
@article{deift2014universality,
  title={\href{https://www.pnas.org/content/111/42/14973}{Universality in numerical computations with random data}},
  author={Deift, P.A. and Menon, G. and Olver, S. and Trogdon, T.},
  journal={Proceedings of the National Academy of Sciences},
  year={2014},
  publisher={National Acad Sciences}
}
@book{tao2012topics,
  title={\href{https://bookstore.ams.org/gsm-132/}{Topics in random matrix theory}},
  author={Tao, T.},
  volume={132},
  year={2012},
  publisher={American Mathematical Soc.}
}
@article{nesterov2005smooth,
  title={\href{https://doi.org/10.1007/s10107-004-0552-5}{Smooth minimization of non-smooth functions}},
  author={Nesterov, Yu},
  journal={Mathematical programming},
  year={2005},
  publisher={Springer}
}
@misc{billingsley1995probability,
  title={Probability and measure},
  author={Billingsley, Patrick},
  year={1995},
  publisher={Wiley Series in Probability and Mathematical Statistics}
}
@article{taylor2017smooth,
  title={\href{https://link.springer.com/article/10.1007/s10107-016-1009-3}{Smooth strongly convex interpolation and exact worst-case performance of first-order methods}},
  author={Taylor, A.B. and Hendrickx, J.M. and Glineur, F.},
  journal={Mathematical Programming},
  year={2017},
  publisher={Springer}
}
@article{deift2017universality,
  title={Universality for eigenvalue algorithms on sample covariance matrices},
  author={Deift, Percy and Trogdon, Thomas},
  journal={SIAM Journal on Numerical Analysis},
  year={2017},
  publisher={SIAM}
}
@article{deift2016universality,
  title={Universality for the Toda algorithm to compute the eigenvalues of a random matrix},
  author={Deift, Percy and Trogdon, Thomas},
  journal={arXiv preprint arXiv:1604.07384},
  year={2016}
}
@article{ding2016singular,
  title={Singular vector distribution of sample covariance matrices},
  author={Ding, Xiucai},
  journal={arXiv preprint arXiv:1611.01837},
  year={2016}
}
@book{hiriart2013convex,
  title={\href{http://dx.doi.org/10.1007/978-3-662-02796-7}{Convex analysis and minimization algorithms I: Fundamentals}},
  author={Hiriart-Urruty, Jean-Baptiste and Lemar{\'e}chal, Claude},
  year={1993},
  publisher={Springer science \& business media}
}
@article{lee2014proximal,
  title={Proximal Newton-type methods for minimizing composite functions},
  author={Lee, Jason D and Sun, Yuekai and Saunders, Michael A},
  journal={SIAM Journal on Optimization},
  year={2014},
  publisher={SIAM}
}

@inproceedings{ma2009identifying,
  title={\href{https://dl.acm.org/citation.cfm?id=1553462}{Identifying suspicious URLs: an application of large-scale online learning}},
  author={Ma, Justin and Saul, Lawrence K and others},
  booktitle={Proceedings 26th ACM international conference on machine learning},
  year={2009},
}

@inproceedings{jaggi2013revisiting,
  title = {\href{http://proceedings.mlr.press/v28/jaggi13.pdf}{Revisiting {{Frank}}-{{Wolfe}}: {projection-free sparse convex optimization}}},
author = {Jaggi, Martin},
  booktitle={International Conference on Machine Learning},
  year = {2013},
}

@article{shalev2013stochastic,
  title={\href{http://www.jmlr.org/papers/volume14/shalev-shwartz13a/shalev-shwartz13a.pdf}{Stochastic dual coordinate ascent methods for regularized loss minimization}},
  author={Shalev-Shwartz, Shai and Zhang, Tong},
  journal={Journal of Machine Learning Research},
  year={2013}
}

@article{mania2017perturbed,
  title={\href{https://doi.org/10.1137/16M1057000}{Perturbed iterate analysis for asynchronous stochastic optimization}},
  author={Mania, Horia and Pan, Xinghao and Papailiopoulos, Dimitris and others},
  journal={SIAM Journal on Optimization},
  year={2017},
  publisher={SIAM}
}

@article{robbins1951,
author = "Robbins, H. and Monro, S.",
fjournal = "The Annals of Mathematical Statistics",
journal = "Ann. Math. Statist.",
publisher = "The Institute of Mathematical Statistics",
title = "\href{http://www.jstor.org/stable/2236626}{A Stochastic Approximation Method}",
year = "1951"
}

@article{goldstein2013adaptive,
  title={\href{https://arxiv.org/pdf/1305.0546.pdf}{Adaptive primal-dual hybrid gradient methods for saddle-point problems}},
  author={Goldstein, Tom and Li, Min and Yuan, Xiaoming and Esser, Ernie and Baraniuk, Richard},
  journal={arXiv preprint arXiv:1305.0546v2},
  year={2015}
}

@misc{rockafellar1997convex,
  title={Convex Analysis},
  author={Rockafellar, R Tyrrell},
  year={1997},
  publisher={Princeton University Press}
}


@article{shalev2012proximal,
  title={\href{https://arxiv.org/pdf/1211.2717.pdf}{Proximal stochastic dual coordinate ascent}},
  author={Shalev-Shwartz, Shai and Zhang, Tong},
  journal={arXiv preprint arXiv:1211.2717},
  year={2012}
}

@article{pedregosa2018adaptive,
  title={\href{https://arxiv.org/abs/1804.02339}{Adaptive Three Operator Splitting}},
  author={Pedregosa, Fabian and Gidel, Gauthier},
  journal={Proceedings of the 35th International Conference on Machine Learning},
  year={2018}
}


@inproceedings{fogel2013convex,
  title={\href{https://arxiv.org/abs/1306.4805}{Convex relaxations for permutation problems}},
  author={Fogel, Fajwel and Jenatton, Rodolphe and Bach, Francis and d'Aspremont, Alexandre},
  booktitle={Advances in Neural Information Processing Systems},
  year={2013}
}

@article{lawler1963quadratic,
  title={\href{http://dx.doi.org/10.1287/mnsc.9.4.586}{The quadratic assignment problem}},
  author={Lawler, Eugene L},
  journal={Management science},
  year={1963},
  publisher={INFORMS}
}

@article{Aflalo2015,
author = {Aflalo, Yonathan and Bronstein, Alexander and Kimmel, Ron},
journal = {Proceedings of the National Academy of Sciences},
title = {\href{http://doi.org/10.1073/pnas.1401651112}{On convex relaxation of graph isomorphism}},
year = {2015}
}

@article{yuan2007non,
  title={\href{http://dx.doi.org/10.1111/j.1467-9868.2007.00581.x}{On the non-negative garrotte estimator}},
  author={Yuan, Ming and Lin, Yi},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year={2007},
  publisher={Wiley Online Library}
}


@article{conte2004thirty,
  title={\href{http://dx.doi.org/10.1142/S0218001404003228}{Thirty years of graph matching in pattern recognition}},
  author={Conte, Donatello and Foggia, Pasquale and Sansone, Carlo and Vento, Mario},
  journal={International journal of pattern recognition and artificial intelligence},
  year={2004},
  publisher={World Scientific}
}

@article{lu2016fast,
  title={\href{https://arxiv.org/abs/1207.1114}{A fast projected fixed-point algorithm for large graph matching}},
  author={Lu, Yao and Huang, Kaizhu and Liu, Cheng-Lin},
  journal={Pattern Recognition},
  year={2016},
  publisher={Elsevier}
}

@article{davis2015three,
  title={\href{https://arxiv.org/abs/1504.01032v1}{A three-operator splitting scheme and its optimization applications}},
  author={Davis, Damek and Yin, Wotao},
  journal={preprint arXiv:1504.01032v1},
  year={2015}
}

@book{bauschke2017convex,
  title={\href{http://dx.doi.org/10.1007/978-3-319-48311-5}{Convex analysis and monotone operator theory in Hilbert spaces}},
  author={Bauschke, Heinz H and Combettes, Patrick L},
  year={2017},
  publisher={Springer Science \& Business Media}
}

@article{bauschke2014rate,
  title={The rate of linear convergence of the Douglas--Rachford algorithm for subspaces is the cosine of the Friedrichs angle},
  author={Bauschke, Heinz H and Cruz, JY Bello and Nghia, Tran TA and Phan, Hung M and Wang, Xianfu},
  journal={Journal of Approximation Theory},
  year={2014},
  publisher={Academic Press}
}

@article{he2015convergence,
  title={On the convergence rate of Douglas--Rachford operator splitting method},
  author={He, Bingsheng and Yuan, Xiaoming},
  journal={Mathematical Programming},
  volume={153},
  number={2},
  pages={715--722},
  year={2015},
  publisher={Springer}
}
@article{barbero2014modular,
  title={\href{https://arxiv.org/abs/1411.0589}{Modular proximal optimization for multidimensional total-variation regularization}},
  author={Barbero, {\'A}lvaro and Sra, Suvrit},
  journal={arXiv preprint arXiv:1411.0589},
  year={2014}
}

@article{vu2013splitting,
  title={\href{https://doi.org/10.1007/s10444-011-9254-8}{A splitting algorithm for dual monotone inclusions involving cocoercive operators}},
  author={V{\~u}, B·∫±ng C{\^o}ng},
  journal={Advances in Computational Mathematics},
  year={2013},
  publisher={Springer}
}


@inproceedings{jacob2009group,
  title={\href{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.329.9684}{Group lasso with overlap and graph lasso}},
  author={Jacob, Laurent and Obozinski, Guillaume and Vert, Jean-Philippe},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  year={2009},
  organization={ACM}
}

@article{villa2013accelerated,
  title={Accelerated and inexact forward-backward algorithms},
  author={Villa, Silvia and Salzo, Saverio and Baldassarre, Luca and Verri, Alessandro},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={3},
  pages={1607--1633},
  year={2013},
  publisher={SIAM}
}
@article{giselsson2016linear,
  title={\href{https://doi.org/10.1109/TAC.2016.2564160}{Linear Convergence and Metric Selection in Douglas-Rachford Splitting and ADMM}},
  author={Giselsson, Pontus and Boyd, Stephen},
  journal={IEEE Transactions on Automatic Control},
  year={2016},
}

@article{davis2017three,
author="Davis, Damek
and Yin, Wotao",
title={\href{https://doi.org/10.1007/s11228-017-0421-z}{A three-operator splitting scheme and its optimization applications}},
journal="Set-Valued and Variational Analysis",
year="2017",
}

@article{bauschke2016douglas,
  title={On the Douglas--Rachford algorithm},
  author={Bauschke, Heinz H and Moursi, Walaa M},
  journal={arXiv preprint arXiv:1604.04603},
  year={2016}
}
@article{eckstein1992douglas,
  title={On the {Douglas-Rachford} splitting method and the proximal point algorithm for maximal monotone operators},
  author={Eckstein, Jonathan and Bertsekas, Dimitri P},
  journal={Mathematical Programming},
  year={1992},
  publisher={Springer}
}
@incollection{auslender1987numerical,
  title={Numerical methods for nondifferentiable convex optimization},
  author={Auslender, Alfred},
  booktitle={Nonlinear Analysis and Optimization},
  pages={102--126},
  year={1987},
  publisher={Springer}
}
@article{songtraining,
  title={Training Deep Neural Networks via Direct Loss Minimization},
  author={Song, Yang and EDU, TSINGHUA and Schwing, Alexander G and EDU, TORONTO and Zemel, Richard S and Urtasun, Raquel}
}
@article{raguet2013generalized,
  title={\href{https://doi.org/10.1137/120872802}{A generalized forward-backward splitting}},
  author={Raguet, Hugo and Fadili, Jalal and Peyr{\'e}, Gabriel},
  journal={SIAM Journal on Imaging Sciences},
  year={2013},
  publisher={SIAM}
}
@inproceedings{zhao2018stochastic,
  title={\href{http://proceedings.mlr.press/v84/zhao18a.html}{Stochastic Three-Composite Convex Minimization with a Linear Operator}},
  author={Zhao, Renbo and Cevher, Volkan},
  booktitle={Proceedings of the 21st International Conference on Artificial Intelligence and Statistics},
  year={2018},
}
@inproceedings{collobert2002parallel,
  title={\href{http://papers.nips.cc/paper/1949-a-parallel-mixture-of-svms-for-very-large-scale-problems.pdf}{A parallel mixture of SVMs for very large scale problems}},
  author={Collobert, Ronan and Bengio, Samy and Bengio, Yoshua},
  booktitle={Advances in Neural Information Processing Systems},
  pages={633--640},
  year={2002}
}

@article{yan2018new,
  title={\href{https://doi.org/10.1007/s10915-018-0680-3}{A New Primal--Dual Algorithm for Minimizing the Sum of Three Functions with a Linear Operator}},
  author={Yan, Ming},
  journal={Journal of Scientific Computing},
  year={2018},
  publisher={Springer}
}


@article{lewis2004rcv1,
  title={\href{http://www.jmlr.org/papers/v5/lewis04a.html}{RCV1: A new benchmark collection for text categorization research}},
  author={Lewis, David D and Yang, Yiming and Rose, Tony G and Li, Fan},
  journal={Journal of machine learning research},
  volume={5},
  number={Apr},
  pages={361--397},
  year={2004}
}
@inproceedings{yu2010feature,
  title={\href{http://ntur.lib.ntu.edu.tw/retrieve/188513/17.pdf}{Feature engineering and classifier ensemble for KDD cup 2010}},
  author={Yu, Hsiang-Fu and Lo, Hung-Yi and Hsieh, Hsun-Ping and Lou, Jing-Kai and McKenzie, Todd G and Chou, Jung-Wei and Chung, Po-Han and Ho, Chia-Hua and Chang, Chun-Fu and Wei, Yin-Hsuan and others},
  booktitle={KDD Cup},
  year={2010}
}
@inproceedings{juan2016field,
  title={\href{http://ntucsu.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf}{Field-aware factorization machines for {CTR} prediction}},
  author={Juan, Yuchin and Zhuang, Yong and Chin, Wei-Sheng and Lin, Chih-Jen},
  booktitle={Proceedings of the 10th {ACM} Conference on Recommender Systems},
  year={2016},
  organization={ACM}
}
@article{bauschke2012firmly,
  title={Firmly nonexpansive mappings and maximally monotone operators: correspondence and duality},
  author={Bauschke, Heinz H and Moffat, Sarah M and Wang, Xianfu},
  journal={Set-Valued and Variational Analysis},
  year={2012},
  publisher={Springer}
}
@article{xiao2014proximal,
  title={\href{https://doi.org/10.1137/140961791}{A proximal stochastic gradient method with progressive variance reduction}},
  author={Xiao, Lin and Zhang, Tong},
  journal={SIAM Journal on Optimization},
  year={2014},
}
@inproceedings{harikandeh2015stopwasting,
  title={StopWasting My Gradients: Practical SVRG},
  author={Harikandeh, Reza and Ahmed, Mohamed Osama and Virani, Alim and Schmidt, Mark and Kone{\v{c}}n{\`y}, Jakub and Sallinen, Scott},
  booktitle={Advances in Neural Information Processing Systems},
  year={2015}
}
@inproceedings{hofmann2015variance,
  title={\href{http://papers.nips.cc/paper/5919-variance-reduced-stochastic-gradient-descent-with-neighbors}{Variance Reduced Stochastic Gradient Descent with Neighbors}},
  author={Hofmann, Thomas and Lucchi, Aurelien and Lacoste-Julien, Simon and McWilliams, Brian},
  booktitle={Advances in Neural Information Processing Systems},
  year={2015}
}
@article{bach2010self,
  title={Self-concordant analysis for logistic regression},
  author={Bach, Francis and others},
  journal={Electronic Journal of Statistics},
  year={2010},
  publisher={Institute of Mathematical Statistics}
}
@article{shalev2015sdca,
  title={SDCA without duality},
  author={Shalev-Shwartz, Shai},
  journal={arXiv preprint arXiv:1502.06177},
  year={2015}
}
@article{lions1979splitting,
  title={\href{http://epubs.siam.org/doi/abs/10.1137/0716071}{Splitting algorithms for the sum of two nonlinear operators}},
  author={Lions, Pierre-Louis and Mercier, Bertrand},
  journal={SIAM Journal on Numerical Analysis},
  year={1979},
}


@article{nesterov2013gradient,
  title={\href{https://doi.org/10.1007/s10107-012-0629-5}{Gradient methods for minimizing composite objective function}},
  author={Nesterov, Yurii and others},
  year={2013},
journal="Mathematical Programming",
}
@inproceedings{mairal2013optimization,
  title={\href{http://proceedings.mlr.press/v28/mairal13.pdf}{Optimization with first-order surrogate functions}},
  author={Mairal, Julien},
  booktitle={Proceedings of the 30th International Conference on Machine Learning (ICML-13)},
  pages={783--791},
  year={2013}
}

@article{yuan2013efficient,
  title={Efficient methods for overlapping group lasso.},
  author={Yuan, L and Liu, J and Ye, J},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2013}
}
@inproceedings{defazio2014saga,
  title={\href{https://arxiv.org/pdf/1407.0202.pdf}{{SAGA}: A fast incremental gradient method with support for non-strongly convex composite objectives}},
  author={Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
  booktitle={Advances in Neural Information Processing Systems},
  year={2014}
}
@inproceedings{hazan2015beyond,
  title={Beyond Convexity: Stochastic Quasi-Convex Optimization},
  author={Hazan, Elad and Levy, Kfir and Shalev-Shwartz, Shai},
  booktitle={Advances in Neural Information Processing Systems},
  year={2015}
}
@article{pearlmutter1994fast,
  title={Fast exact multiplication by the Hessian},
  author={Pearlmutter, Barak A},
  journal={Neural computation},
  year={1994},
  publisher={MIT Press}
}
@inproceedings{mairal2013stochastic,
  title={Stochastic Majorization-Minimization Algorithms for Large-Scale Optimization},
  author={Mairal, Julien},
  booktitle={Neural Information Processing System (NIPS)},
  year={2013}
}
@article{los2012image,
  title={Image denoising: Learning noise distribution via PDE-constrained optimization},
  author={De los Reyes, Juan Carlos and Sch{\"o}nlieb, Carola-Bibiane},
  journal={arXiv preprint arXiv:1207.3425},
  year={2012}
}
@article{tsanas2010accurate,
  title={Accurate telemonitoring of Parkinson's disease progression by noninvasive speech tests},
  author={Tsanas, Athanasios and Little, Max A and McSharry, Patrick E and Ramig, Lorraine O},
  journal={Biomedical Engineering, IEEE Transactions on},
  year={2010},
  publisher={IEEE}
}
@article{lacoste2014sequential,
  title={Sequential model-based ensemble optimization},
  author={Lacoste, Alexandre and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and Marchand, Mario},
  journal={arXiv preprint arXiv:1402.0796},
  year={2014}
}
@inproceedings{nitanda2014stochastic,
  title={Stochastic proximal gradient descent with acceleration techniques},
  author={Nitanda, Atsushi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1574--1582},
  year={2014}
}
@article{sagun2018universal,
  title={Universal halting times in optimization and machine learning},
  author={Sagun, L. and Trogdon, T. and LeCun, Y.},
  journal={Quarterly of Applied Mathematics},
  volume={76},
  number={2},
  pages={289--301},
  year={2018}
}
@article{defazio2016simple,
  title={A Simple Practical Accelerated Method for Finite Sums},
  author={Defazio, Aaron},
  journal={arXiv preprint arXiv:1602.02442},
  year={2016}
}
@article{lin2008trust,
  title={Trust region newton method for logistic regression},
  author={Lin, Chih-Jen and Weng, Ruby C and Keerthi, S Sathiya},
  journal={The Journal of Machine Learning Research},
  volume={9},
  pages={627--650},
  year={2008},
  publisher={JMLR. org}
}
@article{bergstra2012random,
  title={Random search for hyper-parameter optimization},
  author={Bergstra, James and Bengio, Yoshua},
  journal={The Journal of Machine Learning Research},
  volume={13},
  number={1},
  year={2012},
  publisher={JMLR. org}
}
@article{calatroni2015bilevel,
  title={Bilevel approaches for learning of variational imaging models},
  author={Calatroni, Luca and Chung, Cao and Reyes, Juan Carlos De Los and Sch{\"o}nlieb, Carola-Bibiane and Valkonen, Tuomo},
  journal={arXiv preprint arXiv:1505.02120},
  year={2015}
}
@article{reyes2015structure,
  title={The structure of optimal parameters for image restoration problems},
  author={De los Reyes, J.C. and Sch{\"o}nlieb, Carola-Bibiane and Valkonen, Tuomo},
  journal={arXiv preprint arXiv:1505.01953},
  year={2015}
}

@article{de2015bilevel,
  title={Bilevel parameter learning for higher-order total variation regularisation models},
  author={De los Reyes, J.C. and Sch{\"o}nlieb, C-B and Valkonen, T},
  journal={arXiv preprint arXiv:1508.07243},
  year={2015}
}
@article{kunisch2013bilevel,
  title={A bilevel optimization approach for parameter learning in variational models},
  author={Kunisch, Karl and Pock, Thomas},
  journal={SIAM Journal on Imaging Sciences},
  year={2013},
  publisher={Society for Industrial and Applied Mathematics}
}

@book{nesterov2004introductory,
  title={\href{http://dx.doi.org/10.1007/978-1-4419-8853-9}{Introductory lectures on convex optimization}},
  author={Nesterov, Y.},
  year={2004},
  publisher={Springer}
}
@inproceedings{borghesani2014perceptual,
  title={A perceptual-to-conceptual gradient of word coding along the ventral path},
  author={Borghesani, Valentina and Pedregosa, Fabian and Eger, Evelyn and Buiatti, Marco and Piazza, Manuela},
  booktitle={Pattern Recognition in Neuroimaging, 2014 International Workshop on},
  year={2014},
}
@article{luketina2015scalable,
  title={Scalable Gradient-Based Tuning of Continuous Regularization Hyperparameters},
  author={Luketina, Jelena and Berglund, Mathias and Raiko, Tapani},
  journal={arXiv preprint arXiv:1511.06727},
  year={2015}
}
@article{liu1989limited,
  title={On the limited memory BFGS method for large scale optimization},
  author={Liu, Dong C and Nocedal, Jorge},
  journal={Mathematical programming},
  year={1989},
  publisher={Springer}
}
@article{cox2003functional,
  title={Functional magnetic resonance imaging (fMRI) ``brain reading'': detecting and classifying distributed patterns of fMRI activity in human visual cortex},
  author={Cox, David D and Savoy, Robert L},
  journal={Neuroimage},
  year={2003},
  publisher={Elsevier}
}
@article{seeger2008cross,
  title={Cross-validation optimization for large scale structured classification kernel methods},
  author={Seeger, Matthias W},
  journal={The Journal of Machine Learning Research},
  year={2008},
  publisher={JMLR. org}
}
@article{haynes2006decoding,
  title={Decoding mental states from brain activity in humans},
  author={Haynes, John-Dylan and Rees, Geraint},
  journal={Nature Reviews Neuroscience},
  year={2006},
  publisher={Nature Publishing Group}
}
@article{minka2003comparison,
  title={A comparison of numerical optimizers for logistic regression},
  author={Minka, Thomas P},
  journal={Unpublished draft},
  year={2003},
  publisher={Citeseer}
}
@article{owen2007robust,
  title={\href{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.78.5932&rep=rep1&type=pdf}{A robust hybrid of lasso and ridge regression}},
  author={Owen, Art B},
  journal={Contemporary Mathematics},
  year={2007},
  publisher={Providence, RI: American Mathematical Society}
}
@inproceedings{gramfort2013identifying,
  title={\href{https://doi.org/10.1109/PRNI.2013.14}{Identifying predictive regions from {fMRI} with {TV-L1} prior}},
  author={Gramfort, Alexandre and Thirion, Bertrand and Varoquaux, Ga{\"e}l},
  booktitle={International Workshop on Pattern Recognition in Neuroimaging},
  year={2013},
  organization={IEEE}
}
@article{swersky2014freeze,
  title={Freeze-Thaw Bayesian Optimization},
  author={Swersky, Kevin and Snoek, Jasper and Adams, Ryan Prescott},
  journal={arXiv preprint arXiv:1406.3896},
  year={2014}
}
@article{byrd2011use,
  title={On the use of stochastic hessian information in optimization methods for machine learning},
  author={Byrd, Richard H and Chin, Gillian M and Neveitt, Will and Nocedal, Jorge},
  journal={SIAM Journal on Optimization},
  year={2011},
  publisher={SIAM}
}
@inproceedings{roux2012stochastic,
  title={\href{http://papers.nips.cc/paper/4633-a-stochastic-gradient-method-with-an-exponential-convergence-_rate-for-finite-training-sets.pdf}{A stochastic gradient method with an exponential convergence rate for finite training sets}},
  author={Le Roux, Nicolas and Schmidt, Mark and Bach, Francis},
  year={2012}
}

@inproceedings{yurtsever2016stochastic,
  title={\href{https://papers.nips.cc/paper/6127-stochastic-three-composite-convex-minimization}{Stochastic Three-Composite Convex Minimization}},
  author={Yurtsever, Alp and Vu, Cong Bang and Cevher, Volkan},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@article{rosasco2016stochastic,
  title={\href{https://arxiv.org/abs/1507.00848}{A stochastic inertial forward--backward splitting algorithm for multivariate monotone inclusions}},
  author={Rosasco, Lorenzo and Villa, Silvia and V{\~u}, B{\u{a}}ng C{\^o}ng},
  journal={Optimization},
  year={2016},
  publisher={Taylor \& Francis}
}
@article{balamurugan2016stochastic,
  title={\href{https://arxiv.org/abs/1605.06398}{Stochastic Variance Reduction Methods for Saddle-Point Problems}},
  author={Balamurugan, P and Bach, Francis},
  journal={Advances in Neural Information Processing Systems},
  year={2016}
}
@article{combettes2016stochastic,
  title={\href{https://arxiv.org/abs/1602.08021}{Stochastic forward-backward and primal-dual approximation algorithms with application to online image restoration}},
  author={Combettes, Patrick L and Pesquet, Jean-Christophe},
  journal={24th European Signal Processing Conference (EUSIPCO)},  year={2016}
}
@article{ouyang2013stochastic,
  title={\href{http://jmlr.csail.mit.edu/proceedings/papers/v28/ouyang13.pdf}{Stochastic Alternating Direction Method of Multipliers.}},
  author={Ouyang, Hua and He, Niao and Tran, Long and Gray, Alexander G},
  journal={Proceedings of the 26th International Conference on Machine Learning (ICML)},
  year={2013}
  }

  @inproceedings{azadi2014towards,
    title={\href{http://jmlr.org/proceedings/papers/v32/azadi14.pdf}{Towards an optimal stochastic alternating direction method of multipliers}},
    author={Azadi, Samaneh and Sra, Suvrit},
    booktitle={Proceedings of the 31st International Conference on Machine Learning},
    year={2014}
  }

@inproceedings{richard2012estimation,
  title={\href{https://arxiv.org/abs/1206.6474}{Estimation of Simultaneously Sparse and Low Rank Matrices}},
  author={Richard, Emile and Savalle, Pierre-andre and Vayatis, Nicolas},
  booktitle={Proceedings of the 29th International Conference on Machine Learning},
  year={2012}
}
@article{schmidt2017minimizing,
  title={\href{https://doi.org/10.1007/s10107-016-1030-6}{Minimizing finite sums with the stochastic average gradient}},
  author={Schmidt, Mark and Le Roux, Nicolas and Bach, Francis},
  journal={Mathematical Programming},
  year={2017},
  publisher={Springer}
}

@article{candes2006robust,
  title={\href{https://doi.org/10.1109/TIT.2005.862083}{Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information}},
  author={Cand{\`e}s, Emmanuel J and Romberg, Justin and Tao, Terence},
  journal={IEEE Transactions on information theory},
  year={2006},
  publisher={IEEE}
}
@inproceedings{johnson2013accelerating,
  title={\href{http://papers.nips.cc/paper/4937-accelerating-stochastic-gradient-descent-using-predictive-variance-reduc}{Accelerating stochastic gradient descent using predictive variance reduction}},
  author={Johnson, Rie and Zhang, Tong},
  booktitle={Advances in Neural Information Processing Systems},
  year={2013}
}

@article{ryu2017proximal,
  title={\href{https://arxiv.org/abs/1708.06908}{Proximal-Proximal-Gradient Method}},
  author={Ryu, Ernest K and Yin, Wotao},
  journal={arXiv preprint arXiv:1708.06908},
  year={2017}
}

@inproceedings{el2015totally,
  title={\href{https://arxiv.org/abs/1411.1990}{A totally unimodular view of structured sparsity}},
  author={El Halabi, Marwa and Cevher, Volkan},
  booktitle={Proceedings of the 18th International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year={2015}
}

@InProceedings{gidel17a,
  title = 	 {\href{http://proceedings.mlr.press/v54/gidel17a/gidel17a.pdf}{Frank-Wolfe Algorithms for Saddle Point Problems}},
  author = 	 {G. Gidel and T. Jebara and S. Lacoste-Julien},
  booktitle = 	 {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
  year = 	 {2017},
  publisher = 	 {PMLR},
}

@inproceedings{hegde2009compressive,
  title={\href{https://hal.inria.fr/inria-00369584/}{Compressive sensing recovery of spike trains using a structured sparsity model}},
  author={Hegde, Chinmay and Duarte, Marco F and Cevher, Volkan},
  booktitle={SPARS'09-Signal Processing with Adaptive Sparse Structured Representations},
  year={2009}
}

@article{rudin1992nonlinear,
  title={\href{https://doi.org/10.1016/0167-2789(92)90242-F}{Nonlinear total variation based noise removal algorithms}},
  author={Rudin, Leonid I and Osher, Stanley and Fatemi, Emad},
  journal={Physica D: Nonlinear Phenomena},
  year={1992},
  publisher={Elsevier}
}
@book{rockafellar1998variational,
  title={\href{10.1007/978-3-642-02431-3}{Variational analysis}},
  author={Rockafellar, R Tyrrell and Wets, Roger J-B},
  publisher={Springer},
  year={1998}
}

@book{rockafellar1970convex,
  title={Convex analysis},
  author={Rockafellar, Ralph Tyrell},
  year={1970},
  publisher={Princeton university press}
}

@article{deift2017some,
  title={Some open problems in random matrix theory and the theory of integrable systems. II},
  author={Deift, Percy},
  journal={arXiv preprint arXiv:1703.04931},
  year={2017}
}

@inproceedings{evgeniou2005learning,
  title={Learning multiple tasks with kernel methods},
  author={Evgeniou, Theodoros and Micchelli, Charles A and Pontil, Massimiliano},
  booktitle={Journal of Machine Learning Research},
  year={2005}
}
@article{parikh2013proximal,
  title={\href{http://www.nowpublishers.com/article/Details/OPT-003}{Proximal algorithms}},
  author={Parikh, Neal and Boyd, Stephen},
  journal={Foundations and Trends in Optimization},
  year={2013}
}

@Article{Iusem1998,
author="Iusem, A. N.",
title="\href{https://doi.org/10.1023/A:1022670114963}{On Some Properties of Generalized Proximal Point Methods for Variational Inequalities}",
journal="Journal of Optimization Theory and Applications",
year="1998",
}


@article{boyd2011distributed,
  title={\href{http://dx.doi.org/10.1561/2200000016}{Distributed optimization and statistical learning via the alternating direction method of multipliers}},
  author={Boyd, Stephen and Parikh, Neal and others},
  journal={Foundations and Trends in Machine Learning},
  year={2011},
  publisher={Now Publishers Inc.}
}

@article{beck2009gradient,
  title={\href{https://doi.org/10.1017/CBO9780511804458.003}{Gradient-based algorithms with applications to signal recovery}},
  author={Beck, Amir and Teboulle, Marc},
  journal={Convex Optimization in Signal Processing and Communications},
  year={2009}
}
@article{glowinski1975approximation,
  title={\href{http://www.numdam.org/article/M2AN_1975__9_2_41_0.pdf}{Sur l'approximation, par {\'e}l{\'e}ments finis d'ordre un, et la r{\'e}solution, par p{\'e}nalisation-dualit{\'e} d'une classe de probl{\`e}mes de {D}irichlet non lin{\'e}aires}},
  author={Glowinski, Roland and Marroco, A},
  journal={Revue fran{\c{c}}aise d'automatique, informatique, recherche op{\'e}rationnelle. Analyse num{\'e}rique},
  year={1975},
  publisher={EDP Sciences}
}
@article{gabay1976dual,
  title={\href{https://doi.org/10.1016/0898-1221(76)90003-1}{A dual algorithm for the solution of nonlinear variational problems via finite element approximation}},
  author={Gabay, Daniel and Mercier, Bertrand},
  journal={Computers \& Mathematics with Applications},
  year={1976},
  publisher={Elsevier}
}
@article{yan2016primal,
  title={\href{https://arxiv.org/pdf/1611.09805.pdf}{A Primal-dual Three-operator Splitting Scheme}},
  author={Yan, Ming},
  journal={arXiv preprint arXiv:1611.09805},
  year={2016}
}

@article{briceno2015forward,
  title={\href{http://dx.doi.org/10.1080/02331934.2013.855210}{Forward-Douglas--Rachford splitting and forward-partial inverse method for solving monotone inclusions}},
  author={Brice{\~n}o-Arias, Luis M},
  journal={Optimization},
  year={2015},
  publisher={Taylor \& Francis}
}

@article{douglas1956numerical,
  title={\href{http://www.jstor.org/stable/1993056}{On the numerical solution of heat conduction problems in two and three space variables}},
  author={Douglas, Jim and Rachford, Henry H},
  journal={Transactions of the American mathematical Society},
  year={1956},
  publisher={JSTOR}
}

@incollection{yi2017admm,
title = {\href{http://papers.nips.cc/paper/6726-admm-without-a-fixed-penalty-parameter-faster-convergence-with-new-adaptive-penalization.pdf}{ADMM without a fixed penalty parameter: faster convergence with new adaptive penalization}},
author = {Xu, Yi and Liu, Mingrui and Lin, Qihang and Yang, Tianbao},
booktitle = {Advances in Neural Information Processing Systems 30},
year = {2017},
}

@inproceedings{schmidt2011convergence,
  title={\href{http://papers.nips.cc/paper/4452-convergence-rates-of-inexact-proximal-gradient-methods-for-convex-optimization}{Convergence rates of inexact proximal-gradient methods for convex optimization}},
  author={Schmidt, Mark and Le Roux, Nicolas and Bach, Francis},
  booktitle={Advances in neural information processing systems 24},
  year={2011}
}

@incollection{ochs2015bilevel,
  title={Bilevel Optimization with Nonsmooth Lower Level Problems},
  author={Ochs, Peter and Ranftl, Ren{\'e} and Brox, Thomas and Pock, Thomas},
  booktitle={Scale Space and Variational Methods in Computer Vision},
  publisher={Springer}
}

@article{mallows1973some,
  title={Some comments on {$C_p$}},
  author={Mallows, Colin L},
  journal={Technometrics},
  year={1973},
  publisher={Taylor \& Francis Group}
}

@inproceedings{larsen1996design,
  title={Design and regularization of neural networks: the optimal use of a validation set},
  author={Larsen, Jan and Hansen, Lars Kai and Svarer, Claus and Ohlsson, M},
  booktitle={Neural Networks for Signal Processing [1996] VI. Proceedings of the 1996 IEEE Signal Processing Society Workshop},
  year={1996},
  organization={IEEE}
}

@inproceedings{hutter2013evaluation,
  title={An evaluation of sequential model-based optimization for expensive blackbox functions},
  author={Hutter, Frank and Hoos, Holger and Leyton-Brown, Kevin},
  booktitle={Proceedings of the 15th annual conference companion on Genetic and evolutionary computation},
  year={2013},
}

@article{yuan2006model,
  title={\href{http://dx.doi.org/10.1111/j.1467-9868.2005.00532.x}{Model selection and estimation in regression with grouped variables}},
  author={Yuan, Ming and Lin, Yi},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year={2006},
  publisher={Wiley Online Library}
}

@article{liu2011parametric,
  title={Parametric or nonparametric? A parametricness index for model selection},
  author={Liu, Wei and Yang, Yuhong},
  journal={The Annals of Statistics},
  year={2011},
}

@article{stein1981estimation,
  title={Estimation of the mean of a multivariate normal distribution},
  author={Stein, Charles M},
  journal={The annals of Statistics},
  year={1981},
}

@book{golub2012matrix,
  title={Matrix computations},
  author={Golub, Gene H. and Van Loan, Charles F.},
  year={2012},
  publisher={JHU Press}
}

@book{migdalas2013multilevel,
  title={Multilevel optimization: algorithms and applications},
  author={Migdalas, Athanasios and Pardalos, Panos M and V{\"a}rbrand, Peter},
  year={2013},
}

@article{martinet1970breve,
  title={R{\'e}gularisation d'in{\'e}quations variationnelles par approximations successives},
  author={Martinet, Bernard},
  journal={Revue fran{\c{c}}aise d'informatique et de recherche op{\'e}rationnelle, s{\'e}rie rouge},
  year={1970}
}

@article{rockafellar1976monotone,
  title={Monotone operators and the proximal point algorithm},
  author={Rockafellar, R. Tyrrell},
  journal={SIAM journal on control and optimization},
  year={1976},
}

@article{brochu2010tutorial,
  title={A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning},
  author={Brochu, Eric and Cora, Vlad M and De Freitas, Nando},
  journal={arXiv preprint arXiv:1012.2599},
  year={2010}
}

@article{tibshirani2011nearly,
  title={\href{https://doi.org/10.1198/TECH.2010.10111}{Nearly-isotonic regression}},
  author={Tibshirani, Ryan J and Hoefling, Holger and Tibshirani, Robert},
  journal={Technometrics},
  year={2011},
  publisher={Taylor \& Francis}
}
@book{bertsekas2015convex,
  title={\href{http://www.athenasc.com/convexalg.html}{Convex optimization algorithms}},
  author={Bertsekas, D.},
  year={2015},
  publisher={Athena Scientific Belmont}
}


@incollection{combettes2011proximal,
  title={\href{https://doi.org/10.1007/978-1-4419-9569-8_10}{Proximal splitting methods in signal processing}},
  author={Combettes, Patrick L and Pesquet, Jean-Christophe},
  booktitle={Fixed-point algorithms for inverse problems in science and engineering},
  year={2011},
  publisher={Springer}
}

@article{tibshirani1996regression,
  title={Regression shrinkage and selection via the lasso},
  author={Tibshirani, Robert},
  journal={Journal of the Royal Statistical Society. Series B (Methodological)},
  year={1996},
  publisher={JSTOR}
}

@article{tibshirani2005sparsity,
  title={\href{http://dx.doi.org/10.1111/j.1467-9868.2005.00490.x}{Sparsity and smoothness via the fused lasso}},
  author={Tibshirani, Robert and Saunders, Michael and Rosset, Saharon and Zhu, Ji and Knight, Keith},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year={2005},
  publisher={Wiley Online Library}
}


@article{guyon2010model,
  title={Model selection: Beyond the bayesian/frequentist divide},
  author={Guyon, Isabelle and Saffari, Amir and Dror, Gideon and Cawley, Gavin},
  journal={The Journal of Machine Learning Research},
  year={2010},
}

@book{higham2002accuracy,
  title={Accuracy and stability of numerical algorithms},
  author={Higham, Nicholas J},
  year={2002},
}

@inproceedings{domke2012generic,
  title={Generic methods for optimization-based modeling},
  author={Domke, Justin},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2012}
}
@article{d2008smooth,
  title={Smooth optimization with approximate gradient},
  author={d'Aspremont, Alexandre},
  journal={SIAM Journal on Optimization},
  year={2008},
}

@incollection{NIPS2007_3286,
title = {Efficient multiple hyperparameter learning for log-linear models},
author = {{Chuan-Sheng} Foo and Chuong B. Do and Andrew Y. Ng},
booktitle = {Advances in Neural Information Processing Systems 20},
year = {2008},
}
@article{deledalle2014stein,
  title={Stein Unbiased GrAdient estimator of the Risk ({SUGAR}) for multiple parameter selection},
  author={Deledalle, Charles-Alban and Vaiter, Samuel and Fadili, Jalal and Peyr{\'e}, Gabriel},
  journal={SIAM Journal on Imaging Sciences},
  year={2014},
}
@book{nocedal2006numerical,
  title={\href{http://dx.doi.org/10.1007/978-0-387-40065-5}{Numerical optimization}},
  author={Nocedal, Jorge and Wright, Stephen},
  year={2006},
  publisher={Springer Science \& Business Media}
}


@article{bengio2000gradient,
  title={Gradient-based optimization of hyperparameters},
  author={Bengio, Yoshua},
  journal={Neural computation},
  volume={12},
  number={8},
  pages={1889--1900},
  year={2000},
  publisher={MIT Press}
}

@article{lecue2012oracle,
  title={Oracle inequalities for cross-validation type procedures},
  author={Lecu{\'e}, Guillaume and Mitchell, Charles},
  journal={Electronic Journal of Statistics},
  volume={6},
  pages={1803--1837},
  year={2012},
  publisher={Institute of Mathematical Statistics}
}


@incollection{bergstra2011algorithms,
	Author = {J. Bergstra and R. Bardenet and Bengio, Y. and Bal\'{a}zs, K.},
	Booktitle = {Advances in Neural Information Processing Systems 24},
	Title = {Algorithms for Hyper-Parameter Optimization},
	Year = {2011},
}


@article{chapelle2002choosing,
  title={Choosing multiple parameters for support vector machines},
  author={Chapelle, Olivier and Vapnik, Vladimir and Bousquet, Olivier and Mukherjee, Sayan},
  journal={Machine learning},
  year={2002},
  publisher={Springer}
}

@inproceedings{hutter2014efficient,
  title={An Efficient Approach for Assessing Hyperparameter Importance},
  author={Hutter, Frank and Hoos, Holger and Leyton-Brown, Kevin},
  booktitle={Proceedings of The 31st International Conference on Machine Learning},
  year={2014}
}

@book{devroye1996probabilistic,
  title={A probabilistic theory of pattern recognition},
  author={Devroye, Luc},
  year={1996},
  publisher={Springer Science \& Business Media}
}

@incollection{larsen1998adaptive,
  title={Adaptive regularization in neural network modeling},
  author={Larsen, Jan and Svarer, Claus and Andersen, Lars Nonboe and Hansen, Lars Kai},
  booktitle={Neural Networks: Tricks of the Trade},
  year={1998},
  publisher={Springer}
}

@inproceedings{MacDuvAda2015hyper,
  title={Gradient-based Hyperparameter Optimization through Reversible Learning},
  author={Dougal Maclaurin and David Duvenaud and Ryan P. Adams},
  year={2015},
  month={July},
  booktitle={Proceedings of the 32nd International Conference on Machine Learning}
}

@article{bauschke2012attouch,
  title={\href{https://doi.org/10.1016/j.jat.2012.05.008}{Attouch--Th{\'e}ra duality revisited: paramonotonicity and operator splitting}},
  author={Bauschke, Heinz H and Bo{\c{t}}, Radu I and Hare, Warren L and Moursi, Walaa M},
  journal={Journal of Approximation Theory},
  year={2012},
  publisher={Elsevier}
}


@article{abdel2007adaptive,
  title={Adaptive optimization of hyperparameters in L2-regularised logistic regression},
  author={Abdel-Gawad, Ahmed and Ratner, Simon},
  journal={Technical report},
  year={2007}
}

@article{chen2014optimal,
  title={\href{https://doi.org/10.1137/130919362}{Optimal primal-dual methods for a class of saddle point problems}},
  author={Chen, Yunmei and Lan, Guanghui and Ouyang, Yuyuan},
  journal={SIAM Journal on Optimization},
  year={2014},
  publisher={SIAM}
}

@article{kim2009ell1,
  title={\href{https://doi.org/10.1137/070690274}{$\ell_1$ trend filtering}},
  author={Kim, Seung-Jean and Koh, Kwangmoo and Boyd, Stephen and others},
  journal={SIAM review},
  year={2009},
  publisher={SIAM}
}

@article{condat2013direct,
  title={\href{https://doi.org/10.1109/LSP.2013.2278339}{A direct algorithm for {1D} total variation denoising}},
  author={Condat, Laurent},
  journal={IEEE Signal Processing Letters},
  year={2013}
}

@article{johnson2013dynamic,
  title={\href{http://dx.doi.org/10.1080/10618600.2012.681238}{A dynamic programming algorithm for the fused lasso and {$L_0$}-segmentation}},
  author={Johnson, Nicholas},
  journal={Journal of Computational and Graphical Statistics},
  year={2013},
  publisher={Taylor \& Francis Group}
}

@article{Best1990,
  author="Best, Michael J.
  and Chakravarti, Nilotpal",
  title="\href{http://dx.doi.org/10.1007/BF01580873}{Active set algorithms for isotonic regression; A unifying framework}",
  journal="Mathematical Programming",
  year="1990",
}

@article{tibshirani2014adaptive,
  title={\href{http://dx.doi.org/10.1214/13-AOS1189}{Adaptive piecewise polynomial estimation via trend filtering}},
  author={Tibshirani, Ryan J and others},
  journal={The Annals of Statistics},
  year={2014},
  publisher={Institute of Mathematical Statistics}
}


@article{malitsky2016first,
  title={\href{https://arxiv.org/abs/1608.08883}{A first-order primal-dual algorithm with linesearch}},
  author={Malitsky, Yura and Pock, Thomas},
  journal={arXiv preprint arXiv:1608.08883},
  year={2016}
}

@inproceedings{giselsson2016line,
  title={\href{https://arxiv.org/pdf/1603.06772.pdf}{Line search for averaged operator iteration}},
  author={Giselsson, Pontus and F{\"a}lt, Mattias and Boyd, Stephen},
  booktitle={IEEE 55th Conference on Decision and Control (CDC)},
  year={2016},
  organization={IEEE}
}
@article{chambolle2016introduction,
  title={\href{https://doi.org/10.1017/S096249291600009X}{An introduction to continuous optimization for imaging}},
  author={Chambolle, Antonin and Pock, Thomas},
  journal={Acta Numerica},
  year={2016},
  publisher={Cambridge University Press}
}

@article{condat2013primal,
  title={\href{https://doi.org/10.1007/s10957-012-0245-9}{A primal--dual splitting method for convex optimization involving Lipschitzian, proximable and linear composite terms}},
  author={Condat, Laurent},
  journal={Journal of Optimization Theory and Applications},
  year={2013},
  publisher={Springer}
}

@article{richtarik2014iteration,
  title={\href{https://doi.org/10.1007/s10107-012-0614-z}{Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function}},
  author={Richt{\'a}rik, Peter and Tak{\'a}{\v{c}}, Martin},
  journal={Mathematical Programming},
  year={2014},
  publisher={Springer}
}
@article{lambert2016adaptive,
  title={\href{https://doi.org/10.1080/10485252.2016.1190359}{The adaptive BerHu penalty in robust regression}},
  author={Lambert-Lacroix, Sophie and Zwald, Laurent},
  journal={Journal of Nonparametric Statistics},
  year={2016},
  publisher={Taylor \& Francis}
}

@article{pedregosa2017breaking,
  title={\href{http://papers.nips.cc/paper/6611-breaking-the-nonsmooth-barrier-a-scalable-parallel-method-for-composite-optimization}{Breaking the Nonsmooth Barrier: A Scalable Parallel Method for Composite Optimization}},
  author={Pedregosa, Fabian and Leblond, R{\'e}mi and Lacoste-Julien, Simon},
  journal={Advances in Neural Information Processing System 30 (NIPS)},
  year={2017}
}

@article{chambolle2016ergodic,
  title={\href{https://doi.org/10.1007/s10107-015-0957-3}{On the ergodic convergence rates of a first-order primal--dual algorithm}},
  author={Chambolle, Antonin and Pock, Thomas},
  journal={Mathematical Programming},
  year={2015},
  publisher={Springer}
}

@article{leblond2016Asaga,
Author = {R\'emi Leblond and Fabian Pedregosa and Simon Lacoste-Julien},
Title = {\href{https://arxiv.org/abs/1606.04809}{{ASAGA}: Asynchronous Parallel {SAGA}}},
Year = {2017},
journal={Proceedings of the 20th International Conference on Artificial Intelligence and Statistics (AISTATS)},
}

@article{schmidt2013fast,
  title={\href{https://arxiv.org/abs/1308.6370}{Fast convergence of stochastic gradient descent under a strong growth condition}},
  author={Schmidt, M. and Le Roux, N.},
  journal={arXiv preprint arXiv:1308.6370},
  year={2013}
}

@article{bottou2018optimization,
  title={\href{https://epubs.siam.org/doi/10.1137/16M1080173}{Optimization methods for large-scale machine learning}},
  author={Bottou, L. and Curtis, F.E. and Nocedal, J.},
  journal={SIAM Review},
  volume={60},
  number={2},
  pages={223--311},
  year={2018},
  publisher={SIAM}
}

@misc{jax2018github,
  author = {J. Bradbury and R. Frostig and P. Hawkins and M. Johnson and C. Leary and D. Maclaurin and S. Wanderman-Milne},
  title = {\href{http://github.com/google/jax}{{JAX}: composable transformations of {P}ython+{N}um{P}y programs}},
  version = {0.1.55},
  year = {2018},
}

@book{cinlar2011,
  title={Probability and Stochastics},
  author={Erhan Cinlar},
  isbn={978-0-387-87859-1},
  DOI={10.1007/978-0-387-87859-1},
  year={2011},
  publisher={Springer}
}

@article{kiefer1952,
    author = "J. Kiefer and J. Wolfowitz",
    title = "{Stochastic Estimation of the Maximum of a Regression Function}",
    journal = "Ann. Math. Statist.",
    volume = "23",
    number = "3",
    pages = "462--466",
    year = "1952"
}

@article{bottou2018,
    author = "Leon Bottou, Frank E. Curtis and Jorge Nocedal",
    title = "Optimization Methods for Large-Scale Machine Learning",
    journal = "SIAM Rev.", 
    volume = "60",
    number = "2", 
    pages = "223‚Äì-311",
    year = "2018",
    DOI = "https://doi.org/10.1137/16M1080173"
}
 
@article{marchenko1967,
    author = "V. Marchenko and L. Pastur",
    title = "Distribution of eigenvalues for some sets of random matrices",
    journal = "Mathematics of the USSR-Sbornik",
    year = "1967"
}

@article{wilson2017,
       author = {{Wilson}, Ashia C. and {Roelofs}, Rebecca and {Stern}, Mitchell and
         {Srebro}, Nathan and {Recht}, Benjamin},
        title = "{The Marginal Value of Adaptive Gradient Methods in Machine Learning}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = 2017,
        month = may,
          eid = {arXiv:1705.08292},
        pages = {arXiv:1705.08292},
archivePrefix = {arXiv},
       eprint = {1705.08292},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170508292W},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{Hardt2015,
       author = {{Hardt}, Moritz and {Recht}, Benjamin and {Singer}, Yoram},
        title = "{Train faster, generalize better: Stability of stochastic gradient descent}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
         year = 2015,
        month = sep,
          eid = {arXiv:1509.01240},
        pages = {arXiv:1509.01240},
archivePrefix = {arXiv},
       eprint = {1509.01240},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2015arXiv150901240H},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{bousquet2002,
author = "O. Bousquet and A. Elisseeff",
title = "Stability and Generalization",
journal = "Journal of Machine Learning Research",
volume = "2",
pages = "499--526",
year = "2002"
}

@article{maillard2016,
author = "Pascal Maillard and Elliot Paquette",
journal = "Israel Journal of Mathematics",
volume = "212",
number = "1",
pages = "337-384",
year = "2016"
}

@book{nocedal2006,
title = "Numerical Optimization",
author = "J. Nocedal and S. J. Wright",
publisher = "Springer New York",
year = "2006",
edition = "2"
}

@article{mcmahan2011,
author = "H. Brendan McMahan and Matthew Streeter",
title = "Adaptive Subgradient Methods for
Online Learning and Stochastic Optimization",
journal = "Journal of Machine Learning Research",
volume = "12",
year = "2011",
pages = "2121--2159"
}

@ARTICLE{keskar2017,
       author = {{Shirish Keskar}, N. and {Socher}, R.},
        title = "\href{https://arxiv.org/pdf/1712.07628.pdf}{Improving Generalization Performance by Switching from Adam to SGD}",
      journal = {arXiv preprint arXiv:1712.07628},
     keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
         year = 2017
}

@ARTICLE{ma2015,
       author = {{Ma}, Anna and {Needell}, Deanna and {Ramdas}, Aaditya},
        title = "{Convergence properties of the randomized extended Gauss-Seidel and Kaczmarz methods}",
      journal = {arXiv e-prints},
     keywords = {Mathematics - Numerical Analysis},
         year = 2015,
          eid = {arXiv:1503.08235},
        pages = {arXiv:1503.08235},
archivePrefix = {arXiv},
       eprint = {1503.08235},
 primaryClass = {math.NA},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2015arXiv150308235M},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{spielman2009,
author = "Daniel A. Spielman and Shang-Hua Teng",
title = "Smoothed Analysis: An Attempt to Explain the Behavior of Algorithms in Practice",
year = {2009},
pages = {76-84},
volume = {52},
journal = {Commun. ACM},
doi = {10.1145/1562764.1562785}
}

@book{tao2012,
author = "Terence Tao",
title = "Topics in Random Matrix Theory",
volume = "132",
publisher = "American Mathematical Soc.",
year = "2012"
}

@ARTICLE{paquette2020,
       author = {{Paquette}, C. and {van Merri{\"e}nboer}, B. and
         {Pedregosa}, F.},
        title = "\href{https://arxiv.org/pdf/2006.04299.pdf}{Halting Time is Predictable for Large Models: A Universality Property and Average-case Analysis}",
      journal = {arXiv preprint arXiv:2006.04299},
     keywords = {Mathematics - Optimization and Control, Statistics - Machine Learning},
         year = 2020
}

@book{durrett2010,
author = {Rick Durrett},
title = {Probability: theory and examples},
edition = {4},
year = {2010},
publisher = "Cambridge University Press"
}


@article{yin1988,
author = {Y. Q. Yin, Z. D. Bai and P. R. Krishnaiah},
title = {On the limit of the largest eigenvalue of the large dimensional sample covariance matrix},
journal = "Probability Theory and Related Fields",
volume = "78",
pages = "509--521",
year = "1988"
}

@book{vershynin2018,
author = {R. Vershynin},
title = {High-Dimensional Probability, An introduction with Applications in Data Sciences},
year = "2018",
publisher = "Cambridge University Press",
}

%%%Kiwon added these
@book{kingman1993,
title = {\href{https://books.google.co.kr/books/about/Poisson_Processes.html?id=VEiM-OtwDHkC&redir_esc=y}{Poisson Processes}},
author = {Kingman, J. F. C. },
year = {1993},
publisher = {Clarendon Press$\cdot$Oxford}
}

@article{klar2000,
  title={\href{https://www.math.kit.edu/stoch/~klar/seite/veroeffentlichungen/media/tailprob-peis-2000.pdf}{Bounds on Tail Probabilities of Discrete Distributions}},
  author={Klar, B.},
  journal={Probability in the Engineering and Informational Sciences},
  volume = {14},
  pages = {161-171},
  year={2000}
}

@misc{pedregosa2021residual,
      title={A Hitchhiker's Guide to Momentum},
      author={Pedregosa, F.},
      url = {http://fa.bianp.net/blog/2021/hitchhiker/},
      year={2021}
    }




 
