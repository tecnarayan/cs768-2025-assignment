\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alonso-Mora et~al.(2017{\natexlab{a}})Alonso-Mora, Baker, and
  Rus]{AlonsoMora17a}
Alonso-Mora, J., Baker, S., and Rus, D.
\newblock Multi-robot formation control and object transport in dynamic
  environments via constrained optimization.
\newblock \emph{International Journal of Robotics Research}, 36\penalty0
  (9):\penalty0 1000--1021, 2017{\natexlab{a}}.

\bibitem[Alonso-Mora et~al.(2017{\natexlab{b}})Alonso-Mora, Samaranayake,
  Wallar, Frazzoli, and Rus]{AlonsoMora17b}
Alonso-Mora, J., Samaranayake, S., Wallar, A., Frazzoli, E., and Rus, D.
\newblock On-demand high-capacity ride-sharing via dynamic trip-vehicle
  assignment.
\newblock \emph{Proceedings of the National Academy of Sciences}, 114\penalty0
  (3):\penalty0 462--467, 2017{\natexlab{b}}.

\bibitem[Bacoyannis et~al.(2018)Bacoyannis, Glukhov, Jin, Kochems, and
  Song]{Bacoyannis18}
Bacoyannis, V., Glukhov, V., Jin, T., Kochems, J., and Song, D.~R.
\newblock Idiosyncrasies and challenges of data driven learning in electronic
  trading.
\newblock In \emph{NeurIPS Workshop on Challenges and Opportunities for AI in
  Financial Services}, 2018.
\newblock URL \url{https://arxiv.org/abs/1811.09549}.

\bibitem[Battaglia et~al.(2018)Battaglia, Hamrick, Bapst, Sanchez-Gonzalez,
  Zambaldi, Malinowski, Tacchetti, Raposo, Santoro, Faulkner, Gulcehre, Song,
  Ballard, Gilmer, Dahl, Vaswani, Allen, Nash, Langston, Dyer, Heess, Wierstra,
  Kohli, Botvinick, Vinyals, Li, and Pascanu]{Battaglia18}
Battaglia, P.~W., Hamrick, J.~B., Bapst, V., Sanchez-Gonzalez, A., Zambaldi,
  V., Malinowski, M., Tacchetti, A., Raposo, D., Santoro, A., Faulkner, R.,
  Gulcehre, C., Song, F., Ballard, A., Gilmer, J., Dahl, G., Vaswani, A.,
  Allen, K., Nash, C., Langston, V., Dyer, C., Heess, N., Wierstra, D., Kohli,
  P., Botvinick, M., Vinyals, O., Li, Y., and Pascanu, R.
\newblock Relational inductive biases, deep learning, and graph networks, 2018.

\bibitem[{Behbahani} et~al.(2019){Behbahani}, {Shiarlis}, {Chen}, {Kurin},
  {Kasewa}, {Stirbu}, {Gomes}, {Paul}, {Oliehoek}, {Messias}, and
  {Whiteson}]{Behbahani19}
{Behbahani}, F., {Shiarlis}, K., {Chen}, X., {Kurin}, V., {Kasewa}, S.,
  {Stirbu}, C., {Gomes}, J., {Paul}, S., {Oliehoek}, F.~A., {Messias}, J., and
  {Whiteson}, S.
\newblock Learning from demonstration in the wild.
\newblock In \emph{IEEE International Conference on Robotics and Automation},
  pp.\  775--781, 2019.

\bibitem[B{\"{o}}hmer et~al.(2019)B{\"{o}}hmer, Rashid, and
  Whiteson]{Boehmer19}
B{\"{o}}hmer, W., Rashid, T., and Whiteson, S.
\newblock Exploration with unreliable intrinsic reward in multi-agent
  reinforcement learning.
\newblock \emph{CoRR}, abs/1906.02138, 2019.
\newblock URL \url{http://arxiv.org/abs/1906.02138}.
\newblock Presented at the ICML {\em Exploration in Reinforcement Learning}
  workshop.

\bibitem[Castellini et~al.(2019)Castellini, Oliehoek, Savani, and
  Whiteson]{Castellini19}
Castellini, J., Oliehoek, F.~A., Savani, R., and Whiteson, S.
\newblock The representational capacity of action-value networks for
  multi-agent reinforcement learning.
\newblock In \emph{Proceedings of the 18th International Conference on
  Autonomous Agents and MultiAgent Systems}, AAMAS '19, pp.\  1862--1864, 2019.
\newblock URL
  \url{http://www.ifaamas.org/Proceedings/aamas2019/pdfs/p1862.pdf}.

\bibitem[Chen et~al.(2018)Chen, Zhou, Wen, Yang, Su, Zhang, Zhang, Wang, and
  Liu]{Chen18}
Chen, Y., Zhou, M., Wen, Y., Yang, Y., Su, Y., Zhang, W., Zhang, D., Wang, J.,
  and Liu, H.
\newblock Factorized q-learning for large-scale multi-agent systems.
\newblock \emph{CoRR}, abs/1809.03738, 2018.
\newblock URL \url{http://arxiv.org/abs/1809.03738}.

\bibitem[Chung et~al.(2014)Chung, Gulcehre, Cho, and Bengio]{Chung14}
Chung, J., Gulcehre, C., Cho, K., and Bengio, Y.
\newblock Empirical evaluation of gated recurrent neural networks on sequence
  modeling.
\newblock In \emph{NIPS Workshop on Deep Learning}, 2014.
\newblock URL \url{http://arxiv.org/abs/1412.3555}.

\bibitem[Correa-Posada \& S\'anchez-Martin(2015)Correa-Posada and
  S\'anchez-Martin]{CorreaPosada15}
Correa-Posada, C.~M. and S\'anchez-Martin, P.
\newblock Integrated power and natural gas model for energy adequacy in
  short-term operation.
\newblock \emph{IEEE Transactions on Power Systems}, 30\penalty0 (6):\penalty0
  3347--3355, 2015.

\bibitem[Crick \& Pfeffer(2002)Crick and Pfeffer]{Crick02}
Crick, C. and Pfeffer, A.
\newblock Loopy belief propagation as a basis for communication in sensor
  networks.
\newblock In \emph{Proceedings of the Nineteenth conference on Uncertainty in
  Artificial Intelligence}, pp.\  159--166. Morgan Kaufmann Publishers Inc.,
  2002.

\bibitem[Dotoli et~al.(2017)Dotoli, Fay, Mi\'skowicz, and Seatzu]{Dotoli17}
Dotoli, M., Fay, A., Mi\'skowicz, M., and Seatzu, C.
\newblock Advanced control in factory automation: a survey.
\newblock \emph{International Journal of Production Research}, 55\penalty0
  (5):\penalty0 1243--1259, 2017.

\bibitem[Foerster et~al.(2016)Foerster, Assael, de~Freitas, and
  Whiteson]{Foerster16}
Foerster, J., Assael, Y., de~Freitas, N., and Whiteson, S.
\newblock Learning to communicate with deep multi-agent reinforcement learning.
\newblock In \emph{NIPS 2016: Proceedings of the Thirtieth Annual Conference on
  Neural Information Processing Systems}, 2016.
\newblock URL
  \url{http://www.cs.ox.ac.uk/people/shimon.whiteson/pubs/foersternips16.pdf}.

\bibitem[Foerster et~al.(2017)Foerster, Nardelli, Farquhar, Torr, Kohli, and
  Whiteson]{Foerster17}
Foerster, J., Nardelli, N., Farquhar, G., Torr, P., Kohli, P., and Whiteson, S.
\newblock Stabilising experience replay for deep multi-agent reinforcement
  learning.
\newblock In \emph{ICML 2017: Proceedings of the Thirty-Fourth International
  Conference on Machine Learning}, 2017.
\newblock URL
  \url{http://www.cs.ox.ac.uk/people/shimon.whiteson/pubs/foerstericml17.pdf}.

\bibitem[Foerster et~al.(2018)Foerster, Farquhar, Afouras, Nardelli, and
  Whiteson]{Foerster18}
Foerster, J., Farquhar, G., Afouras, T., Nardelli, N., and Whiteson, S.
\newblock Counterfactual multi-agent policy gradients.
\newblock In \emph{The Thirty-Second AAAI Conference on Artificial Intelligence
  (AAAI-18)}, pp.\  2974--2982. AAAI Press, 2018.
\newblock URL \url{https://arxiv.org/abs/1705.08926}.

\bibitem[Guestrin et~al.(2002{\natexlab{a}})Guestrin, Lagoudakis, and
  Parr]{Guestrin02}
Guestrin, C., Lagoudakis, M., and Parr, R.
\newblock Coordinated reinforcement learning.
\newblock In \emph{ICML}, volume~2, pp.\  227--234, 2002{\natexlab{a}}.

\bibitem[Guestrin et~al.(2002{\natexlab{b}})Guestrin, Venkataraman, and
  Koller]{Guestrin02b}
Guestrin, C., Venkataraman, S., and Koller, D.
\newblock Context-specific multiagent coordination and planning with factored
  mdps.
\newblock In \emph{Eighteenth National Conference on Artificial Intelligence},
  pp.\  253--259, 2002{\natexlab{b}}.

\bibitem[Hausknecht \& Stone(2015)Hausknecht and Stone]{Hausknecht15}
Hausknecht, M.~J. and Stone, P.
\newblock Deep recurrent q-learning for partially observable mdps.
\newblock In \emph{2015 {AAAI} Fall Symposia}, pp.\  29--37, 2015.
\newblock URL
  \url{http://www.aaai.org/ocs/index.php/FSS/FSS15/paper/view/11673}.

\bibitem[Jiang et~al.(2020)Jiang, Dun, Huang, and Lu]{Jiang18}
Jiang, J., Dun, C., Huang, T., and Lu, Z.
\newblock Graph convolutional reinforcement learning.
\newblock In \emph{Internation Conference on Learning Representation}, 2020.
\newblock URL \url{https://arxiv.org/abs/1810.09202}.

\bibitem[Kok \& Vlassis(2006)Kok and Vlassis]{Kok06}
Kok, J.~R. and Vlassis, N.
\newblock Collaborative multiagent reinforcement learning by payoff
  propagation.
\newblock \emph{Journal of Machine Learning Research}, 7\penalty0
  (Sep):\penalty0 1789--1828, 2006.

\bibitem[Koller \& Parr(1999)Koller and Parr]{Koller99}
Koller, D. and Parr, R.
\newblock Computing factored value functions for policies in structured mdps.
\newblock In \emph{Proceedings of IJCAI}, pp.\  1332--1339, 1999.

\bibitem[Kraemer \& Banerjee(2016)Kraemer and Banerjee]{Kraemer16}
Kraemer, L. and Banerjee, B.
\newblock Multi-agent reinforcement learning as a rehearsal for decentralized
  planning.
\newblock \emph{Neurocomputing}, 190:\penalty0 82--94, 2016.

\bibitem[Lin(1992)]{Lin92}
Lin, L.-J.
\newblock Self-improving reactive agents based on reinforcement learning,
  planning and teaching.
\newblock \emph{Machine Learning}, 8\penalty0 (3):\penalty0 293--321, 1992.

\bibitem[Liu et~al.(2019)Liu, Wang, Hu, Hao, Chen, and Gao]{Liu19}
Liu, Y., Wang, W., Hu, Y., Hao, J., Chen, X., and Gao, Y.
\newblock Multi-agent game abstraction via graph attention neural network,
  2019.
\newblock URL \url{https://arxiv.org/abs/1911.10715}.

\bibitem[Lowe et~al.(2017)Lowe, WU, Tamar, Harb, Pieter~Abbeel, and
  Mordatch]{Lowe17}
Lowe, R., WU, Y., Tamar, A., Harb, J., Pieter~Abbeel, O., and Mordatch, I.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock In \emph{Advances in Neural Information Processing Systems 30}, pp.\
  6379--6390. 2017.
\newblock URL \url{https://arxiv.org/pdf/1706.02275.pdf}.

\bibitem[{Luo} et~al.(2019){Luo}, {Subagdja}, {Wang}, and {Tan}]{Luo19}
{Luo}, T., {Subagdja}, B., {Wang}, D., and {Tan}, A.
\newblock Multi-agent collaborative exploration through graph-based deep
  reinforcement learning.
\newblock In \emph{2019 IEEE International Conference on Agents (ICA)}, pp.\
  2--7, 2019.
\newblock URL
  \url{http://ica2019.crowdscience.org/wp-content/uploads/2019/10/Full-27-PID6151059.pdf}.

\bibitem[{Malysheva} et~al.(2019){Malysheva}, {Kudenko}, and
  {Shpilman}]{Malysheva19}
{Malysheva}, A., {Kudenko}, D., and {Shpilman}, A.
\newblock Magnet: Multi-agent graph network for deep multi-agent reinforcement
  learning.
\newblock In \emph{Adaptive and Learning Agents Workshop at AAMAS}, 2019.
\newblock URL \url{https://ala2019.vub.ac.be/papers/ALA2019_paper_17.pdf}.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{Mnih15}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., Petersen,
  S., Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumaran, D., Wierstra,
  D., Legg, S., and Hassabis, D.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518:\penalty0 529--533, February 2015.

\bibitem[Murphy et~al.(1999)Murphy, Weiss, and Jordan]{Murphy99}
Murphy, K.~P., Weiss, Y., and Jordan, M.~I.
\newblock Loopy belief propagation for approximate inference: An empirical
  study.
\newblock In \emph{Proceedings of the Fifteenth conference on Uncertainty in
  artificial intelligence}, pp.\  467--475. Morgan Kaufmann Publishers Inc.,
  1999.

\bibitem[Oliehoek \& Amato(2016)Oliehoek and Amato]{Oliehoek16}
Oliehoek, F.~A. and Amato, C.
\newblock \emph{A concise introduction to decentralized POMDPs}.
\newblock Springer Publishing Company, Incorporated, 1st edition, 2016.
\newblock ISBN 3319289276, 9783319289274.

\bibitem[{Oroojlooy jadid} \& Hajinezhad(2019){Oroojlooy jadid} and
  Hajinezhad]{Jadid19}
{Oroojlooy jadid}, A. and Hajinezhad, D.
\newblock A review of cooperative multi-agent deep reinforcement learning.
\newblock \emph{CoRR}, abs/1908.03963, 2019.
\newblock URL \url{http://arxiv.org/abs/1908.03963}.

\bibitem[Panait et~al.(2006)Panait, Luke, and Wiegand]{Panait06}
Panait, L., Luke, S., and Wiegand, R.~P.
\newblock Biasing coevolutionary search for optimal multiagent behaviors.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 10\penalty0
  (6):\penalty0 629--645, 2006.

\bibitem[Pearl(1988)]{Pearl88}
Pearl, J.
\newblock \emph{Probabilistic Reasoning in Intelligent Systems: Networks of
  Plausible Inference}.
\newblock Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1988.
\newblock ISBN 0-934613-73-7.

\bibitem[Rashid et~al.(2018)Rashid, Samvelyan, de~Witt, Farquhar, Foerster, and
  Whiteson]{Rashid18}
Rashid, T., Samvelyan, M., de~Witt, C.~S., Farquhar, G., Foerster, J.~N., and
  Whiteson, S.
\newblock {QMIX:} monotonic value function factorisation for deep multi-agent
  reinforcement learning.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  4292--4301, 2018.

\bibitem[Rogers et~al.(2011)Rogers, Farinelli, Stranders, and
  Jennings]{Rogers11}
Rogers, A.~C., Farinelli, A., Stranders, R., and Jennings, N.~R.
\newblock Bounded approximate decentralised coordination via the max-sum
  algorithm.
\newblock \emph{Artificial Intelligence}, 175\penalty0 (2):\penalty0 730--759,
  2011.
\newblock ISSN 0004-3702.
\newblock URL
  \url{http://www.sciencedirect.com/science/article/pii/S0004370210001803}.

\bibitem[Samvelyan et~al.(2019)Samvelyan, Rashid, de~Witt, Farquhar, Nardelli,
  Rudner, Hung, Torr, Foerster, and Whiteson]{Samvelyan19}
Samvelyan, M., Rashid, T., de~Witt, C.~S., Farquhar, G., Nardelli, N., Rudner,
  T. G.~J., Hung, C.-M., Torr, P. H.~S., Foerster, J., and Whiteson, S.
\newblock {The} {StarCraft} {Multi}-{Agent} {Challenge}.
\newblock \emph{CoRR}, abs/1902.04043, 2019.

\bibitem[{Schr\"oder de Witt} et~al.(2019){Schr\"oder de Witt}, F\"orster,
  Farquhar, Torr, B\"ohmer, and Whiteson]{SchroederDeWitt19}
{Schr\"oder de Witt}, C.~A., F\"orster, J.~N., Farquhar, G., Torr, P.~H.,
  B\"ohmer, W., and Whiteson, S.
\newblock Multi-agent common knowledge reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pp.\
  9927--9939, 2019.
\newblock URL \url{https://arxiv.org/abs/1810.11702}.

\bibitem[Son et~al.(2019)Son, Kim, Kang, Hostallero, and Yi]{Son19}
Son, K., Kim, D., Kang, W.~J., Hostallero, D.~E., and Yi, Y.
\newblock {QTRAN}: Learning to factorize with transformation for cooperative
  multi-agent reinforcement learning.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, volume~97 of \emph{Proceedings of Machine Learning Research}, pp.\
   5887--5896, 2019.
\newblock URL \url{http://proceedings.mlr.press/v97/son19a.html}.

\bibitem[Sunehag et~al.(2018)Sunehag, Lever, Gruslys, Czarnecki, Zambaldi,
  Jaderberg, Lanctot, Sonnerat, Leibo, Tuyls, and Graepel]{Sunehag18}
Sunehag, P., Lever, G., Gruslys, A., Czarnecki, W.~M., Zambaldi, V., Jaderberg,
  M., Lanctot, M., Sonnerat, N., Leibo, J.~Z., Tuyls, K., and Graepel, T.
\newblock Value-decomposition networks for cooperative multi-agent learning
  based on team reward.
\newblock In \emph{Proceedings of the 17th International Conference on
  Autonomous Agents and MultiAgent Systems (AAMAS)}, pp.\  2085--2087, 2018.

\bibitem[Tacchetti et~al.(2019)Tacchetti, Song, Mediano, Zambaldi, Kramár,
  Rabinowitz, Graepel, Botvinick, and Battaglia]{Tacchetti18}
Tacchetti, A., Song, H.~F., Mediano, P. A.~M., Zambaldi, V., Kramár, J.,
  Rabinowitz, N.~C., Graepel, T., Botvinick, M., and Battaglia, P.~W.
\newblock Relational forward models for multi-agent learning.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=rJlEojAqFm}.

\bibitem[Tan(1993)]{Tan93}
Tan, M.
\newblock Multi-agent reinforcement learning: Independent vs. cooperative
  agents.
\newblock In \emph{Proceedings of the tenth international conference on machine
  learning}, pp.\  330--337, 1993.

\bibitem[Van~der Pol \& Oliehoek(2016)Van~der Pol and Oliehoek]{VanDerPol16}
Van~der Pol, E. and Oliehoek, F.~A.
\newblock Coordinated deep reinforcement learners for traffic light control.
\newblock In \emph{NIPS'16 Workshop on Learning, Inference and Control of
  Multi-Agent Systems}, December 2016.
\newblock URL \url{https://sites.google.com/site/malicnips2016/papers}.

\bibitem[van Hasselt et~al.(2016)van Hasselt, Guez, and Silver]{Hasselt16}
van Hasselt, H., Guez, A., and Silver, D.
\newblock Deep reinforcement learning with double q-learning.
\newblock In \emph{Proceedings of the 13th AAAI Conference on Artificial
  Intelligence}, pp.\  2094--2100, 2016.
\newblock URL \url{https://arxiv.org/pdf/1509.06461.pdf}.

\bibitem[Vinyals et~al.(2019)Vinyals, Babuschkin, Czarnecki, Mathieu, Dudzik,
  Chung, Choi, Powell, Ewalds, Georgiev, Oh, Horgan, Kroiss, Danihelka, Huang,
  Sifre, Cai, Agapiou, Jaderberg, Vezhnevets, Leblond, Pohlen, Dalibard,
  Budden, Sulsky, Molloy, Paine, Gulcehre, Wang, Pfaff, Wu, Ring, Yogatama,
  W\"unsch, McKinney, Smith, Schaul, Lillicrap, Kavukcuoglu, Hassabis, Apps,
  and Silver]{Vinyals19}
Vinyals, O., Babuschkin, I., Czarnecki, W.~M., Mathieu, M., Dudzik, A., Chung,
  J., Choi, D.~H., Powell, R., Ewalds, T., Georgiev, P., Oh, J., Horgan, D.,
  Kroiss, M., Danihelka, I., Huang, A., Sifre, L., Cai, T., Agapiou, J.~P.,
  Jaderberg, M., Vezhnevets, A.~S., Leblond, R., Pohlen, T., Dalibard, V.,
  Budden, D., Sulsky, Y., Molloy, J., Paine, T.~L., Gulcehre, C., Wang, Z.,
  Pfaff, T., Wu, Y., Ring, R., Yogatama, D., W\"unsch, D., McKinney, K., Smith,
  O., Schaul, T., Lillicrap, T., Kavukcuoglu, K., Hassabis, D., Apps, C., and
  Silver, D.
\newblock Grandmaster level in {StarCraft II} using multi-agent reinforcement
  learning.
\newblock \emph{Nature}, 575:\penalty0 350--354, 2019.

\bibitem[Wainwright et~al.(2004)Wainwright, Jaakkola, and
  Willsky]{Wainwright04}
Wainwright, M., Jaakkola, T., and Willsky, A.
\newblock Tree consistency and bounds on the performance of the max-product
  algorithm and its generalizations.
\newblock \emph{Statistics and Computing}, 14\penalty0 (2):\penalty0 143--166,
  2004.

\bibitem[Watkins \& Dayan(1992)Watkins and Dayan]{Watkins92}
Watkins, C. and Dayan, P.
\newblock Q-learning.
\newblock \emph{Machine Learning}, 8:\penalty0 279--292, 1992.

\bibitem[Wei et~al.(2018)Wei, Wicke, Freelan, and Luke]{Wei18}
Wei, E., Wicke, D., Freelan, D., and Luke, S.
\newblock Multiagent soft q-learning.
\newblock In \emph{AAAI Spring Symposium Series}, 2018.
\newblock URL
  \url{https://www.aaai.org/ocs/index.php/SSS/SSS18/paper/view/17508/15482}.

\bibitem[Yang et~al.(2018)Yang, Luo, Li, Zhou, Zhang, and Wang]{Yang18}
Yang, Y., Luo, R., Li, M., Zhou, M., Zhang, W., and Wang, J.
\newblock Mean field multi-agent reinforcement learning.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, volume~80, pp.\  5571--5580, 2018.
\newblock URL \url{http://proceedings.mlr.press/v80/yang18d.html}.

\bibitem[Yedidia et~al.(2003)Yedidia, Freeman, and Weiss]{Yedidia03}
Yedidia, J.~S., Freeman, W.~T., and Weiss, Y.
\newblock Understanding belief propagation and its generalizations.
\newblock \emph{Exploring artificial intelligence in the new millennium},
  8:\penalty0 236--239, 2003.

\bibitem[Yedidsion et~al.(2018)Yedidsion, Zivan, and Farinelli]{Yedidsion18}
Yedidsion, H., Zivan, R., and Farinelli, A.
\newblock Applying max-sum to teams of mobile sensing agents.
\newblock \emph{Engineering Applications of Artificial Intelligence},
  71:\penalty0 87--99, 2018.
\newblock ISSN 0952-1976.
\newblock URL
  \url{http://www.sciencedirect.com/science/article/pii/S0952197618300381}.

\end{thebibliography}
