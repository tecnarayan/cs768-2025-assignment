@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{Touvron2023Llama2O,
  title={Llama 2: Open Foundation and Fine-Tuned Chat Models},
  author={Hugo Touvron and Louis Martin and Kevin R. Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Daniel M. Bikel and Lukas Blecher and Cristian Cant{\'o}n Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony S. Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel M. Kloumann and A. V. Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and R. Subramanian and Xia Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zhengxu Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
  journal={ArXiv},
  year={2023},
  volume={abs/2307.09288},
  url={https://api.semanticscholar.org/CorpusID:259950998}
}

@inproceedings{TheC3,
  title={The Claude 3 Model Family: Opus, Sonnet, Haiku},
  author={},
  url={https://api.semanticscholar.org/CorpusID:268232499}
}

@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}

@article{mo2023trustworthy,
  title={How trustworthy are open-source llms? an assessment under malicious demonstrations shows their vulnerabilities},
  author={Mo, Lingbo and Wang, Boshi and Chen, Muhao and Sun, Huan},
  journal={arXiv preprint arXiv:2311.09447},
  year={2023}
}

@article{bhatt2023purple,
  title={Purple llama cyberseceval: A secure coding benchmark for language models},
  author={Bhatt, Manish and Chennabasappa, Sahana and Nikolaidis, Cyrus and Wan, Shengye and Evtimov, Ivan and Gabi, Dominik and Song, Daniel and Ahmad, Faizan and Aschermann, Cornelius and Fontana, Lorenzo and others},
  journal={arXiv preprint arXiv:2312.04724},
  year={2023}
}

@article{zhang2023safetybench,
  title={Safetybench: Evaluating the safety of large language models with multiple choice questions},
  author={Zhang, Zhexin and Lei, Leqi and Wu, Lindong and Sun, Rui and Huang, Yongkang and Long, Chong and Liu, Xiao and Lei, Xuanyu and Tang, Jie and Huang, Minlie},
  journal={arXiv preprint arXiv:2309.07045},
  year={2023}
}

@article{wang2023not,
  title={Do-not-answer: A dataset for evaluating safeguards in llms},
  author={Wang, Yuxia and Li, Haonan and Han, Xudong and Nakov, Preslav and Baldwin, Timothy},
  journal={arXiv preprint arXiv:2308.13387},
  year={2023}
}

@article{wei2024jailbroken,
  title={Jailbroken: How does llm safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhou2024easyjailbreak,
  title={EasyJailbreak: A Unified Framework for Jailbreaking Large Language Models},
  author={Zhou, Weikang and Wang, Xiao and Xiong, Limao and Xia, Han and Gu, Yingshuang and Chai, Mingxu and Zhu, Fukang and Huang, Caishuang and Dou, Shihan and Xi, Zhiheng and others},
  journal={arXiv preprint arXiv:2403.12171},
  year={2024}
}

@article{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{yuan2023rrhf,
  title={Rrhf: Rank responses to align language models with human feedback without tears},
  author={Yuan, Zheng and Yuan, Hongyi and Tan, Chuanqi and Wang, Wei and Huang, Songfang and Huang, Fei},
  journal={arXiv preprint arXiv:2304.05302},
  year={2023}
}

@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{ethayarajh2024kto,
  title={Kto: Model alignment as prospect theoretic optimization},
  author={Ethayarajh, Kawin and Xu, Winnie and Muennighoff, Niklas and Jurafsky, Dan and Kiela, Douwe},
  journal={arXiv preprint arXiv:2402.01306},
  year={2024}
}

@article{huang2023catastrophic,
  title={Catastrophic jailbreak of open-source llms via exploiting generation},
  author={Huang, Yangsibo and Gupta, Samyak and Xia, Mengzhou and Li, Kai and Chen, Danqi},
  journal={arXiv preprint arXiv:2310.06987},
  year={2023}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{ji2024beavertails,
  title={Beavertails: Towards improved safety alignment of llm via a human-preference dataset},
  author={Ji, Jiaming and Liu, Mickel and Dai, Josef and Pan, Xuehai and Zhang, Chi and Bian, Ce and Chen, Boyuan and Sun, Ruiyang and Wang, Yizhou and Yang, Yaodong},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zheng2023secrets,
      title={Secrets of RLHF in Large Language Models Part I: PPO}, 
      author={Rui Zheng and Shihan Dou and Songyang Gao and Wei Shen and Binghai Wang and Yan Liu and Senjie Jin and Qin Liu and Limao Xiong and Lu Chen and Zhiheng Xi and Yuhao Zhou and Nuo Xu and Wenbin Lai and Minghao Zhu and Rongxiang Weng and Wensen Cheng and Cheng Chang and Zhangyue Yin and Yuan Hua and Haoran Huang and Tianxiang Sun and Hang Yan and Tao Gui and Qi Zhang and Xipeng Qiu and Xuanjing Huang},
      year={2023},
      eprint={2307.04964},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{chao2024jailbreakbench,
  title={JailbreakBench: An Open Robustness Benchmark for Jailbreaking Large Language Models},
  author={Chao, Patrick and Debenedetti, Edoardo and Robey, Alexander and Andriushchenko, Maksym and Croce, Francesco and Sehwag, Vikash and Dobriban, Edgar and Flammarion, Nicolas and Pappas, George J and Tramer, Florian and others},
  journal={arXiv preprint arXiv:2404.01318},
  year={2024}
}

@article{chen2022should,
  title={Why should adversarial perturbations be imperceptible? rethink the research paradigm in adversarial NLP},
  author={Chen, Yangyi and Gao, Hongcheng and Cui, Ganqu and Qi, Fanchao and Huang, Longtao and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2210.10683},
  year={2022}
}

@article{bhardwaj2023red,
  title={Red-teaming large language models using chain of utterances for safety-alignment},
  author={Bhardwaj, Rishabh and Poria, Soujanya},
  journal={arXiv preprint arXiv:2308.09662},
  year={2023}
}

@article{zhu2023promptbench,
  title={Promptbench: Towards evaluating the robustness of large language models on adversarial prompts},
  author={Zhu, Kaijie and Wang, Jindong and Zhou, Jiaheng and Wang, Zichen and Chen, Hao and Wang, Yidong and Yang, Linyi and Ye, Wei and Gong, Neil Zhenqiang and Zhang, Yue and others},
  journal={arXiv preprint arXiv:2306.04528},
  year={2023}
}

@article{xu2023sc,
  title={Sc-safety: A multi-round open-ended question adversarial safety benchmark for large language models in chinese},
  author={Xu, Liang and Zhao, Kangkang and Zhu, Lei and Xue, Hang},
  journal={arXiv preprint arXiv:2310.05818},
  year={2023}
}

@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

@article{inan2023llama,
  title={Llama guard: Llm-based input-output safeguard for human-ai conversations},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others},
  journal={arXiv preprint arXiv:2312.06674},
  year={2023}
}

@article{sun2023safety,
  title={Safety assessment of chinese large language models},
  author={Sun, Hao and Zhang, Zhexin and Deng, Jiawen and Cheng, Jiale and Huang, Minlie},
  journal={arXiv preprint arXiv:2304.10436},
  year={2023}
}

@article{Zou2023UniversalAT,
  title={Universal and Transferable Adversarial Attacks on Aligned Language Models},
  author={Andy Zou and Zifan Wang and J. Zico Kolter and Matt Fredrikson},
  journal={ArXiv},
  year={2023},
  volume={abs/2307.15043},
  url={https://api.semanticscholar.org/CorpusID:260202961}
}

@article{Chang2024PlayGG,
  title={Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues},
  author={Zhiyuan Chang and Mingyang Li and Yi Liu and Junjie Wang and Qing Wang and Yang Liu},
  journal={ArXiv},
  year={2024},
  volume={abs/2402.09091},
  url={https://api.semanticscholar.org/CorpusID:267657689}
}

@article{yu2024don,
  title={Don't Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models},
  author={Yu, Zhiyuan and Liu, Xiaogeng and Liang, Shunning and Cameron, Zach and Xiao, Chaowei and Zhang, Ning},
  journal={arXiv preprint arXiv:2403.17336},
  year={2024}
}

@article{zhou2024don,
  title={Don't Say No: Jailbreaking LLM by Suppressing Refusal},
  author={Zhou, Yukai and Wang, Wenjie},
  journal={arXiv preprint arXiv:2404.16369},
  year={2024}
}

@article{white2023prompt,
  title={A prompt pattern catalog to enhance prompt engineering with chatgpt},
  author={White, Jules and Fu, Quchen and Hays, Sam and Sandborn, Michael and Olea, Carlos and Gilbert, Henry and Elnashar, Ashraf and Spencer-Smith, Jesse and Schmidt, Douglas C},
  journal={arXiv preprint arXiv:2302.11382},
  year={2023}
}

@article{giray2023prompt,
  title={Prompt engineering with ChatGPT: a guide for academic writers},
  author={Giray, Louie},
  journal={Annals of biomedical engineering},
  volume={51},
  number={12},
  pages={2629--2633},
  year={2023},
  publisher={Springer}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{min2022rethinking,
  title={Rethinking the role of demonstrations: What makes in-context learning work?},
  author={Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2202.12837},
  year={2022}
}

@article{Sun2023SafetyAO,
  title={Safety Assessment of Chinese Large Language Models},
  author={Hao Sun and Zhexin Zhang and Jiawen Deng and Jiale Cheng and Minlie Huang},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.10436},
  url={https://api.semanticscholar.org/CorpusID:258236069}
}

@article{Shen2023DoAN,
  title={"Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models},
  author={Xinyue Shen and Zeyuan Johnson Chen and Michael Backes and Yun Shen and Yang Zhang},
  journal={ArXiv},
  year={2023},
  volume={abs/2308.03825},
  url={https://api.semanticscholar.org/CorpusID:260704242}
}

@article{yuan2024r,
  title={R-Judge: Benchmarking Safety Risk Awareness for LLM Agents},
  author={Yuan, Tongxin and He, Zhiwei and Dong, Lingzhong and Wang, Yiming and Zhao, Ruijie and Xia, Tian and Xu, Lizhen and Zhou, Binglin and Li, Fangqi and Zhang, Zhuosheng and others},
  journal={arXiv preprint arXiv:2401.10019},
  year={2024}
}

@article{li2024salad,
  title={SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models},
  author={Li, Lijun and Dong, Bowen and Wang, Ruohui and Hu, Xuhao and Zuo, Wangmeng and Lin, Dahua and Qiao, Yu and Shao, Jing},
  journal={arXiv preprint arXiv:2402.05044},
  year={2024}
}

@article{Mo2023HowTA,
  title={How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities},
  author={Lingbo Mo and Boshi Wang and Muhao Chen and Huan Sun},
  journal={ArXiv},
  year={2023},
  volume={abs/2311.09447},
  url={https://api.semanticscholar.org/CorpusID:265220739}
}

@article{dong2022survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Sui, Zhifang},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}

@inproceedings{NEURIPS2023_dfc310e8,
 author = {Feng, Guhao and Zhang, Bohang and Gu, Yuntian and Ye, Haotian and He, Di and Wang, Liwei},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 pages = {70757--70798},
 publisher = {Curran Associates, Inc.},
 title = {Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/dfc310e81992d2e4cedc09ac47eff13e-Paper-Conference.pdf},
 volume = {36},
 year = {2023}
}


@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@misc{chatgpt,
    title = "ChatGPT",
    howpublished = "Website",
    year = {2023},
    note = {\url{https://openai.com/blog/chatgpt}}
}


@misc{claude,
    title = "Claude",
    howpublished = "Website",
    year = {2023},
    note = {\url{https://www.anthropic.com}}
}


@misc{gpt4,
    title = "GPT-4",
    howpublished = "Website",
    year = {2023},
    note = {\url{https://openai.com/gpt-4}}
}

@article{Bai2023QwenTR,
  title={Qwen Technical Report},
  author={Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenhang Ge and Yu Han and Fei Huang and Binyuan Hui and Luo Ji and Mei Li and Junyang Lin and Runji Lin and Dayiheng Liu and Gao Liu and Chengqiang Lu and K. Lu and Jianxin Ma and Rui Men and Xingzhang Ren and Xuancheng Ren and Chuanqi Tan and Sinan Tan and Jianhong Tu and Peng Wang and Shijie Wang and Wei Wang and Shengguang Wu and Benfeng Xu and Jin Xu and An Yang and Hao Yang and Jian Yang and Jian Yang and Shusheng Yang and Yang Yao and Bowen Yu and Yu Bowen and Hongyi Yuan and Zheng Yuan and Jianwei Zhang and Xing Zhang and Yichang Zhang and Zhenru Zhang and Chang Zhou and Jingren Zhou and Xiaohuan Zhou and Tianhang Zhu},
  journal={ArXiv},
  year={2023},
  volume={abs/2309.16609},
  url={https://api.semanticscholar.org/CorpusID:263134555}
}

@article{Jiang2023Mistral7,
  title={Mistral 7B},
  author={Albert Qiaochu Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de Las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and L'elio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timoth{\'e}e Lacroix and William El Sayed},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.06825},
  url={https://api.semanticscholar.org/CorpusID:263830494}
}

@article{Zeng2022GLM130BAO,
  title={GLM-130B: An Open Bilingual Pre-trained Model},
  author={Aohan Zeng and Xiao Liu and Zhengxiao Du and Zihan Wang and Hanyu Lai and Ming Ding and Zhuoyi Yang and Yifan Xu and Wendi Zheng and Xiao Xia and Weng Lam Tam and Zixuan Ma and Yufei Xue and Jidong Zhai and Wenguang Chen and P. Zhang and Yuxiao Dong and Jie Tang},
  journal={ArXiv},
  year={2022},
  volume={abs/2210.02414},
  url={https://api.semanticscholar.org/CorpusID:252715691}
}

@article{Cai2024InternLM2TR,
  title={InternLM2 Technical Report},
  author={Zheng Cai and Maosong Cao and Haojiong Chen and Kai Chen and Keyu Chen and Xin Chen and Xun Chen and Zehui Chen and Zhi Chen and Pei Chu and Xiao-wen Dong and Haodong Duan and Qi Fan and Zhaoye Fei and Yang Gao and Jiaye Ge and Chenya Gu and Yuzhe Gu and Tao Gui and Aijia Guo and Qipeng Guo and Conghui He and Yingfan Hu and Ting Huang and Tao Jiang and Penglong Jiao and Zhen Jin and Zhikai Lei and Jiaxing Li and Jingwen Li and Linyang Li and Shuaibin Li and Wei Li and Yining Li and Hongwei Liu and Jiangning Liu and Jiawei Hong and Kaiwen Liu and Kui-Jie Liu and Xiaoran Liu and Chen Lv and Haijun Lv and Kai Lv and Li Ma and Runyuan Ma and Zerun Ma and Wenchang Ning and Linke Ouyang and Jiantao Qiu and Yuan Qu and Fukai Shang and Yunfan Shao and Demin Song and Zifan Song and Zhihao Sui and Peng Sun and Yu Sun and Huanze Tang and Bin Wang and Guoteng Wang and Jiaqi Wang and Jiayu Wang and Rui Wang and Yudong Wang and Ziyi Wang and Xing Wei and Qizhen Weng and Fan Wu and Yingtong Xiong and Chao Xu and Rui Ze Xu and Hang Yan and Yirong Yan and Xiaogui Yang and Haochen Ye and Huaiyuan Ying and Jia Yu and Jing Yu and Yuhang Zang and Chuyu Zhang and Li Zhang and Pan Zhang and Peng Zhang and Ruijie Zhang and Shuo Zhang and Songyang Zhang and Wenjian Zhang and Wenwei Zhang and Xingcheng Zhang and Xinyue Zhang and Hui Zhao and Qian Zhao and Xiaomeng Zhao and Fen-Fang Zhou and Zaida Zhou and Jingming Zhuo and Yi-Ling Zou and Xipeng Qiu and Yu Qiao and Dahua Lin},
  journal={ArXiv},
  year={2024},
  volume={abs/2403.17297},
  url={https://api.semanticscholar.org/CorpusID:268691939}
}

@article{Kaplan2020ScalingLF,
  title={Scaling Laws for Neural Language Models},
  author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeff Wu and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2001.08361},
  url={https://api.semanticscholar.org/CorpusID:210861095}
}

@article{ding2023wolf,
  title={A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can Fool Large Language Models Easily},
  author={Ding, Peng and Kuang, Jun and Ma, Dan and Cao, Xuezhi and Xian, Yunsen and Chen, Jiajun and Huang, Shujian},
  journal={arXiv preprint arXiv:2311.08268},
  year={2023}
}

@article{feng2021rethinking,
  title={Rethinking supervised pre-training for better downstream transferring},
  author={Feng, Yutong and Jiang, Jianwen and Tang, Mingqian and Jin, Rong and Gao, Yue},
  journal={arXiv preprint arXiv:2110.06014},
  year={2021}
}

@inproceedings{wang2023decodingtrust,
  title={DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models.},
  author={Wang, Boxin and Chen, Weixin and Pei, Hengzhi and Xie, Chulin and Kang, Mintong and Zhang, Chenhui and Xu, Chejian and Xiong, Zidi and Dutta, Ritik and Schaeffer, Rylan and others},
  booktitle={NeurIPS},
  year={2023}
}

@article{liu2024arondight,
  title={Arondight: Red teaming large vision language models with auto-generated multi-modal jailbreak prompts},
  author={Liu, Yi and Cai, Chengjun and Zhang, Xiaoli and Yuan, Xingliang and Wang, Cong},
  journal={arXiv preprint arXiv:2407.15050},
  year={2024}
}

@article{jiang2024hal,
  title={Hal-eval: A universal and fine-grained hallucination evaluation framework for large vision language models},
  author={Jiang, Chaoya and Ye, Wei and Dong, Mengfan and Jia, Hongrui and Xu, Haiyang and Yan, Ming and Zhang, Ji and Zhang, Shikun},
  journal={arXiv preprint arXiv:2402.15721},
  year={2024}
}

@article{liu2024deepseek,
  title={Deepseek-v2: A strong, economical, and efficient mixture-of-experts language model},
  author={Liu, Aixin and Feng, Bei and Wang, Bin and Wang, Bingxuan and Liu, Bo and Zhao, Chenggang and Dengr, Chengqi and Ruan, Chong and Dai, Damai and Guo, Daya and others},
  journal={arXiv preprint arXiv:2405.04434},
  year={2024}
}

@article{zhu2023autodan,
  title={Autodan: Automatic and interpretable adversarial attacks on large language models},
  author={Zhu, Sicheng and Zhang, Ruiyi and An, Bang and Wu, Gang and Barrow, Joe and Wang, Zichao and Huang, Furong and Nenkova, Ani and Sun, Tong},
  journal={arXiv preprint arXiv:2310.15140},
  year={2023}
}

@article{chao2023jailbreaking,
  title={Jailbreaking black box large language models in twenty queries},
  author={Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric},
  journal={arXiv preprint arXiv:2310.08419},
  year={2023}
}

@misc{gpt4o,
  author={OpenAI},
  title={GPT-4o mini: advancing cost-efficient intelligence},
  year={2024},
  url={https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/},
}

@misc{openaio1,
  author={OpenAI},
  title={Introducing OpenAI o1-preview},
  year={2024},
  url={https://openai.com/index/introducing-openai-o1-preview/},
}