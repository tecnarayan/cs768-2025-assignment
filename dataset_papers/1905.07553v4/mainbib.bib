
@inproceedings{taskonomy2018,
title={Taskonomy: Disentangling Task Transfer Learning},
author={Amir R. Zamir and Alexander Sax and William B. Shen and Leonidas J. Guibas and Jitendra Malik and Silvio Savarese},
booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
year={2018},
organization={IEEE},
}

@article{baker2017designing,
  title={Designing Neural Network Architectures using Reinforcement Learning},
  author={Baker, Bowen and Gupta, Otkrist and Naik, Nikhil and Raskar, Ramesh},
  journal={International Conference on Learning Representations},
  year={2017}
}

@article{sun2019adashare,
  title={AdaShare: Learning What To Share For Efficient Deep Multi-Task Learning},
  author={Sun, Ximeng and Panda, Rameswar and Feris, Rogerio},
  journal={arXiv preprint arXiv:1911.12423},
  year={2019}
}

@inproceedings{liu2019end,
  title={End-To-End Multi-Task Learning With Attention},
  author={Liu, Shikun and Johns, Edward and Davison, Andrew J},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={1871--1880},
  year={2019},
  organization={IEEE}
}

@misc{suteu2019regularizing,
    title={Regularizing Deep Multi-Task Networks using Orthogonal Gradients},
    author={Mihai Suteu and Yike Guo},
    year={2019},
    eprint={1912.06844},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@InProceedings{Chennupati_2019_CVPR_Workshops,
author = {Chennupati, Sumanth and Sistu, Ganesh and Yogamani, Senthil and Rawashdeh, Samir},
title = {MultiNet++: Multi-Stream Feature Aggregation and Geometric Loss Strategy for Multi-Task Learning},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2019}
}

@article{leang2020dynamic,
  title={Dynamic Task Weighting Methods for Multi-task Networks in Autonomous Driving Systems},
  author={Leang, Isabelle and Sistu, Ganesh and Burger, Fabian and Bursuc, Andrei and Yogamani, Senthil},
  journal={arXiv preprint arXiv:2001.02223},
  year={2020}
}

@ARTICLE{8848395,
author={T. {Gong} and T. {Lee} and C. {Stephenson} and V. {Renduchintala} and S. {Padhy} and A. {Ndirango} and G. {Keskin} and O. H. {Elibol}},
journal={IEEE Access},
title={A Comparison of Loss Weighting Strategies for Multi task Learning in Deep Neural Networks},
year={2019},
volume={7},
number={},
pages={141627-141632},
keywords={learning (artificial intelligence);neural nets;deep neural networks;deep multitask learning models;task pairs;task specific branches architecture;task-specific cost functions;loss weighting strategies;dynamic weight average;Task analysis;Training;Uncertainty;Deep learning;Data models;Estimation;Training data;Dynamic weighting average;multi-MNIST;multi-objective optimization;multi-task learning;uncertainty weighting},
doi={10.1109/ACCESS.2019.2943604},
ISSN={2169-3536},
month={},}


@inproceedings{47354,
  author    = {Esteban Real and
               Alok Aggarwal and
               Yanping Huang and
               Quoc V. Le},
  title     = {Regularized Evolution for Image Classifier Architecture Search},
  booktitle = {The Thirty-Third {AAAI} Conference on Artificial Intelligence, {AAAI}
               2019, The Thirty-First Innovative Applications of Artificial Intelligence
               Conference, {IAAI} 2019, The Ninth {AAAI} Symposium on Educational
               Advances in Artificial Intelligence, {EAAI} 2019, Honolulu, Hawaii,
               USA, January 27 - February 1, 2019},
  pages     = {4780--4789},
  publisher = {{AAAI} Press},
  year      = {2019},
  url       = {https://doi.org/10.1609/aaai.v33i01.33014780},
  doi       = {10.1609/aaai.v33i01.33014780},
  timestamp = {Wed, 25 Sep 2019 11:05:08 +0200},
  biburl    = {https://dblp.org/rec/conf/aaai/RealAHL19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}






@InProceedings{pmlr-v97-zhou19e,
  title = 	 {{B}ayes{NAS}: A {B}ayesian Approach for Neural Architecture Search},
  author = 	 {Zhou, Hongpeng and Yang, Minghao and Wang, Jun and Pan, Wei},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {7603--7613},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Long Beach, California, USA},
  month = 	 {09--15 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/zhou19e/zhou19e.pdf},
  url = 	 {http://proceedings.mlr.press/v97/zhou19e.html},
  abstract = 	 {One-Shot Neural Architecture Search (NAS) is a promising method to significantly reduce search time without any separate training. It can be treated as a Network Compression problem on the architecture parameters from an over-parameterized network. However, there are two issues associated with most one-shot NAS methods. First, dependencies between a node and its predecessors and successors are often disregarded which result in improper treatment over zero operations. Second, architecture parameters pruning based on their magnitude is questionable. In this paper, we employ the classic Bayesian learning approach to alleviate these two issues by modeling architecture parameters using hierarchical automatic relevance determination (HARD) priors. Unlike other NAS methods, we train the over-parameterized network for only one epoch then update the architecture. Impressively, this enabled us to find the architecture in both proxy and proxyless tasks on CIFAR-10 within only 0.2 GPU days using a single GPU. As a byproduct, our approach can be transferred directly to compress convolutional neural networks by enforcing structural sparsity which achieves extremely sparse networks without accuracy deterioration.}
}

@inproceedings{
elsken2018efficient,
title={Efficient Multi-Objective Neural Architecture Search via Lamarckian Evolution},
author={Thomas Elsken and Jan Hendrik Metzen and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=ByME42AqK7},
}

@inproceedings{45826,
  author    = {Barret Zoph and
               Quoc V. Le},
  title     = {Neural Architecture Search with Reinforcement Learning},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2017},
  url       = {https://openreview.net/forum?id=r1Ue8Hcxg},
  timestamp = {Thu, 04 Apr 2019 13:20:08 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/ZophL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}





@InProceedings{46637,
  title = 	 {Efficient Neural Architecture Search via Parameters Sharing},
  author = 	 {Pham, Hieu and Guan, Melody and Zoph, Barret and Le, Quoc and Dean, Jeff},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {4095--4104},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsm√§ssan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/pham18a/pham18a.pdf},
  url = 	 {http://proceedings.mlr.press/v80/pham18a.html},
  abstract = 	 {We propose Efficient Neural Architecture Search (ENAS), a fast and inexpensive approach for automatic model design. ENAS constructs a large computational graph, where each subgraph represents a neural network architecture, hence forcing all architectures to share their parameters. A controller is trained with policy gradient to search for a subgraph that maximizes the expected reward on a validation set. Meanwhile a model corresponding to the selected subgraph is trained to minimize a canonical cross entropy loss. Sharing parameters among child models allows ENAS to deliver strong empirical performances, whilst using much fewer GPU-hours than existing automatic model design approaches, and notably, 1000x less expensive than standard Neural Architecture Search. On Penn Treebank, ENAS discovers a novel architecture that achieves a test perplexity of 56.3, on par with the existing state-of-the-art among all methods without post-training processing. On CIFAR-10, ENAS finds a novel architecture that achieves 2.89% test error, which is on par with the 2.65% test error of NASNet (Zoph et al., 2018).}
}

@inproceedings{
xie2018snas,
title={{SNAS}: stochastic neural architecture search},
author={Sirui Xie and Hehui Zheng and Chunxiao Liu and Liang Lin},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=rylqooRqK7},
}

@inproceedings{liu2018progressive,
  title={Progressive neural architecture search},
  author={Liu, Chenxi and Zoph, Barret and Neumann, Maxim and Shlens, Jonathon and Hua, Wei and Li, Li-Jia and Fei-Fei, Li and Yuille, Alan and Huang, Jonathan and Murphy, Kevin},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={19--34},
  year={2018}
}

@article{DBLP:journals/corr/RusuRDSKKPH16,
  author    = {Andrei A. Rusu and
               Neil C. Rabinowitz and
               Guillaume Desjardins and
               Hubert Soyer and
               James Kirkpatrick and
               Koray Kavukcuoglu and
               Razvan Pascanu and
               Raia Hadsell},
  title     = {Progressive Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1606.04671},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.04671},
  archivePrefix = {arXiv},
  eprint    = {1606.04671},
  timestamp = {Mon, 13 Aug 2018 16:46:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/RusuRDSKKPH16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bengio2009curriculum,
 title={Curriculum learning},
 author={Bengio, Yoshua and Louradour, J{\‚Äôe}r{\^o}me and Collobert, Ronan and Weston, Jason},
 booktitle={Proceedings of the 26th annual international conference on machine learning},
 pages={41--48},
 year={2009},
 organization={ACM}
}

@INPROCEEDINGS{7780459,
author={K. {He} and X. {Zhang} and S. {Ren} and J. {Sun}},
booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title={Deep Residual Learning for Image Recognition},
year={2016},
volume={},
number={},
pages={770-778},
keywords={image classification;learning (artificial intelligence);neural nets;object detection;COCO segmentation;ImageNet localization;ILSVRC & COCO 2015 competitions;deep residual nets;COCO object detection dataset;visual recognition tasks;CIFAR-10;ILSVRC 2015 classification task;ImageNet test set;VGG nets;residual nets;ImageNet dataset;residual function learning;deeper neural network training;image recognition;deep residual learning;Training;Degradation;Complexity theory;Image recognition;Neural networks;Visualization;Image segmentation},
doi={10.1109/CVPR.2016.90},
ISSN={},
month={June},}

@article{wang2019neural,
  title={Neural Taskonomy: Inferring the Similarity of Task-Derived Representations from Brain Activity},
  author={Wang, Aria Y and Wehbe, Leila and Tarr, Michael J},
  journal={BioRxiv},
  pages={708016},
  year={2019},
  publisher={Cold Spring Harbor Laboratory}
}

@inproceedings{bingel-sogaard-2017-identifying,
    title = "Identifying beneficial task relations for multi-task learning in deep neural networks",
    author = "Bingel, Joachim  and
      S{\o}gaard, Anders",
    booktitle = "Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/E17-2026",
    pages = "164--169",
    abstract = "Multi-task learning (MTL) in deep neural networks for NLP has recently receivedincreasing interest due to some compelling benefits, including its potential toefficiently regularize models and to reduce the need for labeled data. While ithas brought significant improvements in a number of NLP tasks, mixed resultshave been reported, and little is known about the conditions under which MTLleads to gains in NLP. This paper sheds light on the specific task relationsthat can lead to gains from MTL models over single-task setups.",
}

@INPROCEEDINGS{Thrun96islearning,
    author = {Sebastian Thrun},
    title = {Is Learning The n-th Thing Any Easier Than Learning The First?},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {1996},
    pages = {640--646},
    publisher = {The MIT Press}
}

@Article{Caruana1997,
author="Caruana, Rich",
title="Multitask Learning",
journal="Machine Learning",
year="1997",
month="Jul",
day="01",
volume="28",
number="1",
pages="41--75",
issn="1573-0565",
doi="10.1023/A:1007379606734",
url="https://doi.org/10.1023/A:1007379606734"
}


@inproceedings{10.5555/2886521.2886688,
author = {Han, Lei and Zhang, Yu},
title = {Learning Multi-Level Task Groups in Multi-Task Learning},
year = {2015},
isbn = {0262511290},
publisher = {AAAI Press},
booktitle = {Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence},
pages = {2638‚Äì2644},
numpages = {7},
location = {Austin, Texas},
series = {AAAI‚Äô15}
}

@inproceedings{DBLP:conf/cvpr/ManinisRK19,
  author    = {Kevis{-}Kokitsi Maninis and
               Ilija Radosavovic and
               Iasonas Kokkinos},
  title     = {Attentive Single-Tasking of Multiple Tasks},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
               2019, Long Beach, CA, USA, June 16-20, 2019},
  pages     = {1851--1860},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2019},
  url       = {http://openaccess.thecvf.com/content\_CVPR\_2019/html/Maninis\_Attentive\_Single-Tasking\_of\_Multiple\_Tasks\_CVPR\_2019\_paper.html},
  doi       = {10.1109/CVPR.2019.00195},
  timestamp = {Mon, 20 Jan 2020 15:36:04 +0100},
  biburl    = {https://dblp.org/rec/conf/cvpr/ManinisRK19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@paper{AAAI1714430,
	author = {Yu Zhang and Qiang Yang},
	title = {Learning Sparse Task Relations in Multi-Task Learning},
	conference = {AAAI Conference on Artificial Intelligence},
	year = {2017},
	keywords = {Multi-Task Learning},
	abstract = {In multi-task learning, when the number of tasks is large, pairwise task relations exhibit sparse patterns since usually a task cannot be helpful to all of the other tasks and moreover, sparse task relations can reduce the risk of overfitting compared with the dense ones. In this paper, we focus on learning sparse task relations. Based on a regularization framework which can learn task relations among multiple tasks, we propose a SParse covAriance based mulTi-taSk (SPATS) model to learn a sparse covariance by using the ‚Ñìl regularization. The resulting objective function of the SPATS method is convex, which allows us to devise an alternating method to solve it. Moreover, some theoretical properties of the proposed model are studied. Experiments on synthetic and real-world datasets demonstrate the effectiveness of the proposed method.},

	url = {https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14430}
}



@inproceedings{DBLP:conf/cvpr/ZophVSL18,
  author    = {Barret Zoph and
               Vijay Vasudevan and
               Jonathon Shlens and
               Quoc V. Le},
  title     = {Learning Transferable Architectures for Scalable Image Recognition},
  booktitle = {2018 {IEEE} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2018, Salt Lake City, UT, USA, June 18-22, 2018},
  pages     = {8697--8710},
  publisher = {{IEEE} Computer Society},
  year      = {2018},
  url       = {http://openaccess.thecvf.com/content\_cvpr\_2018/html/Zoph\_Learning\_Transferable\_Architectures\_CVPR\_2018\_paper.html},
  doi       = {10.1109/CVPR.2018.00907},
  timestamp = {Wed, 16 Oct 2019 14:14:50 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/ZophVSL18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{8123910, 
author={D. {Zhou} and J. {Wang} and B. {Jiang} and H. {Guo} and Y. {Li}}, 
journal={IEEE Access}, 
title={Multi-Task Multi-View Learning Based on Cooperative Multi-Objective Optimization}, 
year={2018}, 
volume={6}, 
number={}, 
pages={19465-19477}, 
keywords={learning (artificial intelligence);mathematics computing;Pareto optimisation;particle swarm optimisation;quantum computing;multitask multiview learning;single-objective learning framework;multiobjective MTMV learning method;MTMV problem;multiobjective optimization problem;CMO-MTMV method;particle swarm optimization algorithm;multiswarm scheme;numerical optimization methods;view-view relations;multitask multiview models;single-objective MTMV learning methods;instance-instance relations;feature-feature relations;task-task relations;cooperative multiobjective quantum;cooperative multiobjective quantum-behaved particle swarm optimization;CMOQPSO;Optimization;Convergence;Particle swarm optimization;Learning systems;Linear programming;Sun;Multi-task multi-view learning;multi-objective optimization;quantum-behaved particle swarm optimization;multi-swarm strategy}, 
doi={10.1109/ACCESS.2017.2777888}, 
ISSN={2169-3536}, 
month={},}

@INPROCEEDINGS{6378235, 
author={P. B. C. d. {Miranda} and R. B. C. {Prud√™ncio} and A. C. P. L. F. d. {Carvalho} and C. {Soares}}, 
booktitle={2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
title={Combining a multi-objective optimization approach with meta-learning for SVM parameter selection}, 
year={2012}, 
volume={}, 
number={}, 
pages={2909-2914}, 
keywords={learning (artificial intelligence);Pareto optimisation;particle swarm optimisation;pattern classification;support vector machines;multiobjective optimization approach;metalearning;SVM parameter selection;support vector machines;supervised learning technique;particle swarm optimization;crowding distance mechanism;classification problem;random initialization;Pareto front;Support vector machines;Measurement;Search problems;Optimization;Sociology;Statistics;Proposals;Meta-Learning;Multi-Objective Optimization;SVM Parameter Selection;Particle Swarm Optimization}, 
doi={10.1109/ICSMC.2012.6378235}, 
ISSN={1062-922X}, 
month={Oct},}

@Article{RePEc:eee:ejores:v:271:y:2018:i:3:p:808-817,
  author={Mercier, Quentin and Poirion, Fabrice and D√©sid√©ri, Jean-Antoine},
  title={{A stochastic multiple gradient descent algorithm}},
  journal={European Journal of Operational Research},
  year=2018,
  volume={271},
  number={3},
  pages={808-817},
  month={},
  keywords={Multiple objective programming; Multiobjective stochastic optimization; Stochastic gradient algorith},
  doi={10.1016/j.ejor.2018.05.06},
  abstract={In this article, we propose a new method for multiobjective optimization problems in which the objective functions are expressed as expectations of random functions. The present method is based on an extension of the classical stochastic gradient algorithm and a deterministic multiobjective algorithm, the Multiple Gradient Descent Algorithm (MGDA). In MGDA a descent direction common to all specified objective functions is identified through a result of convex geometry. The use of this common descent vector and the Pareto stationarity definition into the stochastic gradient algorithm makes the algorithm able to solve multiobjective problems. The mean square and almost sure convergence of this new algorithm are proven considering the classical stochastic gradient algorithm hypothesis. The algorithm efficiency is illustrated on a set of benchmarks with diverse complexity and assessed in comparison with two classical algorithms (NSGA-II, DMS) coupled with a Monte Carlo expectation estimator.},
  url={https://ideas.repec.org/a/eee/ejores/v271y2018i3p808-817.html}
}

@incollection{NIPS2017_6757,
title = {Learning Multiple Tasks with Multilinear Relationship Networks},
author = {Long, Mingsheng and CAO, ZHANGJIE and Wang, Jianmin and Yu, Philip S},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {1594--1603},
year = {2017},
publisher = {Curran Associates, Inc.},
_url = {http://papers.nips.cc/paper/6757-learning-multiple-tasks-with-multilinear-relationship-networks.pdf}
}

@article{DBLP:journals/corr/ZhangY17aa,
  author    = {Yu Zhang and
               Qiang Yang},
  title     = {A Survey on Multi-Task Learning},
  journal   = {CoRR},
  volume    = {abs/1707.08114},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.08114},
  archivePrefix = {arXiv},
  eprint    = {1707.08114},
  timestamp = {Mon, 13 Aug 2018 16:49:00 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ZhangY17aa},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{5288526, 
author={S. J. {Pan} and Q. {Yang}}, 
journal={IEEE Transactions on Knowledge and Data Engineering}, 
title={A Survey on Transfer Learning}, 
year={2010}, 
volume={22}, 
number={10}, 
pages={1345-1359}, 
keywords={knowledge engineering;learning by example;optimisation;unsupervised learning;machine learning;data mining;knowledge transfer;inductive transfer learning;transductive transfer learning;unsupervised transfer learning;Machine learning;Training data;Data mining;Knowledge transfer;Space technology;Knowledge engineering;Machine learning algorithms;Labeling;Learning systems;Testing;Transfer learning;survey;machine learning;data mining.}, 
doi={10.1109/TKDE.2009.191}, 
ISSN={1041-4347}, 
month={Oct},}

@inproceedings{Razavian:2014:CFO:2679599.2679731,
 author = {Razavian, Ali Sharif and Azizpour, Hossein and Sullivan, Josephine and Carlsson, Stefan},
 title = {CNN Features Off-the-Shelf: An Astounding Baseline for Recognition},
 booktitle = {Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops},
 series = {CVPRW '14},
 year = {2014},
 isbn = {978-1-4799-4308-1},
 pages = {512--519},
 numpages = {8},
 url = {http://dx.doi.org.stanford.idm.oclc.org/10.1109/CVPRW.2014.131},
 doi = {10.1109/CVPRW.2014.131},
 acmid = {2679731},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
} 
@ARTICLE{achille2019task2vec,
       author = {{Achille}, Alessandro and {Lam}, Michael and {Tewari}, Rahul and
        {Ravichandran}, Avinash and {Maji}, Subhransu and {Fowlkes},
        Charless and {Soatto}, Stefano and {Perona}, Pietro},
        title = "{Task2Vec: Task Embedding for Meta-Learning}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
         year = 2019,
        month = Feb,
          eid = {arXiv:1902.03545},
        pages = {arXiv:1902.03545},
archivePrefix = {arXiv},
       eprint = {1902.03545},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/#abs/2019arXiv190203545A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@misc{pal2019zeroshot,
    title={Zero-Shot Task Transfer},
    author={Arghya Pal and Vineeth N Balasubramanian},
    year={2019},
    eprint={1903.01092},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}


@inproceedings{dwivedi2019,
  author    = {K. Dwivedi and G. Roig.},
  title     = {Representation Similarity Analysis for Efficient Task Taxonomy and Transfer Learning.},
  booktitle = {{CVPR}},
  publisher = {{IEEE} Computer Society},
  year      = {2019}
}


@inproceedings{DBLP:conf/cvpr/LuKZCJF17,
  author    = {Yongxi Lu and
               Abhishek Kumar and
               Shuangfei Zhai and
               Yu Cheng and
               Tara Javidi and
               Rog{\'{e}}rio Schmidt Feris},
  title     = {Fully-Adaptive Feature Sharing in Multi-Task Networks with Applications
               in Person Attribute Classification},
  booktitle = {{CVPR}},
  pages     = {1131--1140},
  publisher = {{IEEE} Computer Society},
  year      = {2017}
}

@inproceedings{luolabel,
	title={Label Efficient Learning of Transferable Representations acrosss Domains and Tasks},
	author={Luo, Zelun and Zou, Yuliang and Hoffman, Judy and Fei-Fei, Li F},
	booktitle={Advances in Neural Information Processing Systems},
	pages={164--176},
	year={2017}
}

@inproceedings{niculescu2007inductive,
	title={Inductive transfer for Bayesian network structure learning},
	author={Niculescu-Mizil, Alexandru and Caruana, Rich},
	booktitle={Artificial Intelligence and Statistics},
	pages={339--346},
	year={2007}
}

@inproceedings{mihalkova2007mapping,
	title={Mapping and revising Markov logic networks for transfer learning},
	author={Mihalkova, Lilyana and Huynh, Tuyen and Mooney, Raymond J},
	booktitle={AAAI},
	volume={7},
	pages={608--614},
	year={2007}
}

@inproceedings{finn2016deep,
	title={Deep spatial autoencoders for visuomotor learning},
	author={Finn, Chelsea and Tan, Xin Yu and Duan, Yan and Darrell, Trevor and Levine, Sergey and Abbeel, Pieter},
	booktitle={Robotics and Automation (ICRA), 2016 IEEE International Conference on},
	pages={512--519},
	year={2016},
	organization={IEEE}
}

@InProceedings{10.1007/978-3-642-04180-8_52,
author="Helleputte, Thibault
and Dupont, Pierre",
editor="Buntine, Wray
and Grobelnik, Marko
and Mladeni{\'{c}}, Dunja
and Shawe-Taylor, John",
title="Feature Selection by Transfer Learning with Linear Regularized Models",
booktitle="Machine Learning and Knowledge Discovery in Databases",
year="2009",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="533--547",
abstract="This paper presents a novel feature selection method for classification of high dimensional data, such as those produced by microarrays. It includes a partial supervision to smoothly favor the selection of some dimensions (genes) on a new dataset to be classified. The dimensions to be favored are previously selected from similar datasets in large microarray databases, hence performing inductive transfer learning at the feature level. This technique relies on a feature selection method embedded within a regularized linear model estimation. A practical approximation of this technique reduces to linear SVM learning with iterative input rescaling. The scaling factors depend on the selected dimensions from the related datasets. The final selection may depart from those whenever necessary to optimize the classification objective. Experiments on several microarray datasets show that the proposed method both improves the selected gene lists stability, with respect to sampling variation, as well as the classification performances.",
isbn="978-3-642-04180-8"
}

@InProceedings{Zhang_2019_CVPR,
author = {Zhang, Zhenyu and Cui, Zhen and Xu, Chunyan and Yan, Yan and Sebe, Nicu and Yang, Jian},
title = {Pattern-Affinitive Propagation Across Depth, Surface Normal and Semantic Segmentation},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}

@article{silver2008guest,
	title={Guest editor‚Äôs introduction: special issue on inductive transfer learning},
	author={Silver, Daniel L and Bennett, Kristin P},
	journal={Machine Learning},
	volume={73},
	number={3},
	pages={215--220},
	year={2008},
	publisher={Springer}
}


@inproceedings{DBLP:conf/cvpr/Kokkinos17,
  author    = {Iasonas Kokkinos},
  title     = {UberNet: Training a Universal Convolutional Neural Network for Low-,
               Mid-, and High-Level Vision Using Diverse Datasets and Limited Memory},
  booktitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2017, Honolulu, HI, USA, July 21-26, 2017},
  pages     = {5454--5463},
  year      = {2017},
  url       = {https://doi.org/10.1109/CVPR.2017.579},
  doi       = {10.1109/CVPR.2017.579},
  timestamp = {Tue, 14 Nov 2017 17:15:06 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/cvpr/Kokkinos17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/Ruder17a,
  author    = {Sebastian Ruder},
  title     = {An Overview of Multi-Task Learning in Deep Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1706.05098},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.05098},
  archivePrefix = {arXiv},
  eprint    = {1706.05098},
  timestamp = {Mon, 03 Jul 2017 13:29:02 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/Ruder17a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Tessler:2017:DHA:3298239.3298465,
 author = {Tessler, Chen and Givony, Shahar and Zahavy, Tom and Mankowitz, Daniel J. and Mannor, Shie},
 title = {A Deep Hierarchical Approach to Lifelong Learning in Minecraft},
 booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
 series = {AAAI'17},
 year = {2017},
 location = {San Francisco, California, USA},
 pages = {1553--1561},
 numpages = {9},
 url = {http://dl.acm.org.stanford.idm.oclc.org/citation.cfm?id=3298239.3298465},
 acmid = {3298465},
 publisher = {AAAI Press},
} 

@article{Dai2016InstanceAwareSS,
  title={Instance-Aware Semantic Segmentation via Multi-task Network Cascades},
  author={Jifeng Dai and Kaiming He and Jian Sun},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={3150-3158}
}


@inproceedings{doersch2017multitask,
  title = {Multi-task Self-Supervised Visual Learning},
  author = {Doersch, Carl and Zisserman, Andrew},
  booktitle = {International Conference on Computer Vision},
  year = {2017},
}

@inproceedings{DBLP:conf/eccv/RuddGB16,
  author    = {Ethan M. Rudd and
               Manuel G{\"{u}}nther and
               Terrance E. Boult},
  title     = {{MOON:} {A} Mixed Objective Optimization Network for the Recognition
               of Facial Attributes},
  booktitle = {{ECCV} {(5)}},
  series    = {Lecture Notes in Computer Science},
  volume    = {9909},
  pages     = {19--35},
  publisher = {Springer},
  year      = {2016}
}

@incollection{NIPS1992_641,
title = {Discriminability-Based Transfer between Neural Networks},
author = {Pratt, L. Y.},
booktitle = {Advances in Neural Information Processing Systems 5},
editor = {S. J. Hanson and J. D. Cowan and C. L. Giles},
pages = {204--211},
year = {1993},
publisher = {Morgan-Kaufmann},
_url = {http://papers.nips.cc/paper/641-discriminability-based-transfer-between-neural-networks.pdf}
}

@article{zamir2020consistency,
  title={Robust Learning Through Cross-Task Consistency},
  author={Zamir, Amir and Sax, Alexander and Yeo, Teresa and Kar, Oƒüuzhan and Cheerla, Nikhil and Suri, Rohan and Cao, Zhangjie and Malik, Jitendra and Guibas, Leonidas},
  journal={arXiv},
  year={2020}
}

@inproceedings{36ebd0a9d3dd43f8bb0dbce896aa3c46,
  title     = "Trace Norm Regularised Deep Multi-Task Learning",
  abstract  = "We propose a framework for training multiple neural networks simultaneously. The parameters from all models are regularised by the tensor trace norm, so that each neural network is encouraged to reuse others' parameters if possible -- this is the main motivation behind multi-task learning. In contrast to many deep multi-task learning models, we do not predefine a parameter sharing strategy by specifying which layers have tied parameters. Instead, our framework considers sharing for all shareable layers, and the sharing strategy is learned in a data-driven way.",
  author    = "Yongxin Yang and Timothy Hospedales",
  year      = "2017",
  language  = "English",
  booktitle = "5th International Conference on Learning Representations Workshop",
}

@INPROCEEDINGS{7410535, 
author={H. {Noh} and S. {Hong} and B. {Han}}, 
booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
title={Learning Deconvolution Network for Semantic Segmentation}, 
year={2015}, 
volume={}, 
number={}, 
pages={1520-1528}, 
keywords={convolution;deconvolution;image segmentation;learning (artificial intelligence);neural nets;prediction theory;semantic networks;deconvolution network learning;semantic segmentation algorithm;convolutional neural network;CNN;proposal-wise prediction;Deconvolution;Semantics;Image segmentation;Visualization;Feature extraction;Shape;Image reconstruction}, 
doi={10.1109/ICCV.2015.178}, 
ISSN={2380-7504}, 
month={Dec},}

@InProceedings{Qi_2018_CVPR,
author = {Qi, Xiaojuan and Liao, Renjie and Liu, Zhengzhe and Urtasun, Raquel and Jia, Jiaya},
title = {GeoNet: Geometric Neural Network for Joint Depth and Surface Normal Estimation},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@inproceedings{DBLP:conf/eccv/ChenZPSA18,
  author    = {Liang{-}Chieh Chen and
               Yukun Zhu and
               George Papandreou and
               Florian Schroff and
               Hartwig Adam},
  title     = {Encoder-Decoder with Atrous Separable Convolution for Semantic Image
               Segmentation},
  booktitle = {Computer Vision - {ECCV} 2018 - 15th European Conference, Munich,
               Germany, September 8-14, 2018, Proceedings, Part {VII}},
  pages     = {833--851},
  year      = {2018},
  url       = {https://doi.org/10.1007/978-3-030-01234-2\_49},
  doi       = {10.1007/978-3-030-01234-2\_49},
  timestamp = {Mon, 08 Oct 2018 17:08:05 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/eccv/ChenZPSA18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{10.1007/978-3-319-46487-9_33,
author="Zamir, Amir R.
and Wekel, Tilman
and Agrawal, Pulkit
and Wei, Colin
and Malik, Jitendra
and Savarese, Silvio",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="Generic 3D Representation via Pose Estimation and Matching",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="535--553",
abstract="Though a large body of computer vision research has investigated developing generic semantic representations, efforts towards developing a similar representation for 3D has been limited. In this paper, we learn a generic 3D representation through solving a set of foundational proxy 3D tasks: object-centric camera pose estimation and wide baseline feature matching. Our method is based upon the premise that by providing supervision over a set of carefully selected foundational tasks, generalization to novel tasks and abstraction capabilities can be achieved. We empirically show that the internal representation of a multi-task ConvNet trained to solve the above core problems generalizes to novel 3D tasks (e.g., scene layout estimation, object pose estimation, surface normal estimation) without the need for fine-tuning and shows traits of abstraction abilities (e.g., cross modality pose estimation).",
isbn="978-3-319-46487-9"
}

@incollection{NIPS2016_6502,
title = {SURGE: Surface Regularized Geometry Estimation from a Single Image},
author = {Wang, Peng and Shen, Xiaohui and Russell, Bryan and Cohen, Scott and Price, Brian and Yuille, Alan L},
booktitle = {Advances in Neural Information Processing Systems 29},
editor = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},
pages = {172--180},
year = {2016},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/6502-surge-surface-regularized-geometry-estimation-from-a-single-image.pdf}
}

@InProceedings{pmlr-v70-pentina17a,
  title = 	 {Multi-task Learning with Labeled and Unlabeled Tasks},
  author = 	 {Anastasia Pentina and Christoph H. Lampert},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {2807--2816},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/pentina17a/pentina17a.pdf},
  url = 	 {http://proceedings.mlr.press/v70/pentina17a.html},
  abstract = 	 {In multi-task learning, a learner is given a collection of prediction tasks and needs to solve all of them. In contrast to previous work, which required that annotated training data must be available for all tasks, we consider a new setting, in which for some tasks, potentially most of them, only unlabeled training data is provided. Consequently, to solve all tasks, information must be transferred between tasks with labels and tasks without labels. Focusing on an instance-based transfer method we analyze two variants of this setting: when the set of labeled tasks is fixed, and when it can be actively selected by the learner. We state and prove a generalization bound that covers both scenarios and derive from it an algorithm for making the choice of labeled tasks (in the active case) and for transferring information between the tasks in a principled way. We also illustrate the effectiveness of the algorithm on synthetic and real data.}
}


@inproceedings{DBLP:conf/icpr/RenYZH14,
  author    = {Weiqiang Ren and
               Yinan Yu and
               Junge Zhang and
               Kaiqi Huang},
  title     = {Learning Convolutional Nonlinear Features for {K} Nearest Neighbor
               Image Classification},
  booktitle = {22nd International Conference on Pattern Recognition, {ICPR} 2014,
               Stockholm, Sweden, August 24-28, 2014},
  pages     = {4358--4363},
  year      = {2014},
  crossref  = {DBLP:conf/icpr/2014},
  url       = {https://doi.org/10.1109/ICPR.2014.746},
  doi       = {10.1109/ICPR.2014.746},
  timestamp = {Wed, 24 May 2017 08:30:38 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/icpr/RenYZH14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  pages={248--255},
  year={2009}
}

@article{DBLP:journals/corr/LinMBHPRDZ14,
  author    = {Tsung{-}Yi Lin and
               Michael Maire and
               Serge J. Belongie and
               Lubomir D. Bourdev and
               Ross B. Girshick and
               James Hays and
               Pietro Perona and
               Deva Ramanan and
               Piotr Doll{\'{a}}r and
               C. Lawrence Zitnick},
  title     = {Microsoft {COCO:} Common Objects in Context},
  journal   = {CoRR},
  volume    = {abs/1405.0312},
  year      = {2014}
}

@misc{pascal-voc-2012,
	author = "Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.",
	title = "The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2012 {(VOC2012)} {R}esults",
	howpublished = "http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html"}
	
@InProceedings{BharathICCV2011,
author = "Bharath Hariharan and Pablo Arbelaez and Lubomir Bourdev and Subhransu Maji and Jitendra Malik",
title = "Semantic Contours from Inverse Detectors",
booktitle = "International Conference on Computer Vision (ICCV)",
year = "2011",
}

@ARTICLE{2017arXiv170201105A,
   author = {{Armeni}, I. and {Sax}, A. and {Zamir}, A.~R. and {Savarese}, S.
	},
    title = "{Joint 2D-3D-Semantic Data for Indoor Scene Understanding}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1702.01105},
 primaryClass = "cs.CV",
 keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
     year = 2017,
    month = feb,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170201105A},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{Misra2016CrossStitchNF,
  title={Cross-Stitch Networks for Multi-task Learning},
  author={Ishan Misra and Abhinav Shrivastava and Abhinav Gupta and Martial Hebert},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={3994-4003}
}

@incollection{NIPS2016_6393,
title = {Integrated perception with recurrent multi-task neural networks},
author = {Bilen, Hakan and Vedaldi, Andrea},
booktitle = {Advances in Neural Information Processing Systems 29},
editor = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},
pages = {235--243},
year = {2016},
publisher = {Curran Associates, Inc.},
_url = {http://papers.nips.cc/paper/6393-integrated-perception-with-recurrent-multi-task-neural-networks.pdf}
}

@InProceedings{duong-EtAl:2015:ACL-IJCNLP,
  author    = {Duong, Long  and  Cohn, Trevor  and  Bird, Steven  and  Cook, Paul},
  title     = {Low Resource Dependency Parsing: Cross-lingual Parameter Sharing in a Neural Network Parser},
  booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  month     = {July},
  year      = {2015},
  pages     = {845--850},
}


@inproceedings{Silberman:ECCV12,
  author    = {Nathan Silberman, Derek Hoiem, Pushmeet Kohli and Rob Fergus},
  title     = {Indoor Segmentation and Support Inference from RGBD Images},
  booktitle = {ECCV},
  year      = {2012}
}

@article{Chollet16a,
  author    = {Fran{\c{c}}ois Chollet},
  title     = {Xception: Deep Learning with Depthwise Separable Convolutions},
  journal   = {CoRR},
  volume    = {abs/1610.02357},
  year      = {2016},
  timestamp = {Wed, 07 Jun 2017 14:41:03 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/Chollet16a},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@InProceedings{RFB15a,
  author       = "O. Ronneberger and P.Fischer and T. Brox",
  title        = "U-Net: Convolutional Networks for Biomedical Image Segmentation",
  booktitle    = "Medical Image Computing and Computer-Assisted Intervention (MICCAI)",
  series       = "LNCS",
  volume       = "9351",
  pages        = "234--241",
  year         = "2015",
  publisher    = "Springer",
  note         = "(available on arXiv:1505.04597 [cs.CV])",
  url          = "http://lmb.informatik.uni-freiburg.de/Publications/2015/RFB15a"
}

@article{DBLP:journals/corr/abs-1809-04766,
  author    = {Vladimir Nekrasov and
               Thanuja Dharmasiri and
               Andrew Spek and
               Tom Drummond and
               Chunhua Shen and
               Ian D. Reid},
  title     = {Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric
               Annotations},
  journal   = {CoRR},
  volume    = {abs/1809.04766},
  year      = {2018},
  url       = {http://arxiv.org/abs/1809.04766},
  archivePrefix = {arXiv},
  eprint    = {1809.04766},
  timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1809-04766},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{dvornik2017blitznet,
  title = {{BlitzNet}: A Real-Time Deep Network for Scene Understanding},
  author = {Dvornik, Nikita and Shmelkov, Konstantin and Mairal, Julien and Schmid, Cordelia},
  booktitle = {{IEEE International Conference on Computer Vision (ICCV)}},
  year = {2017}
}

@incollection{NeurIPS2018_Sener_Koltun,
title = {Multi-Task Learning as Multi-Objective Optimization},
author = {Sener, Ozan and Koltun, Vladlen},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {525--536},
year = {2018},
publisher = {Curran Associates, Inc.},
_url = {http://papers.nips.cc/paper/7334-multi-task-learning-as-multi-objective-optimization.pdf}
}


@inproceedings{DBLP:conf/icml/ChenBLR18,
  author    = {Zhao Chen and
               Vijay Badrinarayanan and
               Chen{-}Yu Lee and
               Andrew Rabinovich},
  title     = {GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep
               Multitask Networks},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning,
               {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July
               10-15, 2018},
  pages     = {793--802},
  year      = {2018},
  url       = {http://proceedings.mlr.press/v80/chen18a.html},
  timestamp = {Fri, 13 Jul 2018 14:57:00 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/icml/ChenBLR18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{chollet2017xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Fran{\c{c}}ois},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1251--1258},
  year={2017}
}

@inproceedings{paszke2017automatic,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  booktitle={NIPS-W},
  year={2017}
}

@article{micikevicius2017mixed,
  title={Mixed precision training},
  author={Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and others},
  journal={arXiv preprint arXiv:1710.03740},
  year={2017}
}

@article{DBLP:journals/corr/abs-1801-06519,
  author    = {Arun Mallya and
               Svetlana Lazebnik},
  title     = {Piggyback: Adding Multiple Tasks to a Single, Fixed Network by Learning
               to Mask},
  journal   = {CoRR},
  volume    = {abs/1801.06519},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.06519},
  archivePrefix = {arXiv},
  eprint    = {1801.06519},
  timestamp = {Mon, 13 Aug 2018 16:48:40 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-06519},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/FernandoBBZHRPW17,
  author    = {Chrisantha Fernando and
               Dylan Banarse and
               Charles Blundell and
               Yori Zwols and
               David Ha and
               Andrei A. Rusu and
               Alexander Pritzel and
               Daan Wierstra},
  title     = {PathNet: Evolution Channels Gradient Descent in Super Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1701.08734},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.08734},
  archivePrefix = {arXiv},
  eprint    = {1701.08734},
  timestamp = {Mon, 13 Aug 2018 16:49:06 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/FernandoBBZHRPW17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{10.5555/3122009.3242042,
author = {Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
title = {Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization},
year = {2017},
issue_date = {January 2017},
publisher = {JMLR.org},
volume = {18},
number = {1},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {6765‚Äì6816},
numpages = {52},
keywords = {deep learning, model selection, online optimization, hyperparameter optimization, infinite-armed bandits}
}


@inproceedings{10.5555/2832581.2832731,
author = {Domhan, Tobias and Springenberg, Jost Tobias and Hutter, Frank},
title = {Speeding up Automatic Hyperparameter Optimization of Deep Neural Networks by Extrapolation of Learning Curves},
year = {2015},
isbn = {9781577357384},
publisher = {AAAI Press},
booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
pages = {3460‚Äì3468},
numpages = {9},
location = {Buenos Aires, Argentina},
series = {IJCAI‚Äô15}
}


@inproceedings{ge2017optimization,
  title={On the optimization landscape of tensor decompositions},
  author={Ge, Rong and Ma, Tengyu},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3653--3663},
  year={2017}
}



@inproceedings{kendall2017multi,
  title={Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics},
  author={Kendall, Alex and Gal, Yarin and Cipolla, Roberto},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition ({CVPR})},
  year={2018}
}