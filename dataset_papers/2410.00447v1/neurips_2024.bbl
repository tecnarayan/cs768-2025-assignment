\begin{thebibliography}{53}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 33:\penalty0 6840--6851, 2020.

\bibitem[Dhariwal and Nichol(2021)]{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 34:\penalty0 8780--8794, 2021.

\bibitem[Betker et~al.(2023)Betker, Goh, Jing, Brooks, Wang, Li, Ouyang, Zhuang, Lee, Guo, et~al.]{betker2023improving}
James Betker, Gabriel Goh, Li~Jing, Tim Brooks, Jianfeng Wang, Linjie Li, Long Ouyang, Juntang Zhuang, Joyce Lee, Yufei Guo, et~al.
\newblock Improving image generation with better captions.
\newblock \emph{Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf}, 2:\penalty0 8, 2023.

\bibitem[Nichol et~al.(2021)Nichol, Dhariwal, Ramesh, Shyam, Mishkin, McGrew, Sutskever, and Chen]{nichol2021glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen.
\newblock Glide: Towards photorealistic image generation and editing with text-guided diffusion models.
\newblock \emph{arXiv preprint arXiv:2112.10741}, 2021.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 2022.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{Proceedings of the International Conference on Machine Learning (ICML)}, pages 8748--8763, 2021.

\bibitem[Li et~al.(2022)Li, Li, Xiong, and Hoi]{li2022blip}
Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi.
\newblock Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation.
\newblock In \emph{Proceedings of the International Conference on Machine Learning (ICML)}, pages 12888--12900, 2022.

\bibitem[Li et~al.(2023{\natexlab{a}})Li, Li, Savarese, and Hoi]{li2023blip2}
Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.
\newblock Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models.
\newblock In \emph{Proceedings of the International Conference on Machine Learning (ICML)}, pages 19730--19742, 2023{\natexlab{a}}.

\bibitem[Zheng et~al.(2024)Zheng, Zhang, Wu, Lu, Ma, Jin, Chen, and Shen]{zheng2024dreamlip}
Kecheng Zheng, Yifei Zhang, Wei Wu, Fan Lu, Shuailei Ma, Xin Jin, Wei Chen, and Yujun Shen.
\newblock Dreamlip: Language-image pre-training with long captions.
\newblock \emph{arXiv preprint arXiv:2403.17007}, 2024.

\bibitem[Zheng et~al.(2023)Zheng, Zhou, Li, Qi, Shan, and Li]{zheng2023layoutdiffusion}
Guangcong Zheng, Xianpan Zhou, Xuewei Li, Zhongang Qi, Ying Shan, and Xi~Li.
\newblock Layoutdiffusion: Controllable diffusion model for layout-to-image generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 22490--22499, 2023.

\bibitem[Cheng et~al.(2023)Cheng, Liang, Shi, He, Xiao, and Li]{cheng2023layoutdiffuse}
Jiaxin Cheng, Xiao Liang, Xingjian Shi, Tong He, Tianjun Xiao, and Mu~Li.
\newblock Layoutdiffuse: Adapting foundational diffusion models for layout-to-image generation.
\newblock \emph{arXiv preprint arXiv:2302.08908}, 2023.

\bibitem[Li et~al.(2023{\natexlab{b}})Li, Liu, Wu, Mu, Yang, Gao, Li, and Lee]{li2023gligen}
Yuheng Li, Haotian Liu, Qingyang Wu, Fangzhou Mu, Jianwei Yang, Jianfeng Gao, Chunyuan Li, and Yong~Jae Lee.
\newblock Gligen: Open-set grounded text-to-image generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 22511--22521, 2023{\natexlab{b}}.

\bibitem[Zhou et~al.(2024)Zhou, Li, Ma, Yang, and Yang]{zhou2024migc}
Dewei Zhou, You Li, Fan Ma, Zongxin Yang, and Yi~Yang.
\newblock Migc: Multi-instance generation controller for text-to-image synthesis.
\newblock \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2024.

\bibitem[Liu and Liu(2024)]{liu2024r3cd}
Jinxiu Liu and Qi~Liu.
\newblock R3cd: Scene graph to image generation with relation-aware compositional contrastive control diffusion.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)}, volume~38, pages 3657--3665, 2024.

\bibitem[Farshad et~al.(2023)Farshad, Yeganeh, Chi, Shen, Ommer, and Navab]{farshad2023scenegenie}
Azade Farshad, Yousef Yeganeh, Yu~Chi, Chengzhi Shen, B{\"o}jrn Ommer, and Nassir Navab.
\newblock Scenegenie: Scene graph guided diffusion models for image synthesis.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pages 88--98, 2023.

\bibitem[Yang et~al.(2022)Yang, Huang, Song, Hong, Li, Zhang, Cui, Ghanem, and Yang]{yang2022diffusion}
Ling Yang, Zhilin Huang, Yang Song, Shenda Hong, Guohao Li, Wentao Zhang, Bin Cui, Bernard Ghanem, and Ming-Hsuan Yang.
\newblock Diffusion-based scene graph to image generation with masked contrastive pre-training.
\newblock \emph{arXiv preprint arXiv:2211.11138}, 2022.

\bibitem[Johnson et~al.(2018)Johnson, Gupta, and Fei-Fei]{johnson2018image}
Justin Johnson, Agrim Gupta, and Li~Fei-Fei.
\newblock Image generation from scene graphs.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 1219--1228, 2018.

\bibitem[Ashual and Wolf(2019)]{ashual2019specifying}
Oron Ashual and Lior Wolf.
\newblock Specifying object attributes and relations in interactive scene generation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pages 4561--4569, 2019.

\bibitem[Herzig et~al.(2020)Herzig, Bar, Xu, Chechik, Darrell, and Globerson]{herzig2020learning}
Roei Herzig, Amir Bar, Huijuan Xu, Gal Chechik, Trevor Darrell, and Amir Globerson.
\newblock Learning canonical representations for scene graph to image generation.
\newblock In \emph{Proceedings of the European Conference on Computer Vision (ECCV)}, pages 210--227. Springer, 2020.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 10684--10695, 2022.

\bibitem[Liu et~al.(2022{\natexlab{a}})Liu, Ren, Lin, and Zhao]{liu2022pseudo}
Luping Liu, Yi~Ren, Zhijie Lin, and Zhou Zhao.
\newblock Pseudo numerical methods for diffusion models on manifolds.
\newblock \emph{arXiv preprint arXiv:2202.09778}, 2022{\natexlab{a}}.

\bibitem[Luo et~al.(2020)Luo, Zhang, Wu, and Tenenbaum]{luo2020end}
Andrew Luo, Zhoutong Zhang, Jiajun Wu, and Joshua~B Tenenbaum.
\newblock End-to-end optimization of scene layout.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 3754--3763, 2020.

\bibitem[Tancik et~al.(2020)Tancik, Srinivasan, Mildenhall, Fridovich-Keil, Raghavan, Singhal, Ramamoorthi, Barron, and Ng]{tancik2020fourier}
Matthew Tancik, Pratul Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan Barron, and Ren Ng.
\newblock Fourier features let networks learn high frequency functions in low dimensional domains.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 33:\penalty0 7537--7547, 2020.

\bibitem[Voynov et~al.(2023)Voynov, Chu, Cohen-Or, and Aberman]{voynov2023p+}
Andrey Voynov, Qinghao Chu, Daniel Cohen-Or, and Kfir Aberman.
\newblock $ p+ $: Extended textual conditioning in text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2303.09522}, 2023.

\bibitem[Ren et~al.(2024)Ren, Xu, Wu, Liu, Xiang, and Toisoul]{ren2024move}
Jiawei Ren, Mengmeng Xu, Jui-Chieh Wu, Ziwei Liu, Tao Xiang, and Antoine Toisoul.
\newblock Move anything with layered scene diffusion.
\newblock \emph{arXiv preprint arXiv:2404.07178}, 2024.

\bibitem[Caesar et~al.(2018)Caesar, Uijlings, and Ferrari]{caesar2018coco}
Holger Caesar, Jasper Uijlings, and Vittorio Ferrari.
\newblock Coco-stuff: Thing and stuff classes in context.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 1209--1218, 2018.

\bibitem[Krishna et~al.(2017)Krishna, Zhu, Groth, Johnson, Hata, Kravitz, Chen, Kalantidis, Li, Shamma, et~al.]{krishna2017visual}
Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David~A Shamma, et~al.
\newblock Visual genome: Connecting language and vision using crowdsourced dense image annotations.
\newblock \emph{International Journal of Computer Vision (IJCV)}, 123:\penalty0 32--73, 2017.

\bibitem[Li et~al.(2019)Li, Ma, Bai, Duan, Wei, and Wang]{li2019pastegan}
Yikang Li, Tao Ma, Yeqi Bai, Nan Duan, Sining Wei, and Xiaogang Wang.
\newblock Pastegan: A semi-parametric method to generate image from scene graph.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 32, 2019.

\bibitem[Wu et~al.(2023)Wu, Wei, and Lin]{wu2023scene}
Yang Wu, Pengxu Wei, and Liang Lin.
\newblock Scene graph to image synthesis via knowledge consensus.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)}, volume~37, pages 2856--2865, 2023.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Ho and Salimans(2022)]{ho2022classifier}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock \emph{arXiv preprint arXiv:2207.12598}, 2022.

\bibitem[Salimans et~al.(2016)Salimans, Goodfellow, Zaremba, Cheung, Radford, and Chen]{salimans2016improved}
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi~Chen.
\newblock Improved techniques for training gans.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 29, 2016.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and Hochreiter]{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash equilibrium.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 30, 2017.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and Wojna]{szegedy2016rethinking}
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 2818--2826, 2016.

\bibitem[Huang et~al.(2023{\natexlab{a}})Huang, Sun, Xie, Li, and Liu]{huang2023t2i}
Kaiyi Huang, Kaiyue Sun, Enze Xie, Zhenguo Li, and Xihui Liu.
\newblock T2i-compbench: A comprehensive benchmark for open-world compositional text-to-image generation.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 36:\penalty0 78723--78747, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2022{\natexlab{b}})Liu, Li, Du, Torralba, and Tenenbaum]{liu2022compositional}
Nan Liu, Shuang Li, Yilun Du, Antonio Torralba, and Joshua~B Tenenbaum.
\newblock Compositional visual generation with composable diffusion models.
\newblock In \emph{Proceedings of the European Conference on Computer Vision (ECCV)}, pages 423--439. Springer, 2022{\natexlab{b}}.

\bibitem[Feng et~al.(2022)Feng, He, Fu, Jampani, Akula, Narayana, Basu, Wang, and Wang]{feng2022training}
Weixi Feng, Xuehai He, Tsu-Jui Fu, Varun Jampani, Arjun Akula, Pradyumna Narayana, Sugato Basu, Xin~Eric Wang, and William~Yang Wang.
\newblock Training-free structured diffusion guidance for compositional text-to-image synthesis.
\newblock \emph{arXiv preprint arXiv:2212.05032}, 2022.

\bibitem[Chefer et~al.(2023)Chefer, Alaluf, Vinker, Wolf, and Cohen-Or]{chefer2023attend}
Hila Chefer, Yuval Alaluf, Yael Vinker, Lior Wolf, and Daniel Cohen-Or.
\newblock Attend-and-excite: Attention-based semantic guidance for text-to-image diffusion models.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 42\penalty0 (4):\penalty0 1--10, 2023.

\bibitem[Zhou et~al.(2022)Zhou, Koltun, and Kr{\"a}henb{\"u}hl]{zhou2022simple}
Xingyi Zhou, Vladlen Koltun, and Philipp Kr{\"a}henb{\"u}hl.
\newblock Simple multi-dataset detection.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 7571--7580, 2022.

\bibitem[Podell et~al.(2023)Podell, English, Lacey, Blattmann, Dockhorn, M{\"u}ller, Penna, and Rombach]{podell2023sdxl}
Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas M{\"u}ller, Joe Penna, and Robin Rombach.
\newblock Sdxl: Improving latent diffusion models for high-resolution image synthesis.
\newblock \emph{arXiv preprint arXiv:2307.01952}, 2023.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton, Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans, et~al.]{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 35:\penalty0 36479--36494, 2022.

\bibitem[Song et~al.(2020)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and Poole]{song2020score}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock \emph{arXiv preprint arXiv:2011.13456}, 2020.

\bibitem[Kingma and Welling(2013)]{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Sohn et~al.(2015)Sohn, Lee, and Yan]{sohn2015learning}
Kihyuk Sohn, Honglak Lee, and Xinchen Yan.
\newblock Learning structured output representation using deep conditional generative models.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 28, 2015.

\bibitem[Goodfellow et~al.(2020)Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2020generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial networks.
\newblock \emph{Communications of the ACM}, 63\penalty0 (11):\penalty0 139--144, 2020.

\bibitem[Zhang et~al.(2023)Zhang, Rao, and Agrawala]{zhang2023adding}
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pages 3836--3847, 2023.

\bibitem[Wang et~al.(2024{\natexlab{a}})Wang, Frisvad, Jensen, and Bigdeli]{wang2024stereodiffusion}
Lezhong Wang, Jeppe~Revall Frisvad, Mark~Bo Jensen, and Siavash~Arjomand Bigdeli.
\newblock Stereodiffusion: Training-free stereo image generation using latent diffusion models.
\newblock \emph{arXiv preprint arXiv:2403.04965}, 2024{\natexlab{a}}.

\bibitem[Huang et~al.(2023{\natexlab{b}})Huang, Chan, Jiang, and Liu]{huang2023collaborative}
Ziqi Huang, Kelvin~CK Chan, Yuming Jiang, and Ziwei Liu.
\newblock Collaborative diffusion for multi-modal face generation and editing.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 6080--6090, 2023{\natexlab{b}}.

\bibitem[Johnson et~al.(2015)Johnson, Krishna, Stark, Li, Shamma, Bernstein, and Fei-Fei]{johnson2015image}
Justin Johnson, Ranjay Krishna, Michael Stark, Li-Jia Li, David Shamma, Michael Bernstein, and Li~Fei-Fei.
\newblock Image retrieval using scene graphs.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 3668--3678, 2015.

\bibitem[Tripathi et~al.(2019)Tripathi, Bhiwandiwalla, Bastidas, and Tang]{tripathi2019using}
Subarna Tripathi, Anahita Bhiwandiwalla, Alexei Bastidas, and Hanlin Tang.
\newblock Using scene graph context to improve image generation.
\newblock \emph{arXiv preprint arXiv:1901.03762}, 2019.

\bibitem[Du et~al.(2023)Du, Durkan, Strudel, Tenenbaum, Dieleman, Fergus, Sohl-Dickstein, Doucet, and Grathwohl]{du2023reduce}
Yilun Du, Conor Durkan, Robin Strudel, Joshua~B Tenenbaum, Sander Dieleman, Rob Fergus, Jascha Sohl-Dickstein, Arnaud Doucet, and Will~Sussman Grathwohl.
\newblock Reduce, reuse, recycle: Compositional generation with energy-based diffusion models and mcmc.
\newblock In \emph{Proceedings of the International Conference on Machine Learning (ICML)}, pages 8489--8510, 2023.

\bibitem[Li et~al.(2023{\natexlab{c}})Li, Li, Yang, Wei, Jiang, and Bai]{li2023swinv2}
Ruijun Li, Weihua Li, Yi~Yang, Hanyu Wei, Jianhua Jiang, and Quan Bai.
\newblock Swinv2-imagen: Hierarchical vision transformer diffusion models for text-to-image generation.
\newblock \emph{Neural Computing and Applications}, pages 1--16, 2023{\natexlab{c}}.

\bibitem[Wang et~al.(2024{\natexlab{b}})Wang, Chen, Chen, Ma, Lu, and Lin]{wang2024compositional}
Ruichen Wang, Zekang Chen, Chen Chen, Jian Ma, Haonan Lu, and Xiaodong Lin.
\newblock Compositional text-to-image synthesis with attention map control of diffusion models.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)}, volume~38, pages 5544--5552, 2024{\natexlab{b}}.

\end{thebibliography}
