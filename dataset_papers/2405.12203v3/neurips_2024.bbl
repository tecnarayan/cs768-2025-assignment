\begin{thebibliography}{34}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ball{\'e} et~al.(2017)Ball{\'e}, Laparra, and Simoncelli]{balle2017end}
J.~Ball{\'e}, V.~Laparra, and E.~P. Simoncelli.
\newblock End-to-end optimized image compression.
\newblock In \emph{5th International Conference on Learning Representations, ICLR 2017}, 2017.

\bibitem[Ball{\'e} et~al.(2018)Ball{\'e}, Minnen, Singh, Hwang, and Johnston]{balle2018variational}
J.~Ball{\'e}, D.~Minnen, S.~Singh, S.~J. Hwang, and N.~Johnston.
\newblock Variational image compression with a scale hyperprior.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Ballé et~al.(2020)Ballé, Chou, Minnen, Singh, Johnston, Agustsson, Hwang, and Toderici]{ballé2020nonlinear}
J.~Ballé, P.~A. Chou, D.~Minnen, S.~Singh, N.~Johnston, E.~Agustsson, S.~J. Hwang, and G.~Toderici.
\newblock Nonlinear transform coding, 2020.

\bibitem[Bellard(2014)]{bpg}
F.~Bellard.
\newblock {BPG} image format.
\newblock \url{https://bellard.org/bpg/}, 2014.
\newblock Accessed: 2023-09-27.

\bibitem[Blau and Michaeli(2018)]{blau2018perception}
Y.~Blau and T.~Michaeli.
\newblock The perception-distortion tradeoff.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 6228--6237, 2018.

\bibitem[Chatterjee and Diaconis(2018)]{chatterjee2018sample}
S.~Chatterjee and P.~Diaconis.
\newblock The sample size required in importance sampling.
\newblock \emph{The Annals of Applied Probability}, 28\penalty0 (2):\penalty0 1099--1135, 2018.

\bibitem[Cheng et~al.(2020)Cheng, Sun, Takeuchi, and Katto]{cheng2020learned}
Z.~Cheng, H.~Sun, M.~Takeuchi, and J.~Katto.
\newblock Learned image compression with discretized gaussian mixture likelihoods and attention modules.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 7939--7948, 2020.

\bibitem[Dupont et~al.(2022)Dupont, Loya, Alizadeh, Goliński, Teh, and Doucet]{dupont2022coin}
E.~Dupont, H.~Loya, M.~Alizadeh, A.~Goliński, Y.~W. Teh, and A.~Doucet.
\newblock Coin++: Neural compression across modalities, 2022.

\bibitem[Flamich(2024)]{flamich2024greedy}
G.~Flamich.
\newblock Greedy poisson rejection sampling.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Flamich and Theis(2023)]{flamich2023adaptive}
G.~Flamich and L.~Theis.
\newblock Adaptive greedy rejection sampling.
\newblock In \emph{2023 IEEE International Symposium on Information Theory (ISIT)}, pages 454--459. IEEE, 2023.

\bibitem[Flamich and Wells(2024)]{flamich2024some}
G.~Flamich and L.~Wells.
\newblock Some notes on the sample complexity of approximate channel simulation.
\newblock In \emph{First 'Learn to Compress' Workshop@ ISIT 2024}, 2024.

\bibitem[Flamich et~al.(2020)Flamich, Havasi, and Hern{\'a}ndez-Lobato]{flamich2020compressing}
G.~Flamich, M.~Havasi, and J.~M. Hern{\'a}ndez-Lobato.
\newblock Compressing images by encoding their latent representations with relative entropy coding.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 16131--16141, 2020.

\bibitem[Flamich et~al.(2022)Flamich, Markou, and Hern{\'a}ndez-Lobato]{flamich2022fast}
G.~Flamich, S.~Markou, and J.~M. Hern{\'a}ndez-Lobato.
\newblock Fast relative entropy coding with a* coding.
\newblock In \emph{International Conference on Machine Learning}, pages 6548--6577. PMLR, 2022.

\bibitem[Flamich et~al.(2024)Flamich, Markou, and Hern{\'a}ndez-Lobato]{flamich2024faster}
G.~Flamich, S.~Markou, and J.~M. Hern{\'a}ndez-Lobato.
\newblock Faster relative entropy coding with greedy rejection coding.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Guo et~al.(2024)Guo, Flamich, He, Chen, and Hern{\'a}ndez-Lobato]{guo2024compression}
Z.~Guo, G.~Flamich, J.~He, Z.~Chen, and J.~M. Hern{\'a}ndez-Lobato.
\newblock Compression with bayesian implicit neural representations.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Havasi et~al.(2019)Havasi, Peharz, and Hern{\'a}ndez-Lobato]{havasi2019minimal}
M.~Havasi, R.~Peharz, and J.~M. Hern{\'a}ndez-Lobato.
\newblock Minimal random code learning: Getting bits back from compressed model parameters.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[He et~al.(2023)He, Flamich, Guo, and Hern{\'a}ndez-Lobato]{he2023recombiner}
J.~He, G.~Flamich, Z.~Guo, and J.~M. Hern{\'a}ndez-Lobato.
\newblock Recombiner: Robust and enhanced compression with bayesian implicit neural representations.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2023.

\bibitem[{JVET}(2020)]{VTM}
{JVET}.
\newblock {VVC} offical test model.
\newblock \url{https://jvet.hhi.fraunhofer.de}, 2020.
\newblock Accessed: 2024-03-05.

\bibitem[Kingma and Ba(2017)]{kingma2017adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization, 2017.

\bibitem[Kingma and Welling(2013)]{kingma2013auto}
D.~P. Kingma and M.~Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton, et~al.]{Krizhevsky2009LearningML}
A.~Krizhevsky, G.~Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.(2009), 2009.

\bibitem[LeCun and Cortes(1998)]{LeCun2005TheMD}
Y.~LeCun and C.~Cortes.
\newblock The mnist database of handwritten digits.
\newblock 1998.
\newblock URL \url{http://yann.lecun.com/exdb/mnist/}.

\bibitem[Li and El~Gamal(2018)]{li2018strong}
C.~T. Li and A.~El~Gamal.
\newblock Strong functional representation lemma and applications to coding theorems.
\newblock \emph{IEEE Transactions on Information Theory}, 64\penalty0 (11):\penalty0 6967--6978, 2018.

\bibitem[Maddison(2016)]{maddison2016poisson}
C.~J. Maddison.
\newblock A poisson process model for monte carlo.
\newblock \emph{Perturbation, Optimization, and Statistics}, pages 193--232, 2016.

\bibitem[Maddison et~al.(2014)Maddison, Tarlow, and Minka]{maddison2014sampling}
C.~J. Maddison, D.~Tarlow, and T.~Minka.
\newblock A* sampling.
\newblock \emph{Advances in neural information processing systems}, 27, 2014.

\bibitem[Mentzer et~al.(2019)Mentzer, Agustsson, Tschannen, Timofte, and Van~Gool]{mentzer2019practical}
F.~Mentzer, E.~Agustsson, M.~Tschannen, R.~Timofte, and L.~Van~Gool.
\newblock Practical full resolution learned lossless image compression.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2019.

\bibitem[Nielsen(2013)]{nielsen2013hypothesis}
F.~Nielsen.
\newblock Hypothesis testing, information divergence and computational geometry.
\newblock In \emph{International Conference on Geometric Science of Information}, pages 241--248. Springer, 2013.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, and Duchesnay]{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel, M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos, D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2825--2830, 2011.

\bibitem[Schwarz et~al.(2023)Schwarz, Tack, Teh, Lee, and Shin]{schwarz2023modality}
J.~R. Schwarz, J.~Tack, Y.~W. Teh, J.~Lee, and J.~Shin.
\newblock Modality-agnostic variational compression of implicit neural representations.
\newblock In \emph{Proceedings of the 40th International Conference on Machine Learning}, pages 30342--30364, 2023.

\bibitem[Smola et~al.(2007)Smola, Gretton, Song, and Sch{\"o}lkopf]{smola2007hilbert}
A.~Smola, A.~Gretton, L.~Song, and B.~Sch{\"o}lkopf.
\newblock A hilbert space embedding for distributions.
\newblock In \emph{International conference on algorithmic learning theory}, pages 13--31. Springer, 2007.

\bibitem[Theis and Agustsson(2021)]{theis2021advantages}
L.~Theis and E.~Agustsson.
\newblock On the advantages of stochastic encoders, 2021.

\bibitem[Theis and Yosri(2022)]{theis2022algorithms}
L.~Theis and N.~Yosri.
\newblock Algorithms for the communication of samples.
\newblock In \emph{International Conference on Machine Learning}, pages 21308--21328. PMLR, 2022.

\bibitem[Theis et~al.(2022)Theis, Salimans, Hoffman, and Mentzer]{theis2022lossy}
L.~Theis, T.~Salimans, M.~D. Hoffman, and F.~Mentzer.
\newblock Lossy compression with gaussian diffusion.
\newblock \emph{arXiv preprint arXiv:2206.08889}, 2022.

\bibitem[Townsend et~al.(2019)Townsend, Bird, and Barber]{townsend2019practical}
J.~Townsend, T.~Bird, and D.~Barber.
\newblock Practical lossless compression with latent variables using bits back coding.
\newblock In \emph{7th International Conference on Learning Representations, ICLR 2019}, volume~7. International Conference on Learning Representations (ICLR), 2019.

\end{thebibliography}
