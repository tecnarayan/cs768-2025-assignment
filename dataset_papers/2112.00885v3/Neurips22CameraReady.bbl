\begin{thebibliography}{10}

\bibitem{achiam2017constrained}
Joshua Achiam, David Held, Aviv Tamar, and Pieter Abbeel.
\newblock Constrained {P}olicy {O}ptimization.
\newblock In {\em International Conference on Machine Learning}, pages 22--31.
  PMLR, 2017.

\bibitem{altman1999constrained}
Eitan Altman.
\newblock {\em Constrained {M}arkov decision processes}, volume~7.
\newblock CRC Press, 1999.

\bibitem{altman2002applications}
Eitan Altman.
\newblock Applications of {M}arkov decision processes in communication
  networks.
\newblock In {\em Handbook of {M}arkov decision processes}, pages 489--536.
  Springer, 2002.

\bibitem{amani2019linear}
Sanae Amani, Mahnoosh Alizadeh, and Christos Thrampoulidis.
\newblock Linear stochastic bandits under safety constraints.
\newblock {\em Advances in Neural Information Processing Systems},
  32:9256--9266, 2019.

\bibitem{AmaniSafeOfflineRL}
Sanae Amani and Lin~F. Yang.
\newblock Doubly pessimistic algorithms for strictly safe off-policy
  optimization.
\newblock In {\em 2022 56th Annual Conference on Information Sciences and
  Systems (CISS)}, pages 113--118, 2022.

\bibitem{azar2017minimax}
Mohammad~Gheshlaghi Azar, Ian Osband, and R{\'e}mi Munos.
\newblock Minimax regret bounds for reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  263--272. PMLR, 2017.

\bibitem{bertsekas2000dynamic}
Dimitri~P Bertsekas et~al.
\newblock {\em Dynamic programming and optimal control: Vol. 1}.
\newblock Athena scientific Belmont, 2000.

\bibitem{bhatnagar2012online}
Shalabh Bhatnagar and K~Lakshmanan.
\newblock An online actor--critic algorithm with function approximation for
  constrained {M}arkov decision processes.
\newblock {\em Journal of Optimization Theory and Applications},
  153(3):688--708, 2012.

\bibitem{borkar2005actor}
Vivek~S Borkar.
\newblock An actor-critic algorithm for constrained {M}arkov decision
  processes.
\newblock {\em Systems \& control letters}, 54(3):207--213, 2005.

\bibitem{chaudhary2022safe}
Sapana Chaudhary and Dileep Kalathil.
\newblock Safe online convex optimization with unknown linear safety
  constraints.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~36, pages 6175--6182, 2022.

\bibitem{chow2015trading}
Yin-Lam Chow, Marco Pavone, Brian~M Sadler, and Stefano Carpin.
\newblock Trading safety versus performance: Rapid deployment of robotic swarms
  with robust performance constraints.
\newblock {\em Journal of Dynamic Systems, Measurement, and Control},
  137(3):031005, 2015.

\bibitem{chow2017risk}
Yinlam Chow, Mohammad Ghavamzadeh, Lucas Janson, and Marco Pavone.
\newblock Risk-constrained reinforcement learning with percentile risk
  criteria.
\newblock {\em The Journal of Machine Learning Research}, 18(1):6070--6120,
  2017.

\bibitem{dann2015sample}
Christoph Dann and Emma Brunskill.
\newblock Sample complexity of episodic fixed-horizon reinforcement learning.
\newblock {\em Advances in Neural Information Processing Systems},
  28:2818--2826, 2015.

\bibitem{dann2017unifying}
Christoph Dann, Tor Lattimore, and Emma Brunskill.
\newblock Unifying pac and regret: Uniform pac bounds for episodic
  reinforcement learning.
\newblock {\em arXiv preprint arXiv:1703.07710}, 2017.

\bibitem{ding2021provably}
Dongsheng Ding, Xiaohan Wei, Zhuoran Yang, Zhaoran Wang, and Mihailo Jovanovic.
\newblock Provably efficient safe exploration via primal-dual policy
  optimization.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 3304--3312. PMLR, 2021.

\bibitem{ding2020natural}
Dongsheng Ding, Kaiqing Zhang, Tamer Basar, and Mihailo Jovanovic.
\newblock Natural policy gradient primal-dual method for constrained {M}arkov
  decision processes.
\newblock {\em Advances in Neural Information Processing Systems},
  33:8378--8390, 2020.

\bibitem{ding2013strategic}
Xu~Chu Ding, Alessandro Pinto, and Amit Surana.
\newblock Strategic planning under uncertainties via constrained {M}arkov
  decision processes.
\newblock In {\em 2013 IEEE International Conference on Robotics and
  Automation}, pages 4568--4575. IEEE, 2013.

\bibitem{efroni2020exploration}
Yonathan Efroni, Shie Mannor, and Matteo Pirotta.
\newblock Exploration-exploitation in constrained {MDP}s.
\newblock {\em arXiv preprint arXiv:2003.02189}, 2020.

\bibitem{hasanzadezonuzy2021learning}
Aria HasanzadeZonuzy, Archana Bura, Dileep Kalathil, and Srinivas Shakkottai.
\newblock Learning with safety constraints: Sample complexity of reinforcement
  learning for constrained {MDP}s.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 7667--7674, 2021.

\bibitem{hazan2016introduction}
Elad Hazan.
\newblock Introduction to online convex optimization.
\newblock {\em Foundations and Trends in Optimization}, 2(3-4):157--325, 2016.

\bibitem{jaksch2010near}
Thomas Jaksch, Ronald Ortner, and Peter Auer.
\newblock Near-optimal regret bounds for reinforcement learning.
\newblock {\em Journal of Machine Learning Research}, 11(4), 2010.

\bibitem{jin20c}
Chi Jin, Tiancheng Jin, Haipeng Luo, Suvrit Sra, and Tiancheng Yu.
\newblock Learning adversarial {M}arkov decision processes with bandit feedback
  and unknown transition.
\newblock In {\em Proceedings of the 37th International Conference on Machine
  Learning}, volume 119, pages 4860--4869. PMLR, 13--18 Jul 2020.

\bibitem{kalagarla2021sample}
Krishna~C Kalagarla, Rahul Jain, and Pierluigi Nuzzo.
\newblock A sample-efficient algorithm for episodic finite-horizon {MDP} with
  constraints.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 8030--8037, 2021.

\bibitem{khezeli2020safe}
Kia Khezeli and Eilyan Bitar.
\newblock Safe linear stochastic bandits.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 10202--10209, 2020.

\bibitem{li2019constrained}
Hepeng Li, Zhiqiang Wan, and Haibo He.
\newblock Constrained {EV} charging scheduling based on safe deep reinforcement
  learning.
\newblock {\em IEEE Transactions on Smart Grid}, 11(3):2427--2439, 2019.

\bibitem{liakopoulos2019cautious}
Nikolaos Liakopoulos, Apostolos Destounis, Georgios Paschos, Thrasyvoulos
  Spyropoulos, and Panayotis Mertikopoulos.
\newblock Cautious regret minimization: Online optimization with long-term
  budget constraints.
\newblock In {\em International Conference on Machine Learning}, pages
  3944--3952. PMLR, 2019.

\bibitem{liu2021fast}
Tao Liu, Ruida Zhou, Dileep Kalathil, PR~Kumar, and Chao Tian.
\newblock Fast global convergence of policy optimization for constrained mdps.
\newblock {\em arXiv preprint arXiv:2111.00552}, 2021.

\bibitem{liu2021learning}
Tao Liu, Ruida Zhou, Dileep Kalathil, PR~Kumar, and Chao Tian.
\newblock Learning {P}olicies {w}ith {Z}ero or {B}ounded {C}onstraint
  {V}iolation for {C}onstrained {MDP}s.
\newblock In {\em Thirty-fifth Conference on Neural Information Processing
  Systems}, 2021.

\bibitem{liu2021efficient}
Xin Liu, Bin Li, Pengyi Shi, and Lei Ying.
\newblock An efficient pessimistic-optimistic algorithm for stochastic linear
  bandits with general constraints.
\newblock {\em arXiv preprint arXiv:2102.05295}, 2021.

\bibitem{MaurerP09}
Andreas Maurer and Massimiliano Pontil.
\newblock Empirical {B}ernstein bounds and sample-variance penalization.
\newblock In {\em {COLT} 2009 - The 22nd Conference on Learning Theory,
  Montreal, Quebec, Canada, June 18-21, 2009}, 2009.

\bibitem{moradipari2020stage}
Ahmadreza Moradipari, Christos Thrampoulidis, and Mahnoosh Alizadeh.
\newblock Stage-wise conservative linear bandits.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{neely2017online}
Michael~J Neely and Hao Yu.
\newblock Online convex optimization with time-varying constraints.
\newblock {\em arXiv preprint arXiv:1702.04783}, 2017.

\bibitem{pacchiano2021stochastic}
Aldo Pacchiano, Mohammad Ghavamzadeh, Peter Bartlett, and Heinrich Jiang.
\newblock Stochastic bandits with linear constraints.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 2827--2835. PMLR, 2021.

\bibitem{parulekar2020stochastic}
Advait Parulekar, Soumya Basu, Aditya Gopalan, Karthikeyan Shanmugam, and
  Sanjay Shakkottai.
\newblock Stochastic linear bandits with protected subspace.
\newblock {\em arXiv preprint arXiv:2011.01016}, 2020.

\bibitem{paternain2019constrained}
Santiago Paternain, Luiz Chamon, Miguel Calvo-Fullana, and Alejandro Ribeiro.
\newblock Constrained reinforcement learning has zero duality gap.
\newblock {\em Advances in Neural Information Processing Systems},
  32:7555--7565, 2019.

\bibitem{simao2021alwayssafe}
Thiago~D Sim{\~a}o, Nils Jansen, and Matthijs~TJ Spaan.
\newblock Alwayssafe: Reinforcement learning without safety constraint
  violations during training.
\newblock In {\em Proceedings of the 20th International Conference on
  Autonomous Agents and MultiAgent Systems}. International Foundation for
  Autonomous Agents and Multiagent Systems, 2021.

\bibitem{singh2020learning}
Rahul Singh, Abhishek Gupta, and Ness~B Shroff.
\newblock Learning in {M}arkov decision processes under constraints.
\newblock {\em arXiv preprint arXiv:2002.12435}, 2020.

\bibitem{singh2018throughput}
Rahul Singh and PR~Kumar.
\newblock Throughput optimal decentralized scheduling of multihop networks with
  end-to-end deadline constraints: Unreliable links.
\newblock {\em IEEE Transactions on Automatic Control}, 64(1):127--142, 2018.

\bibitem{singh2018decentralized}
Rahul Singh, PR~Kumar, and Le~Xie.
\newblock Decentralized control via dynamic stochastic prices: The independent
  system operator problem.
\newblock {\em IEEE Transactions on Automatic Control}, 63(10):3206--3220,
  2018.

\bibitem{tessler2018reward}
Chen Tessler, Daniel~J Mankowitz, and Shie Mannor.
\newblock Reward constrained policy optimization.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{usmanova2019safe}
Ilnura Usmanova, Andreas Krause, and Maryam Kamgarpour.
\newblock Safe convex learning under uncertain constraints.
\newblock In {\em The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 2106--2114. PMLR, 2019.

\bibitem{wei2022provably}
Honghao Wei, Xin Liu, and Lei Ying.
\newblock A provably-efficient model-free algorithm for infinite-horizon
  average-reward constrained {M}arkov decision processes.
\newblock In {\em AAAI Conference on Artificial Intelligence}, 2022.

\bibitem{wei2022triple}
Honghao Wei, Xin Liu, and Lei Ying.
\newblock Triple-q: A model-free algorithm for constrained reinforcement
  learning with sublinear regret and zero constraint violation.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 3274--3307. PMLR, 2022.

\bibitem{yang2019projection}
Tsung-Yen Yang, Justinian Rosca, Karthik Narasimhan, and Peter~J Ramadge.
\newblock Projection-based constrained policy optimization.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{yu2017online}
Hao Yu, Michael~J Neely, and Xiaohan Wei.
\newblock Online convex optimization with stochastic constraints.
\newblock In {\em Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pages 1427--1437, 2017.

\bibitem{yuan2018online}
Jianjun Yuan and Andrew Lamperski.
\newblock Online convex optimization for cumulative constraints.
\newblock In {\em Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, pages 6140--6149, 2018.

\bibitem{zhang2020first}
Yiming Zhang, Quan Vuong, and Keith Ross.
\newblock First order constrained optimization in policy space.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{zheng2020constrained}
Liyuan Zheng and Lillian Ratliff.
\newblock Constrained upper confidence reinforcement learning.
\newblock In {\em Learning for Dynamics and Control}, pages 620--629. PMLR,
  2020.

\bibitem{zhou2022anchor}
Ruida Zhou, Tao Liu, Dileep Kalathil, PR~Kumar, and Chao Tian.
\newblock Anchor-changing regularized natural policy gradient for
  multi-objective reinforcement learning.
\newblock {\em arXiv preprint arXiv:2206.05357}, 2022.

\bibitem{zimin2013online}
Alexander Zimin and Gergely Neu.
\newblock Online learning in episodic {M}arkovian decision processes by
  relative entropy policy search.
\newblock In {\em Neural Information Processing Systems 26}, 2013.

\end{thebibliography}
