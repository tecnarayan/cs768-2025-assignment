

@article{Bottou2018,
  author =        {L. Bottou and F. E. Curtis and J. Nocedal},
  journal =       {SIAM Rev.},
  number =        {2},
  pages =         {223--311},
  title =         {{O}ptimization {M}ethods for {L}arge-{S}cale
                   {M}achine {L}earning},
  volume =        {60},
  year =          {2018},
}

@book{sra2012optimization,
  author =        {S. Sra and S. Nowozin and S. J. Wright},
  publisher =     {MIT Press},
  title =         {{O}ptimization for {M}achine {L}earning},
  year =          {2012},
}

@article{RM1951,
  author =        {Robbins, Herbert and Monro, Sutton},
  journal =       {The Annals of Mathematical Statistics},
  number =        {3},
  pages =         {400--407},
  title =         {A Stochastic Approximation Method},
  volume =        {22},
  year =          {1951},
}

@article{Polyak1992,
  author =        {B. Polyak and A. Juditsky},
  journal =       {SIAM J. Control Optim.},
  number =        {4},
  pages =         {838--855},
  publisher =     {SIAM},
  title =         {Acceleration of stochastic approximation by
                   averaging},
  volume =        {30},
  year =          {1992},
}

@article{Nemirovski2009,
  author =        {Nemirovski, A. and Juditsky, A. and Lan, G. and
                   Shapiro, A.},
  journal =       {SIAM J. on Optimization},
  number =        {4},
  pages =         {1574--1609},
  title =         {Robust Stochastic Approximation Approach to
                   Stochastic Programming},
  volume =        {19},
  year =          {2009},
}

@article{ghadimi2013stochastic,
  author =        {S. Ghadimi and G. Lan},
  journal =       {SIAM J. Optim.},
  number =        {4},
  pages =         {2341--2368},
  publisher =     {SIAM},
  title =         {Stochastic first-and zeroth-order methods for
                   nonconvex stochastic programming},
  volume =        {23},
  year =          {2013},
}

@misc{bottou2009curiously,
  author =        {Bottou, L{\'e}on},
  title =         {Curiously fast convergence of some stochastic
                   gradient descent algorithms},
  year =          {2009},
}

@incollection{bottou2012stochastic,
  author =        {L. Bottou},
  booktitle =     {Neural networks: Tricks of the trade},
  pages =         {421--436},
  publisher =     {Springer},
  title =         {Stochastic gradient descent tricks},
  year =          {2012},
}

@article{gurbuzbalaban2015random,
  author =        {G{\"u}rb{\"u}zbalaban, Mert and Ozdaglar, Asu and
                   Parrilo, Pablo},
  journal =       {arXiv preprint arXiv:1510.08560},
  title =         {Why random reshuffling beats stochastic gradient
                   descent},
  year =          {2015},
}

@article{haochen2018random,
  author =        {HaoChen, Jeffery Z and Sra, Suvrit},
  journal =       {arXiv preprint arXiv:1806.10077},
  title =         {Random shuffling beats sgd after finite epochs},
  year =          {2018},
}

@article{Safran2019HowGoodSGDShuffling,
  author =        {Safran, Itay and Shamir, Ohad},
  journal =       {arXiv preprint arXiv:1908.00045},
  title =         {How Good is SGD with Random Shuffling?},
  year =          {2018},
}

@inproceedings{SAG,
  title={A Stochastic Gradient Method with an Exponential Convergence Rate for Finite Training Sets},
  author={Le Roux, Nicolas and Schmidt, Mark and Bach, Francis},
  booktitle={NIPS},
  year={2012},
  pages={2663--2671}
}

@inproceedings{nagaraj2019sgd,
  author =        {Nagaraj, Dheeraj and Jain, Prateek and
                   Netrapalli, Praneeth},
  booktitle =     {International Conference on Machine Learning},
  pages =         {4703--4711},
  title =         {SGD without Replacement: Sharper Rates for General
                   Smooth Convex Functions},
  year =          {2019},
}

@article{nedic2001incremental,
  author =        {A. Nedic and D. P. Bertsekas},
  journal =       {SIAM J. on Optim.},
  number =        {1},
  pages =         {109--138},
  publisher =     {SIAM},
  title =         {Incremental subgradient methods for nondifferentiable
                   optimization},
  volume =        {12},
  year =          {2001},
}

@incollection{nedic2001convergence,
  author =        {A. Nedi{\'c} and D. Bertsekas},
  booktitle =     {Stochastic optimization: algorithms and applications},
  pages =         {223--264},
  publisher =     {Springer},
  title =         {Convergence rate of incremental subgradient
                   algorithms},
  year =          {2001},
}

@article{gurbuzbalaban2015convergence,
  author =        {M. G{\"u}rb{\"u}zbalaban and A. Ozdaglar and
                   P. Parrilo},
  journal =       {arXiv preprint arXiv:1510.08562},
  title =         {Convergence rate of incremental gradient and {N}ewton
                   methods},
  year =          {2015},
}

@inproceedings{Defazio2014,
  author =        {A. Defazio and F. Bach and S. Lacoste-Julien},
  booktitle =     {Advances in Neural Information Processing Systems
                   (NIPS)},
  pages =         {1646--1654},
  title =         {{SAGA}: {A} Fast Incremental Gradient Method With
                   Support for Non-Strongly Convex Composite Objectives},
  year =          {2014},
}

@inproceedings{defazio2014finito,
  author =        {A. Defazio and T. Caetano and J. Domke},
  booktitle =     {International Conference on Machine Learning},
  pages =         {1125--1133},
  title =         {Finito: A faster, permutable incremental gradient
                   method for big data problems},
  year =          {2014},
}

@article{ying2017convergence,
  author =        {B. Ying and K. Yuan and A. H. Sayed},
  journal =       {arXiv preprint arXiv:1708.01383},
  number =        {3},
  pages =         {6},
  title =         {Convergence of variance-reduced stochastic learning
                   under random reshuffling},
  volume =        {2},
  year =          {2017},
}

@inproceedings{shamir2016without,
  author =        {O. Shamir},
  booktitle =     {Advances in neural information processing systems},
  pages =         {46--54},
  title =         {Without-replacement sampling for stochastic gradient
                   methods},
  year =          {2016},
}

@article{meng2019convergence,
  author =        {Q. Meng and W. Chen and Y. Wang and Z.-M. Ma and
                   T.-Y. Liu},
  journal =       {Neurocomputing},
  pages =         {46--57},
  publisher =     {Elsevier},
  title =         {Convergence analysis of distributed stochastic
                   gradient descent with shuffling},
  volume =        {337},
  year =          {2019},
}

@article{li2019incremental,
  author =        {X. Li and Z. Zhu and A. So and J. D. Lee},
  journal =       {arXiv preprint arXiv:1907.11687},
  title =         {Incremental Methods for Weakly Convex Optimization},
  year =          {2019},
}

@book{nesterov2004,
  address =       {Boston, Dordrecht, London},
  author =        {Nesterov, Yurii},
  publisher =     {Kluwer Academic Publ.},
  series =        {Applied optimization},
  title =         {Introductory lectures on convex optimization : a
                   basic course},
  year =          {2004},
  isbn =          {1-4020-7553-7},
}

@article{Tran-Dinh2019a,
  author =        {Q. Tran-Dinh and N. H. Pham and D. T. Phan and
                   L. M. Nguyen},
  journal =       {Preprint: UNC-STOR 07.10.2019},
  title =         {A Hybrid Stochastic Optimization Framework for
                   Stochastic Composite Nonconvex Optimization},
  year =          {2019},
}

@article{Cutkosky2019,
  author =        {A. Cutkosky and F. Orabona},
  journal =       {arxiv:1905.10018},
  title =         {Momentum-Based Variance Reduction in Non-Convex
                   {SGD}},
  year =          {2019},
}

@article{Polyak1964,
  author =        {Polyak, Boris T.},
  journal =       {{USSR} Computational Mathematics and Mathematical
                   Physics},
  number =        {5},
  pages =         {1--17},
  title =         {Some methods of speeding up the convergence of
                   iteration methods},
  volume =        {4},
  year =          {1964},
}

@article{nesterov2006cubic,
  author =        {Nesterov, Yurii and Polyak, Boris T},
  journal =       {Mathematical Programming},
  number =        {1},
  pages =         {177--205},
  publisher =     {Springer-Verlag},
  title =         {Cubic regularization of {N}ewton method and its
                   global performance},
  volume =        {108},
  year =          {2006},
}

@inproceedings{polyak_condition,
  address =       {Cham},
  author =        {Karimi, Hamed and Nutini, Julie and Schmidt, Mark},
  booktitle =     {Machine Learning and Knowledge Discovery in
                   Databases},
  editor =        {Frasconi, Paolo and Landwehr, Niels and
                   Manco, Giuseppe and Vreeken, Jilles},
  pages =         {795--811},
  publisher =     {Springer International Publishing},
  title =         {Linear Convergence of Gradient and Proximal-Gradient
                   Methods Under the {P}olyak-{{\L}}ojasiewicz
                   Condition},
  year =          {2016},
}

@article{bottou2016optimization,
  author =        {Bottou, L{\'e}on and Curtis, Frank E and
                   Nocedal, Jorge},
  journal =       {Siam Review},
  number =        {2},
  pages =         {223--311},
  publisher =     {SIAM},
  title =         {Optimization methods for large-scale machine
                   learning},
  volume =        {60},
  year =          {2018},
}

@article{LIBSVM,
  author =        {Chang, Chih-Chung and Lin, Chih-Jen},
  journal =       {ACM Transactions on Intelligent Systems and
                   Technology},
  note =          {Software available at
                   \url{http://www.csie.ntu.edu.tw/~cjlin/libsvm}},
  pages =         {27:1--27:27},
  title =         {{LIBSVM}: A library for support vector machines},
  volume =        {2},
  year =          {2011},
}

@misc{tensorflow2015-whitepaper,
  author =        {Mart\'{\i}n~Abadi and Ashish~Agarwal and Paul~Barham and
                   Eugene~Brevdo and Zhifeng~Chen and Craig~Citro and
                   Greg~S.~Corrado and Andy~Davis and Jeffrey~Dean and
                   Matthieu~Devin and Sanjay~Ghemawat and Ian~Goodfellow and
                   Andrew~Harp and Geoffrey~Irving and Michael~Isard and
                   Yangqing Jia and Rafal~Jozefowicz and Lukasz~Kaiser and
                   Manjunath~Kudlur and Josh~Levenberg and
                   Dandelion~Man\'{e} and Rajat~Monga and Sherry~Moore and
                   Derek~Murray and Chris~Olah and Mike~Schuster and
                   Jonathon~Shlens and Benoit~Steiner and Ilya~Sutskever and
                   Kunal~Talwar and Paul~Tucker and Vincent~Vanhoucke and
                   Vijay~Vasudevan and Fernanda~Vi\'{e}gas and
                   Oriol~Vinyals and Pete~Warden and Martin~Wattenberg and
                   Martin~Wicke and Yuan~Yu and Xiaoqiang~Zheng},
  note =          {Software available from tensorflow.org},
  title =         {{TensorFlow}: Large-Scale Machine Learning on
                   Heterogeneous Systems},
  year =          {2015},
  url =           {https://www.tensorflow.org/},
}

@article{MNIST,
  author =        {LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and
                   Haffner, Patrick},
  journal =       {Proceedings of the IEEE},
  number =        {11},
  pages =         {2278--2324},
  publisher =     {IEEE},
  title =         {Gradient-based learning applied to document
                   recognition},
  volume =        {86},
  year =          {1998},
}

@misc{BertsekasSurvey,
  author =        {Dimitri P. Bertsekas},
  title =         {Incremental Gradient, Subgradient, and Proximal
                   Methods for Convex Optimization: A Survey},
  year =          {2015},
}

@techreport{CIFAR10,
  author =        {Krizhevsky, Alex and Hinton, Geoffrey},
  institution =   {Citeseer},
  title =         {Learning multiple layers of features from tiny
                   images},
  year =          {2009},
}

@article{JMLR:v18:17-632,
  author  = {Hiroyuki Kasai},
  title   = {{SGDLibrary}: A {MATLAB} library for stochastic optimization algorithms},
  journal = {Journal of Machine Learning Research},
  year    = {2018},
  volume  = {18},
  number  = {215},
  pages   = {1-5},
  url     = {http://jmlr.org/papers/v18/17-632.html}
}

@article{Nguyen2019_sgd_new_aspects,
  author  = {Lam M. Nguyen and Phuong Ha Nguyen and Peter Richt{{\'a}}rik and Katya Scheinberg and Martin Tak{{\'a}}{\v{c}} and Marten van Dijk},
  title   = {New Convergence Aspects of Stochastic Gradient Algorithms},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {176},
  pages   = {1-49},
  url     = {http://jmlr.org/papers/v20/18-759.html}
}

@InProceedings{Nguyen2018_sgdhogwild,
  title = 	 {{SGD} and {H}ogwild! Convergence Without the Bounded Gradients Assumption},
  author = 	 {Nguyen, Lam and Nguyen, Phuong Ha and van Dijk, Marten and Richtarik, Peter and Scheinberg, Katya and Takac, Martin},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning-Volume 80},
  pages={3747--3755}, 
  year = 	 {2018}
}

@inproceedings{Nguyen2017sarah,
  title={SARAH: A novel method for machine learning problems using stochastic recursive gradient},
  author={Nguyen, Lam M and Liu, Jie and Scheinberg, Katya and Tak{\'a}{\v{c}}, Martin},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2613--2621},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{SVRG,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={315--323},
  year={2013}
}

@inproceedings{SAGA,
  title={SAGA: A fast incremental gradient method with support for non-strongly convex composite objectives},
  author={Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1646--1654},
  year={2014}
}

@article{KingmaB14,
  added-at = {2015-01-01T00:00:00.000+0100},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  biburl = {https://www.bibsonomy.org/bibtex/23b0328784dbfce338ba0dd2618a7a059/dblp},
  ee = {http://arxiv.org/abs/1412.6980},
  interhash = {57d2ac873f398f21bb94790081e80394},
  intrahash = {3b0328784dbfce338ba0dd2618a7a059},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2015-06-18T04:22:29.000+0200},
  title = {Adam: A Method for Stochastic Optimization.},
  volume = {abs/1412.6980},
  year = 2014
}

@article{AdaGrad,
 author = {Duchi, John and Hazan, Elad and Singer, Yoram},
 title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
 journal = {Journal of Machine Learning Research},
 volume = {12},
 year = {2011},
 pages = {2121--2159}
}



@InProceedings{pmlr-v97-allen-zhu19a, title = {A Convergence Theory for Deep Learning via Over-Parameterization}, author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao}, booktitle = {Proceedings of the 36th International Conference on Machine Learning}, pages = {242--252}, year = {2019}, editor = {Kamalika Chaudhuri and Ruslan Salakhutdinov}, volume = {97}, series = {Proceedings of Machine Learning Research}, month = {09--15 Jun}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v97/allen-zhu19a/allen-zhu19a.pdf}, url = { http://proceedings.mlr.press/v97/allen-zhu19a.html }}


@InProceedings{pmlr-v80-arora18a,
  title = 	 {On the Optimization of Deep Networks: Implicit Acceleration by Overparameterization},
  author =       {Arora, Sanjeev and Cohen, Nadav and Hazan, Elad},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {244--253},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/arora18a/arora18a.pdf},
  url = 	 {http://proceedings.mlr.press/v80/arora18a.html},
  
}


@inproceedings{nguyen2020global,
 author = {Nguyen, Quynh N and Mondelli, Marco},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {11961--11972},
 publisher = {Curran Associates, Inc.},
 title = {Global Convergence of Deep Networks with One Wide Layer Followed by Pyramidal Topology},
 url = {https://proceedings.neurips.cc/paper/2020/file/8abfe8ac9ec214d68541fcb888c0b4c3-Paper.pdf},
 volume = {33},
 year = {2020}
}


@misc{zou2018stochastic,
      title={Stochastic Gradient Descent Optimizes Over-parameterized Deep ReLU Networks}, 
      author={Difan Zou and Yuan Cao and Dongruo Zhou and Quanquan Gu},
      year={2018},
      eprint={1811.08888},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@inproceedings{
brutzkus2017sgd,
title={{SGD} Learns Over-parameterized Networks that Provably Generalize on Linearly Separable Data},
author={Alon Brutzkus and Amir Globerson and Eran Malach and Shai Shalev-Shwartz},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=rJ33wwxRb},
}


@article{soudry2018implicit,
author = {Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
title = {The Implicit Bias of Gradient Descent on Separable Data},
year = {2018},
issue_date = {January 2018},
publisher = {JMLR.org},
volume = {19},
number = {1},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {2822–2878},
numpages = {57},
keywords = {logistic regression, margin, generalization, gradient descent, implicit regularization}
}


@InProceedings{pmlr-v97-arora19a,
  title = 	 {Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks},
  author =       {Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {322--332},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/arora19a/arora19a.pdf},
  url = 	 {http://proceedings.mlr.press/v97/arora19a.html},
  
}
@misc{chen2020overparameterization,
      title={How Much Over-parameterization Is Sufficient to Learn Deep ReLU Networks?}, 
      author={Zixiang Chen and Yuan Cao and Difan Zou and Quanquan Gu},
      year={2020},
      eprint={1911.12360},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{DanielyNIPS2017,
 author = {Daniely, Amit},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {SGD Learns the Conjugate Kernel Class of the Network},
 url = {https://proceedings.neurips.cc/paper/2017/file/489d0396e6826eb0c1e611d82ca8b215-Paper.pdf},
 volume = {30},
 year = {2017}
}

@InProceedings{pmlr-v97-du19c,
  title = 	 {Gradient Descent Finds Global Minima of Deep Neural Networks},
  author =       {Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {1675--1685},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/du19c/du19c.pdf},
  url = 	 {http://proceedings.mlr.press/v97/du19c.html},
}

@inproceedings{
du2019gradient,
title={Gradient Descent Provably Optimizes Over-parameterized Neural Networks},
author={Simon S. Du and Xiyu Zhai and Barnabas Poczos and Aarti Singh},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=S1eK3i09YQ},
}


@inproceedings{ZouG19nips,
  author    = {Difan Zou and
               Quanquan Gu},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {An Improved Analysis of Training Over-parameterized Deep Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {2053--2062},
  year      = {2019},
  timestamp = {Thu, 21 Jan 2021 15:15:19 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/ZouG19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{zhang2021multilevel,
author = {Zhang, Junyu and Xiao, Lin},
title = {MultiLevel Composite Stochastic Optimization via Nested Variance Reduction},
journal = {SIAM Journal on Optimization},
volume = {31},
number = {2},
pages = {1131-1157},
year = {2021},
doi = {10.1137/19M1285457},

URL = { 
        https://doi.org/10.1137/19M1285457
},
}

@inproceedings{zhang2019stochastic,
 author = {Zhang, Junyu and Xiao, Lin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {A Stochastic Composite Gradient Method with Incremental Variance Reduction},
 url = {https://proceedings.neurips.cc/paper/2019/file/a68259547f3d25ab3c0a5c0adb4e3498-Paper.pdf},
 volume = {32},
 year = {2019}
}


@misc{trandinh2020stochastic,
      title={Stochastic Gauss-Newton Algorithms for Nonconvex Compositional Optimization}, 
      author={Quoc Tran-Dinh and Nhan H. Pham and Lam M. Nguyen},
      year={2020},
      eprint={2002.07290},
      archivePrefix={arXiv},
      primaryClass={math.OC}
}


@InProceedings{pmlr-v80-ma18a,
  title = 	 {The Power of Interpolation: Understanding the Effectiveness of {SGD} in Modern Over-parametrized Learning},
  author =       {Ma, Siyuan and Bassily, Raef and Belkin, Mikhail},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {3325--3334},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/ma18a/ma18a.pdf},
  url = 	 {http://proceedings.mlr.press/v80/ma18a.html},
}

@misc{vaswani2021adaptive,
      title={Adaptive Gradient Methods Converge Faster with Over-Parameterization (but you should do a line-search)}, 
      author={Sharan Vaswani and Issam Laradji and Frederik Kunstner and Si Yi Meng and Mark Schmidt and Simon Lacoste-Julien},
      year={2021},
      eprint={2006.06835},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@InProceedings{pmlr-v130-loizou21a,
  title = 	 { Stochastic Polyak Step-size for SGD: An Adaptive Learning Rate for Fast Convergence },
  author =       {Loizou, Nicolas and Vaswani, Sharan and Hadj Laradji, Issam and Lacoste-Julien, Simon},
  booktitle = 	 {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1306--1314},
  year = 	 {2021},
  editor = 	 {Banerjee, Arindam and Fukumizu, Kenji},
  volume = 	 {130},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--15 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v130/loizou21a/loizou21a.pdf},
  url = 	 {http://proceedings.mlr.press/v130/loizou21a.html},
}


@InProceedings{pmlr-v108-meng20a,
  title = 	 {Fast and Furious Convergence: Stochastic Second Order Methods under Interpolation},
  author =       {Meng, Si Yi and Vaswani, Sharan and Laradji, Issam Hadj and Schmidt, Mark and Lacoste-Julien, Simon},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1375--1386},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v108/meng20a/meng20a.pdf},
  url = 	 {http://proceedings.mlr.press/v108/meng20a.html},
  }

@inproceedings{ziweiiclr2020,
  author    = {Ziwei Ji and
               Matus Telgarsky},
  title     = {Polylogarithmic width suffices for gradient descent to achieve arbitrarily
               small test error with shallow ReLU networks},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  url       = {https://openreview.net/forum?id=HygegyrYwH},
  timestamp = {Thu, 07 May 2020 17:11:47 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/JiT20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{pmlr-v119-tran-dinh20a,
  title = 	 {Stochastic {G}auss-{N}ewton Algorithms for Nonconvex Compositional Optimization},
  author =       {Tran-Dinh, Quoc and Pham, Nhan and Nguyen, Lam},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {9572--9582},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/tran-dinh20a/tran-dinh20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/tran-dinh20a.html},
  
}


@InProceedings{smg_tran21b,
  title = 	 {{SMG}: A Shuffling Gradient-Based Method with Momentum},
  author =       {Tran, Trang H and Nguyen, Lam M and Tran-Dinh, Quoc},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {10379--10389},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/tran21b/tran21b.pdf},
  url = 	 {https://proceedings.mlr.press/v139/tran21b.html},

}


@InProceedings{svrg_nonconvex-reddi16,
  title = 	 {Stochastic Variance Reduction for Nonconvex Optimization},
  author = 	 {Reddi, Sashank J. and Hefny, Ahmed and Sra, Suvrit and Poczos, Barnabas and Smola, Alex},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {314--323},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/reddi16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/reddi16.html},
}

@article{bottou_survey,
author = {Bottou, Léon and Curtis, Frank E. and Nocedal, Jorge},
title = {Optimization Methods for Large-Scale Machine Learning},
journal = {SIAM Review},
volume = {60},
number = {2},
pages = {223-311},
year = {2018},
doi = {10.1137/16M1080173},

}

@article{pegasos,
author = {Shalev-Shwartz, Shai and Singer, Yoram and Srebro, Nathan},
title = {Pegasos: Primal Estimated Sub-GrAdient SOlver for SVM},
year = {2007},
isbn = {9781595937933},
journal = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1273496.1273598},
doi = {10.1145/1273496.1273598},

}
@article{2019gurbuzbalaban,
author = {Gürbüzbalaban, M. and Ozdaglar, A. and Parrilo, P. A.},
title = {Convergence Rate of Incremental Gradient and Incremental Newton Methods},
journal = {SIAM Journal on Optimization},
volume = {29},
number = {4},
pages = {2542-2565},
year = {2019},
doi = {10.1137/17M1147846},

URL = { 
        https://doi.org/10.1137/17M1147846
    
},

}
@inproceedings{2018Levy,
 author = {Levy, Kfir Y. and Yurtsever, Alp and Cevher, Volkan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Online Adaptive Methods, Universality and Acceleration},
 url = {https://proceedings.neurips.cc/paper/2018/file/b0169350cd35566c47ba83c6ec1d6f82-Paper.pdf},
 volume = {31},
 year = {2018}
}

@article{2011duchi11a,
  author  = {John Duchi and Elad Hazan and Yoram Singer},
  title   = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2011},
  volume  = {12},
  number  = {61},
  pages   = {2121-2159},
  url     = {http://jmlr.org/papers/v12/duchi11a.html}
}


@inproceedings{reddi2019,
title={On the Convergence of Adam and Beyond},
author={Sashank J. Reddi and Satyen Kale and Sanjiv Kumar},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=ryQu7f-RZ},
}

@inproceedings{2020Ahn,
 author = {Ahn, Kwangjun and Yun, Chulhee and Sra, Suvrit},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {17526--17535},
 publisher = {Curran Associates, Inc.},
 title = {SGD with shuffling: optimal rates without component convexity and large epoch requirements},
 url = {https://proceedings.neurips.cc/paper/2020/file/cb8acb1dc9821bf74e6ca9068032d623-Paper.pdf},
 volume = {33},
 year = {2020}
}

@InProceedings{pmlr-v130-gower21a,
  title = 	 { SGD for Structured Nonconvex Functions: Learning Rates, Minibatching and Interpolation },
  author =       {Gower, Robert and Sebbouh, Othmane and Loizou, Nicolas},
  booktitle = 	 {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1315--1323},
  year = 	 {2021},
  editor = 	 {Banerjee, Arindam and Fukumizu, Kenji},
  volume = 	 {130},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--15 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v130/gower21a/gower21a.pdf},
  url = 	 {https://proceedings.mlr.press/v130/gower21a.html},
 
}

@article{Lewis2016APM,
  title={A proximal method for composite minimization},
  author={Adrian S. Lewis and Stephen J. Wright},
  journal={Mathematical Programming},
  year={2016},
  volume={158},
  pages={501-546}
}

@article{zhou2019sgd,
  title={Sgd converges to global minimum in deep learning via star-convex path},
  author={Zhou, Yi and Yang, Junjie and Zhang, Huishuai and Liang, Yingbin and Tarokh, Vahid},
  journal={arXiv preprint arXiv:1901.00451},
  year={2019}
}

@inproceedings{hinder2020near,
  title={Near-optimal methods for minimizing star-convex functions and beyond},
  author={Hinder, Oliver and Sidford, Aaron and Sohoni, Nimit},
  booktitle={Conference on Learning Theory},
  pages={1894--1938},
  year={2020},
  organization={PMLR}
}

@article{jin2020convergence,
  title={On The Convergence of First Order Methods for Quasar-Convex Optimization},
  author={Jin, Jikai},
  journal={arXiv preprint arXiv:2010.04937},
  year={2020}
}

@inproceedings{gower2021sgd,
  title={Sgd for structured nonconvex functions: Learning rates, minibatching and interpolation},
  author={Gower, Robert and Sebbouh, Othmane and Loizou, Nicolas},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1315--1323},
  year={2021},
  organization={PMLR}
}

@ARTICLE{Nguyen2022_OptDL,
  author = {Lam M. Nguyen and Trang H. Tran and Marten van Dijk},
  title = {Finite-Sum Optimization: A New Perspective for Convergence to a Global Solution},
  journal = {arXiv preprint arXiv:2202.03524},
  year = {2022}
}

@inproceedings{sankararaman2020impact,
  title={The impact of neural network overparameterization on gradient confusion and stochastic gradient descent},
  author={Sankararaman, Karthik Abinav and De, Soham and Xu, Zheng and Huang, W Ronny and Goldstein, Tom},
  booktitle={International conference on machine learning},
  pages={8469--8479},
  year={2020},
  organization={PMLR}
}

@article{Gurbuzbalaban2019,
   title={Why random reshuffling beats stochastic gradient descent},
   ISSN={1436-4646},
   url={http://dx.doi.org/10.1007/s10107-019-01440-w},
   DOI={10.1007/s10107-019-01440-w},
   journal={Mathematical Programming},
   publisher={Springer Science and Business Media LLC},
   author={Gürbüzbalaban, M. and Ozdaglar, A. and Parrilo, P. A.},
   year={2019},
   month={Oct}
}

@inproceedings{haochen2019random,
  title={Random shuffling beats sgd after finite epochs},
  author={Haochen, Jeff and Sra, Suvrit},
  booktitle={International Conference on Machine Learning},
  pages={2624--2633},
  year={2019},
  organization={PMLR}
}

@article{nguyen2020unified,
  author  = {Lam M. Nguyen and Quoc Tran-Dinh and Dzung T. Phan and Phuong Ha Nguyen and Marten van Dijk},
  title   = {A Unified Convergence Analysis for Shuffling-Type Gradient Methods},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {207},
  pages   = {1-44},
  url     = {http://jmlr.org/papers/v22/20-1238.html}
}

@incollection{pytorch,
    title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
    author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
    booktitle = {Advances in Neural Information Processing Systems 32},
    pages = {8024--8035},
    year = {2019},
    publisher = {Curran Associates, Inc.}
}



@article{mishchenko2020random,
  title={Random reshuffling: Simple analysis with vast improvements},
  author={Mishchenko, Konstantin and Khaled Ragab Bayoumi, Ahmed and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@InProceedings{pmlr-v89-vaswani19a,
  title = 	 {Fast and Faster Convergence of SGD for Over-Parameterized Models and an Accelerated Perceptron},
  author =       {Vaswani, Sharan and Bach, Francis and Schmidt, Mark},
  booktitle = 	 {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1195--1204},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
  volume = 	 {89},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {16--18 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v89/vaswani19a/vaswani19a.pdf},
  url = 	 {https://proceedings.mlr.press/v89/vaswani19a.html},
  
}

@misc{schmidt2013fast,
      title={Fast Convergence of Stochastic Gradient Descent under a Strong Growth Condition}, 
      author={Mark Schmidt and Nicolas Le Roux},
      year={2013},
      eprint={1308.6370},
      archivePrefix={arXiv},
      primaryClass={math.OC}
}

@InProceedings{pmlr-v54-de17a,
  title = 	 {{Automated Inference with Adaptive Batches}},
  author = 	 {De, Soham and Yadav, Abhay and Jacobs, David and Goldstein, Tom},
  booktitle = 	 {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1504--1513},
  year = 	 {2017},
  editor = 	 {Singh, Aarti and Zhu, Jerry},
  volume = 	 {54},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {20--22 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v54/de17a/de17a.pdf},
  url = 	 {https://proceedings.mlr.press/v54/de17a.html},
 
}

@article{JMLR-hardtGDquasar,
  author  = {Moritz Hardt and Tengyu Ma and Benjamin Recht},
  title   = {Gradient Descent Learns Linear Dynamical Systems},
  journal = {Journal of Machine Learning Research},
  year    = {2018},
  volume  = {19},
  number  = {29},
  pages   = {1-44},
  url     = {http://jmlr.org/papers/v19/16-465.html}
}

@INPROCEEDINGS{ieee_lee_starconvex,
  author={Lee, Jasper C.H. and Valiant, Paul},
  booktitle={2016 IEEE 57th Annual Symposium on Foundations of Computer Science (FOCS)}, 
  title={Optimizing Star-Convex Functions}, 
  year={2016},
  volume={},
  number={},
  pages={603-614},
  doi={10.1109/FOCS.2016.71}}


@article{aaai_2021_Bjorck, title={Characterizing the Loss Landscape in Non-Negative Matrix Factorization}, volume={35}, url={https://ojs.aaai.org/index.php/AAAI/article/view/16836},  number={8}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Bjorck, Johan and Kabra, Anmol and Weinberger, Kilian Q. and Gomes, Carla}, year={2021}, month={May}, pages={6768-6776} }

@InProceedings{pmlr-v28-shamir13,
  title = 	 {Stochastic Gradient Descent for Non-smooth Optimization: Convergence Results and Optimal Averaging Schemes},
  author = 	 {Shamir, Ohad and Zhang, Tong},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {71--79},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/shamir13.pdf},
  url = 	 {https://proceedings.mlr.press/v28/shamir13.html},
  
}


@inproceedings{iclrGoodfellow,
  author    = {Ian J. Goodfellow and
               Yaroslav Bulatov and
               Julian Ibarz and
               Sacha Arnoud and
               Vinay D. Shet},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Multi-digit Number Recognition from Street View Imagery using Deep
               Convolutional Neural Networks},
  booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014,
               Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  year      = {2014},
  url       = {http://arxiv.org/abs/1312.6082},
  timestamp = {Thu, 04 Apr 2019 13:20:07 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/GoodfellowBIAS13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{cvpr_Ciresan,
  author    = {Dan C. Ciresan and
               Ueli Meier and
               J{\"{u}}rgen Schmidhuber},
  title     = {Multi-column deep neural networks for image classification},
  booktitle = {2012 {IEEE} Conference on Computer Vision and Pattern Recognition,
               Providence, RI, USA, June 16-21, 2012},
  pages     = {3642--3649},
  publisher = {{IEEE} Computer Society},
  year      = {2012},
  url       = {https://doi.org/10.1109/CVPR.2012.6248110},
  doi       = {10.1109/CVPR.2012.6248110},
  timestamp = {Wed, 16 Oct 2019 14:14:50 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/CiresanMS12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{icml_Collobert,
  author    = {Ronan Collobert and
               Jason Weston},
  editor    = {William W. Cohen and
               Andrew McCallum and
               Sam T. Roweis},
  title     = {A unified architecture for natural language processing: deep neural
               networks with multitask learning},
  booktitle = {Machine Learning, Proceedings of the Twenty-Fifth International Conference
               {(ICML} 2008), Helsinki, Finland, June 5-9, 2008},
  series    = {{ACM} International Conference Proceeding Series},
  volume    = {307},
  pages     = {160--167},
  publisher = {{ACM}},
  year      = {2008},
  url       = {https://doi.org/10.1145/1390156.1390177},
  doi       = {10.1145/1390156.1390177},
  timestamp = {Wed, 28 Nov 2018 12:57:16 +0100},
  biburl    = {https://dblp.org/rec/conf/icml/CollobertW08.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{coling_Goldberg,
  author    = {Yoav Goldberg and
               Graeme Hirst and
               Yang Liu and
               Meng Zhang},
  title     = {Neural Network Methods for Natural Language Processing},
  journal   = {Comput. Linguistics},
  volume    = {44},
  number    = {1},
  year      = {2018},
  url       = {https://doi.org/10.1162/COLI\_r\_00312},
  doi       = {10.1162/COLI\_r\_00312},
  timestamp = {Tue, 02 Feb 2021 09:27:12 +0100},
  biburl    = {https://dblp.org/rec/journals/coling/GoldbergHLZ18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{cvpr_He015,
  author    = {Kaiming He and
               Jian Sun},
  title     = {Convolutional neural networks at constrained time cost},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
               2015, Boston, MA, USA, June 7-12, 2015},
  pages     = {5353--5360},
  publisher = {{IEEE} Computer Society},
  year      = {2015},
  url       = {https://doi.org/10.1109/CVPR.2015.7299173},
  doi       = {10.1109/CVPR.2015.7299173},
  timestamp = {Wed, 16 Oct 2019 14:14:50 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/He015.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{safran2020good,
  title={How good is SGD with random shuffling?},
  author={Safran, Itay and Shamir, Ohad},
  booktitle={Conference on Learning Theory},
  pages={3250--3284},
  year={2020},
  organization={PMLR}
}

@inproceedings{rajput2020closing,
  title={Closing the convergence gap of SGD without replacement},
  author={Rajput, Shashank and Gupta, Anant and Papailiopoulos, Dimitris},
  booktitle={International Conference on Machine Learning},
  pages={7964--7973},
  year={2020},
  organization={PMLR}
}



@article{chollet2015keras,
  title={Keras},
  author={Chollet, Francois and others},
  year={2015},
  publisher={GitHub},
  url={https://github.com/fchollet/keras},
  journal={GitHub},
}

@misc{diabetes,
    title = {Diabetes dataset},
    author = { Efron, Bradley and  Hastie, Trevor and Johnstone,  Iain and Tibshirani, Robert },
    url = {https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html},
    year= {2004},
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@misc{expectancy,
    title = {Life expectancy and Healthy life expectancy},
    author = {Global Health Observatory Data Repository},
    url = {https://apps.who.int/gho/data/view.main.SDG2016LEXREGv?lang=en},
    source = {https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who},
    year= {2016},
}

@misc{california,
    title = {California Housing},
    author = {StatLib Repository},
    url = {https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html},
    year= {1997},
}


@article{beznosikov2021random,
  title={Random-reshuffled SARAH does not need a full gradient computations},
  author={Beznosikov, Aleksandr and Tak{\'a}{\v{c}}, Martin},
  journal={arXiv preprint arXiv:2111.13322},
  year={2021}
}

@article{khaled2020better,
  title={Better theory for SGD in the nonconvex world},
  author={Khaled, Ahmed and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2002.03329},
  year={2020}
}

@InProceedings{Tran2022_ShufflingNesterov,
  title = 	 {{N}esterov Accelerated Shuffling Gradient Method for Convex Optimization},
  author =       {Tran, Trang H and Scheinberg, Katya and Nguyen, Lam M},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {21703--21732},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/tran22a/tran22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/tran22a.html}
}