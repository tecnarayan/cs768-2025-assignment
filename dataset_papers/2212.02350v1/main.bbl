\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{ahuja2020no}
Chaitanya Ahuja, Dong~Won Lee, Ryo Ishii, and Louis-Philippe Morency.
\newblock No gestures left behind: Learning relationships between spoken
  language and freeform gestures.
\newblock In {\em Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing: Findings}, pages 1884--1895, 2020.

\bibitem{ahuja2020style}
Chaitanya Ahuja, Dong~Won Lee, Yukiko~I Nakano, and Louis-Philippe Morency.
\newblock Style transfer for co-speech gesture animation: A multi-speaker
  conditional-mixture approach.
\newblock In {\em European Conference on Computer Vision}, pages 248--265.
  Springer, 2020.

\bibitem{ahuja2019language2pose}
Chaitanya Ahuja and Louis-Philippe Morency.
\newblock Language2pose: Natural language grounded pose forecasting.
\newblock In {\em 2019 International Conference on 3D Vision (3DV)}, pages
  719--728. IEEE, 2019.

\bibitem{alexanderson2020style}
Simon Alexanderson, Gustav~Eje Henter, Taras Kucherenko, and Jonas Beskow.
\newblock Style-controllable speech-driven gesture synthesis using normalising
  flows.
\newblock In {\em Computer Graphics Forum}, volume~39, pages 487--496. Wiley
  Online Library, 2020.

\bibitem{bai2018empirical}
Shaojie Bai, J~Zico Kolter, and Vladlen Koltun.
\newblock An empirical evaluation of generic convolutional and recurrent
  networks for sequence modeling.
\newblock {\em arXiv preprint arXiv:1803.01271}, 2018.

\bibitem{balakrishnan2018synthesizing}
Guha Balakrishnan, Amy Zhao, Adrian~V Dalca, Fredo Durand, and John Guttag.
\newblock Synthesizing images of humans in unseen poses.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 8340--8348, 2018.

\bibitem{bhattacharya2021text2gestures}
Uttaran Bhattacharya, Nicholas Rewkowski, Abhishek Banerjee, Pooja Guhan,
  Aniket Bera, and Dinesh Manocha.
\newblock Text2gestures: A transformer-based network for generating emotive
  body gestures for virtual agents.
\newblock In {\em 2021 IEEE Virtual Reality and 3D User Interfaces (VR)}, pages
  1--10. IEEE, 2021.

\bibitem{burgoon1990nonverbal}
Judee~K Burgoon, Thomas Birk, and Michael Pfau.
\newblock Nonverbal behaviors, persuasion, and credibility.
\newblock {\em Human communication research}, 17(1):140--169, 1990.

\bibitem{cao2014displaced}
Chen Cao, Qiming Hou, and Kun Zhou.
\newblock Displaced dynamic expression regression for real-time facial tracking
  and animation.
\newblock {\em ACM Transactions on graphics (TOG)}, 33(4):1--10, 2014.

\bibitem{cao2019openpose}
Zhe Cao, Gines Hidalgo, Tomas Simon, Shih-En Wei, and Yaser Sheikh.
\newblock Openpose: realtime multi-person 2d pose estimation using part
  affinity fields.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  43(1):172--186, 2019.

\bibitem{cassell1999speech}
Justine Cassell, David McNeill, and Karl-Erik McCullough.
\newblock Speech-gesture mismatches: Evidence for one underlying representation
  of linguistic and nonlinguistic information.
\newblock {\em Pragmatics \& cognition}, 7(1):1--34, 1999.

\bibitem{cassell1994animated}
Justine Cassell, Catherine Pelachaud, Norman Badler, Mark Steedman, Brett
  Achorn, Tripp Becket, Brett Douville, Scott Prevost, and Matthew Stone.
\newblock Animated conversation: rule-based generation of facial expression,
  gesture \& spoken intonation for multiple conversational agents.
\newblock In {\em Proceedings of the 21st annual conference on Computer
  graphics and interactive techniques}, pages 413--420, 1994.

\bibitem{cassell2004beat}
Justine Cassell, Hannes~H{\"o}gni Vilhj{\'a}lmsson, and Timothy Bickmore.
\newblock Beat: the behavior expression animation toolkit.
\newblock In {\em Life-Like Characters}, pages 163--185. Springer, 2004.

\bibitem{chan2019dance}
Caroline Chan, Shiry Ginosar, Tinghui Zhou, and Alexei~A Efros.
\newblock Everybody dance now.
\newblock In {\em IEEE International Conference on Computer Vision (ICCV)},
  2019.

\bibitem{chen2019hierarchical}
Lele Chen, Ross~K Maddox, Zhiyao Duan, and Chenliang Xu.
\newblock Hierarchical cross-modal talking face generation with dynamic
  pixel-wise loss.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7832--7841, 2019.

\bibitem{ExPose:2020}
Vasileios Choutas, Georgios Pavlakos, Timo Bolkart, Dimitrios Tzionas, and
  Michael~J. Black.
\newblock Monocular expressive body regression through body-driven attention.
\newblock In {\em European Conference on Computer Vision (ECCV)}, 2020.

\bibitem{cudeiro2019capture}
Daniel Cudeiro, Timo Bolkart, Cassidy Laidlaw, Anurag Ranjan, and Michael~J
  Black.
\newblock Capture, learning, and synthesis of 3d speaking styles.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10101--10111, 2019.

\bibitem{de2012interplay}
Jan~P De~Ruiter, Adrian Bangerter, and Paula Dings.
\newblock The interplay between gesture and speech in the production of
  referring expressions: Investigating the tradeoff hypothesis.
\newblock {\em Topics in cognitive science}, 4(2):232--248, 2012.

\bibitem{ferstl2018investigating}
Ylva Ferstl and Rachel McDonnell.
\newblock Investigating the use of recurrent motion modelling for speech
  gesture generation.
\newblock In {\em Proceedings of the 18th International Conference on
  Intelligent Virtual Agents}, pages 93--98, 2018.

\bibitem{ferstl2020adversarial}
Ylva Ferstl, Michael Neff, and Rachel McDonnell.
\newblock Adversarial gesture generation with realistic gesture phasing.
\newblock {\em Computers \& Graphics}, 89:117--130, 2020.

\bibitem{geng20193d}
Zhenglin Geng, Chen Cao, and Sergey Tulyakov.
\newblock 3d guided fine-grained face manipulation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 9821--9830, 2019.

\bibitem{ginosar2019learning}
Shiry Ginosar, Amir Bar, Gefen Kohavi, Caroline Chan, Andrew Owens, and
  Jitendra Malik.
\newblock Learning individual styles of conversational gesture.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 3497--3506, 2019.

\bibitem{habibie2021learning}
Ikhsanul Habibie, Weipeng Xu, Dushyant Mehta, Lingjie Liu, Hans-Peter Seidel,
  Gerard Pons-Moll, Mohamed Elgharib, and Christian Theobalt.
\newblock Learning speech-driven 3d conversational gestures from video.
\newblock {\em arXiv preprint arXiv:2102.06837}, 2021.

\bibitem{hasegawa2018evaluation}
Dai Hasegawa, Naoshi Kaneko, Shinichi Shirakawa, Hiroshi Sakuta, and Kazuhiko
  Sumi.
\newblock Evaluation of speech-to-gesture generation using bi-directional lstm
  network.
\newblock In {\em Proceedings of the 18th International Conference on
  Intelligent Virtual Agents}, pages 79--86, 2018.

\bibitem{hermans2017defense}
Alexander Hermans, Lucas Beyer, and Bastian Leibe.
\newblock In defense of the triplet loss for person re-identification.
\newblock {\em arXiv preprint arXiv:1703.07737}, 2017.

\bibitem{ishi2018}
Carlos~T. Ishi, Daichi Machiyashiki, Ryusuke Mikata, and Hiroshi Ishiguro.
\newblock A speech-driven hand gesture generation method and evaluation in
  android robots.
\newblock {\em IEEE Robotics and Automation Letters}, 3(4):3757--3764, 2018.

\bibitem{johnson2016perceptual}
Justin Johnson, Alexandre Alahi, and Li Fei-Fei.
\newblock Perceptual losses for real-time style transfer and super-resolution.
\newblock In {\em European conference on computer vision}, pages 694--711.
  Springer, 2016.

\bibitem{kendon2004gesture}
Adam Kendon.
\newblock {\em Gesture: Visible action as utterance}.
\newblock Cambridge University Press, 2004.

\bibitem{adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In Yoshua Bengio and Yann LeCun, editors, {\em 3rd International
  Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May
  7-9, 2015, Conference Track Proceedings}, 2015.

\bibitem{kucherenko2020gesticulator}
Taras Kucherenko, Patrik Jonell, Sanne van Waveren, Gustav~Eje Henter, Simon
  Alexandersson, Iolanda Leite, and Hedvig Kjellstr\"{o}m.
\newblock Gesticulator: A framework for semantically-aware speech-driven
  gesture generation.
\newblock In {\em Proceedings of the 2020 International Conference on
  Multimodal Interaction}, ICMI '20, page 242â€“250, New York, NY, USA, 2020.
  Association for Computing Machinery.

\bibitem{li2021audio2gestures}
Jing Li, Di Kang, Wenjie Pei, Xuefei Zhe, Ying Zhang, Zhenyu He, and Linchao
  Bao.
\newblock Audio2gestures: Generating diverse gestures from speech audio with
  conditional variational autoencoders.
\newblock {\em arXiv preprint arXiv:2108.06720}, 2021.

\bibitem{li2021learn}
Ruilong Li, Shan Yang, David~A Ross, and Angjoo Kanazawa.
\newblock Learn to dance with aist++: Music conditioned 3d dance generation.
\newblock {\em arXiv preprint arXiv:2101.08779}, 2021.

\bibitem{liu2022visual}
Xian Liu, Rui Qian, Hang Zhou, Di Hu, Weiyao Lin, Ziwei Liu, Bolei Zhou, and
  Xiaowei Zhou.
\newblock Visual sound localization in the wild by cross-modal interference
  erasing.
\newblock {\em arXiv preprint arXiv:2202.06406}, 2022.

\bibitem{liu2022learning}
Xian Liu, Qianyi Wu, Hang Zhou, Yinghao Xu, Rui Qian, Xinyi Lin, Xiaowei Zhou,
  Wayne Wu, Bo Dai, and Bolei Zhou.
\newblock Learning hierarchical cross-modal association for co-speech gesture
  generation.
\newblock {\em arXiv preprint arXiv:2203.13161}, 2022.

\bibitem{liu2022semantic}
Xian Liu, Yinghao Xu, Qianyi Wu, Hang Zhou, Wayne Wu, and Bolei Zhou.
\newblock Semantic-aware implicit neural audio-driven video portrait
  generation.
\newblock {\em arXiv preprint arXiv:2201.07786}, 2022.

\bibitem{librosa}
{McFee, Brian, Colin Raffel, Dawen Liang, Daniel PW Ellis, Matt McVicar, Eric
  Battenberg, and Oriol Nieto}.
\newblock librosa: Audio and music signal analysis in python, 2015.
\newblock In Proceedings of the 14th python in science conference, pp. 18-25.
  2015.

\bibitem{mcneill2011hand}
David McNeill.
\newblock {\em Hand and mind}.
\newblock De Gruyter Mouton, 2011.

\bibitem{ng2022learning}
Evonne Ng, Hanbyul Joo, Liwen Hu, Hao Li, Trevor Darrell, Angjoo Kanazawa, and
  Shiry Ginosar.
\newblock Learning to listen: Modeling non-deterministic dyadic facial motion.
\newblock {\em arXiv preprint arXiv:2204.08451}, 2022.

\bibitem{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock {\em Advances in neural information processing systems},
  32:8026--8037, 2019.

\bibitem{prajwal2020lip}
KR Prajwal, Rudrabha Mukhopadhyay, Vinay~P Namboodiri, and CV Jawahar.
\newblock A lip sync expert is all you need for speech to lip generation in the
  wild.
\newblock In {\em Proceedings of the 28th ACM International Conference on
  Multimedia}, pages 484--492, 2020.

\bibitem{qian2021speech}
Shenhan Qian, Zhi Tu, YiHao Zhi, Wen Liu, and Shenghua Gao.
\newblock Speech drives templates: Co-speech gesture synthesis with learned
  templates.
\newblock {\em arXiv preprint arXiv:2108.08020}, 2021.

\bibitem{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
  Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.
\newblock {\em OpenAI blog}, 1(8):9, 2019.

\bibitem{richard2021meshtalk}
Alexander Richard, Michael Zollh{\"o}fer, Yandong Wen, Fernando De~la Torre,
  and Yaser Sheikh.
\newblock Meshtalk: 3d face animation from speech using cross-modality
  disentanglement.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1173--1182, 2021.

\bibitem{sadoughi2015msp}
Najmeh Sadoughi, Yang Liu, and Carlos Busso.
\newblock Msp-avatar corpus: Motion capture recordings to study the role of
  discourse functions in the design of intelligent virtual agents.
\newblock In {\em 2015 11th IEEE International Conference and Workshops on
  Automatic Face and Gesture Recognition (FG)}, volume~7, pages 1--6. IEEE,
  2015.

\bibitem{siarohin2019animating}
Aliaksandr Siarohin, St{\'e}phane Lathuili{\`e}re, Sergey Tulyakov, Elisa
  Ricci, and Nicu Sebe.
\newblock Animating arbitrary objects via deep motion transfer.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 2377--2386, 2019.

\bibitem{siarohin2019first}
Aliaksandr Siarohin, St{\'e}phane Lathuili{\`e}re, Sergey Tulyakov, Elisa
  Ricci, and Nicu Sebe.
\newblock First order motion model for image animation.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{siarohin2021motion}
Aliaksandr Siarohin, Oliver~J Woodford, Jian Ren, Menglei Chai, and Sergey
  Tulyakov.
\newblock Motion representations for articulated animation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 13653--13662, 2021.

\bibitem{siyao2022bailando}
Li Siyao, Weijiang Yu, Tianpei Gu, Chunze Lin, Quan Wang, Chen Qian,
  Chen~Change Loy, and Ziwei Liu.
\newblock Bailando: 3d dance generation by actor-critic gpt with choreographic
  memory.
\newblock {\em arXiv preprint arXiv:2203.13055}, 2022.

\bibitem{studdert1994hand}
Michael Studdert-Kennedy.
\newblock Hand and mind: What gestures reveal about thought.
\newblock {\em Language and Speech}, 37(2):203--209, 1994.

\bibitem{takeuchi2017creating}
Kenta Takeuchi, Souichirou Kubota, Keisuke Suzuki, Dai Hasegawa, and Hiroshi
  Sakuta.
\newblock Creating a gesture-speech dataset for speech-based automatic gesture
  generation.
\newblock In {\em International Conference on Human-Computer Interaction},
  pages 198--202. Springer, 2017.

\bibitem{tang2018dance}
Taoran Tang, Jia Jia, and Hanyang Mao.
\newblock Dance with melody: An lstm-autoencoder approach to music-oriented
  dance synthesis.
\newblock In {\em Proceedings of the 26th ACM international conference on
  Multimedia}, pages 1598--1606, 2018.

\bibitem{thies2016face2face}
Justus Thies, Michael Zollhofer, Marc Stamminger, Christian Theobalt, and
  Matthias Nie{\ss}ner.
\newblock Face2face: Real-time face capture and reenactment of rgb videos.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2387--2395, 2016.

\bibitem{tolins2016multimodal}
Jackson Tolins, Kris Liu, Yingying Wang, Jean E~Fox Tree, Marilyn Walker, and
  Michael Neff.
\newblock A multimodal motion-captured corpus of matched and mismatched
  extravert-introvert conversational pairs.
\newblock In {\em Proceedings of the Tenth International Conference on Language
  Resources and Evaluation (LREC'16)}, pages 3469--3476, 2016.

\bibitem{trefethen1997numerical}
Lloyd~N Trefethen and David Bau~III.
\newblock {\em Numerical linear algebra}, volume~50.
\newblock Siam, 1997.

\bibitem{van2017neural}
Aaron Van Den~Oord, Oriol Vinyals, et~al.
\newblock Neural discrete representation learning.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{van1998persona}
Susanne Van~Mulken, Elisabeth Andre, and Jochen M{\"u}ller.
\newblock The persona effect: how substantial is it?
\newblock In {\em People and computers XIII}, pages 53--66. Springer, 1998.

\bibitem{volkova2014mpi}
Ekaterina Volkova, Stephan De~La~Rosa, Heinrich~H B{\"u}lthoff, and Betty
  Mohler.
\newblock The mpi emotional body expressions database for narrative scenarios.
\newblock {\em PloS one}, 9:e113647, 2014.

\bibitem{2014Gesture}
P. Wagner, Z. Malisz, and S. Kopp.
\newblock Gesture and speech in interaction: An overview.
\newblock {\em Speech Communication}, 57:209--232, 2014.

\bibitem{wiles2018x2face}
Olivia Wiles, A Koepke, and Andrew Zisserman.
\newblock X2face: A network for controlling face generation using images,
  audio, and pose codes.
\newblock In {\em Proceedings of the European conference on computer vision
  (ECCV)}, pages 670--686, 2018.

\bibitem{wilson2017hand}
Jason~R Wilson, Nah~Young Lee, Annie Saechao, Sharon Hershenson, Matthias
  Scheutz, and Linda Tickle-Degnen.
\newblock Hand gestures and verbal acknowledgments improve human-robot rapport.
\newblock In {\em International Conference on Social Robotics}, pages 334--344.
  Springer, 2017.

\bibitem{winata2020lightweight}
Genta~Indra Winata, Samuel Cahyawijaya, Zhaojiang Lin, Zihan Liu, and Pascale
  Fung.
\newblock Lightweight and efficient end-to-end speech recognition using
  low-rank transformer.
\newblock In {\em ICASSP 2020-2020 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pages 6144--6148. IEEE, 2020.

\bibitem{xu2022freeform}
Jing Xu, Wei Zhang, Yalong Bai, Qibin Sun, and Tao Mei.
\newblock Freeform body motion generation from speech.
\newblock {\em arXiv preprint arXiv:2203.02291}, 2022.

\bibitem{yang2020statistics}
Yanzhe Yang, Jimei Yang, and Jessica Hodgins.
\newblock Statistics-based motion synthesis for social conversations.
\newblock In {\em Computer Graphics Forum}, volume~39, pages 201--212. Wiley
  Online Library, 2020.

\bibitem{yazdian2022gesturevec}
Payam~Jome Yazdian, Mo Chen, and Angelica Lim.
\newblock Gesture2vec: Clustering gestures using representation learning
  methods for co-speech gesture generation, 2022.

\bibitem{yoon2020speech}
Youngwoo Yoon, Bok Cha, Joo-Haeng Lee, Minsu Jang, Jaeyeon Lee, Jaehong Kim,
  and Geehyuk Lee.
\newblock Speech gesture generation from the trimodal context of text, audio,
  and speaker identity.
\newblock {\em ACM Transactions on Graphics (TOG)}, 39(6):1--16, 2020.

\bibitem{yoon2019robots}
Youngwoo Yoon, Woo-Ri Ko, Minsu Jang, Jaeyeon Lee, Jaehong Kim, and Geehyuk
  Lee.
\newblock Robots learn social skills: End-to-end learning of co-speech gesture
  generation for humanoid robots.
\newblock In {\em 2019 International Conference on Robotics and Automation
  (ICRA)}, pages 4303--4309. IEEE, 2019.

\bibitem{yu2020audio}
Jianwei Yu, Shi-Xiong Zhang, Jian Wu, Shahram Ghorbani, Bo Wu, Shiyin Kang,
  Shansong Liu, Xunying Liu, Helen Meng, and Dong Yu.
\newblock Audio-visual recognition of overlapped speech for the lrs2 dataset.
\newblock In {\em ICASSP 2020-2020 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pages 6984--6988. IEEE, 2020.

\bibitem{zakharov2019few}
Egor Zakharov, Aliaksandra Shysheya, Egor Burkov, and Victor Lempitsky.
\newblock Few-shot adversarial learning of realistic neural talking head
  models.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 9459--9468, 2019.

\bibitem{zhou2021pose}
Hang Zhou, Yasheng Sun, Wayne Wu, Chen~Change Loy, Xiaogang Wang, and Ziwei
  Liu.
\newblock Pose-controllable talking face generation by implicitly modularized
  audio-visual representation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, 2021.

\end{thebibliography}
