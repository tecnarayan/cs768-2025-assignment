\begin{thebibliography}{84}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bouzos et~al.(2023)Bouzos, Andreadis, and Mitianoudis]{bouzos2023convolutional}
Bouzos, O., Andreadis, I., and Mitianoudis, N.
\newblock A convolutional neural network-based conditional random field model for structured multi-focus image fusion robust to noise.
\newblock \emph{IEEE Transactions on Image Processing}, 2023.

\bibitem[Brooks et~al.(2023)Brooks, Holynski, and Efros]{brooks2023instructpix2pix}
Brooks, T., Holynski, A., and Efros, A.~A.
\newblock Instructpix2pix: Learning to follow image editing instructions.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition ({CVPR})}, pp.\  18392--18402, 2023.

\bibitem[Cai et~al.(2018)Cai, Gu, and Zhang]{cai2018learning}
Cai, J., Gu, S., and Zhang, L.
\newblock Learning a deep single image contrast enhancer from multi-exposure images.
\newblock \emph{IEEE Transactions on Image Processing}, 27\penalty0 (4):\penalty0 2049--2062, 2018.

\bibitem[Deng \& Dragotti(2021)Deng and Dragotti]{DBLP:journals/pami/0002D21}
Deng, X. and Dragotti, P.~L.
\newblock Deep convolutional neural network for multi-modal image restoration and fusion.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 43\penalty0 (10):\penalty0 3333--3348, 2021.

\bibitem[Deng et~al.(2021)Deng, Zhang, Xu, Gu, and Duan]{deng2021deep}
Deng, X., Zhang, Y., Xu, M., Gu, S., and Duan, Y.
\newblock Deep coupled feedback network for joint exposure fusion and image super-resolution.
\newblock \emph{IEEE Transactions on Image Processing}, 30:\penalty0 3098--3112, 2021.

\bibitem[Gao et~al.(2022)Gao, Deng, Xu, Xu, and Dragotti]{DBLP:journals/tip/GaoDXXD22}
Gao, F., Deng, X., Xu, M., Xu, J., and Dragotti, P.~L.
\newblock Multi-modal convolutional dictionary learning.
\newblock \emph{IEEE Transactions on Image Processing}, 31:\penalty0 1325--1339, 2022.

\bibitem[Guan et~al.(2023)Guan, Xu, Yao, Wang, and Xiong]{guan2023mutual}
Guan, Y., Xu, R., Yao, M., Wang, L., and Xiong, Z.
\newblock Mutual-guided dynamic network for image fusion.
\newblock In \emph{Proceedings of the ACM International Conference on Multimedia ({ACM MM})}, pp.\  1779--1788, 2023.

\bibitem[Guo et~al.(2019)Guo, Nie, Cao, Zhou, Mei, and He]{DBLP:journals/tmm/GuoNCZMH19}
Guo, X., Nie, R., Cao, J., Zhou, D., Mei, L., and He, K.
\newblock Fusegan: Learning to fuse multi-focus image via conditional generative adversarial network.
\newblock \emph{IEEE Transactions on Multimedia}, 21\penalty0 (8):\penalty0 1982--1996, 2019.

\bibitem[Han et~al.(2022)Han, Li, Guo, and Ma]{han2022multi}
Han, D., Li, L., Guo, X., and Ma, J.
\newblock Multi-exposure image fusion via deep perceptual enhancement.
\newblock \emph{Information Fusion}, 79:\penalty0 248--262, 2022.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{HeZRS16}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition ({CVPR})}, pp.\  770--778, 2016.

\bibitem[Hu et~al.(2023)Hu, Jiang, Liu, and Ma]{hu2023zmff}
Hu, X., Jiang, J., Liu, X., and Ma, J.
\newblock Zmff: Zero-shot multi-focus image fusion.
\newblock \emph{Information Fusion}, 92:\penalty0 127--138, 2023.

\bibitem[Huang et~al.(2024)Huang, Liu, Qin, Li, Zhang, Liu, Magno, and Qi]{huang2024billm}
Huang, W., Liu, Y., Qin, H., Li, Y., Zhang, S., Liu, X., Magno, M., and Qi, X.
\newblock Billm: Pushing the limit of post-training quantization for llms.
\newblock \emph{arXiv preprint arXiv:2402.04291}, 2024.

\bibitem[James \& Dasarathy(2014)James and Dasarathy]{DBLP:journals/inffus/JamesD14}
James, A.~P. and Dasarathy, B.~V.
\newblock Medical image fusion: {A} survey of the state of the art.
\newblock \emph{Information Fusion}, 19:\penalty0 4--19, 2014.

\bibitem[Jiang et~al.(2022)Jiang, Zhang, Fan, and Liu]{DBLP:conf/mm/JiangZ0L22}
Jiang, Z., Zhang, Z., Fan, X., and Liu, R.
\newblock Towards all weather and unobstructed multi-spectral image stitching: Algorithm and benchmark.
\newblock In \emph{Proceedings of the ACM International Conference on Multimedia ({ACM MM})}, pp.\  3783--3791, 2022.

\bibitem[Johnson \& Becker()Johnson and Becker]{HarvardMedical}
Johnson, B.~A. and Becker, J.~A.
\newblock Harvard medical website.
\newblock \url{http://www.med.harvard.edu/AANLIB/home.html}.

\bibitem[Jung et~al.(2020)Jung, Kim, Jang, Ha, and Sohn]{jung2020unsupervised}
Jung, H., Kim, Y., Jang, H., Ha, N., and Sohn, K.
\newblock Unsupervised deep image fusion with structure tensor representations.
\newblock \emph{IEEE Transactions on Image Processing}, 29:\penalty0 3845--3858, 2020.

\bibitem[Kirillov et~al.(2023)Kirillov, Mintun, Ravi, Mao, Rolland, Gustafson, Xiao, Whitehead, Berg, Lo, Dollar, and Girshick]{Kirillov_2023_ICCV}
Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao, T., Whitehead, S., Berg, A.~C., Lo, W.-Y., Dollar, P., and Girshick, R.
\newblock Segment anything.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pp.\  4015--4026, October 2023.

\bibitem[Li \& Wu(2018)Li and Wu]{li2018densefuse}
Li, H. and Wu, X.-J.
\newblock Densefuse: A fusion approach to infrared and visible images.
\newblock \emph{IEEE Transactions on Image Processing}, 28\penalty0 (5):\penalty0 2614--2623, 2018.

\bibitem[Li et~al.(2023{\natexlab{a}})Li, Xu, Wu, Lu, and Kittler]{li2023lrrnet}
Li, H., Xu, T., Wu, X., Lu, J., and Kittler, J.
\newblock Lrrnet: {A} novel representation learning guided fusion network for infrared and visible images.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 45\penalty0 (9):\penalty0 11040--11052, 2023{\natexlab{a}}.

\bibitem[Li et~al.(2022)Li, Li, Xiong, and Hoi]{DBLP:conf/icml/0001LXH22}
Li, J., Li, D., Xiong, C., and Hoi, S. C.~H.
\newblock {BLIP:} bootstrapping language-image pre-training for unified vision-language understanding and generation.
\newblock In \emph{Proceedings of the International Conference on Machine Learning ({ICML})}, pp.\  12888--12900, 2022.

\bibitem[Li et~al.(2023{\natexlab{b}})Li, Li, Savarese, and Hoi]{DBLP:conf/icml/0008LSH23}
Li, J., Li, D., Savarese, S., and Hoi, S. C.~H.
\newblock {BLIP-2:} bootstrapping language-image pre-training with frozen image encoders and large language models.
\newblock In \emph{Proceedings of the International Conference on Machine Learning ({ICML})}, pp.\  19730--19742, 2023{\natexlab{b}}.

\bibitem[Li et~al.(2023{\natexlab{c}})Li, Liu, Zhou, Zhang, and Kasabov]{10190200}
Li, J., Liu, J., Zhou, S., Zhang, Q., and Kasabov, N.~K.
\newblock Gesenet: A general semantic-guided network with couple mask ensemble for medical image fusion.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems}, pp.\  1--14, 2023{\natexlab{c}}.

\bibitem[Li et~al.(2023{\natexlab{d}})Li, Liu, Zhou, Zhang, and Kasabov]{li2023gesenet}
Li, J., Liu, J., Zhou, S., Zhang, Q., and Kasabov, N.~K.
\newblock Gesenet: A general semantic-guided network with couple mask ensemble for medical image fusion.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems}, 2023{\natexlab{d}}.

\bibitem[Liang et~al.(2022)Liang, Jiang, Liu, and Ma]{Liang2022ECCV}
Liang, P., Jiang, J., Liu, X., and Ma, J.
\newblock Fusion from decomposition: A self-supervised decomposition approach for image fusion.
\newblock In \emph{Proceedings of the European Conference on Computer Vision (ECCV)}, pp.\  719--735, 2022.

\bibitem[Liu et~al.(2022{\natexlab{a}})Liu, Fan, Huang, Wu, Liu, Zhong, and Luo]{DBLP:conf/cvpr/LiuFHWLZL22}
Liu, J., Fan, X., Huang, Z., Wu, G., Liu, R., Zhong, W., and Luo, Z.
\newblock Target-aware dual adversarial learning and a multi-scenario multi-modality benchmark to fuse infrared and visible for object detection.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition ({CVPR})}, pp.\  5792--5801, 2022{\natexlab{a}}.

\bibitem[Liu et~al.(2022{\natexlab{b}})Liu, Shang, Liu, and Fan]{liu2022attention}
Liu, J., Shang, J., Liu, R., and Fan, X.
\newblock Attention-guided global-local adversarial learning for detail-preserving multi-exposure image fusion.
\newblock \emph{IEEE Transactions on Circuits and Systems for Video Technology}, 32\penalty0 (8):\penalty0 5026--5040, 2022{\natexlab{b}}.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Liu, Wu, Ma, Liu, Zhong, Luo, and Fan]{Liu_2023_ICCV}
Liu, J., Liu, Z., Wu, G., Ma, L., Liu, R., Zhong, W., Luo, Z., and Fan, X.
\newblock Multi-interactive feature learning and a full-time multi-modality benchmark for image fusion and segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pp.\  8115--8124, October 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Wu, Luan, Jiang, Liu, and Fan]{liu2023holoco}
Liu, J., Wu, G., Luan, J., Jiang, Z., Liu, R., and Fan, X.
\newblock Holoco: Holistic and local contrastive learning network for multi-exposure image fusion.
\newblock \emph{Information Fusion}, 95:\penalty0 237--249, 2023{\natexlab{b}}.

\bibitem[Liu et~al.(2017)Liu, Chen, Peng, and Wang]{liu2017multi}
Liu, Y., Chen, X., Peng, H., and Wang, Z.
\newblock Multi-focus image fusion with a deep convolutional neural network.
\newblock \emph{Information Fusion}, 36:\penalty0 191--207, 2017.

\bibitem[Ma et~al.(2020{\natexlab{a}})Ma, Liao, Zhang, Liu, and Xue]{ma2020alpha}
Ma, H., Liao, Q., Zhang, J., Liu, S., and Xue, J.-H.
\newblock An $\alpha$-matte boundary defocus model-based cascaded network for multi-focus image fusion.
\newblock \emph{IEEE Transactions on Image Processing}, 29:\penalty0 8668--8679, 2020{\natexlab{a}}.

\bibitem[Ma et~al.(2019{\natexlab{a}})Ma, Ma, and Li]{ma2019infrared}
Ma, J., Ma, Y., and Li, C.
\newblock Infrared and visible image fusion methods and applications: A survey.
\newblock \emph{Information Fusion}, 45:\penalty0 153--178, 2019{\natexlab{a}}.

\bibitem[Ma et~al.(2019{\natexlab{b}})Ma, Yu, Liang, Li, and Jiang]{ma2019fusiongan}
Ma, J., Yu, W., Liang, P., Li, C., and Jiang, J.
\newblock Fusiongan: A generative adversarial network for infrared and visible image fusion.
\newblock \emph{Information Fusion}, 48:\penalty0 11--26, 2019{\natexlab{b}}.

\bibitem[Ma et~al.(2017)Ma, Li, Yong, Wang, Meng, and Zhang]{DBLP:journals/tip/MaLYWMZ17}
Ma, K., Li, H., Yong, H., Wang, Z., Meng, D., and Zhang, L.
\newblock Robust multi-exposure image fusion: {A} structural patch decomposition approach.
\newblock \emph{IEEE Transactions on Image Processing}, 26\penalty0 (5):\penalty0 2519--2532, 2017.

\bibitem[Ma et~al.(2020{\natexlab{b}})Ma, Duanmu, Zhu, Fang, and Wang]{DBLP:journals/tip/MaDZFW20}
Ma, K., Duanmu, Z., Zhu, H., Fang, Y., and Wang, Z.
\newblock Deep guided learning for fast multi-exposure image fusion.
\newblock \emph{IEEE Transactions on Image Processing}, 2020{\natexlab{b}}.

\bibitem[Nejati et~al.(2015)Nejati, Samavi, and Shirani]{nejati2015multi}
Nejati, M., Samavi, S., and Shirani, S.
\newblock Multi-focus image fusion using dictionary-based sparse representation.
\newblock \emph{Information Fusion}, 25:\penalty0 72--84, 2015.

\bibitem[Nguyen et~al.(2022)Nguyen, Suganuma, and Okatani]{nguyen2022grit}
Nguyen, V.-Q., Suganuma, M., and Okatani, T.
\newblock Grit: Faster and better image captioning transformer using dual visual features.
\newblock In \emph{Proceedings of the European conference on computer vision ({ECCV})}, pp.\  167--184. Springer, 2022.

\bibitem[OpenAI(2023)]{OpenAI_GPT4_2023}
OpenAI.
\newblock Gpt-4 technical report.
\newblock \emph{ArXiv}, abs/2303.08774, 2023.
\newblock URL \url{https://arxiv.org/abs/2303.08774}.

\bibitem[{OpenAI}(2023)]{chatgpt}
{OpenAI}.
\newblock \emph{ChatGPT}, 2023.
\newblock URL \url{https://www.openai.com/chatgpt}.

\bibitem[Prabhakar et~al.(2017)Prabhakar, Srikar, and Babu]{prabhakar2017deepfuse}
Prabhakar, K.~R., Srikar, V.~S., and Babu, R.~V.
\newblock Deepfuse: A deep unsupervised approach for exposure fusion with extreme exposure image pairs.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision ({ICCV})}, pp.\  4724--4732, 2017.

\bibitem[Qin et~al.(2024)Qin, Ma, Zheng, Li, Zhang, Liu, Luo, Liu, and Magno]{qin2024accurate}
Qin, H., Ma, X., Zheng, X., Li, X., Zhang, Y., Liu, S., Luo, J., Liu, X., and Magno, M.
\newblock Accurate lora-finetuning quantization of llms via information retention.
\newblock \emph{arXiv preprint arXiv:2402.05445}, 2024.

\bibitem[Qu et~al.(2022)Qu, Liu, Wang, and Song]{qu2022transmef}
Qu, L., Liu, S., Wang, M., and Song, Z.
\newblock Transmef: A transformer-based multi-exposure image fusion framework using self-supervised multi-task learning.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence ({AAAI})}, volume~36, pp.\  2126--2134, 2022.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{Proceedings of the International conference on machine learning ({ICML})}, pp.\  8748--8763, 2021.

\bibitem[Ramesh et~al.(2021)Ramesh, Pavlov, Goh, Gray, Voss, Radford, Chen, and Sutskever]{ramesh2021zero}
Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., and Sutskever, I.
\newblock Zero-shot text-to-image generation.
\newblock In \emph{Proceedings of the International conference on machine learning ({ICML})}, pp.\  8821--8831, 2021.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{ramesh2022hierarchical}
Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 1\penalty0 (2):\penalty0 3, 2022.

\bibitem[Sun et~al.(2022)Sun, Cao, Zhu, and Hu]{DBLP:conf/mm/SunCZH22}
Sun, Y., Cao, B., Zhu, P., and Hu, Q.
\newblock Detfusion: {A} detection-driven infrared and visible image fusion network.
\newblock In \emph{Proceedings of the ACM International Conference on Multimedia ({ACM MM})}, pp.\  4003--4011, 2022.

\bibitem[Tang et~al.(2022{\natexlab{a}})Tang, Deng, Ma, Huang, and Ma]{DBLP:journals/ieeejas/TangDMHM22}
Tang, L., Deng, Y., Ma, Y., Huang, J., and Ma, J.
\newblock Superfusion: {A} versatile image registration and fusion network with semantic awareness.
\newblock \emph{IEEE/CAA Journal of Automatica Sinica}, 9\penalty0 (12):\penalty0 2121--2137, 2022{\natexlab{a}}.

\bibitem[Tang et~al.(2022{\natexlab{b}})Tang, Yuan, and Ma]{DBLP:journals/inffus/TangYM22}
Tang, L., Yuan, J., and Ma, J.
\newblock Image fusion in the loop of high-level vision tasks: {A} semantic-aware real-time infrared and visible image fusion network.
\newblock \emph{Information Fusion}, 82:\penalty0 28--42, 2022{\natexlab{b}}.

\bibitem[Tang et~al.(2022{\natexlab{c}})Tang, Yuan, Zhang, Jiang, and Ma]{DBLP:journals/inffus/TangYZJM22}
Tang, L., Yuan, J., Zhang, H., Jiang, X., and Ma, J.
\newblock Piafusion: {A} progressive infrared and visible image fusion network based on illumination aware.
\newblock \emph{Information Fusion}, 83-84:\penalty0 79--92, 2022{\natexlab{c}}.

\bibitem[Tang et~al.(2022{\natexlab{d}})Tang, He, Liu, and Duan]{tang2022matr}
Tang, W., He, F., Liu, Y., and Duan, Y.
\newblock Matr: Multimodal medical image fusion via multiscale adaptive transformer.
\newblock \emph{IEEE Transactions on Image Processing}, 31:\penalty0 5134--5149, 2022{\natexlab{d}}.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{touvron2023llama}
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix, T., Rozi{\`e}re, B., Goyal, N., Hambro, E., Azhar, F., et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[Wang et~al.(2022{\natexlab{a}})Wang, Liu, Fan, and Liu]{DBLP:conf/ijcai/WangLFL22}
Wang, D., Liu, J., Fan, X., and Liu, R.
\newblock Unsupervised misaligned infrared and visible image fusion via cross-modality image generation and registration.
\newblock In \emph{Proceedings of the International Joint Conferences on Artificial Intelligence ({IJCAI})}, pp.\  3508--3515, 2022{\natexlab{a}}.

\bibitem[Wang et~al.(2021)Wang, Yu, Yu, Dai, Tsvetkov, and Cao]{wang2021simvlm}
Wang, Z., Yu, J., Yu, A.~W., Dai, Z., Tsvetkov, Y., and Cao, Y.
\newblock Simvlm: Simple visual language model pretraining with weak supervision.
\newblock \emph{arXiv preprint arXiv:2108.10904}, 2021.

\bibitem[Wang et~al.(2022{\natexlab{b}})Wang, Li, Duan, and Zhang]{wang2022self}
Wang, Z., Li, X., Duan, H., and Zhang, X.
\newblock A self-supervised residual feature learning model for multifocus image fusion.
\newblock \emph{IEEE Transactions on Image Processing}, 31:\penalty0 4527--4542, 2022{\natexlab{b}}.

\bibitem[Wang et~al.(2023)Wang, Li, Zhao, Duan, Wang, Liu, and Zhang]{wang2023multi}
Wang, Z., Li, X., Zhao, L., Duan, H., Wang, S., Liu, H., and Zhang, X.
\newblock When multi-focus image fusion networks meet traditional edge-preservation technology.
\newblock \emph{International Journal of Computer Vision}, pp.\  1--24, 2023.

\bibitem[Wen et~al.(2023)Wen, Qin, Du, Fang, Wei, Chen, and Li]{wen2023msgfusion}
Wen, J., Qin, F., Du, J., Fang, M., Wei, X., Chen, C.~P., and Li, P.
\newblock Msgfusion: Medical semantic guided two-branch network for multimodal brain image fusion.
\newblock \emph{IEEE Transactions on Multimedia}, 2023.

\bibitem[Xiao et~al.(2020)Xiao, Xu, Bi, and Li]{xiao2020global}
Xiao, B., Xu, B., Bi, X., and Li, W.
\newblock Global-feature encoding u-net (geu-net) for multi-focus image fusion.
\newblock \emph{IEEE Transactions on Image Processing}, 30:\penalty0 163--175, 2020.

\bibitem[Xiao et~al.(2021)Xiao, Wu, and Bi]{xiao2021dtmnet}
Xiao, B., Wu, H., and Bi, X.
\newblock Dtmnet: a discrete tchebichef moments-based deep neural network for multi-focus image fusion.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition ({CVPR})}, pp.\  43--51, 2021.

\bibitem[Xu \& Ma(2021)Xu and Ma]{DBLP:journals/inffus/Xu021}
Xu, H. and Ma, J.
\newblock Emfusion: An unsupervised enhanced medical image fusion network.
\newblock \emph{Information Fusion}, 76:\penalty0 177--186, 2021.

\bibitem[Xu et~al.(2020{\natexlab{a}})Xu, Ma, Le, Jiang, and Guo]{xu2020aaai}
Xu, H., Ma, J., Le, Z., Jiang, J., and Guo, X.
\newblock Fusiondn: A unified densely connected network for image fusion.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence ({AAAI})}, pp.\  12484--12491, 2020{\natexlab{a}}.

\bibitem[Xu et~al.(2020{\natexlab{b}})Xu, Ma, and Zhang]{xu2020mef}
Xu, H., Ma, J., and Zhang, X.-P.
\newblock Mef-gan: Multi-exposure image fusion via generative adversarial networks.
\newblock \emph{IEEE Transactions on Image Processing}, 29:\penalty0 7203--7216, 2020{\natexlab{b}}.

\bibitem[Xu et~al.(2022{\natexlab{a}})Xu, Ma, Jiang, Guo, and Ling]{9151265}
Xu, H., Ma, J., Jiang, J., Guo, X., and Ling, H.
\newblock U2fusion: {A} unified unsupervised image fusion network.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 44\penalty0 (1):\penalty0 502--518, 2022{\natexlab{a}}.

\bibitem[Xu et~al.(2022{\natexlab{b}})Xu, Ma, Yuan, Le, and Liu]{DBLP:conf/cvpr/Xu0YLL22}
Xu, H., Ma, J., Yuan, J., Le, Z., and Liu, W.
\newblock Rfnet: Unsupervised network for mutually reinforcing multi-modal image registration and fusion.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition ({CVPR})}, pp.\  19647--19656, 2022{\natexlab{b}}.

\bibitem[Xu et~al.(2023)Xu, Yuan, and Ma]{xu2023murf}
Xu, H., Yuan, J., and Ma, J.
\newblock {MURF:} mutually reinforcing multi-modal image registration and fusion.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 45\penalty0 (10):\penalty0 12148--12166, 2023.

\bibitem[Xu et~al.(2015)Xu, Ba, Kiros, Cho, Courville, Salakhudinov, Zemel, and Bengio]{xu2015show}
Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., Zemel, R., and Bengio, Y.
\newblock Show, attend and tell: Neural image caption generation with visual attention.
\newblock In \emph{Proceedings of the International conference on machine learning ({ICML})}, pp.\  2048--2057, 2015.

\bibitem[Xu et~al.(2020{\natexlab{c}})Xu, Ji, Wang, Li, Sun, Zhang, and Zhang]{xu2020towards}
Xu, S., Ji, L., Wang, Z., Li, P., Sun, K., Zhang, C., and Zhang, J.
\newblock Towards reducing severe defocus spread effects for multi-focus image fusion via an optimization based strategy.
\newblock \emph{IEEE Transactions on Computational Imaging}, 6:\penalty0 1561--1570, 2020{\natexlab{c}}.

\bibitem[Xu et~al.(2021)Xu, Zhang, Zhao, Sun, Liu, and Zhang]{DBLP:conf/cvpr/Xu0ZSL021}
Xu, S., Zhang, J., Zhao, Z., Sun, K., Liu, J., and Zhang, C.
\newblock Deep gradient projection networks for pan-sharpening.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition ({CVPR})}, pp.\  1366--1375, 2021.

\bibitem[Yin et~al.(2021{\natexlab{a}})Yin, Chen, and Peng]{yin2021two}
Yin, J.-L., Chen, B.-H., and Peng, Y.-T.
\newblock Two exposure fusion using prior-aware generative adversarial network.
\newblock \emph{IEEE Transactions on Multimedia}, 24:\penalty0 2841--2851, 2021{\natexlab{a}}.

\bibitem[Yin et~al.(2021{\natexlab{b}})Yin, Chen, Peng, and Hwang]{yin2021automatic}
Yin, J.-L., Chen, B.-H., Peng, Y.-T., and Hwang, H.
\newblock Automatic intermediate generation with deep reinforcement learning for robust two-exposure image fusion.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems}, 33\penalty0 (12):\penalty0 7853--7862, 2021{\natexlab{b}}.

\bibitem[Zamir et~al.(2022)Zamir, Arora, Khan, Hayat, Khan, and Yang]{DBLP:conf/cvpr/ZamirA0HK022}
Zamir, S.~W., Arora, A., Khan, S., Hayat, M., Khan, F.~S., and Yang, M.
\newblock Restormer: Efficient transformer for high-resolution image restoration.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition ({CVPR})}, pp.\  5718--5729, 2022.

\bibitem[Zhang \& Ma(2021)Zhang and Ma]{DBLP:journals/ijcv/ZhangM21}
Zhang, H. and Ma, J.
\newblock Sdnet: {A} versatile squeeze-and-decomposition network for real-time image fusion.
\newblock \emph{International Journal of Computer Vision}, 129\penalty0 (10):\penalty0 2761--2785, 2021.

\bibitem[Zhang et~al.(2020{\natexlab{a}})Zhang, Liao, Liu, Ma, Yang, and Xue]{zhang2020real}
Zhang, J., Liao, Q., Liu, S., Ma, H., Yang, W., and Xue, J.-H.
\newblock Real-mff: A large realistic multi-focus image dataset with ground truth.
\newblock \emph{Pattern Recognition Letters}, 138:\penalty0 370--377, 2020{\natexlab{a}}.

\bibitem[Zhang et~al.(2023)Zhang, Sun, Chen, Xiao, Shao, Zhang, Chen, and Luo]{zhang2023gpt4roi}
Zhang, S., Sun, P., Chen, S., Xiao, M., Shao, W., Zhang, W., Chen, K., and Luo, P.
\newblock Gpt4roi: Instruction tuning large language model on region-of-interest.
\newblock \emph{arXiv preprint arXiv:2307.03601}, 2023.

\bibitem[Zhang(2021{\natexlab{a}})]{ZHANG2021111}
Zhang, X.
\newblock Benchmarking and comparing multi-exposure image fusion algorithms.
\newblock \emph{Information Fusion}, 74:\penalty0 111--131, 2021{\natexlab{a}}.

\bibitem[Zhang(2021{\natexlab{b}})]{zhang2021deep}
Zhang, X.
\newblock Deep learning-based multi-focus image fusion: A survey and a comparative study.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 44\penalty0 (9):\penalty0 4819--4838, 2021{\natexlab{b}}.

\bibitem[Zhang \& Demiris(2023)Zhang and Demiris]{10088423}
Zhang, X. and Demiris, Y.
\newblock Visible and infrared image fusion using deep learning.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 45\penalty0 (8):\penalty0 10535--10554, 2023.

\bibitem[Zhang et~al.(2020{\natexlab{b}})Zhang, Liu, Sun, Yan, Zhao, and Zhang]{DBLP:journals/inffus/ZhangLSYZZ20}
Zhang, Y., Liu, Y., Sun, P., Yan, H., Zhao, X., and Zhang, L.
\newblock {IFCNN:} {A} general image fusion framework based on convolutional neural network.
\newblock \emph{Information Fusion}, 54:\penalty0 99--118, 2020{\natexlab{b}}.

\bibitem[Zhao(2023)]{Image2Paragraph}
Zhao, H.
\newblock Image.txt: Transform image into unique paragraph.
\newblock \url{https://zhaohengyuan1.github.io/image2paragraph.github.io/}, 2023.

\bibitem[Zhao et~al.(2023{\natexlab{a}})Zhao, Xie, Zhao, He, and Lu]{DBLP:conf/cvpr/ZhaoXZHL23}
Zhao, W., Xie, S., Zhao, F., He, Y., and Lu, H.
\newblock Metafusion: Infrared and visible image fusion via meta-feature embedding from object detection.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition ({CVPR})}, pp.\  13955--13965. {IEEE}, 2023{\natexlab{a}}.

\bibitem[Zhao et~al.(2020)Zhao, Xu, Zhang, Liu, Zhang, and Li]{zhaoijcai2020}
Zhao, Z., Xu, S., Zhang, C., Liu, J., Zhang, J., and Li, P.
\newblock {DIDFuse}: Deep image decomposition for infrared and visible image fusion.
\newblock In \emph{Proceedings of the International Joint Conference on Artificial Intelligence ({IJCAI})}, pp.\  970--976, 2020.

\bibitem[Zhao et~al.(2022{\natexlab{a}})Zhao, Xu, Zhang, Liang, Zhang, and Liu]{DBLP:journals/tcsv/ZhaoXZLZL22}
Zhao, Z., Xu, S., Zhang, J., Liang, C., Zhang, C., and Liu, J.
\newblock Efficient and model-based infrared and visible image fusion via algorithm unrolling.
\newblock \emph{IEEE Transactions on Circuits and Systems for Video Technology}, 32\penalty0 (3):\penalty0 1186--1196, 2022{\natexlab{a}}.

\bibitem[Zhao et~al.(2022{\natexlab{b}})Zhao, Zhang, Xu, Lin, and Pfister]{DBLP:conf/cvpr/ZhaoZXLP22}
Zhao, Z., Zhang, J., Xu, S., Lin, Z., and Pfister, H.
\newblock Discrete cosine transform network for guided depth map super-resolution.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition ({CVPR})}, pp.\  5687--5697, 2022{\natexlab{b}}.

\bibitem[Zhao et~al.(2023{\natexlab{b}})Zhao, Bai, Zhang, Zhang, Xu, Lin, Timofte, and Van~Gool]{Zhao_2023_CVPR}
Zhao, Z., Bai, H., Zhang, J., Zhang, Y., Xu, S., Lin, Z., Timofte, R., and Van~Gool, L.
\newblock Cddfuse: Correlation-driven dual-branch feature decomposition for multi-modality image fusion.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  5906--5916, June 2023{\natexlab{b}}.

\bibitem[Zhao et~al.(2023{\natexlab{c}})Zhao, Bai, Zhu, Zhang, Xu, Zhang, Zhang, Meng, Timofte, and Van~Gool]{Zhao_2023_ICCV}
Zhao, Z., Bai, H., Zhu, Y., Zhang, J., Xu, S., Zhang, Y., Zhang, K., Meng, D., Timofte, R., and Van~Gool, L.
\newblock Ddfm: Denoising diffusion model for multi-modality image fusion.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pp.\  8082--8093, October 2023{\natexlab{c}}.

\bibitem[Zhu et~al.(2023)Zhu, Chen, Shen, Li, and Elhoseiny]{zhu2023minigpt}
Zhu, D., Chen, J., Shen, X., Li, X., and Elhoseiny, M.
\newblock Minigpt-4: Enhancing vision-language understanding with advanced large language models.
\newblock \emph{arXiv preprint arXiv:2304.10592}, 2023.

\end{thebibliography}
