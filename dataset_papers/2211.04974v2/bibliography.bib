@inproceedings{wagenmaker2022beyond,
  title={Beyond no regret: Instance-dependent pac reinforcement learning},
  author={Wagenmaker, Andrew J and Simchowitz, Max and Jamieson, Kevin},
  booktitle={Conference on Learning Theory},
  pages={358--418},
  year={2022},
  organization={PMLR}
}

@article{wagenmaker2023instance,
  title={Instance-Optimality in Interactive Decision Making: Toward a Non-Asymptotic Theory},
  author={Wagenmaker, Andrew and Foster, Dylan J},
  journal={arXiv preprint arXiv:2304.12466},
  year={2023}
}

@article{wagenmaker2022instance,
  title={Instance-Dependent Near-Optimal Policy Identification in Linear MDPs via Online Experiment Design},
  author={Wagenmaker, Andrew and Jamieson, Kevin},
  journal={arXiv preprint arXiv:2207.02575},
  year={2022}
}

@article{yin2022near,
  title={Near-optimal offline reinforcement learning with linear representation: Leveraging variance information with pessimism},
  author={Yin, Ming and Duan, Yaqi and Wang, Mengdi and Wang, Yu-Xiang},
  journal={arXiv preprint arXiv:2203.05804},
  year={2022}
}

@article{ball2023efficient,
  title={Efficient online reinforcement learning with offline data},
  author={Ball, Philip J and Smith, Laura and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2302.02948},
  year={2023}
}

@article{nakamoto2023cal,
  title={Cal-QL: Calibrated offline RL pre-training for efficient online fine-tuning},
  author={Nakamoto, Mitsuhiko and Zhai, Yuexiang and Singh, Anikait and Mark, Max Sobol and Ma, Yi and Finn, Chelsea and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2303.05479},
  year={2023}
}

@article{zheng2023adaptive,
  title={Adaptive Policy Learning for Offline-to-Online Reinforcement Learning},
  author={Zheng, Han and Luo, Xufang and Wei, Pengfei and Song, Xuan and Li, Dongsheng and Jiang, Jing},
  journal={arXiv preprint arXiv:2303.07693},
  year={2023}
}

@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{simchowitz2019non,
  title={Non-asymptotic gap-dependent regret bounds for tabular mdps},
  author={Simchowitz, Max and Jamieson, Kevin G},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{tennenholtz2021bandits,
  title={Bandits with partially observable confounded data},
  author={Tennenholtz, Guy and Shalit, Uri and Mannor, Shie and Efroni, Yonathan},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={430--439},
  year={2021},
  organization={PMLR}
}

@inproceedings{pacchiano2021towards,
  title={Towards tractable optimism in model-based reinforcement learning},
  author={Pacchiano, Aldo and Ball, Philip and Parker-Holder, Jack and Choromanski, Krzysztof and Roberts, Stephen},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1413--1423},
  year={2021},
  organization={PMLR}
}

@article{jin2021bellman,
  title={Bellman Eluder Dimension: New Rich Classes of RL Problems, and Sample-Efficient Algorithms},
  author={Jin, Chi and Liu, Qinghua and Miryoosefi, Sobhan},
  journal={arXiv preprint arXiv:2102.00815},
  year={2021}
}

@article{foster2021statistical,
  title={The Statistical Complexity of Interactive Decision Making},
  author={Foster, Dylan J and Kakade, Sham M and Qian, Jian and Rakhlin, Alexander},
  journal={arXiv preprint arXiv:2112.13487},
  year={2021}
}

@inproceedings{zanette2020learning,
  title={Learning near optimal policies with low inherent bellman error},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={10978--10989},
  year={2020},
  organization={PMLR}
}

@article{xie2022role,
  title={The Role of Coverage in Online Reinforcement Learning},
  author={Xie, Tengyang and Foster, Dylan J and Bai, Yu and Jiang, Nan and Kakade, Sham M},
  journal={arXiv preprint arXiv:2210.04157},
  year={2022}
}

@article{he2020logarithmic,
  title={Logarithmic regret for reinforcement learning with linear function approximation},
  author={He, Jiafan and Zhou, Dongruo and Gu, Quanquan},
  journal={arXiv preprint arXiv:2011.11566},
  year={2020}
}

@inproceedings{ayoub2020model,
  title={Model-based reinforcement learning with value-targeted regression},
  author={Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin},
  booktitle={International Conference on Machine Learning},
  pages={463--474},
  year={2020},
  organization={PMLR}
}


@inproceedings{zanette2019tighter,
  title={Tighter problem-dependent regret bounds in reinforcement learning without domain knowledge using value function bounds},
  author={Zanette, Andrea and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={7304--7312},
  year={2019},
  organization={PMLR}
}

@inproceedings{zanette2020frequentist,
  title={Frequentist regret bounds for randomized least-squares value iteration},
  author={Zanette, Andrea and Brandfonbrener, David and Brunskill, Emma and Pirotta, Matteo and Lazaric, Alessandro},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1954--1964},
  year={2020},
  organization={PMLR}
}

@article{kearns2002near,
  title={Near-optimal reinforcement learning in polynomial time},
  author={Kearns, Michael and Singh, Satinder},
  journal={Machine learning},
  volume={49},
  number={2},
  pages={209--232},
  year={2002},
  publisher={Springer}
}

@inproceedings{yang2020reinforcement,
  title={Reinforcement learning in feature space: Matrix bandit, kernels, and regret bound},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={10746--10756},
  year={2020},
  organization={PMLR}
}

@inproceedings{weisz2021exponential,
  title={Exponential lower bounds for planning in mdps with linearly-realizable optimal action-value functions},
  author={Weisz, Gell{\'e}rt and Amortila, Philip and Szepesv{\'a}ri, Csaba},
  booktitle={Algorithmic Learning Theory},
  pages={1237--1264},
  year={2021},
  organization={PMLR}
}


@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}
@article{dann2017unifying,
  title={Unifying PAC and regret: Uniform PAC bounds for episodic reinforcement learning},
  author={Dann, Christoph and Lattimore, Tor and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}
@article{auer2008near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Auer, Peter and Jaksch, Thomas and Ortner, Ronald},
  journal={Advances in neural information processing systems},
  volume={21},
  year={2008}
}

@article{tewari2007optimistic,
  title={Optimistic linear programming gives logarithmic regret for irreducible MDPs},
  author={Tewari, Ambuj and Bartlett, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={20},
  year={2007}
}

@inproceedings{zhou2021provably,
  title={Provably efficient reinforcement learning for discounted mdps with feature mapping},
  author={Zhou, Dongruo and He, Jiafan and Gu, Quanquan},
  booktitle={International Conference on Machine Learning},
  pages={12793--12802},
  year={2021},
  organization={PMLR}
}


@article{agrawal2017optimistic,
  title={Optimistic posterior sampling for reinforcement learning: worst-case regret bounds},
  author={Agrawal, Shipra and Jia, Randy},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@article{munos2008finite,
  title={Finite-Time Bounds for Fitted Value Iteration.},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={5},
  year={2008}
}

@inproceedings{wagenmaker2022reward,
  title={Reward-free rl is no harder than reward-aware rl in linear markov decision processes},
  author={Wagenmaker, Andrew J and Chen, Yifang and Simchowitz, Max and Du, Simon and Jamieson, Kevin},
  booktitle={International Conference on Machine Learning},
  pages={22430--22456},
  year={2022},
  organization={PMLR}
}

@article{zhang2021variance,
  title={Variance-Aware Confidence Set: Variance-Dependent Bound for Linear Bandits and Horizon-Free Bound for Linear Mixture MDP},
  author={Zhang, Zihan and Yang, Jiaqi and Ji, Xiangyang and Du, Simon S},
  journal={arXiv preprint arXiv:2101.12745},
  year={2021}
}

@article{zhou2020nearly,
  title={Nearly Minimax Optimal Reinforcement Learning for Linear Mixture Markov Decision Processes},
  author={Zhou, Dongruo and Gu, Quanquan and Szepesvari, Csaba},
  journal={arXiv preprint arXiv:2012.08507},
  year={2020}
}


@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International conference on machine learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}

@inproceedings{chen2019information,
  title={Information-theoretic considerations in batch reinforcement learning},
  author={Chen, Jinglin and Jiang, Nan},
  booktitle={International Conference on Machine Learning},
  pages={1042--1051},
  year={2019},
  organization={PMLR}
}


@article{kidambi2020morel,
  title={Morel: Model-based offline reinforcement learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21810--21823},
  year={2020}
}

@inproceedings{xie2021batch,
  title={Batch value-function approximation with only realizability},
  author={Xie, Tengyang and Jiang, Nan},
  booktitle={International Conference on Machine Learning},
  pages={11404--11413},
  year={2021},
  organization={PMLR}
}

@article{rashidinejad2021bridging,
  title={Bridging offline reinforcement learning and imitation learning: A tale of pessimism},
  author={Rashidinejad, Paria and Zhu, Banghua and Ma, Cong and Jiao, Jiantao and Russell, Stuart},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={11702--11716},
  year={2021}
}

@article{yin2021near,
  title={Near-optimal offline reinforcement learning via double variance reduction},
  author={Yin, Ming and Bai, Yu and Wang, Yu-Xiang},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={7677--7688},
  year={2021}
}

@article{antos2008learning,
  title={Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Machine Learning},
  volume={71},
  number={1},
  pages={89--129},
  year={2008},
  publisher={Springer}
}


@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14129--14142},
  year={2020}
}

@article{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{tirinzoni2022optimistic,
  title={Optimistic PAC Reinforcement Learning: the Instance-Dependent View},
  author={Tirinzoni, Andrea and Al-Marjani, Aymen and Kaufmann, Emilie},
  journal={arXiv preprint arXiv:2207.05852},
  year={2022}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{liu2020provably,
  title={Provably good batch off-policy reinforcement learning without great exploration},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1264--1274},
  year={2020}
}

@article{ross2012agnostic,
  title={Agnostic system identification for model-based reinforcement learning},
  author={Ross, Stephane and Bagnell, J Andrew},
  journal={arXiv preprint arXiv:1203.1007},
  year={2012}
}


@article{ok2018exploration,
  title={Exploration in structured reinforcement learning},
  author={Ok, Jungseul and Proutiere, Alexandre and Tranos, Damianos},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}
@article{brafman2002r,
  title={R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
  author={Brafman, Ronen I and Tennenholtz, Moshe},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Oct},
  pages={213--231},
  year={2002}
}

@inproceedings{yang2021q,
  title={Q-learning with logarithmic regret},
  author={Yang, Kunhe and Yang, Lin and Du, Simon},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1576--1584},
  year={2021},
  organization={PMLR}
}

@inproceedings{jin2021pessimism,
  title={Is pessimism provably efficient for offline rl?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={5084--5096},
  year={2021},
  organization={PMLR}
}

@article{fiez2019sequential,
  title={Sequential experimental design for transductive linear bandits},
  author={Fiez, Tanner and Jain, Lalit and Jamieson, Kevin G and Ratliff, Lillian},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@inproceedings{du2021bilinear,
  title={Bilinear classes: A structural framework for provable generalization in rl},
  author={Du, Simon and Kakade, Sham and Lee, Jason and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={2826--2836},
  year={2021},
  organization={PMLR}
}


@article{dann2021beyond,
  title={Beyond value-function gaps: Improved instance-dependent regret bounds for episodic reinforcement learning},
  author={Dann, Christoph and Marinov, Teodor Vanislavov and Mohri, Mehryar and Zimmert, Julian},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1--12},
  year={2021}
}

@inproceedings{xu2021fine,
  title={Fine-grained gap-dependent bounds for tabular mdps via adaptive multi-step bootstrap},
  author={Xu, Haike and Ma, Tengyu and Du, Simon},
  booktitle={Conference on Learning Theory},
  pages={4438--4472},
  year={2021},
  organization={PMLR}
}

@article{song2022hybrid,
  title={Hybrid RL: Using Both Offline and Online Data Can Make RL Efficient},
  author={Song, Yuda and Zhou, Yifei and Sekhari, Ayush and Bagnell, J Andrew and Krishnamurthy, Akshay and Sun, Wen},
  journal={arXiv preprint arXiv:2210.06718},
  year={2022}
}

@article{xie2021policy,
  title={Policy finetuning: Bridging sample-efficient offline and online reinforcement learning},
  author={Xie, Tengyang and Jiang, Nan and Wang, Huan and Xiong, Caiming and Bai, Yu},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={27395--27407},
  year={2021}
}

@inproceedings{fulton2018safe,
  title={Safe reinforcement learning via formal methods: Toward safe control through proof and learning},
  author={Fulton, Nathan and Platzer, Andr{\'e}},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}


@article{gupta2020safety,
  title={Safety Verification of Model Based Reinforcement Learning Controllers},
  author={Gupta, Akshita and Hwang, Inseok},
  journal={arXiv preprint arXiv:2010.10740},
  year={2020}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}


@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@inproceedings{nair2018overcoming,
  title={Overcoming exploration in reinforcement learning with demonstrations},
  author={Nair, Ashvin and McGrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={6292--6299},
  year={2018},
  organization={IEEE}
}


@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}


@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}


@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{yu2021reinforcement,
  title={Reinforcement learning in healthcare: A survey},
  author={Yu, Chao and Liu, Jiming and Nemati, Shamim and Yin, Guosheng},
  journal={ACM Computing Surveys (CSUR)},
  volume={55},
  number={1},
  pages={1--36},
  year={2021},
  publisher={ACM New York, NY}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}


@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{zhan2022offline,
  title={Offline reinforcement learning with realizability and single-policy concentrability},
  author={Zhan, Wenhao and Huang, Baihe and Huang, Audrey and Jiang, Nan and Lee, Jason},
  booktitle={Conference on Learning Theory},
  pages={2730--2775},
  year={2022},
  organization={PMLR}
}

@article{chen2022offline,
  title={Offline reinforcement learning under value and density-ratio realizability: the power of gaps},
  author={Chen, Jinglin and Jiang, Nan},
  journal={arXiv preprint arXiv:2203.13935},
  year={2022}
}



@article{jiang2020minimax,
  title={Minimax value interval for off-policy evaluation and policy optimization},
  author={Jiang, Nan and Huang, Jiawei},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2747--2758},
  year={2020}
}

@article{xie2021bellman,
  title={Bellman-consistent pessimism for offline reinforcement learning},
  author={Xie, Tengyang and Cheng, Ching-An and Jiang, Nan and Mineiro, Paul and Agarwal, Alekh},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={6683--6694},
  year={2021}
}

@article{uehara2021pessimistic,
  title={Pessimistic model-based offline reinforcement learning under partial coverage},
  author={Uehara, Masatoshi and Sun, Wen},
  journal={arXiv preprint arXiv:2107.06226},
  year={2021}
}
@inproceedings{wagenmaker2021experimental,
  title={Experimental design for regret minimization in linear bandits},
  author={Wagenmaker, Andrew and Katz-Samuels, Julian and Jamieson, Kevin},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3088--3096},
  year={2021},
  organization={PMLR}
}

@article{chang2021mitigating,
  title={Mitigating Covariate Shift in Imitation Learning via Offline Data With Partial Coverage},
  author={Chang, Jonathan and Uehara, Masatoshi and Sreenivas, Dhruv and Kidambi, Rahul and Sun, Wen},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={965--979},
  year={2021}
}
@inproceedings{zhang2022corruption,
  title={Corruption-robust offline reinforcement learning},
  author={Zhang, Xuezhou and Chen, Yiding and Zhu, Xiaojin and Sun, Wen},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={5757--5773},
  year={2022},
  organization={PMLR}
}

@book{kakade2003sample,
  title={On the sample complexity of reinforcement learning},
  author={Kakade, Sham Machandranath},
  year={2003},
  publisher={University of London, University College London (United Kingdom)}
}

@article{kaufmann2016complexity,
  title={On the complexity of best-arm identification in multi-armed bandit models},
  author={Kaufmann, Emilie and Capp{\'e}, Olivier and Garivier, Aur{\'e}lien},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1--42},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{wagenmaker2022first,
  title={First-order regret in reinforcement learning with linear function approximation: A robust estimation approach},
  author={Wagenmaker, Andrew J and Chen, Yifang and Simchowitz, Max and Du, Simon and Jamieson, Kevin},
  booktitle={International Conference on Machine Learning},
  pages={22384--22429},
  year={2022},
  organization={PMLR}
}

@article{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}


@article{dann2015sample,
  title={Sample complexity of episodic fixed-horizon reinforcement learning},
  author={Dann, Christoph and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015}
}

@article{zanette2021provable,
  title={Provable benefits of actor-critic methods for offline reinforcement learning},
  author={Zanette, Andrea and Wainwright, Martin J and Brunskill, Emma},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13626--13640},
  year={2021}
}


@inproceedings{shamir2013complexity,
  title={On the complexity of bandit and derivative-free stochastic convex optimization},
  author={Shamir, Ohad},
  booktitle={Conference on Learning Theory},
  pages={3--24},
  year={2013},
  organization={PMLR}
}

@misc{tsybakov2009introduction,
  title={Introduction to Nonparametric Estimation.},
  author={Tsybakov, Alexandre B},
  journal={Springer series in statistics},
  pages={I--XII},
  year={2009},
  publisher={Springer}
}

@article{zanette2020provably,
  title={Provably efficient reward-agnostic navigation with linear value iteration},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel J and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11756--11766},
  year={2020}
}

@inproceedings{hao2021online,
  title={Online sparse reinforcement learning},
  author={Hao, Botao and Lattimore, Tor and Szepesv{\'a}ri, Csaba and Wang, Mengdi},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={316--324},
  year={2021},
  organization={PMLR}
}

@article{agarwal2021online,
  title={Online target q-learning with reverse experience replay: Efficiently finding the optimal policy for linear mdps},
  author={Agarwal, Naman and Chaudhuri, Syomantak and Jain, Prateek and Nagaraj, Dheeraj and Netrapalli, Praneeth},
  journal={arXiv preprint arXiv:2110.08440},
  year={2021}
}

@inproceedings{zhang2022making,
  title={Making linear mdps practical via contrastive representation learning},
  author={Zhang, Tianjun and Ren, Tongzheng and Yang, Mengjiao and Gonzalez, Joseph and Schuurmans, Dale and Dai, Bo},
  booktitle={International Conference on Machine Learning},
  pages={26447--26466},
  year={2022},
  organization={PMLR}
}

@inproceedings{ren2022free,
  title={A free lunch from the noise: Provable and practical exploration for representation learning},
  author={Ren, Tongzheng and Zhang, Tianjun and Szepesv{\'a}ri, Csaba and Dai, Bo},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1686--1696},
  year={2022},
  organization={PMLR}
}


@inproceedings{katz2020true,
  title={The true sample complexity of identifying good arms},
  author={Katz-Samuels, Julian and Jamieson, Kevin},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1781--1791},
  year={2020},
  organization={PMLR}
}