%@book{cramer_1970, place={Cambridge}, series={Cambridge Tracts in Mathematics}, title={Random Variables and Probability Distributions}, DOI={10.1017/CBO9780511470936}, publisher={Cambridge University Press}, author={Cramer, H.}, year={1970}, collection={Cambridge Tracts in Mathematics}}

@inproceedings{Spirtes1995DirectedCG,
  title={Directed Cyclic Graphical Representations of Feedback Models},
  author={Peter L. Spirtes},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  year={1995}
}

@article{SEM,
author = {Bielby, W T and Hauser, R M},
title = {Structural Equation Models},
journal = {Annual Review of Sociology},
volume = {3},
number = {1},
pages = {137-161},
year = {1977},
doi = {10.1146/annurev.so.03.080177.001033},
URL = {https://doi.org/10.1146/annurev.so.03.080177.001033},
eprint = {https://doi.org/10.1146/annurev.so.03.080177.001033}
}

@article{robust,
title = {Robust, Adaptive Functional Regression in Functional Mixed Model Framework},
author = {Zhu, Hongxiao and Brown, Philip J. and Morris, Jeffrey S.},
year = {2011},
journal = {Journal of the American Statistical Association},
volume = {106},
number = {495},
pages = {1167-1179},
url = {https://EconPapers.repec.org/RePEc:bes:jnlasa:v:106:i:495:y:2011:p:1167-1179}
}

@article{fisher,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/1909242},
 abstract = {This paper examines the implications of the position that simultaneous equation models are limiting approximations to nonsimultaneous ones as time lags go to zero, observations being on averages or sums of variables over time. Necessary conditions that a given simultaneous model can be the limit of such processes in a reasonable way are derived. This leads to tests on the specification of the model and of submodels thereof, which tests examine the interrelations between equations.},
 author = {Franklin M. Fisher},
 journal = {Econometrica},
 number = {1},
 pages = {73--92},
 publisher = {[Wiley, Econometric Society]},
 title = {A Correspondence Principle for Simultaneous Equation Models},
 urldate = {2023-03-06},
 volume = {38},
 year = {1970}
}

@article{histofSEM,
author = {Pearl, Judea},
year = {2010},
month = {12},
pages = {},
title = {The Causal Foundations of Structural Equation Modeling},
journal = {Handbook of Structural Equation Modeling}
}

@article{HP,
author = {Aapo, Hyvärinen and Petteri, Pajunen},
year = {1999},
title = {Nonlinear independent component analysis: Existence and uniqueness results},
journal = {Neural Networks},
abstract = {The question of existence and uniqueness of solutions for nonlinear independent component analysis is addressed. It is shown that if the space of mixing functions is not limited there exists always an infinity of solutions. In particular, it is shown how to construct parameterized families of solutions. The indeterminacies involved are not trivial, as in the linear case. Next, it is shown how to utilize some results of complex analysis to obtain uniqueness of solutions. We show that for two dimensions, the solution is unique up to a rotation, if the mixing function is constrained to be a conformal mapping together with some other assumptions. We also conjecture that the solution is strictly unique except in some degenerate cases, as the indeterminacy implied by the rotation is essentially similar to estimating the model of linear ICA.},
volume = {12},
issue = {3},
pages = {429--439},
url = {https://doi.org/10.1016/S0893-6080(98)00140-3}
}

@article{spirtes2016,
author = {Spirtes, Peter and Zhang, Kun},
year = {2016},
title = {Causal discovery and inference: concepts and recent methodological advances},
journal = {Applied Informatics},
volume = {3},
issue = {1},
abstract = {This paper aims to give a broad coverage of central concepts and principles involved in automated causal inference and emerging approaches to causal discovery from i.i.d data and from time series. After reviewing concepts including manipulations, causal models, sample predictive modeling, causal predictive modeling, and structural equation models, we present the constraint-based approach to causal discovery, which relies on the conditional independence relationships in the data, and discuss the assumptions underlying its validity. We then focus on causal discovery based on structural equations models, in which a key issue is the identifiability of the causal structure implied by appropriately defined structural equation models: in the two-variable case, under what conditions (and why) is the causal direction between the two variables identifiable? We show that the independence between the error term and causes, together with appropriate structural constraints on the structural equation, makes it possible. Next, we report some recent advances in causal discovery from time series. Assuming that the causal relations are linear with nonGaussian noise, we mention two problems which are traditionally difficult to solve, namely causal discovery from subsampled data and that in the presence of confounding time series. Finally, we list a number of open questions in the field of causal discovery and inference.},
doi = {10.1186/s40535-016-0018-x},
url = {https://doi.org/10.1186/s40535-016-0018-x}
}

@article{mrule,
author = {Maria Maddalena Barbieri and James O. Berger},
title = {{Optimal predictive model selection}},
volume = {32},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {870 -- 897},
keywords = {Bayesian linear models, predictive distribution, squared error loss, Variable selection},
year = {2004},
doi = {10.1214/009053604000000238},
URL = {https://doi.org/10.1214/009053604000000238}
}

@misc{fBN,
      title={Functional Bayesian Networks for Discovering Causality from Multivariate Functional Data}, 
      author={Fangting Zhou and Kejun He and Kunbo Wang and Yanxun Xu and Yang Ni},
      year={2022},
      eprint={2210.12832},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@inproceedings{Lacerda,
  title={Discovering Cyclic Causal Models by Independent Components Analysis},
  author={Gustavo Lacerda and Peter L. Spirtes and Joseph Ramsey and Patrik O. Hoyer},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  year={2008}
}

@Manual{fdapace,
    title = {fdapace: Functional Data Analysis and Empirical Dynamics},
    author = {Yidong Zhou and Satarupa Bhattacharjee and Cody Carroll and Yaqing Chen and Xiongtao Dai and Jianing Fan and Alvaro Gajardo and Pantelis Z. Hadjipantelis and Kyunghee Han and Hao Ji and Changbo Zhu and Hans-Georg Müller and Jane-Ling Wang},
    year = {2022},
    note = {R package version 0.5.9},
    url = {https://CRAN.R-project.org/package=fdapace},
  }
  
 @inproceedings{ccd, author = {Richardson, Thomas}, title = {A Discovery Algorithm for Directed Cyclic Graphs}, year = {1996}, isbn = {155860412X}, publisher = {Morgan Kaufmann Publishers Inc.}, address = {San Francisco, CA, USA}, abstract = {Directed acyclic graphs have been used fruitfully to represent causal structures (Pearl 1988). However, in the social sciences and elsewhere models are often used which correspond both causally and statistically to directed graphs with directed cycles (Spirtes 1995). Pearl (1993) discussed predicting the effects of intervention in models of this kind, so-called linear nonrecursive structural equation models. This raises the question of whether it is possible to make inferences about causal structure with cycles, from sample data. In particular do there exist general, informative, feasible and reliable procedures for inferring causal structure from conditional independence relations among variables in a sample generated by an unknown causal structure? In this paper I present a discovery algorithm that is correct in the large sample limit, given commonly (but often implicitly) made plausible assumptions, and which provides information about the existence or non-existence of causal pathways from one variable to another. The algorithm is polynomial on sparse graphs.}, booktitle = {Proceedings of the Twelfth International Conference on Uncertainty in Artificial Intelligence}, pages = {454–461}, numpages = {8}, location = {Portland, OR}, series = {UAI'96} }
 
 @Manual{rcausal,
    title = {rcausal: R-Causal Library},
    author = {Chirayu Wongchokprasitti},
    year = {2019},
    note = {R package version 1.2.1},
  }

@Article{fSEM,
  author={Kuang‐Yao Lee and Lexin Li},
  title={{Functional structural equation model}},
  journal={Journal of the Royal Statistical Society Series B},
  year=2022,
  volume={84},
  number={2},
  pages={600-629},
  month={April},
  keywords={},
  doi={10.1111/rssb.12471},
  abstract={In this article, we introduce a functional structural equation model for estimating directional relations from multivariate functional data. We decouple the estimation into two major steps: directional order determination and selection through sparse functional regression. We first propose a score function at the linear operator level, and show that its minimization can recover the true directional order when the relation between each function and its parental functions is nonlinear. We then develop a sparse functional additive regression, where both the response and the multivariate predictors are functions and the regression relation is additive and nonlinear. We also propose strategies to speed up the computation and scale up our method. In theory, we establish the consistencies of order determination, sparse functional additive regression, and directed acyclic graph estimation, while allowing both the dimension of the Karhunen–Loeve expansion coefficients and the number of random functions to diverge with the sample size. We illustrate the efficacy of our method through simulations, and an application to brain effective connectivity analysis.},
  url={https://ideas.repec.org/a/bla/jorssb/v84y2022i2p600-629.html}
}


@InProceedings{pmlr-v186-yang22a,
  title = 	 {The Functional {LiNGAM}},
  author =       {Yang, Tianle and Suzuki, Joe},
  booktitle = 	 {Proceedings of The 11th International Conference on Probabilistic Graphical Models},
  pages = 	 {25--36},
  year = 	 {2022},
  volume = 	 {186},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {05--07 Oct},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v186/yang22a/yang22a.pdf},
  url = 	 {https://proceedings.mlr.press/v186/yang22a.html},
  abstract = 	 {We consider a causal order such as the cause and effect among variables. In the Linear Non-Gaussian Acyclic Model (LiNGAM), we can only identify the order if at least one of the variables is non-Gaussian. This paper extends the notion of variables to functions (Functional Linear Non-Gaussian Acyclic Model, Func-LiNGAM). We first prove that we can identify the order among random functions if and only if one of them is a non-Gaussian process. In the actual procedure, we approximate the functions by random vectors. To improve the correctness and efficiency, we propose to optimize the coordinates of the vectors in such a way as functional principal component analysis. The experiments contain an order identification simulation among multiple functions for given samples. In particular, we apply the Func-LiNGAM to recognize the brain connectivity pattern with fMRI data. We can see the improvements in accuracy and execution speed compared to existing methods.}
}

@article{cycles1,
author = {Friston, Karl J.},
title = {Functional and Effective Connectivity: A Review},
journal = {Brain Connectivity},
volume = {1},
number = {1},
pages = {13-36},
year = {2011},
doi = {10.1089/brain.2011.0008},
    note ={PMID: 22432952},
URL = {  https://doi.org/10.1089/brain.2011.0008},
eprint = { https://doi.org/10.1089/brain.2011.0008},
abstract = { Abstract Over the past 20 years, neuroimaging has become a predominant technique in systems neuroscience. One might envisage that over the next 20 years the neuroimaging of distributed processing and connectivity will play a major role in disclosing the brain's functional architecture and operational principles. The inception of this journal has been foreshadowed by an ever-increasing number of publications on functional connectivity, causal modeling, connectomics, and multivariate analyses of distributed patterns of brain responses. I accepted the invitation to write this review with great pleasure and hope to celebrate and critique the achievements to date, while addressing the challenges ahead. }
}

@article{cycles2,
    author = {Markov, N. T. and Ercsey-Ravasz, M. M. and Ribeiro Gomes, A. R. and Lamy, C. and Magrou, L. and Vezoli, J. and Misery, P. and Falchier, A. and Quilodran, R. and Gariel, M. A. and Sallet, J. and Gamanut, R. and Huissoud, C. and Clavagnier, S. and Giroud, P. and Sappey-Marinier, D. and Barone, P. and Dehay, C. and Toroczkai, Z. and Knoblauch, K. and Van Essen, D. C. and Kennedy, H.},
    title = "{A Weighted and Directed Interareal Connectivity Matrix for Macaque Cerebral Cortex}",
    journal = {Cerebral Cortex},
    volume = {24},
    number = {1},
    pages = {17-36},
    year = {2012},
    month = {09},
    abstract = "{Retrograde tracer injections in 29 of the 91 areas of the macaque cerebral cortex revealed 1,615 interareal pathways, a third of which have not previously been reported. A weight index (extrinsic fraction of labeled neurons [FLNe]) was determined for each area-to-area pathway. Newly found projections were weaker on average compared with the known projections; nevertheless, the 2 sets of pathways had extensively overlapping weight distributions. Repeat injections across individuals revealed modest FLNe variability given the range of FLNe values (standard deviation \\&lt;1 log unit, range 5 log units). The connectivity profile for each area conformed to a lognormal distribution, where a majority of projections are moderate or weak in strength. In the G29 √ó 29 interareal subgraph, two-thirds of the connections that can exist do exist. Analysis of the smallest set of areas that collects links from all 91 nodes of the G29 √ó 91 subgraph (dominating set analysis) confirms the dense (66\%) structure of the cortical matrix. The G29 √ó 29 subgraph suggests an unexpectedly high incidence of unidirectional links. The directed and weighted G29 √ó 91 connectivity matrix for the macaque will be valuable for comparison with connectivity analyses in other species, including humans. It will also inform future modeling studies that explore the regularities of cortical networks.}",
    issn = {1047-3211},
    doi = {10.1093/cercor/bhs270},
    url = {https://doi.org/10.1093/cercor/bhs270},
    eprint = {https://academic.oup.com/cercor/article-pdf/24/1/17/14097351/bhs270.pdf},
}

@inproceedings{CANM_Mooij,
  author    = {Joris M. Mooij and
               Dominik Janzing and
               Tom Heskes and
               Bernhard Sch{\"{o}}lkopf},
  editor    = {John Shawe{-}Taylor and
               Richard S. Zemel and
               Peter L. Bartlett and
               Fernando C. N. Pereira and
               Kilian Q. Weinberger},
  title     = {On Causal Discovery with Cyclic Additive Noise Models},
  booktitle = {Advances in Neural Information Processing Systems 24: 25th Annual
               Conference on Neural Information Processing Systems 2011. Proceedings
               of a meeting held 12-14 December 2011, Granada, Spain},
  pages     = {639--647},
  year      = {2011},
  url       = {https://proceedings.neurips.cc/paper/2011/hash/d61e4bbd6393c9111e6526ea173a7c8b-Abstract.html},
  timestamp = {Mon, 16 May 2022 15:41:51 +0200},
  biburl    = {https://dblp.org/rec/conf/nips/MooijJHS11.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ConstrainBasedCyclic_Mooij,
  author    = {Joris M. Mooij and
               Tom Claassen},
  editor    = {Ryan P. Adams and
               Vibhav Gogate},
  title     = {Constraint-Based Causal Discovery using Partial Ancestral Graphs in
               the presence of Cycles},
  booktitle = {Proceedings of the Thirty-Sixth Conference on Uncertainty in Artificial
               Intelligence, {UAI} 2020, virtual online, August 3-6, 2020},
  series    = {Proceedings of Machine Learning Research},
  volume    = {124},
  pages     = {1159--1168},
  publisher = {{AUAI} Press},
  year      = {2020},
  url       = {http://proceedings.mlr.press/v124/m-mooij20a.html},
  timestamp = {Wed, 16 Dec 2020 16:53:24 +0100},
  biburl    = {https://dblp.org/rec/conf/uai/MooijC20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchaboutnfdi

@inproceedings{CCD_equillibrium,
  author    = {Joris M. Mooij and
               Tom Heskes},
  editor    = {Ann E. Nicholson and
               Padhraic Smyth},
  title     = {Cyclic Causal Discovery from Continuous Equilibrium Data},
  booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial
               Intelligence, {UAI} 2013, Bellevue, WA, USA, August 11-15, 2013},
  publisher = {{AUAI} Press},
  year      = {2013},
  url       = {https://dslpitt.org/uai/displayArticleDetails.jsp?mmnu=1\&smnu=2\&article\_id=2404\&proceeding\_id=29},
  timestamp = {Fri, 16 Jul 2021 16:15:58 +0200},
  biburl    = {https://dblp.org/rec/conf/uai/MooijH13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{HyttinenEH12,
  author    = {Antti Hyttinen and
               Frederick Eberhardt and
               Patrik O. Hoyer},
  editor    = {Nando de Freitas and
               Kevin P. Murphy},
  title     = {Causal Discovery of Linear Cyclic Models from Multiple Experimental
               Data Sets with Overlapping Variables},
  booktitle = {Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial
               Intelligence, Catalina Island, CA, USA, August 14-18, 2012},
  pages     = {387--396},
  publisher = {{AUAI} Press},
  year      = {2012},
  url       = {https://dslpitt.org/uai/displayArticleDetails.jsp?mmnu=1\&smnu=2\&article\_id=2301\&proceeding\_id=28},
  timestamp = {Mon, 23 Nov 2020 08:36:49 +0100},
  biburl    = {https://dblp.org/rec/conf/uai/HyttinenEH12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchaboutnfdi

@article{CDHD,
  author    = {Biwei Huang and
               Kun Zhang and
               Jiji Zhang and
               Joseph D. Ramsey and
               Ruben Sanchez{-}Romero and
               Clark Glymour and
               Bernhard Sch{\"{o}}lkopf},
  title     = {Causal Discovery from Heterogeneous/Nonstationary Data},
  journal   = {CoRR},
  volume    = {abs/1903.01672},
  year      = {2019},
  url       = {http://arxiv.org/abs/1903.01672},
  eprinttype = {arXiv},
  eprint    = {1903.01672},
  timestamp = {Sat, 23 Jan 2021 01:11:45 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1903-01672.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchaboutnfdi

@inproceedings{CHOD,
  author    = {Fangting Zhou and
               Kejun He and
               Yang Ni},
  editor    = {James Cussens and
               Kun Zhang},
  title     = {Causal discovery with heterogeneous observational data},
  booktitle = {Uncertainty in Artificial Intelligence, Proceedings of the Thirty-Eighth
               Conference on Uncertainty in Artificial Intelligence, {UAI} 2022,
               1-5 August 2022, Eindhoven, The Netherlands},
  series    = {Proceedings of Machine Learning Research},
  volume    = {180},
  pages     = {2383--2393},
  publisher = {{PMLR}},
  year      = {2022},
  url       = {https://proceedings.mlr.press/v180/zhou22a.html},
  timestamp = {Sat, 15 Oct 2022 12:08:13 +0200},
  biburl    = {https://dblp.org/rec/conf/uai/ZhouHN22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{shao2019multivariate,
title={Multivariate functional principal component analysis for brain imaging data},
author={Shao, Jia and Zhu, Hongtu and Li, Runze and Yao, Jianfeng and Marron, JS},
journal={Journal of the American Statistical Association},
volume={114},
number={526},
pages={1605--1620},
year={2019},
publisher={Taylor & Francis}
}

@article{liao2020multivariate,
title={Multivariate functional data analysis for high-dimensional neuroimaging data},
author={Liao, Guanghai and Hu, Jianhua and Li, Runze and Marron, J. S. and Li, Xuan},
journal={Journal of the Royal Statistical Society: Series C},
volume={69},
number={5},
pages={1049--1072},
year={2020},
publisher={Wiley Online Library}
}

@article{ramsay2017multivariate,
title={Multivariate functional data analysis in genomics: challenges and opportunities},
author={Ramsay, James O and Cao, Jiguo and Chen, Jun},
journal={Annual Review of Statistics and Its Application},
volume={4},
pages={213--232},
year={2017},
publisher={Annual Reviews}
}

@article{morris2021multivariate,
title={Multivariate functional principal component analysis for genomics data},
author={Morris, Dylan and Wu, Yichao and Yao, Fang and Zhang, Jing},
journal={Journal of the American Statistical Association},
volume={116},
number={533},
pages={617--632},
year={2021},
publisher={Taylor & Francis}
}

@article{wang2019multivariate,
title={Multivariate functional principal component analysis for longitudinal and clustered data},
author={Wang, Yuanjia and Xue, Lingzhou and Carroll, Raymond J},
journal={Biometrics},
volume={75},
number={2},
pages={501--512},
year={2019},
publisher={Wiley Online Library}
}

@article{polonik2021multivariate,
  title={Multivariate functional principal component analysis for big data with application to climate modeling},
  author={Polonik, Wolfgang and Zhao, Tianqi and Zheng, Yan},
  journal={Annals of Statistics},
  year={2021},
  volume={49},
  number={1},
  pages={506--534},
  publisher={Institute of Mathematical Statistics}
}

@article{li2020multivariate,
  title={Multivariate functional regression for spatiotemporal environmental data},
  author={Li, Hongzhe and Wang, Jian and Zhu, Jun},
  journal={Journal of the American Statistical Association},
  year={2020},
  volume={115},
  number={529},
  pages={1010--1023},
  publisher={Taylor \& Francis}
}

@article{li2021multivariate,
  title={Multivariate functional principal component analysis for spatio-temporal data with application to environmental data},
  author={Li, Wenjie and Li, Hongzhe and Li, Runze},
  journal={Biometrika},
  year={2021},
  volume={108},
  number={2},
  pages={315--332},
  publisher={Oxford University Press}
}

@article{kim2020high,
  title={High-dimensional covariance estimation via multivariate functional principal component analysis},
  author={Kim, Bohwa and Lee, Seunggeun and Seo, Yoonsuh},
  journal={Journal of the American Statistical Association},
  year={2020},
  volume={115},
  number={531},
  pages={1273--1285},
  publisher={Taylor \& Francis}
}

@article{chen2021functional,
  title={Functional partial linear regression with ultrahigh-dimensional predictors},
  author={Chen, Rui and Fan, Jianqing and Liao, Yuan and Mincheva, Martina},
  journal={Journal of the Royal Statistical Society: Series B},
  year={2021},
  volume={83},
  number={2},
  pages={565--589},
  publisher={Wiley Online Library}
}

@article{james2016functional,
  title={Functional data analysis in sport science: Exploring relationships between technique, fatigue and performance in elite sprinting},
  author={James, Nic and Taylor, Sam and Roberts, Simon and Willmott, Alexander},
  journal={Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  volume={65},
  number={4},
  pages={621--634},
  year={2016},
  publisher={Wiley Online Library}
}

@article{jia2017multivariate,
  title={A multivariate functional data analysis framework for sport injury research},
  author={Jia, Tuo and Wang, Li and Li, Changsheng and Shi, Xiaoming},
  journal={Journal of Biomechanics},
  volume={58},
  pages={1--7},
  year={2017},
  publisher={Elsevier}
}

@article{brandman2008feedback,
  title={Feedback loops shape cellular signals in space and time},
  author={Brandman, Onn and Meyer, Thomas},
  journal={Science},
  volume={322},
  number={5900},
  pages={390--395},
  year={2008},
  publisher={American Association for the Advancement of Science}
}

@article{kowal2017bayesian,
  title={A Bayesian multivariate functional dynamic linear model},
  author={Kowal, Daniel R and Matteson, David S and Ruppert, David},
  journal={Journal of the American Statistical Association},
  volume={112},
  number={518},
  pages={733--744},
  year={2017},
  publisher={Taylor \& Francis}
}

@article{beta&bernoulli,
author = {James G. Scott and James O. Berger},
title = {{Bayes and empirical-Bayes multiplicity adjustment in the variable-selection problem}},
volume = {38},
journal = {The Annals of Statistics},
number = {5},
publisher = {Institute of Mathematical Statistics},
pages = {2587 -- 2619},
keywords = {Bayesian model selection, Empirical Bayes, multiple testing, Variable selection},
year = {2010},
doi = {10.1214/10-AOS792},
URL = {https://doi.org/10.1214/10-AOS792}
}

@article{shimizu06a,
  author  = {Shohei Shimizu and Patrik O. Hoyer and Aapo Hyvrinen and Antti Kerminen},
  title   = {A Linear Non-Gaussian Acyclic Model for Causal Discovery},
  journal = {Journal of Machine Learning Research},
  year    = {2006},
  volume  = {7},
  number  = {72},
  pages   = {2003--2030},
  url     = {http://jmlr.org/papers/v7/shimizu06a.html}
}

@article{wahba1978,
author = {Wahba, Grace},
title = {Improper Priors, Spline Smoothing and the Problem of Guarding Against Model Errors in Regression},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
volume = {40},
number = {3},
pages = {364-372},
keywords = {spline smoothing, improper priors, nonparametric regression, model errors},
doi = {https://doi.org/10.1111/j.2517-6161.1978.tb01050.x},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1978.tb01050.x},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1978.tb01050.x},
abstract = {Summary Spline and generalized spline smoothing is shown to be equivalent to Bayesian estimation with a partially improper prior. This result supports the idea that spline smoothing is a natural solution to the regression problem when one is given a set of regression functions but one also wants to hedge against the possibility that the true model is not exactly in the span of the given regression functions. A natural measure of the deviation of the true model from the span of the regression functions comes out of the spline theory in a natural way. An appropriate value of this measure can be estimated from the data and used to constrain the estimated model to have the estimated deviation. Some convergence results and computational tricks are also discussed.},
year = {1978}
}

@article{gu1992penalized,
  title={Penalized likelihood regression: A Bayesian analysis},
  author={Gu, Chong},
  journal={Statistica Sinica},
  volume={2},
  pages={255--264},
  year={1992},
  publisher={Taylor \& Francis}
}

@article{berry2002splines,
author = {Scott M Berry and Raymond J Carroll and David Ruppert},
title = {Bayesian Smoothing and Regression Splines for Measurement Error Problems},
journal = {Journal of the American Statistical Association},
volume = {97},
number = {457},
pages = {160-169},
year  = {2002},
publisher = {Taylor & Francis},
doi = {10.1198/016214502753479301},
URL = {https://doi.org/10.1198/016214502753479301},
eprint = {https://doi.org/10.1198/016214502753479301}
}

@article{Wand,
author = {Wand, M. P. and Ormerod, J. T.},
title = {Corrigendum: ON SEMIPARAMETRIC REGRESSION WITH O'SULLIVAN PENALISED SPLINES},
journal = {Australian \& New Zealand Journal of Statistics},
volume = {52},
number = {2},
pages = {239-239},
doi = {https://doi.org/10.1111/j.1467-842X.2010.00578.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-842X.2010.00578.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-842X.2010.00578.x},
year = {2010}
}

@book{MCLA2000,
  added-at = {2013-01-07T16:10:56.000+0100},
  address = {New York},
  author = {McLachlan, G. J. and Peel, D.},
  biburl = {https://www.bibsonomy.org/bibtex/2462206655359ca92f6c432fb43fef1c1/olivia.bluder},
  interhash = {f4ae707df979236ba50173e48e851415},
  intrahash = {462206655359ca92f6c432fb43fef1c1},
  keywords = {imported},
  owner = {bluder},
  publisher = {Wiley Series in Probability and Statistics},
  timestamp = {2013-01-07T16:11:03.000+0100},
  title = {Finite mixture models},
  year = 2000
}

@book{titterington_85,
  added-at = {2009-09-10T14:36:22.000+0200},
  author = {Titterington, D.M. and Smith, A.F.M. and Makov, U.E.},
  biburl = {https://www.bibsonomy.org/bibtex/293745ce8778a6bac2c2e9298ed36d220/gregoryy},
  interhash = {7d41b8454619c3d5c78daf228f0a5e18},
  intrahash = {93745ce8778a6bac2c2e9298ed36d220},
  keywords = {imported},
  owner = {gregor},
  publisher = {Wiley, New York},
  timestamp = {2009-09-10T14:36:48.000+0200},
  title = {Statistical Analysis of Finite Mixture Distributions},
  year = 1985
}

@book{rossi,
 ISBN = {9780691145327},
 URL = {http://www.jstor.org/stable/j.ctt5hhrfp},
 abstract = {This book reviews and develops Bayesian non-parametric and semi-parametric methods for applications in microeconometrics and quantitative marketing. Most econometric models used in microeconomics and marketing applications involve arbitrary distributional assumptions. As more data becomes available, a natural desire to provide methods that relax these assumptions arises. Peter Rossi advocates a Bayesian approach in which specific distributional assumptions are replaced with more flexible distributions based on mixtures of normals. The Bayesian approach can use either a large but fixed number of normal components in the mixture or an infinite number bounded only by the sample size. By using flexible distributional approximations instead of fixed parametric models, the Bayesian approach can reap the advantages of an efficient method that models all of the structure in the data while retaining desirable smoothing properties. Non-Bayesian non-parametric methods often require additional ad hoc rules to avoid "overfitting," in which resulting density approximates are nonsmooth. With proper priors, the Bayesian approach largely avoids overfitting, while retaining flexibility. This book provides methods for assessing informative priors that require only simple data normalizations. The book also applies the mixture of the normals approximation method to a number of important models in microeconometrics and marketing, including the non-parametric and semi-parametric regression models, instrumental variables problems, and models of heterogeneity. In addition, the author has written a free online software package in R, "bayesm," which implements all of the non-parametric models discussed in the book.},
 author = {Peter E. Rossi},
 publisher = {Princeton University Press},
 title = {Bayesian Non- and Semi-parametric Methods and Applications},
 urldate = {2023-04-22},
 year = {2014}
}

@article{zhang1995event,
  title={Event-related potentials during object recognition tasks},
  author={Zhang, Xiao Lei and Begleiter, Henri and Porjesz, Bernice and Wang, Wenyu and Litke, Ann},
  journal={Brain research bulletin},
  volume={38},
  number={6},
  pages={531--538},
  year={1995},
  publisher={Elsevier}
}

@article{zhu2016bayesian,
  title={Bayesian graphical models for multivariate functional data},
  author={Zhu, Hongxiao and Strawn, Nate and Dunson, David B},
  journal={Journal of Machine Learning Research},
  volume={17},
  number  = {204},
  pages={1--27},
  year={2016},
  publisher={JMLR. org}
}

@article{qiao2019functional,
  title={Functional graphical models},
  author={Qiao, Xinghao and Guo, Shaojun and James, Gareth M},
  journal={Journal of the American Statistical Association},
  volume={114},
  number={525},
  pages={211--222},
  year={2019},
}


@article{knyazev2007motivation,
  title={Motivation, emotion, and their inhibitory control mirrored in brain oscillations},
  author={Knyazev, Gennady G},
  journal={Neuroscience \& Biobehavioral Reviews},
  volume={31},
  number={3},
  pages={377--395},
  year={2007},
}

@article{porjesz2005utility,
  title={The utility of neurophysiological markers in the study of alcoholism},
  author={Porjesz, Bernice and Rangaswamy, Madhavi and Kamarajan, Chella and Jones, Kevin A and Padmanabhapillai, Arpana and Begleiter, Henri},
  journal={Clinical Neurophysiology},
  volume={116},
  number={5},
  pages={993--1018},
  year={2005},
  doi = {10.1016/j.clinph.2004.12.016}
}

@article{Shimizu2011DirectLiNGAMAD,
  title={DirectLiNGAM: A Direct Method for Learning a Linear Non-Gaussian Structural Equation Model},
  author={Shohei Shimizu and Takanori Inazumi and Yasuhiro Sogawa and Aapo Hyv{\"a}rinen and Y. Kawahara and Takashi Washio and Patrik O. Hoyer and Kenneth A. Bollen},
  journal={J. Mach. Learn. Res.},
  year={2011},
  volume={12},
  pages={1225-1248}
}

@article{PCalgo,
author = {Peter Spirtes and Clark Glymour},
title ={An Algorithm for Fast Recovery of Sparse Causal Graphs},
journal = {Social Science Computer Review},
volume = {9},
number = {1},
pages = {62-72},
year = {1991},
doi = {10.1177/089443939100900106},
URL = {https://doi.org/10.1177/089443939100900106},
eprint = {https://doi.org/10.1177/089443939100900106},
abstract = { Previous asymptotically correct algorithms for recovering causal structure from sample probabilities have been limited even in sparse causal graphs to a few variables. We describe an asymptotically correct algorithm whose complexity for fixed graph connectivity increases polynomially in the number of vertices, and may in practice recover sparse graphs with several hundred variables. From sample data with n = 20,000, an implementation of the algorithm on a DECStation 3100 recovers the edges in a linear version of the ALARM network with 37 vertices and 46 edges. Fewer than 8\% of the undirected edges are incorrectly identified in the output. Without prior ordering information, the program also determines the direction of edges for the ALARM graph with an error rate of 14\%. Processing time is less than 10 seconds. Keywords DAGS, Causal Modelling. }
}

@misc{Kalisch2018,
  title={An Overview of the pcalg Package for R},
  author={Markus Kalisch and A. Hauser and Marloes H. Maathuis and Martin M{\"a}chler},
  year={2018}
}

@article{legramanti,
    author = {Legramanti, Sirio and Durante, Daniele and Dunson, David B},
    title = "{Bayesian cumulative shrinkage for infinite factorizations}",
    journal = {Biometrika},
    volume = {107},
    number = {3},
    pages = {745-752},
    year = {2020},
    month = {05},
    abstract = "{The dimension of the parameter space is typically unknown in a variety of models that rely on factorizations. For example, in factor analysis the number of latent factors is not known and has to be inferred from the data. Although classical shrinkage priors are useful in such contexts, increasing shrinkage priors can provide a more effective approach that progressively penalizes expansions with growing complexity. In this article we propose a novel increasing shrinkage prior, called the cumulative shrinkage process, for the parameters that control the dimension in overcomplete formulations. Our construction has broad applicability and is based on an interpretable sequence of spike-and-slab distributions which assign increasing mass to the spike as the model complexity grows. Using factor analysis as an illustrative example, we show that this formulation has theoretical and practical advantages relative to current competitors, including an improved ability to recover the model dimension. An adaptive Markov chain Monte Carlo algorithm is proposed, and the performance gains are outlined in simulations and in an application to personality data.}",
    issn = {0006-3444},
    doi = {10.1093/biomet/asaa008},
    url = {https://doi.org/10.1093/biomet/asaa008},
    eprint = {https://academic.oup.com/biomet/article-pdf/107/3/745/33658377/asaa008\_supplementary\_data.pdf},
}

@article{bhattacharya,
    author = {Bhattacharya, A. and Dunson, D. B.},
    title = "{Sparse Bayesian infinite factor models}",
    journal = {Biometrika},
    volume = {98},
    number = {2},
    pages = {291-306},
    year = {2011},
    month = {06},
    abstract = "{We focus on sparse modelling of high-dimensional covariance matrices using Bayesian latent factor models. We propose a multiplicative gamma process shrinkage prior on the factor loadings which allows introduction of infinitely many factors, with the loadings increasingly shrunk towards zero as the column index increases. We use our prior on a parameter-expanded loading matrix to avoid the order dependence typical in factor analysis models and develop an efficient Gibbs sampler that scales well as data dimensionality increases. The gain in efficiency is achieved by the joint conjugacy property of the proposed prior, which allows block updating of the loadings matrix. We propose an adaptive Gibbs sampler for automatically truncating the infinite loading matrix through selection of the number of important factors. Theoretical results are provided on the support of the prior and truncation approximation bounds. A fast algorithm is proposed to produce approximate Bayes estimates. Latent factor regression methods are developed for prediction and variable selection in applications with high-dimensional correlated predictors. Operating characteristics are assessed through simulation studies, and the approach is applied to predict survival times from gene expression data.}",
    issn = {0006-3444},
    doi = {10.1093/biomet/asr013},
    url = {https://doi.org/10.1093/biomet/asr013},
    eprint = {https://academic.oup.com/biomet/article-pdf/98/2/291/46695653/asr013.pdf},
}

@TechReport{stability,
  author={Jean-Pierre Laffargue},
  title={{The Blanchard And Kahn' S Conditions In Macro-Econometric Models With Perfect Foresight}},
  year=2000,
  month=Jul,
  institution={Society for Computational Economics},
  type={Computing in Economics and Finance 2000},
  url={https://ideas.repec.org/p/sce/scecf0/225.html},
  number={225},
  abstract={Many recent large macro-econometric models assume perfect foresight (for instance the multinational models Multimod Mark 3 and Quest 2). This choice has been made possible by the development of simulation algorithms, which are powerful and easy to use (for example the command Stacks and Lkroot in Troll and the software Dynare which works under Gauss and Matlab - see Juillard). However, the existence and the uniqueness of a solution for these models are not warranted a priori. Blanchard and Kahn established local conditions for these properties, which are easy to check, in terms of eigenvalues computed at the steady state of the model. However, these conditions can be used only on linear models, with coefficients independent of time, and with exogenous variables taking constant values after some date. Unfortunately, macro-econometric models are non-linear, their linear approximation has coefficients which change over time, in the long run many variables grow at positive and different rates, and these models may present an hysteresis. This paper explains how to overcome these difficulties, and apply the Blanchard and Kahn's conditions on this kind of models.We start by imposing a homogeneity condition on the model, which implies that it has a balanced growth path solution. Afterward, we can compute a linear approximation of the model around this path, and require that the solution of the model tends toward the balanced growth path when time increases indefinitely. We call this last condition stability in the absolute difference. However, some coefficients of the linear approximation are geometrical functions of time, and it is impossible to use the results of Blanchard and Kahn in this kind of situation (although the eigenvalues, but not the eigenvectors, of the linear approximation are independent of time).We can overcome this difficulty if we make a change of variables and put all of them on a common trend (with the same growth rate). If this trend has a zero rate, },
  keywords={},
  doi={},
}

@article{finiteMixtures,
author = {Sidney J. Yakowitz and John D. Spragins},
title = {{On the Identifiability of Finite Mixtures}},
volume = {39},
journal = {The Annals of Mathematical Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {209 -- 214},
year = {1968},
doi = {10.1214/aoms/1177698520},
URL = {https://doi.org/10.1214/aoms/1177698520}
}

@article{finiteMixtures1,
author = {Henry Teicher},
title = {{Identifiability of Finite Mixtures}},
volume = {34},
journal = {The Annals of Mathematical Statistics},
number = {4},
publisher = {Institute of Mathematical Statistics},
pages = {1265 -- 1269},
year = {1963},
doi = {10.1214/aoms/1177703862},
URL = {https://doi.org/10.1214/aoms/1177703862}
}

@inproceedings{ramsey2018tetrad,
  title={TETRAD—A toolbox for causal discovery},
  author={Ramsey, Joseph D and Zhang, Kun and Glymour, Madelyn and Romero, Ruben Sanchez and Huang, Biwei and Ebert-Uphoff, Imme and Samarasinghe, Savini and Barnes, Elizabeth A and Glymour, Clark},
  booktitle={8th international workshop on climate informatics},
  year={2018}
}

@article{Zhang1995EventRP,
  title={Event related potentials during object recognition tasks},
  author={Xiao Lei Zhang and Henri Begleiter and Bernice Porjesz and Wenyu Wang and Ann Litke},
  journal={Brain Research Bulletin},
  year={1995},
  volume={38},
  pages={531-538}
}

@book{ramsay_silverman,
  abstract = {{The book presents novel statistical technology, much of it based on the authors' own research work, while keeping the mathematical level widely accessible. It is designed to appeal to students, to applied data analysts, and to experienced researchers; it will have value both within statistics and across a broad spectrum of other fields. This second edition is aimed at a wider range of readers, and especially those who would like to apply these techniques to their research problems.}},
  added-at = {2017-06-29T07:13:07.000+0200},
  author = {Ramsay, J. O. and Silverman, B. W.},
  biburl = {https://www.bibsonomy.org/bibtex/2084b22663454071fd0886b8a33ab49a1/gdmcbain},
  citeulike-article-id = {11611491},
  citeulike-linkout-0 = {http://www.worldcat.org/isbn/9780387400808},
  citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9780387400808},
  citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9780387400808\&index=books\&linkCode=qs},
  citeulike-linkout-3 = {http://www.librarything.com/isbn/9780387400808},
  citeulike-linkout-4 = {http://www.worldcat.org/oclc/803632771},
  comment = {cited by Biau, Devroye, \& Lugosi (2008)},
  interhash = {4cbf559638357928af9178bc39e32383},
  intrahash = {084b22663454071fd0886b8a33ab49a1},
  isbn = {9780387400808},
  keywords = {62-08-computational-methods-for-problems-for-statistics},
  posted-at = {2014-01-23 23:04:55},
  priority = {2},
  publisher = {Springer},
  timestamp = {2020-01-14T22:55:08.000+0100},
  title = {{Functional Data Analysis}},
  url = {http://www.worldcat.org/isbn/9780387400808},
  year = 2005
}

@article{wei_Li,
author = {Zhi Wei and Hongzhe Li},
title = {{A hidden spatial-temporal Markov random field model for network-based analysis of time course gene expression data}},
volume = {2},
journal = {The Annals of Applied Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {408 -- 429},
keywords = {differential expression, Iterative conditional modes, pathway, undirected graph},
year = {2008},
doi = {10.1214/07--AOAS145},
URL = {https://doi.org/10.1214/07--AOAS145}
}


@article{wong2019partially,
  title={Partially linear functional additive models for multivariate functional data},
  author={Wong, Raymond KW and Li, Yehua and Zhu, Zhengyuan},
  journal={Journal of the American Statistical Association},
  volume={114},
  number={525},
  pages={406--418},
  year={2019},
  publisher={Taylor \& Francis}
}

@article{park2022crop,
  title={Crop Yield Prediction Using Bayesian Spatially Varying Coefficient Models with Functional Predictors},
  author={Park, Yeonjoo and Li, Bo and Li, Yehua},
  journal={Journal of the American Statistical Association},
  pages={1--14},
  year={2022},
  publisher={Taylor \& Francis}
}

@misc{kortestapff2022multivariate,
      title={A multivariate functional-data mixture model for spatio-temporal data: inference and cokriging}, 
      author={Moritz Korte-Stapff and Drew Yarger and Stilian Stoev and Tailen Hsing},
      year={2022},
      eprint={2211.04012},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@article{wang2016functional,
  title={Functional data analysis},
  author={Wang, Jane-Ling and Chiou, Jeng-Min and M{\"u}ller, Hans-Georg},
  journal={Annual Review of Statistics and its application},
  volume={3},
  pages={257--295},
  year={2016},
  publisher={Annual Reviews}
}

@article{chiou2016pairwise,
  title={A pairwise interaction model for multivariate functional and longitudinal data},
  author={Chiou, Jeng-Min and M{\"u}ller, Hans-Georg},
  journal={Biometrika},
  volume={103},
  number={2},
  pages={377--396},
  year={2016},
  publisher={Oxford University Press}
}

@misc{volkmann2021multivariate,
      title={Multivariate Functional Additive Mixed Models}, 
      author={Alexander Volkmann and Almond Stöcker and Fabian Scheipl and Sonja Greven},
      year={2021},
      eprint={2103.06606},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@article{hayden,
author = {Hayden, Elizabeth and Wiegand, Ryan and Meyer, Eric and Bauer, Lance and O'Connor, Sean and Nurnberger, John and Chorlian, David and Porjesz, Bernice and Begleiter, Henri},
year = {2007},
month = {01},
pages = {1986-91},
title = {Patterns of Regional Brain Activity in Alcohol‐Dependent Subjects},
volume = {30},
journal = {Alcoholism, clinical and experimental research},
doi = {10.1111/j.1530-0277.2006.00244.x}
}

@article{winterer,
author = {Winterer, G and Enoch, M.-A and White, K and Saylan, Mete and Coppola, Richard and Goldman, D},
year = {2003},
month = {08},
pages = {51-60},
title = {EEG phenotype in alcoholism: Increased coherence in the depressive subtype},
volume = {108},
journal = {Acta psychiatrica Scandinavica},
doi = {10.1034/j.1600-0447.2003.00060.x}
}

@misc{kowal2022semiparametric,
      title={Semiparametric Functional Factor Models with Bayesian Rank Selection}, 
      author={Daniel R. Kowal and Antonio Canale},
      year={2022},
      eprint={2108.02151},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@article{causalRepresentLearn,
  author={Schölkopf, Bernhard and Locatello, Francesco and Bauer, Stefan and Ke, Nan Rosemary and Kalchbrenner, Nal and Goyal, Anirudh and Bengio, Yoshua},
  journal={Proceedings of the IEEE}, 
  title={Toward Causal Representation Learning}, 
  year={2021},
  volume={109},
  number={5},
  pages={612-634},
  doi={10.1109/JPROC.2021.3058954}}


@article{Tang_2023,
	doi = {10.1145/3597199},
  
	url = {https://doi.org/10.1145%2F3597199},
  
	year = 2023,
	month = {jul},
  
	publisher = {Association for Computing Machinery ({ACM})},
  
	volume = {55},
  
	number = {13s},
  
	pages = {1--37},
  
	author = {Zeyu Tang and Jiji Zhang and Kun Zhang},
  
	title = {What-is and How-to for Fairness in Machine Learning: A Survey, Reflection, and Perspective},
  
	journal = {{ACM} Computing Surveys}
}

@article{transferlearning,
author = {Rojas-Carulla, Mateo and Sch\"{o}lkopf, Bernhard and Turner, Richard and Peters, Jonas},
title = {Invariant Models for Causal Transfer Learning},
year = {2018},
issue_date = {January 2018},
publisher = {JMLR.org},
volume = {19},
number = {1},
issn = {1532-4435},
abstract = {Methods of transfer learning try to combine knowledge from several related tasks (or domains) to improve performance on a test task. Inspired by causal methodology, we relax the usual covariate shift assumption and assume that it holds true for a subset of predictor variables: the conditional distribution of the target variable given this subset of predictors is invariant over all tasks. We show how this assumption can be motivated from ideas in the field of causality. We focus on the problem of Domain Generalization, in which no examples from the test task are observed. We prove that in an adversarial setting using this subset for prediction is optimal in Domain Generalization; we further provide examples, in which the tasks are sufficiently diverse and the estimator therefore outperforms pooling the data, even on average. If examples from the test task are available, we also provide a method to transfer knowledge from the training tasks and exploit all available features for prediction. However, we provide no guarantees for this method. We introduce a practical method which allows for automatic inference of the above subset and provide corresponding code. We present results on synthetic data sets and a gene deletion data set.},
journal = {J. Mach. Learn. Res.},
month = {jan},
pages = {1309–1342},
numpages = {34},
keywords = {transfer learning, domain generalization, causality, multi-task learning, domain adaptation}
}

@misc{zeng2023survey,
      title={A Survey on Causal Reinforcement Learning}, 
      author={Yan Zeng and Ruichu Cai and Fuchun Sun and Libo Huang and Zhifeng Hao},
      year={2023},
      eprint={2302.05209},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{waic, author = {Watanabe, Sumio}, title = {A Widely Applicable Bayesian Information Criterion}, year = {2013}, issue_date = {January 2013}, publisher = {JMLR.org}, volume = {14}, number = {1}, issn = {1532-4435}, abstract = {A statistical model or a learning machine is called regular if the map taking a parameter to a probability distribution is one-to-one and if its Fisher information matrix is always positive definite. If otherwise, it is called singular. In regular statistical models, the Bayes free energy, which is defined by the minus logarithm of Bayes marginal likelihood, can be asymptotically approximated by the Schwarz Bayes information criterion (BIC), whereas in singular models such approximation does not hold.Recently, it was proved that the Bayes free energy of a singular model is asymptotically given by a generalized formula using a birational invariant, the real log canonical threshold (RLCT), instead of half the number of parameters in BIC. Theoretical values of RLCTs in several statistical models are now being discovered based on algebraic geometrical methodology. However, it has been difficult to estimate the Bayes free energy using only training samples, because an RLCT depends on an unknown true distribution.In the present paper, we define a widely applicable Bayesian information criterion (WBIC) by the average log likelihood function over the posterior distribution with the inverse temperature 1/log n, where n is the number of training samples. We mathematically prove that WBIC has the same asymptotic expansion as the Bayes free energy, even if a statistical model is singular for or unrealizable by a statistical model. Since WBIC can be numerically calculated without any information about a true distribution, it is a generalized version of BIC onto singular statistical models.}, journal = {J. Mach. Learn. Res.}, month = {mar}, pages = {867–897}, numpages = {31}, keywords = {widely applicable Bayes information criterion, Bayes marginal likelihood} }