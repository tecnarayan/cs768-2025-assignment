@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@article{Fu2020D4RLDF,
  author    = {Justin Fu and
               Aviral Kumar and
               Ofir Nachum and
               George Tucker and
               Sergey Levine},
  title     = {{D4RL:} Datasets for Deep Data-Driven Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2004.07219},
  year      = {2020}
}

@inproceedings{mujoco,
  author    = {Emanuel Todorov and
               Tom Erez and
               Yuval Tassa},
  title     = {MuJoCo: {A} physics engine for model-based control},
  booktitle = {{IROS}},
  pages     = {5026--5033},
  publisher = {{IEEE}},
  year      = {2012}
}

@article{openai_gym,
  author    = {Greg Brockman and
               Vicki Cheung and
               Ludwig Pettersson and
               Jonas Schneider and
               John Schulman and
               Jie Tang and
               Wojciech Zaremba},
  title     = {OpenAI Gym},
  journal   = {CoRR},
  volume    = {abs/1606.01540},
  year      = {2016}
}

@INPROCEEDINGS{adroit, 
    AUTHOR    = {Aravind Rajeswaran AND Vikash Kumar AND Abhishek Gupta AND Giulia Vezzani AND John Schulman AND Emanuel Todorov AND Sergey Levine}, 
    TITLE     = {Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2018}, 
    ADDRESS   = {Pittsburgh, Pennsylvania}, 
    MONTH     = {June}, 
    DOI       = {10.15607/RSS.2018.XIV.049} 
} 

@article{td3+bc,
  title={A minimalist approach to offline reinforcement learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={20132--20145},
  year={2021}
}


@article{rliable,
  title={Deep reinforcement learning at the edge of the statistical precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29304--29320},
  year={2021}
}

@article{BRAC,
  author    = {Yifan Wu and
               George Tucker and
               Ofir Nachum},
  title     = {Behavior Regularized Offline Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1911.11361},
  year      = {2019}
}

@inproceedings{Fisher-BRC,
  title={Offline reinforcement learning with fisher divergence critic regularization},
  author={Kostrikov, Ilya and Fergus, Rob and Tompson, Jonathan and Nachum, Ofir},
  booktitle={International Conference on Machine Learning},
  pages={5774--5783},
  year={2021},
  organization={PMLR}
}

@article{CQL,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@inproceedings{IQL,
  author    = {Ilya Kostrikov and
               Ashvin Nair and
               Sergey Levine},
  title     = {Offline Reinforcement Learning with Implicit Q-Learning},
  booktitle = {{International Conference on Learning Representations}},
  year      = {2022}
}

@article{AWAC,
  author    = {Ashvin Nair and
               Murtaza Dalal and
               Abhishek Gupta and
               Sergey Levine},
  title     = {Accelerating Online Reinforcement Learning with Offline Datasets},
  journal   = {CoRR},
  volume    = {abs/2006.09359},
  year      = {2020}
}


@article{DT,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={15084--15097},
  year={2021}
}

@article{BEAR,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


@article{preference_survey,
  title={A survey of preference-based reinforcement learning methods},
  author={Wirth, Christian and Akrour, Riad and Neumann, Gerhard and F{\"u}rnkranz, Johannes and others},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={136},
  pages={1--46},
  year={2017},
  publisher={Journal of Machine Learning Research/Massachusetts Institute of Technology~â€¦}
}

@inproceedings{ranknet,
  title={Learning to rank using gradient descent},
  author={Burges, Chris and Shaked, Tal and Renshaw, Erin and Lazier, Ari and Deeds, Matt and Hamilton, Nicole and Hullender, Greg},
  booktitle={International Conference on Machine Learning},
  pages={89--96},
  year={2005}
}

@article{offline_survey_sergey,
  author    = {Sergey Levine and
               Aviral Kumar and
               George Tucker and
               Justin Fu},
  title     = {Offline Reinforcement Learning: Tutorial, Review, and Perspectives
               on Open Problems},
  journal   = {CoRR},
  volume    = {abs/2005.01643},
  year      = {2020}
}

@misc{sutton1998introduction,
  title={Introduction to Reinforcement Learning},
  author={Sutton, Richard S and Barto, Andrew G},
  year={1998},
  publisher={MIT Press}
}

@article{offline_survey_rafael,
  author    = {Rafael Figueiredo Prudencio and
               Marcos R. O. A. M{\'{a}}ximo and
               Esther Luna Colombini},
  title     = {A Survey on Offline Reinforcement Learning: Taxonomy, Review, and
               Open Problems},
  journal   = {CoRR},
  volume    = {abs/2203.01387},
  year      = {2022}
}

@article{robotics_survey,
  author    = {Bharat Singh and
               Rajesh Kumar and
               Vinay Pratap Singh},
  title     = {Reinforcement learning in robotic applications: a comprehensive survey},
  journal   = {Artif. Intell. Rev.},
  volume    = {55},
  number    = {2},
  pages     = {945--990},
  year      = {2022}
}

@article{education_survey,
  author    = {Adish Singla and
               Anna N. Rafferty and
               Goran Radanovic and
               Neil T. Heffernan},
  title     = {Reinforcement Learning for Education: Opportunities and Challenges},
  journal   = {CoRR},
  volume    = {abs/2107.08828},
  year      = {2021}
}

@article{healthcare_survey,
  title={Reinforcement learning for clinical decision support in critical care: comprehensive review},
  author={Liu, Siqi and See, Kay Choong and Ngiam, Kee Yuan and Celi, Leo Anthony and Sun, Xingzhi and Feng, Mengling and others},
  journal={Journal of Medical Internet Research},
  volume={22},
  number={7},
  pages={e18477},
  year={2020},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@article{autonomous_driving_survey,
  title={Deep reinforcement learning for autonomous driving: A survey},
  author={Kiran, B Ravi and Sobh, Ibrahim and Talpaert, Victor and Mannion, Patrick and Al Sallab, Ahmad A and Yogamani, Senthil and P{\'e}rez, Patrick},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={23},
  number={6},
  pages={4909--4926},
  year={2021},
  publisher={IEEE}
}

@inproceedings{Off_Policy_Deep_Reinforcement_Learning_without_Exploration,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}


@inproceedings{reward_weighted_regression,
  author    = {Jan Peters and
               Stefan Schaal},
  title     = {Reinforcement learning by reward-weighted regression for operational space control},
  booktitle = {{ICML}},
  series    = {{ACM} International Conference Proceeding Series},
  volume    = {227},
  pages     = {745--750},
  publisher = {{ACM}},
  year      = {2007}
}

@article{Advantage_Weighted_Regression,
  author    = {Xue Bin Peng and
               Aviral Kumar and
               Grace Zhang and
               Sergey Levine},
  title     = {Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1910.00177},
  year      = {2019}
}


@article{Critic_Regularized_Regression,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and Zolna, Konrad and Merel, Josh S and Springenberg, Jost Tobias and Reed, Scott E and Shahriari, Bobak and Siegel, Noah and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7768--7778},
  year={2020}
}

@inproceedings{EMaQ,
  title={Emaq: Expected-max q-learning operator for simple yet effective offline and online rl},
  author={Ghasemipour, Seyed Kamyar Seyed and Schuurmans, Dale and Gu, Shixiang Shane},
  booktitle={International Conference on Machine Learning},
  pages={3682--3691},
  year={2021},
  organization={PMLR}
}

@inproceedings{PPO+BC,
  title={BC + RL : Imitation Learning From Non-Optimal Demonstrations},
  author={Jonathan Booher},
  year={2019}
}

@inproceedings{DDPG_BC,
  author    = {Ashvin Nair and
               Bob McGrew and
               Marcin Andrychowicz and
               Wojciech Zaremba and
               Pieter Abbeel},
  title     = {Overcoming Exploration in Reinforcement Learning with Demonstrations},
  booktitle = {International Conference on Robotics and Automation},
  year      = {2018},
}

@book{Preference_Learning,
  editor    = {Johannes F{\"{u}}rnkranz and
               Eyke H{\"{u}}llermeier},
  title     = {Preference Learning},
  publisher = {Springer},
  year      = {2010}
}

@inproceedings{Pairwise_Preference_Learning_and_Ranking,
  author    = {Johannes F{\"{u}}rnkranz and
               Eyke H{\"{u}}llermeier},
  title     = {Pairwise Preference Learning and Ranking},
  booktitle = {{ECML}},
  series    = {Lecture Notes in Computer Science},
  volume    = {2837},
  pages     = {145--156},
  publisher = {Springer},
  year      = {2003}
}

@article{mcrank,
  title={Mcrank: Learning to rank using multiple classification and gradient boosting},
  author={Li, Ping and Wu, Qiang and Burges, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={20},
  year={2007}
}


@article{lambdarank,
  title={Learning to rank with nonsmooth cost functions},
  author={Burges, Christopher and Ragno, Robert and Le, Quoc},
  journal={Advances in Neural Information Processing Systems},
  volume={19},
  year={2006}
}

@article{lambdamart,
  title={From ranknet to lambdarank to lambdamart: An overview},
  author={Burges, Christopher JC},
  journal={Learning},
  volume={11},
  number={23-581},
  pages={81},
  year={2010}
}

@inproceedings{fu2019diagnosing,
  title={Diagnosing bottlenecks in deep q-learning algorithms},
  author={Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={2021--2030},
  year={2019},
  organization={PMLR}
}

@article{kumar2020discor,
  title={Discor: Corrective feedback in reinforcement learning via distribution correction},
  author={Kumar, Aviral and Gupta, Abhishek and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18560--18572},
  year={2020}
}

@inproceedings{
anonymous2023actorcritic,
title={Actor-Critic Alignment for Offline-to-Online Reinforcement Learning},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations },
year={2023}
}

@inproceedings{TRPO,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={International Conference on Machine Learning},
  year={2002},
  organization={Citeseer}
}

@article{yu2020dynamic,
  author    = {Yiqin Yu and
               Xu Min and
               Shiwan Zhao and
               Jing Mei and
               Fei Wang and
               Dongsheng Li and
               Kenney Ng and
               Shaochun Li},
  title     = {Dynamic Knowledge Distillation for Black-box Hypothesis Transfer Learning},
  journal   = {CoRR},
  volume    = {abs/2007.12355},
  year      = {2020}
}

@article{chi2021tohan,
  title={TOHAN: A one-step approach towards few-shot hypothesis adaptation},
  author={Chi, Haoang and Liu, Feng and Yang, Wenjing and Lan, Long and Liu, Tongliang and Han, Bo and Cheung, William and Kwok, James},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={20970--20982},
  year={2021}
}

@article{wilmer2009markov,
  title={Markov chains and mixing times},
  author={Wilmer, EL and Levin, David A and Peres, Yuval},
  journal={American Mathematical Soc., Providence},
  year={2009}
}

@inproceedings{sac,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@inproceedings{Adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {International Conference on Learning Representations},
  year      = {2015},
}


@article{relu,
  author    = {Abien Fred Agarap},
  title     = {Deep Learning using Rectified Linear Units (ReLU)},
  journal   = {CoRR},
  volume    = {abs/1803.08375},
  year      = {2018}
}



@article{
yue2022boosting,
title={Boosting Offline Reinforcement Learning via Data Rebalancing},
author={Yang Yue and Bingyi Kang and Xiao Ma and Zhongwen Xu and Gao Huang and Shuicheng YAN},
journal={Advances in Neural Information Processing Systems, Workshop},
year={2022}
}


@article{yue2022value,
  title={Value-Consistent Representation Learning for Data-Efficient Reinforcement Learning},
  author={Yue, Yang and Kang, Bingyi and Xu, Zhongwen and Huang, Gao and Yan, Shuicheng},
  journal={Association for the Advancement of Artificial Intelligence},
  year={2023}
}