\begin{thebibliography}{108}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[fai()]{fairlearn}
{Fairlearn Library}.
\newblock URL \url{https://fairlearn.org/}.

\bibitem[gob()]{gobj}
{Global Objectives Library}.
\newblock URL
  \url{https://git.dst.etit.tu-chemnitz.de/external/tf-models/-/tree/master/research/global_objectives}.

\bibitem[tfc()]{tfco}
{TensorFlow Constrained Optimization Library}.
\newblock URL
  \url{https://github.com/google-research/tensorflow_constrained_optimization}.

\bibitem[Agarwal et~al.(2018)Agarwal, Beygelzimer, Dudik, Langford, and
  Wallach]{agarwal2018reductions}
Alekh Agarwal, Alina Beygelzimer, Miroslav Dudik, John Langford, and Hanna
  Wallach.
\newblock A reductions approach to fair classification.
\newblock In \emph{International Conference on Machine Learning}, pages 60--69,
  2018.

\bibitem[Bach et~al.(2006)Bach, Heckerman, and Horvitz]{Bach:2006}
Francis~R. Bach, David Heckerman, and Eric Horvitz.
\newblock Considering cost asymmetry in learning classifiers.
\newblock \emph{Journal of Machine Learning Research}, 7\penalty0
  (63):\penalty0 1713--1741, 2006.
\newblock URL \url{http://jmlr.org/papers/v7/bach06a.html}.

\bibitem[Brodersen et~al.(2010)Brodersen, Ong, Stephan, and
  Buhmann]{Brodersen:2010}
Kay~Henning Brodersen, Cheng~Soon Ong, Klaas~Enno Stephan, and Joachim~M.
  Buhmann.
\newblock The balanced accuracy and its posterior distribution.
\newblock In \emph{2010 20th International Conference on Pattern Recognition},
  pages 3121--3124, 2010.
\newblock \doi{10.1109/ICPR.2010.764}.

\bibitem[Bruch et~al.(2019)Bruch, Zoghi, Bendersky, and Najork]{Bruch+2019}
Sebastian Bruch, Masrour Zoghi, Mike Bendersky, and Marc Najork.
\newblock Revisiting approximate metric optimization in the age of deep neural
  networks.
\newblock In \emph{Proceedings of the 42nd International ACM SIGIR Conference
  on Research and Development in Information Retrieval (SIGIR '19)}, pages
  1241--1244, 2019.

\bibitem[Buda et~al.(2017)Buda, Maki, and Mazurowski]{Buda:2017}
Mateusz Buda, Atsuto Maki, and Maciej~A. Mazurowski.
\newblock A systematic study of the class imbalance problem in convolutional
  neural networks.
\newblock \emph{arXiv:1710.05381 [cs, stat]}, October 2017.

\bibitem[Cao et~al.(2019)Cao, Wei, Gaidon, Arechiga, and Ma]{Cao:2019}
Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, and Tengyu Ma.
\newblock Learning imbalanced datasets with label-distribution-aware margin
  loss.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Chawla et~al.(2002)Chawla, Bowyer, Hall, and Kegelmeyer]{Chawla:2002}
Nitesh~V. Chawla, Kevin~W. Bowyer, Lawrence~O. Hall, and W.~Philip Kegelmeyer.
\newblock {SMOTE}: Synthetic minority over-sampling technique.
\newblock \emph{Journal of Artificial Intelligence Research (JAIR)},
  16:\penalty0 321--357, 2002.

\bibitem[Chen et~al.(2017)Chen, Lucier, Singer, and Syrgkanis]{chen2017robust}
Robert~S Chen, Brendan Lucier, Yaron Singer, and Vasilis Syrgkanis.
\newblock Robust optimization for non-convex objectives.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4705--4714, 2017.

\bibitem[Collell et~al.(2016)Collell, Prelec, and Patil]{Collell:2016}
Guillem Collell, Drazen Prelec, and Kaustubh~R. Patil.
\newblock Reviving threshold-moving: a simple plug-in bagging ensemble for
  binary and multiclass imbalanced data.
\newblock \emph{CoRR}, abs/1606.08698, 2016.

\bibitem[Cotter et~al.(2019{\natexlab{a}})Cotter, Gupta, Jiang, Srebro,
  Sridharan, Wang, Woodworth, and You]{cotter2019training}
Andrew Cotter, Maya Gupta, Heinrich Jiang, Nathan Srebro, Karthik Sridharan,
  Serena Wang, Blake Woodworth, and Seungil You.
\newblock Training well-generalizing classifiers for fairness metrics and other
  data-dependent constraints.
\newblock In \emph{International Conference on Machine Learning}, pages
  1397--1405. PMLR, 2019{\natexlab{a}}.

\bibitem[Cotter et~al.(2019{\natexlab{b}})Cotter, Gupta, and
  Narasimhan]{cotter19stochastic}
Andrew Cotter, Maya Gupta, and Harikrishna Narasimhan.
\newblock On making stochastic classifiers deterministic.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2019{\natexlab{b}}.

\bibitem[Cotter et~al.(2019{\natexlab{c}})Cotter, Jiang, Wang, Narayan, You,
  Sridharan, and Gupta]{cotter2019optimization}
Andrew Cotter, Heinrich Jiang, Serena Wang, Taman Narayan, Seungil You, Karthik
  Sridharan, and Maya~R. Gupta.
\newblock Optimization with non-differentiable constraints with applications to
  fairness, recall, churn, and other goals.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 20\penalty0
  (172):\penalty0 1--59, 2019{\natexlab{c}}.

\bibitem[Crammer and Singer(2001)]{crammer2001algorithmic}
Koby Crammer and Yoram Singer.
\newblock On the algorithmic implementation of multiclass kernel-based vector
  machines.
\newblock \emph{Journal of machine learning research}, 2\penalty0
  (Dec):\penalty0 265--292, 2001.

\bibitem[Cui et~al.(2019)Cui, Jia, Lin, Song, and Belongie]{Cui:2019}
Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie.
\newblock Class-balanced loss based on effective number of samples.
\newblock In \emph{CVPR}, 2019.

\bibitem[Davenport et~al.(2006)Davenport, Baraniuk, and Scott]{Davenport:2006}
M.A. Davenport, R.G. Baraniuk, and C.D. Scott.
\newblock Controlling false alarms with support vector machines.
\newblock In \emph{2006 IEEE International Conference on Acoustics Speech and
  Signal Processing Proceedings}, volume~5, pages V--V, 2006.
\newblock \doi{10.1109/ICASSP.2006.1661344}.

\bibitem[Dembczy{\'n}ski et~al.(2017)Dembczy{\'n}ski, Kot{\l}owski, Koyejo, and
  Natarajan]{dembczynski2017consistency}
Krzysztof Dembczy{\'n}ski, Wojciech Kot{\l}owski, Oluwasanmi Koyejo, and
  Nagarajan Natarajan.
\newblock Consistency analysis for binary classification revisited.
\newblock In \emph{International Conference on Machine Learning}, pages
  961--969. PMLR, 2017.

\bibitem[Deng et~al.(2021)Deng, Liu, Wang, Wang, Yu, and Sun]{Deng:2021}
Zongyong Deng, Hao Liu, Yaoxing Wang, Chenyang Wang, Zekuan Yu, and Xuehong
  Sun.
\newblock {PML:} progressive margin loss for long-tailed age classification.
\newblock \emph{CoRR}, abs/2103.02140, 2021.
\newblock URL \url{https://arxiv.org/abs/2103.02140}.

\bibitem[Dmochowski et~al.(2010)Dmochowski, Sajda, and Parra]{Dmochowski:2010}
Jacek~P. Dmochowski, Paul Sajda, and Lucas~C. Parra.
\newblock Maximum likelihood in cost-sensitive learning: Model specification,
  approximations, and upper bounds.
\newblock \emph{Journal of Machine Learning Research}, 11\penalty0
  (108):\penalty0 3313--3332, 2010.

\bibitem[Domingos(1999)]{Domingos:1999}
Pedro Domingos.
\newblock Metacost: A general method for making classifiers cost-sensitive.
\newblock In \emph{Proceedings of the Fifth ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, KDD '99, page 155–164, New York,
  NY, USA, 1999. Association for Computing Machinery.
\newblock ISBN 1581131437.
\newblock \doi{10.1145/312129.312220}.
\newblock URL \url{https://doi.org/10.1145/312129.312220}.

\bibitem[Dwork et~al.(2012)Dwork, Hardt, Pitassi, Reingold, and
  Zemel]{Dwork:2012}
Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel.
\newblock Fairness through awareness.
\newblock In \emph{Innovations in Theoretical Computer Science Conference
  (ITCS)}, pages 214--226, 2012.

\bibitem[Eban et~al.(2017)Eban, Schain, Mackey, Gordon, Rifkin, and
  Elidan]{eban2017scalable}
Elad Eban, Mariano Schain, Alan Mackey, Ariel Gordon, Ryan Rifkin, and Gal
  Elidan.
\newblock Scalable learning of non-decomposable objectives.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 832--840.
  PMLR, 2017.

\bibitem[Elkan(2001)]{Elkan:2001}
Charles Elkan.
\newblock The foundations of cost-sensitive learning.
\newblock In \emph{Proceedings of the 17th International Joint Conference on
  Artificial Intelligence - Volume 2}, IJCAI'01, page 973–978, San Francisco,
  CA, USA, 2001. Morgan Kaufmann Publishers Inc.
\newblock ISBN 1558608125.

\bibitem[Fawcett and Provost(1996)]{Fawcett:1996}
Tom Fawcett and Foster Provost.
\newblock Combining data mining and machine learning for effective user
  profiling.
\newblock In \emph{Proceedings of the ACM SIGKDD International Conference on
  Knowledge Discovery and Data Mining (KDD)}, pages 8--13. AAAI Press, 1996.

\bibitem[Furlanello et~al.(2018)Furlanello, Lipton, Tschannen, Itti, and
  Anandkumar]{furlanello2018born}
Tommaso Furlanello, Zachary Lipton, Michael Tschannen, Laurent Itti, and Anima
  Anandkumar.
\newblock Born again neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  1607--1616. PMLR, 2018.

\bibitem[Gneiting and Raftery(2007)]{gneiting2007strictly}
Tilmann Gneiting and Adrian~E Raftery.
\newblock Strictly proper scoring rules, prediction, and estimation.
\newblock \emph{Journal of the American statistical Association}, 102\penalty0
  (477):\penalty0 359--378, 2007.

\bibitem[Goh et~al.(2016)Goh, Cotter, Gupta, and
  Friedlander]{goh2016satisfying}
Gabriel Goh, Andrew Cotter, Maya Gupta, and Michael~P Friedlander.
\newblock Satisfying real-world goals with dataset constraints.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2415--2423, 2016.

\bibitem[Hardt et~al.(2016)Hardt, Price, and Srebro]{hardt2016equality}
Moritz Hardt, Eric Price, and Nati Srebro.
\newblock Equality of opportunity in supervised learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3315--3323, 2016.

\bibitem[He and Garcia(2009)]{HeGa09}
Haibo He and Edwardo~A. Garcia.
\newblock Learning from imbalanced data.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering},
  21\penalty0 (9):\penalty0 1263--1284, 2009.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, and Dean]{Hinton:2015}
G.~Hinton, O.~Vinyals, and J.~Dean.
\newblock Distilling the knowledge in a neural network.
\newblock \emph{arXiv:1503.02531}, 2015.

\bibitem[Huang et~al.(2019)Huang, Zhai, Talbott, Martin, Sun, Guestrin, and
  Susskind]{huang2019addressing}
Chen Huang, Shuangfei Zhai, Walter Talbott, Miguel~Bautista Martin, Shih-Yu
  Sun, Carlos Guestrin, and Josh Susskind.
\newblock Addressing the loss-metric mismatch with adaptive loss alignment.
\newblock In \emph{International Conference on Machine Learning}, pages
  2891--2900. PMLR, 2019.

\bibitem[Iranmehr et~al.(2019)Iranmehr, Masnadi{-}Shirazi, and
  Vasconcelos]{Iranmehr:2019}
Arya Iranmehr, Hamed Masnadi{-}Shirazi, and Nuno Vasconcelos.
\newblock Cost-sensitive support vector machines.
\newblock \emph{Neurocomputing}, 343:\penalty0 50--64, 2019.

\bibitem[Jamal et~al.(2020)Jamal, Brown, Yang, Wang, and Gong]{Jamal:2020}
Muhammad~Abdullah Jamal, Matthew Brown, Ming-Hsuan Yang, Liqiang Wang, and
  Boqing Gong.
\newblock Rethinking class-balanced methods for long-tailed visual recognition
  from a domain adaptation perspective.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, June 2020.

\bibitem[Joachims(2005)]{joachims2005support}
Thorsten Joachims.
\newblock A support vector method for multivariate performance measures.
\newblock In \emph{Proceedings of the 22nd international conference on Machine
  learning}, pages 377--384. ACM, 2005.

\bibitem[Johnson and Khoshgoftaar(2019)]{Johnson:2019}
Justin Johnson and Taghi Khoshgoftaar.
\newblock Survey on deep learning with class imbalance.
\newblock \emph{Journal of Big Data}, 6:\penalty0 27, 03 2019.

\bibitem[Kang et~al.(2020)Kang, Xie, Rohrbach, Yan, Gordo, Feng, and
  Kalantidis]{Kang:2020}
Bingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan, Albert Gordo, Jiashi
  Feng, and Yannis Kalantidis.
\newblock Decoupling representation and classifier for long-tailed recognition.
\newblock In \emph{Eighth International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Kar et~al.(2014)Kar, Narasimhan, and Jain]{kar2014online}
Purushottam Kar, Harikrishna Narasimhan, and Prateek Jain.
\newblock Online and stochastic gradient methods for non-decomposable loss
  functions.
\newblock \emph{Advances in Neural Information Processing Systems}, 2014.

\bibitem[Karakoulas and Shawe-Taylor(1998)]{Karakoulas:1998}
Grigoris Karakoulas and John Shawe-Taylor.
\newblock Optimizing classifiers for imbalanced training sets.
\newblock In \emph{Proceedings of the 11th International Conference on Neural
  Information Processing Systems}, NIPS'98, page 253–259, Cambridge, MA, USA,
  1998. MIT Press.

\bibitem[Khan et~al.(2018)Khan, Hayat, Bennamoun, Sohel, and
  Togneri]{Khan:2018}
Salman~H. Khan, Munawar Hayat, Mohammed Bennamoun, Ferdous~A. Sohel, and
  Roberto Togneri.
\newblock Cost-sensitive learning of deep feature representations from
  imbalanced data.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  29\penalty0 (8):\penalty0 3573--3587, 2018.
\newblock \doi{10.1109/TNNLS.2017.2732482}.

\bibitem[Kini et~al.(2021)Kini, Paraskevas, Oymak, and
  Thrampoulidis]{Kini:2021}
Ganesh~Ramachandra Kini, Orestis Paraskevas, Samet Oymak, and Christos
  Thrampoulidis.
\newblock Label-imbalanced and group-sensitive classification under
  overparameterization.
\newblock \emph{CoRR}, abs/2103.01550, 2021.
\newblock URL \url{https://arxiv.org/abs/2103.01550}.

\bibitem[Koyejo et~al.(2014)Koyejo, Natarajan, Ravikumar, and
  Dhillon]{koyejo2014consistent}
Oluwasanmi~O Koyejo, Nagarajan Natarajan, Pradeep~K Ravikumar, and Inderjit~S
  Dhillon.
\newblock Consistent binary classification with generalized performance
  metrics.
\newblock In \emph{NIPS}, pages 2744--2752, 2014.

\bibitem[Krizhevsky(2009)]{Krizhevsky09learningmultiple}
Alex Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, University of Toronto, 2009.

\bibitem[Kubat and Matwin(1997)]{KubatMa97}
Miroslav Kubat and Stan Matwin.
\newblock Addressing the curse of imbalanced training sets: One-sided
  selection.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, 1997.

\bibitem[Kubat et~al.(1997)Kubat, Holte, and Matwin]{Kubat:1997a}
Miroslav Kubat, Robert Holte, and Stan Matwin.
\newblock Learning when negative examples abound.
\newblock In Maarten van Someren and Gerhard Widmer, editors, \emph{Proceedings
  of the European Conference on Machine Learning (ECML)}, volume 1224 of
  \emph{Lecture Notes in Computer Science}, pages 146--153. Springer Berlin
  Heidelberg, 1997.
\newblock ISBN 978-3-540-62858-3.

\bibitem[Kumar et~al.(2021, to appear)Kumar, Narasimhan, and
  Cotter]{Kumar+2021}
Abhishek Kumar, Harikrishna Narasimhan, and Andrew Cotter.
\newblock Implicit rate-constrained optimization of non-decomposable
  objectives.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2021,
  to appear.

\bibitem[Lawrence et~al.(1998)Lawrence, Burns, Back, Tsoi, and
  Giles]{Lawrence:1998}
Steve Lawrence, Ian Burns, Andrew~D. Back, Ah~Chung Tsoi, and C.~Lee Giles.
\newblock Neural network classification and prior class probabilities.
\newblock In \emph{Neural Networks: Tricks of the Trade, This Book is an
  Outgrowth of a 1996 NIPS Workshop}, page 299–313, Berlin, Heidelberg, 1998.
  Springer-Verlag.
\newblock ISBN 3540653112.

\bibitem[Le and Yang(2015)]{le2015tiny}
Ya~Le and Xuan Yang.
\newblock Tiny imagenet visual recognition challenge.
\newblock CS 231N, 2015.

\bibitem[Lee et~al.(2004)Lee, Lin, and Wahba]{lee2004multicategory}
Yoonkyung Lee, Yi~Lin, and Grace Wahba.
\newblock Multicategory support vector machines: Theory and application to the
  classification of microarray data and satellite radiance data.
\newblock \emph{Journal of the American Statistical Association}, 99\penalty0
  (465):\penalty0 67--81, 2004.

\bibitem[Lewis and Gale(1994)]{Lewis:1994}
David~D. Lewis and William~A. Gale.
\newblock A sequential algorithm for training text classifiers.
\newblock In \emph{Proceedings of the 17th Annual International ACM SIGIR
  Conference on Research and Development in Information Retrieval}, SIGIR '94,
  page 3–12, Berlin, Heidelberg, 1994. Springer-Verlag.
\newblock ISBN 038719889X.

\bibitem[Li et~al.(2002)Li, Zaragoza, Herbrich, Shawe-Taylor, and
  Kandola]{Li:2002}
Yaoyong Li, Hugo Zaragoza, Ralf Herbrich, John Shawe-Taylor, and Jaz~S.
  Kandola.
\newblock The perceptron algorithm with uneven margins.
\newblock In \emph{Proceedings of the Nineteenth International Conference on
  Machine Learning}, ICML ’02, page 379–386, San Francisco, CA, USA, 2002.
  Morgan Kaufmann Publishers Inc.
\newblock ISBN 1558608737.

\bibitem[Lin et~al.(2017)Lin, Goyal, Girshick, He, and
  Doll{\'a}r]{lin2017focal}
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
\newblock Focal loss for dense object detection.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 2980--2988, 2017.

\bibitem[Lin et~al.(2002)Lin, Lee, and Wahba]{Lin:2002}
Yi~Lin, Yoonkyung Lee, and Grace Wahba.
\newblock Support vector machines for classification in nonstandard situations.
\newblock \emph{Mach. Learn.}, 46\penalty0 (1–3):\penalty0 191–202, March
  2002.
\newblock ISSN 0885-6125.

\bibitem[Ling and Sheng(2010)]{Ling:2010}
Charles Ling and Victor Sheng.
\newblock Cost-sensitive learning and the class imbalance problem.
\newblock \emph{Encyclopedia of Machine Learning}, 01 2010.

\bibitem[Maloof(2003)]{Maloof03}
Marcus~A. Maloof.
\newblock Learning when data sets are imbalanced and when costs are unequal and
  unknown.
\newblock In \emph{ICML 2003 Workshop on Learning from Imbalanced Datasets},
  2003.

\bibitem[Masnadi-Shirazi and Vasconcelos(2010)]{Masnadi-Shirazi:2010}
Hamed Masnadi-Shirazi and Nuno Vasconcelos.
\newblock Risk minimization, probability elicitation, and cost-sensitive
  {SVM}s.
\newblock In \emph{Proceedings of the 27th International Conference on
  International Conference on Machine Learning}, ICML’10, page 759–766,
  Madison, WI, USA, 2010. Omnipress.
\newblock ISBN 9781605589077.

\bibitem[Menon et~al.(2013)Menon, Narasimhan, Agarwal, and
  Chawla]{menon2013statistical}
Aditya Menon, Harikrishna Narasimhan, Shivani Agarwal, and Sanjay Chawla.
\newblock On the statistical consistency of algorithms for binary
  classification under class imbalance.
\newblock In \emph{International Conference on Machine Learning}, pages
  603--611, 2013.

\bibitem[Menon et~al.(2020)Menon, Jayasumana, Rawat, Jain, Veit, and
  Kumar]{menon2020long}
Aditya~Krishna Menon, Sadeep Jayasumana, Ankit~Singh Rawat, Himanshu Jain,
  Andreas Veit, and Sanjiv Kumar.
\newblock Long-tail learning via logit adjustment.
\newblock \emph{arXiv preprint arXiv:2007.07314}, 2020.

\bibitem[Mohri et~al.(2019)Mohri, Sivek, and Suresh]{Mohri:2019}
Mehryar Mohri, Gary Sivek, and Ananda~Theertha Suresh.
\newblock Agnostic federated learning.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Morik et~al.(1999)Morik, Brockhausen, and Joachims]{Morik:1999}
Katharina Morik, Peter Brockhausen, and Thorsten Joachims.
\newblock Combining statistical learning with a knowledge-based approach - a
  case study in intensive care monitoring.
\newblock In \emph{Proceedings of the Sixteenth International Conference on
  Machine Learning (ICML)}, pages 268--277, San Francisco, CA, USA, 1999.
  Morgan Kaufmann Publishers Inc.
\newblock ISBN 1-55860-612-2.

\bibitem[Nakkiran et~al.(2020)Nakkiran, Kaplun, Bansal, Yang, Barak, and
  Sutskever]{Nakkiran:2020}
Preetum Nakkiran, Gal Kaplun, Yamini Bansal, Tristan Yang, Boaz Barak, and Ilya
  Sutskever.
\newblock Deep double descent: Where bigger models and more data hurt.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Narasimhan(2018)]{narasimhan2018learning}
Harikrishna Narasimhan.
\newblock Learning with complex loss functions and constraints.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 1646--1654, 2018.

\bibitem[Narasimhan et~al.(2014)Narasimhan, Vaish, and
  Agarwal]{narasimhan2014statistical}
Harikrishna Narasimhan, Rohit Vaish, and Shivani Agarwal.
\newblock On the statistical consistency of plug-in classifiers for
  non-decomposable performance measures.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1493--1501, 2014.

\bibitem[Narasimhan et~al.(2015{\natexlab{a}})Narasimhan, Kar, and
  Jain]{narasimhan2015optimizing}
Harikrishna Narasimhan, Purushottam Kar, and Prateek Jain.
\newblock Optimizing non-decomposable performance measures: A tale of two
  classes.
\newblock In \emph{International Conference on Machine Learning}, pages
  199--208. PMLR, 2015{\natexlab{a}}.

\bibitem[Narasimhan et~al.(2015{\natexlab{b}})Narasimhan, Ramaswamy, Saha, and
  Agarwal]{narasimhan2015consistent}
Harikrishna Narasimhan, Harish Ramaswamy, Aadirupa Saha, and Shivani Agarwal.
\newblock Consistent multiclass algorithms for complex performance measures.
\newblock In \emph{ICML}, pages 2398--2407, 2015{\natexlab{b}}.

\bibitem[Narasimhan et~al.(2019)Narasimhan, Cotter, and
  Gupta]{narasimhan2019optimizing}
Harikrishna Narasimhan, Andrew Cotter, and Maya Gupta.
\newblock Optimizing generalized rate metrics with three players.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  10746--10757, 2019.

\bibitem[Natarajan et~al.(2016)Natarajan, Koyejo, Ravikumar, and
  Dhillon]{natarajan2016optimal}
Nagarajan Natarajan, Oluwasanmi Koyejo, Pradeep Ravikumar, and Inderjit
  Dhillon.
\newblock Optimal classification with multivariate losses.
\newblock In \emph{International Conference on Machine Learning}, pages
  1530--1538. PMLR, 2016.

\bibitem[Neyshabur et~al.(2019)Neyshabur, Li, Bhojanapalli, LeCun, and
  Srebro]{Neyshabur:2019}
Behnam Neyshabur, Zhiyuan Li, Srinadh Bhojanapalli, Yann LeCun, and Nathan
  Srebro.
\newblock The role of over-parametrization in generalization of neural
  networks.
\newblock In \emph{7th International Conference on Learning Representations,
  {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019}. OpenReview.net, 2019.

\bibitem[Parambath et~al.(2014)Parambath, Usunier, and
  Grandvalet]{parambath2014optimizing}
Shameem~Puthiya Parambath, Nicolas Usunier, and Yves Grandvalet.
\newblock Optimizing f-measures by cost-sensitive classification.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2123--2131, 2014.

\bibitem[Patrini et~al.(2017)Patrini, Rozza, Krishna~Menon, Nock, and
  Qu]{patrini2017making}
Giorgio Patrini, Alessandro Rozza, Aditya Krishna~Menon, Richard Nock, and
  Lizhen Qu.
\newblock Making deep neural networks robust to label noise: A loss correction
  approach.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 1944--1952, 2017.

\bibitem[Provost(2000)]{Provost:2000}
Foster Provost.
\newblock {Machine learning from imbalanced data sets 101}.
\newblock In \emph{Proceedings of the AAAI-2000 Workshop on Imbalanced Data
  Sets}, 2000.

\bibitem[Qi et~al.(2021)Qi, Luo, Xu, Ji, and Yang]{Qi+2021}
Qi~Qi, Youzhi Luo, Zhao Xu, Shuiwang Ji, and Tianbao Yang.
\newblock Stochastic optimization of area under precision-recall curve for deep
  learning with provable convergence.
\newblock \emph{CoRR}, abs/2104.08736, 2021.
\newblock URL \url{https://arxiv.org/abs/2104.08736}.

\bibitem[Ramaswamy and Agarwal(2016)]{ramaswamy2016convex}
Harish~G Ramaswamy and Shivani Agarwal.
\newblock Convex calibration dimension for multiclass loss matrices.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 397--441, 2016.

\bibitem[Ren et~al.(2020)Ren, Yu, sheng, Ma, Zhao, Yi, and Li]{Ren:2020}
Jiawei Ren, Cunjun Yu, shunan sheng, Xiao Ma, Haiyu Zhao, Shuai Yi, and
  hongsheng Li.
\newblock Balanced meta-softmax for long-tailed visual recognition.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 4175--4186. Curran Associates, Inc., 2020.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{ILSVRC15}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein,
  Alexander~C. Berg, and Li~Fei-Fei.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock \emph{International Journal of Computer Vision (IJCV)}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[Rusu et~al.(2016)Rusu, Colmenarejo, G{\"u}l{{c}}ehre, Desjardins,
  Kirkpatrick, Pascanu, Mnih, Kavukcuoglu, and Hadsell]{rusu2016policy}
Andrei~A Rusu, Sergio~Gomez Colmenarejo, {{C}}aglar G{\"u}l{{c}}ehre, Guillaume
  Desjardins, James Kirkpatrick, Razvan Pascanu, Volodymyr Mnih, Koray
  Kavukcuoglu, and Raia Hadsell.
\newblock Policy distillation.
\newblock In \emph{ICLR (Poster)}, 2016.

\bibitem[Sagawa et~al.(2020)Sagawa, Raghunathan, Koh, and Liang]{Sagawa:2020b}
S.~Sagawa, A.~Raghunathan, P.~W. Koh, and P.~Liang.
\newblock An investigation of why overparameterization exacerbates spurious
  correlations.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Sagawa et~al.(2019)Sagawa, Koh, Hashimoto, and
  Liang]{sagawa2019distributionally}
Shiori Sagawa, Pang~Wei Koh, Tatsunori~B Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Sanyal et~al.(2018)Sanyal, Kumar, Kar, Chawla, and
  Sebastiani]{sanyal2018optimizing}
Amartya Sanyal, Pawan Kumar, Purushottam Kar, Sanjay Chawla, and Fabrizio
  Sebastiani.
\newblock Optimizing non-decomposable measures with deep networks.
\newblock \emph{Machine Learning}, 107\penalty0 (8):\penalty0 1597--1620, 2018.

\bibitem[Scott(2012)]{Scott:2012}
Clayton Scott.
\newblock {Calibrated asymmetric surrogate losses}.
\newblock \emph{Electronic Journal of Statistics}, 6\penalty0 (none):\penalty0
  958 -- 992, 2012.
\newblock \doi{10.1214/12-EJS699}.
\newblock URL \url{https://doi.org/10.1214/12-EJS699}.

\bibitem[Sohoni et~al.(2020)Sohoni, Dunnmon, Angus, Gu, and
  R\'{e}]{Sohoni:2020}
N.~Sohoni, J.~Dunnmon, G.~Angus, A.~Gu, and C.~R\'{e}.
\newblock No subclass left behind: Fine-grained robustness in coarse-grained
  classification problems.
\newblock In \emph{Conference on Neural Information Processing Systems
  (NeurIPS)}, 2020.

\bibitem[Song et~al.(2016)Song, Schwing, Urtasun, et~al.]{song2016training}
Yang Song, Alexander Schwing, Raquel Urtasun, et~al.
\newblock Training deep neural networks via direct loss minimization.
\newblock In \emph{International Conference on Machine Learning}, pages
  2169--2177. PMLR, 2016.

\bibitem[{Tan} et~al.(2020){Tan}, {Wang}, {Li}, {Li}, {Ouyang}, {Yin}, and
  {Yan}]{Tan:2020}
J.~{Tan}, C.~{Wang}, B.~{Li}, Q.~{Li}, W.~{Ouyang}, C.~{Yin}, and J.~{Yan}.
\newblock Equalization loss for long-tailed object recognition.
\newblock In \emph{2020 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 11659--11668, 2020.

\bibitem[Tavker et~al.(2020)Tavker, Ramaswamy, and Narasimhan]{Tavker+2020}
S.~K. Tavker, H.~G. Ramaswamy, and H.~Narasimhan.
\newblock Consistent plug-in classifiers for complex objectives and
  constraints.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Tsochantaridis et~al.(2005)Tsochantaridis, Joachims, Hofmann, Altun,
  and Singer]{tsochantaridis2005large}
Ioannis Tsochantaridis, Thorsten Joachims, Thomas Hofmann, Yasemin Altun, and
  Yoram Singer.
\newblock Large margin methods for structured and interdependent output
  variables.
\newblock \emph{Journal of machine learning research}, 6\penalty0 (9), 2005.

\bibitem[Van~Horn and Perona(2017)]{VanHorn:2017}
Grant Van~Horn and Pietro Perona.
\newblock The devil is in the tails: Fine-grained classification in the wild.
\newblock \emph{arXiv preprint arXiv:1709.01450}, 2017.

\bibitem[Vapnik(1998)]{Vapnik:1998}
Vladimir~N. Vapnik.
\newblock \emph{Statistical Learning Theory}.
\newblock Wiley-Interscience, 1998.

\bibitem[Wallace et~al.(2011)Wallace, K.Small, Brodley, and
  Trikalinos]{Wallace:2011}
B.C. Wallace, K.Small, C.E. Brodley, and T.A. Trikalinos.
\newblock Class imbalance, redux.
\newblock In \emph{Proc.\ ICDM}, 2011.

\bibitem[Wang et~al.(2021)Wang, Zhang, Zang, Cao, Pang, Gong, Chen, Liu, Loy,
  and Lin]{Wang:2021b}
Jiaqi Wang, Wenwei Zhang, Yuhang Zang, Yuhang Cao, Jiangmiao Pang, Tao Gong,
  Kai Chen, Ziwei Liu, Chen~Change Loy, and Dahua Lin.
\newblock Seesaw loss for long-tailed instance segmentation.
\newblock In \emph{Proceedings of the {IEEE} Conference on Computer Vision and
  Pattern Recognition}, 2021.

\bibitem[Williamson et~al.(2016)Williamson, Vernet, and
  Reid]{williamson2016composite}
Robert~C Williamson, Elodie Vernet, and Mark~D Reid.
\newblock Composite multiclass losses.
\newblock \emph{Journal of Machine Learning Research}, 17:\penalty0 1--52,
  2016.

\bibitem[Wu et~al.(2008)Wu, Lin, Chen, and Chen]{Wu:2008}
Shan-Hung Wu, Keng-Pei Lin, Chung-Min Chen, and Ming-Syan Chen.
\newblock Asymmetric support vector machines: Low false-positive learning under
  the user tolerance.
\newblock In \emph{Proceedings of the 14th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, KDD ’08, page 749–757, New York,
  NY, USA, 2008. Association for Computing Machinery.
\newblock ISBN 9781605581934.

\bibitem[Wu et~al.(2020)Wu, Huang, Liu, Wang, and Lin]{Wu:2020}
Tong Wu, Qingqiu Huang, Ziwei Liu, Yu~Wang, and Dahua Lin.
\newblock Distribution-balanced loss for multi-label classification in
  long-tailed datasets.
\newblock In Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm,
  editors, \emph{Computer Vision -- ECCV 2020}, pages 162--178, Cham, 2020.
  Springer International Publishing.
\newblock ISBN 978-3-030-58548-8.

\bibitem[Wu and Srihari(2003)]{Wu:2003}
Xiaoyun Wu and Rohini Srihari.
\newblock New $\nu$-support vector machines and their sequential minimal
  optimization.
\newblock In \emph{AAAI}, pages 824--831, 01 2003.

\bibitem[Xie et~al.(2020)Xie, Luong, Hovy, and Le]{xie2020self}
Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc~V Le.
\newblock Self-training with noisy student improves imagenet classification.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 10687--10698, 2020.

\bibitem[Xie and Manski(1989)]{Xie:1989}
Yu~Xie and Charles~F. Manski.
\newblock The logit model and response-based samples.
\newblock \emph{Sociological Methods \& Research}, 17\penalty0 (3):\penalty0
  283--302, 1989.

\bibitem[Yan et~al.(2018)Yan, Koyejo, Zhong, and Ravikumar]{yan2018binary}
Bowei Yan, Sanmi Koyejo, Kai Zhong, and Pradeep Ravikumar.
\newblock Binary classification with karmic, threshold-quasi-concave metrics.
\newblock In \emph{International Conference on Machine Learning}, pages
  5531--5540. PMLR, 2018.

\bibitem[Ye et~al.(2012)Ye, Chai, Lee, and Chieu]{ye2012optimizing}
Nan Ye, Kian~Ming Chai, Wee~Sun Lee, and Hai~Leong Chieu.
\newblock Optimizing f-measures: a tale of two approaches.
\newblock In \emph{Proceedings of the 29th International Conference on Machine
  Learning}, pages 289--296. Omnipress, 2012.

\bibitem[Yin et~al.(2019)Yin, Yu, Sohn, Liu, and Chandraker]{Yin:2018}
Xi~Yin, Xiang Yu, Kihyuk Sohn, Xiaoming Liu, and Manmohan Chandraker.
\newblock Feature transfer learning for face recognition with under-represented
  data.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, June 2019.

\bibitem[Zadrozny et~al.(2003)Zadrozny, Langford, and Abe]{Zadrozny:2003}
B.~Zadrozny, J.~Langford, and N.~Abe.
\newblock Cost-sensitive learning by cost-proportionate example weighting.
\newblock In \emph{Third IEEE International Conference on Data Mining}, pages
  435--442, 2003.
\newblock \doi{10.1109/ICDM.2003.1250950}.

\bibitem[Zafar et~al.(2017)Zafar, Valera, Rogriguez, and
  Gummadi]{zafar2017constraints}
Muhammad~Bilal Zafar, Isabel Valera, Manuel~Gomez Rogriguez, and Krishna~P
  Gummadi.
\newblock Fairness constraints: Mechanisms for fair classification.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 962--970,
  2017.

\bibitem[Zhang et~al.(2018)Zhang, Li, Pu, Wang, Yan, and Zha]{Zhang:2018}
Ao~Zhang, Nan Li, Jian Pu, Jun Wang, Junchi Yan, and Hongyuan Zha.
\newblock Tau-fpl: Tolerance-constrained learning in linear time.
\newblock In Sheila~A. McIlraith and Kilian~Q. Weinberger, editors,
  \emph{Proceedings of the Thirty-Second {AAAI} Conference on Artificial
  Intelligence, (AAAI-18)}, pages 4398--4405. {AAAI} Press, 2018.

\bibitem[Zhang et~al.(2017)Zhang, Bengio, Hardt, Recht, and
  Vinyals]{Zhang:2017}
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals.
\newblock Understanding deep learning requires rethinking generalization.
\newblock In \emph{5th International Conference on Learning Representations,
  {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track
  Proceedings}. OpenReview.net, 2017.

\bibitem[Zhang et~al.(2019)Zhang, Liu, Wang, and Shen]{Zhang:2019}
Junjie Zhang, Lingqiao Liu, Peng Wang, and Chunhua Shen.
\newblock To balance or not to balance: A simple-yet-effective approach for
  learning with long-tailed distributions, 2019.

\bibitem[Zhang et~al.(2021{\natexlab{a}})Zhang, Chen, Hu, and Peng]{Zhang+2021}
Shaoyu Zhang, Chen Chen, Xiyuan Hu, and Silong Peng.
\newblock Balanced knowledge distillation for long-tailed learning.
\newblock \emph{CoRR}, abs/2104.10510, 2021{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2104.10510}.

\bibitem[Zhang et~al.(2021{\natexlab{b}})Zhang, Li, Yan, He, and
  Sun]{Zhang:2021}
Songyang Zhang, Zeming Li, Shipeng Yan, Xuming He, and Jian Sun.
\newblock Distribution alignment: A unified framework for long-tail visual
  recognition.
\newblock In \emph{CVPR}, 2021{\natexlab{b}}.

\bibitem[Zhou and Liu(2006)]{Zhou:2006}
Zhi-Hua Zhou and Xu-Ying Liu.
\newblock Training cost-sensitive neural networks with methods addressing the
  class imbalance problem.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering (TKDE)},
  18\penalty0 (1), 2006.

\bibitem[Zhou and Liu(2010)]{zhou2010multi}
Zhi-Hua Zhou and Xu-Ying Liu.
\newblock On multi-class cost-sensitive learning.
\newblock \emph{Computational Intelligence}, 26\penalty0 (3):\penalty0
  232--257, 2010.

\end{thebibliography}
