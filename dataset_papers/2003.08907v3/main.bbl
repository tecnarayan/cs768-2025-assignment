\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Patel(2017)]{aidiagnosis2017}
Neel~V. Patel.
\newblock \emph{Why Doctors Aren't Afraid of Better, More Efficient AI
  Diagnosing Cancer}, 2017.
\newblock URL
  \url{https://www.thedailybeast.com/why-doctors-arent-afraid-of-better-more-efficient-ai-diagnosing-cancer}.
\newblock Accessed September 27, 2020.

\bibitem[Krizhevsky(2009)]{krizhevsky2009learning}
Alex Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, University of Toronto, 2009.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein,
  Alexander~C. Berg, and Li~Fei-Fei.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock \emph{International Journal of Computer Vision (IJCV)}, 115\penalty0
  (3):\penalty0 211--252, 2015.
\newblock \doi{10.1007/s11263-015-0816-y}.

\bibitem[Carter et~al.(2019)Carter, Mueller, Jain, and Gifford]{sis}
Brandon Carter, Jonas Mueller, Siddhartha Jain, and David Gifford.
\newblock What made you do this? {U}nderstanding black-box decisions with
  sufficient input subsets.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 567--576, 2019.

\bibitem[Ilyas et~al.(2019)Ilyas, Santurkar, Tsipras, Engstrom, Tran, and
  Madry]{ilyas2019adversarial}
Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon
  Tran, and Aleksander Madry.
\newblock Adversarial examples are not bugs, they are features.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Torralba and Efros(2011)]{torralba2011unbiased}
Antonio Torralba and Alexei~A Efros.
\newblock Unbiased look at dataset bias.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 1521--1528. IEEE, 2011.

\bibitem[Tommasi et~al.(2017)Tommasi, Patricia, Caputo, and
  Tuytelaars]{tommasi2017deeper}
Tatiana Tommasi, Novi Patricia, Barbara Caputo, and Tinne Tuytelaars.
\newblock A deeper look at dataset bias.
\newblock In \emph{Domain Adaptation in Computer Vision Applications}, pages
  37--55. Springer, 2017.

\bibitem[Fong et~al.(2019)Fong, Patrick, and Vedaldi]{fong2019understanding}
Ruth Fong, Mandela Patrick, and Andrea Vedaldi.
\newblock Understanding deep networks via extremal perturbations and smooth
  masks.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 2950--2958, 2019.

\bibitem[Samek et~al.(2016)Samek, Binder, Montavon, Lapuschkin, and
  M{\"u}ller]{samek2016evaluating}
Wojciech Samek, Alexander Binder, Gr{\'e}goire Montavon, Sebastian Lapuschkin,
  and Klaus-Robert M{\"u}ller.
\newblock Evaluating the visualization of what a deep neural network has
  learned.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  28\penalty0 (11):\penalty0 2660--2673, 2016.

\bibitem[Agarwal and Nguyen(2020)]{agarwal2020explaining}
Chirag Agarwal and Anh Nguyen.
\newblock Explaining image classifiers by removing input features using
  generative models.
\newblock In \emph{Proceedings of the Asian Conference on Computer Vision},
  2020.

\bibitem[Dhurandhar et~al.(2018)Dhurandhar, Chen, Luss, Tu, Ting, Shanmugam,
  and Das]{dhurandhar2018explanations}
Amit Dhurandhar, Pin-Yu Chen, Ronny Luss, Chun-Chen Tu, Paishun Ting,
  Karthikeyan Shanmugam, and Payel Das.
\newblock Explanations based on the missing: towards contrastive explanations
  with pertinent negatives.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Rosenfeld et~al.(2018)Rosenfeld, Zemel, and
  Tsotsos]{rosenfeld2018elephant}
Amir Rosenfeld, Richard Zemel, and John~K Tsotsos.
\newblock The elephant in the room.
\newblock \emph{arXiv preprint arXiv:1808.03305}, 2018.

\bibitem[Shetty et~al.(2019)Shetty, Schiele, and Fritz]{shetty2019not}
Rakshith Shetty, Bernt Schiele, and Mario Fritz.
\newblock Not using the car to see the sidewalk--quantifying and controlling
  the effects of context in classification and segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 8218--8226, 2019.

\bibitem[Singh et~al.(2020)Singh, Mahajan, Grauman, Lee, Feiszli, and
  Ghadiyaram]{singh2020don}
Krishna~Kumar Singh, Dhruv Mahajan, Kristen Grauman, Yong~Jae Lee, Matt
  Feiszli, and Deepti Ghadiyaram.
\newblock Don't judge an object by its context: Learning to overcome contextual
  bias.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 11070--11078, 2020.

\bibitem[Lapuschkin et~al.(2019)Lapuschkin, W{\"a}ldchen, Binder, Montavon,
  Samek, and M{\"u}ller]{lapuschkin2019unmasking}
Sebastian Lapuschkin, Stephan W{\"a}ldchen, Alexander Binder, Gr{\'e}goire
  Montavon, Wojciech Samek, and Klaus-Robert M{\"u}ller.
\newblock Unmasking clever hans predictors and assessing what machines really
  learn.
\newblock \emph{Nature Communications}, 10\penalty0 (1):\penalty0 1--8, 2019.

\bibitem[Gatys et~al.(2017)Gatys, Ecker, and Bethge]{gatys2017texture}
Leon~A Gatys, Alexander~S Ecker, and Matthias Bethge.
\newblock Texture and art with deep neural networks.
\newblock \emph{Current Opinion in Neurobiology}, 46:\penalty0 178--186, 2017.

\bibitem[Geirhos et~al.(2019)Geirhos, Rubisch, Michaelis, Bethge, Wichmann, and
  Brendel]{geirhos2018imagenet}
Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix~A
  Wichmann, and Wieland Brendel.
\newblock {ImageNet}-trained {CNNs} are biased towards texture; increasing
  shape bias improves accuracy and robustness.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Brendel and Bethge(2019)]{brendel2019approximating}
Wieland Brendel and Matthias Bethge.
\newblock Approximating {CNNs} with {Bag-of-local-Features} models works
  surprisingly well on {ImageNet}.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Geirhos et~al.(2018)Geirhos, Temme, Rauber, Sch{\"u}tt, Bethge, and
  Wichmann]{geirhos2018generalisation}
Robert Geirhos, Carlos R~Medina Temme, Jonas Rauber, Heiko~H Sch{\"u}tt,
  Matthias Bethge, and Felix~A Wichmann.
\newblock Generalisation in humans and deep neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Nguyen et~al.(2015{\natexlab{a}})Nguyen, Yosinski, and Clune]{fooled}
Anh Nguyen, Jason Yosinski, and Jeff Clune.
\newblock Deep neural networks are easily fooled: High confidence predictions
  for unrecognizable images.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 427--436, 2015{\natexlab{a}}.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Nguyen et~al.(2015{\natexlab{b}})Nguyen, Yosinski, and
  Clune]{nguyen2015deep}
Anh Nguyen, Jason Yosinski, and Jeff Clune.
\newblock Deep neural networks are easily fooled: High confidence predictions
  for unrecognizable images.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 427--436, 2015{\natexlab{b}}.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Hooker et~al.(2019)Hooker, Erhan, Kindermans, and
  Kim]{hooker2019benchmark}
Sara Hooker, Dumitru Erhan, Pieter-Jan Kindermans, and Been Kim.
\newblock A benchmark for interpretability methods in deep neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Ghorbani et~al.(2019)Ghorbani, Wexler, Zou, and
  Kim]{ghorbani2019towards}
Amirata Ghorbani, James Wexler, James~Y Zou, and Been Kim.
\newblock Towards automatic concept-based explanations.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Geirhos et~al.(2020)Geirhos, Jacobsen, Michaelis, Zemel, Brendel,
  Bethge, and Wichmann]{geirhos2020shortcut}
Robert Geirhos, J{\"o}rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel,
  Wieland Brendel, Matthias Bethge, and Felix~A Wichmann.
\newblock Shortcut learning in deep neural networks.
\newblock \emph{Nature Machine Intelligence}, 2\penalty0 (11):\penalty0
  665--673, 2020.

\bibitem[Feng et~al.(2018)Feng, Wallace, Grissom~II, Iyyer, Rodriguez, and
  Boyd-Graber]{feng2018pathologies}
Shi Feng, Eric Wallace, Alvin Grissom~II, Mohit Iyyer, Pedro Rodriguez, and
  Jordan Boyd-Graber.
\newblock Pathologies of neural models make interpretations difficult.
\newblock In \emph{Empirical Methods in Natural Language Processing}, 2018.

\bibitem[Niven and Kao(2019)]{Niven19}
Timothy Niven and Hung-Yu Kao.
\newblock Probing neural network comprehension of natural language arguments.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pages 4658--4664, 2019.

\bibitem[Hendrycks and Dietterich(2019)]{hendrycks2019robustness}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Recht et~al.(2018)Recht, Roelofs, Schmidt, and
  Shankar]{recht2018cifar10.1}
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar.
\newblock Do {CIFAR-10} classifiers generalize to {CIFAR-10}?
\newblock \emph{arXiv preprint arXiv:1806.00451}, 2018.

\bibitem[He et~al.(2016{\natexlab{a}})He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 770--778, 2016{\natexlab{a}}.

\bibitem[He et~al.(2016{\natexlab{b}})He, Zhang, Ren, and Sun]{he2016identity}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Identity mappings in deep residual networks.
\newblock In \emph{European Conference on Computer Vision}. Springer,
  2016{\natexlab{b}}.

\bibitem[Simonyan and Zisserman(2015)]{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Sutskever et~al.(2013)Sutskever, Martens, Dahl, and
  Hinton]{sutskever2013importance}
Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton.
\newblock On the importance of initialization and momentum in deep learning.
\newblock In \emph{International Conference on Machine Learning}, 2013.

\bibitem[Osband et~al.(2016)Osband, Blundell, Pritzel, and
  Van~Roy]{boostrappeddqn}
Ian Osband, Charles Blundell, Alexander Pritzel, and Benjamin Van~Roy.
\newblock Deep exploration via bootstrapped dqn.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy2016rethinking}
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew
  Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2818--2826, 2016.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock {PyTorch}: An imperative style, high-performance deep learning
  library.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Santurkar et~al.(2019)Santurkar, Ilyas, Tsipras, Engstrom, Tran, and
  Madry]{santurkar2019image}
Shibani Santurkar, Andrew Ilyas, Dimitris Tsipras, Logan Engstrom, Brandon
  Tran, and Aleksander Madry.
\newblock Image synthesis with a single (robust) classifier.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger.
\newblock On calibration of modern neural networks.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Karpathy(2011)]{karpathy2011lessons}
Andrej Karpathy.
\newblock Lessons learned from manually classifying {CIFAR-10}.
\newblock \emph{Published online at http://karpathy. github.
  io/2011/04/27/manually-classifying-cifar10}, 2011.

\bibitem[Goh et~al.(2001)Goh, Chang, and Cheng]{goh2001svm}
King-Shy Goh, Edward Chang, and Kwang-Ting Cheng.
\newblock {SVM} binary classifier ensembles for image classification.
\newblock In \emph{Proceedings of the Tenth International Conference on
  Information and Knowledge Management}, pages 395--402. ACM, 2001.

\bibitem[Ju et~al.(2018)Ju, Bibaut, and van~der Laan]{ju2018relative}
Cheng Ju, Aur{\'e}lien Bibaut, and Mark van~der Laan.
\newblock The relative performance of ensemble methods with deep convolutional
  neural networks for image classification.
\newblock \emph{Journal of Applied Statistics}, 45\penalty0 (15):\penalty0
  2800--2818, 2018.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{srivastava2014dropout}
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
  Salakhutdinov.
\newblock Dropout: A simple way to prevent neural networks from overfitting.
\newblock \emph{Journal of Machine Learning Research}, 15:\penalty0 1929--1958,
  2014.

\bibitem[Adebayo et~al.(2018)Adebayo, Gilmer, Muelly, Goodfellow, Hardt, and
  Kim]{adebayo2018sanity}
Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt,
  and Been Kim.
\newblock Sanity checks for saliency maps.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Ross et~al.(2017)Ross, Hughes, and Doshi-Velez]{ross2017right}
Andrew~Slavin Ross, Michael~C Hughes, and Finale Doshi-Velez.
\newblock Right for the right reasons: training differentiable models by
  constraining their explanations.
\newblock In \emph{Proceedings of the 26th International Joint Conference on
  Artificial Intelligence}, pages 2662--2670, 2017.

\bibitem[Simpson et~al.(2019)Simpson, Dutil, Bengio, and
  Cohen]{simpson2019gradmask}
Becks Simpson, Francis Dutil, Yoshua Bengio, and Joseph~Paul Cohen.
\newblock {GradMask}: Reduce overfitting by regularizing saliency.
\newblock \emph{arXiv preprint arXiv:1904.07478}, 2019.

\bibitem[Viviano et~al.(2021)Viviano, Simpson, Dutil, Bengio, and
  Cohen]{viviano2019underwhelming}
Joseph~D Viviano, Becks Simpson, Francis Dutil, Yoshua Bengio, and Joseph~Paul
  Cohen.
\newblock Saliency is a possible red herring when diagnosing poor
  generalization.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Kindermans et~al.(2019)Kindermans, Hooker, Adebayo, Alber, Sch{\"u}tt,
  D{\"a}hne, Erhan, and Kim]{kindermans2019reliability}
Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber, Kristof~T
  Sch{\"u}tt, Sven D{\"a}hne, Dumitru Erhan, and Been Kim.
\newblock The (un) reliability of saliency methods.
\newblock In \emph{Explainable AI: Interpreting, Explaining and Visualizing
  Deep Learning}, pages 267--280. Springer, 2019.

\bibitem[Torralba et~al.(2008)Torralba, Fergus, and Freeman]{torralba200880}
Antonio Torralba, Rob Fergus, and William~T Freeman.
\newblock 80 million tiny images: A large data set for nonparametric object and
  scene recognition.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 30\penalty0 (11):\penalty0 1958--1970, 2008.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and
  Weinberger]{huang2017densely}
Gao Huang, Zhuang Liu, Laurens Van Der~Maaten, and Kilian~Q Weinberger.
\newblock Densely connected convolutional networks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 4700--4708, 2017.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Naseer et~al.(2021)Naseer, Ranasinghe, Khan, Hayat, Khan, and
  Yang]{naseer2021intriguing}
Muzammal Naseer, Kanchana Ranasinghe, Salman Khan, Munawar Hayat, Fahad~Shahbaz
  Khan, and Ming-Hsuan Yang.
\newblock Intriguing properties of vision transformers.
\newblock \emph{arXiv preprint arXiv:2105.10497}, 2021.

\end{thebibliography}
