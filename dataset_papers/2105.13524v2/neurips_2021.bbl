\begin{thebibliography}{56}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Cassandra et~al.(1994)Cassandra, Kaelbling, and Littman]{caka94}
A.~R. Cassandra, L.~P. Kaelbling, and M.~L. Littman.
\newblock Acting optimally in partially observable stochastic domains.
\newblock In \emph{National Conference on Artificial Intelligence}, 1994.

\bibitem[Chandak et~al.(2020)Chandak, Theocharous, Shankar, White, Mahadevan,
  and Thomas]{icml2020_3200}
Y.~Chandak, G.~Theocharous, S.~Shankar, M.~White, S.~Mahadevan, and P.~Thomas.
\newblock Optimizing for the future in non-stationary mdps.
\newblock In \emph{International Conference on Machine Learning, {(}ICML{)}},
  pages 119:1414--1425, 2020.

\bibitem[Chebotar et~al.(2019)Chebotar, Handa, Makoviychuk, Macklin, Issac,
  Ratliff, and Fox]{DBLP:conf/icra/ChebotarHMMIRF19}
Y.~Chebotar, A.~Handa, V.~Makoviychuk, M.~Macklin, J.~Issac, N.~D. Ratliff, and
  D.~Fox.
\newblock Closing the sim-to-real loop: Adapting simulation randomization with
  real world experience.
\newblock In \emph{International Conference on Robotics and Automation,
  {(}ICRA{)}}, pages 8973--8979, 2019.

\bibitem[Chen et~al.(2018)Chen, Deng, and Shen]{DBLP:conf/nips/ChenDS18}
B.~Chen, W.~Deng, and H.~Shen.
\newblock Virtual class enhanced discriminative embedding learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  {(}NeurIPS{)}}, pages 31:1942--1952, 2018.

\bibitem[Cobbe et~al.(2019)Cobbe, Klimov, Hesse, Kim, and
  Schulman]{DBLP:conf/icml/CobbeKHKS19}
K.~Cobbe, O.~Klimov, C.~Hesse, T.~Kim, and J.~Schulman.
\newblock Quantifying generalization in reinforcement learning.
\newblock In \emph{International Conference on Machine Learning, {(}ICML{)}},
  pages 97:1282--1289, 2019.

\bibitem[Duan et~al.(2016)Duan, Schulman, Chen, Bartlett, Sutskever, and
  Abbeel]{DBLP:journals/corr/DuanSCBSA16}
Y.~Duan, J.~Schulman, X.~Chen, P.~L. Bartlett, I.~Sutskever, and P.~Abbeel.
\newblock $\textrm{RL}^2$: Fast reinforcement learning via slow reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv: 1611.02779}, 2016.

\bibitem[Duff(2002)]{duff2002optimal}
M.~O. Duff.
\newblock \emph{Optimal Learning: Computational Procedures for Bayes-adaptive
  Markov Decision Processes}.
\newblock University of Massachusetts at Amherst, 2002.

\bibitem[Fakoor et~al.(2020)Fakoor, Chaudhari, Soatto, and
  Smola]{DBLP:conf/iclr/FakoorCSS20}
R.~Fakoor, P.~Chaudhari, S.~Soatto, and A.~J. Smola.
\newblock Meta-q-learning.
\newblock In \emph{International Conference on Learning Representations,
  {(}ICLR{)}}, 2020.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{DBLP:conf/icml/FinnAL17}
C.~Finn, P.~Abbeel, and S.~Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International Conference on Machine Learning, {(}ICML{)}},
  pages 70:1126--1135, 2017.

\bibitem[Florensa et~al.(2018)Florensa, Held, Geng, and
  Abbeel]{DBLP:conf/icml/FlorensaHGA18}
C.~Florensa, D.~Held, X.~Geng, and P.~Abbeel.
\newblock Automatic goal generation for reinforcement learning agents.
\newblock In \emph{International Conference on Machine Learning {(}ICML{)}},
  pages 80:1515--1528, 2018.

\bibitem[Ghavamzadeh et~al.(2015)Ghavamzadeh, Mannor, Pineau, and
  Tamar]{DBLP:journals/ftml/GhavamzadehMPT15}
M.~Ghavamzadeh, S.~Mannor, J.~Pineau, and A.~Tamar.
\newblock Bayesian reinforcement learning: {A} survey.
\newblock \emph{Found. Trends Mach. Learn.}, pages 8(5--6):359--483, 2015.

\bibitem[Gupta et~al.(2018{\natexlab{a}})Gupta, Eysenbach, Finn, and
  Levine]{DBLP:journals/corr/abs-1806-04640}
A.~Gupta, B.~Eysenbach, C.~Finn, and S.~Levine.
\newblock Unsupervised meta-learning for reinforcement learning.
\newblock \emph{arXiv preprint arXiv: 1806.04640}, 2018{\natexlab{a}}.

\bibitem[Gupta et~al.(2018{\natexlab{b}})Gupta, Mendonca, Liu, Abbeel, and
  Levine]{DBLP:conf/nips/GuptaMLAL18}
A.~Gupta, R.~Mendonca, Y.~Liu, P.~Abbeel, and S.~Levine.
\newblock Meta-reinforcement learning of structured exploration strategies.
\newblock In \emph{Advances in Neural Information Processing Systems
  {(}NeurIPS{)}}, pages 31:5302--5311, 2018{\natexlab{b}}.

\bibitem[Hafner et~al.(2020)Hafner, Lillicrap, Ba, and
  Norouzi]{DBLP:conf/iclr/HafnerLB020}
D.~Hafner, T.~P. Lillicrap, J.~Ba, and M.~Norouzi.
\newblock Dream to control: Learning behaviors by latent imagination.
\newblock In \emph{International Conference on Learning Representations,
  {(ICLR)}}, 2020.

\bibitem[Humplik et~al.(2019)Humplik, Galashov, Hasenclever, Ortega, Teh, and
  Heess]{DBLP:journals/corr/abs-1905-06424}
J.~Humplik, A.~Galashov, L.~Hasenclever, P.~A. Ortega, Y.~W. Teh, and N.~Heess.
\newblock Meta reinforcement learning as task inference.
\newblock \emph{arXiv preprint arXiv: 1905.06424}, 2019.

\bibitem[Igl et~al.(2019)Igl, Ciosek, Li, Tschiatschek, Zhang, Devlin, and
  Hofmann]{DBLP:conf/nips/IglCLTZDH19}
M.~Igl, K.~Ciosek, Y.~Li, S.~Tschiatschek, C.~Zhang, S.~Devlin, and K.~Hofmann.
\newblock Generalization in reinforcement learning with selective noise
  injection and information bottleneck.
\newblock In \emph{Neural Information Processing Systems {(}NeurIPS{)}}, pages
  32:13978--13990, 2019.

\bibitem[Jabri et~al.(2019)Jabri, Hsu, Eysenbach, Gupta, Levine, and
  Finn]{DBLP:conf/nips/JabriHEGLF19}
A.~Jabri, K.~Hsu, B.~Eysenbach, A.~Gupta, S.~Levine, and C.~Finn.
\newblock Unsupervised curricula for visual meta-reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  {(}NeurIPS{)}}, volume~32, 2019.

\bibitem[Kaddour et~al.(2020)Kaddour, S{\ae}mundsson, and
  Deisenroth]{DBLP:conf/nips/KaddourSD20}
J.~Kaddour, S.~S{\ae}mundsson, and M.~P. Deisenroth.
\newblock Probabilistic active meta-learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  {(}NeurIPS{)}}, pages 33:20813--20822, 2020.

\bibitem[Kaelbling et~al.(1998)Kaelbling, Littman, and
  Cassandra]{kaelbling:aij98}
L.~P. Kaelbling, M.~L. Littman, and A.~R. Cassandra.
\newblock Planning and acting in partially observable stochastic domains.
\newblock \emph{Artificial Intelligence}, 101:\penalty0 99--134, 1998.

\bibitem[Kingma and Welling(2014)]{DBLP:journals/corr/KingmaW14}
D.~P. Kingma and M.~Welling.
\newblock Auto-encoding variational bayes.
\newblock In \emph{International Conference on Learning Representations
  {(}ICLR{)}}, 2014.

\bibitem[Kirsch et~al.(2020)Kirsch, van Steenkiste, and
  Schmidhuber]{DBLP:conf/iclr/KirschSS}
L.~Kirsch, S.~van Steenkiste, and J.~Schmidhuber.
\newblock Improving generalization in meta reinforcement learning using learned
  objectives.
\newblock In \emph{International Conference on Learning Representations,
  {(}ICLR{)}}, 2020.

\bibitem[Laskin et~al.(2020)Laskin, Lee, Stooke, Pinto, Abbeel, and
  Srinivas]{DBLP:conf/nips/LaskinLSPAS19}
M.~Laskin, K.~Lee, A.~Stooke, L.~Pinto, P.~Abbeel, and A.~Srinivas.
\newblock Reinforcement learning with augmented data.
\newblock In \emph{Neural Information Processing Systems {(}NeurIPS{)}}, pages
  33:19884--19895, 2020.

\bibitem[Lee et~al.(2020{\natexlab{a}})Lee, Nagabandi, Abbeel, and
  Levine]{DBLP:conf/nips/LEENAL20}
A.~X. Lee, A.~Nagabandi, P.~Abbeel, and S.~Levine.
\newblock Stochastic latent actor-critic: Deep reinforcement learning with a
  latent variable model.
\newblock In \emph{Advances in Neural Information Processing Systems
  {(}NeurIPS{)}}, pages 33:741--752, 2020{\natexlab{a}}.

\bibitem[Lee et~al.(2020{\natexlab{b}})Lee, Lee, Shin, and
  Lee]{DBLP:conf/iclr/LeeLSL20}
K.~Lee, K.~Lee, J.~Shin, and H.~Lee.
\newblock Network randomization: {A} simple technique for generalization in
  deep reinforcement learning.
\newblock In \emph{International Conference on Learning Representations,
  {(}ICLR{)}}, 2020{\natexlab{b}}.

\bibitem[Lee et~al.(2020{\natexlab{c}})Lee, Seo, Lee, Lee, and
  Shin]{icml2020_3567}
K.~Lee, Y.~Seo, S.~Lee, H.~Lee, and J.~Shin.
\newblock Context-aware dynamics model for generalization in model-based
  reinforcement learning.
\newblock In \emph{International Conference on Machine Learning, {(}ICML{)}},
  pages 119:5757--5766, 2020{\natexlab{c}}.

\bibitem[Lin et~al.(2020)Lin, Thomas, Yang, and Ma]{DBLP:conf/nips/LinTYM}
Z.~Lin, G.~Thomas, G.~Yang, and T.~Ma.
\newblock Model-based adversarial meta-reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  {(}NeurIPS{)}}, pages 33:10161--10173, 2020.

\bibitem[Liu et~al.(2019)Liu, Davison, and Johns]{DBLP:conf/nips/LiuDJ19}
S.~Liu, A.~J. Davison, and E.~Johns.
\newblock Self-supervised generalisation with meta auxiliary learning.
\newblock In \emph{Neural Information Processing Systems {(}NeurIPS{)}}, pages
  32:1679--1689, 2019.

\bibitem[Martin(1967)]{martin1967bayesian}
J.~J. Martin.
\newblock \emph{Bayesian Decision Problems and Markov Chains}.
\newblock Wiley, 1967.

\bibitem[Mehta et~al.(2020)Mehta, Deleu, Raparthy, Pal, and Paull]{MehtaDRPP}
B.~Mehta, T.~Deleu, S.~C. Raparthy, C.~J. Pal, and L.~Paull.
\newblock Curriculum in gradient-based meta-reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2002.07956}, 2020.

\bibitem[Mendonca et~al.(2020)Mendonca, Geng, Finn, and
  Levine]{DBLP:journals/corr/abs-2006-07178}
R.~Mendonca, X.~Geng, C.~Finn, and S.~Levine.
\newblock Meta-reinforcement learning robust to distributional shift via model
  identification and experience relabeling.
\newblock \emph{arXiv preprint arXiv: 2006.07178}, 2020.

\bibitem[Peng et~al.(2021)Peng, Zhu, and Jiao]{peng2021linear}
M.~Peng, B.~Zhu, and J.~Jiao.
\newblock Linear representation meta-reinforcement learning for instant
  adaptation.
\newblock \emph{arXiv preprint arXiv: 2101.04750}, 2021.

\bibitem[Raileanu et~al.(2020{\natexlab{a}})Raileanu, Goldstein, Szlam, and
  Fergus]{icml2020_3993}
R.~Raileanu, M.~Goldstein, A.~Szlam, and R.~Fergus.
\newblock Fast adaptation to new environments via policy-dynamics value
  functions.
\newblock In \emph{International Conference on Machine Learning, {(}ICML{)}},
  pages 119:7920--7931, 2020{\natexlab{a}}.

\bibitem[Raileanu et~al.(2020{\natexlab{b}})Raileanu, Goldstein, Yarats,
  Kostrikov, and Fergus]{DBLP:journals/corr/RaileanuGYKF}
R.~Raileanu, M.~Goldstein, D.~Yarats, I.~Kostrikov, and R.~Fergus.
\newblock Automatic data augmentation for generalization in deep reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:2006.12862}, 2020{\natexlab{b}}.

\bibitem[Rajeswaran et~al.(2017)Rajeswaran, Lowrey, Todorov, and
  Kakade]{DBLP:conf/nips/RajeswaranLTK17}
A.~Rajeswaran, K.~Lowrey, E.~Todorov, and S.~M. Kakade.
\newblock Towards generalization and simplicity in continuous control.
\newblock In \emph{Advances in Neural Information Processing Systems
  {(}NeurIPS{)}}, pages 30:6550--6561, 2017.

\bibitem[Rakelly et~al.(2019)Rakelly, Zhou, Finn, Levine, and
  Quillen]{DBLP:conf/icml/RakellyZFLQ19}
K.~Rakelly, A.~Zhou, C.~Finn, S.~Levine, and D.~Quillen.
\newblock Efficient off-policy meta-reinforcement learning via probabilistic
  context variables.
\newblock In \emph{International Conference on Machine Learning, {(}ICML{)}},
  pages 97:5331--5340, 2019.

\bibitem[Rothfuss et~al.(2019)Rothfuss, Lee, Clavera, Asfour, and
  Abbeel]{DBLP:conf/iclr/RothfussLCAA19}
J.~Rothfuss, D.~Lee, I.~Clavera, T.~Asfour, and P.~Abbeel.
\newblock Promp: Proximal meta-policy search.
\newblock In \emph{International Conference on Learning Representations,
  {(}ICLR{)}}, 2019.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{DBLP:journals/corr/SchulmanWDRK17}
J.~Schulman, F.~Wolski, P.~Dhariwal, A.~Radford, and O.~Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv: 1707.06347}, 2017.

\bibitem[Song et~al.(2020{\natexlab{a}})Song, Jiang, Tu, Du, and
  Neyshabur]{DBLP:conf/iclr/SongJTDN20}
X.~Song, Y.~Jiang, S.~Tu, Y.~Du, and B.~Neyshabur.
\newblock Observational overfitting in reinforcement learning.
\newblock In \emph{International Conference on Learning Representations,
  {(}ICLR{)}}, 2020{\natexlab{a}}.

\bibitem[Song et~al.(2020{\natexlab{b}})Song, Mavalankar, Sun, and
  Gao]{icml2020_5014}
Y.~Song, A.~Mavalankar, W.~Sun, and S.~Gao.
\newblock Provably efficient model-based policy adaptation.
\newblock In \emph{International Conference on Machine Learning {(}ICML{)}},
  pages 119:9088--9098, 2020{\natexlab{b}}.

\bibitem[Stadie et~al.(2018)Stadie, Yang, Houthooft, Chen, Duan, Wu, Abbeel,
  and Sutskever]{DBLP:conf/nips/StadieYHCDWAS18}
B.~C. Stadie, G.~Yang, R.~Houthooft, X.~Chen, Y.~Duan, Y.~Wu, P.~Abbeel, and
  I.~Sutskever.
\newblock The importance of sampling in meta-reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  {(}NeurIPS{)}}, pages 31:9280--9290, 2018.

\bibitem[Tobin et~al.(2017)Tobin, Fong, Ray, Schneider, Zaremba, and
  Abbeel]{DBLP:conf/iros/TobinFRSZA17}
J.~Tobin, R.~Fong, A.~Ray, J.~Schneider, W.~Zaremba, and P.~Abbeel.
\newblock Domain randomization for transferring deep neural networks from
  simulation to the real world.
\newblock In \emph{International Conference on Intelligent Robots and Systems
  {(}IROS{)}}, pages 23--30, 2017.

\bibitem[{Todorov} et~al.(2012){Todorov}, {Erez}, and {Tassa}]{6386109}
E.~{Todorov}, T.~{Erez}, and Y.~{Tassa}.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{International Conference on Intelligent Robots and Systems
  (IROS)}, pages 5026--5033, 2012.

\bibitem[Wang et~al.(2016)Wang, Kurth{-}Nelson, Tirumala, Soyer, Leibo, Munos,
  Blundell, Kumaran, and Botvinick]{DBLP:journals/corr/WangKTSLMBKB16}
J.~X. Wang, Z.~Kurth{-}Nelson, D.~Tirumala, H.~Soyer, J.~Z. Leibo, R.~Munos,
  C.~Blundell, D.~Kumaran, and M.~Botvinick.
\newblock Learning to reinforcement learn.
\newblock In \emph{Annual Meeting of the Cognitive Science Community
  {(}CogSci{)}}, 2016.

\bibitem[Wang et~al.(2020{\natexlab{a}})Wang, Kang, Shao, and
  Feng]{DBLP:conf/nips/WangKSF20}
K.~Wang, B.~Kang, J.~Shao, and J.~Feng.
\newblock Improving generalization in reinforcement learning with mixture
  regularization.
\newblock In \emph{Advances in Neural Information Processing Systems
  {(}NeurIPS{)}}, pages 33:7968--7978, 2020{\natexlab{a}}.

\bibitem[Wang et~al.(2019)Wang, Lehman, Clune, and
  Stanley]{DBLP:journals/corr/abs-1901-01753}
R.~Wang, J.~Lehman, J.~Clune, and K.~O. Stanley.
\newblock Paired open-ended trailblazer {(POET):} endlessly generating
  increasingly complex and diverse learning environments and their solutions.
\newblock \emph{arXiv preprint arXiv: 1901.01753}, 2019.

\bibitem[Wang et~al.(2020{\natexlab{b}})Wang, Lehman, Rawal, Zhi, Li, Clune,
  and Stanley]{icml2020_4745}
R.~Wang, J.~Lehman, A.~Rawal, J.~Zhi, Y.~Li, J.~Clune, and K.~Stanley.
\newblock Enhanced poet: Open-ended reinforcement learning through unbounded
  invention of learning challenges and their solutions.
\newblock In \emph{International Conference on Machine Learning, {(}ICML{)}},
  pages 119:9940--9951, 2020{\natexlab{b}}.

\bibitem[{Whiteson} et~al.(2011){Whiteson}, {Tanner}, {Taylor}, and
  {Stone}]{5967363}
S.~{Whiteson}, B.~{Tanner}, M.~E. {Taylor}, and P.~{Stone}.
\newblock Protecting against evaluation overfitting in empirical reinforcement
  learning.
\newblock In \emph{IEEE Symposium on Adaptive Dynamic Programming and
  Reinforcement Learning (ADPRL)}, pages 120--127, 2011.

\bibitem[Xie et~al.(2020)Xie, Harrison, and
  Finn]{DBLP:journals/corr/abs-2006-10701}
A.~Xie, J.~Harrison, and C.~Finn.
\newblock Deep reinforcement learning amidst lifelong non-stationarity.
\newblock \emph{arXiv preprint arXiv: 2006.10701}, 2020.

\bibitem[Yang et~al.(2020)Yang, Petersen, Zha, and
  Faissol]{DBLP:conf/iclr/YangPZF20}
J.~Yang, B.~K. Petersen, H.~Zha, and D.~Faissol.
\newblock Single episode policy transfer in reinforcement learning.
\newblock In \emph{International Conference on Learning Representations,
  {(}ICLR{)}}, 2020.

\bibitem[Yarats et~al.(2021)Yarats, Kostrikov, and
  Fergus]{DBLP:conf/iclr/YaratsKF21}
D.~Yarats, I.~Kostrikov, and R.~Fergus.
\newblock Image augmentation is all you need: Regularizing deep reinforcement
  learning from pixels.
\newblock In \emph{International Conference on Learning Representations,
  {(}ICLR{)}}, 2021.

\bibitem[Yin et~al.(2020)Yin, Tucker, Zhou, Levine, and
  Finn]{DBLP:conf/iclr/YinTZLF}
M.~Yin, G.~Tucker, M.~Zhou, S.~Levine, and C.~Finn.
\newblock Meta-learning without memorization.
\newblock In \emph{International Conference on Learning Representations,
  {(}ICLR{)}}, 2020.

\bibitem[Zhang et~al.(2018{\natexlab{a}})Zhang, Vinyals, Munos, and
  Bengio]{DBLP:journals/corr/ZhangVMB18}
C.~Zhang, O.~Vinyals, R.~Munos, and S.~Bengio.
\newblock A study on overfitting in deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv: 1804.06893}, 2018{\natexlab{a}}.

\bibitem[Zhang et~al.(2018{\natexlab{b}})Zhang, Ciss{\'{e}}, Dauphin, and
  Lopez{-}Paz]{DBLP:conf/iclr/ZhangCDL18}
H.~Zhang, M.~Ciss{\'{e}}, Y.~N. Dauphin, and D.~Lopez{-}Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock In \emph{International Conference on Learning Representations,
  {(}ICLR{)}}, 2018{\natexlab{b}}.

\bibitem[Zhu et~al.(2020)Zhu, Zhang, Lee, and Zhang]{DBLP:conf/nips/ZhuZLZ20}
G.~Zhu, M.~Zhang, H.~Lee, and C.~Zhang.
\newblock Bridging imagination and reality for model-based deep reinforcement
  learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  {(}NeurIPS{)}}, pages 33:8993--9006, 2020.

\bibitem[Zintgraf et~al.(2019)Zintgraf, Shiarlis, Kurin, Hofmann, and
  Whiteson]{DBLP:conf/icml/ZintgrafSKHW19}
L.~M. Zintgraf, K.~Shiarlis, V.~Kurin, K.~Hofmann, and S.~Whiteson.
\newblock Fast context adaptation via meta-learning.
\newblock In \emph{International Conference on Machine Learning, {(}ICML{)}},
  pages 97:7693--7702, 2019.

\bibitem[Zintgraf et~al.(2020)Zintgraf, Shiarlis, Igl, Schulze, Gal, Hofmann,
  and Whiteson]{DBLP:conf/iclr/ZintgrafSISGHW20}
L.~M. Zintgraf, K.~Shiarlis, M.~Igl, S.~Schulze, Y.~Gal, K.~Hofmann, and
  S.~Whiteson.
\newblock Varibad: {A} very good method for bayes-adaptive deep {RL} via
  meta-learning.
\newblock In \emph{International Conference on Learning Representations,
  {(}ICLR{)}}, 2020.

\end{thebibliography}
