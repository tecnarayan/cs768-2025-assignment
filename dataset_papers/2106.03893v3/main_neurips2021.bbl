\begin{thebibliography}{10}

\bibitem{alon_bottleneck_2020}
Uri Alon and Eran Yahav.
\newblock On the bottleneck of graph neural networks and its practical
  implications.
\newblock {\em {arXiv}:2006.05205 [cs, stat]}, 2020.

\bibitem{beaini_deep_2020}
Dominique Beaini, Sofiane Achiche, Alexandre Duperré, and Maxime Raison.
\newblock Deep green function convolution for improving saliency in
  convolutional neural networks.
\newblock {\em The Visual Computer}, 37(2):227--244, 2020.

\bibitem{beaini_improving_2020}
Dominique Beaini, Sofiane Achiche, and Maxime Raison.
\newblock Improving convolutional neural networks via conservative field
  regularisation and integration.

\bibitem{beaini_directional_2021}
Dominique Beaini, Saro Passaro, Vincent Létourneau, William~L. Hamilton,
  Gabriele Corso, and Pietro Liò.
\newblock Directional graph networks.
\newblock {\em ICML2021}, 2021.

\bibitem{bresson2017gatedGCN}
Xavier Bresson and Thomas Laurent.
\newblock Residual gated graph convnets.
\newblock {\em arXiv preprint arXiv:1711.07553}, 2017.

\bibitem{bronstein_geometric_2017}
Michael~M. Bronstein, Joan Bruna, Yann {LeCun}, Arthur Szlam, and Pierre
  Vandergheynst.
\newblock Geometric deep learning: going beyond euclidean data.
\newblock {\em {IEEE} Signal Processing Magazine}, 34(4):18--42, 2017.

\bibitem{cajori1999history}
F.~Cajori.
\newblock {\em A History of Mathematics}.
\newblock AMS Chelsea Publishing Series. AMS Chelsea, 1999.

\bibitem{changeSGAN}
Heng Chang, Yu~Rong, Tingyang Xu, Wenbing Huang, Somayeh Sojoudi, Junzhou
  Huang, and Wenwu Zhu.
\newblock Spectral graph attention network.
\newblock {\em CoRR}, abs/2003.07450, 2020.

\bibitem{chung_discrete_2000}
Fan Chung and S.~T. Yau.
\newblock Discrete green's functions.
\newblock {\em Journal of Combinatorial Theory, Series A}, 91(1):191--214,
  2000.

\bibitem{COIFMAN20065}
Ronald~R. Coifman and Stéphane Lafon.
\newblock Diffusion maps.
\newblock {\em Applied and Computational Harmonic Analysis}, 21(1):5--30, 2006.
\newblock Special Issue: Diffusion Maps and Wavelets.

\bibitem{corso2020principal}
Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Li{\`o}, and Petar
  Veli{\v{c}}kovi{\'c}.
\newblock Principal neighbourhood aggregation for graph nets.
\newblock {\em arXiv preprint arXiv:2004.05718}, 2020.

\bibitem{cosmo_isospectralization_2019}
Luca Cosmo, Mikhail Panine, Arianna Rampini, Maks Ovsjanikov, Michael~M.
  Bronstein, and Emanuele Rodola.
\newblock Isospectralization, or how to hear shape, style, and correspondence.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2019.

\bibitem{dongadaptive}
Yushun Dong, Kaize Ding, Brian Jalaian, Shuiwang Ji, and Jundong Li.
\newblock Graph neural networks with adaptive frequency response filter.
\newblock {\em CoRR}, abs/2104.12840, 2021.

\bibitem{dwivedi2020generalization}
Vijay~Prakash Dwivedi and Xavier Bresson.
\newblock A generalization of transformer networks to graphs, 2020.

\bibitem{dwivedi2020benchmarking}
Vijay~Prakash Dwivedi, Chaitanya~K Joshi, Thomas Laurent, Yoshua Bengio, and
  Xavier Bresson.
\newblock Benchmarking graph neural networks.
\newblock {\em arXiv preprint arXiv:2003.00982}, 2020.

\bibitem{Feynman:1494701}
Richard~Phillips Feynman, Robert~Benjamin Leighton, and Matthew Sands.
\newblock {\em {The Feynman lectures on physics; New millennium ed.}}
\newblock Basic Books, New York, NY, 2010.
\newblock Originally published 1963-1965.

\bibitem{gilmer2017mpnn}
Justin Gilmer, Samuel~S Schoenholz, Patrick~F Riley, Oriol Vinyals, and
  George~E Dahl.
\newblock Neural message passing for quantum chemistry.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 1263--1272. JMLR. org, 2017.

\bibitem{hamilton2017inductive}
Will Hamilton, Zhitao Ying, and Jure Leskovec.
\newblock Inductive representation learning on large graphs.
\newblock In {\em Advances in neural information processing systems}, pages
  1024--1034, 2017.

\bibitem{hamilton_2020}
William~L. Hamilton.
\newblock {\em Graph Representation Learning}.
\newblock Morgan and Claypool, 2020.

\bibitem{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural computation}, 9(8):1735--1780, 1997.

\bibitem{hu2020open}
Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu,
  Michele Catasta, and Jure Leskovec.
\newblock Open graph benchmark: Datasets for machine learning on graphs.
\newblock {\em arXiv preprint arXiv:2005.00687}, 2020.

\bibitem{jin_junction_2018}
Wengong Jin, Regina Barzilay, and Tommi Jaakkola.
\newblock Junction tree variational autoencoder for molecular graph generation.
\newblock {\em {arXiv}:1802.04364 [cs, stat]}, 2018.

\bibitem{kac_can_1966}
Mark Kac.
\newblock Can one hear the shape of a drum?
\newblock {\em The American Mathematical Monthly}, 73(4):1, 1966.

\bibitem{kazi2020differentiable}
Anees Kazi, Luca Cosmo, Nassir Navab, and Michael Bronstein.
\newblock Differentiable graph module (dgm) graph convolutional networks.
\newblock {\em arXiv preprint arXiv:2002.04999}, 2020.

\bibitem{kipf2016gcn}
Thomas~N Kipf and Max Welling.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock {\em arXiv preprint arXiv:1609.02907}, 2016.

\bibitem{levy_laplace_beltrami_2006}
B.~Levy.
\newblock Laplace-beltrami eigenfunctions towards an algorithm that
  "understands" geometry.
\newblock In {\em {IEEE} International Conference on Shape Modeling and
  Applications 2006 ({SMI}'06)}, pages 13--13, 2006.

\bibitem{li_distance_2020}
Pan Li, Yanbang Wang, Hongwei Wang, and Jure Leskovec.
\newblock Distance encoding: Design provably more powerful neural networks for
  graph representation learning, 2020.

\bibitem{lipman_2010_biharmonic}
Yaron Lipman, Raif~M. Rustamov, and Thomas~A. Funkhouser.
\newblock Biharmonic distance.
\newblock {\em ACM Trans. Graph.}, 29(3), July 2010.

\bibitem{maron2019provably}
Haggai Maron, Heli Ben-Hamu, Hadar Serviansky, and Yaron Lipman.
\newblock Provably powerful graph networks.
\newblock {\em arXiv preprint arXiv:1905.11136}, 2019.

\bibitem{morris2019weisfeiler}
Christopher Morris, Martin Ritzert, Matthias Fey, William~L Hamilton, Jan~Eric
  Lenssen, Gaurav Rattan, and Martin Grohe.
\newblock Weisfeiler and leman go neural: Higher-order graph neural networks.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 4602--4609, 2019.

\bibitem{paszke2017pytorch}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem{rodola_partial_2015}
Emanuele Rodolà, Luca Cosmo, Michael~M. Bronstein, Andrea Torsello, and Daniel
  Cremers.
\newblock Partial functional correspondence, 2015.

\bibitem{schrier_can_2020}
Joshua Schrier.
\newblock Can one hear the shape of a molecule (from its coulomb matrix
  eigenvalues)?
\newblock {\em Journal of Chemical Information and Modeling}, 60(8):3804--3811,
  2020.
\newblock Publisher: American Chemical Society.

\bibitem{tay_efficient_2020}
Yi~Tay, Mostafa Dehghani, Dara Bahri, and Donald Metzler.
\newblock Efficient transformers: A survey, 2020.

\bibitem{van_dam_which_2003}
Edwin~R. van Dam and Willem~H. Haemers.
\newblock Which graphs are determined by their spectrum?
\newblock {\em Linear Algebra and its Applications}, 373:241--272, 2003.

\bibitem{vaswani_2017_attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em CoRR}, abs/1706.03762, 2017.

\bibitem{velikovic2017gat}
Petar Veli{\v{c}}kovi{\'c}, Guillem Cucurull, Arantxa Casanova, Adriana Romero,
  Pietro Lio, and Yoshua Bengio.
\newblock Graph attention networks.
\newblock {\em arXiv preprint arXiv:1710.10903}, 2017.

\bibitem{wang2019dgl}
Minjie Wang, Da~Zheng, Zihao Ye, Quan Gan, Mufei Li, Xiang Song, Jinjing Zhou,
  Chao Ma, Lingfan Yu, Yu~Gai, Tianjun Xiao, Tong He, George Karypis, Jinyang
  Li, and Zheng Zhang.
\newblock Deep graph library: A graph-centric, highly-performant package for
  graph neural networks.
\newblock {\em arXiv preprint arXiv:1909.01315}, 2019.

\bibitem{xu2018gin}
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka.
\newblock How powerful are graph neural networks?
\newblock {\em arXiv preprint arXiv:1810.00826}, 2018.

\bibitem{yun2020transformers}
Chulhee Yun, Srinadh Bhojanapalli, Ankit~Singh Rawat, Sashank~J. Reddi, and
  Sanjiv Kumar.
\newblock Are transformers universal approximators of sequence-to-sequence
  functions?, 2020.

\bibitem{yun2020sparsetransformers}
Chulhee Yun, Yin{-}Wen Chang, Srinadh Bhojanapalli, Ankit~Singh Rawat,
  Sashank~J. Reddi, and Sanjiv Kumar.
\newblock {\textdollar}o(n){\textdollar} connections are expressive enough:
  Universal approximability of sparse transformers.
\newblock {\em CoRR}, abs/2006.04862, 2020.

\bibitem{yun_graph_2020}
Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, and Hyunwoo~J. Kim.
\newblock Graph transformer networks, 2020.

\end{thebibliography}
