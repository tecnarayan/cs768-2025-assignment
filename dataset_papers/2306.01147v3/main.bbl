\begin{thebibliography}{34}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anil et~al.(2019)Anil, Lucas, and Grosse]{pmlr-v97-anil19a}
Anil, C., Lucas, J., and Grosse, R.
\newblock Sorting out {L}ipschitz function approximation.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  291--301, 2019.

\bibitem[Archer \& Wang(1993)Archer and Wang]{archer93}
Archer, N.~P. and Wang, S.
\newblock Application of the back propagation neural network algorithm with
  monotonicity constraints for two-group classification problems.
\newblock \emph{Decision Sciences}, 24\penalty0 (1):\penalty0 60--75, 1993.

\bibitem[Best \& Chakravarti(1990)Best and Chakravarti]{best1990active}
Best, M.~J. and Chakravarti, N.
\newblock Active set algorithms for isotonic regression; a unifying framework.
\newblock \emph{Mathematical Programming}, 47\penalty0 (1-3):\penalty0
  425--439, 1990.

\bibitem[Cano et~al.(2019)Cano, Gutiérrez, Krawczyk, Woźniak, and
  García]{cano:19}
Cano, J.-R., Gutiérrez, P.~A., Krawczyk, B., Woźniak, M., and García, S.
\newblock Monotonic classification: An overview on algorithms, performance
  measures and data sets.
\newblock \emph{Neurocomputing}, 341:\penalty0 168--182, 2019.

\bibitem[Cassotti et~al.(2015)Cassotti, Ballabio, Todeschini, and
  Consonni]{cassotti2015similarity}
Cassotti, M., Ballabio, D., Todeschini, R., and Consonni, V.
\newblock A similarity-based {QSAR} model for predicting acute toxicity towards
  the fathead minnow (pimephales promelas).
\newblock \emph{SAR and QSAR in Environmental Research}, 26\penalty0
  (3):\penalty0 217--243, 2015.

\bibitem[Chen \& Guestrin(2016)Chen and Guestrin]{Chen:2016}
Chen, T. and Guestrin, C.
\newblock {XGBoost}: A scalable tree boosting system.
\newblock In \emph{International Conference on Knowledge Discovery and Data
  Mining (KDD)}, pp.\  785--794. ACM, 2016.

\bibitem[Clevert et~al.(2016)Clevert, Unterthiner, and
  Hochreiter]{clevert2015fast}
Clevert, D.-A., Unterthiner, T., and Hochreiter, S.
\newblock Fast and accurate deep network learning by exponential linear units
  ({ELUs}).
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2016.

\bibitem[Cole \& Williamson(2019)Cole and Williamson]{cole2019avoiding}
Cole, G.~W. and Williamson, S.~A.
\newblock Avoiding resentment via monotonic fairness.
\newblock \emph{arXiv preprint arXiv:1909.01251}, 2019.

\bibitem[Daniels \& Velikova(2010)Daniels and Velikova]{daniels:2010}
Daniels, H. and Velikova, M.
\newblock Monotone and partially monotone neural networks.
\newblock \emph{IEEE Transactions on Neural Networks}, 21\penalty0
  (6):\penalty0 906--917, 2010.

\bibitem[De~Leeuw et~al.(2009)De~Leeuw, Hornik, and Mair]{de2009isotone}
De~Leeuw, J., Hornik, K., and Mair, P.
\newblock Isotone optimization in {R}: pool-adjacent-violators algorithm
  ({PAVA}) and active set methods.
\newblock \emph{Journal of Statistical Software}, 32\penalty0 (5):\penalty0
  1--24, 2009.

\bibitem[Dua \& Graff(2017)Dua and Graff]{Dua:2019}
Dua, D. and Graff, C.
\newblock {UCI} machine learning repository, 2017.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[Eidnes \& Nøkland(2018)Eidnes and Nøkland]{eides:18}
Eidnes, L.~H. and Nøkland, A.
\newblock Shifting mean activation towards zero with bipolar activation
  functions.
\newblock In \emph{International Conference on Learning Representations (ICLR)
  Workshop Track Proceedings}, 2018.

\bibitem[Gupta et~al.(2019)Gupta, Shukla, Marla, Kolbeinsson, and
  Yellepeddi]{gupta2019incorporate}
Gupta, A., Shukla, N., Marla, L., Kolbeinsson, A., and Yellepeddi, K.
\newblock How to incorporate monotonicity in deep networks while preserving
  flexibility?
\newblock In \emph{NeurIPS 2019 Workshop on Machine Learning with Guarantees},
  2019.

\bibitem[Hiernaux et~al.(2023)Hiernaux, Issoufou, Igel, Kariryaa, Kourouma,
  Chave, Mougin, and Savadogo]{hiernaux:23}
Hiernaux, P., Issoufou, B.-A.~H., Igel, C., Kariryaa, A., Kourouma, M., Chave,
  J., Mougin, E., and Savadogo, P.
\newblock Allometric equations to estimate the dry mass of sahel woody plants
  from very-high resolution satellite imagery.
\newblock \emph{Forest Ecology and Management}, 529, 2023.

\bibitem[Igel \& H\"usken(2003)Igel and H\"usken]{igel:01e}
Igel, C. and H\"usken, M.
\newblock Empirical evaluation of the improved {R}prop learning algorithm.
\newblock \emph{Neurocomputing}, 50\penalty0 (C):\penalty0 105--123, 2003.

\bibitem[Liu et~al.(2020)Liu, Han, Zhang, and Liu]{liu2020certified}
Liu, X., Han, X., Zhang, N., and Liu, Q.
\newblock Certified monotonic neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~33, pp.\  15427--15438, 2020.

\bibitem[Maas et~al.(2013)Maas, Hannun, and Ng]{maas2013rectifier}
Maas, A.~L., Hannun, A.~Y., and Ng, A.~Y.
\newblock Rectifier nonlinearities improve neural network acoustic models.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2013.

\bibitem[Mikulincer \& Reichman(2022)Mikulincer and Reichman]{mikulincer:22}
Mikulincer, D. and Reichman, D.
\newblock Size and depth of monotone neural networks: interpolation and
  approximation.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2022.

\bibitem[Milani~Fard et~al.(2016)Milani~Fard, Canini, Cotter, Pfeifer, and
  Gupta]{fard:16}
Milani~Fard, M., Canini, K., Cotter, A., Pfeifer, J., and Gupta, M.
\newblock Fast and flexible monotonic functions with ensembles of lattices.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~29, 2016.

\bibitem[Nair \& Hinton(2010)Nair and Hinton]{nair2010rectified}
Nair, V. and Hinton, G.~E.
\newblock Rectified linear units improve restricted {Boltzmann} machines.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  807--814, 2010.

\bibitem[Niculescu-Mizil \& Caruana(2005)Niculescu-Mizil and
  Caruana]{niculescu2005predicting}
Niculescu-Mizil, A. and Caruana, R.
\newblock Predicting good probabilities with supervised learning.
\newblock In \emph{International Conference on Machine learning (ICML)}, pp.\
  625--632, 2005.

\bibitem[Nolte et~al.(2022)Nolte, Kitouni, and Williams]{nolte2022expressive}
Nolte, N., Kitouni, O., and Williams, M.
\newblock Expressive monotonic neural networks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2022.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos,
  Cournapeau, Brucher, Perrot, and {{\'E}}douard Duchesnay]{scikit-learn}
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel,
  O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J.,
  Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and {{\'E}}douard
  Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2825--2830,
  2011.

\bibitem[Prechelt(2012)]{Prechelt2012}
Prechelt, L.
\newblock Early stopping --- but when?
\newblock In Montavon, G., Orr, G.~B., and M{\"u}ller, K.-R. (eds.),
  \emph{Neural Networks: Tricks of the Trade: Second Edition}, pp.\  53--67.
  Springer, 2012.
\newblock ISBN 978-3-642-35289-8.

\bibitem[Riedmiller \& Braun(1993)Riedmiller and Braun]{riedmiller1993direct}
Riedmiller, M. and Braun, H.
\newblock A direct adaptive method for faster backpropagation learning: The
  {RPROP} algorithm.
\newblock In \emph{IEEE International Conference on Neural Networks}, pp.\
  586--591. IEEE, 1993.

\bibitem[Runje \& Shankaranarayana(2023)Runje and Shankaranarayana]{runje23}
Runje, D. and Shankaranarayana, S.~M.
\newblock Constrained monotonic neural networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, volume
  202 of \emph{Proceedings of Machine Learning Research}, pp.\  29338--29353.
  PMLR, 23--29 Jul 2023.

\bibitem[Sill(1997)]{sill:97}
Sill, J.
\newblock Monotonic networks.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~10. MIT Press, 1997.

\bibitem[Sivaraman et~al.(2020)Sivaraman, Farnadi, Millstein, and Van~den
  Broeck]{sivaraman2020counterexample}
Sivaraman, A., Farnadi, G., Millstein, T., and Van~den Broeck, G.
\newblock Counterexample-guided learning of monotonic neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~33, pp.\  11936--11948, 2020.

\bibitem[Tsanas \& Xifara(2012)Tsanas and Xifara]{tsanas2012accurate}
Tsanas, A. and Xifara, A.
\newblock Accurate quantitative estimation of energy performance of residential
  buildings using statistical machine learning tools.
\newblock \emph{Energy and Buildings}, 49:\penalty0 560--567, 2012.

\bibitem[Tucker et~al.(2023)Tucker, Brandt, Hiernaux, Kariryaa, Rasmussen,
  Small, Igel, Reiner, Melocik, Meyer, Sinno, Romero, Glennie, Fitts, Morin,
  Pinzon, McClain, Morin, Porter, Loeffle, Kergoat, Issoufou, Savadogo,
  Wigneron, Poulter, Ciais, Kaufmann, Myneni, Saatchi, and Fensholt]{tucker:23}
Tucker, C., Brandt, M., Hiernaux, P., Kariryaa, A., Rasmussen, K., Small, J.,
  Igel, C., Reiner, F., Melocik, K., Meyer, J., Sinno, S., Romero, E., Glennie,
  E., Fitts, Y., Morin, A., Pinzon, J., McClain, D., Morin, P., Porter, C.,
  Loeffle, S., Kergoat, L., Issoufou, B.-A., Savadogo, P., Wigneron, J.-P.,
  Poulter, B., Ciais, P., Kaufmann, R., Myneni, R., Saatchi, S., and Fensholt,
  R.
\newblock Sub-continental scale carbon stocks of individual trees in {African}
  drylands.
\newblock \emph{Nature}, 615:\penalty0 80--86, 2023.

\bibitem[Wang \& Gupta(2020)Wang and Gupta]{wang2020deontological}
Wang, S. and Gupta, M.
\newblock Deontological ethics by monotonicity shape constraints.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, pp.\  2043--2054, 2020.

\bibitem[Yanagisawa et~al.(2022)Yanagisawa, Miyaguchi, and
  Katsuki]{yanagisawa2022hierarchical}
Yanagisawa, H., Miyaguchi, K., and Katsuki, T.
\newblock Hierarchical lattice layer for partially monotone neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2022.

\bibitem[Yeh(1998)]{yeh1998modeling}
Yeh, I.-C.
\newblock Modeling of strength of high-performance concrete using artificial
  neural networks.
\newblock \emph{Cement and Concrete Research}, 28\penalty0 (12):\penalty0
  1797--1808, 1998.

\bibitem[You et~al.(2017)You, Ding, Canini, Pfeifer, and Gupta]{you:17}
You, S., Ding, D., Canini, K., Pfeifer, J., and Gupta, M.
\newblock Deep lattice networks and partial monotonic functions.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~30, 2017.

\end{thebibliography}
