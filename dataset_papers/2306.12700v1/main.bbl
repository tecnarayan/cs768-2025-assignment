\begin{thebibliography}{10}

\bibitem{GPT3}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
  Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
  Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
  Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
  and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock In {\em NeurIPS}, 2020.

\bibitem{cettolo-etal-2014-report}
Mauro Cettolo, Jan Niehues, Sebastian St{\"u}ker, Luisa Bentivogli, and
  Marcello Federico.
\newblock Report on the 11th {IWSLT} evaluation campaign.
\newblock In {\em Proceedings of the 11th International Workshop on Spoken
  Language Translation: Evaluation Campaign}, 2014.

\bibitem{DBLP:journals/corr/ChenPSA17}
Liang{-}Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam.
\newblock Rethinking atrous convolution for semantic image segmentation.
\newblock {\em arXiv:1706.05587}, 2017.

\bibitem{DBLP:journals/corr/ChenGS15}
Tianqi Chen, Ian~J. Goodfellow, and Jonathon Shlens.
\newblock Net2net: Accelerating learning via knowledge transfer.
\newblock In Yoshua Bengio and Yann LeCun, editors, {\em ICLR}, 2016.

\bibitem{DBLP:journals/tc/DaiYJ19}
Xiaoliang Dai, Hongxu Yin, and Niraj~K. Jha.
\newblock Nest: {A} neural network synthesis tool based on a grow-and-prune
  paradigm.
\newblock {\em {IEEE} Trans. Computers}, 2019.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock {ImageNet}: A large-scale hierarchical image database.
\newblock In {\em CVPR}, 2009.

\bibitem{DBLP:conf/naacl/DevlinCLT19}
Jacob Devlin, Ming{-}Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT:} pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em NAACL}, 2019.

\bibitem{DBLP:journals/jmlr/DuchiHS11}
John~C. Duchi, Elad Hazan, and Yoram Singer.
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock {\em JMLR}, 2011.

\bibitem{DBLP:conf/iclr/ElskenMH18}
Thomas Elsken, Jan~Hendrik Metzen, and Frank Hutter.
\newblock Simple and efficient architecture search for convolutional neural
  networks.
\newblock In {\em ICLR Workshop}, 2018.

\bibitem{evci2022gradmax}
Utku Evci, Bart van Merrienboer, Thomas Unterthiner, Fabian Pedregosa, and Max
  Vladymyrov.
\newblock Gradmax: Growing neural networks using gradient information.
\newblock In {\em ICLR}, 2022.

\bibitem{nasfpn}
Golnaz Ghiasi, Tsung-Yi Lin, Ruoming Pang, and Quoc~V. Le.
\newblock Nas-fpn: Learning scalable feature pyramid architecture for object
  detection.
\newblock {\em arXiv:1904.07392}, 2019.

\bibitem{ginsburg2018large}
Boris Ginsburg, Igor Gitman, and Yang You.
\newblock Large batch training of convolutional networks with layer-wise
  adaptive rate scaling, 2018.

\bibitem{DBLP:conf/iccv/Girshick15}
Ross~B. Girshick.
\newblock Fast {R-CNN}.
\newblock In {\em ICCV}, 2015.

\bibitem{gross2016training}
Sam Gross and Michael Wilber.
\newblock Training and investigating residual nets.
\newblock {\em \url{http://torch.ch/blog/2016/02/04/resnets.html}}, 2016.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, pages 770--778, 2016.

\bibitem{DBLP:conf/cvpr/HeZRS16}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{DBLP:conf/aistats/HorvathKRA21}
Samuel Horv{\'{a}}th, Aaron Klein, Peter Richt{\'{a}}rik, and C{\'{e}}dric
  Archambeau.
\newblock Hyperparameter transfer learning with adaptive complexity.
\newblock In {\em AISTATS}, 2021.

\bibitem{DBLP:journals/corr/HowardZCKWWAA17}
Andrew~G. Howard, Menglong Zhu, Bo~Chen, Dmitry Kalenichenko, Weijun Wang,
  Tobias Weyand, Marco Andreetto, and Hartwig Adam.
\newblock Mobilenets: Efficient convolutional neural networks for mobile vision
  applications.
\newblock {\em arXiv:1704.04861}, 2017.

\bibitem{DBLP:conf/eccv/HuangSLSW16}
Gao Huang, Yu~Sun, Zhuang Liu, Daniel Sedra, and Kilian~Q. Weinberger.
\newblock Deep networks with stochastic depth.
\newblock In {\em ECCV}, 2016.

\bibitem{DBLP:conf/icml/IoffeS15}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In {\em ICML}, 2015.

\bibitem{DBLP:journals/corr/KingmaB14}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In Yoshua Bengio and Yann LeCun, editors, {\em ICLR}, 2015.

\bibitem{krizhevsky2014cifar}
Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.
\newblock The {CIFAR}-10 dataset.
\newblock {\em \url{http://www.cs.toronto.edu/~kriz/cifar.html}}, 2014.

\bibitem{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock {ImageNet} classification with deep convolutional neural networks.
\newblock In {\em NeurIPS}, 2012.

\bibitem{li2019learn}
Xilai Li, Yingbo Zhou, Tianfu Wu, Richard Socher, and Caiming Xiong.
\newblock Learn to grow: A continual structure learning framework for
  overcoming catastrophic forgetting.
\newblock {\em arXiv preprint arXiv:1904.00310}, 2019.

\bibitem{autodeeplab}
Chenxi Liu, Liang{-}Chieh Chen, Florian Schroff, Hartwig Adam, Wei Hua, Alan~L.
  Yuille, and Li~Fei{-}Fei.
\newblock Auto-deeplab: Hierarchical neural architecture search for semantic
  image segmentation.
\newblock In {\em CVPR}, 2019.

\bibitem{splitting2019}
Qiang Liu, Wu~Lemeng, and Wang Dilin.
\newblock Splitting steepest descent for growing neural architectures.
\newblock In {\em NeurIPS}, 2019.

\bibitem{DBLP:conf/eccv/LiuAESRFB16}
Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott~E. Reed,
  Cheng{-}Yang Fu, and Alexander~C. Berg.
\newblock {SSD:} single shot multibox detector.
\newblock In {\em ECCV}, 2016.

\bibitem{DBLP:conf/cvpr/LongSD15}
Jonathan Long, Evan Shelhamer, and Trevor Darrell.
\newblock Fully convolutional networks for semantic segmentation.
\newblock In {\em CVPR}, 2015.

\bibitem{DBLP:conf/acl/PapineniRWZ02}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei{-}Jing Zhu.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock In {\em ACL}, 2002.

\bibitem{DBLP:conf/nips/PerroneJSA18}
Valerio Perrone, Rodolphe Jenatton, Matthias~W. Seeger, and C{\'{e}}dric
  Archambeau.
\newblock Scalable hyperparameter transfer learning.
\newblock In {\em NeurIPS}, 2018.

\bibitem{amoeba}
Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc~V. Le.
\newblock Regularized evolution for image classifier architecture search.
\newblock In {\em AAAI}, 2019.

\bibitem{DBLP:conf/cvpr/SavareseMBM21}
Pedro Savarese, David McAllester, Sudarshan Babu, and Michael Maire.
\newblock Domain-independent dominance of adaptive methods.
\newblock In {\em CVPR}, 2021.

\bibitem{DBLP:journals/corr/SimonyanZ14a}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In {\em ICLR}, 2015.

\bibitem{tieleman2012lecture}
Tijmen Tieleman, Geoffrey Hinton, et~al.
\newblock Lecture 6.5-rmsprop: Divide the gradient by a running average of its
  recent magnitude.
\newblock {\em COURSERA: Neural networks for machine learning}, 2012.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, 2017.

\bibitem{DBLP:conf/icml/WanH0M20}
Chengcheng Wan, Henry Hoffmann, Shan Lu, and Michael Maire.
\newblock Orthogonalized {SGD} and nested architectures for anytime neural
  networks.
\newblock In {\em ICML}, 2020.

\bibitem{DBLP:conf/icml/WeiWRC16}
Tao Wei, Changhu Wang, Yong Rui, and Chang~Wen Chen.
\newblock Network morphism.
\newblock In {\em ICML}, 2016.

\bibitem{DBLP:conf/kdd/Wen0CL20}
Wei Wen, Feng Yan, Yiran Chen, and Hai Li.
\newblock Autogrow: Automatic layer growing in deep convolutional networks.
\newblock In {\em KDD}, 2020.

\bibitem{DBLP:conf/nips/WuLS020}
Lemeng Wu, Bo~Liu, Peter Stone, and Qiang Liu.
\newblock Firefly neural architecture descent: a general approach for growing
  neural networks.
\newblock In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell,
  Maria{-}Florina Balcan, and Hsuan{-}Tien Lin, editors, {\em NeurIPS}, 2020.

\bibitem{wu2020steepest}
Lemeng Wu, Mao Ye, Qi~Lei, Jason~D Lee, and Qiang Liu.
\newblock Steepest descent neural architecture optimization: Escaping local
  optimum with signed neural splitting.
\newblock {\em arXiv preprint arXiv:2003.10392}, 2020.

\bibitem{DBLP:conf/icml/YangH21}
Greg Yang and Edward~J. Hu.
\newblock Tensor programs {IV:} feature learning in infinite-width neural
  networks.
\newblock In {\em ICML}, 2021.

\bibitem{yang2021tuning}
Greg Yang, Edward~J Hu, Igor Babuschkin, Szymon Sidor, Xiaodong Liu, David
  Farhi, Nick Ryder, Jakub Pachocki, Weizhu Chen, and Jianfeng Gao.
\newblock Tuning large neural networks via zero-shot hyperparameter transfer.
\newblock In A.~Beygelzimer, Y.~Dauphin, P.~Liang, and J.~Wortman Vaughan,
  editors, {\em NeurIPS}, 2021.

\bibitem{DBLP:conf/aistats/YogatamaM14}
Dani Yogatama and Gideon Mann.
\newblock Efficient transfer learning method for automatic hyperparameter
  tuning.
\newblock In {\em AISTATS}, 2014.

\bibitem{You2020Large}
Yang You, Jing Li, Sashank Reddi, Jonathan Hseu, Sanjiv Kumar, Srinadh
  Bhojanapalli, Xiaodan Song, James Demmel, Kurt Keutzer, and Cho-Jui Hsieh.
\newblock Large batch optimization for deep learning: Training bert in 76
  minutes.
\newblock In {\em ICLR}, 2020.

\bibitem{yuan2021growing}
Xin Yuan, Pedro Henrique~Pamplona Savarese, and Michael Maire.
\newblock Growing efficient deep networks by structured continuous
  sparsification.
\newblock In {\em ICLR}, 2021.

\bibitem{zagoruyko2016wide}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock {\em arXiv preprint arXiv:1605.07146}, 2016.

\bibitem{scalingvision}
Xiaohua Zhai, Alexander Kolesnikov, Neil Houlsby, and Lucas Beyer.
\newblock Scaling vision transformers.
\newblock In {\em CVPR}, 2022.

\end{thebibliography}
