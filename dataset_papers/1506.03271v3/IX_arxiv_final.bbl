\begin{thebibliography}{26}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alon et~al.(2012)Alon, Cesa-Bianchi, Gentile, and Mansour]{ACGM13}
N.~Alon, N.~Cesa-Bianchi, C.~Gentile, and Y.~Mansour.
\newblock {From Bandits to Experts: A Tale of Domination and Independence}.
\newblock In \emph{{NIPS-25}}, pages 1610--1618, 2012.

\bibitem[Alon et~al.(2014)Alon, Cesa-Bianchi, Gentile, Mannor, Mansour, and
  Shamir]{ACGMMS14}
N.~Alon, N.~Cesa-Bianchi, C.~Gentile, S.~Mannor, Y.~Mansour, and O.~Shamir.
\newblock Nonstochastic multi-armed bandits with graph-structured feedback.
\newblock \emph{arXiv preprint arXiv:1409.8428}, 2014.

\bibitem[Audibert and Bubeck(2009)]{AB09}
J.-Y. Audibert and S.~Bubeck.
\newblock Minimax policies for adversarial and stochastic bandits.
\newblock In \emph{Proceedings of the 22nd Annual Conference on Learning Theory
  (COLT)}, 2009.

\bibitem[Audibert and Bubeck(2010)]{audibert10inf}
J.-Y. Audibert and S.~Bubeck.
\newblock Regret bounds and minimax policies under partial monitoring.
\newblock \emph{Journal of Machine Learning Research}, 11:\penalty0 2785--2836,
  2010.

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, Freund, and
  Schapire]{auer2002bandit}
P.~Auer, N.~Cesa-Bianchi, Y.~Freund, and R.~E. Schapire.
\newblock The nonstochastic multiarmed bandit problem.
\newblock \emph{SIAM J. Comput.}, 32\penalty0 (1):\penalty0 48--77, 2002.
\newblock ISSN 0097-5397.

\bibitem[Bartlett et~al.(2008)Bartlett, Dani, Hayes, Kakade, Rakhlin, and
  Tewari]{BaDaHaKaRaTe08}
P.~L. Bartlett, V.~Dani, T.~P. Hayes, S.~Kakade, A.~Rakhlin, and A.~Tewari.
\newblock High-probability regret bounds for bandit online linear optimization.
\newblock In \emph{COLT}, pages 335--342, 2008.

\bibitem[Beygelzimer et~al.(2011)Beygelzimer, Langford, Li, Reyzin, and
  Schapire]{BLLRS11}
A.~Beygelzimer, J.~Langford, L.~Li, L.~Reyzin, and R.~E. Schapire.
\newblock Contextual bandit algorithms with supervised learning guarantees.
\newblock In \emph{AISTATS 2011}, pages 19--26, 2011.

\bibitem[Bubeck et~al.(2012)Bubeck, Cesa-Bianchi, and Kakade]{BCK12}
S.~Bubeck, N.~Cesa-Bianchi, and S.~M. Kakade.
\newblock Towards minimax policies for online linear optimization with bandit
  feedback.
\newblock 2012.

\bibitem[Bubeck and Cesa-Bianchi(2012)]{bubeck12survey}
S.~Bubeck and N.~Cesa-Bianchi.
\newblock \emph{Regret Analysis of Stochastic and Nonstochastic Multi-armed
  Bandit Problems}.
\newblock Now Publishers Inc, 2012.

\bibitem[Cesa-Bianchi and Lugosi(2006)]{CBLu06:book}
N.~Cesa-Bianchi and G.~Lugosi.
\newblock \emph{Prediction, Learning, and Games}.
\newblock Cambridge University Press, New York, NY, USA, 2006.

\bibitem[Cesa-Bianchi et~al.(2012)Cesa-Bianchi, Gaillard, Lugosi, and
  Stoltz]{CBGLS12}
N.~Cesa-Bianchi, P.~Gaillard, G.~Lugosi, and G.~Stoltz.
\newblock Mirror descent meets fixed share (and feels no regret).
\newblock In \emph{{NIPS-25}}, pages 989--997. 2012.

\bibitem[Freedman(1975)]{Fre75}
D.~A. Freedman.
\newblock On tail probabilities for martingales.
\newblock \emph{The Annals of Probability}, 3:\penalty0 100--118, 1975.

\bibitem[Freund and Schapire(1997)]{FS97}
Y.~Freund and R.~E. Schapire.
\newblock A decision-theoretic generalization of on-line learning and an
  application to boosting.
\newblock \emph{Journal of Computer and System Sciences}, 55:\penalty0
  119--139, 1997.

\bibitem[Hannan(1957)]{Han57}
J.~Hannan.
\newblock Approximation to {B}ayes risk in repeated play.
\newblock \emph{Contributions to the theory of games}, 3:\penalty0 97--139,
  1957.

\bibitem[Hazan and Kale(2011)]{HK11}
E.~Hazan and S.~Kale.
\newblock Better algorithms for benign bandits.
\newblock \emph{The Journal of Machine Learning Research}, 12:\penalty0
  1287--1311, 2011.

\bibitem[Hazan et~al.(2014)Hazan, Karnin, and Meka]{HKM14}
E.~Hazan, Z.~Karnin, and R.~Meka.
\newblock Volumetric spanners: an efficient exploration basis for learning.
\newblock In \emph{COLT}, pages 408--422, 2014.

\bibitem[Herbster and Warmuth(1998)]{HW98}
M.~Herbster and M.~Warmuth.
\newblock Tracking the best expert.
\newblock \emph{Machine Learning}, 32:\penalty0 151--178, 1998.

\bibitem[Kalai and Vempala(2005)]{KV05}
A.~Kalai and S.~Vempala.
\newblock Efficient algorithms for online decision problems.
\newblock \emph{Journal of Computer and System Sciences}, 71:\penalty0
  291--307, 2005.

\bibitem[Koc\'ak et~al.(2014)Koc\'ak, Neu, Valko, and Munos]{KNVM14}
T.~Koc\'ak, G.~Neu, M.~Valko, and R.~Munos.
\newblock Efficient learning by implicit exploration in bandit problems with
  side observations.
\newblock In \emph{{NIPS-27}}, pages 613--621, 2014.

\bibitem[Littlestone and Warmuth(1994)]{LiWa94}
N.~Littlestone and M.~Warmuth.
\newblock The weighted majority algorithm.
\newblock \emph{Information and Computation}, 108:\penalty0 212--261, 1994.

\bibitem[Mannor and Shamir(2011)]{MS11}
S.~Mannor and O.~Shamir.
\newblock {From Bandits to Experts: On the Value of Side-Observations}.
\newblock In \emph{Neural Information Processing Systems}, 2011.

\bibitem[McMahan and Streeter(2009)]{McMaStre09}
H.~B. McMahan and M.~Streeter.
\newblock Tighter bounds for multi-armed bandits with expert advice.
\newblock In \emph{COLT}, 2009.

\bibitem[Neu(2015)]{Neu15}
G.~Neu.
\newblock First-order regret bounds for combinatorial semi-bandits.
\newblock In \emph{COLT}, pages 1360--1375, 2015.

\bibitem[Rakhlin and Sridharan(2013)]{RS13}
A.~Rakhlin and K.~Sridharan.
\newblock Online learning with predictable sequences.
\newblock In \emph{COLT}, pages 993--1019, 2013.

\bibitem[Seldin et~al.(2012)Seldin, Cesa-Bianchi, Auer, Laviolette, and
  Shawe-Taylor]{SCALS12}
Y.~Seldin, N.~Cesa-Bianchi, P.~Auer, F.~Laviolette, and J.~Shawe-Taylor.
\newblock {PAC-Bayes-Bernstein} inequality for martingales and its application
  to multiarmed bandits.
\newblock In \emph{Proceedings of the Workshop on On-line Trading of
  Exploration and Exploitation 2}, 2012.

\bibitem[Vovk(1990)]{Vov90}
V.~Vovk.
\newblock Aggregating strategies.
\newblock In \emph{Proceedings of the third annual workshop on Computational
  learning theory (COLT)}, pages 371--386, 1990.

\end{thebibliography}
