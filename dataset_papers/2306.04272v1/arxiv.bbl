\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Changpinyo et~al.(2021)Changpinyo, Sharma, Ding, and Soricut]{cc12m}
Changpinyo, S., Sharma, P., Ding, N., and Soricut, R.
\newblock Conceptual 12m: Pushing web-scale image-text pre-training to
  recognize long-tail visual concepts.
\newblock In \emph{CVPR}, 2021.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{simclr}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{ICML}, 2020.

\bibitem[Chung(1997)]{chung1997spectral}
Chung, F.~R.
\newblock \emph{Spectral graph theory}, volume~92.
\newblock American Mathematical Soc., 1997.

\bibitem[Clauset et~al.(2008)Clauset, Moore, and
  Newman]{clauset2008hierarchical}
Clauset, A., Moore, C., and Newman, M.~E.
\newblock Hierarchical structure and the prediction of missing links in
  networks.
\newblock \emph{Nature}, 453\penalty0 (7191):\penalty0 98--101, 2008.

\bibitem[Deerwester et~al.(1990)Deerwester, Dumais, Furnas, Landauer, and
  Harshman]{deerwester1990indexing}
Deerwester, S., Dumais, S.~T., Furnas, G.~W., Landauer, T.~K., and Harshman, R.
\newblock Indexing by latent semantic analysis.
\newblock \emph{Journal of the American Society for Information Science},
  41\penalty0 (6):\penalty0 391--407, 1990.

\bibitem[Deng et~al.(2009{\natexlab{a}})Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{CVPR}, 2009{\natexlab{a}}.

\bibitem[Deng et~al.(2009{\natexlab{b}})Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{CVPR}, 2009{\natexlab{b}}.

\bibitem[Ding et~al.(2005)Ding, He, and Simon]{ding2005equivalence}
Ding, C., He, X., and Simon, H.~D.
\newblock On the equivalence of nonnegative matrix factorization and spectral
  clustering.
\newblock In \emph{SDM}, 2005.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{ICLR}, 2021.

\bibitem[Eckart \& Young(1936)Eckart and Young]{eckart1936approximation}
Eckart, C. and Young, G.
\newblock The approximation of one matrix by another of lower rank.
\newblock \emph{Psychometrika}, 1\penalty0 (3):\penalty0 211--218, 1936.

\bibitem[HaoChen et~al.(2021)HaoChen, Wei, Gaidon, and Ma]{haochen}
HaoChen, J.~Z., Wei, C., Gaidon, A., and Ma, T.
\newblock Provable guarantees for self-supervised deep learning with spectral
  contrastive loss.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, 2016.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{moco}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{CVPR}, 2020.

\bibitem[Hjelm et~al.(2019)Hjelm, Fedorov, Lavoie-Marchildon, Grewal, Bachman,
  Trischler, and Bengio]{infomax}
Hjelm, R.~D., Fedorov, A., Lavoie-Marchildon, S., Grewal, K., Bachman, P.,
  Trischler, A., and Bengio, Y.
\newblock Learning deep representations by mutual information estimation and
  maximization.
\newblock In \emph{ICLR}, 2019.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising diffusion probabilistic models.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Huang et~al.(2021)Huang, Du, Xue, Chen, Zhao, and
  Huang]{huang2021makes}
Huang, Y., Du, C., Xue, Z., Chen, X., Zhao, H., and Huang, L.
\newblock What makes multi-modal learning better than single (provably).
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Li et~al.(2019)Li, Yatskar, Yin, Hsieh, and Chang]{li2019visualbert}
Li, L.~H., Yatskar, M., Yin, D., Hsieh, C.-J., and Chang, K.-W.
\newblock Visualbert: A simple and performant baseline for vision and language.
\newblock \emph{arXiv preprint arXiv:1908.03557}, 2019.

\bibitem[Li et~al.(2022{\natexlab{a}})Li, Fan, Hu, Feichtenhofer, and
  He]{li2022scaling}
Li, Y., Fan, H., Hu, R., Feichtenhofer, C., and He, K.
\newblock Scaling language-image pre-training via masking.
\newblock \emph{arXiv preprint arXiv:2212.00794}, 2022{\natexlab{a}}.

\bibitem[Li et~al.(2022{\natexlab{b}})Li, Liang, Zhao, Cui, Ouyang, Shao, Yu,
  and Yan]{declip}
Li, Y., Liang, F., Zhao, L., Cui, Y., Ouyang, W., Shao, J., Yu, F., and Yan, J.
\newblock Supervision exists everywhere: A data efficient contrastive
  language-image pre-training paradigm.
\newblock In \emph{ICLR}, 2022{\natexlab{b}}.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{mscoco}
Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D.,
  Doll{\'a}r, P., and Zitnick, C.~L.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{ECCV}, 2014.

\bibitem[Lu et~al.(2019)Lu, Batra, Parikh, and Lee]{lu2019vilbert}
Lu, J., Batra, D., Parikh, D., and Lee, S.
\newblock Vilbert: Pretraining task-agnostic visiolinguistic representations
  for vision-and-language tasks.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Mu et~al.(2022)Mu, Kirillov, Wagner, and Xie]{mu2022slip}
Mu, N., Kirillov, A., Wagner, D., and Xie, S.
\newblock Slip: Self-supervision meets language-image pre-training.
\newblock In \emph{ECCV}, 2022.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{InfoNCE}
Oord, A. v.~d., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Pennington et~al.(2014)Pennington, Socher, and
  Manning]{pennington2014glove}
Pennington, J., Socher, R., and Manning, C.~D.
\newblock Glove: Global vectors for word representation.
\newblock In \emph{EMNLP}, 2014.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{clip}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry,
  G., Askell, A., Mishkin, P., Clark, J., et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{ICML}, 2021.

\bibitem[Santurkar et~al.(2022)Santurkar, Dubois, Taori, Liang, and
  Hashimoto]{santurkar2022caption}
Santurkar, S., Dubois, Y., Taori, R., Liang, P., and Hashimoto, T.
\newblock Is a caption worth a thousand images? a controlled study for
  representation learning.
\newblock \emph{arXiv preprint arXiv:2207.07635}, 2022.

\bibitem[Saunshi et~al.(2019)Saunshi, Plevrakis, Arora, Khodak, and
  Khandeparkar]{arora}
Saunshi, N., Plevrakis, O., Arora, S., Khodak, M., and Khandeparkar, H.
\newblock A theoretical analysis of contrastive unsupervised representation
  learning.
\newblock In \emph{ICML}, 2019.

\bibitem[Saunshi et~al.(2022)Saunshi, Ash, Goel, Misra, Zhang, Arora, Kakade,
  and Krishnamurthy]{saunshi2022understanding}
Saunshi, N., Ash, J., Goel, S., Misra, D., Zhang, C., Arora, S., Kakade, S.,
  and Krishnamurthy, A.
\newblock Understanding contrastive learning requires incorporating inductive
  biases.
\newblock In \emph{ICML}, 2022.

\bibitem[Sun et~al.(2020)Sun, Xu, Cao, Kong, Hu, Zhang, and Wang]{sun2020tcgm}
Sun, X., Xu, Y., Cao, P., Kong, Y., Hu, L., Zhang, S., and Wang, Y.
\newblock Tcgm: An information-theoretic framework for semi-supervised
  multi-modality learning.
\newblock In \emph{ECCV}, 2020.

\bibitem[Thomee et~al.(2016)Thomee, Shamma, Friedland, Elizalde, Ni, Poland,
  Borth, and Li]{thomee2016yfcc100m}
Thomee, B., Shamma, D.~A., Friedland, G., Elizalde, B., Ni, K., Poland, D.,
  Borth, D., and Li, L.-J.
\newblock Yfcc100m: The new data in multimedia research.
\newblock \emph{Communications of the ACM}, 59\penalty0 (2):\penalty0 64--73,
  2016.

\bibitem[Tschannen et~al.(2022)Tschannen, Mustafa, and
  Houlsby]{tschannen2022image}
Tschannen, M., Mustafa, B., and Houlsby, N.
\newblock Image-and-language understanding from pixels only.
\newblock \emph{arXiv preprint arXiv:2212.08045}, 2022.

\bibitem[Wang \& Isola(2020)Wang and Isola]{wang2020understanding}
Wang, T. and Isola, P.
\newblock Understanding contrastive representation learning through alignment
  and uniformity on the hypersphere.
\newblock In \emph{ICML}, 2020.

\bibitem[Wang et~al.(2021)Wang, Geng, Jiang, Li, Wang, Yang, and
  Lin]{wang2021residual}
Wang, Y., Geng, Z., Jiang, F., Li, C., Wang, Y., Yang, J., and Lin, Z.
\newblock Residual relaxation for multi-view representation learning.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Wang et~al.(2022)Wang, Zhang, Wang, Yang, and Lin]{wang2022chaos}
Wang, Y., Zhang, Q., Wang, Y., Yang, J., and Lin, Z.
\newblock Chaos is a ladder: A new theoretical understanding of contrastive
  learning via augmentation overlap.
\newblock In \emph{ICLR}, 2022.

\bibitem[Wang et~al.(2023)Wang, Zhang, Du, Yang, Lin, and
  Wang]{wang2023message}
Wang, Y., Zhang, Q., Du, T., Yang, J., Lin, Z., and Wang, Y.
\newblock A message passing perspective on learning dynamics of contrastive
  learning.
\newblock In \emph{ICLR}, 2023.

\bibitem[Yao et~al.(2022)Yao, Huang, Hou, Lu, Niu, Xu, Liang, Li, Jiang, and
  Xu]{yao2021filip}
Yao, L., Huang, R., Hou, L., Lu, G., Niu, M., Xu, H., Liang, X., Li, Z., Jiang,
  X., and Xu, C.
\newblock Filip: Fine-grained interactive language-image pre-training.
\newblock In \emph{ICLR}, 2022.

\bibitem[Zhang et~al.(2020)Zhang, Jiang, Miura, Manning, and
  Langlotz]{zhang2020contrastive}
Zhang, Y., Jiang, H., Miura, Y., Manning, C.~D., and Langlotz, C.~P.
\newblock Contrastive learning of medical visual representations from paired
  images and text.
\newblock \emph{arXiv preprint arXiv:2010.00747}, 2020.

\end{thebibliography}
