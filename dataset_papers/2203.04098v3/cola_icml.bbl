\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Albrecht \& Stone(2017)Albrecht and Stone]{albrecht2019reasoning}
Albrecht, S.~V. and Stone, P.
\newblock Reasoning about hypothetical agent behaviours and their parameters.
\newblock In \emph{Proceedings of the 16th Conference on Autonomous Agents and
  MultiAgent Systems}, pp.\  547--555, 2017.

\bibitem[Axelrod \& Hamilton(1981)Axelrod and Hamilton]{Axelrod84}
Axelrod, R. and Hamilton, W.~D.
\newblock The evolution of cooperation.
\newblock \emph{Science}, 211\penalty0 (4489):\penalty0 1390--1396, 1981.

\bibitem[Azizian et~al.(2020)Azizian, Mitliagkas, Lacoste-Julien, and
  Gidel]{azizian2020tight}
Azizian, W., Mitliagkas, I., Lacoste-Julien, S., and Gidel, G.
\newblock A tight and unified analysis of gradient-based methods for a whole
  spectrum of differentiable games.
\newblock In \emph{Proceedings of the Twenty Third International Conference on
  Artificial Intelligence and Statistics}, volume 108 of \emph{Proceedings of
  Machine Learning Research}, pp.\  2863--2873, 2020.

\bibitem[Balduzzi et~al.(2018)Balduzzi, Racani{\`{e}}re, Martens, Foerster,
  Tuyls, and Graepel]{balduzzi_mechanics_2018}
Balduzzi, D., Racani{\`{e}}re, S., Martens, J., Foerster, J.~N., Tuyls, K., and
  Graepel, T.
\newblock The mechanics of n-player differentiable games.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, volume~80 of \emph{Proceedings of Machine Learning Research}, pp.\
   363--372, 2018.

\bibitem[Barto \& Mahadevan(2003)Barto and Mahadevan]{barto2002hierarchical}
Barto, A.~G. and Mahadevan, S.
\newblock Recent advances in hierarchical reinforcement learning.
\newblock \emph{Discret. Event Dyn. Syst.}, 13\penalty0 (1-2):\penalty0 41--77,
  2003.

\bibitem[Dafoe et~al.(2021)Dafoe, Hughes, Bachrach, Collins, McKee, Leibo,
  Larson, and Graepel]{dafoe2020open}
Dafoe, A., Hughes, E., Bachrach, Y., Collins, T., McKee, K.~R., Leibo, J.~Z.,
  Larson, K., and Graepel, T.
\newblock Open problems in cooperative ai.
\newblock In \emph{Cooperative AI workshop}, 2021.

\bibitem[Foerster et~al.(2018{\natexlab{a}})Foerster, Chen, Al-Shedivat,
  Whiteson, Abbeel, and Mordatch]{foerster_learning_2018}
Foerster, J., Chen, R.~Y., Al-Shedivat, M., Whiteson, S., Abbeel, P., and
  Mordatch, I.
\newblock Learning with opponent-learning awareness.
\newblock In \emph{Proceedings of the 17th International Conference on
  Autonomous Agents and MultiAgent Systems}, pp.\  122--130,
  2018{\natexlab{a}}.

\bibitem[Foerster et~al.(2018{\natexlab{b}})Foerster, Farquhar, Al{-}Shedivat,
  Rockt{\"{a}}schel, Xing, and Whiteson]{foerster_dice_2018}
Foerster, J.~N., Farquhar, G., Al{-}Shedivat, M., Rockt{\"{a}}schel, T., Xing,
  E.~P., and Whiteson, S.
\newblock Dice: The infinitely differentiable monte carlo estimator.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, volume~80 of \emph{Proceedings of Machine Learning Research}, pp.\
   1524--1533, 2018{\natexlab{b}}.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget{-}Abadie, Mirza, Xu,
  Warde{-}Farley, Ozair, Courville, and Bengio]{goodfellow2014gans}
Goodfellow, I.~J., Pouget{-}Abadie, J., Mirza, M., Xu, B., Warde{-}Farley, D.,
  Ozair, S., Courville, A.~C., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~27, pp.\  2672--2680, 2014.

\bibitem[Güth et~al.(1982)Güth, Schmittberger, and
  Schwarze]{guth_experimental_1982}
Güth, W., Schmittberger, R., and Schwarze, B.
\newblock An experimental analysis of ultimatum bargaining.
\newblock \emph{Journal of Economic Behavior \& Organization}, 3\penalty0
  (4):\penalty0 367--388, 1982.

\bibitem[Harper et~al.(2017)Harper, Knight, Jones, Koutsovoulos, Glynatsi, and
  Campbell]{Harper_2017}
Harper, M., Knight, V., Jones, M., Koutsovoulos, G., Glynatsi, N.~E., and
  Campbell, O.
\newblock Reinforcement learning produces dominant strategies for the iterated
  prisoner’s dilemma.
\newblock \emph{PLOS ONE}, 12\penalty0 (12):\penalty0 e0188046, 2017.

\bibitem[He \& Boyd{-}Graber(2016)He and Boyd{-}Graber]{he2016opponent}
He, H. and Boyd{-}Graber, J.~L.
\newblock Opponent modeling in deep reinforcement learning.
\newblock In \emph{Proceedings of the 33nd International Conference on Machine
  Learning}, volume~48 of \emph{{JMLR} Workshop and Conference Proceedings},
  pp.\  1804--1813, 2016.

\bibitem[Henrich et~al.(2006)Henrich, Boyd, Bowles, Camerer, Fehr, and
  Gintis]{henrich_foundations_2006}
Henrich, J., Boyd, R., Bowles, S., Camerer, C., Fehr, E., and Gintis, H.
\newblock Foundations of {Human} {Sociality}: {Economic} {Experiments} and
  {Ethnographic} {Evidence} {From} {Fifteen} {Small}-{Scale} {Societies}.
\newblock In \emph{American {Anthropologist}}, volume 108. 2006.

\bibitem[Hutter(2021)]{hutter2020learning}
Hutter, A.
\newblock Learning in two-player games between transparent opponents.
\newblock arXiv preprint arXiv:2012.02671, 2021.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma2017adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: {A} method for stochastic optimization.
\newblock In \emph{3rd International Conference on Learning Representations},
  2015.

\bibitem[Korpelevich(1977)]{eg_original}
Korpelevich, G.~M.
\newblock The extragradient method for finding saddle points and other
  problems.
\newblock volume~13, pp.\  35--49, 1977.

\bibitem[Lee \& K(1967)Lee and K]{lee_application_1967}
Lee, K. and K, L.
\newblock \emph{The {Application} of {Decision} {Theory} and {Dynamic}
  {Programming} to {Adaptive} {Control} {Systems}}.
\newblock Thesis, 1967.

\bibitem[Letcher(2018)]{letcher2018thesis}
Letcher, A.
\newblock Stability and exploitation in differentiable games.
\newblock Master's thesis, University of Oxford, 2018.

\bibitem[Letcher et~al.(2019{\natexlab{a}})Letcher, Balduzzi, Racani{\`{e}}re,
  Martens, Foerster, Tuyls, and Graepel]{letcher_differentiable_2019}
Letcher, A., Balduzzi, D., Racani{\`{e}}re, S., Martens, J., Foerster, J.~N.,
  Tuyls, K., and Graepel, T.
\newblock Differentiable game mechanics.
\newblock \emph{J. Mach. Learn. Res.}, 20:\penalty0 84:1--84:40,
  2019{\natexlab{a}}.

\bibitem[Letcher et~al.(2019{\natexlab{b}})Letcher, Foerster, Balduzzi,
  Rockt{\"{a}}schel, and Whiteson]{letcher_stable_2019}
Letcher, A., Foerster, J.~N., Balduzzi, D., Rockt{\"{a}}schel, T., and
  Whiteson, S.
\newblock Stable opponent shaping in differentiable games.
\newblock In \emph{7th International Conference on Learning Representations},
  2019{\natexlab{b}}.

\bibitem[Lu et~al.(2022)Lu, Willi, Schroeder~de Witt, and Foerster]{lu2022mfos}
Lu, C., Willi, T., Schroeder~de Witt, C., and Foerster, J.
\newblock Model-free opponent shaping.
\newblock \emph{arXiv preprint arXiv:2205.01447}, 2022.

\bibitem[Mazumdar et~al.(2019)Mazumdar, Jordan, and
  Sastry]{mazumdar_finding_2019}
Mazumdar, E.~V., Jordan, M.~I., and Sastry, S.~S.
\newblock On finding local nash equilibria (and only local nash equilibria) in
  zero-sum games.
\newblock arXiv preprint arXiv:1901.00838, 2019.

\bibitem[Mealing \& Shapiro(2017)Mealing and Shapiro]{mealing2017opponent}
Mealing, R. and Shapiro, J.~L.
\newblock Opponent modeling by expectation-maximization and sequence prediction
  in simplified poker.
\newblock \emph{{IEEE} Trans. Comput. Intell. {AI} Games}, 9\penalty0
  (1):\penalty0 11--24, 2017.

\bibitem[Mescheder et~al.(2017)Mescheder, Nowozin, and
  Geiger]{mescheder_numerics_2018}
Mescheder, L.~M., Nowozin, S., and Geiger, A.
\newblock The numerics of gans.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~30, pp.\  1825--1835, 2017.

\bibitem[Oosterbeek et~al.(2004)Oosterbeek, Sloof, and van~de
  Kuilen]{oosterbeek_cultural_2004}
Oosterbeek, H., Sloof, R., and van~de Kuilen, G.
\newblock Cultural {Differences} in {Ultimatum} {Game} {Experiments}:
  {Evidence} from a {Meta}-{Analysis}.
\newblock \emph{Experimental Economics}, 7\penalty0 (2):\penalty0 171--188,
  2004.

\bibitem[Oroojlooyjadid \& Hajinezhad(2019)Oroojlooyjadid and
  Hajinezhad]{oroojlooyjadid2019review}
Oroojlooyjadid, A. and Hajinezhad, D.
\newblock A review of cooperative multi-agent deep reinforcement learning.
\newblock 2019.

\bibitem[Osborne \& Rubinstein(1994)Osborne and
  Rubinstein]{osborne_gametheory_1994}
Osborne, M.~J. and Rubinstein, A.
\newblock \emph{A Course in Game Theory}.
\newblock The MIT Press, Cambridge, MA, 1994.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{pytorch2019}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E.,
  DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L.,
  Bai, J., and Chintala, S.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, pp.\  8024--8035. 2019.

\bibitem[Racani{\`{e}}re et~al.(2017)Racani{\`{e}}re, Weber, Reichert, Buesing,
  Guez, Rezende, Badia, Vinyals, Heess, Li, Pascanu, Battaglia, Hassabis,
  Silver, and Wierstra]{racaniere2017imagination}
Racani{\`{e}}re, S., Weber, T., Reichert, D.~P., Buesing, L., Guez, A.,
  Rezende, D.~J., Badia, A.~P., Vinyals, O., Heess, N., Li, Y., Pascanu, R.,
  Battaglia, P.~W., Hassabis, D., Silver, D., and Wierstra, D.
\newblock Imagination-augmented agents for deep reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~30, pp.\  5690--5701, 2017.

\bibitem[Sanfey et~al.(2003)Sanfey, Rilling, Aronson, Nystrom, and
  Cohen]{sanfey_neural_2003}
Sanfey, A.~G., Rilling, J.~K., Aronson, J.~A., Nystrom, L.~E., and Cohen, J.~D.
\newblock The {Neural} {Basis} of {Economic} {Decision}-{Making} in the
  {Ultimatum} {Game}.
\newblock \emph{Science}, 300\penalty0 (5626):\penalty0 1755--1758, 2003.

\bibitem[Sch{\"{a}}fer \& Anandkumar(2019)Sch{\"{a}}fer and
  Anandkumar]{schafer_competitive_2020}
Sch{\"{a}}fer, F. and Anandkumar, A.
\newblock Competitive gradient descent.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, pp.\  7623--7633, 2019.

\bibitem[Schmidhuber(1991)]{Schmidhuber:90sab}
Schmidhuber, J.
\newblock A possibility for implementing curiosity and boredom in
  model-building neural controllers.
\newblock In Meyer, J.~A. and Wilson, S.~W. (eds.), \emph{Proc. of the
  International Conference on Simulation of Adaptive Behavior: From Animals to
  Animats}, pp.\  222--227. MIT Press/Bradford Books, 1991.

\bibitem[Schäfer et~al.(2020)Schäfer, Anandkumar, and
  Owhadi]{schafer2020competitive}
Schäfer, F., Anandkumar, A., and Owhadi, H.
\newblock Competitive mirror descent.
\newblock arXiv preprint arXiv:2006.10179, 2020.

\bibitem[Silver et~al.(2017)Silver, Schrittwieser, Simonyan, Antonoglou, Huang,
  Guez, Hubert, Baker, Lai, Bolton, Chen, Lillicrap, Hui, Sifre, van~den
  Driessche, Graepel, and Hassabis]{silver2017go}
Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez,
  A., Hubert, T., Baker, L., Lai, M., Bolton, A., Chen, Y., Lillicrap, T.~P.,
  Hui, F., Sifre, L., van~den Driessche, G., Graepel, T., and Hassabis, D.
\newblock Mastering the game of go without human knowledge.
\newblock \emph{Nat.}, 550\penalty0 (7676):\penalty0 354--359, 2017.

\bibitem[Synnaeve \& Bessi{\`{e}}re(2011)Synnaeve and
  Bessi{\`{e}}re]{synnaeve2011bayesian}
Synnaeve, G. and Bessi{\`{e}}re, P.
\newblock A bayesian model for opening prediction in {RTS} games with
  application to starcraft.
\newblock In \emph{{IEEE} Conference on Computational Intelligence and Games},
  pp.\  281--288, 2011.

\bibitem[Vinyals et~al.(2019)Vinyals, Babuschkin, Czarnecki, Mathieu, Dudzik,
  Chung, Choi, Powell, Ewalds, Georgiev, Oh, Horgan, Kroiss, Danihelka, Huang,
  Sifre, Cai, Agapiou, Jaderberg, Vezhnevets, Leblond, Pohlen, Dalibard,
  Budden, Sulsky, Molloy, Paine, G{\"{u}}l{\c{c}}ehre, Wang, Pfaff, Wu, Ring,
  Yogatama, W{\"{u}}nsch, McKinney, Smith, Schaul, Lillicrap, Kavukcuoglu,
  Hassabis, Apps, and Silver]{vinyals2019alphastar}
Vinyals, O., Babuschkin, I., Czarnecki, W.~M., Mathieu, M., Dudzik, A., Chung,
  J., Choi, D.~H., Powell, R., Ewalds, T., Georgiev, P., Oh, J., Horgan, D.,
  Kroiss, M., Danihelka, I., Huang, A., Sifre, L., Cai, T., Agapiou, J.~P.,
  Jaderberg, M., Vezhnevets, A.~S., Leblond, R., Pohlen, T., Dalibard, V.,
  Budden, D., Sulsky, Y., Molloy, J., Paine, T.~L., G{\"{u}}l{\c{c}}ehre,
  {\c{C}}., Wang, Z., Pfaff, T., Wu, Y., Ring, R., Yogatama, D., W{\"{u}}nsch,
  D., McKinney, K., Smith, O., Schaul, T., Lillicrap, T.~P., Kavukcuoglu, K.,
  Hassabis, D., Apps, C., and Silver, D.
\newblock Grandmaster level in starcraft {II} using multi-agent reinforcement
  learning.
\newblock \emph{Nat.}, 575\penalty0 (7782):\penalty0 350--354, 2019.

\bibitem[Weber \& Mateas(2009)Weber and Mateas]{weber2009datamining}
Weber, B.~G. and Mateas, M.
\newblock A data mining approach to strategy prediction.
\newblock In \emph{Proceedings of the 2009 {IEEE} Symposium on Computational
  Intelligence and Games}, pp.\  140--147, 2009.

\bibitem[Wen et~al.(2019)Wen, Yang, Luo, Wang, and Pan]{wen2019probabilistic}
Wen, Y., Yang, Y., Luo, R., Wang, J., and Pan, W.
\newblock Probabilistic recursive reasoning for multi-agent reinforcement
  learning.
\newblock In \emph{7th International Conference on Learning Representations},
  2019.

\bibitem[Zhang \& Lesser(2010)Zhang and Lesser]{Zha}
Zhang, C. and Lesser, V.~R.
\newblock Multi-agent learning with policy prediction.
\newblock In \emph{Proceedings of the Twenty-Fourth {AAAI} Conference on
  Artificial Intelligence}, 2010.

\end{thebibliography}
