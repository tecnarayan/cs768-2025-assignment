\begin{thebibliography}{28}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Blanchard et~al.(2017{\natexlab{a}})Blanchard, Mhamdi, Guerraoui, and
  Stainer]{blanchard17}
Peva Blanchard, El~Mahdi~El Mhamdi, Rachid Guerraoui, and Julien Stainer.
\newblock Machine learning with adversaries: Byzantine tolerant gradient
  descent.
\newblock In \emph{Advances in Neural Information Processing Systems 30: Annual
  Conference on Neural Information Processing Systems 2017, 4-9 December 2017,
  Long Beach, CA, {USA}}, pages 118--128, 2017{\natexlab{a}}.
\newblock URL
  \url{http://papers.nips.cc/paper/6617-machine-learning-with-adversaries-byzantine-tolerant-gradient-descent}.

\bibitem[Chen et~al.(2017)Chen, Su, and Xu]{chen2017distributed}
Yudong Chen, Lili Su, and Jiaming Xu.
\newblock Distributed statistical machine learning in adversarial settings:
  Byzantine gradient descent.
\newblock \emph{Proceedings of the ACM on Measurement and Analysis of Computing
  Systems}, 1\penalty0 (2):\penalty0 44, 2017.

\bibitem[Xie et~al.(2018{\natexlab{a}})Xie, Koyejo, and Gupta]{xie18}
Cong Xie, Oluwasanmi Koyejo, and Indranil Gupta.
\newblock Generalized byzantine-tolerant sgd.
\newblock \emph{arXiv preprint arXiv:1802.10116}, 2018{\natexlab{a}}.

\bibitem[Damaskinos et~al.(2019{\natexlab{a}})Damaskinos, El~Mhamdi, Guerraoui,
  and Guirguis]{Damaskinos2019aggregathor}
Georgios Damaskinos, El~Mahdi El~Mhamdi, Rachid Guerraoui, and Sebastien
  Guirguis, Arsany~Rouault.
\newblock Aggregathor: Byzantine machine learning via robust gradient
  aggregation.
\newblock \emph{Conference on Systems and Machine Learning},
  2019{\natexlab{a}}.

\bibitem[Yin et~al.(2018{\natexlab{a}})Yin, Chen, Ramchandran, and
  Bartlett]{DBLP:journals/corr/abs-1806-05358}
Dong Yin, Yudong Chen, Kannan Ramchandran, and Peter Bartlett.
\newblock Defending against saddle point attack in byzantine-robust distributed
  learning.
\newblock \emph{CoRR}, abs/1806.05358, 2018{\natexlab{a}}.
\newblock URL \url{http://arxiv.org/abs/1806.05358}.

\bibitem[Yin et~al.(2018{\natexlab{b}})Yin, Chen, Ramchandran, and
  Bartlett]{yin2018byzantine}
Dong Yin, Yudong Chen, Kannan Ramchandran, and Peter Bartlett.
\newblock Byzantine-robust distributed learning: Towards optimal statistical
  rates.
\newblock In \emph{International Conference on Machine Learning}, pages
  5636--5645, 2018{\natexlab{b}}.

\bibitem[Chen et~al.(2018)Chen, Wang, Charles, and
  Papailiopoulos]{chen2018draco}
Lingjiao Chen, Hongyi Wang, Zachary Charles, and Dimitris Papailiopoulos.
\newblock Draco: Byzantine-resilient distributed training via redundant
  gradients.
\newblock In \emph{International Conference on Machine Learning}, pages
  902--911, 2018.

\bibitem[Data et~al.(2018)Data, Song, and Diggavi]{data2018data}
Deepesh Data, Linqi Song, and Suhas Diggavi.
\newblock Data encoding for byzantine-resilient distributed gradient descent.
\newblock In \emph{2018 56th Annual Allerton Conference on Communication,
  Control, and Computing (Allerton)}, pages 863--870. IEEE, 2018.

\bibitem[Yu et~al.(2018)Yu, Raviv, So, and Avestimehr]{yu2018lagrange}
Qian Yu, Netanel Raviv, Jinhyun So, and A~Salman Avestimehr.
\newblock Lagrange coded computing: Optimal design for resiliency, security and
  privacy.
\newblock \emph{arXiv preprint arXiv:1806.00939}, 2018.

\bibitem[Mhamdi et~al.(2018)Mhamdi, Guerraoui, and Rouault]{mhamdi2018hidden}
El~Mahdi~El Mhamdi, Rachid Guerraoui, and S{\'e}bastien Rouault.
\newblock The hidden vulnerability of distributed learning in byzantium.
\newblock \emph{arXiv preprint arXiv:1802.07927}, 2018.

\bibitem[Baruch et~al.(2019)Baruch, Baruch, and Goldberg]{baruch2019little}
Moran Baruch, Gilad Baruch, and Yoav Goldberg.
\newblock A little is enough: Circumventing defenses for distributed learning.
\newblock \emph{arXiv preprint arXiv:1902.06156}, 2019.

\bibitem[Lamport et~al.(1982)Lamport, Shostak, and Pease]{lamport1982byzantine}
Leslie Lamport, Robert Shostak, and Marshall Pease.
\newblock The byzantine generals problem.
\newblock \emph{ACM Transactions on Programming Languages and Systems
  (TOPLAS)}, 4\penalty0 (3):\penalty0 382--401, 1982.

\bibitem[El-Mhamdi et~al.(2019)El-Mhamdi, Guerraoui, Guirguis, and
  Rouault]{el2019sgd}
El-Mahdi El-Mhamdi, Rachid Guerraoui, Arsany Guirguis, and Sebastien Rouault.
\newblock Sgd: Decentralized byzantine resilience.
\newblock \emph{arXiv preprint arXiv:1905.03853}, 2019.

\bibitem[Xie et~al.(2018{\natexlab{b}})Xie, Koyejo, and Gupta]{xie2018zeno}
Cong Xie, Oluwasanmi Koyejo, and Indranil Gupta.
\newblock Zeno: Byzantine-suspicious stochastic gradient descent.
\newblock \emph{arXiv preprint arXiv:1805.10032}, 2018{\natexlab{b}}.

\bibitem[Xie et~al.(2019)Xie, Koyejo, and Gupta]{xie2019fall}
Cong Xie, Sanmi Koyejo, and Indranil Gupta.
\newblock Fall of empires: Breaking byzantine-tolerant sgd by inner product
  manipulation.
\newblock \emph{arXiv preprint arXiv:1903.03936}, 2019.

\bibitem[El-Mhamdi and Guerraoui(2019)]{el2019fast}
El-Mahdi El-Mhamdi and Rachid Guerraoui.
\newblock Fast and secure distributed learning in high dimension.
\newblock \emph{arXiv preprint arXiv:1905.04374}, 2019.

\bibitem[Blanchard et~al.(2017{\natexlab{b}})Blanchard, Guerraoui, Stainer,
  et~al.]{blanchard2017machine}
Peva Blanchard, Rachid Guerraoui, Julien Stainer, et~al.
\newblock Machine learning with adversaries: Byzantine tolerant gradient
  descent.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  119--129, 2017{\natexlab{b}}.

\bibitem[Alistarh et~al.(2018)Alistarh, Allen-Zhu, and Li]{NIPS2018_7712}
Dan Alistarh, Zeyuan Allen-Zhu, and Jerry Li.
\newblock Byzantine stochastic gradient descent.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, \emph{Advances in Neural Information Processing
  Systems 31}, pages 4618--4628. Curran Associates, Inc., 2018.
\newblock URL
  \url{http://papers.nips.cc/paper/7712-byzantine-stochastic-gradient-descent.pdf}.

\bibitem[Bernstein et~al.(2018)Bernstein, Zhao, Azizzadenesheli, and
  Anandkumar]{bernstein2018signsgd}
Jeremy Bernstein, Jiawei Zhao, Kamyar Azizzadenesheli, and Anima Anandkumar.
\newblock signsgd with majority vote is communication efficient and fault
  tolerant.
\newblock \emph{arXiv}, 2018.

\bibitem[Minsker et~al.(2015)]{minsker2015geometric}
Stanislav Minsker et~al.
\newblock Geometric median and robust estimation in banach spaces.
\newblock \emph{Bernoulli}, 21\penalty0 (4):\penalty0 2308--2335, 2015.

\bibitem[Lugosi et~al.(2019)Lugosi, Mendelson, et~al.]{lugosi2019sub}
G{\'a}bor Lugosi, Shahar Mendelson, et~al.
\newblock Sub-gaussian estimators of the mean of a random vector.
\newblock \emph{The Annals of Statistics}, 47\penalty0 (2):\penalty0 783--794,
  2019.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem[Dalcin et~al.(2011)Dalcin, Paz, Kler, and Cosimo]{MPI4PY}
Lisandro~D Dalcin, Rodrigo~R Paz, Pablo~A Kler, and Alejandro Cosimo.
\newblock Parallel distributed computing using python.
\newblock \emph{Advances in Water Resources}, 34\penalty0 (9):\penalty0
  1124--1139, 2011.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Simonyan and Zisserman(2014)]{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Linial and Luria(2014)]{linial14}
Nathan Linial and Zur Luria.
\newblock Chernoff's inequality-a very elementary proof.
\newblock \emph{arXiv preprint arXiv:1403.7739}, 2014.

\bibitem[C.~Pelekis(2017)]{pelekis17}
J.~Ramon C.~Pelekis.
\newblock Hoeffdingâ€™s inequality for sums of weakly dependent random
  variables.
\newblock \emph{Mediterranean Journal of Mathematics}, 2017.

\bibitem[Damaskinos et~al.(2019{\natexlab{b}})Damaskinos, Mhamdi, Guerraoui,
  Guirguis, and Rouault]{aggregathor2019}
Georgios Damaskinos, El~Mahdi~El Mhamdi, Rachid Guerraoui, Arsany Guirguis, and
  S{\`e}bastien Rouault.
\newblock Aggregathor: Byzantine machine learning via robust gradient
  aggregation.
\newblock In \emph{SysML}, 2019{\natexlab{b}}.

\end{thebibliography}
