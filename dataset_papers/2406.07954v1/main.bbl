\begin{thebibliography}{26}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdelnabi et~al.(2024)Abdelnabi, Fay, Cherubin, Salem, Fritz, and Paverd]{abdelnabi2024track}
Sahar Abdelnabi, Aideen Fay, Giovanni Cherubin, Ahmed Salem, Mario Fritz, and Andrew Paverd.
\newblock Are you still on track!? {Catching} {LLM} task drift with activations.
\newblock \emph{arXiv preprint arXiv:2406.00799}, 2024.

\bibitem[Akhtar et~al.(2024)Akhtar, Benjelloun, Conforti, Gijsbers, Giner-Miguelez, Jain, Kuchnik, Lhoest, Marcenac, Maskey, Mattson, Oala, Ruyssen, Shinde, Simperl, Thomas, Tykhonov, Vanschoren, van~der Velde, Vogler, and Wu]{akhtar2024croissant}
Mubashara Akhtar, Omar Benjelloun, Costanza Conforti, Pieter Gijsbers, Joan Giner-Miguelez, Nitisha Jain, Michael Kuchnik, Quentin Lhoest, Pierre Marcenac, Manil Maskey, Peter Mattson, Luis Oala, Pierre Ruyssen, Rajat Shinde, Elena Simperl, Goeffry Thomas, Slava Tykhonov, Joaquin Vanschoren, Jos van~der Velde, Steffen Vogler, and Carole-Jean Wu.
\newblock Croissant: A metadata format for ml-ready datasets.
\newblock In \emph{Proceedings of the Eighth Workshop on Data Management for End-to-End Machine Learning}, SIGMOD/PODS ’24. ACM, June 2024.
\newblock \doi{10.1145/3650203.3663326}.
\newblock URL \url{http://dx.doi.org/10.1145/3650203.3663326}.

\bibitem[Andriushchenko et~al.(2024)Andriushchenko, Croce, and Flammarion]{andriushchenko2024jailbreaking}
Maksym Andriushchenko, Francesco Croce, and Nicolas Flammarion.
\newblock Jailbreaking leading safety-aligned {LLM}s with simple adaptive attacks.
\newblock \emph{arXiv preprint arXiv:2404.02151}, 2024.

\bibitem[Anil et~al.(2024)Anil, Durmus, Sharma, Benton, Kundu, Batson, Rimsky, Tong, Mu, Ford, et~al.]{anil2024many}
Cem Anil, Esin Durmus, Mrinank Sharma, Joe Benton, Sandipan Kundu, Joshua Batson, Nina Rimsky, Meg Tong, Jesse Mu, Daniel Ford, et~al.
\newblock Many-shot jailbreaking, 2024.

\bibitem[Anwar et~al.(2024)Anwar, Saparov, Rando, Paleka, Turpin, Hase, Lubana, Jenner, Casper, Sourbut, et~al.]{anwar2024foundational}
Usman Anwar, Abulhair Saparov, Javier Rando, Daniel Paleka, Miles Turpin, Peter Hase, Ekdeep~Singh Lubana, Erik Jenner, Stephen Casper, Oliver Sourbut, et~al.
\newblock Foundational challenges in assuring alignment and safety of large language models.
\newblock \emph{arXiv preprint arXiv:2404.09932}, 2024.

\bibitem[Branch et~al.(2022)Branch, Cefalu, McHugh, Hujer, Bahl, Iglesias, Heichman, and Darwishi]{branch2022evaluating}
Hezekiah~J Branch, Jonathan~Rodriguez Cefalu, Jeremy McHugh, Leyla Hujer, Aditya Bahl, Daniel del~Castillo Iglesias, Ron Heichman, and Ramesh Darwishi.
\newblock Evaluating the susceptibility of pre-trained language models via handcrafted adversarial examples.
\newblock \emph{arXiv preprint arXiv:2209.02128}, 2022.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{carlini2017adversarial}
Nicholas Carlini and David Wagner.
\newblock Adversarial examples are not easily detected: Bypassing ten detection methods.
\newblock In \emph{Proceedings of the 10th ACM workshop on artificial intelligence and security}, pp.\  3--14, 2017.

\bibitem[{Center for AI Safety}(2023)]{noauthor_trojan_nodate}
{Center for AI Safety}.
\newblock The trojan detection challenge 2023 {(LLM} edition), 2023.
\newblock URL \url{https://trojandetection.ai/}.

\bibitem[Debenedetti et~al.(2023)Debenedetti, Severi, Carlini, Choquette-Choo, Jagielski, Nasr, Wallace, and Tram{\`e}r]{debenedetti2023privacy}
Edoardo Debenedetti, Giorgio Severi, Nicholas Carlini, Christopher~A Choquette-Choo, Matthew Jagielski, Milad Nasr, Eric Wallace, and Florian Tram{\`e}r.
\newblock Privacy side channels in machine learning systems.
\newblock \emph{arXiv preprint arXiv:2309.05610}, 2023.

\bibitem[Evertz et~al.(2024)Evertz, Chlosta, Sch{\"o}nherr, and Eisenhofer]{evertz-24-whisper}
Jonathan Evertz, Merlin Chlosta, Lea Sch{\"o}nherr, and Thorsten Eisenhofer.
\newblock Whispers in the machine: Confidentiality in {LLM}-integrated systems.
\newblock \emph{arXiv preprint arXiv:2402.06922}, 2024.

\bibitem[Glukhov et~al.(2024)Glukhov, Shumailov, Gal, Papernot, and Papyan]{glukhov2023llm}
David Glukhov, Ilia Shumailov, Yarin Gal, Nicolas Papernot, and Vardan Papyan.
\newblock Position paper: Rethinking {LLM} censorship as a security problem.
\newblock In \emph{ICML}, 2024.

\bibitem[Greshake et~al.(2023)Greshake, Abdelnabi, Mishra, Endres, Holz, and Fritz]{greshake2023not}
Kai Greshake, Sahar Abdelnabi, Shailesh Mishra, Christoph Endres, Thorsten Holz, and Mario Fritz.
\newblock Not what you've signed up for: Compromising real-world {LLM}-integrated applications with indirect prompt injection.
\newblock In \emph{Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security}, pp.\  79--90, 2023.

\bibitem[Hendrycks et~al.(2020)Hendrycks, Burns, Basart, Zou, Mazeika, Song, and Steinhardt]{hendrycks2020measuring}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding.
\newblock \emph{arXiv preprint arXiv:2009.03300}, 2020.

\bibitem[{Lakera AI}(2023)]{gandalf_ignore_instructions}
{Lakera AI}.
\newblock Gandalf ignore instructions, 2023.
\newblock URL \url{https://huggingface.co/datasets/Lakera/gandalf_ignore_instructions}.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Deng, Li, Wang, Zhang, Liu, Wang, Zheng, and Liu]{liu-24-promptinjection}
Yi~Liu, Gelei Deng, Yuekang Li, Kailong Wang, Tianwei Zhang, Yepang Liu, Haoyu Wang, Yan Zheng, and Yang Liu.
\newblock Prompt injection attack against {LLM}-integrated applications.
\newblock \emph{arXiv preprint arXiv:2306.05499}, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Deng, Xu, Li, Zheng, Zhang, Zhao, Zhang, Wang, and Liu]{liu-24-jailbreaking}
Yi~Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng, Ying Zhang, Lida Zhao, Tianwei Zhang, Kailong Wang, and Yang Liu.
\newblock Jailbreaking chatgpt via prompt engineering: An empirical study.
\newblock \emph{arXiv preprint arXiv:2305.13860}, 2023{\natexlab{b}}.

\bibitem[Liu et~al.(2023{\natexlab{c}})Liu, Jia, Geng, Jia, and Gong]{liu-23-promptinjection}
Yupei Liu, Yuqi Jia, Runpeng Geng, Jinyuan Jia, and Neil~Zhenqiang Gong.
\newblock Formalizing and benchmarking prompt injection attacks and defenses.
\newblock \emph{arXiv preprint arXiv:2310.12815}, 2023{\natexlab{c}}.

\bibitem[Perez \& Ribeiro(2022)Perez and Ribeiro]{perez2022ignore}
F{\'a}bio Perez and Ian Ribeiro.
\newblock Ignore previous prompt: Attack techniques for language models.
\newblock \emph{arXiv preprint arXiv:2211.09527}, 2022.

\bibitem[Pushkarna et~al.(2022)Pushkarna, Zaldivar, and Kjartansson]{pushkarna2022datacards}
Mahima Pushkarna, Andrew Zaldivar, and Oddur Kjartansson.
\newblock Data cards: Purposeful and transparent dataset documentation for responsible ai.
\newblock In \emph{2022 ACM Conference on Fairness, Accountability, and Transparency}, FAccT ’22. ACM, June 2022.
\newblock \doi{10.1145/3531146.3533231}.

\bibitem[Rando et~al.(2024)Rando, Croce, Mitka, Shabalin, Andriushchenko, Flammarion, and Tram{\`e}r]{rando2024competition}
Javier Rando, Francesco Croce, Kry{\v{s}}tof Mitka, Stepan Shabalin, Maksym Andriushchenko, Nicolas Flammarion, and Florian Tram{\`e}r.
\newblock Competition report: Finding universal jailbreak backdoors in aligned {LLM}s.
\newblock \emph{arXiv preprint arXiv:2404.14461}, 2024.

\bibitem[Russinovich et~al.(2024)Russinovich, Salem, and Eldan]{russinovich2024great}
Mark Russinovich, Ahmed Salem, and Ronen Eldan.
\newblock Great, now write an article about that: The crescendo multi-turn {LLM} jailbreak attack.
\newblock \emph{arXiv preprint arXiv:2404.01833}, 2024.

\bibitem[Sawada et~al.(2023)Sawada, Paleka, Havrilla, Tadepalli, Vidas, Kranias, Nay, Gupta, and Komatsuzaki]{sawada2023arb}
Tomohiro Sawada, Daniel Paleka, Alexander Havrilla, Pranav Tadepalli, Paula Vidas, Alexander Kranias, John~J Nay, Kshitij Gupta, and Aran Komatsuzaki.
\newblock {ARB}: Advanced reasoning benchmark for large language models.
\newblock \emph{arXiv preprint arXiv:2307.13692}, 2023.

\bibitem[Schulhoff et~al.(2023)Schulhoff, Pinto, Khan, Bouchard, Si, Anati, Tagliabue, Kost, Carnahan, and Boyd-Graber]{schulhoff-etal-2023-ignore}
Sander Schulhoff, Jeremy Pinto, Anaum Khan, Louis-Fran{\c{c}}ois Bouchard, Chenglei Si, Svetlina Anati, Valen Tagliabue, Anson Kost, Christopher Carnahan, and Jordan Boyd-Graber.
\newblock Ignore this title and {H}ack{AP}rompt: Exposing systemic vulnerabilities of {LLM}s through a global prompt hacking competition.
\newblock In \emph{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pp.\  4945--4977. Association for Computational Linguistics, 2023.
\newblock \doi{10.18653/v1/2023.emnlp-main.302}.

\bibitem[Toyer et~al.(2023)Toyer, Watkins, Mendes, Svegliato, Bailey, Wang, Ong, Elmaaroufi, Abbeel, Darrell, et~al.]{toyer2023tensor}
Sam Toyer, Olivia Watkins, Ethan~Adrian Mendes, Justin Svegliato, Luke Bailey, Tiffany Wang, Isaac Ong, Karim Elmaaroufi, Pieter Abbeel, Trevor Darrell, et~al.
\newblock Tensor trust: Interpretable prompt injection attacks from an online game.
\newblock \emph{arXiv preprint arXiv:2311.01011}, 2023.

\bibitem[Tramer et~al.(2020)Tramer, Carlini, Brendel, and Madry]{tramer2020adaptive}
Florian Tramer, Nicholas Carlini, Wieland Brendel, and Aleksander Madry.
\newblock On adaptive attacks to adversarial example defenses.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Wallace et~al.(2024)Wallace, Xiao, Leike, Weng, Heidecke, and Beutel]{wallace2024instruction}
Eric Wallace, Kai Xiao, Reimar Leike, Lilian Weng, Johannes Heidecke, and Alex Beutel.
\newblock The instruction hierarchy: Training {LLM}s to prioritize privileged instructions.
\newblock \emph{arXiv preprint arXiv:2404.13208}, 2024.

\end{thebibliography}
