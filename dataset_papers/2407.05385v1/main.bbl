\begin{thebibliography}{34}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ainsworth et~al.(2023)Ainsworth, Hayase, and Srinivasa]{ainsworth2023_git-rebasin}
Ainsworth, S., Hayase, J., and Srinivasa, S.
\newblock Git re-basin: Merging models modulo permutation symmetries.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=CQsmMYmlP5T}.

\bibitem[Arpit et~al.(2017)Arpit, Jastrzebski, Ballas, Krueger, Bengio, Kanwal, Maharaj, Fischer, Courville, Bengio, and Lacoste-Julien]{arpit2017_memorization}
Arpit, D., Jastrzebski, S., Ballas, N., Krueger, D., Bengio, E., Kanwal, M.~S., Maharaj, T., Fischer, A., Courville, A., Bengio, Y., and Lacoste-Julien, S.
\newblock A closer look at memorization in deep networks.
\newblock In Precup, D. and Teh, Y.~W. (eds.), \emph{Proceedings of the 34th International Conference on Machine Learning}, volume~70 of \emph{Proceedings of Machine Learning Research}, pp.\  233--242. PMLR, 06--11 Aug 2017.
\newblock URL \url{https://proceedings.mlr.press/v70/arpit17a.html}.

\bibitem[De~Bie et~al.(2005)De~Bie, Cristianini, and Rosipal]{DeBie2005}
De~Bie, T., Cristianini, N., and Rosipal, R.
\newblock \emph{Eigenproblems in Pattern Recognition}, pp.\  129--167.
\newblock Springer Berlin Heidelberg, Berlin, Heidelberg, 2005.
\newblock ISBN 978-3-540-28247-1.
\newblock \doi{10.1007/3-540-28247-5_5}.
\newblock URL \url{https://doi.org/10.1007/3-540-28247-5_5}.

\bibitem[Draxler et~al.(2018)Draxler, Veschgini, Salmhofer, and Hamprecht]{draxler2018_no-barriers}
Draxler, F., Veschgini, K., Salmhofer, M., and Hamprecht, F.
\newblock Essentially no barriers in neural network energy landscape.
\newblock In Dy, J. and Krause, A. (eds.), \emph{Proceedings of the 35th International Conference on Machine Learning}, volume~80 of \emph{Proceedings of Machine Learning Research}, pp.\  1309--1318. PMLR, 10--15 Jul 2018.
\newblock URL \url{https://proceedings.mlr.press/v80/draxler18a.html}.

\bibitem[Entezari et~al.(2022)Entezari, Sedghi, Saukh, and Neyshabur]{entezari2022_perm-invariance-lmc}
Entezari, R., Sedghi, H., Saukh, O., and Neyshabur, B.
\newblock The role of permutation invariance in linear mode connectivity of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=dNigytemkL}.

\bibitem[Frankle et~al.(2020)Frankle, Dziugaite, Roy, and Carbin]{pmlr-v119-frankle20a_lmc_lth}
Frankle, J., Dziugaite, G.~K., Roy, D., and Carbin, M.
\newblock Linear mode connectivity and the lottery ticket hypothesis.
\newblock In III, H.~D. and Singh, A. (eds.), \emph{Proceedings of the 37th International Conference on Machine Learning}, volume 119 of \emph{Proceedings of Machine Learning Research}, pp.\  3259--3269. PMLR, 13--18 Jul 2020.
\newblock URL \url{https://proceedings.mlr.press/v119/frankle20a.html}.

\bibitem[Freeman \& Bruna(2017)Freeman and Bruna]{freeman2017topology}
Freeman, C.~D. and Bruna, J.
\newblock Topology and geometry of half-rectified network optimization.
\newblock In \emph{International Conference on Learning Representations}, 2017.
\newblock URL \url{https://openreview.net/forum?id=Bk0FWVcgx}.

\bibitem[Garipov et~al.(2018)Garipov, Izmailov, Podoprikhin, Vetrov, and Wilson]{garipov2018_fge}
Garipov, T., Izmailov, P., Podoprikhin, D., Vetrov, D.~P., and Wilson, A.~G.
\newblock Loss surfaces, mode connectivity, and fast ensembling of dnns.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~31. Curran Associates, Inc., 2018.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2018/file/be3087e74e9100d4bc4c6268cdbe8456-Paper.pdf}.

\bibitem[Goodfellow \& Vinyals(2015)Goodfellow and Vinyals]{goodfellow2015_qualitatively}
Goodfellow, I.~J. and Vinyals, O.
\newblock Qualitatively characterizing neural network optimization problems.
\newblock In Bengio, Y. and LeCun, Y. (eds.), \emph{The third International Conference on Learning Representations}, 2015.
\newblock URL \url{http://arxiv.org/abs/1412.6544}.

\bibitem[Gotmare et~al.(2019)Gotmare, Keskar, Xiong, and Socher]{gotmare2018a}
Gotmare, A., Keskar, N.~S., Xiong, C., and Socher, R.
\newblock A closer look at deep learning heuristics: Learning rate restarts, warmup and distillation.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=r14EOsCqKX}.

\bibitem[Ho(1995)]{ho1995random}
Ho, T.~K.
\newblock Random decision forests.
\newblock In \emph{Proceedings of 3rd international conference on document analysis and recognition}, volume~1, pp.\  278--282. IEEE, 1995.

\bibitem[Horoi et~al.(2022)Horoi, Huang, Rieck, Lajoie, Wolf, and Krishnaswamy]{horoi2022_exploring}
Horoi, S., Huang, J., Rieck, B., Lajoie, G., Wolf, G., and Krishnaswamy, S.
\newblock Exploring the geometry and topology of neural network loss landscapes.
\newblock In Bouadi, T., Fromont, E., and H{\"u}llermeier, E. (eds.), \emph{Advances in Intelligent Data Analysis XX}, pp.\  171--184, Cham, 2022. Springer International Publishing.
\newblock ISBN 978-3-031-01333-1.

\bibitem[Ilharco et~al.(2023)Ilharco, Ribeiro, Wortsman, Schmidt, Hajishirzi, and Farhadi]{ilharco2023_task-arithmetic}
Ilharco, G., Ribeiro, M.~T., Wortsman, M., Schmidt, L., Hajishirzi, H., and Farhadi, A.
\newblock Editing models with task arithmetic.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=6t0Kwf8-jrj}.

\bibitem[Izmailov et~al.(2018)Izmailov, Podoprikhin, Garipov, Vetrov, and Wilson]{izmailov2018_averaging}
Izmailov, P., Podoprikhin, D., Garipov, T., Vetrov, D., and Wilson, A.~G.
\newblock Averaging weights leads to wider optima and better generalization.
\newblock In Globerson, A. and Silva, R. (eds.), \emph{Uncertainty in Artificial Intelligence}, volume~34. AUAI Press, 2018.
\newblock URL \url{http://auai.org/uai2018/proceedings/papers/313.pdf}.

\bibitem[Jolicoeur-Martineau et~al.(2024)Jolicoeur-Martineau, Gervais, FATRAS, Zhang, and Lacoste-Julien]{jolicoeurmartineau2023_papa}
Jolicoeur-Martineau, A., Gervais, E., FATRAS, K., Zhang, Y., and Lacoste-Julien, S.
\newblock Population parameter averaging ({PAPA}).
\newblock \emph{Transactions on Machine Learning Research}, 2024.
\newblock ISSN 2835-8856.
\newblock URL \url{https://openreview.net/forum?id=cPDVjsOytS}.

\bibitem[Jordan et~al.(2023)Jordan, Sedghi, Saukh, Entezari, and Neyshabur]{jordan2023repair}
Jordan, K., Sedghi, H., Saukh, O., Entezari, R., and Neyshabur, B.
\newblock {REPAIR}: {RE}normalizing permuted activations for interpolation repair.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=gU5sJ6ZggcX}.

\bibitem[Keskar et~al.(2017)Keskar, Mudigere, Nocedal, Smelyanskiy, and Tang]{keskar2017large_batch}
Keskar, N.~S., Mudigere, D., Nocedal, J., Smelyanskiy, M., and Tang, P. T.~P.
\newblock On large-batch training for deep learning: Generalization gap and sharp minima.
\newblock In \emph{5th International Conference on Learning Representations~(ICLR)}, 2017.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and Hinton]{krizhevsky2009_cifar}
Krizhevsky, A. and Hinton, G.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical Report~0, University of Toronto, Toronto, Ontario, 2009.
\newblock URL \url{https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf}.

\bibitem[Li et~al.(2018)Li, Xu, Taylor, Studer, and Goldstein]{Goldstein_LL_NIPS2018_7875}
Li, H., Xu, Z., Taylor, G., Studer, C., and Goldstein, T.
\newblock Visualizing the loss landscape of neural nets.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, volume~31, pp.\  6389--6399. Curran Associates, Inc., 2018.

\bibitem[Li et~al.(2015)Li, Yosinski, Clune, Lipson, and Hopcroft]{li2015_convergent}
Li, Y., Yosinski, J., Clune, J., Lipson, H., and Hopcroft, J.
\newblock Convergent learning: Do different neural networks learn the same representations?
\newblock In Storcheus, D., Rostamizadeh, A., and Kumar, S. (eds.), \emph{Proceedings of the 1st International Workshop on Feature Extraction: Modern Questions and Challenges at NIPS 2015}, volume~44 of \emph{Proceedings of Machine Learning Research}, pp.\  196--212, Montreal, Canada, 11 Dec 2015. PMLR.
\newblock URL \url{https://proceedings.mlr.press/v44/li15convergent.html}.

\bibitem[Lobacheva et~al.(2020)Lobacheva, Chirkova, Kodryan, and Vetrov]{lobacheva2020power}
Lobacheva, E., Chirkova, N., Kodryan, M., and Vetrov, D.~P.
\newblock On power laws in deep ensembles.
\newblock \emph{Advances In Neural Information Processing Systems}, 33:\penalty0 2375--2385, 2020.

\bibitem[McMahan et~al.(2017)McMahan, Moore, Ramage, Hampson, and Arcas]{mcmahan17_fedavg}
McMahan, B., Moore, E., Ramage, D., Hampson, S., and Arcas, B. A.~y.
\newblock {Communication-Efficient Learning of Deep Networks from Decentralized Data}.
\newblock In Singh, A. and Zhu, J. (eds.), \emph{Proceedings of the 20th International Conference on Artificial Intelligence and Statistics}, volume~54 of \emph{Proceedings of Machine Learning Research}, pp.\  1273--1282. PMLR, 20--22 Apr 2017.
\newblock URL \url{https://proceedings.mlr.press/v54/mcmahan17a.html}.

\bibitem[Morcos et~al.(2018)Morcos, Raghu, and Bengio]{morcos2018_insights}
Morcos, A., Raghu, M., and Bengio, S.
\newblock Insights on representational similarity in neural networks with canonical correlation.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~31. Curran Associates, Inc., 2018.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2018/file/a7a3d70c6d17a73140918996d03c014f-Paper.pdf}.

\bibitem[Pe\~na et~al.(2023)Pe\~na, Medeiros, Dubail, Aminbeidokhti, Granger, and Pedersoli]{pena2023_sinkhorn-rebasin}
Pe\~na, F. A.~G., Medeiros, H.~R., Dubail, T., Aminbeidokhti, M., Granger, E., and Pedersoli, M.
\newblock Re-basin via implicit sinkhorn differentiation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  20237--20246, June 2023.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, Krueger, and Sutskever]{radford2021_clip}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., Krueger, G., and Sutskever, I.
\newblock Learning transferable visual models from natural language supervision.
\newblock In Meila, M. and Zhang, T. (eds.), \emph{Proceedings of the 38th International Conference on Machine Learning}, volume 139 of \emph{Proceedings of Machine Learning Research}, pp.\  8748--8763. PMLR, 18--24 Jul 2021.
\newblock URL \url{https://proceedings.mlr.press/v139/radford21a.html}.

\bibitem[Raghu et~al.(2017)Raghu, Gilmer, Yosinski, and Sohl-Dickstein]{raghu2017_svcca}
Raghu, M., Gilmer, J., Yosinski, J., and Sohl-Dickstein, J.
\newblock Svcca: Singular vector canonical correlation analysis for deep learning dynamics and interpretability.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R., Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2017/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf}.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma, Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{russakovsky2015_imagenet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.~C., and Fei-Fei, L.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock \emph{International Journal of Computer Vision (IJCV)}, 115\penalty0 (3):\penalty0 211--252, 2015.
\newblock \doi{10.1007/s11263-015-0816-y}.

\bibitem[Sharma et~al.(2024)Sharma, Kwok, Denton, Roy, Rolnick, and Dziugaite]{sharma2024simultaneous}
Sharma, E., Kwok, D., Denton, T., Roy, D.~M., Rolnick, D., and Dziugaite, G.~K.
\newblock Simultaneous linear connectivity of neural networks modulo permutation, 2024.
\newblock URL \url{https://arxiv.org/abs/2404.06498}.

\bibitem[Simonyan \& Zisserman(2015)Simonyan and Zisserman]{simonyan2015a_vgg}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In \emph{the 3rd International Conference on Learning Representations (ICLR 2015)}, pp.\  1--14, 2015.

\bibitem[Singh \& Jaggi(2020)Singh and Jaggi]{singh-jaggi2020_OT-fusion}
Singh, S.~P. and Jaggi, M.
\newblock Model fusion via optimal transport.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~33, pp.\  22045--22055. Curran Associates, Inc., 2020.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2020/file/fb2697869f56484404c8ceee2985b01d-Paper.pdf}.

\bibitem[Stoica et~al.(2024)Stoica, Bolya, Bjorner, Ramesh, Hearn, and Hoffman]{stoica2024zipit}
Stoica, G., Bolya, D., Bjorner, J.~B., Ramesh, P., Hearn, T., and Hoffman, J.
\newblock Zipit! merging models from different tasks without training.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=LEYUkvdUhq}.

\bibitem[Tatro et~al.(2020)Tatro, Chen, Das, Melnyk, Sattigeri, and Lai]{tatro2020_opt-mode_con}
Tatro, N., Chen, P.-Y., Das, P., Melnyk, I., Sattigeri, P., and Lai, R.
\newblock Optimizing mode connectivity via neuron alignment.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~33, pp.\  15300--15311. Curran Associates, Inc., 2020.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2020/file/aecad42329922dfc97eee948606e1f8e-Paper.pdf}.

\bibitem[Wortsman et~al.(2022)Wortsman, Ilharco, Gadre, Roelofs, Gontijo-Lopes, Morcos, Namkoong, Farhadi, Carmon, Kornblith, and Schmidt]{wortsman22_modelsoups}
Wortsman, M., Ilharco, G., Gadre, S.~Y., Roelofs, R., Gontijo-Lopes, R., Morcos, A.~S., Namkoong, H., Farhadi, A., Carmon, Y., Kornblith, S., and Schmidt, L.
\newblock Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time.
\newblock In Chaudhuri, K., Jegelka, S., Song, L., Szepesvari, C., Niu, G., and Sabato, S. (eds.), \emph{Proceedings of the 39th International Conference on Machine Learning}, volume 162 of \emph{Proceedings of Machine Learning Research}, pp.\  23965--23998. PMLR, 17--23 Jul 2022.
\newblock URL \url{https://proceedings.mlr.press/v162/wortsman22a.html}.

\bibitem[Yadav et~al.(2023)Yadav, Tam, Choshen, Raffel, and Bansal]{yadav2023tiesmerging}
Yadav, P., Tam, D., Choshen, L., Raffel, C., and Bansal, M.
\newblock {TIES}-merging: Resolving interference when merging models.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=xtaX3WyCj1}.

\end{thebibliography}
