\begin{thebibliography}{62}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anwar et~al.(2017)Anwar, Hwang, and Sung]{Anwar2017Structured}
Anwar, S., Hwang, K., and Sung, W.
\newblock Structured pruning of deep convolutional neural networks.
\newblock \emph{Proc. of the J. Emerg. Technol. Comput. Syst.}, 13\penalty0
  (3), February 2017.
\newblock ISSN 1550-4832.

\bibitem[Boyd et~al.(2011)Boyd, Parikh, Chu, Peleato, and
  Eckstein]{Boyd2011ADMM}
Boyd, S., Parikh, N., Chu, E., Peleato, B., and Eckstein, J.
\newblock Distributed optimization and statistical learning via the alternating
  direction method of multipliers.
\newblock \emph{Found. Trends Mach. Learn.}, 3\penalty0 (1):\penalty0 1–122,
  January 2011.
\newblock ISSN 1935-8237.

\bibitem[Chatzianastasis et~al.(2021)Chatzianastasis, Dasoulas, Siolas, and
  Vazirgiannis]{chatzianastasis2021graph}
Chatzianastasis, M., Dasoulas, G., Siolas, G., and Vazirgiannis, M.
\newblock Graph-based neural architecture search with operation embeddings.
\newblock In \emph{Proc. of the IEEE/CVF International Conference on Computer
  Vision (CVPR)}, pp.\  393--402, 2021.

\bibitem[Chen et~al.(2020)Chen, Chen, and Pan]{chen2020storage}
Chen, J., Chen, S., and Pan, S.~J.
\newblock Storage efficient and dynamic flexible runtime channel pruning via
  deep reinforcement learning.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.~F., and Lin,
  H. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  14747--14758. Curran Associates, Inc., 2020.

\bibitem[Chen et~al.(2021)Chen, Ji, Ding, Fang, Wang, Zhu, Liang, Shi, Yi, and
  Tu]{chen2021oto}
Chen, T., Ji, B., Ding, T., Fang, B., Wang, G., Zhu, Z., Liang, L., Shi, Y.,
  Yi, S., and Tu, X.
\newblock Only train once: A one-shot neural network training and pruning
  framework.
\newblock In Ranzato, M., Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan,
  J.~W. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~34, pp.\  19637--19651. Curran Associates, Inc., 2021.

\bibitem[Chin et~al.(2020)Chin, Ding, Zhang, and Marculescu]{chin2020legr}
Chin, T.-W., Ding, R., Zhang, C., and Marculescu, D.
\newblock Towards efficient model compression via learned global ranking.
\newblock In \emph{Proc. of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2020.

\bibitem[Dudziak et~al.(2021)Dudziak, Chau, Abdelfattah, Lee, Kim, and
  Lane]{Dudziak2021BPR_NAS}
Dudziak, L., Chau, T., Abdelfattah, M.~S., Lee, R., Kim, H., and Lane, N.~D.
\newblock {BRP-NAS}: Prediction-based {NAS} using gcns, 2021.

\bibitem[Gao et~al.(2021)Gao, Huang, Cai, and Huang]{gao_network_2021}
Gao, S., Huang, F., Cai, W., and Huang, H.
\newblock Network {Pruning} via {Performance} {Maximization}.
\newblock In \emph{Proc. of the {IEEE}/{CVF} {Conference} on {Computer}
  {Vision} and {Pattern} {Recognition} ({CVPR})}, pp.\  9270--9280, June 2021.

\bibitem[Gholami et~al.(2021)Gholami, Kim, Dong, Yao, Mahoney, and
  Keutzer]{gholami2021survey_quantization}
Gholami, A., Kim, S., Dong, Z., Yao, Z., Mahoney, M.~W., and Keutzer, K.
\newblock A survey of quantization methods for efficient neural network
  inference, 2021.

\bibitem[Gilmer et~al.(2017)Gilmer, Schoenholz, Riley, Vinyals, and
  Dahl]{gilmer2017neural}
Gilmer, J., Schoenholz, S.~S., Riley, P.~F., Vinyals, O., and Dahl, G.~E.
\newblock Neural message passing for quantum chemistry.
\newblock In \emph{Proc. of International conference on machine learning}, pp.\
   1263--1272. PMLR, 2017.

\bibitem[Guo et~al.(2020)Guo, Wang, Li, and Yan]{guo2020dmcp}
Guo, S., Wang, Y., Li, Q., and Yan, J.
\newblock Dmcp: Differentiable markov channel pruning for neural networks.
\newblock In \emph{Proc. of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2020.

\bibitem[Guo et~al.(2016)Guo, Yao, and Chen]{Guo2016unstructured}
Guo, Y., Yao, A., and Chen, Y.
\newblock Dynamic network surgery for efficient dnns.
\newblock In Lee, D., Sugiyama, M., Luxburg, U., Guyon, I., and Garnett, R.
  (eds.), \emph{Proc. of the Advances in Neural Information Processing
  Systems}, volume~29, pp.\  1379--1387. Curran Associates, Inc., 2016.

\bibitem[Guo et~al.(2019)Guo, Zheng, Tan, Chen, Chen, Zhao, and
  Huang]{Guo2019NAS_NAT}
Guo, Y., Zheng, Y., Tan, M., Chen, Q., Chen, J., Zhao, P., and Huang, J.
\newblock {NAT}: Neural architecture transformer for accurate and compact
  architectures.
\newblock In \emph{Proc. of the Advances in Neural Information Processing
  Systems}, volume~32, pp.\  737--748. Curran Associates, Inc., 2019.

\bibitem[Han et~al.(2016)Han, Mao, and Dally]{han2015deep}
Han, S., Mao, H., and Dally, W.~J.
\newblock Deep compression: Compressing deep neural networks with pruning,
  trained quantization and huffman coding.
\newblock In \emph{Proc. of International Conference on Learning
  Representations (ICLR)}, 2016.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016ResNet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proc. of the IEEE conference on computer vision and pattern
  recognition}, pp.\  770--778, 2016.

\bibitem[He et~al.(2017)He, Zhang, and Sun]{he2017handcraft_channel}
He, Y., Zhang, X., and Sun, J.
\newblock Channel pruning for accelerating very deep neural networks.
\newblock In \emph{Proc. of the IEEE International Conference on Computer
  Vision}, pp.\  1389--1397, 2017.

\bibitem[He et~al.(2018{\natexlab{a}})He, Kang, Dong, Fu, and Yang]{he2018sfp}
He, Y., Kang, G., Dong, X., Fu, Y., and Yang, Y.
\newblock Soft filter pruning for accelerating deep convolutional neural
  networks.
\newblock In \emph{International Joint Conference on Artificial Intelligence
  (IJCAI)}, pp.\  2234--2240, 2018{\natexlab{a}}.

\bibitem[He et~al.(2018{\natexlab{b}})He, Lin, Liu, Wang, Li, and
  Han]{he2018amc}
He, Y., Lin, J., Liu, Z., Wang, H., Li, L.-J., and Han, S.
\newblock {AMC}: {AutoML} for model compression and acceleration on mobile
  devices.
\newblock In \emph{Proc. of the European Conference on Computer Vision (ECCV)},
  pp.\  784--800, 2018{\natexlab{b}}.

\bibitem[He et~al.(2019)He, Liu, Wang, Hu, and Yang]{he2019FPGM}
He, Y., Liu, P., Wang, Z., Hu, Z., and Yang, Y.
\newblock Filter pruning via geometric median for deep convolutional neural
  networks acceleration.
\newblock In \emph{Proc. of the IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2019.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, and Dean]{hinton2015distilling}
Hinton, G., Vinyals, O., and Dean, J.
\newblock Distilling the knowledge in a neural network.
\newblock In \emph{Proc. of NIPS Deep Learning and Representation Learning
  Workshop}, 2015.

\bibitem[Howard et~al.(2019)Howard, Sandler, Chu, Chen, Chen, Tan, Wang, Zhu,
  Pang, Vasudevan, et~al.]{howard2019searching}
Howard, A., Sandler, M., Chu, G., Chen, L.-C., Chen, B., Tan, M., Wang, W.,
  Zhu, Y., Pang, R., Vasudevan, V., et~al.
\newblock Searching for mobilenetv3.
\newblock In \emph{Proc. of the IEEE/CVF International Conference on Computer
  Vision}, pp.\  1314--1324, 2019.

\bibitem[Huang et~al.(2018)Huang, Liu, Van~der Maaten, and
  Weinberger]{huang2018condensenet}
Huang, G., Liu, S., Van~der Maaten, L., and Weinberger, K.~Q.
\newblock Condensenet: An efficient densenet using learned group convolutions.
\newblock In \emph{Proc. of the IEEE conference on computer vision and pattern
  recognition}, pp.\  2752--2761, 2018.

\bibitem[Jian-Hao~Luo(2020)]{luo2020AutoPruner}
Jian-Hao~Luo, J.~W.
\newblock Autopruner: An end-to-end trainable filter pruning method for
  efficient deep model inference.
\newblock \emph{Pattern Recognition}, 2020.

\bibitem[Kipf \& Welling(2017)Kipf and Welling]{kipf2017gcn}
Kipf, T.~N. and Welling, M.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock In \emph{Proc. of the International Conference on Learning
  Representations (ICLR)}, 2017.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and Hinton]{Krizhevsky2009Cifar}
Krizhevsky, A. and Hinton, G.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Lai et~al.(2021)Lai, Zhang, Liu, Chang, Liao, Chuang, Qian, Khurana,
  Cox, and Glass]{lai2021parp}
Lai, C.-I.~J., Zhang, Y., Liu, A.~H., Chang, S., Liao, Y.-L., Chuang, Y.-S.,
  Qian, K., Khurana, S., Cox, D., and Glass, J.
\newblock Parp: Prune, adjust and re-prune for self-supervised speech
  recognition.
\newblock In Ranzato, M., Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan,
  J.~W. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~34, pp.\  21256--21272. Curran Associates, Inc., 2021.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Wu, Su, and Wang]{li2020eagleeye}
Li, B., Wu, B., Su, J., and Wang, G.
\newblock Eagleeye: Fast sub-net evaluation for efficient neural network
  pruning.
\newblock In Vedaldi, A., Bischof, H., Brox, T., and Frahm, J.-M. (eds.),
  \emph{Proc. of the Computer Vision -- ECCV 2020}, pp.\  639--654, Cham,
  2020{\natexlab{a}}. Springer International Publishing.
\newblock ISBN 978-3-030-58536-5.

\bibitem[Li et~al.(2016)Li, Kadav, Durdanovic, Samet, and
  Graf]{Li2016handcraft}
Li, H., Kadav, A., Durdanovic, I., Samet, H., and Graf, H.~P.
\newblock Pruning filters for efficient convnets, 2016.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Gu, Mayer, Gool, and
  Timofte]{li2020group}
Li, Y., Gu, S., Mayer, C., Gool, L.~V., and Timofte, R.
\newblock Group sparsity: The hinge between filter pruning and decomposition
  for network compression.
\newblock In \emph{Proc. of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pp.\  8018--8027, 2020{\natexlab{b}}.

\bibitem[Li et~al.(2020{\natexlab{c}})Li, Gu, Zhang, Van~Gool, and
  Timofte]{li2020dhp}
Li, Y., Gu, S., Zhang, K., Van~Gool, L., and Timofte, R.
\newblock {DHP}: Differentiable meta pruning via hypernetworks,
  2020{\natexlab{c}}.

\bibitem[Li et~al.(2021{\natexlab{a}})Li, Hao, Li, Xiong, and
  Chen]{li2021gnasr}
Li, Y., Hao, C., Li, P., Xiong, J., and Chen, D.
\newblock Generic neural architecture search via regression.
\newblock In Ranzato, M., Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan,
  J.~W. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~34, pp.\  20476--20490. Curran Associates, Inc., 2021{\natexlab{a}}.

\bibitem[Li et~al.(2021{\natexlab{b}})Li, Yuan, Niu, Zhao, Li, Cai, Shen, Zhan,
  Kong, Jin, et~al.]{li2021npas}
Li, Z., Yuan, G., Niu, W., Zhao, P., Li, Y., Cai, Y., Shen, X., Zhan, Z., Kong,
  Z., Jin, Q., et~al.
\newblock Npas: A compiler-aware framework of unified network pruning and
  architecture search for beyond real-time mobile acceleration.
\newblock In \emph{Proc. of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp.\  14255--14266, 2021{\natexlab{b}}.

\bibitem[Liben-Nowell \& Kleinberg(2007)Liben-Nowell and
  Kleinberg]{Nowell2007linkprediction}
Liben-Nowell, D. and Kleinberg, J.
\newblock The link-prediction problem for social networks.
\newblock \emph{Journal of the American Society for Information Science and
  Technology}, 58\penalty0 (7):\penalty0 1019--1031, 2007.

\bibitem[Liebenwein et~al.(2020)Liebenwein, Baykal, Lang, Feldman, and
  Rus]{liebenwein2020pfp}
Liebenwein, L., Baykal, C., Lang, H., Feldman, D., and Rus, D.
\newblock Provable filter pruning for efficient neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Lillicrap et~al.(2016)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap2016ddpg}
Lillicrap, T.~P., Hunt, J.~J., Pritzel, A., Heess, N., Erez, T., Tassa, Y.,
  Silver, D., and Wierstra, D.
\newblock Continuous control with deep reinforcement learning.
\newblock In \emph{Proc. of the ICLR (Poster)}, 2016.

\bibitem[Lin et~al.(2017)Lin, Rao, Lu, and Zhou]{Lin2017RNP}
Lin, J., Rao, Y., Lu, J., and Zhou, J.
\newblock Runtime neural pruning.
\newblock In \emph{Proc. of the Advances in Neural Information Processing
  Systems}, pp.\  2181--2191, 2017.

\bibitem[Lin et~al.(2020)Lin, Ji, Wang, Zhang, Zhang, Tian, and
  Shao]{lin2020hrank}
Lin, M., Ji, R., Wang, Y., Zhang, Y., Zhang, B., Tian, Y., and Shao, L.
\newblock Hrank: Filter pruning using high-rank feature map.
\newblock In \emph{Proc. of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pp.\  1529--1538, 2020.

\bibitem[Liu et~al.(2020)Liu, Ma, Xu, Wang, Tang, and Ye]{liu2020AutoCompress}
Liu, N., Ma, X., Xu, Z., Wang, Y., Tang, J., and Ye, J.
\newblock {AutoCompress}: An automatic dnn structured pruning framework for
  ultra-high compression rates.
\newblock In \emph{Proc. of the Artificial Intelligence Conference (AAAI)},
  pp.\  4876--4883, 2020.

\bibitem[Liu et~al.(2021)Liu, Liu, Lin, Dong, and Wang]{liu_learnable_2021}
Liu, Y., Liu, L., Lin, C., Dong, Z., and Wang, W.
\newblock Learnable {Motion} {Coherence} for {Correspondence} {Pruning}.
\newblock In \emph{Proc. of the {IEEE}/{CVF} {Conference} on {Computer}
  {Vision} and {Pattern} {Recognition} ({CVPR})}, pp.\  3237--3246, June 2021.

\bibitem[Liu et~al.(2019)Liu, Mu, Zhang, Guo, Yang, Cheng, and
  Sun]{liu2019metapruning}
Liu, Z., Mu, H., Zhang, X., Guo, Z., Yang, X., Cheng, K.-T., and Sun, J.
\newblock Metapruning: Meta learning for automatic neural network channel
  pruning.
\newblock In \emph{Proc. of the IEEE International Conference on Computer
  Vision}, pp.\  3296--3305, 2019.

\bibitem[Ma et~al.(2018)Ma, Zhang, Zheng, and Sun]{ma2018shufflenetv2}
Ma, N., Zhang, X., Zheng, H.-T., and Sun, J.
\newblock Shufflenet v2: Practical guidelines for efficient cnn architecture
  design.
\newblock In \emph{Proc. of the European conference on computer vision (ECCV)},
  pp.\  116--131, 2018.

\bibitem[Mehta et~al.(2020)Mehta, Hajishirzi, and Rastegari]{mehta2020dicenet}
Mehta, S., Hajishirzi, H., and Rastegari, M.
\newblock Dicenet: Dimension-wise convolutions for efficient networks.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2020.

\bibitem[Ning et~al.(2020{\natexlab{a}})Ning, Zhao, Li, Lei, Wang, and
  Yang]{ning2020dsa}
Ning, X., Zhao, T., Li, W., Lei, P., Wang, Y., and Yang, H.
\newblock {DSA}: More efficient budgeted pruning via differentiable sparsity
  allocation.
\newblock In \emph{Proc. of 16th European Computer Vision Conference}, pp.\
  592--607. Springer, 2020{\natexlab{a}}.

\bibitem[Ning et~al.(2020{\natexlab{b}})Ning, Zheng, Zhao, Wang, and
  Yang]{ning2020generic}
Ning, X., Zheng, Y., Zhao, T., Wang, Y., and Yang, H.
\newblock A generic graph-based neural architecture encoding scheme for
  predictor-based nas.
\newblock In \emph{Proc. of European Conference on Computer Vision}, pp.\
  189--204. Springer, 2020{\natexlab{b}}.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{Olga2015ImageNet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., Berg, A.~C., and Fei-Fei, L.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock \emph{International Journal of Computer Vision (IJCV)}, 115\penalty0
  (3):\penalty0 211--252, 2015.
\newblock \doi{10.1007/s11263-015-0816-y}.

\bibitem[Schlichtkrull et~al.(2018)Schlichtkrull, Kipf, Bloem, van den Berg,
  Titov, and Welling]{Schlichtkrull2018rgcn}
Schlichtkrull, M., Kipf, T.~N., Bloem, P., van den Berg, R., Titov, I., and
  Welling, M.
\newblock Modeling relational data with graph convolutional networks.
\newblock In Gangemi, A., Navigli, R., Vidal, M.-E., Hitzler, P., Troncy, R.,
  Hollink, L., Tordai, A., and Alam, M. (eds.), \emph{The Semantic Web}, pp.\
  593--607, Cham, 2018. Springer International Publishing.
\newblock ISBN 978-3-319-93417-4.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017ppo}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms, 2017.

\bibitem[Shi et~al.(2019)Shi, Pi, Xu, Li, Kwok, and Zhang]{Han2020NAS_oneshot}
Shi, H., Pi, R., Xu, H., Li, Z., Kwok, J.~T., and Zhang, T.
\newblock Bridging the gap between sample-based and one-shot neural
  architecture search with {BONAS}, 2019.

\bibitem[Tan \& Le(2019)Tan and Le]{tan2019efficientnet}
Tan, M. and Le, Q.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In \emph{Proc. of the International Conference on Machine Learning},
  pp.\  6105--6114. PMLR, 2019.

\bibitem[Tang et~al.(2020)Tang, Wang, Xu, Tao, XU, Xu, and Xu]{tang2020scop}
Tang, Y., Wang, Y., Xu, Y., Tao, D., XU, C., Xu, C., and Xu, C.
\newblock Scop: Scientific control for reliable neural network pruning.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.~F., and Lin,
  H. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  10936--10947. Curran Associates, Inc., 2020.

\bibitem[Wang et~al.(2017)Wang, Zhang, Wang, and Hu]{wang2017SPP}
Wang, H., Zhang, Q., Wang, Y., and Hu, R.
\newblock Structured probabilistic pruning for deep convolutional neural
  network acceleration.
\newblock \emph{British Machine Vision Conference}, 2017.

\bibitem[Wang et~al.(2020)Wang, Wang, Cai, Lin, Liu, Wang, Lin, and
  Han]{wang2020apq}
Wang, T., Wang, K., Cai, H., Lin, J., Liu, Z., Wang, H., Lin, Y., and Han, S.
\newblock Apq: Joint search for network architecture, pruning and quantization
  policy.
\newblock In \emph{Proc. of IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  2075--2084, 2020.

\bibitem[Wang et~al.(2021)Wang, Li, and Wang]{Wang2021cov}
Wang, Z., Li, C., and Wang, X.
\newblock Convolutional neural network pruning with structural redundancy
  reduction.
\newblock In \emph{Proc. of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp.\  14913--14922, June 2021.

\bibitem[Yang et~al.(2018)Yang, Howard, Chen, Zhang, Go, Sandler, Sze, and
  Adam]{yang2018netadapt}
Yang, T.-J., Howard, A., Chen, B., Zhang, X., Go, A., Sandler, M., Sze, V., and
  Adam, H.
\newblock Netadapt: Platform-aware neural network adaptation for mobile
  applications.
\newblock In \emph{The European Conference on Computer Vision (ECCV)},
  September 2018.

\bibitem[Yao et~al.(2021)Yao, Pi, Xu, Zhang, Li, and
  Zhang]{Yao2021JointDetNASUY}
Yao, L., Pi, R., Xu, H., Zhang, W., Li, Z., and Zhang, T.
\newblock Joint-detnas: Upgrade your detector with nas, pruning and dynamic
  distillation.
\newblock In \emph{Proc. of IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  10170--10179, 2021.

\bibitem[Ye et~al.(2020)Ye, Gong, Nie, Zhou, Klivans, and
  Liu]{ye2020goodsubnet}
Ye, M., Gong, C., Nie, L., Zhou, D., Klivans, A., and Liu, Q.
\newblock Good subnetworks provably exist: Pruning via greedy forward
  selection.
\newblock In III, H.~D. and Singh, A. (eds.), \emph{Proc. of the 37th
  International Conference on Machine Learning}, volume 119 of \emph{Proc. of
  Machine Learning Research}, pp.\  10820--10830. PMLR, 13--18 Jul 2020.

\bibitem[Ying et~al.(2018)Ying, You, Morris, Ren, Hamilton, and
  Leskovec]{Ying2018DiffPool}
Ying, R., You, J., Morris, C., Ren, X., Hamilton, W.~L., and Leskovec, J.
\newblock Hierarchical graph representation learning with differentiable
  pooling.
\newblock In \emph{Proc. of the 32nd International Conference on Neural
  Information Processing Systems}, NIPS'18, pp.\  4805–4815, Red Hook, NY,
  USA, 2018. Curran Associates Inc.

\bibitem[Yu \& Huang(2019)Yu and Huang]{yu2019autoslim}
Yu, J. and Huang, T.
\newblock Autoslim: Towards one-shot architecture search for channel numbers,
  2019.

\bibitem[Yu et~al.(2021)Yu, Mazaheri, and Jannesari]{yu2020agmc}
Yu, S., Mazaheri, A., and Jannesari, A.
\newblock Auto graph encoder-decoder for neural network pruning.
\newblock In \emph{Proc. of the IEEE/CVF International Conference on Computer
  Vision (ICCV)}, pp.\  6362--6372, October 2021.

\bibitem[Zhang et~al.(2018{\natexlab{a}})Zhang, Ye, Zhang, Tang, Wen, Fardad,
  and Wang]{zhang2018unstructured}
Zhang, T., Ye, S., Zhang, K., Tang, J., Wen, W., Fardad, M., and Wang, Y.
\newblock A systematic {DNN} weight pruning framework using alternating
  direction method of multipliers.
\newblock \emph{ECCV}, 2018{\natexlab{a}}.

\bibitem[Zhang et~al.(2018{\natexlab{b}})Zhang, Zhou, Lin, and
  Sun]{zhang2018shufflenet}
Zhang, X., Zhou, X., Lin, M., and Sun, J.
\newblock Shufflenet: An extremely efficient convolutional neural network for
  mobile devices.
\newblock In \emph{Proc. of the IEEE conference on computer vision and pattern
  recognition}, pp.\  6848--6856, 2018{\natexlab{b}}.

\bibitem[Zhuang et~al.(2020)Zhuang, Zhang, Huang, Zeng, Shuang, and
  Li]{zhuang2020neuron}
Zhuang, T., Zhang, Z., Huang, Y., Zeng, X., Shuang, K., and Li, X.
\newblock Neuron-level structured pruning using polarization regularizer.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.~F., and Lin,
  H. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  9865--9877. Curran Associates, Inc., 2020.

\end{thebibliography}
