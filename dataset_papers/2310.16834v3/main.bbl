\begin{thebibliography}{57}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anderson(2012)]{anderson2012continuous}
Anderson, W.~J.
\newblock \emph{Continuous-time Markov chains: An applications-oriented approach}.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Austin et~al.(2021)Austin, Johnson, Ho, Tarlow, and van~den Berg]{Austin2021StructuredDD}
Austin, J., Johnson, D.~D., Ho, J., Tarlow, D., and van~den Berg, R.
\newblock Structured denoising diffusion models in discrete state-spaces.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Benton et~al.(2022)Benton, Shi, Bortoli, Deligiannidis, and Doucet]{Benton2022FromDD}
Benton, J., Shi, Y., Bortoli, V.~D., Deligiannidis, G., and Doucet, A.
\newblock From denoising diffusions to denoising markov models.
\newblock \emph{ArXiv}, abs/2211.03595, 2022.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:253384277}.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{Brown2020LanguageMA}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D.
\newblock Language models are few-shot learners.
\newblock In \emph{Advances in Neural Information Processing Systems}, volume~33, 2020.

\bibitem[Campbell et~al.(2022)Campbell, Benton, Bortoli, Rainforth, Deligiannidis, and Doucet]{Campbell2022ACT}
Campbell, A., Benton, J., Bortoli, V.~D., Rainforth, T., Deligiannidis, G., and Doucet, A.
\newblock A continuous time framework for discrete denoising models.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Chen \& Duvenaud(2019)Chen and Duvenaud]{Chen2019NeuralNW}
Chen, R. T.~Q. and Duvenaud, D.~K.
\newblock Neural networks with cheap differential operators.
\newblock In \emph{Neural Information Processing Systems}, 2019.

\bibitem[Chen et~al.(2022)Chen, Zhang, and Hinton]{chen2022analog}
Chen, T., Zhang, R., and Hinton, G.
\newblock Analog bits: Generating discrete data using diffusion models with self-conditioning.
\newblock \emph{arXiv preprint arXiv:2208.04202}, 2022.

\bibitem[Chen et~al.(2023)Chen, Yuan, Li, Kou, Zhang, and Gu]{chen2023fast}
Chen, Z., Yuan, H., Li, Y., Kou, Y., Zhang, J., and Gu, Q.
\newblock Fast sampling via de-randomization for discrete diffusion models.
\newblock \emph{arXiv preprint arXiv:2312.09193}, 2023.

\bibitem[Dao et~al.(2022)Dao, Fu, Ermon, Rudra, and R'e]{Dao2022FlashAttentionFA}
Dao, T., Fu, D.~Y., Ermon, S., Rudra, A., and R'e, C.
\newblock Flashattention: Fast and memory-efficient exact attention with io-awareness.
\newblock In \emph{Neural Information Processing Systems}, 2022.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{Devlin2019BERTPO}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language understanding.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)}. Association for Computational Linguistics, 2019.

\bibitem[Dieleman et~al.(2022)Dieleman, Sartran, Roshannai, Savinov, Ganin, Richemond, Doucet, Strudel, Dyer, Durkan, Hawthorne, Leblond, Grathwohl, and Adler]{Dieleman2022ContinuousDF}
Dieleman, S., Sartran, L., Roshannai, A., Savinov, N., Ganin, Y., Richemond, P.~H., Doucet, A., Strudel, R., Dyer, C., Durkan, C., Hawthorne, C., Leblond, R., Grathwohl, W., and Adler, J.
\newblock Continuous diffusion for categorical data.
\newblock \emph{ArXiv}, abs/2211.15089, 2022.

\bibitem[Efron(2011)]{Efron2011TweediesFA}
Efron, B.
\newblock Tweedie’s formula and selection bias.
\newblock \emph{Journal of the American Statistical Association}, 106:\penalty0 1602 -- 1614, 2011.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:23284154}.

\bibitem[Gillespie(2001)]{Gillespie2001ApproximateAS}
Gillespie, D.~T.
\newblock Approximate accelerated stochastic simulation of chemically reacting systems.
\newblock \emph{Journal of Chemical Physics}, 115:\penalty0 1716--1733, 2001.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:5109777}.

\bibitem[Gokaslan \& Cohen(2019)Gokaslan and Cohen]{Gokaslan2019OpenWeb}
Gokaslan, A. and Cohen, V.
\newblock Openwebtext corpus.
\newblock \url{http://Skylion007.github.io/OpenWebTextCorpus}, 2019.

\bibitem[Gong et~al.(2023)Gong, Li, Feng, Wu, and Kong]{gong2023diffuseq}
Gong, S., Li, M., Feng, J., Wu, Z., and Kong, L.
\newblock Diffuseq: Sequence to sequence text generation with diffusion models.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[Graves et~al.(2023)Graves, Srivastava, Atkinson, and Gomez]{graves2023bayesian}
Graves, A., Srivastava, R.~K., Atkinson, T., and Gomez, F.
\newblock Bayesian flow networks.
\newblock \emph{arXiv preprint arXiv:2308.07037}, 2023.

\bibitem[Gulrajani \& Hashimoto(2023)Gulrajani and Hashimoto]{Gulrajani2023LikelihoodBasedDL}
Gulrajani, I. and Hashimoto, T.
\newblock Likelihood-based diffusion language models.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2023.

\bibitem[Han et~al.(2022)Han, Kumar, and Tsvetkov]{han2022ssd}
Han, X., Kumar, S., and Tsvetkov, Y.
\newblock Ssd-lm: Semi-autoregressive simplex-based diffusion language model for text generation and modular control.
\newblock \emph{arXiv preprint arXiv:2210.17432}, 2022.

\bibitem[Hanson(2007)]{FloydASP}
Hanson, F.~B.
\newblock \emph{Applied Stochastic Processes and Control for Jump-Diffusions: Modeling, Analysis and Computation}.
\newblock Society for Industrial and Applied Mathematics, Philadelphia, PA, 2007.
\newblock \doi{10.1137/1.9780898718638}.
\newblock URL \url{https://epubs.siam.org/doi/abs/10.1137/1.9780898718638}.

\bibitem[He et~al.(2022)He, Sun, Wang, Huang, and Qiu]{He2022DiffusionBERTIG}
He, Z., Sun, T., Wang, K., Huang, X., and Qiu, X.
\newblock Diffusionbert: Improving generative masked language models with diffusion models.
\newblock In \emph{Annual Meeting of the Association for Computational Linguistics}, 2022.

\bibitem[Ho(2022)]{Ho2022ClassifierFreeDG}
Ho, J.
\newblock Classifier-free diffusion guidance.
\newblock \emph{ArXiv}, abs/2207.12598, 2022.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:249145348}.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{Ho2020DenoisingDP}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising diffusion probabilistic models.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Holtzman et~al.(2019)Holtzman, Buys, Du, Forbes, and Choi]{holtzman2019curious}
Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y.
\newblock The curious case of neural text degeneration.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Hoogeboom et~al.(2021)Hoogeboom, Nielsen, Jaini, Forr{\'e}, and Welling]{hoogeboom2021argmax}
Hoogeboom, E., Nielsen, D., Jaini, P., Forr{\'e}, P., and Welling, M.
\newblock Argmax flows and multinomial diffusion: Learning categorical distributions.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 12454--12465, 2021.

\bibitem[Hutchinson(1989)]{Hutchinson1989ASE}
Hutchinson, M.~F.
\newblock A stochastic estimator of the trace of the influence matrix for laplacian smoothing splines.
\newblock \emph{Communications in Statistics - Simulation and Computation}, 18:\penalty0 1059--1076, 1989.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:120969358}.

\bibitem[Hyv{\"a}rinen(2005)]{Hyvrinen2005EstimationON}
Hyv{\"a}rinen, A.
\newblock Estimation of non-normalized statistical models by score matching.
\newblock \emph{J. Mach. Learn. Res.}, 6:\penalty0 695--709, 2005.

\bibitem[Hyv{\"a}rinen(2007)]{Hyvrinen2007SomeEO}
Hyv{\"a}rinen, A.
\newblock Some extensions of score matching.
\newblock \emph{Comput. Stat. Data Anal.}, 51:\penalty0 2499--2512, 2007.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:2352990}.

\bibitem[Kelly(1980)]{Kelly1980ReversibilityAS}
Kelly, F.
\newblock Reversibility and stochastic networks.
\newblock 1980.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:125211322}.

\bibitem[Li et~al.(2022)Li, Thickstun, Gulrajani, Liang, and Hashimoto]{Li2022DiffusionLMIC}
Li, X., Thickstun, J., Gulrajani, I., Liang, P.~S., and Hashimoto, T.~B.
\newblock Diffusion-lm improves controllable text generation.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Lou \& Ermon(2023)Lou and Ermon]{lou2023reflected}
Lou, A. and Ermon, S.
\newblock Reflected diffusion models.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2023.

\bibitem[Mahabadi et~al.(2023)Mahabadi, Tae, Ivison, Henderson, Beltagy, Peters, and Cohan]{mahabadi2023tess}
Mahabadi, R.~K., Tae, J., Ivison, H., Henderson, J., Beltagy, I., Peters, M.~E., and Cohan, A.
\newblock Tess: Text-to-text self-conditioned simplex diffusion.
\newblock \emph{arXiv preprint arXiv:2305.08379}, 2023.

\bibitem[Meng et~al.(2021)Meng, He, Song, Song, Wu, Zhu, and Ermon]{Meng2021SDEditGI}
Meng, C., He, Y., Song, Y., Song, J., Wu, J., Zhu, J.-Y., and Ermon, S.
\newblock Sdedit: Guided image synthesis and editing with stochastic differential equations.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:245704504}.

\bibitem[Meng et~al.(2022)Meng, Choi, Song, and Ermon]{Meng2022ConcreteSM}
Meng, C., Choi, K., Song, J., and Ermon, S.
\newblock Concrete score matching: Generalized score matching for discrete data.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[{\O}ksendal(1987)]{ksendal1987StochasticDE}
{\O}ksendal, B.
\newblock Stochastic differential equations : an introduction with applications.
\newblock \emph{Journal of the American Statistical Association}, 82:\penalty0 948, 1987.

\bibitem[Peebles \& Xie(2023)Peebles and Xie]{Peebles2022ScalableDM}
Peebles, W.~S. and Xie, S.
\newblock Scalable diffusion models with transformers.
\newblock In \emph{International Conference on Computer Vision}, 2023.

\bibitem[Pillutla et~al.(2021)Pillutla, Swayamdipta, Zellers, Thickstun, Welleck, Choi, and Harchaoui]{pillutla2021mauve}
Pillutla, K., Swayamdipta, S., Zellers, R., Thickstun, J., Welleck, S., Choi, Y., and Harchaoui, Z.
\newblock Mauve: Measuring the gap between neural text and human text using divergence frontiers.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 4816--4828, 2021.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and Sutskever]{Radford2019LanguageMA}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:160025533}.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{Ramesh2022HierarchicalTI}
Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{ArXiv}, abs/2204.06125, 2022.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:248097655}.

\bibitem[Shih et~al.(2022)Shih, Sadigh, and Ermon]{shih2022training}
Shih, A., Sadigh, D., and Ermon, S.
\newblock Training and inference on any-order autoregressive models the right way.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 2762--2775, 2022.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and Ganguli]{SohlDickstein2015DeepUL}
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine Learning}, 2015.

\bibitem[Song et~al.(2021{\natexlab{a}})Song, Meng, and Ermon]{song2021denoising}
Song, J., Meng, C., and Ermon, S.
\newblock Denoising diffusion implicit models.
\newblock In \emph{International Conference on Learning Representations}, 2021{\natexlab{a}}.
\newblock URL \url{https://openreview.net/forum?id=St1giarCHLP}.

\bibitem[Song \& Ermon(2019)Song and Ermon]{Song2019GenerativeMB}
Song, Y. and Ermon, S.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock In \emph{Neural Information Processing Systems}, 2019.

\bibitem[Song et~al.(2019)Song, Garg, Shi, and Ermon]{Song2019SlicedSM}
Song, Y., Garg, S., Shi, J., and Ermon, S.
\newblock Sliced score matching: A scalable approach to density and score estimation.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, 2019.

\bibitem[Song et~al.(2021{\natexlab{b}})Song, Durkan, Murray, and Ermon]{Song2021MaximumLT}
Song, Y., Durkan, C., Murray, I., and Ermon, S.
\newblock Maximum likelihood training of score-based diffusion models.
\newblock In \emph{Neural Information Processing Systems}, 2021{\natexlab{b}}.

\bibitem[Song et~al.(2021{\natexlab{c}})Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and Poole]{Song2020ScoreBasedGM}
Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole, B.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock In \emph{International Conference on Learning Representations}, 2021{\natexlab{c}}.
\newblock URL \url{https://openreview.net/forum?id=PxTIG12RRHS}.

\bibitem[Strudel et~al.(2022)Strudel, Tallec, Altch{\'e}, Du, Ganin, Mensch, Grathwohl, Savinov, Dieleman, Sifre, et~al.]{strudel2022self}
Strudel, R., Tallec, C., Altch{\'e}, F., Du, Y., Ganin, Y., Mensch, A., Grathwohl, W.~S., Savinov, N., Dieleman, S., Sifre, L., et~al.
\newblock Self-conditioned embedding diffusion for text generation.
\newblock 2022.

\bibitem[Su et~al.(2021)Su, Lu, Pan, Wen, and Liu]{Su2021RoFormerET}
Su, J., Lu, Y., Pan, S., Wen, B., and Liu, Y.
\newblock Roformer: Enhanced transformer with rotary position embedding.
\newblock \emph{ArXiv}, abs/2104.09864, 2021.

\bibitem[Sun et~al.(2023)Sun, Yu, Dai, Schuurmans, and Dai]{Sun2022ScorebasedCD}
Sun, H., Yu, L., Dai, B., Schuurmans, D., and Dai, H.
\newblock Score-based continuous-time discrete diffusion models.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[Tran et~al.(2019)Tran, Vafa, Agrawal, Dinh, and Poole]{tran2019discrete}
Tran, D., Vafa, K., Agrawal, K., Dinh, L., and Poole, B.
\newblock Discrete flows: Invertible generative models of discrete data.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{Vaswani2017AttentionIA}
Vaswani, A., Shazeer, N.~M., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N., Kaiser, L., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{NIPS}, 2017.

\bibitem[Vincent(2011)]{Vincent2011ACB}
Vincent, P.
\newblock A connection between score matching and denoising autoencoders.
\newblock \emph{Neural Computation}, 23:\penalty0 1661--1674, 2011.

\bibitem[Wang \& Cho(2019)Wang and Cho]{wang2019bert}
Wang, A. and Cho, K.
\newblock Bert has a mouth, and it must speak: Bert as a markov random field language model.
\newblock \emph{arXiv preprint arXiv:1902.04094}, 2019.

\bibitem[Wolf et~al.(2020)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac, Rault, Louf, Funtowicz, Davison, Shleifer, von Platen, Ma, Jernite, Plu, Xu, Le~Scao, Gugger, Drame, Lhoest, and Rush]{wolf-etal-2020-transformers}
Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M., Davison, J., Shleifer, S., von Platen, P., Ma, C., Jernite, Y., Plu, J., Xu, C., Le~Scao, T., Gugger, S., Drame, M., Lhoest, Q., and Rush, A.
\newblock Transformers: State-of-the-art natural language processing.
\newblock In Liu, Q. and Schlangen, D. (eds.), \emph{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations}, pp.\  38--45, Online, October 2020. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.emnlp-demos.6}.
\newblock URL \url{https://aclanthology.org/2020.emnlp-demos.6}.

\bibitem[Ye et~al.(2023)Ye, Zheng, Bao, Qian, and Wang]{ye2023dinoiser}
Ye, J., Zheng, Z., Bao, Y., Qian, L., and Wang, M.
\newblock Dinoiser: Diffused conditional sequence learning by manipulating noises.
\newblock \emph{arXiv preprint arXiv:2302.10025}, 2023.

\bibitem[Yule(1971)]{yule1971method}
Yule, G.~U.
\newblock On a method of investigating periodicities in disturbed series with special reference to wolfer’s sunspot numbers.
\newblock \emph{Statistical Papers of George Udny Yule}, pp.\  389--420, 1971.

\bibitem[Zheng et~al.(2023)Zheng, Yuan, Yu, and Kong]{Zheng2023ARD}
Zheng, L., Yuan, J., Yu, L., and Kong, L.
\newblock A reparameterized discrete diffusion model for text generation.
\newblock \emph{ArXiv}, abs/2302.05737, 2023.

\bibitem[Ziegler \& Rush(2019)Ziegler and Rush]{ziegler2019latent}
Ziegler, Z. and Rush, A.
\newblock Latent normalizing flows for discrete sequences.
\newblock In \emph{International Conference on Machine Learning}, pp.\  7673--7682. PMLR, 2019.

\end{thebibliography}
