@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


@inproceedings{DSS,
  title={Domain-specific suppression for adaptive object detection},
  author={Wang, Yu and Zhang, Rui and Zhang, Shuo and Li, Miao and Xia, Yangyang and Zhang, XiShan and Liu, ShaoLi},
  booktitle={CVPR},
  pages={9603--9612},
  year={2021}
}
@inproceedings{SCAN,
  title={SCAN: Cross Domain Object Detection with Semantic Conditioned Adaptation},
  author={Li, Wuyang and Liu, Xinyu and Yao, Xiwen and Yuan, Yixuan},
  booktitle={AAAI},
  volume={6},
  pages={7},
  year={2022}
}
@article{FSAC,
  title={Frequency Spectrum Augmentation Consistency for Domain Adaptive Object Detection},
  author={Liu, Rui and Han, Yahong and Wang, Yaowei and Tian, Qi},
  journal={arXiv preprint arXiv:2112.08605},
  year={2021}
}

@inproceedings{RPN,
  title={Rpn prototype alignment for domain adaptive object detector},
  author={Zhang, Yixin and Wang, Zilei and Mao, Yushi},
  booktitle={CVPR},
  pages={12425--12434},
  year={2021}
}
@inproceedings{MEGA-CDA,
  title={Mega-cda: Memory guided attention for category-aware unsupervised domain adaptive object detection},
  author={Vs, Vibashan and Gupta, Vikram and Oza, Poojan and Sindagi, Vishwanath A and Patel, Vishal M},
  booktitle={CVPR},
  pages={4516--4526},
  year={2021}
}
@inproceedings{VD,
  title={Vector-decomposed disentanglement for domain-invariant object detection},
  author={Wu, Aming and Liu, Rui and Han, Yahong and Zhu, Linchao and Yang, Yi},
  booktitle={ICCV},
  pages={9342--9351},
  year={2021}
}
@article{SAD,
  title={Self-adversarial disentangling for specific domain adaptation},
  author={Zhou, Qianyu and Gu, Qiqi and Pang, Jiangmiao and Feng, Zhengyang and Cheng, Guangliang and Lu, Xuequan and Shi, Jianping and Ma, Lizhuang},
  journal={TPAMI},
  volume={45},
  number={7},
  pages={8954--8968},
  year={2023}
}

@inproceedings{Contrasitive,
  title={Contrastive adaptation network for unsupervised domain adaptation},
  author={Kang, Guoliang and Jiang, Lu and Yang, Yi and Hauptmann, Alexander G},
  booktitle={CVPR},
  pages={4893--4902},
  year={2019}
}
@article{Category-level,
  title={Category-level adversarial adaptation for semantic segmentation using purified features},
  author={Luo, Yawei and Liu, Ping and Zheng, Liang and Guan, Tao and Yu, Junqing and Yang, Yi},
  journal={TPAMI},
  year={2021},
  publisher={IEEE}
}
@article{Where,
  title={Where and how to transfer: knowledge aggregation-induced transferability perception for unsupervised domain adaptation},
  author={Dong, Jiahua and Cong, Yang and Sun, Gan and Fang, Zhen and Ding, Zhengming},
  journal={TPAMI},
  year={2021},
  publisher={IEEE}
}
@inproceedings{DAFormer,
  title={Daformer: Improving network architectures and training strategies for domain-adaptive semantic segmentation},
  author={Hoyer, Lukas and Dai, Dengxin and Van Gool, Luc},
  booktitle={CVPR},
  pages={9924--9935},
  year={2022}
}
@inproceedings{SDA,
  title={Seeking similarities over differences: Similarity-based domain alignment for adaptive object detection},
  author={Rezaeianaran, Farzaneh and Shetty, Rakshith and Aljundi, Rahaf and Reino, Daniel Olmeda and Zhang, Shanshan and Schiele, Bernt},
  booktitle={ICCV},
  pages={9204--9213},
  year={2021}
}
@inproceedings{Category-contrast,
  title={Category contrast for unsupervised domain adaptation in visual tasks},
  author={Huang, Jiaxing and Guan, Dayan and Xiao, Aoran and Lu, Shijian and Shao, Ling},
  booktitle={CVPR},
  pages={1203--1214},
  year={2022}
}
@inproceedings{SIGMA,
  title={SIGMA: Semantic-complete Graph Matching for Domain Adaptive Object Detection},
  author={Li, Wuyang and Liu, Xinyu and Yuan, Yixuan},
  booktitle={CVPR},
  pages={5291--5300},
  year={2022}
}
@inproceedings{CBAM,
  title={Cbam: Convolutional block attention module},
  author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
  booktitle={ECCV},
  pages={3--19},
  year={2018},
  organization={Springer}
}
@inproceedings{Resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  pages={770--778},
  year={2016}
}
@inproceedings{DA-Faster,
  title={Domain adaptive faster r-cnn for object detection in the wild},
  author={Chen, Yuhua and Li, Wen and Sakaridis, Christos and Dai, Dengxin and Van Gool, Luc},
  booktitle={CVPR},
  pages={3339--3348},
  year={2018}
}
@inproceedings{DIDN,
  title={Domain-invariant disentangled network for generalizable object detection},
  author={Lin, Chuang and Yuan, Zehuan and Zhao, Sicheng and Sun, Peize and Wang, Changhu and Cai, Jianfei},
  booktitle={ICCV},
  pages={8771--8780},
  year={2021}
}
@inproceedings{EPM,
  title={Every pixel matters: Center-aware feature alignment for domain adaptive object detector},
  author={Hsu, Cheng-Chun and Tsai, Yi-Hsuan and Lin, Yen-Yu and Yang, Ming-Hsuan},
  booktitle={ECCV},
  pages={733--748},
  year={2020},
  organization={Springer}
}
@inproceedings{KTNet,
  title={Knowledge mining and transferring for domain adaptive object detection},
  author={Tian, Kun and Zhang, Chenghao and Wang, Ying and Xiang, Shiming and Pan, Chunhong},
  booktitle={ICCV},
  pages={9133--9142},
  year={2021}
}
@article{DANN,
  title={Domain-adversarial training of neural networks},
  author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and Marchand, Mario and Lempitsky, Victor},
  journal={JMLR},
  volume={17},
  number={1},
  pages={2096--2030},
  year={2016},
  publisher={JMLR. org}
}
@inproceedings{JAN,
  title={Deep transfer learning with joint adaptation networks},
  author={Long, Mingsheng and Zhu, Han and Wang, Jianmin and Jordan, Michael I},
  booktitle={ICML},
  pages={2208--2217},
  year={2017},
  organization={PMLR}
}
@inproceedings{FCP,
  title={Feature constrained by pixel: Hierarchical adversarial deep domain adaptation},
  author={Shao, Rui and Lan, Xiangyuan and Yuen, Pong C},
  booktitle={ACMMM},
  pages={220--228},
  year={2018}
}
@inproceedings{SAP,
  title={Spatial attention pyramid network for unsupervised domain adaptation},
  author={Li, Congcong and Du, Dawei and Zhang, Libo and Wen, Longyin and Luo, Tiejian and Wu, Yanjun and Zhu, Pengfei},
  booktitle={ECCV},
  pages={481--497},
  year={2020},
  organization={Springer}
}
@inproceedings{Strong-weak,
  title={Strong-weak distribution alignment for adaptive object detection},
  author={Saito, Kuniaki and Ushiku, Yoshitaka and Harada, Tatsuya and Saenko, Kate},
  booktitle={CVPR},
  pages={6956--6965},
  year={2019}
}
@inproceedings{RCAN,
  title={Image super-resolution using very deep residual channel attention networks},
  author={Zhang, Yulun and Li, Kunpeng and Li, Kai and Wang, Lichen and Zhong, Bineng and Fu, Yun},
  booktitle={ECCV},
  pages={286--301},
  year={2018},
  organization={Springer}
}
@inproceedings{ATTENTION,
  title={Attention to scale: Scale-aware semantic image segmentation},
  author={Chen, Liang-Chieh and Yang, Yi and Wang, Jiang and Xu, Wei and Yuille, Alan L},
  booktitle={CVPR},
  pages={3640--3649},
  year={2016}
}
@inproceedings{TRIDENT,
  title={Scale-aware trident networks for object detection},
  author={Li, Yanghao and Chen, Yuntao and Wang, Naiyan and Zhang, Zhaoxiang},
  booktitle={ICCV},
  pages={6054--6063},
  year={2019}
}


@inproceedings{Cityscapes,
title={The Cityscapes Dataset for Semantic Urban Scene Understanding},
author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
booktitle={CVPR},
year={2016}
}
@article{FoggyCityscapes,
  author = {Sakaridis, Christos and Dai, Dengxin and Van Gool, Luc},
  title = {Semantic Foggy Scene Understanding with Synthetic Data},
  journal = {IJCV},
  year = {2018},
  month = {Sep},
  volume = {126},
  number = {9},
  pages = {973--992}
}
@INPROCEEDINGS{KITTI,
  author = {Andreas Geiger and Philip Lenz and Raquel Urtasun},
  title = {Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite},
  booktitle = {CVPR},
  year = {2012}
}
@inproceedings{SIM10K,
  title={Driving in the Matrix: Can virtual worlds replace human-generated annotations for real world tasks?},
  author={Johnson-Roberson, Matthew and Barto, Charles and Mehta, Rounak and Sridhar, Sharath Nittur and Rosaen, Karl and Vasudevan, Ram},
  booktitle={ICRA 2017},
  pages={746--753},
  year={2017},
  organization={IEEE}
}
@article{MMD,
  title={A kernel two-sample test},
  author={Gretton, Arthur and Borgwardt, Karsten M and Rasch, Malte J and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
  journal={JMLR},
  volume={13},
  number={1},
  pages={723--773},
  year={2012},
  publisher={JMLR. org}
}
@inproceedings{DAN,
  title={Learning transferable features with deep adaptation networks},
  author={Long, Mingsheng and Cao, Yue and Wang, Jianmin and Jordan, Michael},
  booktitle={ICML},
  pages={97--105},
  year={2015},
  organization={PMLR}
}
@article{DTN,
  title={Deep transfer network: Unsupervised domain adaptation},
  author={Zhang, Xu and Yu, Felix Xinnan and Chang, Shih-Fu and Wang, Shengjin},
  journal={arXiv preprint arXiv:1503.00591},
  year={2015}
}
@article{RTN,
  title={Unsupervised domain adaptation with residual transfer networks},
  author={Long, Mingsheng and Zhu, Han and Wang, Jianmin and Jordan, Michael I},
  journal={NeurIPS},
  volume={29},
  year={2016}
}
@inproceedings{WMMD,
  title={Mind the class weight bias: Weighted maximum mean discrepancy for unsupervised domain adaptation},
  author={Yan, Hongliang and Ding, Yukang and Li, Peihua and Wang, Qilong and Xu, Yong and Zuo, Wangmeng},
  booktitle={CVPR},
  pages={2272--2281},
  year={2017}
}
@inproceedings{CTF,
  title={Cross-domain object detection through coarse-to-fine feature adaptation},
  author={Zheng, Yangtao and Huang, Di and Liu, Songtao and Wang, Yunhong},
  booktitle={CVPR},
  pages={13766--13775},
  year={2020}
}
@inproceedings{GPA,
  title={Cross-domain detection via graph-induced prototype alignment},
  author={Xu, Minghao and Wang, Hang and Ni, Bingbing and Tian, Qi and Zhang, Wenjun},
  booktitle={CVPR},
  pages={12355--12364},
  year={2020}
}
@inproceedings{RCNN,
  title={Rich feature hierarchies for accurate object detection and semantic segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={CVPR},
  pages={580--587},
  year={2014}
}
@inproceedings{FastRCNN,
  title={Fast r-cnn},
  author={Girshick, Ross},
  booktitle={ICCV},
  pages={1440--1448},
  year={2015}
}
@article{FasterRCNN,
  title={Faster r-cnn: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={NeurIPS},
  volume={28},
  year={2015}
}
@inproceedings{FPN,
  title={Feature pyramid networks for object detection},
  author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
  booktitle={CVPR},
  pages={2117--2125},
  year={2017}
}
@article{RFCN,
  title={R-fcn: Object detection via region-based fully convolutional networks},
  author={Dai, Jifeng and Li, Yi and He, Kaiming and Sun, Jian},
  journal={NeurIPS},
  volume={29},
  year={2016}
}
@inproceedings{SSD,
  title={Ssd: Single shot multibox detector},
  author={Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C},
  booktitle={ECCV},
  pages={21--37},
  year={2016},
  organization={Springer}
}
@inproceedings{YOLO,
  title={You only look once: Unified, real-time object detection},
  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
  booktitle={CVPR},
  pages={779--788},
  year={2016}
}
@inproceedings{YOLOv5,
  title={TPH-YOLOv5: Improved YOLOv5 based on transformer prediction head for object detection on drone-captured scenarios},
  author={Zhu, Xingkui and Lyu, Shuchang and Wang, Xu and Zhao, Qi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2778--2788},
  year={2021}
}
@inproceedings{FCOS,
  title={Fcos: Fully convolutional one-stage object detection},
  author={Tian, Zhi and Shen, Chunhua and Chen, Hao and He, Tong},
  booktitle={ICCV},
  pages={9627--9636},
  year={2019}
}
@inproceedings{AT,
  title={Cross-Domain Adaptive Teacher for Object Detection},
  author={Li, Yu-Jhe and Dai, Xiaoliang and Ma, Chih-Yao and Liu, Yen-Cheng and Chen, Kan and Wu, Bichen and He, Zijian and Kitani, Kris and Vajda, Peter},
  booktitle={CVPR},
  pages={7581--7590},
  year={2022}
}
@article{MT,
  title={Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results},
  author={Tarvainen, Antti and Valpola, Harri},
  journal={NPIS},
  volume={30},
  year={2017}
}
@inproceedings{TDD,
  title={Cross Domain Object Detection by Target-Perceived Dual Branch Distillation},
  author={He, Mengzhe and Wang, Yali and Wu, Jiaxi and Wang, Yiru and Li, Hanqing and Li, Bo and Gan, Weihao and Wu, Wei and Qiao, Yu},
  booktitle={CVPR},
  pages={9570--9580},
  year={2022}
}
@inproceedings{TIA,
  title={Task-specific Inconsistency Alignment for Domain Adaptive Object Detection},
  author={Zhao, Liang and Wang, Limin},
  booktitle={CVPR},
  pages={14217--14226},
  year={2022}
}
@inproceedings{GRL,
  title={Unsupervised domain adaptation by backpropagation},
  author={Ganin, Yaroslav and Lempitsky, Victor},
  booktitle={ICML},
  pages={1180--1189},
  year={2015},
  organization={PMLR}
}
@article{UaDAN,
  title={Uncertainty-aware unsupervised domain adaptation in object detection},
  author={Guan, Dayan and Huang, Jiaxing and Xiao, Aoran and Lu, Shijian and Cao, Yanpeng},
  journal={TMM},
  volume={24},
  pages={2502--2514},
  year={2021},
  publisher={IEEE}
}
@inproceedings{Style,
  title={Style mixing and patchwise prototypical matching for one-shot unsupervised domain adaptive semantic segmentation},
  author={Wu, Xinyi and Wu, Zhenyao and Lu, Yuhang and Ju, Lili and Wang, Song},
  booktitle={AAAI},
  volume={36},
  number={3},
  pages={2740--2749},
  year={2022}
}



@inproceedings{linearprob,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={CVPR},
  pages={16000--16009},
  year={2022}
}
@article{poda,
  title={P $\{$$\backslash$O$\}$ DA: Prompt-driven Zero-shot Domain Adaptation},
  author={Fahes, Mohammad and Vu, Tuan-Hung and Bursuc, Andrei and P{\'e}rez, Patrick and de Charette, Raoul},
  journal={arXiv preprint arXiv:2212.03241},
  year={2022}
}
@article{ClipTheGap,
  title={CLIP the Gap: A Single Domain Generalization Approach for Object Detection},
  author={Vidit, Vidit and Engilberge, Martin and Salzmann, Mathieu},
  journal={arXiv preprint arXiv:2301.05499},
  year={2023}
}
@inproceedings{CLIP,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}
@inproceedings{GLIP,
  title={Grounded language-image pre-training},
  author={Li, Liunian Harold and Zhang, Pengchuan and Zhang, Haotian and Yang, Jianwei and Li, Chunyuan and Zhong, Yiwu and Wang, Lijuan and Yuan, Lu and Zhang, Lei and Hwang, Jenq-Neng and others},
  booktitle={CVPR},
  pages={10965--10975},
  year={2022}
}
@inproceedings{ALIGN,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={ICML},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}
@inproceedings{ViLD,
title={Open-vocabulary Object Detection via Vision and Language Knowledge Distillation},
author={Xiuye Gu and Tsung-Yi Lin and Weicheng Kuo and Yin Cui},
booktitle={ICLR},
year={2022}
}
@inproceedings{Regionclip,
  title={Regionclip: Region-based language-image pretraining},
  author={Zhong, Yiwu and Yang, Jianwei and Zhang, Pengchuan and Li, Chunyuan and Codella, Noel and Li, Liunian Harold and Zhou, Luowei and Dai, Xiyang and Yuan, Lu and Li, Yin and others},
  booktitle={CVPR},
  pages={16793--16803},
  year={2022}
}
@inproceedings{KgCoOp,
  title={Visual-language prompt tuning with knowledge-guided context optimization},
  author={Yao, Hantao and Zhang, Rui and Xu, Changsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6757--6767},
  year={2023}
}
@article{DICN,
  title={Dual Instance-Consistent Network for Cross-Domain Object Detection},
  author={Jiao, Yifan and Yao, Hantao and Xu, Changsheng},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2022},
  publisher={IEEE}
}
@inproceedings{DetPro,
  title={Learning to prompt for open-vocabulary object detection with vision-language model},
  author={Du, Yu and Wei, Fangyun and Zhang, Zihe and Shi, Miaojing and Gao, Yue and Li, Guoqi},
  booktitle={CVPR},
  pages={14084--14093},
  year={2022}
}
@article{CoOp,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={IJCV},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}
@inproceedings{coco,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={ECCV},
  pages={740--755},
  year={2014},
  organization={Springer}
}
@article{Transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={NeurIPS},
  volume={30},
  year={2017}
}
@inproceedings{CoCoOp,
  title={Conditional prompt learning for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  booktitle={CVPR},
  pages={16816--16825},
  year={2022}
}
@inproceedings{ViT,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={ICLR},
year={2021}
}
@inproceedings{DBGL,
  title={Dual bipartite graph learning: A general approach for domain adaptive object detection},
  author={Chen, Chaoqi and Li, Jiongcheng and Zheng, Zebiao and Huang, Yue and Ding, Xinghao and Yu, Yizhou},
  booktitle={ICCV},
  pages={2703--2712},
  year={2021}
}
@article{FGRR,
  title={Relation matters: foreground-aware graph-based relational reasoning for domain adaptive object detection},
  author={Chen, Chaoqi and Li, Jiongcheng and Zhou, Hong-Yu and Han, Xiaoguang and Huang, Yue and Ding, Xinghao and Yu, Yizhou},
  journal={TPAMI},
  volume={45},
  number={03},
  pages={3677--3694},
  year={2023}
}
@article{sigma++,
  title={SIGMA++: Improved Semantic-complete Graph Matching for Domain Adaptive Object Detection},
  author={Li, Wuyang and Liu, Xinyu and Yuan, Yixuan},
  journal={TPAMI},
  volume={45},
  number={07},
  pages={9022--9040},
  year={2023}
}
@inproceedings{clipart,
  title={Cross-domain weakly-supervised object detection through progressive domain adaptation},
  author={Inoue, Naoto and Furuta, Ryosuke and Yamasaki, Toshihiko and Aizawa, Kiyoharu},
  booktitle={CVPR},
  pages={5001--5009},
  year={2018}
}
@article{pascal,
  title={The pascal visual object classes challenge: A retrospective},
  author={Everingham, Mark and Eslami, SM Ali and Van Gool, Luc and Williams, Christopher KI and Winn, John and Zisserman, Andrew},
  journal={IJCV},
  volume={111},
  pages={98--136},
  year={2015}
}