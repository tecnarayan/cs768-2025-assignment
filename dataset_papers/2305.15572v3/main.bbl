\begin{thebibliography}{29}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ajalloeian and Stich(2020)]{ajalloeian2020convergence}
Ahmad Ajalloeian and Sebastian~U Stich.
\newblock On the convergence of {SGD} with biased gradients.
\newblock arXiv preprint arXiv:2008.00051, 2020.

\bibitem[Bubeck et~al.(2015)]{bubeck2015convex}
S{\'e}bastien Bubeck et~al.
\newblock Convex optimization: Algorithms and complexity.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  8\penalty0 (3-4):\penalty0 231--357, 2015.

\bibitem[Bull(2011)]{bull2011convergence}
Adam~D. Bull.
\newblock Convergence rates of efficient global optimization algorithms.
\newblock \emph{Journal of Machine Learning Research}, 12\penalty0
  (88):\penalty0 2879--2904, 2011.

\bibitem[Chatzigeorgiou(2013)]{chatzigeorgiou2013bounds}
Ioannis Chatzigeorgiou.
\newblock Bounds on the {L}ambert function and their application to the outage
  analysis of user cooperation.
\newblock \emph{IEEE Communications Letters}, 17\penalty0 (8):\penalty0
  1505--1508, 2013.

\bibitem[Davydov and Schaback(2016)]{davydov2016error}
Oleg Davydov and Robert Schaback.
\newblock Error bounds for kernel-based numerical differentiation.
\newblock \emph{Numerische Mathematik}, 132:\penalty0 243--269, 2016.

\bibitem[De~Freitas et~al.(2012)De~Freitas, Smola, and
  Zoghi]{de2012exponential}
Nando De~Freitas, Alex Smola, and Masrour Zoghi.
\newblock Exponential regret bounds for {Gaussian} process bandits with
  deterministic observations.
\newblock In \emph{Proceedings of the 29th International Conference on Machine
  Learning}, 2012.

\bibitem[Deshwal and Doppa(2021)]{deshwal2021combining}
Aryan Deshwal and Jana Doppa.
\newblock Combining latent space and structured kernels for {B}ayesian
  optimization over combinatorial spaces.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~34, pages 8185--8200, 2021.

\bibitem[Devroye and Lugosi(2001)]{devroye2001combinatorial}
Luc Devroye and G{\'a}bor Lugosi.
\newblock \emph{Combinatorial Methods in Density Estimation}.
\newblock Springer Science \& Business Media, 2001.

\bibitem[Eriksson and Poloczek(2021)]{eriksson2021scalable}
David Eriksson and Matthias Poloczek.
\newblock Scalable constrained {B}ayesian optimization.
\newblock In \emph{Proceedings of The 24th International Conference on
  Artificial Intelligence and Statistics}, volume 130, pages 730--738. PMLR,
  2021.

\bibitem[Eriksson et~al.(2019)Eriksson, Pearce, Gardner, Turner, and
  Poloczek]{eriksson2019scalable}
David Eriksson, Michael Pearce, Jacob Gardner, Ryan~D Turner, and Matthias
  Poloczek.
\newblock Scalable global optimization via local {Bayesian} optimization.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, 2019.

\bibitem[Garnett(2023)]{garnett2023}
Roman Garnett.
\newblock \emph{Bayesian Optimization}.
\newblock Cambridge University Press, 2023.

\bibitem[Grosnit et~al.(2021)Grosnit, Tutunov, Maraval, Griffiths,
  Cowen-Rivers, Yang, Zhu, Lyu, Chen, Wang, et~al.]{grosnit2021high}
Antoine Grosnit, Rasul Tutunov, Alexandre~Max Maraval, Ryan-Rhys Griffiths,
  Alexander~I Cowen-Rivers, Lin Yang, Lin Zhu, Wenlong Lyu, Zhitang Chen, Jun
  Wang, et~al.
\newblock High-dimensional {B}ayesian optimisation with variational
  autoencoders and deep metric learning.
\newblock arXiv preprint arXiv:2106.03609, 2021.

\bibitem[Gómez-Bombarelli et~al.(2018)Gómez-Bombarelli, Wei, Duvenaud,
  Hernández-Lobato, Sánchez-Lengeling, Sheberla, Aguilera-Iparraguirre,
  Hirzel, Adams, and Aspuru-Guzik]{gomez2018automatic}
Rafael Gómez-Bombarelli, Jennifer~N. Wei, David Duvenaud, José~Miguel
  Hernández-Lobato, Benjamín Sánchez-Lengeling, Dennis Sheberla, Jorge
  Aguilera-Iparraguirre, Timothy~D. Hirzel, Ryan~P. Adams, and Alán
  Aspuru-Guzik.
\newblock Automatic chemical design using a data-driven continuous
  representation of molecules.
\newblock \emph{ACS Central Science}, 4\penalty0 (2):\penalty0 268--276, 2018.

\bibitem[Kamath(2015)]{kamath2015bounds}
Gautam Kamath.
\newblock Bounds on the expectation of the maximum of samples from a
  {Gaussian}.
\newblock 2015.
\newblock URL \url{http://www.gautamkamath.com/writings/gaussian_max.pdf}.

\bibitem[Kandasamy et~al.(2015)Kandasamy, Schneider, and
  Poczos]{kandasamy2015high}
Kirthevasan Kandasamy, Jeff Schneider, and Barnabas Poczos.
\newblock High dimensional {B}ayesian optimisation and bandits via additive
  models.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning}, volume~37, pages 295--304, 2015.

\bibitem[Kawaguchi et~al.(2015)Kawaguchi, Kaelbling, and
  Lozano-P\'{e}rez]{kawaguchi2015bayesian}
Kenji Kawaguchi, Leslie~Pack Kaelbling, and Tom\'{a}s Lozano-P\'{e}rez.
\newblock Bayesian optimization with exponential convergence.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~28, 2015.

\bibitem[Maus et~al.(2022)Maus, Jones, Moore, Kusner, Bradshaw, and
  Gardner]{maus2022local}
Natalie Maus, Haydn Jones, Juston Moore, Matt~J Kusner, John Bradshaw, and
  Jacob Gardner.
\newblock Local latent space {B}ayesian optimization over structured inputs.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~35, pages 34505--34518, 2022.

\bibitem[Maus et~al.(2023)Maus, Wu, Eriksson, and Gardner]{maus2023discovering}
Natalie Maus, Kaiwen Wu, David Eriksson, and Jacob Gardner.
\newblock Discovering many diverse solutions with {B}ayesian optimization.
\newblock In \emph{Proceedings of The 26th International Conference on
  Artificial Intelligence and Statistics}, volume 206, pages 1779--1798, 2023.

\bibitem[M{\"u}ller et~al.(2021)M{\"u}ller, von Rohr, and
  Trimpe]{muller2021local}
Sarah M{\"u}ller, Alexander von Rohr, and Sebastian Trimpe.
\newblock Local policy search with {Bayesian} optimization.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~34, pages 20708--20720, 2021.

\bibitem[Nguyen et~al.(2022)Nguyen, Wu, Gardner, and Garnett]{nguyen2022local}
Quan Nguyen, Kaiwen Wu, Jacob Gardner, and Roman Garnett.
\newblock Local {B}ayesian optimization via maximizing probability of descent.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~35, pages 13190--13202, 2022.

\bibitem[Scarlett(2018)]{scarlett2018tight}
Jonathan Scarlett.
\newblock Tight regret bounds for {B}ayesian optimization in one dimension.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, volume~80, pages 4500--4508, 2018.

\bibitem[Shu et~al.(2023)Shu, Dai, Sng, Verma, Jaillet, and
  Low]{shu2023zerothorder}
Yao Shu, Zhongxiang Dai, Weicong Sng, Arun Verma, Patrick Jaillet, and Bryan
  Kian~Hsiang Low.
\newblock Zeroth-order optimization with trajectory-informed derivative
  estimation.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{snoek2012practical}
Jasper Snoek, Hugo Larochelle, and Ryan~P Adams.
\newblock Practical {B}ayesian optimization of machine learning algorithms.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~25, 2012.

\bibitem[Srinivas et~al.(2010)Srinivas, Krause, Kakade, and
  Seeger]{srinivas2010gaussian}
Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger.
\newblock Gaussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock In \emph{Proceedings of the 27th International Conference on Machine
  Learning}, pages 1015--1022, 2010.

\bibitem[Stanton et~al.(2022)Stanton, Maddox, Gruver, Maffettone, Delaney,
  Greenside, and Wilson]{stanton2022accelerating}
Samuel Stanton, Wesley Maddox, Nate Gruver, Phillip Maffettone, Emily Delaney,
  Peyton Greenside, and Andrew~Gordon Wilson.
\newblock Accelerating {B}ayesian optimization for biological sequence design
  with denoising autoencoders.
\newblock In \emph{Proceedings of the 39th International Conference on Machine
  Learning}, volume 162, pages 20459--20478, 2022.

\bibitem[Tripp et~al.(2020)Tripp, Daxberger, and
  Hern\'{a}ndez-Lobato]{tripp2020sample}
Austin Tripp, Erik Daxberger, and Jos\'{e}~Miguel Hern\'{a}ndez-Lobato.
\newblock Sample-efficient optimization in the latent space of deep generative
  models via weighted retraining.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pages 11259--11272, 2020.

\bibitem[Wang et~al.(2020)Wang, Fonseca, and Tian]{wang2020learning}
Linnan Wang, Rodrigo Fonseca, and Yuandong Tian.
\newblock Learning search space partition for black-box optimization using
  {Monte} {Carlo} tree search.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pages 19511--19522, 2020.

\bibitem[Wendland(2004)]{wendland2004scattered}
Holger Wendland.
\newblock \emph{Scattered Data Approximation}, volume~17.
\newblock Cambridge University Press, 2004.

\bibitem[Wilson et~al.(2021)Wilson, Borovitskiy, Terenin, Mostowsky, and
  Deisenroth]{wilson2021pathwise}
James~T Wilson, Viacheslav Borovitskiy, Alexander Terenin, Peter Mostowsky, and
  Marc~Peter Deisenroth.
\newblock Pathwise conditioning of {G}aussian processes.
\newblock \emph{The Journal of Machine Learning Research}, 22\penalty0
  (1):\penalty0 4741--4787, 2021.

\end{thebibliography}
