\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{Agrawal2015}
Pulkit Agrawal, Jo{\~{a}}o Carreira, and Jitendra Malik.
\newblock Learning to see by moving.
\newblock In {\em ICCV}, 2015.

\bibitem{Arnab2021}
Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Lu{\v{c}}i{\'c},
  and Cordelia Schmid.
\newblock {ViViT}: A video vision transformer.
\newblock In {\em ICCV}, 2021.

\bibitem{Bao2021}
Hangbo Bao, Li Dong, and Furu Wei.
\newblock {BEiT}: {BERT} pre-training of image {Transformers}.
\newblock {\em arXiv:2106.08254}, 2021.

\bibitem{Bertasius2021}
Gedas Bertasius, Heng Wang, and Lorenzo Torresani.
\newblock Is space-time attention all you need for video understanding?
\newblock In {\em ICML}, 2021.

\bibitem{Brown2020}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
  Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
  Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
  Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
  and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock In {\em NeurIPS}, 2020.

\bibitem{Carreira2018}
Jo{\~{a}}o Carreira, Eric Noland, Andras Banki-Horvath, Chloe Hillier, and
  Andrew Zisserman.
\newblock A short note about {Kinetics-600}.
\newblock {\em arXiv:1808.01340}, 2018.

\bibitem{Carreira2019}
Jo{\~{a}}o Carreira, Eric Noland, Chloe Hillier, and Andrew Zisserman.
\newblock A short note on the {Kinetics-700} human action dataset.
\newblock {\em arXiv:1907.06987}, 2019.

\bibitem{Carreira2017}
Jo{\~{a}}o Carreira and Andrew Zisserman.
\newblock Quo vadis, action recognition? a new model and the kinetics dataset.
\newblock In {\em CVPR}, 2017.

\bibitem{Chen2020c}
Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and
  Ilya Sutskever.
\newblock Generative pretraining from pixels.
\newblock In {\em ICML}, 2020.

\bibitem{Chen2020}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In {\em ICML}, 2020.

\bibitem{Clark2020}
Kevin Clark, Minh-Thang Luong, Quoc~V Le, and Christopher~D Manning.
\newblock {ELECTRA}: Pre-training text encoders as discriminators rather than
  generators.
\newblock In {\em ICLR}, 2020.

\bibitem{Cubuk2020}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock {RandAugment}: Practical automated data augmentation with a reduced
  search space.
\newblock In {\em CVPR Workshops}, 2020.

\bibitem{Dalal2005}
Navneet Dalal and Bill Triggs.
\newblock Histograms of oriented gradients for human detection.
\newblock In {\em CVPR}, 2005.

\bibitem{Deng2009}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock {ImageNet: A large-scale hierarchical image database}.
\newblock In {\em CVPR}, 2009.

\bibitem{Devlin2019}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional {Transformers} for
  language understanding.
\newblock In {\em NAACL}, 2019.

\bibitem{Diba2019}
Ali Diba, Vivek Sharma, Luc~Van Gool, and Rainer Stiefelhagen.
\newblock {DynamoNet: Dynamic Action and Motion Network}.
\newblock In {\em ICCV}, 2019.

\bibitem{Dong2021}
Xiaoyi Dong, Jianmin Bao, Ting Zhang, Dongdong Chen, Weiming Zhang, Lu Yuan,
  Dong Chen, Fang Wen, and Nenghai Yu.
\newblock {PeCo}: Perceptual codebook for {BERT} pre-training of {Vision
  Transformers}.
\newblock {\em arXiv:2111.12710}, 2021.

\bibitem{Dosovitskiy2021}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em ICLR}, 2021.

\bibitem{Fan2021}
Haoqi Fan, Bo Xiong, Karttikeya Mangalam, Yanghao Li, Zhicheng Yan, Jitendra
  Malik, and Christoph Feichtenhofer.
\newblock {Multiscale Vision Transformers}.
\newblock In {\em ICCV}, 2021.

\bibitem{Feichtenhofer2020}
Christoph Feichtenhofer.
\newblock {X3D}: Expanding architectures for efficient video recognition.
\newblock In {\em CVPR}, 2020.

\bibitem{Feichtenhofer2019}
Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and Kaiming He.
\newblock {SlowFast} networks for video recognition.
\newblock In {\em ICCV}, 2019.

\bibitem{Feichtenhofer2021}
Christoph Feichtenhofer, Haoqi Fan, Bo Xiong, Ross Girshick, and Kaiming He.
\newblock A large-scale study on unsupervised spatiotemporal representation
  learning.
\newblock In {\em CVPR}, 2021.

\bibitem{Fernando2017}
Basura Fernando, Hakan Bilen, Efstratios Gavves, and Stephen Gould.
\newblock Self-supervised video representation learning with odd-one-out
  networks.
\newblock In {\em ICCV}, 2017.

\bibitem{Ghadiyaram2019}
Deepti Ghadiyaram, Matt Feiszli, Du Tran, Xueting Yan, Heng Wang, and Dhruv
  Mahajan.
\newblock Large-scale weakly-supervised pre-training for video action
  recognition.
\newblock In {\em CVPR}, 2019.

\bibitem{Goroshin2015}
Ross Goroshin, Joan Bruna, Jonathan Tompson, David Eigen, and Yann LeCun.
\newblock Unsupervised learning of spatiotemporally coherent metrics.
\newblock In {\em ICCV}, 2015.

\bibitem{Goyal2017}
Priya Goyal, Piotr Doll{\'a}r, Ross Girshick, Pieter Noordhuis, Lukasz
  Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He.
\newblock Accurate, large minibatch {SGD}: Training {ImageNet} in 1 hour.
\newblock {\em arXiv:1706.02677}, 2017.

\bibitem{Goyal2017a}
Raghav Goyal, Samira Ebrahimi~Kahou, Vincent Michalski, Joanna Materzynska,
  Susanne Westphal, Heuna Kim, Valentin Haenel, Ingo Fruend, Peter Yianilos,
  Moritz Mueller-Freitag, et~al.
\newblock The ``something something'' video database for learning and
  evaluating visual common sense.
\newblock In {\em ICCV}, 2017.

\bibitem{Grill2020}
Jean-Bastien Grill, Florian Strub, Florent Altch\'{e}, Corentin Tallec, Pierre
  Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila~Pires, Zhaohan
  Guo, Mohammad Gheshlaghi~Azar, Bilal Piot, Koray Kavukcuoglu, Remi Munos, and
  Michal Valko.
\newblock Bootstrap your own latent - a new approach to self-supervised
  learning.
\newblock In {\em NeurIPS}, 2020.

\bibitem{Gu2018}
Chunhui Gu, Chen Sun, Sudheendra Vijayanarasimhan, Caroline Pantofaru, David~A.
  Ross, George Toderici, Yeqing Li, Susanna Ricco, Rahul Sukthankar, Cordelia
  Schmid, and Jitendra Malik.
\newblock {AVA}: A video dataset of spatio-temporally localized atomic visual
  actions.
\newblock In {\em CVPR}, 2018.

\bibitem{Han2019}
Tengda Han, Weidi Xie, and Andrew Zisserman.
\newblock Video representation learning by dense predictive coding.
\newblock In {\em Workshop on Large Scale Holistic Video Understanding, ICCV},
  2019.

\bibitem{He2021}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross
  Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock {\em arXiv:2111.06377}, 2021.

\bibitem{He2020}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In {\em CVPR}, 2020.

\bibitem{Hoffer2020}
Elad Hoffer, Tal Ben-Nun, Itay Hubara, Niv Giladi, Torsten Hoefler, and Daniel
  Soudry.
\newblock Augment your batch: Improving generalization through instance
  repetition.
\newblock In {\em CVPR}, 2020.

\bibitem{Huang2016}
Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, and Kilian~Q Weinberger.
\newblock Deep networks with stochastic depth.
\newblock In {\em ECCV}, 2016.

\bibitem{Kay2017}
Will Kay, Jo{\~{a}}o Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier,
  Sudheendra Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul
  Natsev, et~al.
\newblock The {Kinetics} human action video dataset.
\newblock {\em arXiv:1705.06950}, 2017.

\bibitem{Kondratyuk2021}
Dan Kondratyuk, Liangzhe Yuan, Yandong Li, Li Zhang, Mingxing Tan, Matthew
  Brown, and Boqing Gong.
\newblock {MoviNets}: Mobile video networks for efficient video recognition.
\newblock In {\em CVPR}, 2021.

\bibitem{LeCun1989}
Yann LeCun, Bernhard Boser, John~S Denker, Donnie Henderson, Richard~E Howard,
  Wayne Hubbard, and Lawrence~D Jackel.
\newblock Backpropagation applied to handwritten zip code recognition.
\newblock {\em Neural computation}, 1989.

\bibitem{Lee2017}
Hsin{-}Ying Lee, Jia{-}Bin Huang, Maneesh Singh, and Ming{-}Hsuan Yang.
\newblock Unsupervised representation learning by sorting sequence.
\newblock In {\em ICCV}, 2017.

\bibitem{Li2021a}
Yanghao Li, Chao-Yuan Wu, Haoqi Fan, Karttikeya Mangalam, Bo Xiong, Jitendra
  Malik, and Christoph Feichtenhofer.
\newblock Improved multiscale vision transformers for classification and
  detection.
\newblock {\em arXiv:2112.01526}, 2021.

\bibitem{Liu2021c}
Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue
  Cao, Zheng Zhang, Li Dong, Furu Wei, and Baining Guo.
\newblock {Swin Transformer} v2: Scaling up capacity and resolution.
\newblock {\em arXiv:2111.09883}, 2021.

\bibitem{Liu2021b}
Ze Liu, Jia Ning, Yue Cao, Yixuan Wei, Zheng Zhang, Stephen Lin, and Han Hu.
\newblock {Video Swin Transformer}.
\newblock {\em arXiv:2106.13230}, 2021.

\bibitem{Loshchilov2016}
Ilya Loshchilov and Frank Hutter.
\newblock {SGDR}: Stochastic gradient descent with warm restarts.
\newblock In {\em ICLR}, 2017.

\bibitem{Loshchilov2019}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In {\em ICLR}, 2019.

\bibitem{Lotter2017}
William Lotter, Gabriel Kreiman, and David Cox.
\newblock Deep predictive coding networks for video prediction and unsupervised
  learning.
\newblock In {\em ICLR}, 2017.

\bibitem{Mathieu2016}
Michael Mathieu, Camille Couprie, and Yann LeCun.
\newblock Deep multi-scale video prediction beyond mean square error.
\newblock In {\em ICLR}, 2016.

\bibitem{Misra2016}
Ishan Misra, C.~Lawrence Zitnick, and Martial Hebert.
\newblock Shuffle and learn: Unsupervised learning using temporal order
  verification.
\newblock In {\em ECCV}, 2016.

\bibitem{Oord2017}
Aaron van~den Oord, Oriol Vinyals, and Koray Kavukcuoglu.
\newblock Neural discrete representation learning.
\newblock In {\em NeurIPS}, 2017.

\bibitem{Pan2021}
Junting Pan, Siyu Chen, Mike~Zheng Shou, Yu Liu, Jing Shao, and Hongsheng Li.
\newblock Actor-context-actor relation network for spatio-temporal action
  localization.
\newblock In {\em CVPR}, 2021.

\bibitem{Pathak2017}
Deepak Pathak, Ross Girshick, Piotr Doll{\'a}r, Trevor Darrell, and Bharath
  Hariharan.
\newblock Learning features by watching objects move.
\newblock In {\em CVPR}, 2017.

\bibitem{Pathak2016}
Deepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, and Alexei~A
  Efros.
\newblock Context encoders: Feature learning by inpainting.
\newblock In {\em CVPR}, 2016.

\bibitem{Qian2021}
Rui Qian, Tianjian Meng, Boqing Gong, Ming-Hsuan Yang, Huisheng Wang, Serge
  Belongie, and Yin Cui.
\newblock Spatiotemporal contrastive video representation learning.
\newblock In {\em CVPR}, 2021.

\bibitem{Radford2018}
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem{Radford2019}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.

\bibitem{Raffel2020}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J. Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock {\em JMLR}, 2020.

\bibitem{Ramesh2021}
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec
  Radford, Mark Chen, and Ilya Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock In {\em ICML}, 2021.

\bibitem{Recasens2021}
Adria Recasens, Pauline Luc, Jean-Baptiste Alayrac, Luyu Wang, Florian Strub,
  Corentin Tallec, Mateusz Malinowski, Viorica P{\u{a}}tr{\u{a}}ucean, Florent
  Altch{\'e}, Michal Valko, et~al.
\newblock Broaden your views for self-supervised video learning.
\newblock In {\em ICCV}, 2021.

\bibitem{Ren2015}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock {Faster R-CNN}: Towards real-time object detection with region
  proposal networks.
\newblock In {\em NeurIPS}, 2015.

\bibitem{Sermanet2018}
Pierre Sermanet et~al.
\newblock Time-contrastive networks: Self-supervised learning from video.
\newblock In {\em ICRA}, 2018.

\bibitem{Shaw2018}
Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani.
\newblock Self-attention with relative position representations.
\newblock {\em arXiv:1803.02155}, 2018.

\bibitem{Srivastava2014}
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
  Salakhutdinov.
\newblock Dropout: A simple way to prevent neural networks from overfitting.
\newblock {\em The Journal of Machine Learning Research}, 2014.

\bibitem{Srivastava2015b}
N. Srivastava, E. Mansimov, and R. Salakhudinov.
\newblock Unsupervised learning of video representations using {LSTMs}.
\newblock In {\em ICML}, 2015.

\bibitem{Sun2019}
Chen Sun, Fabien Baradel, Kevin Murphy, and Cordelia Schmid.
\newblock Contrastive bidirectional transformer for temporal representation
  learning.
\newblock {\em arXiv:1906.05743}, 2019.

\bibitem{Szegedy2015}
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
  Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
\newblock Going deeper with convolutions.
\newblock In {\em CVPR}, 2015.

\bibitem{inception}
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew
  Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock In {\em CVPR}, 2016.

\bibitem{Tan2021}
Hao Tan, Jie Lei, Thomas Wolf, and Mohit Bansal.
\newblock {VIMPAC}: Video pre-training via masked token prediction and
  contrastive learning.
\newblock {\em arXiv:2106.11250}, 2021.

\bibitem{Tong2022}
Zhan Tong, Yibing Song, Jue Wang, and Limin Wang.
\newblock {VideoMAE}: Masked autoencoders are data-efficient learners for
  self-supervised video pre-training.
\newblock {\em arXiv:2203.12602}, 2022.

\bibitem{Vaswani2017}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, 2017.

\bibitem{Vincent2008}
Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol.
\newblock Extracting and composing robust features with denoising autoencoders.
\newblock In {\em ICML}, 2008.

\bibitem{Vincent2010}
Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, Pierre-Antoine
  Manzagol, and L{\'e}on Bottou.
\newblock Stacked denoising autoencoders: Learning useful representations in a
  deep network with a local denoising criterion.
\newblock {\em JMLR}, 2010.

\bibitem{Vondrick2016}
Carl Vondrick, Hamed Pirsiavash, and Antonio Torralba.
\newblock Anticipating visual representations from unlabelled video.
\newblock In {\em CVPR}, 2016.

\bibitem{Vondrick2018}
Carl Vondrick, Abhinav Shrivastava, Alireza Fathi, Sergio Guadarrama, and Kevin
  Murphy.
\newblock Tracking emerges by colorizing videos.
\newblock In {\em ECCV}, 2018.

\bibitem{Walker2016}
Jacob Walker, Carl Doersch, Abhinav Gupta, and Martial Hebert.
\newblock An uncertain future: Forecasting from static images using variational
  autoencoders.
\newblock In {\em ECCV}, 2016.

\bibitem{Wang2022}
Rui Wang, Dongdong Chen, Zuxuan Wu, Yinpeng Chen, Xiyang Dai, Mengchen Liu,
  Yu-Gang Jiang, Luowei Zhou, and Lu Yuan.
\newblock {BEVT}: {BERT} pretraining of video transformers.
\newblock In {\em CVPR}, 2022.

\bibitem{Wang2018}
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.
\newblock Non-local neural networks.
\newblock In {\em CVPR}, 2018.

\bibitem{Wang2015a}
Xiaolong Wang and Abhinav Gupta.
\newblock Unsupervised learning of visual representations using videos.
\newblock In {\em ICCV}, 2015.

\bibitem{Wang2019a}
Xiaolong Wang, Allan Jabri, and Alexei~A. Efros.
\newblock Learning correspondence from the cycle-consistency of time.
\newblock In {\em CVPR}, 2019.

\bibitem{Wei2021}
Chen Wei, Haoqi Fan, Saining Xie, Chao-Yuan Wu, Alan Yuille, and Christoph
  Feichtenhofer.
\newblock Masked feature prediction for self-supervised visual pre-training.
\newblock {\em arXiv:2112.09133}, 2021.

\bibitem{Wei2018}
Donglai Wei, Joseph~J. Lim, Andrew Zisserman, and William~T. Freeman.
\newblock Learning and using the arrow of time.
\newblock In {\em CVPR}, 2018.

\bibitem{Wiskott2002}
Laurenz Wiskott and Terrence Sejnowski.
\newblock Slow feature analysis: Unsupervised learning of invariances.
\newblock In {\em Neural Computation}, 2002.

\bibitem{Xie2021a}
Zhenda Xie, Zheng Zhang, Yue Cao, Yutong Lin, Jianmin Bao, Zhuliang Yao, Qi
  Dai, and Han Hu.
\newblock {SimMIM}: A simple framework for masked image modeling.
\newblock {\em arXiv:2111.09886}, 2021.

\bibitem{Xu2019}
Dejing Xu, Jun Xiao, Zhou Zhao, Jian Shao, Di Xie, and Yueting Zhuang.
\newblock Self-supervised spatiotemporal learning via video clip order
  prediction.
\newblock In {\em CVPR}, 2019.

\bibitem{Yan2022}
Shen Yan, Xuehan Xiong, Anurag Arnab, Zhichao Lu, Mi Zhang, Chen Sun, and
  Cordelia Schmid.
\newblock Multiview transformers for video recognition.
\newblock {\em arXiv:2201.04288}, 2022.

\bibitem{Yuan2021a}
Lu Yuan, Dongdong Chen, Yi-Ling Chen, Noel Codella, Xiyang Dai, Jianfeng Gao,
  Houdong Hu, Xuedong Huang, Boxin Li, Chunyuan Li, Ce Liu, Mengchen Liu,
  Zicheng Liu, Yumao Lu, Yu Shi, Lijuan Wang, Jianfeng Wang, Bin Xiao, Zhen
  Xiao, Jianwei Yang, Michael Zeng, Luowei Zhou, and Pengchuan Zhang.
\newblock Florence: A new foundation model for computer vision.
\newblock {\em arXiv:2111.11432}, 2021.

\bibitem{Yun2019}
Sangdoo Yun, Dongyoon Han, Seong~Joon Oh, Sanghyuk Chun, Junsuk Choe, and
  Youngjoon Yoo.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In {\em ICCV}, 2019.

\bibitem{Zhang2021}
Bowen Zhang, Jiahui Yu, Christopher Fifty, Wei Han, Andrew~M Dai, Ruoming Pang,
  and Fei Sha.
\newblock Co-training {Transformer} with videos and images improves action
  recognition.
\newblock {\em arXiv:2112.07175}, 2021.

\bibitem{Zhang2018a}
Hongyi Zhang, Moustapha Cisse, Yann~N Dauphin, and David Lopez-Paz.
\newblock {mixup}: Beyond empirical risk minimization.
\newblock In {\em ICLR}, 2018.

\end{thebibliography}
