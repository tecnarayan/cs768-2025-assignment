\begin{thebibliography}{10}

\bibitem{bauer2007regularization}
Frank Bauer, Sergei Pereverzev, and Lorenzo Rosasco.
\newblock On regularization algorithms in learning theory.
\newblock {\em Journal of complexity}, 23(1):52--72, 2007.

\bibitem{belkin2006manifold}
Mikhail Belkin, Partha Niyogi, and Vikas Sindhwani.
\newblock Manifold regularization: A geometric framework for learning from
  labeled and unlabeled examples.
\newblock {\em The Journal of Machine Learning Research}, 7:2399--2434, 2006.

\bibitem{bickel2007discriminative}
Steffen Bickel, Michael Br{\"u}ckner, and Tobias Scheffer.
\newblock Discriminative learning for differing training and test
  distributions.
\newblock In {\em Proceedings of the 24th international conference on Machine
  learning}, pages 81--88. ACM, 2007.

\bibitem{carroll1988optimal}
Raymond~J Carroll and Peter Hall.
\newblock Optimal rates of convergence for deconvolving a density.
\newblock {\em Journal of the American Statistical Association},
  83(404):1184--1186, 1988.

\bibitem{devito2006learning}
Ernesto De~Vito, Lorenzo Rosasco, Andrea Caponnetto, Umberto De~Giovannini, and
  Francesca Odone.
\newblock Learning from examples as an inverse problem.
\newblock {\em Journal of Machine Learning Research}, 6(1):883, 2006.

\bibitem{devito2010spectral}
Ernesto De~Vito, Lorenzo Rosasco, and Alessandro Toigo.
\newblock Spectral regularization for support estimation.
\newblock {\em Advances in Neural Information Processing Systems, NIPS
  Foundation}, pages 1--9, 2010.

\bibitem{egger95}
P.~Eggermont and V.~LaRicca.
\newblock Maximum smoothed likelihood density estimation for inverse problems.
\newblock {\em Annals of Statistics}, 23:199--220, 1995.

\bibitem{gretton2009covariate}
Arthur Gretton, Alex Smola, Jiayuan Huang, Marcel Schmittfull, Karsten
  Borgwardt, and Bernhard Sch{\"o}lkopf.
\newblock Covariate shift by kernel mean matching.
\newblock {\em Dataset shift in machine learning}, pages 131--160, 2009.

\bibitem{grunewalder2012conditional}
S~Gr{\"u}new{\"a}lder, G~Lever, L~Baldassarre, S~Patterson, A~Gretton, and
  M~Pontil.
\newblock Conditional mean embeddings as regressors.
\newblock In {\em Proceedings of the 29th International Conference on Machine
  Learning, ICML 2012}, volume~2, pages 1823--1830, 2012.

\bibitem{huang2006correcting}
Jiayuan Huang, Alexander~J. Smola, Arthur Gretton, Karsten~M. Borgwardt, and
  Bernhard Sch{\"o}lkopf.
\newblock Correcting sample selection bias by unlabeled data.
\newblock In {\em NIPS}, pages 601--608, 2006.

\bibitem{Izenman91}
Alan~Julian Izenman.
\newblock Review papers: Recent developments in nonparametric density
  estimation.
\newblock {\em Journal of the American Statistical Association},
  86(413):205--224, 1991.

\bibitem{InvDensity08}
David Jacho-ChÃ¡vez.
\newblock k nearest-neighbor estimation of inverse density weighted
  expectations.
\newblock {\em Economics Bulletin}, 3(48):1--6, 2008.

\bibitem{kanamori2009least}
Takafumi Kanamori, Shohei Hido, and Masashi Sugiyama.
\newblock A least-squares approach to direct importance estimation.
\newblock {\em The Journal of Machine Learning Research}, 10:1391--1445, 2009.

\bibitem{kim2008robust}
Joo~Seuk Kim and Clayton Scott.
\newblock Robust kernel density estimation.
\newblock In {\em Acoustics, Speech and Signal Processing, 2008. ICASSP 2008.
  IEEE International Conference on}, pages 3381--3384. IEEE, 2008.

\bibitem{kress1999linear}
Rainer Kress.
\newblock {\em Linear integral equations}, volume~82.
\newblock Springer Verlag, 1999.

\bibitem{ImpSampling96}
Jun Liu.
\newblock Metropolized independent sampling with comparisons to rejection
  sampling and importance sampling.
\newblock {\em Statistics and Computing}, 6:113--119, 1996.

\bibitem{neal2001annealed}
Radford~M Neal.
\newblock Annealed importance sampling.
\newblock {\em Statistics and Computing}, 11(2):125--139, 2001.

\bibitem{nguyen2008estimating}
XuanLong Nguyen, Martin~J Wainwright, and Michael~I Jordan.
\newblock Estimating divergence functionals and the likelihood ratio by
  penalized convex risk minimization.
\newblock {\em Advances in neural information processing systems},
  20:1089--1096, 2008.

\bibitem{pan2010survey}
Sinno~Jialin Pan and Qiang Yang.
\newblock A survey on transfer learning.
\newblock {\em Knowledge and Data Engineering, IEEE Transactions on},
  22(10):1345--1359, 2010.

\bibitem{KDE}
E.~Parzen.
\newblock On estimation of a probability density function and mode.
\newblock {\em The Annals of Mathematical Statistics}, 33:1065--1076, 1962.

\bibitem{scholkopf2001learning}
Bernhard Sch{\"o}lkopf and Alexander~J Smola.
\newblock {\em Learning with kernels: Support vector machines, regularization,
  optimization, and beyond}.
\newblock MIT press, 2001.

\bibitem{shawe2004kernel}
John Shawe-Taylor and Nello Cristianini.
\newblock {\em Kernel methods for pattern analysis}.
\newblock Cambridge university press, 2004.

\bibitem{shi2009data}
Tao Shi, Mikhail Belkin, and Bin Yu.
\newblock Data spectroscopy: Eigenspaces of convolution operators and
  clustering.
\newblock {\em The Annals of Statistics}, 37(6B):3960--3984, 2009.

\bibitem{shimodaira2000improving}
Hidetoshi Shimodaira.
\newblock Improving predictive inference under covariate shift by weighting the
  log-likelihood function.
\newblock {\em Journal of Statistical Planning and Inference}, 90(2):227--244,
  2000.

\bibitem{smola1998kernel}
Alex~J Smola and Bernhard Sch{\"o}lkopf.
\newblock On a kernel-based method for pattern recognition, regression,
  approximation, and operator inversion.
\newblock {\em Algorithmica}, 22(1):211--231, 1998.

\bibitem{steinwart2008support}
Ingo Steinwart and Andreas Christmann.
\newblock {\em Support vector machines}.
\newblock Springer, 2008.

\bibitem{Strichartz_lap}
R.~S. Strichartz.
\newblock Analysis of the laplacian on the complete riemannian manifold.
\newblock {\em Journal of Functional Analysis}, 52:48--79, 1983.

\bibitem{sugiyama2007covariate}
Masashi Sugiyama, Matthias Krauledat, and Klaus-Robert M{\"u}ller.
\newblock Covariate shift adaptation by importance weighted cross validation.
\newblock {\em The Journal of Machine Learning Research}, 8:985--1005, 2007.

\bibitem{sugiyama2008direct}
Masashi Sugiyama, Shinichi Nakajima, Hisashi Kashima, Paul Von~Buenau, and
  Motoaki Kawanabe.
\newblock Direct importance estimation with model selection and its application
  to covariate shift adaptation.
\newblock {\em Advances in Neural Information Processing Systems},
  20:1433--1440, 2008.

\bibitem{Taylor_PDE}
M.E. Taylor.
\newblock {\em Partial Differential Equation.}
\newblock Springer, 1997.

\bibitem{vapnik1999support}
Vladimir Vapnik and Sayan Mukherjee.
\newblock Support vector method for multivariate density estimation.
\newblock In {\em NIPS}, pages 659--665, 1999.

\bibitem{wahba1977practical}
Grace Wahba.
\newblock Practical approximate solutions to linear operator equations when the
  data are noisy.
\newblock {\em SIAM Journal on Numerical Analysis}, 14(4):651--667, 1977.

\bibitem{williams2000effect}
Christopher Williams and Matthias Seeger.
\newblock The effect of the input density distribution on kernel-based
  classifiers.
\newblock In {\em Proceedings of the 17th International Conference on Machine
  Learning}. Citeseer, 2000.

\bibitem{yao2007early}
Yuan Yao, Lorenzo Rosasco, and Andrea Caponnetto.
\newblock On early stopping in gradient descent learning.
\newblock {\em Constructive Approximation}, 26(2):289--315, 2007.

\bibitem{yu2012covariate}
Yaoliang Yu and Csaba Szepesv{\'a}ri.
\newblock Analysis of kernel mean matching under covariate shift.
\newblock In {\em ICML}, 2012.

\bibitem{zadrozny2004learning}
Bianca Zadrozny.
\newblock Learning and evaluating classifiers under sample selection bias.
\newblock In {\em Proceedings of the twenty-first international conference on
  Machine learning}, page 114. ACM, 2004.

\end{thebibliography}
