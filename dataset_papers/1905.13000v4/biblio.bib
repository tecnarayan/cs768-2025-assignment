
@techreport{polyak1987introduction,
	title={Introduction to optimization},
	author={Polyak, Boris T},
	year={1987}
}


@article{buhlmann2003boosting,
	title={Boosting with the L 2 loss: regression and classification},
	author={B{\"u}hlmann, Peter and Yu, Bin},
	journal={Journal of the American Statistical Association},
	volume={98},
	number={462},
	pages={324--339},
	year={2003},
	publisher={Taylor \& Francis}
}

@article{soudry2018implicit,
	title={The implicit bias of gradient descent on separable data},
	author={Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
	journal={The Journal of Machine Learning Research},
	volume={19},
	number={1},
	pages={2822--2878},
	year={2018},
	publisher={JMLR. org}
}

@article{zhang2016understanding,
	title={Understanding deep learning requires rethinking generalization},
	author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	journal={arXiv preprint arXiv:1611.03530},
	year={2016}
}


@inproceedings{su2014differential,
	title={A differential equation for modeling Nesterovâ€™s accelerated gradient method: Theory and insights},
	author={Su, Weijie and Boyd, Stephen and Candes, Emmanuel},
	booktitle={Advances in Neural Information Processing Systems},
	pages={2510--2518},
	year={2014}
}


@article{baldassarre2012multi,
	title={Multi-output learning via spectral filtering},
	author={Baldassarre, Luca and Rosasco, Lorenzo and Barla, Annalisa and Verri, Alessandro},
	journal={Machine learning},
	volume={87},
	number={3},
	pages={259--301},
	year={2012},
	publisher={Springer}
}

@article{attouch2019rate,
	title={Rate of convergence of the Nesterov accelerated gradient method in the subcritical case $\alpha\leq 3$},
	author={Attouch, Hedy and Chbani, Zaki and Riahi, Hassan},
	journal={ESAIM: Control, Optimisation and Calculus of Variations},
	volume={25},
	pages={2},
	year={2019},
	publisher={EDP Sciences}
}

@inproceedings{bottou2008tradeoffs,
	title={The tradeoffs of large scale learning},
	author={Bottou, L{\'e}on and Bousquet, Olivier},
	booktitle={Advances in neural information processing systems},
	pages={161--168},
	year={2008}
}


@book{steinwart2008support,
	title={Support vector machines},
	author={Steinwart, Ingo and Christmann, Andreas},
	year={2008},
	publisher={Springer Science \& Business Media}
}

@book{cucker2007learning,
	title={Learning theory: an approximation theory viewpoint},
	author={Cucker, Felipe and Zhou, Ding Xuan},
	volume={24},
	year={2007},
	publisher={Cambridge University Press}
}


@article{ramsay2004functional,
	title={Functional data analysis},
	author={Ramsay, James O},
	journal={Encyclopedia of Statistical Sciences},
	volume={4},
	year={2004},
	publisher={Wiley Online Library}
}

@article{polyak1987introduction,
	title={Introduction to Optimization. Optimization Software},
	author={Polyak, Boris T},
	journal={Inc., Publications Division, New York},
	volume={1},
	year={1987}
}


@book{engl1996regularization,
	title={Regularization of inverse problems},
	author={Engl, Heinz Werner and Hanke, Martin and Neubauer, Andreas},
	volume={375},
	year={1996},
	publisher={Springer Science \& Business Media}
}




@inproceedings{nesterov1983method,
	title={A method for solving the convex programming problem with convergence rate O (1/k\^{} 2)},
	author={Nesterov, Yurii E},
	booktitle={Dokl. akad. nauk Sssr},
	volume={269},
	pages={543--547},
	year={1983}
}




@article{neubauer2017nesterov,
	title={On Nesterov acceleration for Landweber iteration of linear ill-posed problems},
	author={Neubauer, Andreas},
	journal={Journal of Inverse and Ill-posed Problems},
	volume={25},
	number={3},
	pages={381--390},
	year={2017},
	publisher={De Gruyter}
}


@book{szeg1939orthogonal,
	title={Orthogonal polynomials},
	author={Szeg, Gabor},
	volume={23},
	year={1939},
	publisher={American Mathematical Soc.}
}




@Article{Blanchard2018,
	author="Blanchard, Gilles
	and M{\"u}cke, Nicole",
	title="Optimal Rates for Regularization of Statistical Inverse Learning Problems",
	journal="Foundations of Computational Mathematics",
	year="2018",
	month="Aug",
	day="01",
	volume="18",
	number="4",
	pages="971--1013",
	abstract="We consider a statistical inverse learning (also called inverse regression) problem, where we observe the image of a function f through a linear operator A at i.i.d. random design points {\$}{\$}X{\_}i{\$}{\$}Xi, superposed with an additive noise. The distribution of the design points is unknown and can be very general. We analyze simultaneously the direct (estimation of Af) and the inverse (estimation of f) learning problems. In this general framework, we obtain strong and weak minimax optimal rates of convergence (as the number of observations n grows large) for a large class of spectral regularization methods over regularity classes defined through appropriate source conditions. This improves on or completes previous results obtained in related settings. The optimality of the obtained rates is shown not only in the exponent in n but also in the explicit dependency of the constant factor in the variance of the noise and the radius of the source condition set.",
	issn="1615-3383",
	doi="10.1007/s10208-017-9359-7",
	url="https://doi.org/10.1007/s10208-017-9359-7"
}




@article{lin2018optimal,
	title={Optimal convergence for distributed learning with stochastic gradient methods and spectral-regularization algorithms},
	author={Lin, Junhong and Cevher, Volkan},
	journal={stat},
	volume={1050},
	pages={22},
	year={2018}
}


@inproceedings{ghadimi2015global,
	title={Global convergence of the heavy-ball method for convex optimization},
	author={Ghadimi, Euhanna and Feyzmahdavian, Hamid Reza and Johansson, Mikael},
	booktitle={2015 European Control Conference (ECC)},
	pages={310--315},
	year={2015},
	organization={IEEE}
}


@article{lessard2016analysis,
	title={Analysis and design of optimization algorithms via integral quadratic constraints},
	author={Lessard, Laurent and Recht, Benjamin and Packard, Andrew},
	journal={SIAM Journal on Optimization},
	volume={26},
	number={1},
	pages={57--95},
	year={2016},
	publisher={SIAM}
}


@article{wang2013scaled,
	title={Scaled heavy-ball acceleration of the Richardson-Lucy algorithm for 3D microscopy image restoration},
	author={Wang, Hongbin and Miller, Paul C},
	journal={IEEE Transactions on Image Processing},
	volume={23},
	number={2},
	pages={848--854},
	year={2013},
	publisher={IEEE}
}

@inproceedings{scieur2017integration,
	title={Integration methods and optimization algorithms},
	author={Scieur, Damien and Roulet, Vincent and Bach, Francis and d'Aspremont, Alexandre},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1109--1118},
	year={2017}
}

@inproceedings{kidambi2018insufficiency,
	title={On the insufficiency of existing momentum schemes for stochastic optimization},
	author={Kidambi, Rahul and Netrapalli, Praneeth and Jain, Prateek and Kakade, Sham},
	booktitle={2018 Information Theory and Applications Workshop (ITA)},
	pages={1--9},
	year={2018},
	organization={IEEE}
}

@article{basu2018convergence,
	title={Convergence guarantees for rmsprop and adam in non-convex optimization and their comparison to nesterov acceleration on autoencoders},
	author={Basu, Amitabh and De, Soham and Mukherjee, Anirbit and Ullah, Enayat},
	journal={arXiv preprint arXiv:1807.06766},
	year={2018}
}

@inproceedings{wilson2017marginal,
	title={The marginal value of adaptive gradient methods in machine learning},
	author={Wilson, Ashia C and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nati and Recht, Benjamin},
	booktitle={Advances in Neural Information Processing Systems},
	pages={4148--4158},
	year={2017}
}

@article{xie2018interpolatron,
	title={Interpolatron: Interpolation or extrapolation schemes to accelerate optimization for deep neural networks},
	author={Xie, Guangzeng and Wang, Yitan and Zhou, Shuchang and Zhang, Zhihua},
	journal={arXiv preprint arXiv:1805.06753},
	year={2018}
}

@article{yang2016unified,
	title={Unified convergence analysis of stochastic momentum methods for convex and non-convex optimization},
	author={Yang, Tianbao and Lin, Qihang and Li, Zhe},
	journal={arXiv preprint arXiv:1604.03257},
	year={2016}
}


@article{devolder2014first,
	title={First-order methods of smooth convex optimization with inexact oracle},
	author={Devolder, Olivier and Glineur, Fran{\c{c}}ois and Nesterov, Yurii},
	journal={Mathematical Programming},
	volume={146},
	number={1-2},
	pages={37--75},
	year={2014},
	publisher={Springer}
}

@article{caponnetto2007optimal,
	title={Optimal rates for the regularized least-squares algorithm},
	author={Caponnetto, Andrea and De Vito, Ernesto},
	journal={Foundations of Computational Mathematics},
	volume={7},
	number={3},
	pages={331--368},
	year={2007},
	publisher={Springer}
}


@article{bousquet2002stability,
	title={Stability and generalization},
	author={Bousquet, Olivier and Elisseeff, Andr{\'e}},
	journal={Journal of machine learning research},
	volume={2},
	number={Mar},
	pages={499--526},
	year={2002}
}


@article{chen2018stability,
	title={Stability and convergence trade-off of iterative optimization algorithms},
	author={Chen, Yuansi and Jin, Chi and Yu, Bin},
	journal={arXiv preprint arXiv:1804.01619},
	year={2018}
}


@incollection{lecun2012efficient,
	title={Efficient backprop},
	author={LeCun, Yann A and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
	booktitle={Neural networks: Tricks of the trade},
	pages={9--48},
	year={2012},
	publisher={Springer}
}

@article{lin2018optimal_spectral,
	title={Optimal rates for spectral algorithms with least-squares regression over hilbert spaces},
	author={Lin, Junhong and Rudi, Alessandro and Rosasco, Lorenzo and Cevher, Volkan},
	journal={Applied and Computational Harmonic Analysis},
	year={2018},
	publisher={Elsevier}
}

@inproceedings{rosasco2015learning,
	title={Learning with incremental iterative regularization},
	author={Rosasco, Lorenzo and Villa, Silvia},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1630--1638},
	year={2015}
}


@article{charles2017stability,
	title={Stability and generalization of learning algorithms that converge to global optima},
	author={Charles, Zachary and Papailiopoulos, Dimitris},
	journal={arXiv preprint arXiv:1710.08402},
	year={2017}
}

@inproceedings{lin2016optimal,
	title={Optimal learning for multi-pass stochastic gradient methods},
	author={Lin, Junhong and Rosasco, Lorenzo},
	booktitle={Advances in Neural Information Processing Systems},
	pages={4556--4564},
	year={2016}
}

@article{hardt2015train,
	title={Train faster, generalize better: Stability of stochastic gradient descent},
	author={Hardt, Moritz and Recht, Benjamin and Singer, Yoram},
	journal={arXiv preprint arXiv:1509.01240},
	year={2015}
}

@article{matet2017don,
	title={Don't relax: early stopping for convex regularization},
	author={Matet, Simon and Rosasco, Lorenzo and Villa, Silvia and Vu, Bang Long},
	journal={arXiv preprint arXiv:1707.05422},
	year={2017}
}

@article{yao2007early,
	title={On early stopping in gradient descent learning},
	author={Yao, Yuan and Rosasco, Lorenzo and Caponnetto, Andrea},
	journal={Constructive Approximation},
	volume={26},
	number={2},
	pages={289--315},
	year={2007},
	publisher={Springer}
}


@article{fujii1993norm,
	title={Norm inequalities equivalent to Heinz inequality},
	author={Fujii, Junichi and Fujii, Masatoshi and Furuta, Takayuki and Nakamoto, Ritsuo},
	journal={Proceedings of the American Mathematical Society},
	volume={118},
	number={3},
	pages={827--830},
	year={1993}
}


@article{zavriev1993heavy,
	title={Heavy-ball method in nonconvex optimization problems},
	author={Zavriev, SK and Kostyuk, FV},
	journal={Computational Mathematics and Modeling},
	volume={4},
	number={4},
	pages={336--341},
	year={1993},
	publisher={Springer}
}


@article{mathe2006regularization,
	title={Regularization of some linear ill-posed problems with discretized random noisy data},
	author={Math{\'e}, Peter and Pereverzev, Sergei},
	journal={Mathematics of Computation},
	volume={75},
	number={256},
	pages={1913--1929},
	year={2006}
}


@inproceedings{lin2016generalization,
	title={Generalization properties and implicit regularization for multiple passes SGM},
	author={Lin, Junhong and Camoriano, Raffaello and Rosasco, Lorenzo},
	booktitle={International Conference on Machine Learning},
	pages={2340--2348},
	year={2016}
}


@inproceedings{gunasekar2018implicit,
	title={Implicit bias of gradient descent on linear convolutional networks},
	author={Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
	booktitle={Advances in Neural Information Processing Systems},
	pages={9461--9471},
	year={2018}
}


@article{soudry2018implicit,
	title={The implicit bias of gradient descent on separable data},
	author={Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
	journal={The Journal of Machine Learning Research},
	volume={19},
	number={1},
	pages={2822--2878},
	year={2018},
	publisher={JMLR. org}
}

@article{devolder2014first,
	title={First-order methods of smooth convex optimization with inexact oracle},
	author={Devolder, Olivier and Glineur, Fran{\c{c}}ois and Nesterov, Yurii},
	journal={Mathematical Programming},
	volume={146},
	number={1-2},
	pages={37--75},
	year={2014},
	publisher={Springer}
}


@article{raskutti2014early,
	title={Early stopping and non-parametric regression: an optimal data-dependent stopping rule},
	author={Raskutti, Garvesh and Wainwright, Martin J and Yu, Bin},
	journal={The Journal of Machine Learning Research},
	volume={15},
	number={1},
	pages={335--366},
	year={2014},
	publisher={JMLR. org}
}


@article{mathe2002moduli,
	title={Moduli of continuity for operator valued functions},
	author={Math{\'e}, Peter and Pereverzev, Sergei V},
	journal={Numerical Functional Analysis and Optimization},
	volume={23},
	number={5-6},
	pages={623--631},
	year={2002},
	publisher={Taylor \& Francis}
}