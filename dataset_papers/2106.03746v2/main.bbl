\begin{thebibliography}{10}

\bibitem{DBLP:conf/iclr/AsanoRV20a}
Yuki~Markus Asano, Christian Rupprecht, and Andrea Vedaldi.
\newblock Self-labelling via simultaneous clustering and representation
  learning.
\newblock In {\em ICLR}, 2020.

\bibitem{VICReg}
Adrien Bardes, Jean Ponce, and Yann LeCun.
\newblock {VICReg}: Variance-invariance-covariance regularization for
  self-supervised learning.
\newblock {\em arXiv:2105.04906}, 2021.

\bibitem{NIPS2016_65fc52ed}
Miguel~A Bautista, Artsiom Sanakoyeu, Ekaterina Tikhoncheva, and Bjorn Ommer.
\newblock {CliqueCNN:} deep unsupervised exemplar learning.
\newblock In {\em NeurIPS}, 2016.

\bibitem{cai2018cascade}
Zhaowei Cai and Nuno Vasconcelos.
\newblock Cascade {R-CNN}: Delving into high quality object detection.
\newblock In {\em CVPR}, 2018.

\bibitem{DETR}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em ECCV}, 2020.

\bibitem{DeepClustering}
Mathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze.
\newblock Deep clustering for unsupervised learning of visual features.
\newblock In {\em ECCV}, 2018.

\bibitem{SwAV}
Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, and
  Armand Joulin.
\newblock Unsupervised learning of visual features by contrasting cluster
  assignments.
\newblock In {\em NeurIPS}, 2020.

\bibitem{DINO}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv{\'{e}} J{\'{e}}gou, Julien
  Mairal, Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock {\em arXiv:2104.14294}, 2021.

\bibitem{iGPT}
Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and
  Ilya Sutskever.
\newblock Generative pretraining from pixels.
\newblock In {\em ICML}, 2020.

\bibitem{simclr}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey~E. Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In {\em ICML}, 2020.

\bibitem{simsiam}
Xinlei Chen and Kaiming He.
\newblock Exploring simple siamese representation learning.
\newblock In {\em CVPR}, 2021.

\bibitem{DBLP:journals/corr/abs-2104-02057}
Xinlei Chen, Saining Xie, and Kaiming He.
\newblock An empirical study of training self-supervised vision transformers.
\newblock {\em ICCV}, 2021.

\bibitem{ELECTRA}
Kevin Clark, Minh-Thang Luong, Quoc~V. Le, and Christopher~D. Manning.
\newblock {ELECTRA: P}re-training text encoders as discriminators rather than
  generators.
\newblock In {\em ICLR}, 2020.

\bibitem{contributors2020mmcv}
MMCV Contributors.
\newblock Openmmlab foundational library for computer vision research, 2020.

\bibitem{DBLP:journals/corr/abs-2009-09796}
Michael Crawshaw.
\newblock Multi-task learning with deep neural networks: {A} survey.
\newblock {\em arXiv:2009.09796}, 2020.

\bibitem{UP-DETR}
Zhigang Dai, Bolun Cai, Yugeng Lin, and Junying Chen.
\newblock {UP-DETR:} unsupervised pre-training for object detection with
  transformers.
\newblock In {\em CVPR}, 2021.

\bibitem{devlin-etal-2019-bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em NAACL,}, 2019.

\bibitem{doersch2015unsupervised}
Carl Doersch, Abhinav Gupta, and Alexei~A Efros.
\newblock Unsupervised visual representation learning by context prediction.
\newblock In {\em ICCV}, 2015.

\bibitem{ViT}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em ICLR}, 2021.

\bibitem{DBLP:conf/cvpr/DwibediATSZ19}
Debidatta Dwibedi, Yusuf Aytar, Jonathan Tompson, Pierre Sermanet, and Andrew
  Zisserman.
\newblock Temporal cycle-consistency learning.
\newblock In {\em CVPR}, 2019.

\bibitem{little-friends}
Debidatta Dwibedi, Yusuf Aytar, Jonathan Tompson, Pierre Sermanet, and Andrew
  Zisserman.
\newblock With a little help from my friends: Nearest-neighbor contrastive
  learning of visual representations.
\newblock In {\em ICCV}, 2021.

\bibitem{w-mse}
Aleksandr Ermolov, Aliaksandr Siarohin, Enver Sangineto, and Nicu Sebe.
\newblock Whitening for self-supervised representation learning.
\newblock In {\em ICML}, 2021.

\bibitem{DBLP:conf/eccv/GansbekeVGPG20}
Wouter~Van Gansbeke, Simon Vandenhende, Stamatios Georgoulis, Marc Proesmans,
  and Luc~Van Gool.
\newblock {SCAN:} learning to classify images without labels.
\newblock In {\em ECCV}, 2020.

\bibitem{RotNet}
Spyros Gidaris, Praveer Singh, and Nikos Komodakis.
\newblock Unsupervised representation learning by predicting image rotations.
\newblock In {\em ICLR}, 2018.

\bibitem{byol}
Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre~H.
  Richemond, Elena Buchatskaya, Carl Doersch, Bernardo~Avila Pires,
  Zhaohan~Daniel Guo, Mohammad~Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu,
  Rémi Munos, and Michal Valko.
\newblock Bootstrap your own latent: A new approach to self-supervised
  learning.
\newblock In {\em NeurIPS}, 2020.

\bibitem{MoCo}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In {\em CVPR}, 2020.

\bibitem{he2017mask}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Mask {R-CNN}.
\newblock In {\em ICCV}, 2017.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{DIM}
R.~Devon Hjelm, Alex Fedorov, Samuel Lavoie{-}Marchildon, Karan Grewal, Philip
  Bachman, Adam Trischler, and Yoshua Bengio.
\newblock Learning deep representations by mutual information estimation and
  maximization.
\newblock In {\em ICLR}, 2019.

\bibitem{DBLP:conf/iccv/HuZXL19}
Han Hu, Zheng Zhang, Zhenda Xie, and Stephen Lin.
\newblock Local relation networks for image recognition.
\newblock In {\em ICCV}, 2019.

\bibitem{hua2021feature}
Tianyu Hua, Wenxiao Wang, Zihui Xue, Yue Wang, Sucheng Ren, and Hang Zhao.
\newblock On feature decorrelation in self-supervised learning.
\newblock {\em arXiv:2105.00470}, 2021.

\bibitem{GAT}
Drew~A. Hudson and C.~Lawrence Zitnick.
\newblock {Generative Adversarial Transformers}.
\newblock In {\em ICML}, 2021.

\bibitem{IIC}
Xu~Ji, Jo{\~{a}}o~F. Henriques, and Andrea Vedaldi.
\newblock Invariant information clustering for unsupervised image
  classification and segmentation.
\newblock In {\em ICCV}, 2019.

\bibitem{TransGAN}
Yifan Jiang, Shiyu Chang, and Zhangyang Wang.
\newblock {TransGAN}: Two transformers can make one strong {GAN}.
\newblock {\em arXiv:2102.07074}, 2021.

\bibitem{cifar}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{CornerNet}
Hei Law and Jia Deng.
\newblock Cornernet: Detecting objects as paired keypoints.
\newblock {\em Int. J. Comput. Vis.}, 128(3):642--656, 2020.

\bibitem{LocalViT}
Yawei Li, Kai Zhang, Jiezhang Cao, Radu Timofte, and Luc~Van Gool.
\newblock {LocalViT}: Bringing locality to vision transformers.
\newblock {\em arXiv:2104.05707}, 2021.

\bibitem{DetNet}
Zeming Li, Chao Peng, Gang Yu, Xiangyu Zhang, Yangdong Deng, and Jian Sun.
\newblock Detnet: Design backbone for object detection.
\newblock In {\em ECCV}, 2018.

\bibitem{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft {COCO}: Common objects in context.
\newblock In {\em ECCV}, 2014.

\bibitem{Swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock {\em arXiv:2103.14030}, 2021.

\bibitem{loshchilov2017decoupled}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock {\em arXiv:1711.05101}, 2017.

\bibitem{TrackFormer}
Tim Meinhardt, Alexander Kirillov, Laura Leal{-}Taix{\'{e}}, and Christoph
  Feichtenhofer.
\newblock {TrackFormer}: Multi-object tracking with transformers.
\newblock {\em arXiv:2101.02702}, 2021.

\bibitem{DBLP:journals/corr/abs-1301-3781}
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.
\newblock Efficient estimation of word representations in vector space.
\newblock {\em arXiv:1301.3781}, 2013.

\bibitem{DBLP:conf/nips/MikolovSCCD13}
Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory~S. Corrado, and Jeffrey Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In {\em NeurIPS}, 2013.

\bibitem{misra2019selfsupervised}
Ishan Misra and Laurens van~der Maaten.
\newblock Self-supervised learning of pretext-invariant representations.
\newblock In {\em CVPR}, 2020.

\bibitem{DBLP:journals/corr/abs-2105-10497}
Muzammal Naseer, Kanchana Ranasinghe, Salman~H. Khan, Munawar Hayat,
  Fahad~Shahbaz Khan, and Ming{-}Hsuan Yang.
\newblock Intriguing properties of vision transformers.
\newblock {\em arXiv:2105.10497}, 2021.

\bibitem{netzer2011reading}
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo~Wu, and Andrew~Y
  Ng.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In {\em NeurIPS Workshop on Deep Learning and Unsupervised Feature
  Learning}, 2011.

\bibitem{flower}
Maria-Elena Nilsback and Andrew Zisserman.
\newblock Automated flower classification over a large number of classes.
\newblock In {\em Indian Conference on Computer Vision, Graphics \& Image
  Processing}, 2008.

\bibitem{noroozi2016unsupervised}
Mehdi Noroozi and Paolo Favaro.
\newblock Unsupervised learning of visual representations by solving jigsaw
  puzzles.
\newblock In {\em ECCV}, 2016.

\bibitem{noroozi2017representation}
Mehdi Noroozi, Hamed Pirsiavash, and Paolo Favaro.
\newblock Representation learning by learning to count.
\newblock In {\em ICCV}, 2017.

\bibitem{peng2019moment}
Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo~Wang.
\newblock Moment matching for multi-source domain adaptation.
\newblock In {\em CVPR}, 2019.

\bibitem{Radford2018ImprovingLU}
Alec Radford and Karthik Narasimhan.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem{DBLP:journals/jmlr/RaffelSRLNMZLL20}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J. Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock {\em Journal of Machine Learning Research}, 21:140:1--140:67, 2020.

\bibitem{DBLP:journals/corr/abs-2108-08810}
Maithra Raghu, Thomas Unterthiner, Simon Kornblith, Chiyuan Zhang, and Alexey
  Dosovitskiy.
\newblock Do vision transformers see like convolutional neural networks?
\newblock {\em arXiv:2108.08810}, 2021.

\bibitem{imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock {\em International Journal of Computer Vision}, 115(3):211--252,
  2015.

\bibitem{DBLP:conf/naacl/ShawUV18}
Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani.
\newblock Self-attention with relative position representations.
\newblock In {\em NAACL}, 2018.

\bibitem{strudel2021segmenter}
Robin Strudel, Ricardo Garcia, Ivan Laptev, and Cordelia Schmid.
\newblock Segmenter: Transformer for semantic segmentation.
\newblock In {\em ICCV}, 2021.

\bibitem{VideoBERT}
Chen Sun, Austin Myers, Carl Vondrick, Kevin Murphy, and Cordelia Schmid.
\newblock {VideoBERT:} {A} joint model for video and language representation
  learning.
\newblock In {\em ICCV}, 2019.

\bibitem{sun2020sparsercnn}
Peize Sun, Rufeng Zhang, Yi~Jiang, Tao Kong, Chenfeng Xu, Wei Zhan, Masayoshi
  Tomizuka, Lei Li, Zehuan Yuan, Changhu Wang, et~al.
\newblock {Sparse R-CNN}: End-to-end object detection with learnable proposals.
\newblock {\em arXiv:2011.12450}, 2020.

\bibitem{tian2019contrastive}
Yonglong Tian, Dilip Krishnan, and Phillip Isola.
\newblock Contrastive multiview coding.
\newblock In {\em ECCV}, 2020.

\bibitem{DeiT}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv{\'e} J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock {\em arXiv:2012.12877}, 2020.

\bibitem{CPC}
A{\"{a}}ron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock {\em arXiv:1807.03748}, 2018.

\bibitem{attention-is-all-you-need}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, 2017.

\bibitem{wang2020understanding}
Tongzhou Wang and Phillip Isola.
\newblock Understanding contrastive representation learning through alignment
  and uniformity on the hypersphere.
\newblock In {\em ICML}, 2020.

\bibitem{non-local-net}
Xiaolong Wang, Ross~B. Girshick, Abhinav Gupta, and Kaiming He.
\newblock Non-local neural networks.
\newblock In {\em CVPR}, 2018.

\bibitem{CvT}
Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu~Yuan, and Lei
  Zhang.
\newblock {CvT}: Introducing convolutions to vision transformers.
\newblock {\em arXiv:2103.15808}, 2021.

\bibitem{xiao2018unified}
Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, and Jian Sun.
\newblock Unified perceptual parsing for scene understanding.
\newblock In {\em ECCV}, 2018.

\bibitem{CoaT}
Weijian Xu, Yifan Xu, Tyler Chang, and Zhuowen Tu.
\newblock Co-scale conv-attentional image transformers.
\newblock {\em arXiv:2104.06399}, 2021.

\bibitem{CeiT}
Kun Yuan, Shaopeng Guo, Ziwei Liu, Aojun Zhou, Fengwei Yu, and Wei Wu.
\newblock Incorporating convolution designs into visual transformers.
\newblock {\em arXiv:2103.11816}, 2021.

\bibitem{T2T}
Li~Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Zihang Jiang, Francis~EH
  Tay, Jiashi Feng, and Shuicheng Yan.
\newblock Tokens-to-token {ViT}: Training vision transformers from scratch on
  {ImageNet}.
\newblock In {\em ICCV}, 2021.

\bibitem{CutMix}
Sangdoo Yun, Dongyoon Han, Sanghyuk Chun, Seong~Joon Oh, Youngjoon Yoo, and
  Junsuk Choe.
\newblock {CutMix: R}egularization strategy to train strong classifiers with
  localizable features.
\newblock In {\em ICCV}, 2019.

\bibitem{barlow}
Jure Zbontar, Li~Jing, Ishan Misra, Yann LeCun, and St{\'{e}}phane Deny.
\newblock Barlow twins: Self-supervised learning via redundancy reduction.
\newblock In {\em ICML}, 2021.

\bibitem{mixup}
Hongyi Zhang, Moustapha Ciss{\'{e}}, Yann~N. Dauphin, and David Lopez{-}Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock In {\em ICLR}, 2018.

\bibitem{PointTransformer}
Hengshuang Zhao, Li~Jiang, Jiaya Jia, Philip H.~S. Torr, and Vladlen Koltun.
\newblock Point transformer.
\newblock {\em arXiv:2012.09164}, 2020.

\bibitem{zhou2019semantic}
Bolei Zhou, Hang Zhao, Xavier Puig, Tete Xiao, Sanja Fidler, Adela Barriuso,
  and Antonio Torralba.
\newblock Semantic understanding of scenes through the ade20k dataset.
\newblock {\em International Journal of Computer Vision}, 127(3):302--321,
  2019.

\bibitem{Deformable-DETR}
Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai.
\newblock Deformable {DETR}: Deformable transformers for end-to-end object
  detection.
\newblock In {\em ICLR}, 2021.

\bibitem{DBLP:journals/corr/abs-1903-12355}
Chengxu Zhuang, Alex~Lin Zhai, and Daniel Yamins.
\newblock Local aggregation for unsupervised learning of visual embeddings.
\newblock In {\em ICCV}, 2019.

\end{thebibliography}
