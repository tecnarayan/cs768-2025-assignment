\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alain and Bengio(2016)]{alain2016understanding}
G.~Alain and Y.~Bengio.
\newblock Understanding intermediate layers using linear classifier probes.
\newblock \emph{arXiv preprint arXiv:1610.01644}, 2016.

\bibitem[Bello et~al.(2019)Bello, Zoph, Vaswani, Shlens, and
  Le]{bello2019attention}
I.~Bello, B.~Zoph, A.~Vaswani, J.~Shlens, and Q.~V. Le.
\newblock Attention augmented convolutional networks.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 3286--3295, 2019.

\bibitem[Bhojanapalli et~al.(2021)Bhojanapalli, Chakrabarti, Glasner, Li,
  Unterthiner, and Veit]{bhojanapalli2021understanding}
S.~Bhojanapalli, A.~Chakrabarti, D.~Glasner, D.~Li, T.~Unterthiner, and
  A.~Veit.
\newblock Understanding robustness of transformers for image classification.
\newblock \emph{arXiv preprint arXiv:2103.14586}, 2021.

\bibitem[Carion et~al.(2020)Carion, Massa, Synnaeve, Usunier, Kirillov, and
  Zagoruyko]{carion2020end}
N.~Carion, F.~Massa, G.~Synnaeve, N.~Usunier, A.~Kirillov, and S.~Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In \emph{European Conference on Computer Vision}, pages 213--229.
  Springer, 2020.

\bibitem[Caron et~al.(2021)Caron, Touvron, Misra, J{\'e}gou, Mairal,
  Bojanowski, and Joulin]{caron2021emerging}
M.~Caron, H.~Touvron, I.~Misra, H.~J{\'e}gou, J.~Mairal, P.~Bojanowski, and
  A.~Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock \emph{arXiv preprint arXiv:2104.14294}, 2021.

\bibitem[Chen et~al.(2020)Chen, Radford, Child, Wu, Jun, Luan, and
  Sutskever]{chen2020generative}
M.~Chen, A.~Radford, R.~Child, J.~Wu, H.~Jun, D.~Luan, and I.~Sutskever.
\newblock Generative pretraining from pixels.
\newblock In \emph{International Conference on Machine Learning}, pages
  1691--1703. PMLR, 2020.

\bibitem[Chen et~al.(2021)Chen, Xie, and He]{chen2021empirical}
X.~Chen, S.~Xie, and K.~He.
\newblock An empirical study of training self-supervised vision transformers.
\newblock \emph{arXiv preprint arXiv:2104.02057}, 2021.

\bibitem[Conneau et~al.(2018)Conneau, Kruszewski, Lample, Barrault, and
  Baroni]{conneau2018you}
A.~Conneau, G.~Kruszewski, G.~Lample, L.~Barrault, and M.~Baroni.
\newblock What you can cram into a single vector: Probing sentence embeddings
  for linguistic properties.
\newblock In \emph{ACL}, 2018.

\bibitem[Cordonnier et~al.(2019)Cordonnier, Loukas, and
  Jaggi]{cordonnier2019relationship}
J.-B. Cordonnier, A.~Loukas, and M.~Jaggi.
\newblock On the relationship between self-attention and convolutional layers.
\newblock \emph{arXiv preprint arXiv:1911.03584}, 2019.

\bibitem[Cortes et~al.(2012)Cortes, Mohri, and
  Rostamizadeh]{cortes2012algorithms}
C.~Cortes, M.~Mohri, and A.~Rostamizadeh.
\newblock Algorithms for learning kernels based on centered alignment.
\newblock \emph{The Journal of Machine Learning Research}, 13\penalty0
  (1):\penalty0 795--828, 2012.

\bibitem[d'Ascoli et~al.(2021)d'Ascoli, Touvron, Leavitt, Morcos, Biroli, and
  Sagun]{d2021convit}
S.~d'Ascoli, H.~Touvron, M.~Leavitt, A.~Morcos, G.~Biroli, and L.~Sagun.
\newblock Convit: Improving vision transformers with soft convolutional
  inductive biases.
\newblock \emph{arXiv preprint arXiv:2103.10697}, 2021.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Gretton et~al.(2007)Gretton, Fukumizu, Teo, Song, Sch{\"o}lkopf,
  Smola, et~al.]{gretton2007kernel}
A.~Gretton, K.~Fukumizu, C.~H. Teo, L.~Song, B.~Sch{\"o}lkopf, A.~J. Smola,
  et~al.
\newblock A kernel statistical test of independence.
\newblock In \emph{Nips}, volume~20, pages 585--592. Citeseer, 2007.

\bibitem[Kolesnikov et~al.(2019)Kolesnikov, Beyer, Zhai, Puigcerver, Yung,
  Gelly, and Houlsby]{kolesnikov2019big}
A.~Kolesnikov, L.~Beyer, X.~Zhai, J.~Puigcerver, J.~Yung, S.~Gelly, and
  N.~Houlsby.
\newblock Big transfer (bit): General visual representation learning.
\newblock \emph{arXiv preprint arXiv:1912.11370}, 6\penalty0 (2):\penalty0 8,
  2019.

\bibitem[Kornblith et~al.(2019)Kornblith, Norouzi, Lee, and
  Hinton]{kornblith2019similarity}
S.~Kornblith, M.~Norouzi, H.~Lee, and G.~Hinton.
\newblock Similarity of neural network representations revisited.
\newblock In \emph{ICML}, 2019.

\bibitem[Kornblith et~al.(2020)Kornblith, Lee, Chen, and
  Norouzi]{kornblith2020s}
S.~Kornblith, H.~Lee, T.~Chen, and M.~Norouzi.
\newblock What's in a loss function for image classification?
\newblock \emph{arXiv preprint arXiv:2010.16402}, 2020.

\bibitem[Kriegeskorte et~al.(2008)Kriegeskorte, Mur, and
  Bandettini]{kriegeskorte2008representational}
N.~Kriegeskorte, M.~Mur, and P.~A. Bandettini.
\newblock Representational similarity analysis-connecting the branches of
  systems neuroscience.
\newblock \emph{Frontiers in systems neuroscience}, 2:\penalty0 4, 2008.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Advances in neural information processing systems},
  25:\penalty0 1097--1105, 2012.

\bibitem[Kudugunta et~al.(2019)Kudugunta, Bapna, Caswell, Arivazhagan, and
  Firat]{kudugunta2019investigating}
S.~R. Kudugunta, A.~Bapna, I.~Caswell, N.~Arivazhagan, and O.~Firat.
\newblock Investigating multilingual nmt representations at scale.
\newblock \emph{arXiv preprint arXiv:1909.02197}, 2019.

\bibitem[Lindsay(2020)]{lindsay2020convolutional}
G.~W. Lindsay.
\newblock Convolutional neural networks as a model of the visual system: past,
  present, and future.
\newblock \emph{Journal of cognitive neuroscience}, pages 1--15, 2020.

\bibitem[Luo et~al.(2017)Luo, Li, Urtasun, and Zemel]{luo2017understanding}
W.~Luo, Y.~Li, R.~Urtasun, and R.~Zemel.
\newblock Understanding the effective receptive field in deep convolutional
  neural networks.
\newblock \emph{arXiv preprint arXiv:1701.04128}, 2017.

\bibitem[Maheswaranathan et~al.(2019)Maheswaranathan, Williams, Golub, Ganguli,
  and Sussillo]{maheswaranathan2019universality}
N.~Maheswaranathan, A.~H. Williams, M.~D. Golub, S.~Ganguli, and D.~Sussillo.
\newblock Universality and individuality in neural dynamics across large
  populations of recurrent networks.
\newblock \emph{Advances in neural information processing systems},
  2019:\penalty0 15629, 2019.

\bibitem[Merchant et~al.(2020)Merchant, Rahimtoroghi, Pavlick, and
  Tenney]{merchant2020happens}
A.~Merchant, E.~Rahimtoroghi, E.~Pavlick, and I.~Tenney.
\newblock What happens to bert embeddings during fine-tuning?
\newblock \emph{arXiv preprint arXiv:2004.14448}, 2020.

\bibitem[Morcos et~al.(2018)Morcos, Raghu, and Bengio]{morcos2018insights}
A.~S. Morcos, M.~Raghu, and S.~Bengio.
\newblock Insights on representational similarity in neural networks with
  canonical correlation.
\newblock \emph{arXiv preprint arXiv:1806.05759}, 2018.

\bibitem[Mustafa et~al.(2021)Mustafa, Loh, Freyberg, MacWilliams, Wilson,
  McKinney, Sieniek, Winkens, Liu, Bui, et~al.]{mustafa2021supervised}
B.~Mustafa, A.~Loh, J.~Freyberg, P.~MacWilliams, M.~Wilson, S.~M. McKinney,
  M.~Sieniek, J.~Winkens, Y.~Liu, P.~Bui, et~al.
\newblock Supervised transfer learning at scale for medical imaging.
\newblock \emph{arXiv preprint arXiv:2101.05913}, 2021.

\bibitem[Naseer et~al.(2021)Naseer, Ranasinghe, Khan, Hayat, Khan, and
  Yang]{naseer2021intriguing}
M.~Naseer, K.~Ranasinghe, S.~Khan, M.~Hayat, F.~S. Khan, and M.-H. Yang.
\newblock Intriguing properties of vision transformers, 2021.

\bibitem[Nguyen et~al.(2020)Nguyen, Raghu, and Kornblith]{nguyen2020wide}
T.~Nguyen, M.~Raghu, and S.~Kornblith.
\newblock Do wide and deep networks learn the same things? uncovering how
  neural network representations vary with width and depth.
\newblock \emph{arXiv preprint arXiv:2010.15327}, 2020.

\bibitem[Parmar et~al.(2018)Parmar, Vaswani, Uszkoreit, Kaiser, Shazeer, Ku,
  and Tran]{parmar2018image}
N.~Parmar, A.~Vaswani, J.~Uszkoreit, L.~Kaiser, N.~Shazeer, A.~Ku, and D.~Tran.
\newblock Image transformer.
\newblock In \emph{International Conference on Machine Learning}, pages
  4055--4064. PMLR, 2018.

\bibitem[Paul and Chen(2021)]{paul2021vision}
S.~Paul and P.-Y. Chen.
\newblock Vision transformers are robust learners.
\newblock \emph{arXiv preprint arXiv:2105.07581}, 2021.

\bibitem[Peters et~al.(2018)Peters, Neumann, Zettlemoyer, and
  Yih]{peters2018dissecting}
M.~E. Peters, M.~Neumann, L.~Zettlemoyer, and W.-t. Yih.
\newblock Dissecting contextual word embeddings: Architecture and
  representation.
\newblock In \emph{EMNLP}, 2018.

\bibitem[Raghu et~al.(2019{\natexlab{a}})Raghu, Raghu, Bengio, and
  Vinyals]{raghu2019rapid}
A.~Raghu, M.~Raghu, S.~Bengio, and O.~Vinyals.
\newblock Rapid learning or feature reuse? towards understanding the
  effectiveness of maml.
\newblock \emph{arXiv preprint arXiv:1909.09157}, 2019{\natexlab{a}}.

\bibitem[Raghu et~al.(2017)Raghu, Gilmer, Yosinski, and
  Sohl-Dickstein]{raghu2017svcca}
M.~Raghu, J.~Gilmer, J.~Yosinski, and J.~Sohl-Dickstein.
\newblock Svcca: Singular vector canonical correlation analysis for deep
  learning dynamics and interpretability.
\newblock \emph{arXiv preprint arXiv:1706.05806}, 2017.

\bibitem[Raghu et~al.(2019{\natexlab{b}})Raghu, Zhang, Kleinberg, and
  Bengio]{raghu2019transfusion}
M.~Raghu, C.~Zhang, J.~Kleinberg, and S.~Bengio.
\newblock Transfusion: Understanding transfer learning for medical imaging.
\newblock \emph{arXiv preprint arXiv:1902.07208}, 2019{\natexlab{b}}.

\bibitem[Ramachandran et~al.(2019)Ramachandran, Parmar, Vaswani, Bello,
  Levskaya, and Shlens]{ramachandran2019stand}
P.~Ramachandran, N.~Parmar, A.~Vaswani, I.~Bello, A.~Levskaya, and J.~Shlens.
\newblock Stand-alone self-attention in vision models.
\newblock \emph{arXiv preprint arXiv:1906.05909}, 2019.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang,
  A.~Karpathy, A.~Khosla, M.~Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International journal of computer vision}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[Shi et~al.(2019)Shi, Shea-Brown, and Buice]{shi2019comparison}
J.~Shi, E.~Shea-Brown, and M.~Buice.
\newblock Comparison against task driven artificial neural networks reveals
  functional properties in mouse visual cortex.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 5764--5774, 2019.

\bibitem[Song et~al.(2012)Song, Smola, Gretton, Bedo, and
  Borgwardt]{song2012feature}
L.~Song, A.~Smola, A.~Gretton, J.~Bedo, and K.~Borgwardt.
\newblock Feature selection via dependence maximization.
\newblock \emph{Journal of Machine Learning Research}, 13\penalty0 (5), 2012.

\bibitem[Sun et~al.(2017)Sun, Shrivastava, Singh, and Gupta]{sun2017revisiting}
C.~Sun, A.~Shrivastava, S.~Singh, and A.~Gupta.
\newblock Revisiting unreasonable effectiveness of data in deep learning era.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 843--852, 2017.

\bibitem[Tay et~al.(2021)Tay, Dehghani, Gupta, Bahri, Aribandi, Qin, and
  Metzler]{tay2021pre}
Y.~Tay, M.~Dehghani, J.~Gupta, D.~Bahri, V.~Aribandi, Z.~Qin, and D.~Metzler.
\newblock Are pre-trained convolutions better than pre-trained transformers?
\newblock \emph{arXiv preprint arXiv:2105.03322}, 2021.

\bibitem[Tolstikhin et~al.(2021)Tolstikhin, Houlsby, Kolesnikov, Beyer, Zhai,
  Unterthiner, Yung, Keysers, Uszkoreit, Lucic, et~al.]{tolstikhin2021mlp}
I.~Tolstikhin, N.~Houlsby, A.~Kolesnikov, L.~Beyer, X.~Zhai, T.~Unterthiner,
  J.~Yung, D.~Keysers, J.~Uszkoreit, M.~Lucic, et~al.
\newblock Mlp-mixer: An all-mlp architecture for vision.
\newblock \emph{arXiv preprint arXiv:2105.01601}, 2021.

\bibitem[Touvron et~al.(2021)Touvron, Bojanowski, Caron, Cord, El-Nouby, Grave,
  Joulin, Synnaeve, Verbeek, and J{\'e}gou]{touvron2021resmlp}
H.~Touvron, P.~Bojanowski, M.~Caron, M.~Cord, A.~El-Nouby, E.~Grave, A.~Joulin,
  G.~Synnaeve, J.~Verbeek, and H.~J{\'e}gou.
\newblock Resmlp: Feedforward networks for image classification with
  data-efficient training.
\newblock \emph{arXiv preprint arXiv:2105.03404}, 2021.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  L.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock \emph{arXiv preprint arXiv:1706.03762}, 2017.

\bibitem[Voita et~al.(2019)Voita, Sennrich, and Titov]{voita2019bottom}
E.~Voita, R.~Sennrich, and I.~Titov.
\newblock The bottom-up evolution of representations in the transformer: A
  study with machine translation and language modeling objectives.
\newblock In \emph{EMNLP}, 2019.

\bibitem[Wu et~al.(2020{\natexlab{a}})Wu, Xu, Dai, Wan, Zhang, Yan, Tomizuka,
  Gonzalez, Keutzer, and Vajda]{wu2020visual}
B.~Wu, C.~Xu, X.~Dai, A.~Wan, P.~Zhang, Z.~Yan, M.~Tomizuka, J.~Gonzalez,
  K.~Keutzer, and P.~Vajda.
\newblock Visual transformers: Token-based image representation and processing
  for computer vision.
\newblock \emph{arXiv preprint arXiv:2006.03677}, 2020{\natexlab{a}}.

\bibitem[Wu et~al.(2020{\natexlab{b}})Wu, Belinkov, Sajjad, Durrani, Dalvi, and
  Glass]{wu2020similarity}
J.~M. Wu, Y.~Belinkov, H.~Sajjad, N.~Durrani, F.~Dalvi, and J.~Glass.
\newblock Similarity analysis of contextual word representation models.
\newblock \emph{arXiv preprint arXiv:2005.01172}, 2020{\natexlab{b}}.

\bibitem[Wu et~al.(2019)Wu, Conneau, Li, Zettlemoyer, and
  Stoyanov]{wu2019emerging}
S.~Wu, A.~Conneau, H.~Li, L.~Zettlemoyer, and V.~Stoyanov.
\newblock Emerging cross-lingual structure in pretrained language models.
\newblock \emph{arXiv preprint arXiv:1911.01464}, 2019.

\bibitem[Yuan et~al.(2021)Yuan, Chen, Wang, Yu, Shi, Jiang, Tay, Feng, and
  Yan]{yuan2021tokens}
L.~Yuan, Y.~Chen, T.~Wang, W.~Yu, Y.~Shi, Z.~Jiang, F.~E. Tay, J.~Feng, and
  S.~Yan.
\newblock Tokens-to-token vit: Training vision transformers from scratch on
  imagenet.
\newblock \emph{arXiv preprint arXiv:2101.11986}, 2021.

\bibitem[Zhai et~al.(2019)Zhai, Puigcerver, Kolesnikov, Ruyssen, Riquelme,
  Lucic, Djolonga, Pinto, Neumann, Dosovitskiy, et~al.]{zhai2019visual}
X.~Zhai, J.~Puigcerver, A.~Kolesnikov, P.~Ruyssen, C.~Riquelme, M.~Lucic,
  J.~Djolonga, A.~S. Pinto, M.~Neumann, A.~Dosovitskiy, et~al.
\newblock The visual task adaptation benchmark.
\newblock 2019.

\end{thebibliography}
