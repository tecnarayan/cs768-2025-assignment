\begin{thebibliography}{56}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Barham, Chen, Chen, Davis, Dean, Devin,
  Ghemawat, Irving, Isard, et~al.]{abadi2016tensorflow}
Mart{\'\i}n Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
  Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et~al.
\newblock Tensorflow: A system for large-scale machine learning.
\newblock In \emph{12th USENIX symposium on operating systems design and
  implementation (OSDI 16)}, pages 265--283, 2016.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in neural information processing systems},
  32:\penalty0 8026--8037, 2019.

\bibitem[LeCun et~al.(1989)LeCun, Boser, Denker, Henderson, Howard, Hubbard,
  and Jackel]{lecun1989}
Y.~LeCun, B.~Boser, J.~S. Denker, D.~Henderson, R.~E. Howard, W.~Hubbard, and
  L.~D. Jackel.
\newblock Backpropagation applied to handwritten zip code recognition.
\newblock \emph{Neural Computation}, 1\penalty0 (4):\penalty0 541--551, 1989.
\newblock \doi{10.1162/neco.1989.1.4.541}.

\bibitem[Fukushima and Miyake(1982)]{fukushima1982455}
Kunihiko Fukushima and Sei Miyake.
\newblock Neocognitron: A new algorithm for pattern recognition tolerant of
  deformations and shifts in position.
\newblock \emph{Pattern Recognition}, 15\penalty0 (6):\penalty0 455--469, 1982.
\newblock ISSN 0031-3203.
\newblock \doi{https://doi.org/10.1016/0031-3203(82)90024-3}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/0031320382900243}.

\bibitem[Krizhevsky et~al.(2012{\natexlab{a}})Krizhevsky, Sutskever, and
  Hinton]{alexnet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Proceedings of the 25th International Conference on Neural
  Information Processing Systems - Volume 1}, NIPS'12, page 1097–1105, Red
  Hook, NY, USA, 2012{\natexlab{a}}. Curran Associates Inc.

\bibitem[Barham and Isard(2019)]{ml_systems_stuck}
Paul Barham and Michael Isard.
\newblock Machine learning systems are stuck in a rut.
\newblock In \emph{Proceedings of the Workshop on Hot Topics in Operating
  Systems}, HotOS '19, page 177–183, New York, NY, USA, 2019. Association for
  Computing Machinery.
\newblock ISBN 9781450367271.
\newblock \doi{10.1145/3317550.3321441}.
\newblock URL \url{https://doi.org/10.1145/3317550.3321441}.

\bibitem[Hinton et~al.(2018)Hinton, Sabour, and Frosst]{46653}
Geoffrey Hinton, Sara Sabour, and Nicholas Frosst.
\newblock Matrix capsules with em routing.
\newblock 2018.
\newblock URL \url{https://openreview.net/pdf?id=HJWLfGWRb}.

\bibitem[Theis and Wong(2017)]{7878935}
Thomas~N. Theis and H.-S.~Philip Wong.
\newblock The end of moore's law: A new beginning for information technology.
\newblock \emph{Computing in Science Engineering}, 19\penalty0 (2):\penalty0
  41--50, 2017.
\newblock \doi{10.1109/MCSE.2017.29}.

\bibitem[Markidis et~al.(2018)Markidis, Chien, Laure, Peng, and
  Vetter]{NVIDIATC}
S.~Markidis, S.~W. Chien, E.~Laure, I.~Peng, and J.~Vetter.
\newblock Nvidia tensor core programmability, performance \& precision.
\newblock \emph{2018 IEEE International Parallel and Distributed Processing
  Symposium Workshops (IPDPSW)}, pages 522--531, 2018.

\bibitem[Jouppi et~al.(2017)Jouppi, Young, Patil, Patterson, Agrawal, Bajwa,
  Bates, Bhatia, Boden, Borchers, Boyle, Cantin, Chao, Clark, Coriell, Daley,
  Dau, Dean, Gelb, Ghaemmaghami, Gottipati, Gulland, Hagmann, Ho, Hogberg, Hu,
  Hundt, Hurt, Ibarz, Jaffey, Jaworski, Kaplan, Khaitan, Killebrew, Koch,
  Kumar, Lacy, Laudon, Law, Le, Leary, Liu, Lucke, Lundin, MacKean, Maggiore,
  Mahony, Miller, Nagarajan, Narayanaswami, Ni, Nix, Norrie, Omernick,
  Penukonda, Phelps, Ross, Ross, Salek, Samadiani, Severn, Sizikov, Snelham,
  Souter, Steinberg, Swing, Tan, Thorson, Tian, Toma, Tuttle, Vasudevan,
  Walter, Wang, Wilcox, and Yoon]{tpu}
Norman~P. Jouppi, Cliff Young, Nishant Patil, David Patterson, Gaurav Agrawal,
  Raminder Bajwa, Sarah Bates, Suresh Bhatia, Nan Boden, Al~Borchers, Rick
  Boyle, Pierre-luc Cantin, Clifford Chao, Chris Clark, Jeremy Coriell, Mike
  Daley, Matt Dau, Jeffrey Dean, Ben Gelb, Tara~Vazir Ghaemmaghami, Rajendra
  Gottipati, William Gulland, Robert Hagmann, C.~Richard Ho, Doug Hogberg, John
  Hu, Robert Hundt, Dan Hurt, Julian Ibarz, Aaron Jaffey, Alek Jaworski,
  Alexander Kaplan, Harshit Khaitan, Daniel Killebrew, Andy Koch, Naveen Kumar,
  Steve Lacy, James Laudon, James Law, Diemthu Le, Chris Leary, Zhuyuan Liu,
  Kyle Lucke, Alan Lundin, Gordon MacKean, Adriana Maggiore, Maire Mahony,
  Kieran Miller, Rahul Nagarajan, Ravi Narayanaswami, Ray Ni, Kathy Nix, Thomas
  Norrie, Mark Omernick, Narayana Penukonda, Andy Phelps, Jonathan Ross, Matt
  Ross, Amir Salek, Emad Samadiani, Chris Severn, Gregory Sizikov, Matthew
  Snelham, Jed Souter, Dan Steinberg, Andy Swing, Mercedes Tan, Gregory
  Thorson, Bo~Tian, Horia Toma, Erick Tuttle, Vijay Vasudevan, Richard Walter,
  Walter Wang, Eric Wilcox, and Doe~Hyun Yoon.
\newblock In-datacenter performance analysis of a tensor processing unit.
\newblock \emph{SIGARCH Comput. Archit. News}, 45\penalty0 (2):\penalty0
  1–12, June 2017.
\newblock ISSN 0163-5964.
\newblock \doi{10.1145/3140659.3080246}.
\newblock URL \url{https://doi.org/10.1145/3140659.3080246}.

\bibitem[Jia et~al.(2019)Jia, Tillman, Maggioni, and Scarpazza]{IPU}
Zhe Jia, Blake Tillman, Marco Maggioni, and D.~Scarpazza.
\newblock Dissecting the graphcore ipu architecture via microbenchmarking.
\newblock \emph{ArXiv}, abs/1912.03413, 2019.

\bibitem[Adams et~al.(2019)Adams, Ma, Anderson, Baghdadi, Li, Gharbi, Steiner,
  Johnson, Fatahalian, Durand, and Ragan-Kelley]{halide_autoscheduler}
Andrew Adams, Karima Ma, Luke Anderson, Riyadh Baghdadi, Tzu-Mao Li,
  Micha\"{e}l Gharbi, Benoit Steiner, Steven Johnson, Kayvon Fatahalian,
  Fr\'{e}do Durand, and Jonathan Ragan-Kelley.
\newblock Learning to optimize halide with tree search and random programs.
\newblock \emph{ACM Trans. Graph.}, 38\penalty0 (4), July 2019.
\newblock ISSN 0730-0301.
\newblock \doi{10.1145/3306346.3322967}.
\newblock URL \url{https://doi.org/10.1145/3306346.3322967}.

\bibitem[Steiner et~al.(2021)Steiner, Cummins, He, and
  Leather]{MLSYS2021_73278a4a}
Benoit Steiner, Chris Cummins, Horace He, and Hugh Leather.
\newblock Value learning for throughput optimization of deep learning
  workloads.
\newblock In A.~Smola, A.~Dimakis, and I.~Stoica, editors, \emph{Proceedings of
  Machine Learning and Systems}, volume~3, pages 323--334, 2021.
\newblock URL
  \url{https://proceedings.mlsys.org/paper/2021/file/73278a4a86960eeb576a8fd4c9ec6997-Paper.pdf}.

\bibitem[Chen et~al.(2018)Chen, Zheng, Yan, Jiang, Moreau, Ceze, Guestrin, and
  Krishnamurthy]{tvm}
Tianqi Chen, Lianmin Zheng, Eddie Yan, Ziheng Jiang, Thierry Moreau, Luis Ceze,
  Carlos Guestrin, and Arvind Krishnamurthy.
\newblock Learning to optimize tensor programs.
\newblock In \emph{Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, NIPS'18, page 3393–3404, Red Hook, NY,
  USA, 2018. Curran Associates Inc.

\bibitem[Zheng et~al.(2020)Zheng, Jia, Sun, Wu, Yu, Haj-Ali, Wang, Yang, Zhuo,
  Sen, Gonzalez, and Stoica]{ansor}
Lianmin Zheng, Chengfan Jia, Minmin Sun, Zhao Wu, Cody~Hao Yu, Ameer Haj-Ali,
  Yida Wang, Jun Yang, Danyang Zhuo, Koushik Sen, Joseph~E. Gonzalez, and Ion
  Stoica.
\newblock Ansor: Generating high-performance tensor programs for deep learning.
\newblock In \emph{14th {USENIX} Symposium on Operating Systems Design and
  Implementation ({OSDI} 20)}, pages 863--879. {USENIX} Association, November
  2020.
\newblock ISBN 978-1-939133-19-9.
\newblock URL
  \url{https://www.usenix.org/conference/osdi20/presentation/zheng}.

\bibitem[Jia et~al.(2018)Jia, Zaharia, and Aiken]{flexflow}
Zhihao Jia, Matei Zaharia, and Alex Aiken.
\newblock Beyond data and model parallelism for deep neural networks.
\newblock \emph{CoRR}, abs/1807.05358, 2018.
\newblock URL \url{http://arxiv.org/abs/1807.05358}.

\bibitem[Jia et~al.(2020)Jia, Lin, Gao, Zaharia, and Aiken]{roc}
Zhihao Jia, Sina Lin, Mingyu Gao, Matei Zaharia, and Alex Aiken.
\newblock Improving the accuracy, scalability, and performance of graph neural
  networks with roc.
\newblock In I.~Dhillon, D.~Papailiopoulos, and V.~Sze, editors,
  \emph{Proceedings of Machine Learning and Systems}, volume~2, pages 187--198,
  2020.
\newblock URL
  \url{https://proceedings.mlsys.org/paper/2020/file/fe9fc289c3ff0af142b6d3bead98a923-Paper.pdf}.

\bibitem[Wang et~al.(2021)Wang, Zhai, Gao, Ma, Tang, Zheng, Li, Rong, Chen, and
  Jia]{pet}
Haojie Wang, Jidong Zhai, Mingyu Gao, Zixuan Ma, Shizhi Tang, Liyan Zheng,
  Yuanzhi Li, Kaiyuan Rong, Yuanyong Chen, and Zhihao Jia.
\newblock {PET}: Optimizing tensor programs with partially equivalent
  transformations and automated corrections.
\newblock In \emph{15th {USENIX} Symposium on Operating Systems Design and
  Implementation ({OSDI} 21)}, pages 37--54. {USENIX} Association, July 2021.
\newblock ISBN 978-1-939133-22-9.
\newblock URL \url{https://www.usenix.org/conference/osdi21/presentation/wang}.

\bibitem[Rasley et~al.(2020)Rasley, Rajbhandari, Ruwase, and
  He]{rasley2020deepspeed}
Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He.
\newblock Deepspeed: System optimizations enable training deep learning models
  with over 100 billion parameters.
\newblock In \emph{Proceedings of the 26th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pages 3505--3506, 2020.

\bibitem[Bottou and LeCun(2002)]{bottou2002lush}
L{\'e}on Bottou and Yann LeCun.
\newblock Lush.
\newblock 2002.
\newblock URL \url{http://lush. sourceforge.net}.

\bibitem[Bergstra et~al.(2010)Bergstra, Breuleux, Bastien, Lamblin, Pascanu,
  Desjardins, Turian, Warde-Farley, and Bengio]{bergstra2010theano}
James Bergstra, Olivier Breuleux, Fr{\'e}d{\'e}ric Bastien, Pascal Lamblin,
  Razvan Pascanu, Guillaume Desjardins, Joseph Turian, David Warde-Farley, and
  Yoshua Bengio.
\newblock Theano: a cpu and gpu math expression compiler.
\newblock In \emph{Proceedings of the Python for scientific computing
  conference (SciPy)}, volume~4, pages 1--7. Austin, TX, 2010.

\bibitem[Collobert et~al.(2011)Collobert, Kavukcuoglu, and Farabet]{torch7}
Ronan Collobert, Koray Kavukcuoglu, and Clement Farabet.
\newblock Torch7: A matlab-like environment for machine learning.
\newblock 01 2011.

\bibitem[Jia et~al.(2014)Jia, Shelhamer, Donahue, Karayev, Long, Girshick,
  Guadarrama, and Darrell]{jia2014caffe}
Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross
  Girshick, Sergio Guadarrama, and Trevor Darrell.
\newblock Caffe: Convolutional architecture for fast feature embedding.
\newblock In \emph{Proceedings of the 22nd ACM international conference on
  Multimedia}, pages 675--678, 2014.

\bibitem[Chen et~al.(2015)Chen, Li, Li, Lin, Wang, Wang, Xiao, Xu, Zhang, and
  Zhang]{chen2015mxnet}
Tianqi Chen, Mu~Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun Xiao,
  Bing Xu, Chiyuan Zhang, and Zheng Zhang.
\newblock Mxnet: A flexible and efficient machine learning library for
  heterogeneous distributed systems.
\newblock \emph{arXiv preprint arXiv:1512.01274}, 2015.

\bibitem[Team(2016)]{dl4j}
Eclipse Deeplearning4j~Development Team.
\newblock Deeplearning4j: Open-source distributed deep learning for the jvm.
\newblock 2016.
\newblock URL \url{https://github.com/eclipse/deeplearning4j}.

\bibitem[Innes(2018)]{innes2018flux}
Mike Innes.
\newblock Flux: Elegant machine learning with julia.
\newblock \emph{Journal of Open Source Software}, 3\penalty0 (25):\penalty0
  602, 2018.

\bibitem[Bradbury et~al.(2018)Bradbury, Frostig, Hawkins, Johnson, Leary,
  Maclaurin, Necula, Paszke, Vander{P}las, Wanderman-{M}ilne, and
  Zhang]{jax2018github}
James Bradbury, Roy Frostig, Peter Hawkins, Matthew~James Johnson, Chris Leary,
  Dougal Maclaurin, George Necula, Adam Paszke, Jake Vander{P}las, Skye
  Wanderman-{M}ilne, and Qiao Zhang.
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs,
  2018.
\newblock URL \url{http://github.com/google/jax}.

\bibitem[Tokui et~al.(2019)Tokui, Okuta, Akiba, Niitani, Ogawa, Saito, Suzuki,
  Uenishi, Vogel, and Yamazaki~Vincent]{tokui2019chainer}
Seiya Tokui, Ryosuke Okuta, Takuya Akiba, Yusuke Niitani, Toru Ogawa, Shunta
  Saito, Shuji Suzuki, Kota Uenishi, Brian Vogel, and Hiroyuki
  Yamazaki~Vincent.
\newblock Chainer: A deep learning framework for accelerating the research
  cycle.
\newblock In \emph{Proceedings of the 25th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pages 2002--2011, 2019.

\bibitem[Ma et~al.(2019)Ma, Yu, Wu, and Wang]{ma2019paddlepaddle}
Yanjun Ma, Dianhai Yu, Tian Wu, and Haifeng Wang.
\newblock Paddlepaddle: An open-source deep learning platform from industrial
  practice.
\newblock \emph{Frontiers of Data and Computing}, 1\penalty0 (1):\penalty0
  105--115, 2019.

\bibitem[Gill and Kemerer(1990)]{gill}
G.K Gill and C.F Kemerer.
\newblock Productivity impacts of software complexity and developer experience.
\newblock \emph{MIT Sloan}, 1990.

\bibitem[Krizhevsky et~al.(2012{\natexlab{b}})Krizhevsky, Sutskever, and
  Hinton]{krizhevsky12}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Advances in neural information processing systems}, pages
  1097--1105, 2012{\natexlab{b}}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{transformers}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, \L{}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, NIPS'17, page 6000–6010, Red Hook, NY,
  USA, 2017. Curran Associates Inc.
\newblock ISBN 9781510860964.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Carion et~al.(2020)Carion, Massa, Synnaeve, Usunier, Kirillov, and
  Zagoruyko]{carion2020end}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In \emph{European Conference on Computer Vision}, pages 213--229.
  Springer, 2020.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Pratap et~al.(2019)Pratap, Hannun, Xu, Cai, Kahn, Synnaeve,
  Liptchinsky, and Collobert]{wav2letter++}
Vineel Pratap, Awni Hannun, Qiantong Xu, Jeff Cai, Jacob Kahn, Gabriel
  Synnaeve, Vitaliy Liptchinsky, and Ronan Collobert.
\newblock Wav2letter++: A fast open-source speech recognition system.
\newblock In \emph{ICASSP 2019 - 2019 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}, pages 6460--6464, 2019.
\newblock \doi{10.1109/ICASSP.2019.8683535}.

\bibitem[Chetlur et~al.(2014)Chetlur, Woolley, Vandermersch, Cohen, Tran,
  Catanzaro, and Shelhamer]{chetlur2014cudnn}
Sharan Chetlur, Cliff Woolley, Philippe Vandermersch, Jonathan Cohen, John
  Tran, Bryan Catanzaro, and Evan Shelhamer.
\newblock cudnn: Efficient primitives for deep learning.
\newblock \emph{arXiv preprint arXiv:1410.0759}, 2014.

\bibitem[Intel(2020{\natexlab{a}})]{mkl}
Intel.
\newblock Mkl developer reference.
\newblock
  \url{https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top.html},
  2020{\natexlab{a}}.

\bibitem[Intel(2020{\natexlab{b}})]{onednn}
Intel.
\newblock Onednn.
\newblock \url{https://github.com/oneapi-src/oneDNN}, 2020{\natexlab{b}}.

\bibitem[Yalamanchili et~al.(2015)Yalamanchili, Arshad, Mohammed, Garigipati,
  Entschev, Kloppenborg, Malcolm, and Melonakos]{Yalamanchili2015}
Pavan Yalamanchili, Umar Arshad, Zakiuddin Mohammed, Pradeep Garigipati, Peter
  Entschev, Brian Kloppenborg, James Malcolm, and John Melonakos.
\newblock {ArrayFire - A high performance software library for parallel
  computing with an easy-to-use API}, 2015.
\newblock URL \url{https://github.com/arrayfire/arrayfire}.

\bibitem[Khan et~al.(2019)Khan, Fultz, Tamazov, Lowell, Liu, Melesse,
  Nandhimandalam, Nasyrov, Perminov, Shah, et~al.]{khan2019miopen}
Jehandad Khan, Paul Fultz, Artem Tamazov, Daniel Lowell, Chao Liu, Michael
  Melesse, Murali Nandhimandalam, Kamil Nasyrov, Ilya Perminov, Tejash Shah,
  et~al.
\newblock Miopen: An open source library for deep learning primitives.
\newblock \emph{arXiv preprint arXiv:1910.00078}, 2019.

\bibitem[Harris et~al.(2020)Harris, Millman, van~der Walt, Gommers, Virtanen,
  Cournapeau, Wieser, Taylor, Berg, Smith, Kern, Picus, Hoyer, van Kerkwijk,
  Brett, Haldane, del R{\'{i}}o, Wiebe, Peterson, G{\'{e}}rard-Marchant,
  Sheppard, Reddy, Weckesser, Abbasi, Gohlke, and Oliphant]{harris2020array}
Charles~R. Harris, K.~Jarrod Millman, St{\'{e}}fan~J. van~der Walt, Ralf
  Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, Julian Taylor,
  Sebastian Berg, Nathaniel~J. Smith, Robert Kern, Matti Picus, Stephan Hoyer,
  Marten~H. van Kerkwijk, Matthew Brett, Allan Haldane, Jaime~Fern{\'{a}}ndez
  del R{\'{i}}o, Mark Wiebe, Pearu Peterson, Pierre G{\'{e}}rard-Marchant,
  Kevin Sheppard, Tyler Reddy, Warren Weckesser, Hameer Abbasi, Christoph
  Gohlke, and Travis~E. Oliphant.
\newblock Array programming with {NumPy}.
\newblock \emph{Nature}, 585\penalty0 (7825):\penalty0 357--362, September
  2020.
\newblock \doi{10.1038/s41586-020-2649-2}.
\newblock URL \url{https://doi.org/10.1038/s41586-020-2649-2}.

\bibitem[NCCL(2019)]{nccl}
NCCL.
\newblock Nvidia collective communications library (nccl).
\newblock \url{https://github.com/NVIDIA/nccl}, 2019.

\bibitem[Gloo(2019)]{gloo}
Gloo.
\newblock Gloo: a collective communications library.
\newblock \url{https://github.com/facebookincubator/gloo}, 2019.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{Paszke2017AutomaticDI}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zach
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem[Collobert et~al.(2016)Collobert, Puhrsch, and Synnaeve]{wav2letter}
Ronan Collobert, Christian Puhrsch, and Gabriel Synnaeve.
\newblock Wav2letter: an end-to-end convnet-based speech recognition system.
\newblock \emph{arXiv preprint arXiv:1609.03193}, 2016.

\bibitem[Synnaeve et~al.(2019)Synnaeve, Xu, Kahn, Likhomanenko, Grave, Pratap,
  Sriram, Liptchinsky, and Collobert]{synnaeve2019end}
Gabriel Synnaeve, Qiantong Xu, Jacob Kahn, Tatiana Likhomanenko, Edouard Grave,
  Vineel Pratap, Anuroop Sriram, Vitaliy Liptchinsky, and Ronan Collobert.
\newblock End-to-end asr: from supervised to semi-supervised learning with
  modern architectures.
\newblock \emph{arXiv preprint arXiv:1911.08460}, 2019.

\bibitem[Likhomanenko et~al.(2021)Likhomanenko, Xu, Pratap, Tomasello, Kahn,
  Avidov, Collobert, and Synnaeve]{likhomanenko2020rethinking}
Tatiana Likhomanenko, Qiantong Xu, Vineel Pratap, Paden Tomasello, Jacob Kahn,
  Gilad Avidov, Ronan Collobert, and Gabriel Synnaeve.
\newblock {Rethinking Evaluation in ASR: Are Our Models Robust Enough?}
\newblock In \emph{Proc. Interspeech 2021}, pages 311--315, 2021.
\newblock \doi{10.21437/Interspeech.2021-1758}.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{coco}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{European conference on computer vision}, pages 740--755.
  Springer, 2014.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Dauphin et~al.(2017)Dauphin, Fan, Auli, and
  Grangier]{dauphin2017gated}
Yann~N. Dauphin, Angela Fan, Michael Auli, and David Grangier.
\newblock Language modeling with gated convolutional networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning - Volume 70}, ICML'17, page 933–941. JMLR.org, 2017.

\bibitem[Collobert et~al.(2019)Collobert, Hannun, and
  Synnaeve]{collobert2019fully}
Ronan Collobert, Awni Hannun, and Gabriel Synnaeve.
\newblock A fully differentiable beam search decoder.
\newblock In \emph{International Conference on Machine Learning}, pages
  1341--1350. PMLR, 2019.

\bibitem[Rajbhandari et~al.(2020)Rajbhandari, Rasley, Ruwase, and
  He]{rajbhandari2020zero}
Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He.
\newblock Zero: Memory optimizations toward training trillion parameter models.
\newblock In \emph{SC20: International Conference for High Performance
  Computing, Networking, Storage and Analysis}, pages 1--16. IEEE, 2020.

\bibitem[Kehne et~al.(2015)Kehne, Metter, and Bellosa]{kehne2015gpuswap}
Jens Kehne, Jonathan Metter, and Frank Bellosa.
\newblock Gpuswap: Enabling oversubscription of gpu memory through transparent
  swapping.
\newblock In \emph{Proceedings of the 11th ACM SIGPLAN/SIGOPS International
  Conference on Virtual Execution Environments}, pages 65--77, 2015.

\bibitem[Li et~al.(2020)Li, Zhao, Varma, Salpekar, Noordhuis, Li, Paszke,
  Smith, Vaughan, Damania, et~al.]{li2020pytorch}
Shen Li, Yanli Zhao, Rohan Varma, Omkar Salpekar, Pieter Noordhuis, Teng Li,
  Adam Paszke, Jeff Smith, Brian Vaughan, Pritam Damania, et~al.
\newblock Pytorch distributed: Experiences on accelerating data parallel
  training.
\newblock \emph{arXiv preprint arXiv:2006.15704}, 2020.

\end{thebibliography}
