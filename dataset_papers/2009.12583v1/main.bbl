\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Advani \& Saxe(2017)Advani and Saxe]{advani2017high}
Advani, M.~S. and Saxe, A.~M.
\newblock High-dimensional dynamics of generalization error in neural networks.
\newblock \emph{arXiv preprint arXiv:1710.03667}, 2017.

\bibitem[Allen-Zhu et~al.(2019)Allen-Zhu, Li, and Liang]{allen2019learning}
Allen-Zhu, Z., Li, Y., and Liang, Y.
\newblock Learning and generalization in overparameterized neural networks,
  going beyond two layers.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  6155--6166, 2019.

\bibitem[Belkin et~al.(2019)Belkin, Hsu, Ma, and Mandal]{belkin2019reconciling}
Belkin, M., Hsu, D., Ma, S., and Mandal, S.
\newblock Reconciling modern machine-learning practice and the classical
  bias--variance trade-off.
\newblock \emph{Proceedings of the National Academy of Sciences}, 116\penalty0
  (32):\penalty0 15849--15854, 2019.

\bibitem[Blier \& Ollivier(2018)Blier and Ollivier]{blier2018description}
Blier, L. and Ollivier, Y.
\newblock The description length of deep learning models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2216--2226, 2018.

\bibitem[Cohen et~al.(2017)Cohen, Afshar, Tapson, and
  Van~Schaik]{cohen2017emnist}
Cohen, G., Afshar, S., Tapson, J., and Van~Schaik, A.
\newblock Emnist: Extending mnist to handwritten letters.
\newblock In \emph{2017 International Joint Conference on Neural Networks
  (IJCNN)}, pp.\  2921--2926. IEEE, 2017.

\bibitem[Dawid(1984)]{dawid1984present}
Dawid, A.~P.
\newblock Present position and potential developments: Some personal views
  statistical theory the prequential approach.
\newblock \emph{Journal of the Royal Statistical Society: Series A (General)},
  147\penalty0 (2):\penalty0 278--290, 1984.

\bibitem[Domingos(2000)]{domingos2000unified}
Domingos, P.
\newblock A unified bias-variance decomposition.
\newblock In \emph{Proceedings of 17th International Conference on Machine
  Learning}, pp.\  231--238, 2000.

\bibitem[Geman et~al.(1992)Geman, Bienenstock, and Doursat]{geman1992neural}
Geman, S., Bienenstock, E., and Doursat, R.
\newblock Neural networks and the bias/variance dilemma.
\newblock \emph{Neural computation}, 4\penalty0 (1):\penalty0 1--58, 1992.

\bibitem[Gr\"{u}nwald(2007)]{grunwald2007mdl}
Gr\"{u}nwald, P.~D.
\newblock \emph{The Minimum Description Length Principle}.
\newblock The MIT Press, 2007.
\newblock ISBN 0262072815.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Guo, C., Pleiss, G., Sun, Y., and Weinberger, K.~Q.
\newblock On calibration of modern neural networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  1321--1330. JMLR. org, 2017.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Hestness et~al.(2017)Hestness, Narang, Ardalani, Diamos, Jun,
  Kianinejad, Patwary, Ali, Yang, and Zhou]{hestness2017deep}
Hestness, J., Narang, S., Ardalani, N., Diamos, G., Jun, H., Kianinejad, H.,
  Patwary, M., Ali, M., Yang, Y., and Zhou, Y.
\newblock Deep learning scaling is predictable, empirically.
\newblock \emph{arXiv preprint arXiv:1712.00409}, 2017.

\bibitem[Jacot et~al.(2018)Jacot, Gabriel, and Hongler]{jacot2018neuraltangent}
Jacot, A., Gabriel, F., and Hongler, C.
\newblock Neural tangent kernel: Convergence and generalization in neural
  networks.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 31}, pp.\  8571--8580. Curran Associates,
  Inc., 2018.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, Citeseer, 2009.

\bibitem[LeCun(1998)]{lecun1998mnist}
LeCun, Y.
\newblock The mnist database of handwritten digits.
\newblock \emph{http://yann. lecun. com/exdb/mnist/}, 1998.

\bibitem[Mac~Kay(2003)]{mackay2003information}
Mac~Kay, D.~J.
\newblock \emph{Information theory, inference and learning algorithms}.
\newblock Cambridge university press, 2003.

\bibitem[Mandt et~al.(2017)Mandt, Hoffman, and Blei]{mandt2017stochastic}
Mandt, S., Hoffman, M.~D., and Blei, D.~M.
\newblock Stochastic gradient descent as approximate bayesian inference.
\newblock \emph{The Journal of Machine Learning Research}, 18\penalty0
  (1):\penalty0 4873--4907, 2017.

\bibitem[Nakkiran et~al.(2019)Nakkiran, Kaplun, Bansal, Yang, Barak, and
  Sutskever]{nakkiran2019deep}
Nakkiran, P., Kaplun, G., Bansal, Y., Yang, T., Barak, B., and Sutskever, I.
\newblock Deep double descent: Where bigger models and more data hurt.
\newblock \emph{arXiv preprint arXiv:1912.02292}, 2019.

\bibitem[Rissanen(1978)]{rissanen1978modeling}
Rissanen, J.
\newblock Modeling by shortest data description.
\newblock \emph{Automatica}, 14\penalty0 (5):\penalty0 465--471, 1978.

\bibitem[Rissanen(1989)]{rissanen1989stochastic}
Rissanen, J.
\newblock \emph{Stochastic complexity in statistical inquiry}.
\newblock World Scientific, 1989.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{ILSVRC15}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., Berg, A.~C., and Fei-Fei, L.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock \emph{International Journal of Computer Vision (IJCV)}, 115\penalty0
  (3):\penalty0 211--252, 2015.
\newblock \doi{10.1007/s11263-015-0816-y}.

\bibitem[Simonyan \& Zisserman(2014)Simonyan and Zisserman]{simonyan2014very}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Spigler et~al.(2018)Spigler, Geiger, d'Ascoli, Sagun, Biroli, and
  Wyart]{spigler2018jamming}
Spigler, S., Geiger, M., d'Ascoli, S., Sagun, L., Biroli, G., and Wyart, M.
\newblock A jamming transition from under-to over-parametrization affects loss
  landscape and generalization.
\newblock \emph{arXiv preprint arXiv:1810.09665}, 2018.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy2016rethinking}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2818--2826, 2016.

\bibitem[Tieleman \& Hinton(2012)Tieleman and Hinton]{tieleman2012lecture}
Tieleman, T. and Hinton, G.
\newblock Lecture 6.5-rmsprop: Divide the gradient by a running average of its
  recent magnitude.
\newblock \emph{COURSERA: Neural networks for machine learning}, 4\penalty0
  (2):\penalty0 26--31, 2012.

\bibitem[Ying et~al.(2019)Ying, Klein, Real, Christiansen, Murphy, and
  Hutter]{ying2019bench}
Ying, C., Klein, A., Real, E., Christiansen, E., Murphy, K., and Hutter, F.
\newblock Nas-bench-101: Towards reproducible neural architecture search.
\newblock \emph{arXiv preprint arXiv:1902.09635}, 2019.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and
  Komodakis]{zagoruyko2016wide}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock \emph{arXiv preprint arXiv:1605.07146}, 2016.

\bibitem[Zhang et~al.(2016)Zhang, Bengio, Hardt, Recht, and
  Vinyals]{zhang2016understanding}
Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals, O.
\newblock Understanding deep learning requires rethinking generalization.
\newblock \emph{arXiv preprint arXiv:1611.03530}, 2016.

\bibitem[Zoran et~al.(2019)Zoran, Chrzanowski, Huang, Gowal, Mott, and
  Kohl]{zoran2019towards}
Zoran, D., Chrzanowski, M., Huang, P.-S., Gowal, S., Mott, A., and Kohl, P.
\newblock Towards robust image classification using sequential attention
  models.
\newblock \emph{arXiv preprint arXiv:1912.02184}, 2019.

\end{thebibliography}
