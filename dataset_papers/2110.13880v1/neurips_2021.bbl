\begin{thebibliography}{10}

\bibitem{alvarez2018towards}
David Alvarez-Melis and Tommi~S Jaakkola.
\newblock Towards robust interpretability with self-explaining neural networks.
\newblock {\em arXiv preprint arXiv:1806.07538}, 2018.

\bibitem{andreas2016learning}
Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein.
\newblock Learning to compose neural networks for question answering.
\newblock In {\em Proceedings of NAACL-HLT}, pages 1545--1554, 2016.

\bibitem{andreas2016neural}
Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein.
\newblock Neural module networks.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 39--48, 2016.

\bibitem{antognini2021rationalization}
Diego Antognini and Boi Faltings.
\newblock Rationalization through concepts.
\newblock {\em arXiv preprint arXiv:2105.04837}, 2021.

\bibitem{bahdanau2014neural}
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock {\em arXiv preprint arXiv:1409.0473}, 2014.

\bibitem{bao2018deriving}
Yujia Bao, Shiyu Chang, Mo~Yu, and Regina Barzilay.
\newblock Deriving machine attention from human rationales.
\newblock {\em arXiv preprint arXiv:1808.09367}, 2018.

\bibitem{bastings2020elephant}
Jasmijn Bastings and Katja Filippova.
\newblock The elephant in the interpretability room: Why use attention as
  explanation when we have saliency methods?
\newblock In {\em Proceedings of the Third BlackboxNLP Workshop on Analyzing
  and Interpreting Neural Networks for NLP}, pages 149--155, 2020.

\bibitem{bastings2019interpretable}
Joost Bastings, Wilker Aziz, and Ivan Titov.
\newblock Interpretable neural predictions with differentiable binary
  variables.
\newblock {\em arXiv preprint arXiv:1905.08160}, 2019.

\bibitem{bengio2013estimating}
Yoshua Bengio, Nicholas L{\'e}onard, and Aaron Courville.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock {\em arXiv preprint arXiv:1308.3432}, 2013.

\bibitem{carton2018extractive}
Samuel Carton, Qiaozhu Mei, and Paul Resnick.
\newblock Extractive adversarial networks: High-recall explanations for
  identifying personal attacks in social media posts.
\newblock In {\em Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pages 3497--3507, 2018.

\bibitem{chang2019game}
Shiyu Chang, Yang Zhang, Mo~Yu, and Tommi Jaakkola.
\newblock A game theoretic approach to class-wise selective rationalization.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  10055--10065, 2019.

\bibitem{chang2020invariant}
Shiyu Chang, Yang Zhang, Mo~Yu, and Tommi Jaakkola.
\newblock Invariant rationalization.
\newblock In {\em International Conference on Machine Learning}, pages
  1448--1458. PMLR, 2020.

\bibitem{chen2018learning}
Jianbo Chen, Le~Song, Martin Wainwright, and Michael Jordan.
\newblock Learning to explain: An information-theoretic perspective on model
  interpretation.
\newblock In {\em International Conference on Machine Learning}, pages
  882--891, 2018.

\bibitem{chen2018shapley}
Jianbo Chen, Le~Song, Martin~J Wainwright, and Michael~I Jordan.
\newblock {L-Shapley and C-Shapley}: Efficient model interpretation for
  structured data.
\newblock {\em arXiv preprint arXiv:1808.02610}, 2018.

\bibitem{chung2014empirical}
Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio.
\newblock Empirical evaluation of gated recurrent neural networks on sequence
  modeling.
\newblock {\em arXiv preprint arXiv:1412.3555}, 2014.

\bibitem{deyoung2019eraser}
Jay DeYoung, Sarthak Jain, Nazneen~Fatema Rajani, Eric Lehman, Caiming Xiong,
  Richard Socher, and Byron~C Wallace.
\newblock Eraser: A benchmark to evaluate rationalized nlp models.
\newblock {\em arXiv preprint arXiv:1911.03429}, 2019.

\bibitem{glockner2020you}
Max Glockner, Ivan Habernal, and Iryna Gurevych.
\newblock Why do you think that? exploring faithful sentence-level rationales
  without supervision.
\newblock {\em arXiv preprint arXiv:2010.03384}, 2020.

\bibitem{guerreiro2021spectra}
Nuno~Miguel Guerreiro and Andr{\'e}~FT Martins.
\newblock Spectra: Sparse structured text rationalization.
\newblock {\em arXiv preprint arXiv:2109.04552}, 2021.

\bibitem{jacovi2021aligning}
Alon Jacovi and Yoav Goldberg.
\newblock Aligning faithful interpretations with their social attribution.
\newblock {\em Transactions of the Association for Computational Linguistics},
  9:294--310, 2021.

\bibitem{jain2019attention}
Sarthak Jain and Byron~C Wallace.
\newblock Attention is not explanation.
\newblock In {\em Proceedings of the 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 3543--3556, 2019.

\bibitem{jang2016categorical}
Eric Jang, Shixiang Gu, and Ben Poole.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock {\em arXiv preprint arXiv:1611.01144}, 2016.

\bibitem{johnson2017inferring}
Justin Johnson, Bharath Hariharan, Laurens van~der Maaten, Judy Hoffman,
  Li~Fei-Fei, C~Lawrence~Zitnick, and Ross Girshick.
\newblock Inferring and executing programs for visual reasoning.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2989--2998, 2017.

\bibitem{kim2017structured}
Yoon Kim, Carl Denton, Luong Hoang, and Alexander~M Rush.
\newblock Structured attention networks.
\newblock {\em arXiv preprint arXiv:1702.00887}, 2017.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{kononenko2010efficient}
Igor Kononenko et~al.
\newblock An efficient explanation of individual classifications using game
  theory.
\newblock {\em Journal of Machine Learning Research}, 11(Jan):1--18, 2010.

\bibitem{lehman2019inferring}
Eric Lehman, Jay DeYoung, Regina Barzilay, and Byron~C Wallace.
\newblock Inferring which medical treatments work from reports of clinical
  trials.
\newblock In {\em Proceedings of the 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 3705--3717, 2019.

\bibitem{lei2016rationalizing}
Tao Lei, Regina Barzilay, and Tommi Jaakkola.
\newblock Rationalizing neural predictions.
\newblock {\em arXiv preprint arXiv:1606.04155}, 2016.

\bibitem{li2016visualizing}
Jiwei Li, Xinlei Chen, Eduard Hovy, and Dan Jurafsky.
\newblock Visualizing and understanding neural models in {NLP}.
\newblock In {\em Proceedings of the 2016 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 681--691, 2016.

\bibitem{li2016understanding}
Jiwei Li, Will Monroe, and Dan Jurafsky.
\newblock Understanding neural networks through representation erasure.
\newblock {\em arXiv preprint arXiv:1612.08220}, 2016.

\bibitem{lundberg2017unified}
Scott~M Lundberg and Su-In Lee.
\newblock A unified approach to interpreting model predictions.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4765--4774, 2017.

\bibitem{martins2016softmax}
Andre Martins and Ramon Astudillo.
\newblock From softmax to sparsemax: A sparse model of attention and
  multi-label classification.
\newblock In {\em International conference on machine learning}, pages
  1614--1623. PMLR, 2016.

\bibitem{mcauley2012learning}
Julian McAuley, Jure Leskovec, and Dan Jurafsky.
\newblock Learning attitudes and attributes from multi-aspect reviews.
\newblock In {\em 2012 IEEE 12th International Conference on Data Mining},
  pages 1020--1025. IEEE, 2012.

\bibitem{mohankumar2020towards}
Akash~Kumar Mohankumar, Preksha Nema, Sharan Narasimhan, Mitesh~M Khapra,
  Balaji~Vasan Srinivasan, and Balaraman Ravindran.
\newblock Towards transparent and explainable attention models.
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}, pages 4206--4216, 2020.

\bibitem{pennington2014glove}
Jeffrey Pennington, Richard Socher, and Christopher Manning.
\newblock Glove: Global vectors for word representation.
\newblock In {\em Proceedings of the 2014 conference on empirical methods in
  natural language processing (EMNLP)}, pages 1532--1543, 2014.

\bibitem{pruthi2020learning}
Danish Pruthi, Mansi Gupta, Bhuwan Dhingra, Graham Neubig, and Zachary~C
  Lipton.
\newblock Learning to deceive with attention-based explanations.
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}, pages 4782--4793, 2020.

\bibitem{ribeiro2016should}
Marco~Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.
\newblock Why should {I} trust you?: Explaining the predictions of any
  classifier.
\newblock In {\em Proceedings of the 22nd ACM SIGKDD international conference
  on knowledge discovery and data mining}, pages 1135--1144. ACM, 2016.

\bibitem{ross2020explaining}
Alexis Ross, Ana Marasovi{\'c}, and Matthew~E Peters.
\newblock Explaining nlp models via minimal contrastive editing (mice).
\newblock {\em arXiv preprint arXiv:2012.13985}, 2020.

\bibitem{serrano2019attention}
Sofia Serrano and Noah~A Smith.
\newblock Is attention interpretable?
\newblock In {\em Proceedings of the 57th Annual Meeting of the Association for
  Computational Linguistics}, pages 2931--2951, 2019.

\bibitem{sha2020learning}
Lei Sha, Oana-Maria Camburu, and Thomas Lukasiewicz.
\newblock Learning from the best: Rationalizing prediction by adversarial
  information calibration.
\newblock {\em arXiv preprint arXiv:2012.08884}, 2020.

\bibitem{simonyan2013deep}
Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
\newblock Deep inside convolutional networks: {Visualising} image
  classification models and saliency maps.
\newblock {\em arXiv preprint arXiv:1312.6034}, 2013.

\bibitem{sundararajan2017axiomatic}
Mukund Sundararajan, Ankur Taly, and Qiqi Yan.
\newblock Axiomatic attribution for deep networks.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 3319--3328. JMLR. org, 2017.

\bibitem{treviso2020explanation}
Marcos Treviso and Andr{\'e}~FT Martins.
\newblock The explanation game: Towards prediction explainability through
  sparse communication.
\newblock In {\em Proceedings of the Third BlackboxNLP Workshop on Analyzing
  and Interpreting Neural Networks for NLP}, pages 107--118, 2020.

\bibitem{tutek2020staying}
Martin Tutek and Jan Snajder.
\newblock Staying true to your word:(how) can attention become explanation?
\newblock In {\em Proceedings of the 5th Workshop on Representation Learning
  for NLP}, pages 131--142, 2020.

\bibitem{wiegreffe2019attention}
Sarah Wiegreffe and Yuval Pinter.
\newblock Attention is not not explanation.
\newblock In {\em Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 11--20, 2019.

\bibitem{xu2015show}
Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan
  Salakhudinov, Rich Zemel, and Yoshua Bengio.
\newblock Show, attend and tell: Neural image caption generation with visual
  attention.
\newblock In {\em International conference on machine learning}, pages
  2048--2057, 2015.

\bibitem{yu2019rethinking}
Mo~Yu, Shiyu Chang, Yang Zhang, and Tommi~S Jaakkola.
\newblock Rethinking cooperative rationalization: Introspective extraction and
  complement control.
\newblock {\em arXiv preprint arXiv:1910.13294}, 2019.

\bibitem{zheng2021irrationality}
Yiming Zheng, Serena Booth, Julie Shah, and Yilun Zhou.
\newblock The irrationality of neural rationale models.
\newblock {\em arXiv preprint arXiv:2110.07550}, 2021.

\end{thebibliography}
