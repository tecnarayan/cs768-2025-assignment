@article{alaoui2022sampling,
  title={Sampling from the Sherrington-Kirkpatrick Gibbs measure via algorithmic stochastic localization},
  author={Alaoui, Ahmed El and Montanari, Andrea and Sellke, Mark},
  journal={arXiv preprint arXiv:2203.05093},
  year={2022}
}

@inproceedings{daniely2017sgd,
  title={{SGD} learns the conjugate kernel class of the network},
  author={Daniely, Amit},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={2419--2427},
  year={2017}
}
@misc{Bao2022AnalyticDPMAA,
  title={Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models},
  author={Fan Bao and Chongxuan Li and Jun Zhu and Bo Zhang},
  journal={ArXiv},
  year={2022},
  note={arXiv:2201.06503}
}
@misc{Bortoli2022ConvergenceOD,
  title={Convergence of denoising diffusion models under the manifold hypothesis},
  author={Valentin DeBortoli},
  journal={ArXiv},
  year={2022},
  note={arXiv:2208.05314}
}
@misc{convergencescore2,
  
  url = {https://arxiv.org/abs/2209.12381},
  
  author = {Lee, Holden and Lu, Jianfeng and Tan, Yixin},
  
  
  title = {Convergence of score-based generative modeling for general data distributions},
  
  publisher = {arXiv},
  
  year = {2022},
  
}

@article{SamplingEasy,
  title={Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions},
  author={Sitan Chen and Sinho Chewi and Jungshian Li and Yuanzhi Li and Adil Salim and Anru R. Zhang},
  journal={ArXiv},
  year={2022},
  volume={abs/2209.11215}
}
  


@inproceedings{Bortoli2021DiffusionSB,
  title={Diffusion Schr{\"o}dinger Bridge with Applications to Score-Based Generative Modeling},
  author={Valentin DeBortoli and James Thornton and Jeremy Heng and A. Doucet},
  booktitle={NeurIPS},
  year={2021}
}
@misc{Block2020GenerativeMW,
  title={Generative Modeling with Denoising Auto-Encoders and Langevin Sampling},
  author={Adam Block and Youssef Mroueh and Alexander Rakhlin},
  journal={ArXiv},
  year={2020},
  note={arXiv:2002.00107}
}
@book{Karatzas1987BrownianMA,
  title={Brownian motion and stochastic calculus},
  author={Karatzas, Ioannis and Shreve, Steven},
  volume={113},
  year={1991},
  publisher={Springer Science \& Business Media}
}
@article{Anderson1982ReversetimeDE,
  title={Reverse-time diffusion equation models},
  author={Brian. D. O. Anderson},
  journal={Stochastic Processes and their Applications},
  year={1982},
  volume={12},
  pages={313-326}
}
@inproceedings{Vempala2019RapidCO,
  title={Rapid Convergence of the Unadjusted Langevin Algorithm: Isoperimetry Suffices},
  author={Santosh S. Vempala and Andre Wibisono},
  booktitle={NeurIPS},
  year={2019}
}

@article{Laurent2000AdaptiveEO,
  title={Adaptive estimation of a quadratic functional by model selection},
  author={B{\'e}atrice Laurent and Pascal Massart},
  journal={Annals of Statistics},
  year={2000},
  volume={28},
  pages={1302-1338}
}
@misc{Boffi2022ProbabilityFS,
  title={Probability flow solution of the Fokker-Planck equation},
  author={Nicholas M. Boffi and Eric Vanden-Eijnden},
  journal={ArXiv},
  year={2022},
  note={arXiv:2206.04642}
}
@InProceedings{pmlr-v178-chewi22a,
  title = 	 {Analysis of Langevin Monte Carlo from Poincare to Log-Sobolev},
  author =       {Chewi, Sinho and Erdogdu, Murat A and Li, Mufan and Shen, Ruoqi and Zhang, Shunshi},
  booktitle = 	 {Proceedings of Thirty Fifth Conference on Learning Theory},
  pages = 	 {1--2},
  year = 	 {2022},
  editor = 	 {Loh, Po-Ling and Raginsky, Maxim},
  volume = 	 {178},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {02--05 Jul},
  publisher =    {PMLR},
}


@misc{convergence-score,
  doi = {10.48550/ARXIV.2206.06227},
  
  url = {https://arxiv.org/abs/2206.06227},
  
  author = {Lee, Holden and Lu, Jianfeng and Tan, Yixin},
  

  
  title = {Convergence for score-based generative modeling with polynomial complexity},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{Song2021DenoisingDI,
  title={Denoising Diffusion Implicit Models},
  author={Jiaming Song and Chenlin Meng and Stefano Ermon},
  journal={ArXiv},
  year={2021},
  note={arXiv:2010.02502}
}
@misc{Zhang2022FastSO,
  title={Fast Sampling of Diffusion Models with Exponential Integrator},
  author={Qinsheng Zhang and Yongxin Chen},
  journal={ArXiv},
  year={2022},
  note={arXiv:2204.13902}
}
@misc{Lu2022DPMSolverAF,
  title={DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps},
  author={Cheng Lu and Yuhao Zhou and Fan Bao and Jianfei Chen and Chongxuan Li and Jun Zhu},
  journal={ArXiv},
  year={2022},
  note={arXiv:2206.00927}
}
@inproceedings{Austin2021StructuredDD,
  title={Structured Denoising Diffusion Models in Discrete State-Spaces},
  author={Jacob Austin and Daniel D. Johnson and Jonathan Ho and Daniel Tarlow and Rianne van den Berg},
  booktitle={NeurIPS},
  year={2021}
}
@article{Vincent2011ACB,
  title={A Connection Between Score Matching and Denoising Autoencoders},
  author={Pascal Vincent},
  journal={Neural Computation},
  year={2011},
  volume={23},
  pages={1661-1674}
}
@article{Rombach2021HighResolutionIS,
  title={High-Resolution Image Synthesis with Latent Diffusion Models},
  author={Robin Rombach and A. Blattmann and Dominik Lorenz and Patrick Esser and Bj{\"o}rn Ommer},
  journal={CVPR},
  year={2021},
}
@article{Dhariwal2021DiffusionMB,
  title={Diffusion Models Beat GANs on Image Synthesis},
  author={Prafulla Dhariwal and Alex Nichol},
  journal={Advances in Neural Information Processing Systems},
  year={2021},
}
@misc{Zhao2016EnergybasedGA,
  title={Energy-based Generative Adversarial Network},
  author={Junbo Jake Zhao and Micha{\"e}l Mathieu and Yann LeCun},
  journal={ArXiv},
  year={2016},
  note={arXiv:1609.03126}
}
@article{Hyvrinen2005EstimationON,
  title={Estimation of Non-Normalized Statistical Models by Score Matching},
  author={Aapo Hyv{\"a}rinen},
  journal={J. Mach. Learn. Res.},
  year={2005},
  volume={6},
  pages={695-709}
}
@inproceedings{Song2019SlicedSM,
  title={Sliced Score Matching: A Scalable Approach to Density and Score Estimation},
  author={Yang Song and Sahaj Garg and Jiaxin Shi and Stefano Ermon},
  booktitle={UAI},
  year={2019}
}
@misc{Chung2021ComeCloserDiffuseFasterAC,
  title={Come-Closer-Diffuse-Faster: Accelerating Conditional Diffusion Models for Inverse Problems through Stochastic Contraction},
  author={Hyungjin Chung and Byeongsu Sim and Jong-Chul Ye},
  journal={ArXiv},
  year={2021},
  note={arXiv:2112.05146}
}
@misc{Song2022SolvingIP,
  title={Solving Inverse Problems in Medical Imaging with Score-Based Generative Models},
  author={Yang Song and Liyue Shen and Lei Xing and Stefano Ermon},
  journal={ArXiv},
  year={2022},
  note={arXiv:2111.08005}
}
@inproceedings{Shi2021LearningGF,
  title={Learning Gradient Fields for Molecular Conformation Generation},
  author={Chence Shi and Shitong Luo and Minkai Xu and Jian Tang},
  booktitle={ICML},
  year={2021}
}
@misc{Gnaneshwar2022ScoreBasedGM,
  title={Score-Based Generative Models for Molecule Generation},
  author={Dwaraknath Gnaneshwar and Bharath Ramsundar and Dhairya Gandhi and Rachel C. Kurchin and Venkatasubramanian Viswanathan},
  journal={ArXiv},
  year={2022},
  note={arXiv:2203.04698}
}
@inproceedings{Wu2022DiffusionbasedMG,
  title={Diffusion-based Molecule Generation with Informative Prior Bridges},
  author={Lemeng Wu and Chengyue Gong and Xingchao Liu and Mao Ye and Qiang Liu},
  year={2022}
}
@misc{Wang2022DiffusionPA,
  title={Diffusion Policies as an Expressive Policy Class for Offline Reinforcement Learning},
  author={Zhendong Wang and Jonathan J. Hunt and Mingyuan Zhou},
  journal={ArXiv},
  year={2022},
  note={arXiv:2208.06193}
}
@misc{Kingma2014AutoEncodingVB,
  title={Auto-Encoding Variational Bayes},
  author={Diederik P. Kingma and Max Welling},
  journal={CoRR},
  year={2014},
  note={arXiv:1312.6114}
}
@inproceedings{JimenezRezende2015VariationalIW,
  title={Variational Inference with Normalizing Flows},
  author={Danilo Jimenez Rezende and Shakir Mohamed},
  booktitle={ICML},
  year={2015}
}
@inproceedings{Goodfellow2014GenerativeAN,
  title={Generative Adversarial Nets},
  author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron C. Courville and Yoshua Bengio},
  booktitle={NIPS},
  year={2014}
}
@inproceedings{SGMSDEsong,
 author = {Yang Song and
               Jascha Sohl{-}Dickstein and
               Diederik P. Kingma and
               Abhishek Kumar and
               Ben Poole},
 booktitle = {International Conference on Learning Representations},
 title = {Score-Based Generative Modeling through Stochastic Differential Equations},
 year = {2020}
}
@inproceedings{SGMsong,
 author = {Song, Yang and Ermon, Stefano},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Generative Modeling by Estimating Gradients of the Data Distribution},
 volume = {32},
 year = {2019}
}


@article{HDP,
  author = {Vershynin, Roman},
  title = {High-Dimensional Probability},
  url = {https://www.math.uci.edu/~rvershyn/papers/HDP-book/HDP-book.pdf},
  year = 2019
}

@inproceedings{Lu2022MaximumLT,
  title={Maximum Likelihood Training for Score-Based Diffusion ODEs by High-Order Denoising Score Matching},
  author={Chengjiang Lu and Kaiwen Zheng and Fan Bao and Jianfei Chen and Chongxuan Li and Jun Zhu},
  booktitle={ICML},
  year={2022}
}
@inproceedings{Song2021MaximumLT,
  title={Maximum Likelihood Training of Score-Based Diffusion Models},
  author={Yang Song and Conor Durkan and Iain Murray and Stefano Ermon},
  booktitle={NeurIPS},
  year={2021}
}
@inproceedings{eldan2016power,
  title={The power of depth for feedforward neural networks},
  author={Eldan, Ronen and Shamir, Ohad},
  booktitle={Conference on learning theory},
  pages={907--940},
  year={2016},
  organization={PMLR}
}
@misc{inexactLangevin,
  url = {https://arxiv.org/abs/2211.01512},
  author = {Wibisono, Andre and Yang, Kaylee Yingxi},
  
  title = {Convergence in KL Divergence of the Inexact Langevin Algorithm with Application to Score-based Generative Models},
  
  publisher = {arXiv},
  
  year = {2022},
  
}


@book{lorentz1966approximation,
  title={Approximation of Functions, Athena Series},
  author={Lorentz, GG},
  year={1966},
  publisher={Holt, Rinehart and Winston, New York}
}

@article{Awasthi2020OnTR,
  title={On the Rademacher Complexity of Linear Hypothesis Sets},
  author={Pranjal Awasthi and Natalie Frank and Mehryar Mohri},
  journal={ArXiv},
  year={2020},
  volume={abs/2007.11045}
}
@article{mei2019generalization,
  title={The Generalization Error of Random Features Regression: Precise Asymptotics and the Double Descent Curve},
  author={Mei, Song and Montanari, Andrea},
  journal={Communications on Pure and Applied Mathematics},
  year={2019},
  publisher={Wiley Online Library}
}
@misc{statistic-efficiency,
  url = {https://arxiv.org/abs/2210.00726},
  author = {Koehler, Frederic and Heckett, Alexander and Risteski, Andrej},

  title = {Statistical Efficiency of Score Matching: The View from Isoperimetry},
  
  publisher = {arXiv},
  
  year = {2022},
}

@article{gribonval2021approximation,
  title={Approximation spaces of deep neural networks},
  author={Gribonval, R{\'e}mi and Kutyniok, Gitta and Nielsen, Morten and Voigtlaender, Felix},
  journal={Constructive Approximation},
  pages={1--109},
  year={2021},
  publisher={Springer}
}

@article{suzuki2019deep,
  title={Deep learning is adaptive to intrinsic dimensionality of model smoothness in anisotropic Besov space},
  author={Suzuki, Taiji and Nitanda, Atsushi},
  journal={arXiv preprint arXiv:1910.12799},
  year={2019}
}


@article{daubechies2019nonlinear,
  title={Nonlinear approximation and (deep) {ReLU} networks},
  author={Daubechies, I and DeVore, R and Foucart, S and Hanin, B and Petrova, G},
  journal={arXiv preprint arXiv:1905.02199},
  year={2021}
}



@inproceedings{zhang2016l1,
  title={{$\ell_1$}-regularized neural networks are improperly learnable in polynomial time},
  author={Zhang, Yuchen and Lee, Jason D and Jordan, Michael I},
  booktitle={International Conference on Machine Learning},
  pages={993--1001},
  year={2016},
  organization={PMLR}
}

@article{shalev2011learning,
  title={Learning kernel-based halfspaces with the 0-1 loss},
  author={Shalev-Shwartz, Shai and Shamir, Ohad and Sridharan, Karthik},
  journal={SIAM Journal on Computing},
  volume={40},
  number={6},
  pages={1623--1646},
  year={2011},
  publisher={SIAM}
}

@article{livni2014computational,
  title={On the Computational Efficiency of Training Neural Networks},
  author={Livni, Roi and Shalev-Shwartz, Shai and Shamir, Ohad},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  pages={855--863},
  year={2014}
}

@inproceedings{ongie2019function,
  title={A Function Space View of Bounded Norm Infinite Width {ReLU} Nets: The Multivariate Case},
  author={Ongie, Greg and Willett, Rebecca and Soudry, Daniel and Srebro, Nathan},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{siegel2020approximation,
  title={Approximation rates for neural networks with general activation functions},
  author={Siegel, Jonathan W and Xu, Jinchao},
  journal={Neural Networks},
  volume={128},
  pages={313--321},
  year={2020},
  publisher={Elsevier}
}

@article{poggio2018theory,
  title={Theory {I}: Deep networks and the curse of dimensionality},
  author={Poggio, T and Liao, Q},
  journal={Bulletin of the Polish Academy of Sciences. Technical Sciences},
  volume={66},
  number={6},
  year={2018}
}

@inproceedings{scetbon2021spectral,
  title={A Spectral Analysis of Dot-product Kernels},
  author={Scetbon, Meyer and Harchaoui, Zaid},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3394--3402},
  year={2021},
  organization={PMLR}
}

@inproceedings{cho2009kernel,
  title={Kernel methods for deep learning},
  author={Cho, Youngmin and Saul, Lawrence K},
  booktitle={Proceedings of the 22nd International Conference on Neural Information Processing Systems},
  pages={342--350},
  year={2009}
}

@inproceedings{bietti2021deep,
title={Deep Equals Shallow for {ReLU} Networks in Kernel Regimes},
author={Alberto Bietti and Francis Bach},
booktitle={International Conference on Learning Representations},
year={2021}
}


@inproceedings{chizat2020implicit,
  title={Implicit bias of gradient descent for wide two-layer neural networks trained with the logistic loss},
  author={Chizat, Lenaic and Bach, Francis},
  booktitle={Conference on Learning Theory},
  pages={1305--1338},
  year={2020},
  organization={PMLR}
}

@article{schoenberg1988positive,
  title={Positive definite functions on spheres},
  author={Schoenberg, IJ and others},
  journal={Duke Mathematical Journal},
  volume={9},
  number={1},
  pages={96--108},
  year={1942}
}

@article{smola2001regularization,
  title={Regularization with dot-product kernels},
  author={Smola, Alex J and Ovari, Zoltan L and Williamson, Robert C},
  journal={Advances in neural information processing systems},
  pages={308--314},
  year={2001},
  publisher={MIT; 1998}
}

@article{aronszajn1950theory,
  title={Theory of reproducing kernels},
  author={Aronszajn, Nachman},
  journal={Transactions of the American mathematical society},
  volume={68},
  number={3},
  pages={337--404},
  year={1950},
  publisher={JSTOR}
}
@misc{Near-Minimax,
  doi = {10.48550/ARXIV.2109.08844},
  url = {https://arxiv.org/abs/2109.08844},
  author = {Parhi, Rahul and Nowak, Robert D.},
  title = {Near-Minimax Optimal Estimation With Shallow ReLU Neural Networks},
  publisher = {arXiv},
  year = {2021}
}

@article{ma2019priori,
  title={A priori estimates of the population risk for two-layer neural networks},
  author={E, Weinan and Ma, Chao and Wu, Lei},
  journal={Communications in Mathematical Sciences},
  volume={17},
  number={5},
  pages={1407--1425},
  year={2019},
  publisher={International Press of Boston}
}


@inproceedings{daniely2017depth,
  title={Depth separation for neural networks},
  author={Daniely, Amit},
  booktitle={Conference on Learning Theory},
  pages={690--696},
  year={2017},
  organization={PMLR}
}

@article{kurkova2001bounds,
  title={Bounds on rates of variable-basis and neural-network approximation},
  author={Kurkov{\'a}, Vera and Sanguineti, Marcello},
  journal={IEEE Transactions on Information Theory},
  volume={47},
  number={6},
  pages={2659--2665},
  year={2001},
  publisher={IEEE}
}


@article{devore1998nonlinear,
  title={Nonlinear approximation},
  author={DeVore, Ronald A},
  journal={Acta numerica},
  volume={7},
  pages={51--150},
  year={1998},
  publisher={Cambridge University Press}
}




@article{wojtowytsch2020some,
  title={Some observations on partial differential equations in {Barron} and multi-layer spaces},
  author={E, Weinan and Wojtowytsch, Stephan},
  journal={arXiv preprint arXiv:2012.01484},
  year={2020}
}

@article{weinan2021barron,
  title={The {Barron} Space and the Flow-Induced Function Spaces for Neural Network Models},
  author={E, Weinan and Ma, Chao and Wu, Lei},
  journal={Constructive Approximation},
  pages={1--38},
  year={2021},
  publisher={Springer}
}


@book{ledoux2013probability,
  title={Probability in Banach Spaces: isoperimetry and processes},
  author={Ledoux, Michel and Talagrand, Michel},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@inproceedings{rahimi2008uniform,
  title={Uniform approximation of functions with random bases},
  author={Rahimi, Ali and Recht, Benjamin},
  booktitle={2008 46th Annual Allerton Conference on Communication, Control, and Computing},
  pages={555--561},
  year={2008},
  organization={IEEE}
}

@book{mohri2018foundations,
  title={Foundations of machine learning},
  author={Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
  year={2018},
  publisher={MIT press}
}



@book{traub1983information,
  title={Information, uncertainty, complexity},
  author={Traub, Joseph Frederick and Wasilkowski, Grzegorz W{\l}odzimierz and Wo{\'z}niakowski, Henryk},
  year={1983},
  publisher={Addison-Wesley Reading, MA}
}

@book{stein2011functional,
  title={Functional analysis: introduction to further topics in analysis},
  author={Stein, Elias M and Shakarchi, Rami},
  volume={4},
  year={2011},
  publisher={Princeton University Press}
}

@article{jolliffe2003principal,
  title={Principal component analysis},
  author={Jolliffe, IT},
  journal={Technometrics},
  volume={45},
  number={3},
  pages={276},
  year={2003},
  publisher={American Society for Quality}
}

@article{bach2017breaking,
  title={Breaking the curse of dimensionality with convex neural networks},
  author={Bach, Francis},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={629--681},
  year={2017},
  publisher={JMLR. org}
}
@inproceedings{Vaart1998AsymptoticSF,
  title={Asymptotic Statistics: Frontmatter},
  author={Aad van der Vaart},
  year={1998}
}
@article{Bartolucci2021UnderstandingNN,
  title={Understanding neural networks with reproducing kernel Banach spaces},
  author={Francesca Bartolucci and Ernesto de Vito and Lorenzo Rosasco and Stefano Vigogna},
  journal={ArXiv},
  year={2021},
  volume={abs/2109.09710}
}
@article{Parhi2021BanachSR,
  title={Banach Space Representer Theorems for Neural Networks and Ridge Splines},
  author={Rahul Parhi and Robert D. Nowak},
  journal={J. Mach. Learn. Res.},
  year={2021},
  volume={22},
  pages={43:1-43:40}
}
@article{Zhang2009ReproducingKB,
  title={Reproducing kernel Banach spaces for machine learning},
  author={Haizhang Zhang and Yuesheng Xu and Jun Zhang},
  journal={2009 International Joint Conference on Neural Networks},
  year={2009},
  pages={3520-3527}
}
@article{Kuo2008MultivariateLA,
  title={Multivariate $L^\infty$ approximation in the worst case setting over reproducing kernel Hilbert spaces},
  author={Frances Y. Kuo and Grzegorz W. Wasilkowski and Henryk Wozniakowski},
  journal={J. Approx. Theory},
  year={2008},
  volume={152},
  pages={135-160}
}
@inproceedings{Rao1991TheoryOO,
  title={Theory of Orlicz spaces},
  author={Malempati M. Rao and Zhong Dao Ren},
  year={1991}
}
@inproceedings{Ren2002ApplicationsOO,
  title={Applications Of Orlicz Spaces},
  author={Zhong Dao Ren and Malempati M. Rao},
  year={2002}
}
@article{Lin2019OnRK,
  title={On Reproducing Kernel Banach Spaces: Generic Definitions and Unified Framework of Constructions},
  author={Rongrong Lin and Haizhang Zhang and Jun Zhang},
  journal={ArXiv},
  year={2019},
  volume={abs/1901.01002}
}
@article{Unser2021AUR,
  title={A Unifying Representer Theorem for Inverse Problems and Machine Learning},
  author={Michael A. Unser},
  journal={Found. Comput. Math.},
  year={2021},
  volume={21},
  pages={941-960}
}
@article{Zhou2020OnUC,
  title={On Uniform Convergence and Low-Norm Interpolation Learning},
  author={Lijia Zhou and Danica J. Sutherland and Nathan Srebro},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.05942}
}
@article{novak2006deterministic,
  title={Deterministic and stochastic error bounds in numerical analysis},
  author={Novak, Erich},
  year={2006},
  publisher={Springer}
}

@article{spruill2007asymptotic,
  title={Asymptotic distribution of coordinates on high dimensional spheres},
  author={Spruill, Marcus},
  journal={Electronic communications in probability},
  volume={12},
  pages={234--247},
  year={2007},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@misc{vershynin2019high,
  title={High-dimensional probability},
  author={Vershynin, Roman},
  year={2019},
  publisher={Cambridge, UK: Cambridge University Press}
}



@article{schmidt2020nonparametric,
  title={Nonparametric regression using deep neural networks with ReLU activation function},
  author={Schmidt-Hieber, Johannes and others},
  journal={Annals of Statistics},
  volume={48},
  number={4},
  pages={1875--1897},
  year={2020},
  publisher={Institute of Mathematical Statistics}
}
@InProceedings{songmeiGap,
  title = 	 {Exact Gap between Generalization Error and Uniform Convergence in Random Feature Models},
  author =       {Yang, Zitong and Bai, Yu and Mei, Song},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {11704--11715},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  url = 	 {https://proceedings.mlr.press/v139/yang21a.html}
}
@inproceedings{Rahimi2007RandomFF,
  title={Random Features for Large-Scale Kernel Machines},
  author={Ali Rahimi and Benjamin Recht},
  booktitle={NIPS},
  year={2007}
}
@article{MEI2021,
title = {Generalization error of random feature and kernel methods: Hypercontractivity and kernel matrix concentration},
journal = {Applied and Computational Harmonic Analysis},
year = {2021},
issn = {1063-5203},
doi = {https://doi.org/10.1016/j.acha.2021.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S1063520321001044},
author = {Song Mei and Theodor Misiakiewicz and Andrea Montanari}
}
@inproceedings{convexneural,
 author = {Bengio, Yoshua and Roux, Nicolas and Vincent, Pascal and Delalleau, Olivier and Marcotte, Patrice},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Y. Weiss and B. Sch\"{o}lkopf and J. Platt},
 publisher = {MIT Press},
 title = {Convex Neural Networks},
 url = {https://proceedings.neurips.cc/paper/2005/file/0fc170ecbb8ff1afb2c6de48ea5343e7-Paper.pdf},
 volume = {18},
 year = {2005}
}


@article{ghorbani2021linearized,
  title={Linearized two-layers neural networks in high dimension},
  author={Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
  journal={The Annals of Statistics},
  volume={49},
  number={2},
  pages={1029--1054},
  year={2021},
  publisher={Institute of Mathematical Statistics}
}
@inproceedings{Rudi2017GeneralizationPO,
  title={Generalization Properties of Learning with Random Features},
  author={Alessandro Rudi and Lorenzo Rosasco},
  booktitle={NIPS},
  year={2017}
}
@article{Celentano2021MinimumCI,
  title={Minimum complexity interpolation in random features models},
  author={Michael Celentano and Theodor Misiakiewicz and Andrea Montanari},
  journal={ArXiv},
  year={2021},
  volume={abs/2103.15996}
}
@article{Asymptotic-Distribution,
author = {Marcus Spruill},
title = {{Asymptotic Distribution of Coordinates on High Dimensional Spheres}},
volume = {12},
journal = {Electronic Communications in Probability},
publisher = {Institute of Mathematical Statistics and Bernoulli Society},
pages = {234 -- 247},
keywords = {dependent arrays, empiric distribution, Isoperimetry, micro-canonical ensemble, Minkowski area},
year = {2007}
}
@misc{linearapprox,
  doi = {10.48550/ARXIV.2108.04964},
  year = 	 {2021}, 
  url = {https://arxiv.org/abs/2108.04964},
  
  author = {Lei Wu and Jihao Long},
  
  title = {A spectral-based analysis of the separation between two-layer neural networks and linear methods}}
@inproceedings{localRad,
 author = {Srebro, Nathan and Sridharan, Karthik and Tewari, Ambuj},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Lafferty and C. Williams and J. Shawe-Taylor and R. Zemel and A. Culotta},
 publisher = {Curran Associates, Inc.},
 title = {Smoothness, Low Noise and Fast Rates},
 url = {https://proceedings.neurips.cc/paper/2010/file/76cf99d3614e23eabab16fb27e944bf9-Paper.pdf},
 volume = {23},
 year = {2010}
}

@article{Jinchao2022,
title = {High-order approximation rates for shallow neural networks with cosine and ReLUk activation functions},
journal = {Applied and Computational Harmonic Analysis},
volume = {58},
pages = {1-26},
year = {2022},
doi = {https://doi.org/10.1016/j.acha.2021.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S1063520321001056},
author = {Jonathan W. Siegel and Jinchao Xu},
keywords = {Neural networks, Approximation rates, Approximation lower bounds, Finite element methods},
}

@article{barron1993universal,
  title={Universal approximation bounds for superpositions of a sigmoidal function},
  author={Barron, Andrew R.},
  journal={IEEE Transactions on Information theory},
  volume={39},
  number={3},
  pages={930--945},
  year={1993},
  publisher={IEEE}
}

@article{barron1994approximation,
  title={Approximation and estimation bounds for artificial neural networks},
  author={Barron, Andrew R},
  journal={Machine Learning},
  volume={14},
  number={1},
  pages={115--133},
  year={1994},
  publisher={Springer}
}


@inproceedings{suzuki2018adaptivity,
title={Adaptivity of deep {ReLU} network for learning in {Besov} and mixed smooth {Besov} spaces: optimal rate and curse of dimensionality},
author={Taiji Suzuki},
booktitle={International Conference on Learning Representations},
year={2019}
}


@article{krizhevsky2017imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Communications of the ACM},
  volume={60},
  number={6},
  pages={84--90},
  year={2017},
  publisher={AcM New York, NY, USA}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}


@article{ma2020towards,
  title={Towards a Mathematical Understanding of Neural Network-Based Machine Learning: what we know and what we don't},
  author={Ma, Chao and Wojtowytsch, Stephan and Wu, Lei and others},
  journal={arXiv preprint arXiv:2009.10713},
  year={2020}
}

@article{makovoz1998uniform,
  title={Uniform approximation by neural networks},
  author={Makovoz, Yuly},
  journal={Journal of Approximation Theory},
  volume={95},
  number={2},
  pages={215--228},
  year={1998},
  publisher={Elsevier}
}

@inproceedings{barron1992neural,
  title={Neural net approximation},
  author={Barron, Andrew R},
  booktitle={Proc. 7th Yale Workshop on Adaptive and Learning Systems},
  volume={1},
  pages={69--72},
  year={1992}
}

@article{kuo2008multivariate,
  title={Multivariate {$L^\infty$} approximation in the worst case setting over reproducing kernel Hilbert spaces},
  author={Kuo, Frances Y and Wasilkowski, Grzegorz W and Wo{\'z}niakowski, Henryk},
  journal={Journal of Approximation Theory},
  volume={152},
  number={2},
  pages={135--160},
  year={2008},
  publisher={Academic Press}
}


@inproceedings{steinwart2009optimal,
  title={Optimal Rates for Regularized Least Squares Regression.},
  author={Steinwart, Ingo and Hush, Don R and Scovel, Clint and others},
  booktitle={COLT},
  pages={79--93},
  year={2009}
}


@inproceedings{daniely2016toward,
  title={Toward deeper understanding of neural networks: The power of initialization and a dual view on expressivity},
  author={Daniely, Amit and Frostig, Roy and Singer, Yoram},
  booktitle={Advances In Neural Information Processing Systems},
  pages={2253--2261},
  year={2016}
}

@article{yehudai2019power,
  title={On the Power and Limitations of Random Features for Understanding Neural Networks},
  author={Yehudai, Gilad and Shamir, Ohad},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={6598--6608},
  year={2019}
}

@inproceedings{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle={Advances in neural information processing systems},
  pages={8571--8580},
  year={2018}
}


@inproceedings{arora2019exact,
  title={On exact computation with an infinitely wide neural net},
  author={Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8141--8150},
  year={2019}
}

@article{eckart1936approximation,
  title={The approximation of one matrix by another of lower rank},
  author={Eckart, Carl and Young, Gale},
  journal={Psychometrika},
  volume={1},
  number={3},
  pages={211--218},
  year={1936},
  publisher={Springer}
}

@article{misra2019mish,
  title={Mish: A self regularized non-monotonic activation function},
  author={Misra, Diganta},
  journal={arXiv preprint arXiv:1908.08681},
  year={2019}
}

@book{o2014analysis,
  title={Analysis of boolean functions},
  author={O'Donnell, Ryan},
  year={2014},
  publisher={Cambridge University Press}
}

@article{ros2019complex,
  title={Complex energy landscapes in spiked-tensor and simple glassy models: Ruggedness, arrangements of local minima, and phase transitions},
  author={Ros, Valentina and Arous, Gerard Ben and Biroli, Giulio and Cammarota, Chiara},
  journal={Physical Review X},
  volume={9},
  number={1},
  pages={011003},
  year={2019},
  publisher={APS}
}


@article{auer1996exponentially,
  title={Exponentially many local minima for single neurons},
  author={Auer, Peter and Herbster, Mark and Warmuth, Manfred K and others},
  journal={Advances in neural information processing systems},
  pages={316--322},
  year={1996},
  publisher={Morgan Kaufmann Publishers}
}

@article{brady1989back,
  title={Back propagation fails to separate where perceptrons succeed},
  author={Brady, Martin L and Raghavan, Raghu and Slawny, Joseph},
  journal={IEEE Transactions on Circuits and Systems},
  volume={36},
  number={5},
  pages={665--674},
  year={1989},
  publisher={IEEE}
}

@article{sun2018geometric,
  title={A geometric analysis of phase retrieval},
  author={Sun, Ju and Qu, Qing and Wright, John},
  journal={Foundations of Computational Mathematics},
  volume={18},
  number={5},
  pages={1131--1198},
  year={2018},
  publisher={Springer}
}

@inproceedings{kalan2019fitting,
  title={Fitting relus via sgd and quantized sgd},
  author={Kalan, Seyed Mohammadreza Mousavi and Soltanolkotabi, Mahdi and Avestimehr, A Salman},
  booktitle={2019 IEEE International Symposium on Information Theory (ISIT)},
  pages={2469--2473},
  year={2019},
  organization={IEEE}
}

@article{soltanolkotabi2017learning,
  title={Learning relus via gradient descent},
  author={Soltanolkotabi, Mahdi},
  journal={arXiv preprint arXiv:1705.04591},
  year={2017}
}

@InProceedings{maillard20a, 
  title = {Landscape Complexity for the Empirical Risk of Generalized Linear Models}, 
  author = {Maillard, Antoine and Ben Arous, G\'erard and Biroli, Giulio}, 
  booktitle = {Proceedings of The First Mathematical and Scientific Machine Learning Conference}, pages = {287--327}, 
  year = {2020}, 
  volume = {107}, 
  month = {20--24 Jul}, 
  publisher = {PMLR}
}

@article{tan2019online,
  title={Online stochastic gradient descent with arbitrary initialization solves non-smooth, non-convex phase retrieval},
  author={Tan, Yan Shuo and Vershynin, Roman},
  journal={arXiv preprint arXiv:1910.12837},
  year={2019}
}


@article{chen2019gradient,
  title={Gradient descent with random initialization: Fast global convergence for nonconvex phase retrieval},
  author={Chen, Yuxin and Chi, Yuejie and Fan, Jianqing and Ma, Cong},
  journal={Mathematical Programming},
  volume={176},
  number={1},
  pages={5--37},
  year={2019},
  publisher={Springer}
}


@article{kakade2011efficient,
  title={Efficient learning of generalized linear and single index models with isotonic regression},
  author={Kakade, Sham and Kalai, Adam Tauman and Kanade, Varun and Shamir, Ohad},
  journal={arXiv preprint arXiv:1104.2018},
  year={2011}
}

@article{mei2018landscape,
  title={The landscape of empirical risk for nonconvex losses},
  author={Mei, Song and Bai, Yu and Montanari, Andrea and others},
  journal={Annals of Statistics},
  volume={46},
  number={6A},
  pages={2747--2774},
  year={2018},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{oymak2019overparameterized,
  title={Overparameterized nonlinear learning: Gradient descent takes the shortest path?},
  author={Oymak, Samet and Soltanolkotabi, Mahdi},
  booktitle={International Conference on Machine Learning},
  pages={4951--4960},
  year={2019},
  organization={PMLR}
}


@article{weinan2020comparative,
  title={A comparative analysis of optimization and generalization properties of two-layer neural network and random feature models under gradient descent dynamics},
  author={Weinan, E and Ma, Chao and Wu, Lei},
  journal={Science China Mathematics},
  pages={1--24},
  year={2020},
  publisher={Springer}
}


@misc{Fast-rates-for-noisy-interpolation,
  doi = {10.48550/ARXIV.2203.03597},
  
  url = {https://arxiv.org/abs/2203.03597},
  
  author = {Donhauser, Konstantin and Ruggeri, Nicolo and Stojanovic, Stefan and Yang, Fanny},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Fast rates for noisy interpolation require rethinking the effects of inductive bias},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@book{wainwright2019high,
  title={High-Dimensional Statistics: A Non-Asymptotic Viewpoint},
  author={Wainwright, M.J.},
  series={Cambridge Series in Statistical and Probabilistic Mathematics},
  year={2019},
  publisher={Cambridge University Press}
}


@article{klusowski2016risk,
  title={Risk bounds for high-dimensional ridge function combinations including neural networks},
  author={Klusowski, Jason M and Barron, Andrew R},
  journal={arXiv preprint arXiv:1607.01434},
  year={2016}
}


@inproceedings{kalai2009isotron,
  title={The Isotron Algorithm: High-Dimensional Isotonic Regression.},
  author={Kalai, Adam Tauman and Sastry, Ravi},
  booktitle={COLT},
  year={2009},
  organization={Citeseer}
}

@article{du2017convolutional,
  title={When is a convolutional filter easy to learn?},
  author={Du, Simon S and Lee, Jason D and Tian, Yuandong},
  journal={arXiv preprint arXiv:1709.06129},
  year={2017}
}

@inproceedings{goel2017reliably,
  title={Reliably learning the relu in polynomial time},
  author={Goel, Surbhi and Kanade, Varun and Klivans, Adam and Thaler, Justin},
  booktitle={Conference on Learning Theory},
  pages={1004--1042},
  year={2017},
  organization={PMLR}
}

@article{kakade2011efficient,
  title={Efficient learning of generalized linear and single index models with isotonic regression},
  author={Kakade, Sham and Kalai, Adam Tauman and Kanade, Varun and Shamir, Ohad},
  journal={arXiv preprint arXiv:1104.2018},
  year={2011}
}

@article{tessera2021keep,
  title={Keep the Gradients Flowing: Using Gradient Flow to Study Sparse Network Optimization},
  author={Tessera, Kale-ab and Hooker, Sara and Rosman, Benjamin},
  journal={arXiv preprint arXiv:2102.01670},
  year={2021}
}

@article{xie2020smooth,
  title={Smooth adversarial training},
  author={Xie, Cihang and Tan, Mingxing and Gong, Boqing and Yuille, Alan and Le, Quoc V},
  journal={arXiv preprint arXiv:2006.14536},
  year={2020}
}


@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal={arXiv preprint arXiv:1706.03762},
  year={2017}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018}
}


@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{elfwing2018sigmoid,
  title={Sigmoid-weighted linear units for neural network function approximation in reinforcement learning},
  author={Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
  journal={Neural Networks},
  volume={107},
  pages={3--11},
  year={2018},
  publisher={Elsevier}
}

@article{ramachandran2017searching,
  title={Searching for activation functions},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.05941},
  year={2017}
}


@article{chen2020comparison,
  title={A Comparison Study of Deep Galerkin Method and Deep Ritz Method for Elliptic Problems with Different Boundary Conditions},
  author={Chen, Jingrun and Du, Rui and Wu, Keke},
  journal={arXiv e-prints},
  pages={arXiv--2005},
  year={2020}
}

@article{liang2021reproducing,
  title={Reproducing Activation Function for Deep Learning},
  author={Liang, Senwei and Lyu, Liyao and Wang, Chunmei and Yang, Haizhao},
  journal={arXiv preprint arXiv:2101.04844},
  year={2021}
}

@article{li2020multi,
  title={A multi-scale DNN algorithm for nonlinear elliptic equations with multiple scales},
  author={Li, Xi-An and Xu, Zhi-Qin John and Zhang, Lei},
  journal={Communications in Computational Physics},
  volume={28},
  number={5},
  pages={1886--1906},
  year={2020}
}

@article{sitzmann2020implicit,
  title={Implicit neural representations with periodic activation functions},
  author={Sitzmann, Vincent and Martel, Julien and Bergman, Alexander and Lindell, David and Wetzstein, Gordon},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{shamir2018distribution,
  title={Distribution-specific hardness of learning neural networks},
  author={Shamir, Ohad},
  journal={The Journal of Machine Learning Research},
  volume={19},
  number={1},
  pages={1135--1163},
  year={2018},
  publisher={JMLR. org}
}


@article{goel2020statistical,
  title={Statistical-query lower bounds via functional gradients},
  author={Goel, Surbhi and Gollakota, Aravind and Klivans, Adam},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}


@inproceedings{blum1994weakly,
  title={Weakly learning DNF and characterizing statistical query learning using Fourier analysis},
  author={Blum, Avrim and Furst, Merrick and Jackson, Jeffrey and Kearns, Michael and Mansour, Yishay and Rudich, Steven},
  booktitle={Proceedings of the twenty-sixth annual ACM symposium on Theory of computing},
  pages={253--262},
  year={1994}
}

@article{kearns1998efficient,
  title={Efficient noise-tolerant learning from statistical queries},
  author={Kearns, Michael},
  journal={Journal of the ACM (JACM)},
  volume={45},
  number={6},
  pages={983--1006},
  year={1998},
  publisher={ACM New York, NY, USA}
}


@inproceedings{goel2020superpolynomial,
  title={Superpolynomial lower bounds for learning one-layer neural networks using gradient descent},
  author={Goel, Surbhi and Gollakota, Aravind and Jin, Zhihan and Karmalkar, Sushrut and Klivans, Adam},
  booktitle={International Conference on Machine Learning},
  pages={3587--3596},
  year={2020},
  organization={PMLR}
}


@inproceedings{diakonikolas2020algorithms,
  title={Algorithms and {SQ} lower bounds for {PAC} learning one-hidden-layer relu networks},
  author={Diakonikolas, Ilias and Kane, Daniel M and Kontonis, Vasilis and Zarifis, Nikos},
  booktitle={Conference on Learning Theory},
  pages={1514--1539},
  year={2020},
  organization={PMLR}
}

@article{abbe2020universality,
  title={On the universality of deep learning},
  author={Abbe, Emmanuel and Sandon, Colin},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}


@article{chen2020learning,
  title={Learning Deep ReLU Networks Is Fixed-Parameter Tractable},
  author={Chen, Sitan and Klivans, Adam R and Meka, Raghu},
  journal={arXiv preprint arXiv:2009.13512},
  year={2020}
}

@article{daniely2020hardness,
  title={Hardness of Learning Neural Networks with Natural Weights},
  author={Daniely, Amit and Vardi, Gal},
  journal={arXiv preprint arXiv:2006.03177},
  year={2020}
}



@article{yehudai2020learning,
  title={Learning a Single Neuron with Gradient Methods},
  author={Yehudai, Gilad and Shamir, Ohad},
  journal={arXiv preprint arXiv:2001.05205},
  year={2020}
}

@article{malach2020hardness,
  title={When Hardness of Approximation Meets Hardness of Learning},
  author={Malach, Eran and Shalev-Shwartz, Shai},
  journal={arXiv preprint arXiv:2008.08059},
  year={2020}
}

@inproceedings{goel2017reliably,
  title={Reliably learning the relu in polynomial time},
  author={Goel, Surbhi and Kanade, Varun and Klivans, Adam and Thaler, Justin},
  booktitle={Conference on Learning Theory},
  pages={1004--1042},
  year={2017},
  organization={PMLR}
}


@inproceedings{goel2019time,
  title={Time/Accuracy Tradeoffs for Learning a ReLU with respect to Gaussian Marginals},
  author={Goel, Surbhi and Karmalkar, Sushrut and Klivans, Adam},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8584--8593},
  year={2019}
}

@article{goel2020statistical,
  title={Statistical-query lower bounds via functional gradients},
  author={Goel, Surbhi and Gollakota, Aravind and Klivans, Adam},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{goel2017eigenvalue,
  title={Eigenvalue decay implies polynomial-time learnability for neural networks},
  author={Goel, Surbhi and Klivans, Adam},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2192--2202},
  year={2017}
}

@article{diakonikolas2020near,
  title={Near-optimal sq lower bounds for agnostically learning halfspaces and relus under gaussian marginals},
  author={Diakonikolas, Ilias and Kane, Daniel and Zarifis, Nikos},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{malach2020computational,
  title={Computational Separation Between Convolutional and Fully-Connected Networks},
  author={Malach, Eran and Shalev-Shwartz, Shai},
  journal={arXiv preprint arXiv:2010.01369},
  year={2020}
}

@article{daniely2020learning,
  title={Learning Parities with Neural Networks},
  author={Daniely, Amit and Malach, Eran},
  journal={arXiv preprint arXiv:2002.07400},
  year={2020}
}

@article{malach2020implications,
  title={The Implications of Local Correlation on Learning Some Deep Functions},
  author={Malach, Eran and Shalev-Shwartz, Shai},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{ghorbani2021,
  title={Linearized two-layers neural networks in high dimension},
  author={Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
  journal={The Annals of Statistics},
  volume={49},
  number={2},
  pages={1029--1054},
  year={2021},
  publisher={Institute of Mathematical Statistics}
}

@article{ghorbani2020neural,
  title={When do neural networks outperform kernel methods?},
  author={Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
  journal={arXiv preprint arXiv:2006.13409},
  year={2020}
}


@article{geifman2020similarity,
  title={On the similarity between the laplace and neural tangent kernels},
  author={Geifman, Amnon and Yadav, Abhay and Kasten, Yoni and Galun, Meirav and Jacobs, David and Basri, Ronen},
  journal={arXiv preprint arXiv:2007.01580},
  year={2020}
}



@inproceedings{chen2021deep,
title={Deep Neural Tangent Kernel and {Laplace} Kernel Have the Same {RKHS}},
author={Lin Chen and Sheng Xu},
booktitle={International Conference on Learning Representations},
year={2021}
}

@article{lu2021priori-b,
  title={A Priori Generalization Analysis of the Deep Ritz Method for Solving High Dimensional Elliptic Equations},
  author={Lu, Jianfeng and Lu, Yulong and Wang, Min},
  journal={arXiv preprint arXiv:2101.01708},
  year={2021}
}

@article{lu2021priori,
  title={A Priori Generalization Error Analysis of Two-Layer Neural Networks for Solving High Dimensional {S}chr{\"o}dinger Eigenvalue Problems},
  author={Lu, Jianfeng and Lu, Yulong},
  journal={arXiv preprint arXiv:2105.01228},
  year={2021}
}

@article{frei2020agnostic,
  title={Agnostic learning of a single neuron with gradient descent},
  author={Frei, Spencer and Cao, Yuan and Gu, Quanquan},
  journal={arXiv preprint arXiv:2005.14426},
  year={2020}
}

@article{panigrahi2019effect,
  title={Effect of activation functions on the training of overparametrized neural nets},
  author={Panigrahi, Abhishek and Shetty, Abhishek and Goyal, Navin},
  journal={arXiv preprint arXiv:1908.05660},
  year={2019}
}

@inproceedings{chen2020dynamical,
 author = {Chen, Zhengdao and Rotskoff, Grant and Bruna, Joan and Vanden-Eijnden, Eric},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {A Dynamical Central Limit Theorem for Shallow Neural Networks},
 year = {2020}
}


@article{hendrycks2016gaussian,
  title={Gaussian error linear units ({GELUs})},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{bietti2019inductive,
  title={On the inductive bias of neural tangent kernels},
  author={Bietti, Alberto and Mairal, Julien},
  journal={arXiv preprint arXiv:1905.12173},
  year={2019}
}

@inproceedings{carratino2018learning,
  title={Learning with {SGD} and random features},
  author={Carratino, Luigi and Rudi, Alessandro and Rosasco, Lorenzo},
  booktitle={Proceedings of the 32nd International Conference on Neural Information Processing Systems},
  pages={10213--10224},
  year={2018}
}

@article{bach2017equivalence,
  title={On the equivalence between kernel quadrature rules and random feature expansions},
  author={Bach, Francis},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={714--751},
  year={2017},
}

@inproceedings{xie2017diverse,
  title={Diverse neural network learns true target functions},
  author={Xie, Bo and Liang, Yingyu and Song, Le},
  booktitle={Artificial Intelligence and Statistics},
  pages={1216--1224},
  year={2017},
  organization={PMLR}
}

@book{atkinson2012spherical,
  title={Spherical harmonics and approximations on the unit sphere: {An} introduction},
  author={Atkinson, Kendall and Han, Weimin},
  volume={2044},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{ozdemir2020fourier,
  title={The Fourier transform of the first derivative of the generalized logistic growth curve},
  author={{\"O}ZDEM{\.I}R, Yunus and B{\.I}LGE, Ay{\c{s}}e H{\"u}meyra},
  journal={International Journal of Advances in Engineering and Pure Sciences},
  volume={32},
  number={1},
  pages={52--56},
  year={2020}
}

@book{olver2010nist,
  title={NIST handbook of mathematical functions},
  author={Olver, Frank WJ and Lozier, Daniel W and Boisvert, Ronald F and Clark, Charles W},
  year={2010},
  publisher={Cambridge university press},
  howpublished={\url{http://my.url.com/}}
}

@book{varadhan1984large,
  title={Large deviations and applications},
  author={Varadhan, SR Srinivasa},
  year={1984},
  publisher={SIAM}
}

@article{siegel2020high,
  title={High-Order Approximation Rates for Neural Networks with {ReLU$^k$} Activation Functions},
  author={Siegel, Jonathan W and Xu, Jinchao},
  journal={arXiv preprint arXiv:2012.07205},
  year={2020}
}

@article{li2019better,
  title={Better approximations of high dimensional smooth functions by deep neural networks with rectified power units},
  author={Li, Bo and Tang, Shanshan and Yu, Haijun},
  journal={arXiv preprint arXiv:1903.05858},
  year={2019}
}

@article{weinan2018deep,
  title={The deep {Ritz} method: {A} deep learning-based numerical algorithm for solving variational problems},
  author={Weinan, E and Yu, Bing},
  journal={Communications in Mathematics and Statistics},
  volume={6},
  number={1},
  pages={1--12},
  year={2018},
  publisher={Springer}
}
@article{lee2021universal,
  title={Universal Approximation for Log-concave Distributions using Well-conditioned Normalizing Flows},
  author={Lee, Holden and Pabbaraju, Chirag and Sevekari, Anish and Risteski, Andrej},
  journal={arXiv preprint arXiv:2107.02951},
  year={2021}
}
@article{dockhorn2021score,
  title={Score-based generative modeling with critically-damped langevin diffusion},
  author={Dockhorn, Tim and Vahdat, Arash and Kreis, Karsten},
  journal={arXiv preprint arXiv:2112.07068},
  year={2021}
}