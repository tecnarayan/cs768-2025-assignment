\begin{thebibliography}{38}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2019)Agarwal, Dudik, and Wu]{agarwal2019fair}
A.~Agarwal, M.~Dudik, and Z.~S. Wu.
\newblock Fair regression: Quantitative definitions and reduction-based
  algorithms.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Allen-Zhu(2021)]{allenzhu2021make}
Z.~Allen-Zhu.
\newblock How to make the gradients small stochastically: Even faster convex
  and nonconvex sgd, 2021.

\bibitem[Arjevani et~al.(2023)Arjevani, Carmon, Duchi, Foster, Srebro, and
  Woodworth]{arjevani2023lower}
Y.~Arjevani, Y.~Carmon, J.~Duchi, D.~Foster, N.~Srebro, and B.~Woodworth.
\newblock Lower bounds for non-convex stochastic optimization.
\newblock \emph{Mathematical Programming}, 199\penalty0 (1-2):\penalty0
  165--214, 2023.

\bibitem[Barocas et~al.(2018)Barocas, Hardt, and
  Narayanan]{barocas-hardt-narayanan}
S.~Barocas, M.~Hardt, and A.~Narayanan.
\newblock \emph{Fairness and Machine Learning}.
\newblock fairmlbook.org, 2018.

\bibitem[Beck(2014)]{beck2014introduction}
A.~Beck.
\newblock \emph{Introduction to nonlinear optimization: Theory, algorithms, and
  applications with MATLAB}.
\newblock SIAM, 2014.

\bibitem[Bhatia and Davis(2000)]{bhatia2000}
R.~Bhatia and C.~Davis.
\newblock A better bound on the variance.
\newblock \emph{The American Mathematical Monthly}, 107\penalty0 (4):\penalty0
  353--357, 2000.
\newblock \doi{10.1080/00029890.2000.12005203}.

\bibitem[Boyd and Vandenberghe(2004)]{boyd2004convex}
S.~Boyd and L.~Vandenberghe.
\newblock \emph{Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem[Calders et~al.(2009)Calders, Kamiran, and
  Pechenizkiy]{calders2009building}
T.~Calders, F.~Kamiran, and M.~Pechenizkiy.
\newblock Building classifiers with independency constraints.
\newblock In \emph{IEEE international conference on Data mining}, 2009.

\bibitem[Chiappa et~al.(2020)Chiappa, Jiang, Stepleton, Pacchiano, Jiang, and
  Aslanides]{chiappa2020general}
S.~Chiappa, R.~Jiang, T.~Stepleton, A.~Pacchiano, H.~Jiang, and J.~Aslanides.
\newblock A general approach to fairness with optimal transport.
\newblock In \emph{AAAI}, 2020.

\bibitem[Chzhen and Schreuder(2020{\natexlab{a}})]{chzhen2020example}
E.~Chzhen and N.~Schreuder.
\newblock An example of prediction which complies with demographic parity and
  equalizes group-wise risks in the context of regression.
\newblock \emph{arXiv preprint arXiv:2011.07158}, 2020{\natexlab{a}}.

\bibitem[Chzhen and Schreuder(2020{\natexlab{b}})]{chzhen2020minimax}
E.~Chzhen and N.~Schreuder.
\newblock A minimax framework for quantifying risk-fairness trade-off in
  regression.
\newblock \emph{arXiv preprint arXiv:2007.14265v2}, 2020{\natexlab{b}}.

\bibitem[Chzhen et~al.(2019)Chzhen, Denis, Hebiri, Oneto, and
  Pontil]{Chzhen_Denis_Hebiri_Oneto_Pontil19}
E.~Chzhen, C.~Denis, M.~Hebiri, L.~Oneto, and M.~Pontil.
\newblock Leveraging labeled and unlabeled data for consistent fair binary
  classification.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Chzhen et~al.(2020{\natexlab{a}})Chzhen, Denis, Hebiri, Oneto, and
  Pontil]{chzhen2020-wass}
E.~Chzhen, C.~Denis, M.~Hebiri, L.~Oneto, and M.~Pontil.
\newblock Fair regression with wasserstein barycenters.
\newblock \emph{NeurIPS 2020}, 2020{\natexlab{a}}.

\bibitem[Chzhen et~al.(2020{\natexlab{b}})Chzhen, Denis, Oneto, and
  Pontil]{chzhen2020-discr}
E.~Chzhen, M.~Denis, C.and~Hebiri, L.~Oneto, and M.~Pontil.
\newblock Fair regression via plug-in estimator and recalibration.
\newblock \emph{NeurIPS 2020}, 2020{\natexlab{b}}.

\bibitem[Chzhen et~al.(2021)Chzhen, Denis, and Hebiri]{chzhen2019minimax}
E.~Chzhen, C.~Denis, and M.~Hebiri.
\newblock Minimax semi-supervised set-valued approach to multi-class
  classification.
\newblock \emph{Bernoulli}, 2021.

\bibitem[Denis et~al.(2024)Denis, Elie, Hebiri, and Hu]{denis2021fairness}
C.~Denis, R.~Elie, M.~Hebiri, and F.~Hu.
\newblock Fairness guarantees in multi-class classification with demographic
  parity.
\newblock \emph{Journal of Machine Learning Research}, 25\penalty0
  (130):\penalty0 1--46, 2024.

\bibitem[Dwork et~al.(2011)Dwork, Hardt, Pitassi, Reingold, and
  Zemel]{dwork2012}
C.~Dwork, M.~Hardt, T.~Pitassi, O.~Reingold, and R.~Zemel.
\newblock Fairness through awareness, 2011.
\newblock URL \url{https://arxiv.org/abs/1104.3913}.

\bibitem[Feldman et~al.(2015)Feldman, Friedler, Moeller, Scheidegger, and
  Venkatasubramanian]{feldman2015certifying}
M.~Feldman, S.~A. Friedler, J.~Moeller, C.~Scheidegger, and
  S.~Venkatasubramanian.
\newblock Certifying and removing disparate impact.
\newblock In \emph{International Conference on Knowledge Discovery and Data
  Mining}, 2015.

\bibitem[Foster et~al.(2019)Foster, Sekhari, Shamir, Srebro, Sridharan, and
  Woodworth]{foster2019complexity}
D.~Foster, A.~Sekhari, O.~Shamir, N.~Srebro, K.~Sridharan, and B.~Woodworth.
\newblock The complexity of making the gradient small in stochastic convex
  optimization.
\newblock In \emph{Conference on Learning Theory}, pages 1319--1345. PMLR,
  2019.

\bibitem[Gao and Pavel(2017)]{gao2017}
B.~Gao and L.~Pavel.
\newblock On the properties of the softmax function with application in game
  theory and reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1704.00805}, 2017.

\bibitem[Gaucher et~al.(2023)Gaucher, Schreuder, and
  Chzhen]{pmlr-v206-gaucher23a}
S.~Gaucher, N.~Schreuder, and E.~Chzhen.
\newblock Fair learning with wasserstein barycenters for non-decomposable
  performance measures.
\newblock In \emph{Proceedings of The 26th International Conference on
  Artificial Intelligence and Statistics}, volume 206 of \emph{Proceedings of
  Machine Learning Research}, pages 2436--2459. PMLR, 25--27 Apr 2023.
\newblock URL \url{https://proceedings.mlr.press/v206/gaucher23a.html}.

\bibitem[Ghadimi and Lan(2012)]{ghadimi2012optimal}
S.~Ghadimi and G.~Lan.
\newblock Optimal stochastic approximation algorithms for strongly convex
  stochastic composite optimization i: A generic algorithmic framework.
\newblock \emph{SIAM Journal on Optimization}, 22\penalty0 (4):\penalty0
  1469--1492, 2012.

\bibitem[Gordaliza et~al.(2019)Gordaliza, Del~Barrio, Fabrice, and
  Loubes]{gordaliza2019obtaining}
P.~Gordaliza, E.~Del~Barrio, G.~Fabrice, and J.~M. Loubes.
\newblock Obtaining fairness using optimal transport theory.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Hardt et~al.(2016)Hardt, Price, and Srebro]{hardt2016equality}
M.~Hardt, E.~Price, and N.~Srebro.
\newblock Equality of opportunity in supervised learning.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Jiang et~al.(2020)Jiang, Pacchiano, Stepleton, Jiang, and
  Chiappa]{jiang2019wasserstein}
R.~Jiang, A.~Pacchiano, T.~Stepleton, H.~Jiang, and S.~Chiappa.
\newblock Wasserstein fair classification.
\newblock \emph{Uncertainty in Artificial Intelligence Conference}, 2020.

\bibitem[{Le Gouic} et~al.(2020){Le Gouic}, Loubes, and
  Rigollet]{gouic2020price}
T.~{Le Gouic}, {J.-M.} Loubes, and P.~Rigollet.
\newblock Projection to fairness in statistical learning.
\newblock \emph{arXiv preprint arXiv:2005.11720}, 2020.

\bibitem[Lichman(2013)]{lichman2013}
M.~Lichman.
\newblock Adult.
\newblock UCI Machine Learning Repository, 2013.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[Lum and Johndrow(2016)]{lum2016statistical}
K.~Lum and J.~Johndrow.
\newblock A statistical framework for fair predictive algorithms.
\newblock \emph{arXiv preprint arXiv:1610.08077}, 2016.

\bibitem[Maheshwari and Perrot(2022)]{maheshwari2022fairgrad}
G.~Maheshwari and M.~Perrot.
\newblock Fairgrad: Fairness aware gradient descent.
\newblock \emph{arXiv preprint arXiv:2206.10923}, 2022.

\bibitem[Narasimhan et~al.(2020)Narasimhan, Cotter, Gupta, and
  Wang]{narasimhan2020pairwise}
H.~Narasimhan, A.~Cotter, M.~Gupta, and S.~Wang.
\newblock Pairwise fairness for ranking and regression.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 5248--5255, 2020.

\bibitem[Nedi{\'c} and Ozdaglar(2009)]{nedic2009subgradient}
A~Nedi{\'c} and A~Ozdaglar.
\newblock Subgradient methods for saddle-point problems.
\newblock \emph{Journal of Optimization Theory and Applications}, 142\penalty0
  (1):\penalty0 205--228, 2009.

\bibitem[Nesterov(2005)]{nesterov2005}
Y.~Nesterov.
\newblock Smooth minimization of non-smooth functions.
\newblock \emph{Mathematical programming}, 103\penalty0 (3):\penalty0 127--152,
  2005.

\bibitem[Nesterov(2012)]{nesterov2012make}
Y.~Nesterov.
\newblock How to make the gradients small.
\newblock \emph{Optima. Mathematical Optimization Society Newsletter},
  \penalty0 (88):\penalty0 10--11, 2012.

\bibitem[Redmond(2009)]{misc_communities_and_crime_183}
M.~Redmond.
\newblock {Communities and Crime}.
\newblock UCI Machine Learning Repository, 2009.
\newblock {DOI}: https://doi.org/10.24432/C53W3X.

\bibitem[Wightman(1998)]{Wightman1998LSACNL}
L.~Wightman.
\newblock Lsac national longitudinal bar passage study. lsac research report
  series.
\newblock 1998.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:151073942}.

\bibitem[Zafar et~al.(2017)Zafar, Valera, Gomez~Rodriguez, and
  Gummadi]{zafar2017fairness}
M.~Zafar, I.~Valera, M.~Gomez~Rodriguez, and K.~Gummadi.
\newblock Fairness beyond disparate treatment \& disparate impact: Learning
  classification without disparate mistreatment.
\newblock In \emph{International Conference on World Wide Web}, 2017.

\bibitem[Zemel et~al.(2013)Zemel, Wu, Swersky, Pitassi, and
  Dwork]{zemel2013learning}
R.~Zemel, Y.~Wu, K.~Swersky, T.~Pitassi, and C.~Dwork.
\newblock Learning fair representations.
\newblock In \emph{International Conference on Machine Learning}, 2013.

\bibitem[Zhao(2021)]{zhao2021costs}
H.~Zhao.
\newblock Costs and benefits of fair regression.
\newblock \emph{arXiv preprint arXiv:2106.08812}, 2021.

\end{thebibliography}
