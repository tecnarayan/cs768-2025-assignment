\begin{thebibliography}{}

\bibitem[\protect\citename{Agrawal \& Domke, }2021]{agrawal_amortized_2021}
Agrawal, Abhinav, \& Domke, Justin. 2021.
\newblock Amortized Variational Inference for Simple Hierarchical Models.
\newblock {\em Pages  21388--21399 of:} {\em Advances in {{Neural Information
  Processing Systems}}},  vol. 34.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Agrawal {\em et~al.}, }2020]{agrawal_advances_2020}
Agrawal, Abhinav, Sheldon, Daniel~R, \& Domke, Justin. 2020.
\newblock Advances in Black-Box {{VI}}: {{Normalizing}} Flows, Importance
  Weighting, and Optimization.
\newblock {\em Pages  17358--17369 of:} {\em Advances in {{Neural Information
  Processing Systems}}},  vol. 33.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Ahn {\em et~al.}, }2020]{ahn_sgd_2020}
Ahn, Kwangjun, Yun, Chulhee, \& Sra, Suvrit. 2020.
\newblock {{SGD}} with Shuffling: Optimal Rates without Component Convexity and
  Large Epoch Requirements.
\newblock {\em Pages  17526--17535 of:} {\em Advances in {{Neural Information
  Processing Systems}}},  vol. 33.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Alquier \& Ridgway,
  }2020]{alquier_concentration_2020}
Alquier, Pierre, \& Ridgway, James. 2020.
\newblock Concentration of Tempered Posteriors and of Their Variational
  Approximations.
\newblock {\em The Annals of Statistics}, {\bf 48}(3), 1475--1497.

\bibitem[\protect\citename{Altosaar {\em et~al.},
  }2018]{altosaar_proximity_2018}
Altosaar, Jaan, Ranganath, Rajesh, \& Blei, David. 2018.
\newblock Proximity Variational Inference.
\newblock {\em Pages  1961--1969 of:} {\em Proceedings of the {{International
  Conference}} on {{Artificial Intelligence}} and {{Statistics}}}.
\newblock {{PMLR}}, vol. 84.
\newblock {JMLR}.

\bibitem[\protect\citename{Amari, }1998]{amari_natural_1998}
Amari, Shun-ichi. 1998.
\newblock Natural Gradient Works Efficiently in Learning.
\newblock {\em Neural Computation}, {\bf 10}(2), 251--276.

\bibitem[\protect\citename{{Bertin-Mahieux} {\em et~al.},
  }2011]{bertin-mahieux_million_2011}
{Bertin-Mahieux}, Thierry, Ellis, Daniel~P.W., Whitman, Brian, \& Lamere, Paul.
  2011.
\newblock The Million Song Dataset.
\newblock {\em In:} {\em Proceedings of the International Conference on Music
  Information}.

\bibitem[\protect\citename{Bhatia {\em et~al.}, }2022]{bhatia_statistical_2022}
Bhatia, Kush, Kuang, Nikki~Lijing, Ma, Yi-An, \& Wang, Yixin. 2022 (July).
\newblock {\em Statistical and Computational Trade-Offs in Variational
  Inference: A Case Study in Inferential Model Selection}.
\newblock {{arXiv}} Preprint arXiv:2207.11208. {arXiv}.

\bibitem[\protect\citename{Bingham {\em et~al.}, }2019]{bingham_pyro_2019}
Bingham, Eli, Chen, Jonathan~P., Jankowiak, Martin, Obermeyer, Fritz, Pradhan,
  Neeraj, Karaletsos, Theofanis, Singh, Rohit, Szerlip, Paul, Horsfall, Paul,
  \& Goodman, Noah~D. 2019.
\newblock Pyro: {{Deep}} Universal Probabilistic Programming.
\newblock {\em Journal of Machine Learning Research}, {\bf 20}(28), 1--6.

\bibitem[\protect\citename{Blei {\em et~al.}, }2017]{blei_variational_2017}
Blei, David~M., Kucukelbir, Alp, \& McAuliffe, Jon~D. 2017.
\newblock Variational Inference: {{A}} Review for Statisticians.
\newblock {\em Journal of the American Statistical Association}, {\bf
  112}(518), 859--877.

\bibitem[\protect\citename{Bottou, }1999]{bottou_online_1999}
Bottou, L{\'e}on. 1999.
\newblock On-Line Learning and Stochastic Approximations.
\newblock {\em Pages  9--42 of:} {\em On-{{Line Learning}} in {{Neural
  Networks}}}, first edn.
\newblock {Cambridge University Press}.

\bibitem[\protect\citename{Bottou, }2009]{bottou_curiously_2009}
Bottou, L{\'e}on. 2009.
\newblock {\em Curiously Fast Convergence of Some Stochastic Gradient Descent
  Algorithms}.

\bibitem[\protect\citename{Buchholz {\em et~al.},
  }2018]{buchholz_quasimonte_2018}
Buchholz, Alexander, Wenzel, Florian, \& Mandt, Stephan. 2018.
\newblock Quasi-{{Monte Carlo}} Variational Inference.
\newblock {\em Pages  668--677 of:} {\em Proceedings of the {{International
  Conference}} on {{Machine Learning}}}.
\newblock {{PMLR}}, vol. 80.
\newblock {JMLR}.

\bibitem[\protect\citename{Carpenter {\em et~al.}, }2017]{carpenter_stan_2017}
Carpenter, Bob, Gelman, Andrew, Hoffman, Matthew~D., Lee, Daniel, Goodrich,
  Ben, Betancourt, Michael, Brubaker, Marcus, Guo, Jiqiang, Li, Peter, \&
  Riddell, Allen. 2017.
\newblock Stan: {{A}} Probabilistic Programming Language.
\newblock {\em Journal of Statistical Software}, {\bf 76}(1).

\bibitem[\protect\citename{Carvalho {\em et~al.},
  }2009]{carvalho_handling_2009}
Carvalho, Carlos~M., Polson, Nicholas~G., \& Scott, James~G. 2009.
\newblock Handling Sparsity via the Horseshoe.
\newblock {\em Pages  73--80 of:} {\em Proceedings of the {{International
  Conference}} on {{Artificial Intelligence}} and {{Statistics}}}.
\newblock {{PMLR}}, vol. 5.
\newblock {JMLR}.

\bibitem[\protect\citename{Carvalho {\em et~al.},
  }2010]{carvalho_horseshoe_2010}
Carvalho, Carlos~M., Polson, Nicholas~G., \& Scott, James~G. 2010.
\newblock The Horseshoe Estimator for Sparse Signals.
\newblock {\em Biometrika}, {\bf 97}(2), 465--480.

\bibitem[\protect\citename{Challis \& Barber, }2013]{challis_gaussian_2013}
Challis, Edward, \& Barber, David. 2013.
\newblock Gaussian {{Kullback}}-{{Leibler}} Approximate Inference.
\newblock {\em Journal of Machine Learning Research}, {\bf 14}(68), 2239--2286.

\bibitem[\protect\citename{Christmas \& Everson, }2011]{christmas_robust_2011}
Christmas, Jacqueline, \& Everson, Richard. 2011.
\newblock Robust Autoregression: {{Student}}-{{T}} Innovations Using
  Variational {{Bayes}}.
\newblock {\em IEEE Transactions on Signal Processing}, {\bf 59}(1), 48--57.

\bibitem[\protect\citename{Dhaka {\em et~al.}, }2020]{dhaka_robust_2020}
Dhaka, Akash~Kumar, Catalina, Alejandro, Andersen, Michael~R, ns~Magnusson,
  M{\aa}, Huggins, Jonathan, \& Vehtari, Aki. 2020.
\newblock Robust, Accurate Stochastic Optimization for Variational Inference.
\newblock {\em Pages  10961--10973 of:} {\em Advances in {{Neural Information
  Processing Systems}}},  vol. 33.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Dhaka {\em et~al.}, }2021]{dhaka_challenges_2021}
Dhaka, Akash~Kumar, Catalina, Alejandro, Welandawe, Manushi, Andersen,
  Michael~R., Huggins, Jonathan, \& Vehtari, Aki. 2021.
\newblock Challenges and Opportunities in High Dimensional Variational
  Inference.
\newblock {\em Pages  7787--7798 of:} {\em Advances in {{Neural Information
  Processing Systems}}},  vol. 34.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Diao {\em et~al.}, }2023]{diao_forwardbackward_2023}
Diao, Michael~Ziyang, Balasubramanian, Krishna, Chewi, Sinho, \& Salim, Adil.
  2023.
\newblock Forward-Backward {{Gaussian}} Variational Inference via {{JKO}} in
  the {{Bures}}-{{Wasserstein}} Space.
\newblock {\em Pages  7960--7991 of:} {\em Proceedings of the {{International
  Conference}} on {{Machine Learning}}}.
\newblock {{PMLR}}, vol. 202.
\newblock {JMLR}.

\bibitem[\protect\citename{Dieng {\em et~al.}, }2017]{dieng_variational_2017}
Dieng, Adji~Bousso, Tran, Dustin, Ranganath, Rajesh, Paisley, John, \& Blei,
  David. 2017.
\newblock Variational Inference via {$\chi$} Upper Bound Minimization.
\newblock {\em Pages  2729--2738 of:} {\em Advances in {{Neural Information
  Processing Systems}}},  vol. 30.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Dillon {\em et~al.}, }2017]{dillon_tensorflow_2017}
Dillon, Joshua~V., Langmore, Ian, Tran, Dustin, Brevdo, Eugene, Vasudevan,
  Srinivas, Moore, Dave, Patton, Brian, Alemi, Alex, Hoffman, Matt, \& Saurous,
  Rif~A. 2017 (Nov.).
\newblock {\em {{TensorFlow}} Distributions}.
\newblock {{arXiv}} Preprint arXiv:1711.10604. {arXiv}.

\bibitem[\protect\citename{Domke, }2019]{domke_provable_2019}
Domke, Justin. 2019.
\newblock Provable Gradient Variance Guarantees for Black-Box Variational
  Inference.
\newblock {\em Pages  329--338 of:} {\em Advances in {{Neural Information
  Processing Systems}}},  vol. 32.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Domke, }2020]{domke_provable_2020}
Domke, Justin. 2020.
\newblock Provable Smoothness Guarantees for Black-Box Variational Inference.
\newblock {\em Pages  2587--2596 of:} {\em Proceedings of the International
  Conference on Machine Learning}.
\newblock {{PMLR}}, vol. 119.
\newblock {JMLR}.

\bibitem[\protect\citename{Domke {\em et~al.}, }2023]{domke_provable_2023b}
Domke, Justin, Garrigos, Guillaume, \& Gower, Robert. 2023.
\newblock Provable Convergence Guarantees for Black-Box Variational Inference.
\newblock {\em In:} {\em Advances in {{Neural Information Processing Systems}}
  (to Appear)}.
\newblock {New Orleans, LA, USA}: {arXiv}.

\bibitem[\protect\citename{Dua \& Graff, }2017]{dua_uci_2017}
Dua, Dheeru, \& Graff, Casey. 2017.
\newblock {{UCI}} Machine Learning Repository.

\bibitem[\protect\citename{Duchi {\em et~al.}, }2011]{duchi_adaptive_2011}
Duchi, John, Hazan, Elad, \& Singer, Yoram. 2011.
\newblock Adaptive Subgradient Methods for Online Learning and Stochastic
  Optimization.
\newblock {\em Journal of Machine Learning Research}, {\bf 12}(Jul),
  2121--2159.

\bibitem[\protect\citename{Dugas {\em et~al.}, }2000]{dugas_incorporating_2000}
Dugas, Charles, Bengio, Yoshua, B{\'e}lisle, Fran{\c c}ois, Nadeau, Claude, \&
  Garcia, Ren{\'e}. 2000.
\newblock Incorporating Second-Order Functional Knowledge for Better Option
  Pricing.
\newblock {\em In:} {\em Advances in {{Neural Information Processing
  Systems}}},  vol. 13.
\newblock {MIT Press}.

\bibitem[\protect\citename{Dwivedi {\em et~al.},
  }2019]{dwivedi_logconcave_2019}
Dwivedi, Raaz, Chen, Yuansi, Wainwright, Martin~J., \& Yu, Bin. 2019.
\newblock Log-Concave Sampling: {{Metropolis}}-{{Hastings}} Algorithms Are
  Fast.
\newblock {\em Journal of Machine Learning Research}, {\bf 20}(183), 1--42.

\bibitem[\protect\citename{Fan {\em et~al.}, }2015]{fan_fast_2015}
Fan, Kai, Wang, Ziteng, Beck, Jeff, Kwok, James, \& Heller, Katherine~A. 2015.
\newblock Fast Second Order Stochastic Backpropagation for Variational
  Inference.
\newblock {\em Pages  1387--1395 of:} {\em Advances in {{Neural Information
  Processing Systems}}},  vol. 28.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Fjelde {\em et~al.}, }2020]{fjelde_bijectors_2020}
Fjelde, Tor~Erlend, Xu, Kai, Tarek, Mohamed, Yalburgi, Sharan, \& Ge, Hong.
  2020.
\newblock {{Bijectors.jl:}} {{Flexible}} Transformations for Probability
  Distributions.
\newblock {\em Pages  1--17 of:} {\em Proceedings of {{The Symposium}} on
  {{Advances}} in {{Approximate Bayesian Inference}}}.
\newblock {{PMLR}}, vol. 118.
\newblock {JMLR}.

\bibitem[\protect\citename{Freund {\em et~al.}, }2022]{freund_when_2022}
Freund, Yoav, Ma, Yi-An, \& Zhang, Tong. 2022.
\newblock When Is the Convergence Time of Langevin Algorithms Dimension
  Independent? {{A}} Composite Optimization Viewpoint.
\newblock {\em Journal of Machine Learning Research}, {\bf 23}(214), 1--32.

\bibitem[\protect\citename{Fujisawa \& Sato, }2021]{fujisawa_multilevel_2021}
Fujisawa, Masahiro, \& Sato, Issei. 2021.
\newblock Multilevel {{Monte Carlo}} Variational Inference.
\newblock {\em Journal of Machine Learning Research}, {\bf 22}(278), 1--44.

\bibitem[\protect\citename{Garrigos \& Gower, }2023]{garrigos_handbook_2023}
Garrigos, Guillaume, \& Gower, Robert~M. 2023 (Feb.).
\newblock {\em Handbook of Convergence Theorems for (Stochastic) Gradient
  Methods}.
\newblock {{arXiv}} Preprint arXiv:2301.11235. {arXiv}.

\bibitem[\protect\citename{Ge {\em et~al.}, }2018]{ge_turing_2018}
Ge, Hong, Xu, Kai, \& Ghahramani, Zoubin. 2018.
\newblock Turing: A Language for Flexible Probabilistic Inference.
\newblock {\em Pages  1682--1690 of:} {\em Proceedings of the {{International
  Conference}} on {{Machine Learning}}}.
\newblock {{PMLR}}, vol. 84.
\newblock {JMLR}.

\bibitem[\protect\citename{Gelman \& Hill, }2007]{gelman_data_2007}
Gelman, Andrew, \& Hill, Jennifer. 2007.
\newblock {\em Data Analysis Using Regression and Multilevel/Hierarchical
  Models}.
\newblock Analytical Methods for Social Research.
\newblock {Cambridge; New York}: {Cambridge University Press}.

\bibitem[\protect\citename{Giordano {\em et~al.},
  }2018]{giordano_covariances_2018}
Giordano, Ryan, Broderick, Tamara, \& Jordan, Michael~I. 2018.
\newblock Covariances, Robustness, and Variational {{Bayes}}.
\newblock {\em Journal of Machine Learning Research}, {\bf 19}(51), 1--49.

\bibitem[\protect\citename{Giordano {\em et~al.}, }2023]{giordano_black_2023}
Giordano, Ryan, Ingram, Martin, \& Broderick, Tamara. 2023 (Apr.).
\newblock {\em Black Box Variational Inference with a Deterministic Objective:
  {{Faster}}, More Accurate, and Even More Black Box}.
\newblock {{arXiv}} Preprint arXiv:2304.05527. {arXiv}.

\bibitem[\protect\citename{Goldberger {\em et~al.},
  }2000]{goldberger_physiobank_2000}
Goldberger, Ary~L., Amaral, Luis A.~N., Glass, Leon, Hausdorff, Jeffrey~M.,
  Ivanov, Plamen~Ch., Mark, Roger~G., Mietus, Joseph~E., Moody, George~B.,
  Peng, Chung-Kang, \& Stanley, H.~Eugene. 2000.
\newblock {{PhysioBank}}, {{PhysioToolkit}}, and {{PhysioNet}}: {{Components}}
  of a New Research Resource for Complex Physiologic Signals.
\newblock {\em Circulation}, {\bf 101}(23).

\bibitem[\protect\citename{Gorbunov {\em et~al.}, }2020]{gorbunov_unified_2020}
Gorbunov, Eduard, Hanzely, Filip, \& Richtarik, Peter. 2020.
\newblock A Unified Theory of {{SGD}}: {{Variance}} Reduction, Sampling,
  Quantization and Coordinate Descent.
\newblock {\em Pages  680--690 of:} {\em Proceedings of the {{International
  Conference}} on {{Artificial Intelligence}} and {{Statistics}}}.
\newblock {{PMLR}}, vol. 108.
\newblock {JMLR}.

\bibitem[\protect\citename{Gower {\em et~al.}, }2019]{gower_sgd_2019}
Gower, Robert~Mansel, Loizou, Nicolas, Qian, Xun, Sailanbayev, Alibek, Shulgin,
  Egor, \& Richt{\'a}rik, Peter. 2019.
\newblock {{SGD}}: {{General}} Analysis and Improved Rates.
\newblock {\em Pages  5200--5209 of:} {\em Proceedings of the International
  Conference on Machine Learning}.
\newblock {{PMLR}}, vol. 97.
\newblock {JMLR}.

\bibitem[\protect\citename{Haochen \& Sra, }2019]{haochen_random_2019}
Haochen, Jeff, \& Sra, Suvrit. 2019.
\newblock Random Shuffling Beats {{SGD}} after Finite Epochs.
\newblock {\em Pages  2624--2633 of:} {\em Proceedings of the {{International
  Conference}} on {{Machine Learning}}}.
\newblock {{PMLR}}, vol. 97.
\newblock {JMLR}.

\bibitem[\protect\citename{{Hernandez-Lobato} {\em et~al.},
  }2016]{hernandez-lobato_blackbox_2016}
{Hernandez-Lobato}, Jose, Li, Yingzhen, Rowland, Mark, Bui, Thang,
  {Hernandez-Lobato}, Daniel, \& Turner, Richard. 2016.
\newblock Black-Box Alpha Divergence Minimization.
\newblock {\em Pages  1511--1520 of:} {\em Proceedings of the International
  Conference on Machine Learning}.
\newblock {{PMLR}}, vol. 48.
\newblock {JMLR}.

\bibitem[\protect\citename{Hoffman \& Ma, }2020]{hoffman_blackbox_2020}
Hoffman, Matthew, \& Ma, Yian. 2020.
\newblock Black-Box Variational Inference as a Parametric Approximation to
  {{Langevin}} Dynamics.
\newblock {\em Pages  4324--4341 of:} {\em Proceedings of the {{International
  Conference}} on {{Machine Learning}}}.
\newblock {{PMLR}}, vol. 119.
\newblock {JMLR}.

\bibitem[\protect\citename{Jager {\em et~al.}, }2003]{jager_longterm_2003}
Jager, F., Taddei, A., Moody, G.~B., Emdin, M., Antoli{\v c}, G., Dorn, R.,
  Smrdel, A., Marchesi, C., \& Mark, R.~G. 2003.
\newblock Long-Term {{ST}} Database: {{A}} Reference for the Development and
  Evaluation of Automated Ischaemia Detectors and for the Study of the Dynamics
  of Myocardial Ischaemia.
\newblock {\em Medical and Biological Engineering and Computing}, {\bf 41}(2),
  172--182.

\bibitem[\protect\citename{Jordan {\em et~al.},
  }1999]{jordan_introduction_1999}
Jordan, Michael~I., Ghahramani, Zoubin, Jaakkola, Tommi~S., \& Saul,
  Lawrence~K. 1999.
\newblock An Introduction to Variational Methods for Graphical Models.
\newblock {\em Machine Learning}, {\bf 37}(2), 183--233.

\bibitem[\protect\citename{Karimi {\em et~al.}, }2016]{karimi_linear_2016}
Karimi, Hamed, Nutini, Julie, \& Schmidt, Mark. 2016.
\newblock Linear Convergence of Gradient and Proximal-Gradient Methods under
  the {{Polyak}}-{{\L ojasiewicz}} Condition.
\newblock {\em Pages  795--811 of:} {\em Machine {{Learning}} and {{Knowledge
  Discovery}} in {{Databases}}}.
\newblock Lecture {{Notes}} in {{Computer Science}}.
\newblock {Cham}: {Springer International Publishing}.

\bibitem[\protect\citename{Kawala {\em et~al.}, }2013]{kawala_predictions_2013}
Kawala, Fran{\c c}ois, {Douzal-Chouakria}, Ahlame, Gaussier, Eric, \& Diemert,
  Eustache. 2013.
\newblock Pr\'edictions d'activit\'e Dans Les R\'eseaux Sociaux En Ligne.
\newblock {\em Page ~16 of:} {\em Actes de La {{Conf\'erence}} Sur Les
  {{Mod\`eles}} et L{${'}$}{{Analyse}} Des {{R\'eseaux}} : {{Approches
  Math\'ematiques}} et {{Informatique}}}.

\bibitem[\protect\citename{Khaled \& Richt{\'a}rik, }2023]{khaled_better_2023}
Khaled, Ahmed, \& Richt{\'a}rik, Peter. 2023.
\newblock Better Theory for {{SGD}} in the Nonconvex World.
\newblock {\em Transactions of Machine Learning Research}.

\bibitem[\protect\citename{Khan \& Lin, }2017]{khan_conjugatecomputation_2017}
Khan, Mohammad, \& Lin, Wu. 2017.
\newblock Conjugate-Computation Variational Inference: Converting Variational
  Inference in Non-Conjugate Models to Inferences in Conjugate Models.
\newblock {\em Pages  878--887 of:} {\em Proceedings of the {{International
  Conference}} on {{Artificial Intelligence}} and {{Statistics}}}.
\newblock {{PMLR}}, vol. 54.
\newblock {JMLR}.

\bibitem[\protect\citename{Khan {\em et~al.}, }2016]{khan_faster_2016}
Khan, Mohammad~Emtiyaz, Babanezhad, Reza, Lin, Wu, Schmidt, Mark, \& Sugiyama,
  Masashi. 2016.
\newblock Faster Stochastic Variational Inference Using Proximal-Gradient
  Methods with General Divergence Functions.
\newblock {\em Pages  319--328 of:} {\em Proceedings of the Conference on
  Uncertainty in Artificial Intelligence}.
\newblock {{UAI}}'16.
\newblock {Arlington, Virginia, USA}: {AUAI Press}.

\bibitem[\protect\citename{Khan {\em et~al.}, }2015]{khan_kullbackleibler_2015}
Khan, Mohammad Emtiyaz~E, Baque, Pierre, Fleuret, Fran{\c c}ois, \& Fua,
  Pascal. 2015.
\newblock Kullback-{{Leibler}} Proximal Variational Inference.
\newblock {\em In:} {\em Advances in {{Neural Information Processing
  Systems}}},  vol. 28.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Kim {\em et~al.}, }2022]{kim_markov_2022}
Kim, Kyurae, Oh, Jisu, Gardner, Jacob, Dieng, Adji~Bousso, \& Kim, Hongseok.
  2022.
\newblock Markov Chain Score Ascent: {{A}} Unifying Framework of Variational
  Inference with Markovian Gradients.
\newblock {\em Pages  34802--34816 of:} {\em Advances in Neural Information
  Processing Systems},  vol. 35.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Kim {\em et~al.}, }2023]{kim_practical_2023}
Kim, Kyurae, Wu, Kaiwen, Oh, Jisu, \& Gardner, Jacob~R. 2023.
\newblock Practical and Matching Gradient Variance Bounds for Black-Box
  Variational {{Bayesian}} Inference.
\newblock {\em Pages  16853--16876 of:} {\em Proceedings of the {{International
  Conference}} on {{Machine Learning}}}.
\newblock {{PMLR}}, vol. 202.
\newblock {Honolulu, HI, USA}: {JMLR}.

\bibitem[\protect\citename{Kingma \& Ba, }2015]{kingma_adam_2015}
Kingma, Diederik~P., \& Ba, Jimmy. 2015.
\newblock Adam: {{A Method}} for {{Stochastic Optimization}}.
\newblock {\em In:} {\em Proceedings of the {{International}} Conference on
  Learning Representations}.

\bibitem[\protect\citename{Kingma \& Welling, }2014]{kingma_autoencoding_2014}
Kingma, Diederik~P., \& Welling, Max. 2014 (Apr.).
\newblock Auto-Encoding Variational {{Bayes}}.
\newblock {\em In:} {\em Proceedings of the {{International Conference}} on
  {{Learning Representations}}}.

\bibitem[\protect\citename{Kucukelbir {\em et~al.},
  }2017]{kucukelbir_automatic_2017}
Kucukelbir, Alp, Tran, Dustin, Ranganath, Rajesh, Gelman, Andrew, \& Blei,
  David~M. 2017.
\newblock Automatic Differentiation Variational Inference.
\newblock {\em Journal of Machine Learning Research}, {\bf 18}(14), 1--45.

\bibitem[\protect\citename{Kunstner {\em et~al.}, }2023]{kunstner_noise_2023}
Kunstner, Frederik, Chen, Jacques, Lavington, Jonathan~Wilder, \& Schmidt,
  Mark. 2023 (Feb.).
\newblock Noise Is Not the Main Factor behind the Gap between Sgd and Adam on
  Transformers, but Sign Descent Might Be.
\newblock {\em In:} {\em Proceedings of the {{International Conference}} on
  {{Learning Representations}}}.

\bibitem[\protect\citename{Lambert {\em et~al.},
  }2022]{lambert_variational_2022}
Lambert, Marc, Chewi, Sinho, Bach, Francis, Bonnabel, Silv{\`e}re, \& Rigollet,
  Philippe. 2022.
\newblock Variational Inference via {{Wasserstein}} Gradient Flows.
\newblock {\em Pages  14434--14447 of:} {\em Advances in {{Neural Information
  Processing Systems}}},  vol. 35.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Leger, }2023]{leger_parametrization_2023}
Leger, Jean-Benoist. 2023 (Jan.).
\newblock {\em Parametrization Cookbook: {{A}} Set of Bijective
  Parametrizations for Using Machine Learning Methods in Statistical
  Inference}.
\newblock {{arXiv}} Preprint arXiv:2301.08297. {arXiv}.

\bibitem[\protect\citename{Lin {\em et~al.}, }2019]{lin_fast_2019}
Lin, Wu, Khan, Mohammad~Emtiyaz, \& Schmidt, Mark. 2019.
\newblock Fast and Simple Natural-Gradient Variational Inference with Mixture
  of Exponential-Family Approximations.
\newblock {\em Pages  3992--4002 of:} {\em Proceedings of the {{International
  Conference}} on {{Machine Learning}}}.
\newblock {{PMLR}}, vol. 97.
\newblock {JMLR}.

\bibitem[\protect\citename{Liu \& Owen, }2021]{liu_quasimonte_2021}
Liu, Sifan, \& Owen, Art~B. 2021.
\newblock Quasi-{{Monte Carlo}} Quasi-{{Newton}} in {{Variational Bayes}}.
\newblock {\em Journal of Machine Learning Research}, {\bf 22}(243), 1--23.

\bibitem[\protect\citename{Magnusson {\em et~al.},
  }2022]{magnusson_posteriordb_2022}
Magnusson, M{\aa}ns, B{\"u}rkner, Paul, \& Vehtari, Aki. 2022 (Nov.).
\newblock {\em Posteriordb: A Set of Posteriors for {{Bayesian}} Inference and
  Probabilistic Programming}.

\bibitem[\protect\citename{Mishchenko {\em et~al.},
  }2020]{mishchenko_random_2020}
Mishchenko, Konstantin, Khaled, Ahmed, \& Richtarik, Peter. 2020.
\newblock Random Reshuffling: Simple Analysis with Vast Improvements.
\newblock {\em Pages  17309--17320 of:} {\em Advances in {{Neural Information
  Processing Systems}}},  vol. 33.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Naesseth {\em et~al.},
  }2020]{naesseth_markovian_2020}
Naesseth, Christian, Lindsten, Fredrik, \& Blei, David. 2020.
\newblock Markovian Score Climbing: {{Variational}} Inference with KL(p||q).
\newblock {\em Pages  15499--15510 of:} {\em Advances in {{Neural Information
  Processing Systems}}},  vol. 33.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Nagaraj {\em et~al.}, }2019]{nagaraj_sgd_2019}
Nagaraj, Dheeraj, Jain, Prateek, \& Netrapalli, Praneeth. 2019.
\newblock {{SGD}} without Replacement: {{Sharper}} Rates for General Smooth
  Convex Functions.
\newblock {\em Pages  4703--4711 of:} {\em Proceedings of the {{International
  Conference}} on {{Machine Learning}}}.
\newblock {{PMLR}}, vol. 97.
\newblock {JMLR}.

\bibitem[\protect\citename{Nemirovski {\em et~al.},
  }2009]{nemirovski_robust_2009}
Nemirovski, A., Juditsky, A., Lan, G., \& Shapiro, A. 2009.
\newblock Robust Stochastic Approximation Approach to Stochastic Programming.
\newblock {\em SIAM Journal on Optimization}, {\bf 19}(4), 1574--1609.

\bibitem[\protect\citename{Nguyen {\em et~al.}, }2018]{nguyen_sgd_2018}
Nguyen, Lam, Nguyen, Phuong~Ha, {van Dijk}, Marten, Richtarik, Peter,
  Scheinberg, Katya, \& Takac, Martin. 2018.
\newblock {{SGD}} and {{Hogwild}}! {{Convergence}} without the Bounded
  Gradients Assumption.
\newblock {\em Pages  3750--3758 of:} {\em Proceedings of the International
  Conference on Machine Learning}.
\newblock {{PMLR}}, vol. 80.
\newblock {JMLR}.

\bibitem[\protect\citename{Patil {\em et~al.}, }2010]{patil_pymc_2010}
Patil, Anand, Huard, David, \& Fonnesbeck, Christopher. 2010.
\newblock {{PyMC}}: {{Bayesian}} Stochastic Modelling in {{Python}}.
\newblock {\em Journal of Statistical Software}, {\bf 35}(4).

\bibitem[\protect\citename{Ranganath {\em et~al.}, }2014]{ranganath_black_2014}
Ranganath, Rajesh, Gerrish, Sean, \& Blei, David. 2014.
\newblock Black Box Variational Inference.
\newblock {\em Pages  814--822 of:} {\em Proceedings of the International
  Conference on Artificial Intelligence and Statistics}.
\newblock {{PMLR}}, vol. 33.
\newblock {JMLR}.

\bibitem[\protect\citename{Reddi {\em et~al.}, }2023]{reddi_convergence_2023}
Reddi, Sashank~J., Kale, Satyen, \& Kumar, Sanjiv. 2023 (May).
\newblock On the Convergence of Adam and Beyond.
\newblock {\em In:} {\em Proceedings of the {{International Conference}} on
  {{Learning Representations}}}.

\bibitem[\protect\citename{Regier {\em et~al.}, }2017]{regier_fast_2017}
Regier, Jeffrey, Jordan, Michael~I, \& McAuliffe, Jon. 2017.
\newblock Fast Black-Box Variational Inference through Stochastic Trust-Region
  Optimization.
\newblock {\em Pages  2399--2408 of:} {\em Advances in {{Neural Information
  Processing Systems}}},  vol. 30.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Robbins \& Monro, }1951]{robbins_stochastic_1951}
Robbins, Herbert, \& Monro, Sutton. 1951.
\newblock A Stochastic Approximation Method.
\newblock {\em The Annals of Mathematical Statistics}, {\bf 22}(3), 400--407.

\bibitem[\protect\citename{Roeder {\em et~al.}, }2017]{roeder_sticking_2017}
Roeder, Geoffrey, Wu, Yuhuai, \& Duvenaud, David~K. 2017.
\newblock Sticking the Landing: {{Simple}}, Lower-Variance Gradient Estimators
  for Variational Inference.
\newblock {\em Pages  6928--6937 of:} {\em Advances in {{Neural Information
  Processing Systems}}},  vol. 30.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Shannon {\em et~al.}, }2003]{shannon_cytoscape_2003}
Shannon, Paul, Markiel, Andrew, Ozier, Owen, Baliga, Nitin~S., Wang,
  Jonathan~T., Ramage, Daniel, Amin, Nada, Schwikowski, Benno, \& Ideker, Trey.
  2003.
\newblock Cytoscape: {{A Software Environment}} for {{Integrated Models}} of
  {{Biomolecular Interaction Networks}}.
\newblock {\em Genome Research}, {\bf 13}(11), 2498--2504.

\bibitem[\protect\citename{Titsias, }2009]{titsias_variational_2009}
Titsias, Michalis. 2009.
\newblock Variational Learning of Inducing Variables in Sparse Gaussian
  Processes.
\newblock {\em Pages  567--574 of:} {\em Proceedings of the {{International
  Conference}} on {{Artificial Intelligence}} and {{Statistics}}}.
\newblock {{PMLR}}, vol. 5.
\newblock {JMLR}.

\bibitem[\protect\citename{Titsias \& {L{\'a}zaro-Gredilla},
  }2014]{titsias_doubly_2014}
Titsias, Michalis, \& {L{\'a}zaro-Gredilla}, Miguel. 2014.
\newblock Doubly Stochastic Variational {{Bayes}} for Non-Conjugate Inference.
\newblock {\em Pages  1971--1979 of:} {\em Proceedings of the {{International
  Conference}} on {{Machine Learning}}}.
\newblock {{PMLR}}, vol. 32.
\newblock {JMLR}.

\bibitem[\protect\citename{van~der Vaart, }1998]{vaart_asymptotic_1998}
van~der Vaart, A.~W. 1998.
\newblock {\em Asymptotic {{Statistics}}}. First edn.
\newblock {Cambridge University Press}.

\bibitem[\protect\citename{Vaswani {\em et~al.}, }2019]{vaswani_fast_2019}
Vaswani, Sharan, Bach, Francis, \& Schmidt, Mark. 2019.
\newblock Fast and Faster Convergence of {{SGD}} for Over-Parameterized Models
  and an Accelerated Perceptron.
\newblock {\em Pages  1195--1204 of:} {\em Proceedings of the {{International
  Conference}} on {{Artificial Intelligence}} and {{Statistics}}}.
\newblock {{PMLR}}, vol. 89.
\newblock {JMLR}.

\bibitem[\protect\citename{Wang \& Blei, }2019]{wang_variational_2019}
Wang, Yixin, \& Blei, David. 2019.
\newblock Variational Bayes under Model Misspecification.
\newblock {\em In:} {\em Advances in {{Neural Information Processing
  Systems}}},  vol. 32.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Welandawe {\em et~al.},
  }2022]{welandawe_robust_2022}
Welandawe, Manushi, Andersen, Michael~Riis, Vehtari, Aki, \& Huggins,
  Jonathan~H. 2022 (Mar.).
\newblock {\em Robust, Automated, and Accurate Black-Box Variational
  Inference}.
\newblock {{arXiv}} Preprint arXiv:2203.15945. {arXiv}.

\bibitem[\protect\citename{Wright \& Recht, }2021]{wright_optimization_2021}
Wright, Stephen~J., \& Recht, Benjamin. 2021.
\newblock {\em Optimization for Data Analysis}.
\newblock {New York}: {Cambridge University Press}.

\bibitem[\protect\citename{Xu {\em et~al.}, }2019]{xu_variance_2019}
Xu, Ming, Quiroz, Matias, Kohn, Robert, \& Sisson, Scott~A. 2019.
\newblock Variance Reduction Properties of the Reparameterization Trick.
\newblock {\em Pages  2711--2720 of:} {\em Proceedings of the {{International
  Conference}} on {{Artificial Intelligence}} and {{Statistics}}}.
\newblock {{PMLR}}, vol. 89.
\newblock {JMLR}.

\bibitem[\protect\citename{Xu \& Campbell, }2022]{xu_computational_2022}
Xu, Zuheng, \& Campbell, Trevor. 2022.
\newblock The Computational Asymptotics of {{Gaussian}} Variational Inference
  and the {{Laplace}} Approximation.
\newblock {\em Statistics and Computing}, {\bf 32}(4), 63.

\bibitem[\protect\citename{Yao {\em et~al.}, }2018]{yao_yes_2018}
Yao, Yuling, Vehtari, Aki, Simpson, Daniel, \& Gelman, Andrew. 2018.
\newblock Yes, but Did It Work?: {{Evaluating}} Variational Inference.
\newblock {\em Pages  5581--5590 of:} {\em Proceedings of the {{International
  Conference}} on {{Machine Learning}}}.
\newblock {{PMLR}}, vol. 80.
\newblock {JMLR}.

\bibitem[\protect\citename{Yun {\em et~al.}, }2021]{yun_adaptive_2021}
Yun, Jihun, Lozano, Aurelie~C, \& Yang, Eunho. 2021.
\newblock Adaptive Proximal Gradient Methods for Structured Neural Networks.
\newblock {\em Pages  24365--24378 of:} {\em Advances in {{Neural Information
  Processing Systems}}},  vol. 34.
\newblock {Curran Associates, Inc.}

\bibitem[\protect\citename{Zhang {\em et~al.}, }2019]{zhang_advances_2019}
Zhang, Cheng, Butepage, Judith, Kjellstrom, Hedvig, \& Mandt, Stephan. 2019.
\newblock Advances in Variational Inference.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  {\bf 41}(8), 2008--2026.

\bibitem[\protect\citename{Zhang {\em et~al.}, }2022]{zhang_adam_2022}
Zhang, Yushun, Chen, Congliang, Shi, Naichen, Sun, Ruoyu, \& Luo, Zhi-Quan.
  2022.
\newblock Adam Can Converge without Any Modification on Update Rules.
\newblock {\em Pages  28386--28399 of:} {\em Advances in Neural Information
  Processing Systems},  vol. 35.
\newblock {Curran Associates, Inc.}

\end{thebibliography}
