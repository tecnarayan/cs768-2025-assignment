\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{MWCC20}

\bibitem[ABS13]{Attouch13}
H.~Attouch, J.~Bolte, and B.~F. Svaiter.
\newblock {Convergence of descent methods for semi-algebraic and tame problems:
  proximal algorithms, forward--backward splitting, and regularized
  Gauss--Seidel methods}.
\newblock {\em Mathematical Programming}, 137(1):91--129, 2013.

\bibitem[ACP16]{AnderssonCarlssonPerfekt16}
F.~Andersson, M.~Carlsson, and K.-M. Perfekt.
\newblock Operator-{L}ipschitz estimates for the singular value functional
  calculus.
\newblock {\em Proc. Amer. Math. Soc.}, 144(5):1867--1875, 2016.

\bibitem[ALMT14]{Amelunxen14}
D.~Amelunxen, M.~Lotz, M.~B. McCoy, and J.~A. Tropp.
\newblock Living on the edge: Phase transitions in convex programs with random
  data.
\newblock {\em Information and Inference: A Journal of the IMA}, 3(3):224--294,
  2014.

\bibitem[BA15]{boumal_absil_15}
N.~Boumal and P.-A. Absil.
\newblock Low-rank matrix completion via preconditioned optimization on the
  Grassmann manifold.
\newblock {\em Linear Algebra and its Applications}, 15(475):200--239, 2015.

\bibitem[BDL07]{BolteKL07}
J.~Bolte, A.~Daniilidis, and A.~Lewis.
\newblock The {{\L}}ojasiewicz inequality for nonsmooth subanalytic functions
  with applications to subgradient dynamical systems.
\newblock {\em SIAM Journal on Optimization}, 17(4):1205--1223, 2007.

\bibitem[BGLS95]{Bonnans95}
J.~F. Bonnans, J.~C. Gilbert, C.~Lemar{\'e}chal, and C.~A. Sagastiz{\'a}bal.
\newblock A family of variable metric proximal methods.
\newblock {\em Mathematical Programming}, 68(1):15--47, 1995.

\bibitem[Bj{\"o}96]{Bjoerck96}
{\AA}.~Bj{\"o}rck.
\newblock {\em Numerical Methods for Least Squares Problems}.
\newblock Society for Industrial and Applied Mathematics, 1996.

\bibitem[BM03]{Burer03}
S.~Burer and R.~D. Monteiro.
\newblock A nonlinear programming algorithm for solving semidefinite programs
  via low-rank factorization.
\newblock {\em Mathematical Programming}, 95(2):329--357, 2003.

\bibitem[BMAS14]{manopt}
N.~Boumal, B.~Mishra, P.-A. Absil, and R.~Sepulchre.
\newblock {M}anopt, a {M}atlab Toolbox for Optimization on Manifolds.
\newblock {\em J. Mach. Learn. Res.}, 15(42):1455--1459, 2014.

\bibitem[BNZ21]{BauchNadler20}
J.~Bauch, B.~Nadler, and P.~Zilber.
\newblock Rank 2r iterative least squares: efficient recovery of
  ill-conditioned low rank matrices from few entries.
\newblock {\em SIAM J. Math. Data Sci.}, 3(1):439--465, 2021.

\bibitem[Bou20]{Boumal20}
N.~Boumal.
\newblock An introduction to optimization on smooth manifolds.
\newblock {\em Available online at
  \url{http://sma.epfl.ch/~nboumal/book/IntroOptimManifolds_Boumal_2020.pdf},
  November}, 2020.

\bibitem[CC18]{chen_chi18}
Y.~Chen and Y.~Chi.
\newblock {Harnessing Structures in Big Data via Guaranteed Low-Rank Matrix
  Estimation: Recent Theory and Fast Algorithms via Convex and Nonconvex
  Optimization}.
\newblock {\em {IEEE} Signal Process. Mag.}, 35(4):14--31, 2018.

\bibitem[CCBB15]{cloninger_czaja_bai_basser}
A.~Cloninger, W.~Czaja, R.~Bai, and P.~J. Basser.
\newblock {Solving 2D Fredholm Integral from Incomplete Measurements Using
  Compressive Sensing}.
\newblock {\em SIAM J. Imaging Sci.}, 7(3):1775--1798, 2015.

\bibitem[CCF{\etalchar{+}}20]{Chen20noisy}
Y.~Chen, Y.~Chi, J.~Fan, C.~Ma, and Y.~Yan.
\newblock Noisy matrix completion: Understanding statistical guarantees for
  convex relaxation via nonconvex optimization.
\newblock {\em SIAM Journal on Optimization}, 30(4):3098--3121, 2020.

\bibitem[CESV13]{Candes13}
E.~J. Cand\`{e}s, Y.~Eldar, T.~Strohmer, and V.~Voroninski.
\newblock {Phase Retrieval via Matrix Completion}.
\newblock {\em SIAM J. Imag. Sci.}, 6(1):199--225, 2013.

\bibitem[Che12]{Chen2012smoothing}
X.~Chen.
\newblock Smoothing methods for nonsmooth, nonconvex minimization.
\newblock {\em Math. Program.}, 134(1):71--99, 2012.

\bibitem[{Che}15]{Chen15}
Y.~{Chen}.
\newblock {Incoherence-Optimal Matrix Completion}.
\newblock {\em IEEE Trans. Inf. Theory}, 61(5):2909--2923, 2015.

\bibitem[CLC19]{ChiLuChen19}
Y.~{Chi}, Y.~M. {Lu}, and Y.~{Chen}.
\newblock {Nonconvex Optimization Meets Low-Rank Matrix Factorization: An
  Overview}.
\newblock {\em IEEE Trans. Signal Process.}, 67(20):5239--5269, 2019.

\bibitem[CLL20]{ChenLiuLi19}
J.~Chen, D.~Liu, and X.~Li.
\newblock Nonconvex Rectangular Matrix Completion via Gradient Descent Without
  $\ell_{2,\infty}$-Regularization.
\newblock {\em IEEE Trans. Inf. Theory}, 66(9):5806--5841, 2020.

\bibitem[CP10]{CandesPlan10}
E.~Cand\`{e}s and Y.~Plan.
\newblock Matrix completion with noise.
\newblock {\em Proceedings of the IEEE}, 98(6):925--936, 2010.

\bibitem[CP11]{Combettes2011}
P.~L. Combettes and J.-C. Pesquet.
\newblock Proximal Splitting Methods in Signal Processing.
\newblock In H.~H. Bauschke, R.~S. Burachik, P.~L. Combettes, V.~Elser, D.~R.
  Luke, and H.~Wolkowicz, editors, {\em Fixed-Point Algorithms for Inverse
  Problems in Science and Engineering}, pages 185--212. Springer New York, New
  York, NY, 2011.

\bibitem[CPR14]{Chouzenoux14}
E.~Chouzenoux, J.-C. Pesquet, and A.~Repetti.
\newblock Variable metric forward--backward algorithm for minimizing the sum of
  a differentiable function and a convex function.
\newblock {\em Journal of Optimization Theory and Applications},
  162(1):107--132, 2014.

\bibitem[CQS98]{ChenQiSun98}
X.~Chen, L.~Qi, and D.~Sun.
\newblock Global and superlinear convergence of the smoothing Newton method and
  its application to general box constrained variational inequalities.
\newblock {\em Mathematics of computation}, 67(222):519--540, 1998.

\bibitem[CR09]{CR09}
E.~J. Cand{\`e}s and B.~Recht.
\newblock Exact matrix completion via convex optimization.
\newblock {\em Found. Comput. Math.}, 9(6):717--772, 2009.

\bibitem[CT10]{CandesTao10}
E.~J. {Cand\`{e}s} and T.~{Tao}.
\newblock {The Power of Convex Relaxation: Near-Optimal Matrix Completion}.
\newblock {\em IEEE Trans. Inf. Theory}, 56(5):2053--2080, 2010.

\bibitem[DDFG10]{Daubechies10}
I.~Daubechies, R.~DeVore, M.~Fornasier, and C.~G\"unt\"urk.
\newblock Iteratively Reweighted Least Squares Minimization for Sparse
  Recovery.
\newblock {\em Commun. Pure Appl. Math.}, 63:1--38, 2010.

\bibitem[DPG{\etalchar{+}}14]{Dauphin14}
Y.~N. Dauphin, R.~Pascanu, C.~Gulcehre, K.~Cho, S.~Ganguli, and Y.~Bengio.
\newblock Identifying and attacking the saddle point problem in
  high-dimensional non-convex optimization.
\newblock In {\em {Advances in Neural Information Processing Systems (NIPS)}},
  pages 2933--2941, 2014.

\bibitem[DR16]{Davenport16}
M.~A. Davenport and J.~Romberg.
\newblock {An Overview of Low-Rank Matrix Recovery From Incomplete
  Observations}.
\newblock {\em IEEE J. Sel. Topics Signal Process.}, 10:608--622, 2016.

\bibitem[DSST18]{Ding18}
C.~Ding, D.~Sun, J.~Sun, and K.-C. Toh.
\newblock Spectral operators of matrices.
\newblock {\em Math. Program.}, 168(1):509--531, 2018.

\bibitem[Faz02]{Fazel02}
M.~Fazel.
\newblock {\em Matrix rank minimization with applications}.
\newblock Ph.D. Thesis, Electrical Engineering Department, Stanford University,
  2002.

\bibitem[FGP15]{Frankel15}
P.~Frankel, G.~Garrigos, and J.~Peypouquet.
\newblock {Splitting methods with variable metric for Kurdyka--{\L}ojasiewicz
  functions and general convergence rates}.
\newblock {\em Journal of Optimization Theory and Applications},
  165(3):874--900, 2015.

\bibitem[FHB03]{FHB03}
M.~{Fazel}, H.~{Hindi}, and S.~P. {Boyd}.
\newblock {Log-det heuristic for matrix rank minimization with applications to
  Hankel and Euclidean distance matrices}.
\newblock In {\em {Proceedings of the American Control Conference}}, volume~3,
  pages 2156--2162, 2003.

\bibitem[FL12]{fannjiang_liao}
A.~Fannjiang and W.~Liao.
\newblock {Coherence Pattern--Guided Compressive Sensing with Unresolved
  Grids}.
\newblock {\em SIAM J. Imaging Sciences}, 5(1):179--202, 2012.

\bibitem[Fou18]{Foucart18}
S.~Foucart.
\newblock {Concave Mirsky Inequality and Low-Rank Recovery}.
\newblock {\em SIAM J. Matrix Anal. Appl.}, 39(1):99--103, 2018.

\bibitem[FPRW16]{Fornasier16}
M.~Fornasier, S.~Peter, H.~Rauhut, and S.~Worm.
\newblock Conjugate gradient acceleration of iteratively re-weighted least
  squares methods.
\newblock {\em Comput. Optim. Appl.}, 65(1):205--259, 2016.

\bibitem[FRW11]{Fornasier11}
M.~Fornasier, H.~Rauhut, and R.~Ward.
\newblock Low-rank Matrix Recovery via Iteratively Reweighted Least Squares
  Minimization.
\newblock {\em SIAM J. Optim.}, 21(4):1614--1640, 2011.

\bibitem[GGK00]{Gohberg2000}
I.~Gohberg, S.~Goldberg, and N.~Krupnik.
\newblock {\em {Traces and determinants of linear operators}}, volume 116 of
  {\em Operator Theory: Advances and Applications}.
\newblock Springer, Basel, 2000.

\bibitem[GU77]{Golub77}
G.~H. Golub and R.~Underwood.
\newblock The block Lanczos method for computing eigenvalues.
\newblock In {\em Mathematical software}, pages 361--377. Elsevier, 1977.

\bibitem[GVRH20]{Giampouras20}
P.~Giampouras, R.~Vidal, A.~Rontogiannis, and B.~Haeffele.
\newblock {A novel variational form of the Schatten-$p$ quasi-norm}.
\newblock In {\em NeurIPS}, 2020.

\bibitem[HAG17]{Huang17intrinsic}
W.~Huang, P.-A. Absil, and K.~A. Gallivan.
\newblock Intrinsic representation of tangent vectors and vector transports on
  matrix manifolds.
\newblock {\em Numerische Mathematik}, 136(2):523--543, 2017.

\bibitem[HJ91]{horn_johnson}
R.~Horn and C.~Johnson.
\newblock {\em Topics in Matrix Analysis}.
\newblock Cambridge University Press, 1st edition edition, 1991.

\bibitem[HS52]{HestenesStiefel52}
M.~R. Hestenes and E.~Stiefel.
\newblock Methods of Conjugate Gradients for Solving Linear Systems.
\newblock {\em Journal of research of the National Bureau of Standards}, 49(1),
  1952.

\bibitem[KBV09]{koren_bell_volinsky}
Y.~Koren, R.~Bell, and C.~Volinsky.
\newblock {Matrix Factorization Techniques for Recommender Systems}.
\newblock {\em Computer}, 42(8):30--37, 2009.

\bibitem[KS18]{KS18}
C.~K{\"u}mmerle and J.~Sigl.
\newblock {Harmonic Mean Iteratively Reweighted Least Squares for Low-Rank
  Matrix Recovery}.
\newblock {\em J. Mach. Learn. Res.}, 19(47):1--49, 2018.

\bibitem[LHLZ20]{Luo20}
Y.~Luo, W.~Huang, X.~Li, and A.~R. Zhang.
\newblock Recursive Importance Sketching for Rank Constrained Least Squares:
  Algorithms and High-order Convergence.
\newblock {\em arXiv preprint arXiv:2011.08360}, 2020.

\bibitem[LS05]{Lewis05_Nonsm1}
A.~S. Lewis and H.~S. Sendov.
\newblock {Nonsmooth Analysis of Singular Values. Part I: Theory}.
\newblock {\em Set-Valued Analysis}, 13(3):213--241, 2005.

\bibitem[LTYL15]{Lu2015nonconvex}
C.~Lu, J.~Tang, S.~Yan, and Z.~Lin.
\newblock Nonconvex nonsmooth low rank minimization via iteratively reweighted
  nuclear norm.
\newblock {\em IEEE Trans. Image Process.}, 25(2):829--839, 2015.

\bibitem[LXY13]{Lai13}
M.~Lai, Y.~Xu, and W.~Yin.
\newblock Improved iteratively reweighted least squares for unconstrained
  smoothed $\ell_q$ minimization.
\newblock {\em SIAM J. Numer. Anal}, page 2013, 2013.

\bibitem[Meu06]{Meurant}
G.~Meurant.
\newblock {\em The Lanczos and Conjugate Gradient Algorithms: From Theory to
  Finite Precision Computations}.
\newblock Society for Industrial and Applied Mathematics,, 2006.

\bibitem[MF12]{Mohan10}
K.~Mohan and M.~Fazel.
\newblock Iterative Reweighted Algorithms for Matrix Rank Minimization.
\newblock {\em J. Mach. Learn. Res.}, 13(1):3441--3473, 2012.

\bibitem[Mir60]{Mirsky60}
L.~Mirsky.
\newblock {Symmetric Gauge Functions And Unitarily Invariant Norms}.
\newblock {\em The Quarterly Journal of Mathematics}, 11(1):50--59, 1960.

\bibitem[MM15]{MuscoMusco15}
C.~Musco and C.~Musco.
\newblock {Randomized Block Krylov Methods for Stronger and Faster Approximate
  Singular Value Decomposition}.
\newblock In {\em {Advances in Neural Information Processing Systems (NIPS)}},
  pages 1396--1404, 2015.

\bibitem[MS14]{MishraS14}
B.~Mishra and R.~Sepulchre.
\newblock {R3MC:} {A} {Riemannian} three-factor algorithm for low-rank matrix
  completion.
\newblock In {\em 53rd {IEEE} Conference on Decision and Control, {CDC} 2014,
  Los Angeles, CA, USA, December 15-17, 2014}, pages 1137--1142. {IEEE}, 2014.

\bibitem[MSW20]{Mazumder20}
R.~Mazumder, D.~Saldana, and H.~Weng.
\newblock Matrix completion with nonconvex regularization: Spectral operators
  and scalable algorithms.
\newblock {\em Statistics and Computing}, pages 1--26, 2020.

\bibitem[Mur10]{Murray2010}
W.~Murray.
\newblock {Newton-Type Methods}.
\newblock {\em Wiley Encyclopedia of Operations Research and Management
  Science}, 2010.

\bibitem[MWCC20]{MaWangChiChen19}
C.~Ma, K.~Wang, Y.~Chi, and Y.~Chen.
\newblock Implicit Regularization in Nonconvex Statistical Estimation: Gradient
  Descent Converges Linearly for Phase Retrieval, Matrix Completion, and Blind
  Deconvolution.
\newblock {\em Foundations of Computational Mathematics}, 20:451--632, 2020.

\bibitem[Nof17]{Noferini17}
V.~Noferini.
\newblock {A Formula for the Fr{\'e}chet Derivative of a Generalized Matrix
  Function}.
\newblock {\em SIAM J. Matrix Anal. Appl.}, 38(2):434--457, 2017.

\bibitem[NW06]{NocedalWright06}
J.~Nocedal and S.~Wright.
\newblock {\em Numerical optimization}.
\newblock Springer Science \& Business Media, 2006.

\bibitem[PABN16]{Pimentel15}
D.~L. Pimentel-Alarc{\'o}n, N.~Boston, and R.~D. Nowak.
\newblock {A Characterization of Deterministic Sampling Patterns for Low-Rank
  Matrix Completion}.
\newblock {\em IEEE J. Sel. Topics Signal Process.}, 10(4):623--636, 2016.

\bibitem[PMR19]{PaternainMokhtariRibeiro19}
S.~Paternain, A.~Mokhtari, and A.~Ribeiro.
\newblock {A Newton-Based Method for Nonconvex Optimization with Fast Evasion
  of Saddle Points}.
\newblock {\em SIAM J. Optim.}, 29(1):343--368, 2019.

\bibitem[Rec11]{recht}
B.~Recht.
\newblock {A Simpler Approach to Matrix Completion}.
\newblock {\em J. Mach. Learn. Res.}, 12:3413--3430, 2011.

\bibitem[RFP10]{Recht10}
B.~Recht, M.~Fazel, and P.~A. Parrilo.
\newblock Guaranteed Minimum-Rank Solutions of Linear Matrix Equations via
  Nuclear Norm Minimization.
\newblock {\em SIAM Rev.}, 52(3):471--501, 2010.

\bibitem[RXH11]{Recht11}
B.~Recht, W.~Xu, and B.~Hassibi.
\newblock Null space conditions and thresholds for rank minimization.
\newblock {\em Math. Program.}, 127(1):175--202, 2011.

\bibitem[SL16]{SunL15}
R.~Sun and Z.~Q. Luo.
\newblock {Guaranteed Matrix Completion via Non-Convex Factorization}.
\newblock {\em IEEE Trans. Inf. Theory}, 62(11):6535--6579, 2016.

\bibitem[Ste06]{Stewart06}
M.~Stewart.
\newblock Perturbation of the {SVD} in the presence of small singular values.
\newblock {\em Linear Algebra Appl.}, 419(1):53--77, 2006.

\bibitem[TMC20]{tong_ma_chi}
T.~Tong, C.~Ma, and Y.~Chi.
\newblock Accelerating Ill-Conditioned Low-Rank Matrix Estimation via Scaled
  Gradient Descent.
\newblock {\em arXiv preprint arXiv:2005.08898}, 2020.

\bibitem[TTW{\etalchar{+}}14]{Tan2014}
M.~Tan, I.~W. Tsang, L.~Wang, B.~Vandereycken, and S.~J. Pan.
\newblock {Riemannian pursuit for big matrix recovery}.
\newblock In {\em {International Conference on Machine Learning (ICML)}}, pages
  1539--1547. PMLR, 2014.

\bibitem[TW13]{TannerWei13}
J.~Tanner and K.~Wei.
\newblock {Normalized Iterative Hard Thresholding for Matrix Completion}.
\newblock {\em SIAM J. Sci. Comput.}, 35(5):S104--S125, 2013.

\bibitem[TW16]{TannerWei16}
J.~Tanner and K.~Wei.
\newblock Low rank matrix completion by alternating steepest descent methods.
\newblock {\em Appl. Comput. Harmon. Anal.}, 40(2):417--429, 2016.

\bibitem[UV15]{Uschmajew_Vandereycken}
A.~Uschmajew and B.~Vandereycken.
\newblock Greedy rank updates combined with {R}iemannian descent methods for
  low-rank optimization.
\newblock In {\em Sampling Theory and Applications (SampTA), 2015 International
  Conference on}, pages 420--424. IEEE, 2015.

\bibitem[Van13]{Vandereycken13}
B.~Vandereycken.
\newblock {Low-Rank Matrix Completion by {R}iemannian Optimization}.
\newblock {\em SIAM J. Optim.}, 23(2), 2013.

\bibitem[Ver18]{Ver18}
R.~Vershynin.
\newblock {\em High-Dimensional Probability: An Introduction with Applications
  in Data Science}.
\newblock Cambridge Series in Statistical and Probabilistic Mathematics.
  Cambridge University Press, 2018.

\bibitem[Vor12]{Voronin12}
S.~Voronin.
\newblock {\em Regularization of linear systems with sparsity constraints with
  applications to large scale inverse problems}.
\newblock Ph.D. Thesis, Princeton University, 2012.

\bibitem[WCCL16]{WeiCCL16MatrixRecovery}
K.~Wei, J.-F. Cai, T.~F. Chan, and S.~Leung.
\newblock {Guarantees of Riemannian Optimization for Low Rank Matrix Recovery}.
\newblock {\em SIAM J. Matrix Anal. Appl.}, 37(3):1198--1222, 2016.

\bibitem[WCCL20]{wei_cai_chan_leung}
K.~Wei, J.-F. Cai, T.~F. Chan, and S.~Leung.
\newblock {Guarantees of Riemannian optimization for low rank matrix
  completion}.
\newblock {\em Inverse Probl. Imaging}, 14(2):233--265, 2020.

\bibitem[Wed72]{Wedin72}
P.-{\AA}. Wedin.
\newblock Perturbation bounds in connection with singular value decomposition.
\newblock {\em BIT}, 12(1):99--111, 1972.

\bibitem[Woo50]{Woodbury50}
M.~A. Woodbury.
\newblock Inverting modified matrices.
\newblock {\em Memorandum report}, 42(106):336, 1950.

\bibitem[WYZ12]{Wen12}
Z.~Wen, W.~Yin, and Y.~Zhang.
\newblock Solving a low-rank factorization model for matrix completion by a
  nonlinear successive over-relaxation algorithm.
\newblock {\em Mathematical Programming Computation}, 4(4):333--361, 2012.

\bibitem[Yan09]{Yang09}
Z.~Yang.
\newblock {\em A study on nonsymmetric matrix-valued functions}.
\newblock Master's thesis, Department of Mathematics, National University of
  Singapore, 2009.

\bibitem[YGL18]{Yuan18}
Q.~Yuan, M.~Gu, and B.~Li.
\newblock Superlinear convergence of randomized block lanczos algorithm.
\newblock In {\em 2018 IEEE International Conference on Data Mining (ICDM)},
  pages 1404--1409. IEEE, 2018.

\bibitem[ZL16]{ZhengL16}
Q.~{Zheng} and J.~{Lafferty}.
\newblock {Convergence Analysis for Rectangular Matrix Completion Using
  Burer-Monteiro Factorization and Gradient Descent}.
\newblock {\em arXiv preprint arXiv:1605.07051}, 2016.

\end{thebibliography}
