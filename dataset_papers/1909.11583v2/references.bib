
@book{sutton-barto18,
	Author = {Richard S. Sutton and Andrew G. Barto and Francis Bach},
	Publisher = {MIT press},
	Title = {Reinforcement Learning: An Introduction},
	Year = {2018}
	}

@article{bellemare2013arcade,
  title={The {A}rcade {L}earning {E}nvironment: An evaluation platform for general agents.},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={JAIR},
  year={2013}
}

@inproceedings{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  booktitle={ICLR},
  year={2015}
}

@incollection{Munos:2016,
title = {Safe and Efficient Off-Policy Reinforcement Learning},
author = {Munos, Remi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
booktitle = {NIPS},
year = {2016},
}


@inproceedings{Precup:2000,
 author = {Precup, Doina and Sutton, Richard S. and Singh, Satinder P.},
 title = {Eligibility Traces for Off-Policy Policy Evaluation},
 booktitle = {ICML},
 year = {2000},
} 


@article{Asis:2018,
  author    = {Kristopher De Asis and
               Richard S. Sutton},
  title     = {Per-decision Multi-step Temporal Difference Learning with Control
               Variates},
  journal   = {Arxiv},
  volume    = {abs/1807.01830},
  year      = {2018}
}

@article{Mahmood:2017,
  author    = {Ashique Rupam Mahmood and
               Huizhen Yu and
               Richard S. Sutton},
  title     = {Multi-step Off-policy Learning Without Importance Sampling Ratios},
  journal   = {Arxiv},
  volume    = {abs/1702.03006},
  year      = {2017}
}

@article{Hochreiter:1997,
 author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
 title = {Long Short-Term Memory},
 journal = {Neural Comput.},
 issue_date = {November 15, 1997},
 volume = {9},
 number = {8},
 month = nov,
 year = {1997},
 issn = {0899-7667},
 pages = {1735--1780},
 numpages = {46},
 doi = {10.1162/neco.1997.9.8.1735},
 acmid = {1246450},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 


@article{Kaiser:2019,
  author    = {Lukasz Kaiser and
               Mohammad Babaeizadeh and
               Piotr Milos and
               Blazej Osinski and
               Roy H. Campbell and
               Konrad Czechowski and
               Dumitru Erhan and
               Chelsea Finn and
               Piotr Kozakowski and
               Sergey Levine and
               Ryan Sepassi and
               George Tucker and
               Henryk Michalewski},
  title     = {Model-Based Reinforcement Learning for Atari},
  journal   = {Arxiv},
  volume    = {abs/1903.00374},
  year      = {2019}
}

@article{Sutton:1988,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton},
  journal={ML},
  year={1988}
}

@incollection{Xu:2018,
title = {Meta-Gradient Reinforcement Learning},
author = {Xu, Zhongwen and van Hasselt, Hado P and Silver, David},
booktitle = {NIPS},
year = {2018},
}

@article{Silver:2017,
  author    = {David Silver and
               Thomas Hubert and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Matthew Lai and
               Arthur Guez and
               Marc Lanctot and
               Laurent Sifre and
               Dharshan Kumaran and
               Thore Graepel and
               Timothy P. Lillicrap and
               Karen Simonyan and
               Demis Hassabis},
  title     = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
               Learning Algorithm},
  journal   = {Arxiv},
  volume    = {abs/1712.01815},
  year      = {2017},
  archivePrefix = {arXiv},
  eprint    = {1712.01815},
  timestamp = {Wed, 03 Jan 2018 12:33:17 +0100},
}


@article{Kahn:1955,
 author = {Herman Kahn},
 title = {Use of different Monte Carlo sampling techniques},
 journal = {Santa Monica, Calif.},
 year = {1955},
} 

@article{Tolman:1948,
 author = {Edward C. Tolman},
 title = {Cognitive Maps in Rats and Men},
 journal = {The Psychological Review},
 year = {1948},
} 

@article{Olton:1979,
 author = {David S. Olton},
 title = {Mazes, maps, and memory},
 journal = {American Psychologist},
 year = {1979},
} 

@phdthesis{Watkins:1989,
	Author = {C. J. C. H. Watkins},
	Date-Added = {2016-10-31 17:28:30 +0000},
	Date-Modified = {2016-10-31 17:28:35 +0000},
	School = {King's College, Cambridge, England},
	Title = {Learning from Delayed Rewards},
	Year = {1989}}

@INPROCEEDINGS{Williams:90,
    author = {Ronald Williams and Leemon C. Baird},
    title = {A Mathematical Analysis Of Actor-Critic Architectures For Learning Optimal Controls Through Incremental Dynamic Programming},
    booktitle = {Proceedings of the Sixth Yale Workshop on Adaptive and Learning Systems},
    year = {1990},
    pages = {96--101}
}

@article{Williams1992,
 author = {Williams},
 title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
 journal = {ML},
 year = {1992},
} 

@phdthesis{Lin:1992,
 author = {Lin, Long-Ji},
 title = {Reinforcement Learning for Robots Using Neural Networks},
 year = {1992},
 note = {UMI Order No. GAX93-22750},
 publisher = {Carnegie Mellon University},
 address = {Pittsburgh, PA, USA},
} 

@inproceedings{Riedmiller:2005,
 author = {Riedmiller, Martin},
 title = {Neural Fitted Q Iteration -- First Experiences with a Data Efficient Neural Reinforcement Learning Method},
 booktitle = {ECML},
 year = {2005},
} 

@article{Pohlen:2018,
  author    = {Tobias Pohlen and
               Bilal Piot and
               Todd Hester and
               Mohammad Gheshlaghi Azar and
               Dan Horgan and
               David Budden and
               Gabriel Barth{-}Maron and
               Hado van Hasselt and
               John Quan and
               Mel Vecer{\'{\i}}k and
               Matteo Hessel and
               R{\'{e}}mi Munos and
               Olivier Pietquin},
  title     = {Observe and Look Further: Achieving Consistent Performance on Atari},
  journal   = {Arxiv},
  volume    = {abs/1805.11593},
  year      = {2018},
  archivePrefix = {arXiv},
  eprint    = {1805.11593},
  timestamp = {Mon, 13 Aug 2018 16:48:00 +0200},
}

@article{Tesauro:1995,
 author = {Tesauro, Gerald},
 title = {Temporal Difference Learning and TD-Gammon},
 journal = {Commun. ACM},
 issue_date = {March 1995},
 volume = {38},
 number = {3},
 month = mar,
 year = {1995},
 issn = {0001-0782},
 pages = {58--68},
 numpages = {11},
 doi = {10.1145/203330.203343},
 acmid = {203343},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@inproceedings{Mnih:2016,
  author    = {Volodymyr Mnih and
               Adri{\`{a}} Puigdom{\`{e}}nech Badia and
               Mehdi Mirza and
               Alex Graves and
               Timothy P. Lillicrap and
               Tim Harley and
               David Silver and
               Koray Kavukcuoglu},
	Booktitle = {ICML},
	Title = {Asynchronous Methods for Deep Reinforcement Learning},
	Year = {2016}}


@InProceedings{Haarnoja:2018,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author = 	 {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = {ICML},
  year      =  {2018},
}


@INPROCEEDINGS{Baird:95,
    author = {Leemon Baird},
    title = {Residual Algorithms: Reinforcement Learning with Function Approximation},
    booktitle = {In Proceedings of the Twelfth International Conference on Machine Learning},
    year = {1995},
    pages = {30--37},
    publisher = {Morgan Kaufmann}
}

@TECHREPORT{Tsitsiklis:97,
    author = {John N. Tsitsiklis and Benjamin Van Roy},
    title = {An analysis of temporal-difference learning with function approximation},
    institution = {IEEE Transactions on Automatic Control},
    year = {1997}
}

@article{vanHasselt:2018,
  author    = {Hado van Hasselt and
               Yotam Doron and
               Florian Strub and
               Matteo Hessel and
               Nicolas Sonnerat and
               Joseph Modayil},
  title     = {Deep Reinforcement Learning and the Deadly Triad},
  journal   = {Arxiv},
  volume    = {abs/1812.02648},
  year      = {2018},
  archivePrefix = {arXiv},
  eprint    = {1812.02648},
  timestamp = {Tue, 01 Jan 2019 15:01:25 +0100},
}

@article{Zhang:2018,
  author    = {Shangtong Zhang and
               Richard S. Sutton},
  title     = {A Deeper Look at Experience Replay},
  journal   = {Arxiv},
  volume    = {abs/1712.01275},
  year      = {2017},
  archivePrefix = {arXiv},
  eprint    = {1712.01275},
  timestamp = {Mon, 13 Aug 2018 16:46:10 +0200},
}

@article{bellman:1957,
  added-at = {2017-04-07T12:00:35.000+0200},
  author = {Bellman, Richard},
  journal = {Journal of Mathematics and Mechanics},
  title = {A Markovian decision process},
  year = 1957
}

@incollection{Osband:2016,
title = {Deep Exploration via Bootstrapped DQN},
author = {Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
booktitle = {NIPS},
year = {2016},
}

@article{Jouppi:2017,
  author    = {Norman P. Jouppi and
               Cliff Young and
               Nishant Patil and
               David A. Patterson and
               Gaurav Agrawal and
               Raminder Bajwa and
               Sarah Bates and
               Suresh Bhatia and
               Nan Boden and
               Al Borchers and
               Rick Boyle and
               Pierre{-}luc Cantin and
               Clifford Chao and
               Chris Clark and
               Jeremy Coriell and
               Mike Daley and
               Matt Dau and
               Jeffrey Dean and
               Ben Gelb and
               Tara Vazir Ghaemmaghami and
               Rajendra Gottipati and
               William Gulland and
               Robert Hagmann and
               Richard C. Ho and
               Doug Hogberg and
               John Hu and
               Robert Hundt and
               Dan Hurt and
               Julian Ibarz and
               Aaron Jaffey and
               Alek Jaworski and
               Alexander Kaplan and
               Harshit Khaitan and
               Andy Koch and
               Naveen Kumar and
               Steve Lacy and
               James Laudon and
               James Law and
               Diemthu Le and
               Chris Leary and
               Zhuyuan Liu and
               Kyle Lucke and
               Alan Lundin and
               Gordon MacKean and
               Adriana Maggiore and
               Maire Mahony and
               Kieran Miller and
               Rahul Nagarajan and
               Ravi Narayanaswami and
               Ray Ni and
               Kathy Nix and
               Thomas Norrie and
               Mark Omernick and
               Narayana Penukonda and
               Andy Phelps and
               Jonathan Ross and
               Amir Salek and
               Emad Samadiani and
               Chris Severn and
               Gregory Sizikov and
               Matthew Snelham and
               Jed Souter and
               Dan Steinberg and
               Andy Swing and
               Mercedes Tan and
               Gregory Thorson and
               Bo Tian and
               Horia Toma and
               Erick Tuttle and
               Vijay Vasudevan and
               Richard Walter and
               Walter Wang and
               Eric Wilcox and
               Doe Hyun Yoon},
  title     = {In-Datacenter Performance Analysis of a Tensor Processing Unit},
  journal   = {Arxiv},
  volume    = {abs/1704.04760},
  year      = {2017}
}

@incollection{Osband:2018,
title = {Randomized Prior Functions for Deep Reinforcement Learning},
author = {Osband, Ian and Aslanides, John and Cassirer, Albin},
booktitle = {NIPS},
year = {2018},
}



@article{Mankowitz:2018,
  author    = {Daniel J. Mankowitz and
               Augustin Z{\'{\i}}dek and
               Andr{\'{e}} Barreto and
               Dan Horgan and
               Matteo Hessel and
               John Quan and
               Junhyuk Oh and
               Hado van Hasselt and
               David Silver and
               Tom Schaul},
  title     = {Unicorn: Continual Learning with a Universal, Off-policy Agent},
  journal   = {Arxiv},
  volume    = {abs/1802.08294},
  year      = {2018},
}

@inproceedings{Sutton:2000,
  title={Policy gradient methods for RL with function approximation},
  author={Sutton and McAllester and Singh and Mansour},
  booktitle={NIPS},
  year={2000}
}

@article{Sutton:2011,
  title={Horde: A scalable real-time architecture for learning knowledge
    from unsupervised sensorimotor interaction},
  author={Sutton, Richard S. and Modayil, Joseph and Delp, Michael and Degris, Thomas
    and Pilarski, Patrick M. and White, Adam and Precup, Doina},
  journal={Proc. of 10th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS 2011)},
  year={2011},
}

@inproceedings{Sutton:2014,
  title={A new Q($\lambda$) with interim forward view and {Monte Carlo} equivalence},
  author={Sutton, Richard S. and Mahmood, Ashique Rupam and Precup, Doina and van Hasselt, Hado},
  booktitle={ICML},
  year={2014}
}

@inproceedings{vanHasselt:2016,
  title={Deep Reinforcement Learning with Double {Q}-Learning.},
  author={{van Hasselt}, Hado and Guez, Arthur and Silver, David},
  booktitle={AAAI},
  year={2016}
}

@article{Schulman:17,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {Arxiv},
  volume    = {abs/1707.06347},
  year      = {2017}
}

@inproceedings{McGovern:2001,
 author = {McGovern, Amy and Barto, Andrew G.},
 title = {Automatic Discovery of Subgoals in Reinforcement Learning Using Diverse Density},
 booktitle = {Proceedings of the Eighteenth International Conference on Machine Learning},
 series = {ICML '01},
 year = {2001},
 isbn = {1-55860-778-1},
 pages = {361--368},
 numpages = {8},
 acmid = {655681},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 
[download]

@article{Kretchmar:2002,
  title={Parallel Reinforcement Learning.},
  author={{Kretchmar}, R.M},
  journal={SCI2002. The 6th World Conference on Systemics, Cybernetics, and Informatics. Orlando, FL},
  year={2002}
}


@article{Sutton:1999,
 author = {Sutton, Richard S. and Precup, Doina and Singh, Satinder},
 title = {Between MDPs and semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning},
 journal = {Artif. Intell.},
 issue_date = {Aug. 1999},
 volume = {112},
 number = {1-2},
 month = aug,
 year = {1999},
 issn = {0004-3702},
 pages = {181--211},
 numpages = {31},
 doi = {10.1016/S0004-3702(99)00052-1},
 acmid = {319108},
 publisher = {Elsevier Science Publishers Ltd.},
 address = {Essex, UK},
 keywords = {Markov decision processes, hierarchical planning, intra-options learning, macroactions, macros, options, reinforcement learning, semi-Markov decision processes, subgoals, temporal abstraction},
} 


@InProceedings{Schulman:15,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {John Schulman and Sergey Levine and Pieter Abbeel and Michael Jordan and Philipp Moritz},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1889--1897},
  year = 	 {2015},
  editor = 	 {Francis Bach and David Blei},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher = 	 {PMLR},
}

@Book{Conn:2000,
  Title = {Trust-Region Methods},
  Author = {Andrew R. Conn and Nicholas I. M. Gould and {\relax Ph}ilippe L. Toint},
  Publisher = {SIAM},
  Year = {2000},
  Address = {Philadelphia, PA, USA}
}

@incollection{Snoek:2012,
title = {Practical Bayesian Optimization of Machine Learning Algorithms},
author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
booktitle = {NIPS},
year = {2012},
}

@article{Schaul:2019,
 author = {Schaul, Tom and Borsa, Diana and Modayil, Joseph and Pascanu, Razvan},
 title = {Ray Interference: a Source of Plateaus in Deep Reinforcement Learning},
 year = {2019},
}


@article{Bergstra:2012,
 author = {Bergstra, James and Bengio, Yoshua},
 title = {Random Search for Hyper-parameter Optimization},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2012},
 volume = {13},
 number = {1},
 month = feb,
 year = {2012},
 issn = {1532-4435},
 pages = {281--305},
 numpages = {25},
 acmid = {2188395},
 publisher = {JMLR.org},
 keywords = {deep learning, global optimization, model selection, neural networks, response surface modeling},
} 

@inproceedings{AuxTasksDepth,
	Author = {Piotr Mirowski and
               Razvan Pascanu and
               Fabio Viola and
               Hubert Soyer and
               Andrew J. Ballard and
               Andrea Banino and
               Misha Denil and
               Ross Goroshin and
               Laurent Sifre and
               Koray Kavukcuoglu and
               Dharshan Kumaran and
               Raia Hadsell},
	Booktitle = {ICLR},
	Title = {Learning to Navigate in Complex Environments},
	Year = {2017},
}


@article{OptionCritic,
  author    = {Pierre{-}Luc Bacon and
               Jean Harb and
               Doina Precup},
  title     = {The Option-Critic Architecture},
  journal   = {AAAI},
  year      = {2017},
}

@inproceedings{AuxTasksFPS,
	Author = {Guillaume Lample and
               Devendra Singh Chaplot},
	Booktitle = {AAAI},
	Title = {Playing {FPS} Games with Deep Reinforcement Learning},
	Year = {2016},
}


@article{Dota,
  author    = {OpenAI},
  title     = {OpenAI Dota 2 1v1 bot},
  journal   = {https://openai.com/the-international/},
  year      = {2017},
}



@inproceedings{Hester:2017,
  title={Learning from Demonstrations for Real World Reinforcement Learning},
  author    = {Todd Hester and
               Matej Vecerik and
               Olivier Pietquin and
               Marc Lanctot and
               Tom Schaul and
               Bilal Piot and
               Andrew Sendonaris and
               Gabriel Dulac{-}Arnold and
               Ian Osband and
               John Agapiou and
               Joel Z. Leibo and
               Audrunas Gruslys},
 booktitle  = {AAAI},
 year   = {2017},
}


@article{Moore:1993,
author = {Andrew Moore and C. G. Atkeson},
title = {Prioritized Sweeping: Reinforcement Learning with Less Data and Less Real Time},
journal = {Machine Learning},
year = {1993},
month = {October},
volume = {13},
}

@article{Beattie:2016,
  author    = {Charles Beattie and
               Joel Z. Leibo and
               Denis Teplyashin and
               Tom Ward and
               Marcus Wainwright and
               Heinrich K{\"{u}}ttler and
               Andrew Lefrancq and
               Simon Green and
               V{\'{\i}}ctor Vald{\'{e}}s and
               Amir Sadik and
               Julian Schrittwieser and
               Keith Anderson and
               Sarah York and
               Max Cant and
               Adam Cain and
               Adrian Bolton and
               Stephen Gaffney and
               Helen King and
               Demis Hassabis and
               Shane Legg and
               Stig Petersen},
  title     = {DeepMind Lab},
  journal   = {Arxiv},
  volume    = {abs/1612.03801},
  year      = {2016},
  archivePrefix = {arXiv},
  eprint    = {1612.03801},
  timestamp = {Mon, 13 Aug 2018 16:48:18 +0200},
}

@article{Starcraft2,
  author    = {Oriol Vinyals and
               Timo Ewalds and
               Sergey Bartunov and
               Petko Georgiev and
               Alexander Sasha Vezhnevets and
               Michelle Yeo and
               Alireza Makhzani and
               Heinrich K{\"{u}}ttler and
               John Agapiou and
               Julian Schrittwieser and
               John Quan and
               Stephen Gaffney and
               Stig Petersen and
               Karen Simonyan and
               Tom Schaul and
               Hado van Hasselt and
               David Silver and
               Timothy P. Lillicrap and
               Kevin Calderone and
               Paul Keet and
               Anthony Brunasso and
               David Lawrence and
               Anders Ekermo and
               Jacob Repp and
               Rodney Tsing},
  title     = {StarCraft {II:} {A} New Challenge for Reinforcement Learning},
  journal   = {Arxiv},
  volume    = {abs/1708.04782},
  year      = {2017},
  archivePrefix = {arXiv},
  eprint    = {1708.04782},
  timestamp = {Mon, 13 Aug 2018 16:47:24 +0200},
}

@article{jaderberg2017pbt,
  author    = {Max Jaderberg and
               Valentin Dalibard and
               Simon Osindero and
               Wojciech M. Czarnecki and
               Jeff Donahue and
               Ali Razavi and
               Oriol Vinyals and
               Tim Green and
               Iain Dunning and
               Karen Simonyan and
               Chrisantha Fernando and
               Koray Kavukcuoglu},
  title     = {Population Based Training of Neural Networks},
  journal   = {Arxiv},
  volume    = {abs/1711.09846},
  year      = {2017},
}

@INPROCEEDINGS{Ziyu2017,
    author = {Ziyu Wang and Victor Bapst and Nicolas Heess and Volodymyr Mnih and Remi Munos and Koray Kavukcuoglu and Nando de Freitas},
    title = {Sample Efficient Actor-Critic with Experience Replay},
    booktitle = {ICLR},
    year = {2017},
}

@inbook{Schonebaum:2017,
author = {Gerben Schonebaum and Jaime Junell and Erik-Jan Van Kampen},
title = {Human Demonstrations for Fast and Safe Exploration in Reinforcement Learning},
booktitle = {AIAA Information Systems-AIAA Infotech @ Aerospace},
pages = {1069--1086},
doi = {10.2514/6.2017-1069},
year = {2017},
}


@inproceedings{ApeX,
  title={Distributed Prioritized Experience Replay},
  author={Dan Horgan and John Quan and David Budden and Gabriel Barth-Maron and Matteo Hessel and Hado van Hasselt and David Silver},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{IMPALA,
  title={IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures},
  author={Lasse Espeholt and Hubert Soyer and Remi Munos and Karen Simonyan and Volodymir Mnih and Tom Ward and Yotam Doron and Vlad Firoiu and Tim Harley and Iain Dunning and Shane Legg and Koray Kavukcuoglu},
  booktitle={ICML},
  year={2018}
}

@article{DmLab,
  author    = {Charles Beattie and
               Joel Z. Leibo and
               Denis Teplyashin and
               Tom Ward and
               Marcus Wainwright and
               Heinrich K{\"{u}}ttler and
               Andrew Lefrancq and
               Simon Green and
               V{\'{\i}}ctor Vald{\'{e}}s and
               Amir Sadik and
               Julian Schrittwieser and
               Keith Anderson and
               Sarah York and
               Max Cant and
               Adam Cain and
               Adrian Bolton and
               Stephen Gaffney and
               Helen King and
               Demis Hassabis and
               Shane Legg and
               Stig Petersen},
  title     = {DeepMind Lab},
  journal   = {Arxiv},
  volume    = {abs/1612.03801},
  year      = {2016},
  archivePrefix = {arXiv},
  eprint    = {1612.03801},
  timestamp = {Wed, 07 Jun 2017 14:42:49 +0200},
}


@article{Rainbow,
  author    = {Matteo Hessel and
               Joseph Modayil and
               Hado van Hasselt and
               Tom Schaul and
               Georg Ostrovski and
               Will Dabney and
               Daniel Horgan and
               Bilal Piot and
               Mohammad Gheshlaghi Azar and
               David Silver},
  title     = {Rainbow: Combining Improvements in Deep Reinforcement Learning},
  journal   = {Arxiv},
  volume    = {abs/1710.02298},
  year      = {2017},
  archivePrefix = {arXiv},
  eprint    = {1710.02298},
  timestamp = {Wed, 01 Nov 2017 19:05:43 +0100},
}


@inproceedings{Reactor,
    title={The Reactor: A fast and sample-efficient Actor-Critic agent for  Reinforcement Learning},
    author={Audrunas Gruslys and Will Dabney and Mohammad Gheshlaghi Azar and Bilal Piot and Marc Bellemare and Remi Munos},
    booktitle={ICLR},
    year={2018},
}


@article{dqn-arxiv,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Alex Graves and
               Ioannis Antonoglou and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Playing Atari with Deep Reinforcement Learning},
  journal   = {Arxiv},
  volume    = {abs/1312.5602},
  year      = {2013},
  timestamp = {Wed, 07 Jun 2017 14:43:06 +0200},
}

@article{mnih15human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{jaderberg2016reinforcement,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={ICLR},
  year={2017},
}

@inproceedings{hessel2018multitask,
  title={Multi-task Deep Reinforcement Learning with PopArt},
  author={Matteo Hessel and Hubert Soyer and Lasse Espeholt and Wojciech Czarnecki and Simon Schmitt and Hado van Hasselt},
 booktitle  = {AAAI},
 year   = {2019},
}


@article{Maron:2018,
  author    = {Gabriel Barth{-}Maron and
               Matthew W. Hoffman and
               David Budden and
               Will Dabney and
               Dan Horgan and
               Dhruva TB and
               Alistair Muldal and
               Nicolas Heess and
               Timothy P. Lillicrap},
  title     = {Distributed Distributional Deterministic Policy Gradients},
  journal   = {ICLR},
  year      = {2018},
}

@article{Nair:2015,
  title={Massively parallel methods for deep reinforcement learning},
  author={Nair, Arun and Srinivasan, Praveen and Blackwell, Sam and Alcicek, Cagdas and Fearon, Rory and De Maria, Alessandro and Panneershelvam, Vedavyas and Suleyman, Mustafa and Beattie, Charles and Petersen, Stig and  Legg, Shane and Mnih, Volodymyr and Kavukcuoglu, Koray and Silver,  David},
  journal   = {Arxiv},
  volume    = {abs/1507.04296},
  year={2015}
}

@inproceedings{    
Kapturowski:2019,    
title={Recurrent Experience Replay in Distributed Reinforcement Learning},    
author={Kapturowski, Steven and Ostrovski, Georg and Quan, John and Munos, Remi and Dabney, Will},
booktitle={ICLR},    
year={2019},
}

@article{Pascanu:2012,
  author    = {Razvan Pascanu and
               Tomas Mikolov and
               Yoshua Bengio},
  title     = {Understanding the exploding gradient problem},
  journal   = {Arxiv},
  volume    = {abs/1211.5063},
  year      = {2012}
}

@inproceedings{preco,
  author    = {Brandon Amos and
               Laurent Dinh and
               Serkan Cabi and
               Thomas Roth{\"{o}}rl and
               Sergio Gomez Colmenarejo and
               Alistair Muldal and
               Tom Erez and
               Yuval Tassa and
               Nando de Freitas and
               Misha Denil},
  title     = {Learning Awareness Models},
  booktitle   = {ICLR},
  year      = {2018},
}


@incollection{NIPS2017_6974,
title = {Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning},
author = {Gu, Shixiang (Shane) and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch\"{o}lkopf, Bernhard and Levine, Sergey},
booktitle = {NIPS},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
year = {2017},
}


@article{Lake2017BuildingMT,
  title={Building Machines That Learn and Think Like People},
  author={Brenden M. Lake and Tomer D. Ullman and Joshua B. Tenenbaum and Samuel J Gershman},
  journal={The Behavioral and brain sciences},
  year={2017},
  volume={40},
  pages={
          e253
        }
}


@inproceedings{Degris2012OffPolicyA,
  title={Off-Policy Actor-Critic},
  author={Thomas Degris and Martha White and Richard S. Sutton},
  booktitle={ICML},
  year={2012},
}
