\begin{thebibliography}{48}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdollahi(2020)]{abdollahi2020novel}
Abdollahi, H.
\newblock A novel hybrid model for forecasting crude oil price based on time
  series decomposition.
\newblock \emph{Applied energy}, 267:\penalty0 115035, 2020.

\bibitem[Acuna \& Rodriguez(2004)Acuna and Rodriguez]{acuna2004treatment}
Acuna, E. and Rodriguez, C.
\newblock The treatment of missing values and its effect on classifier
  accuracy.
\newblock In \emph{Classification, Clustering, and Data Mining Applications:
  Proceedings of the Meeting of the International Federation of Classification
  Societies (IFCS), Illinois Institute of Technology, Chicago, 15--18 July
  2004}, pp.\  639--647. Springer, 2004.

\bibitem[Alcaraz \& Strodthoff(2022)Alcaraz and
  Strodthoff]{alcaraz2022diffusion}
Alcaraz, J. M.~L. and Strodthoff, N.
\newblock Diffusion-based time series imputation and forecasting with
  structured state space models.
\newblock \emph{arXiv preprint arXiv:2208.09399}, 2022.

\bibitem[Bandara et~al.(2021)Bandara, Hyndman, and Bergmeir]{bandara2021mstl}
Bandara, K., Hyndman, R.~J., and Bergmeir, C.
\newblock Mstl: A seasonal-trend decomposition algorithm for time series with
  multiple seasonal patterns.
\newblock \emph{arXiv preprint arXiv:2107.13462}, 2021.

\bibitem[Benavoli \& Corani(2021)Benavoli and Corani]{benavoli2021state}
Benavoli, A. and Corani, G.
\newblock State space approximation of gaussian processes for time series
  forecasting.
\newblock In \emph{Advanced Analytics and Learning on Temporal Data: 6th ECML
  PKDD Workshop, AALTD 2021, Bilbao, Spain, September 13, 2021, Revised
  Selected Papers 6}, pp.\  21--35. Springer, 2021.

\bibitem[Bonilla et~al.(2008)Bonilla, Chai, and Williams]{Bonilla08multitask}
Bonilla, E., Chai, K.~M., and Williams, C.
\newblock Multi-task {G}aussian process prediction.
\newblock In \emph{Advances in Neural Information Processing Systems 20}. 2008.

\bibitem[Brakel et~al.(2013)Brakel, Stroobandt, and
  Schrauwen]{brakel2013training}
Brakel, P., Stroobandt, D., and Schrauwen, B.
\newblock Training energy-based models for time-series imputation.
\newblock \emph{The Journal of Machine Learning Research}, 14\penalty0
  (1):\penalty0 2771--2797, 2013.

\bibitem[Cao et~al.(2018)Cao, Wang, Li, Zhou, Li, and Li]{cao2018brits}
Cao, W., Wang, D., Li, J., Zhou, H., Li, L., and Li, Y.
\newblock Brits: Bidirectional recurrent imputation for time series.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Chen et~al.()Chen, Chen, and He]{chen10urban}
Chen, X., Chen, Y., and He, Z.
\newblock Urban traffic speed dataset of guangzhou, china, march 2018.
\newblock \emph{URL https://doi. org/10.5281/zenodo}, 1205229.

\bibitem[Chen et~al.(2023)Chen, Deng, Fang, Li, Yang, Zhang, Rasul, Zhe,
  Schneider, and Nevmyvaka]{chen2023provably}
Chen, Y., Deng, W., Fang, S., Li, F., Yang, N.~T., Zhang, Y., Rasul, K., Zhe,
  S., Schneider, A., and Nevmyvaka, Y.
\newblock Provably convergent schr$\backslash$" odinger bridge with
  applications to probabilistic time series imputation.
\newblock \emph{arXiv preprint arXiv:2305.07247}, 2023.

\bibitem[Cleveland et~al.(1990)Cleveland, Cleveland, McRae, and
  Terpenning]{cleveland1990stl}
Cleveland, R.~B., Cleveland, W.~S., McRae, J.~E., and Terpenning, I.
\newblock Stl: A seasonal-trend decomposition.
\newblock \emph{J. Off. Stat}, 6\penalty0 (1):\penalty0 3--73, 1990.

\bibitem[Du et~al.(2023)Du, C{\^o}t{\'e}, and Liu]{du2023saits}
Du, W., C{\^o}t{\'e}, D., and Liu, Y.
\newblock Saits: Self-attention-based imputation for time series.
\newblock \emph{Expert Systems with Applications}, 219:\penalty0 119619, 2023.

\bibitem[Durbin \& Koopman(2012)Durbin and Koopman]{durbin2012time}
Durbin, J. and Koopman, S.~J.
\newblock \emph{Time series analysis by state space methods}, volume~38.
\newblock OUP Oxford, 2012.

\bibitem[Fang \& Wang(2020)Fang and Wang]{fang2020time}
Fang, C. and Wang, C.
\newblock Time series data imputation: A survey on deep learning approaches.
\newblock \emph{arXiv preprint arXiv:2011.11347}, 2020.

\bibitem[Fang et~al.(2022)Fang, Narayan, Kirby, and Zhe]{fang2022bayesian}
Fang, S., Narayan, A., Kirby, R., and Zhe, S.
\newblock Bayesian continuous-time tucker decomposition.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  6235--6245. PMLR, 2022.

\bibitem[Fang et~al.(2024)Fang, Yu, Li, Wang, Kirby, and
  Zhe]{fang2024streaming}
Fang, S., Yu, X., Li, S., Wang, Z., Kirby, M., and Zhe, S.
\newblock Streaming factor trajectory learning for temporal tensor
  decomposition.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Fortuin et~al.(2020)Fortuin, Baranchuk, R{\"a}tsch, and
  Mandt]{fortuin2020gp}
Fortuin, V., Baranchuk, D., R{\"a}tsch, G., and Mandt, S.
\newblock Gp-vae: Deep probabilistic time series imputation.
\newblock In \emph{International conference on artificial intelligence and
  statistics}, pp.\  1651--1661. PMLR, 2020.

\bibitem[Hartikainen \& S{\"a}rkk{\"a}(2010)Hartikainen and
  S{\"a}rkk{\"a}]{hartikainen2010kalman}
Hartikainen, J. and S{\"a}rkk{\"a}, S.
\newblock Kalman filtering and smoothing solutions to temporal gaussian process
  regression models.
\newblock In \emph{2010 IEEE international workshop on machine learning for
  signal processing}, pp.\  379--384. IEEE, 2010.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 6840--6851, 2020.

\bibitem[Jin et~al.(2023)Jin, Koh, Wen, Zambon, Alippi, Webb, King, and
  Pan]{jin2023survey}
Jin, M., Koh, H.~Y., Wen, Q., Zambon, D., Alippi, C., Webb, G.~I., King, I.,
  and Pan, S.
\newblock A survey on graph neural networks for time series: Forecasting,
  classification, imputation, and anomaly detection.
\newblock \emph{arXiv preprint arXiv:2307.03759}, 2023.

\bibitem[Kalman(1960)]{kalman1960new}
Kalman, R.~E.
\newblock A new approach to linear filtering and prediction problems.
\newblock 1960.

\bibitem[Lancaster \& Rodman(1995)Lancaster and Rodman]{lancaster1995algebraic}
Lancaster, P. and Rodman, L.
\newblock \emph{Algebraic riccati equations}.
\newblock Clarendon press, 1995.

\bibitem[Li et~al.(2015)Li, Su, Zhang, Lin, and Li]{li2015trend}
Li, L., Su, X., Zhang, Y., Lin, Y., and Li, Z.
\newblock Trend modeling for traffic time series analysis: An integrated study.
\newblock \emph{IEEE Transactions on Intelligent Transportation Systems},
  16\penalty0 (6):\penalty0 3430--3439, 2015.

\bibitem[Liu et~al.(2023)Liu, Ma, Yang, Zhou, Xia, Wang, Wen, and
  Sun]{liu2023sadi}
Liu, H., Ma, Z., Yang, L., Zhou, T., Xia, R., Wang, Y., Wen, Q., and Sun, L.
\newblock Sadi: A self-adaptive decomposed interpretable framework for electric
  load forecasting under extreme events.
\newblock In \emph{ICASSP 2023-2023 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  1--5. IEEE, 2023.

\bibitem[LIU et~al.(2023)LIU, Li, Cong, Chen, and JIANG]{liu2023multivariate}
LIU, S., Li, X., Cong, G., Chen, Y., and JIANG, Y.
\newblock Multivariate time-series imputation with disentangled temporal
  representations.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem[Liu et~al.(2019)Liu, Yu, Zheng, Zhan, and Yue]{liu2019naomi}
Liu, Y., Yu, R., Zheng, S., Zhan, E., and Yue, Y.
\newblock Naomi: Non-autoregressive multiresolution sequence imputation.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Minka(2001{\natexlab{a}})]{minka2001expectation}
Minka, T.~P.
\newblock Expectation propagation for approximate bayesian inference.
\newblock In \emph{Proceedings of the Seventeenth conference on Uncertainty in
  artificial intelligence}, pp.\  362--369, 2001{\natexlab{a}}.

\bibitem[Minka(2001{\natexlab{b}})]{minka2001family}
Minka, T.~P.
\newblock \emph{A family of algorithms for approximate Bayesian inference}.
\newblock PhD thesis, Massachusetts Institute of Technology,
  2001{\natexlab{b}}.

\bibitem[Mulyadi et~al.(2021)Mulyadi, Jun, and Suk]{mulyadi2021uncertainty}
Mulyadi, A.~W., Jun, E., and Suk, H.-I.
\newblock Uncertainty-aware variational-recurrent imputation network for
  clinical time series.
\newblock \emph{IEEE Transactions on Cybernetics}, 52\penalty0 (9):\penalty0
  9684--9694, 2021.

\bibitem[Qiu et~al.(2018)Qiu, Jammalamadaka, and Ning]{qiu2018multivariate}
Qiu, J., Jammalamadaka, S.~R., and Ning, N.
\newblock Multivariate bayesian structural time series model.
\newblock \emph{J. Mach. Learn. Res.}, 19\penalty0 (1):\penalty0 2744--2776,
  2018.

\bibitem[Rasmussen \& Williams(2006)Rasmussen and Williams]{Rasmussen06GP}
Rasmussen, C.~E. and Williams, C. K.~I.
\newblock \emph{Gaussian Processes for Machine Learning}.
\newblock MIT Press, 2006.

\bibitem[Rasul et~al.(2021)Rasul, Seward, Schuster, and
  Vollgraf]{rasul2021autoregressive}
Rasul, K., Seward, C., Schuster, I., and Vollgraf, R.
\newblock Autoregressive denoising diffusion models for multivariate
  probabilistic time series forecasting.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  8857--8868. PMLR, 2021.

\bibitem[Rauch et~al.(1965)Rauch, Tung, and Striebel]{rauch1965maximum}
Rauch, H.~E., Tung, F., and Striebel, C.~T.
\newblock Maximum likelihood estimates of linear dynamic systems.
\newblock \emph{AIAA journal}, 3\penalty0 (8):\penalty0 1445--1450, 1965.

\bibitem[Roberts et~al.(2013)Roberts, Osborne, Ebden, Reece, Gibson, and
  Aigrain]{roberts2013gaussian}
Roberts, S., Osborne, M., Ebden, M., Reece, S., Gibson, N., and Aigrain, S.
\newblock Gaussian processes for time-series modelling, 2013.

\bibitem[S{\"a}rkk{\"a}(2013)]{sarkka2013bayesian}
S{\"a}rkk{\"a}, S.
\newblock \emph{Bayesian filtering and smoothing}.
\newblock Number~3. Cambridge University Press, 2013.

\bibitem[Solin \& S{\"a}rkk{\"a}(2014)Solin and
  S{\"a}rkk{\"a}]{solin2014explicit}
Solin, A. and S{\"a}rkk{\"a}, S.
\newblock Explicit link between periodic covariance functions and state space
  models.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  904--912.
  PMLR, 2014.

\bibitem[Solin et~al.(2016)]{solin2016stochastic}
Solin, A. et~al.
\newblock Stochastic differential equation methods for spatio-temporal gaussian
  process regression.
\newblock 2016.

\bibitem[Song et~al.(2020)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and
  Poole]{song2020score}
Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole,
  B.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock \emph{arXiv preprint arXiv:2011.13456}, 2020.

\bibitem[Tashiro et~al.(2021)Tashiro, Song, Song, and Ermon]{tashiro2021csdi}
Tashiro, Y., Song, J., Song, Y., and Ermon, S.
\newblock Csdi: Conditional score-based diffusion models for probabilistic time
  series imputation.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 24804--24816, 2021.

\bibitem[Van~Buuren \& Groothuis-Oudshoorn(2011)Van~Buuren and
  Groothuis-Oudshoorn]{van2011mice}
Van~Buuren, S. and Groothuis-Oudshoorn, K.
\newblock mice: Multivariate imputation by chained equations in r.
\newblock \emph{Journal of statistical software}, 45:\penalty0 1--67, 2011.

\bibitem[Wang \& Zhe(2019)Wang and Zhe]{wang2019conditional}
Wang, Z. and Zhe, S.
\newblock Conditional expectation propagation.
\newblock In \emph{UAI}, pp.\ ~6, 2019.

\bibitem[Wang et~al.(2024)Wang, Fang*, Li, and Zhe]{wang2024dynamic}
Wang, Z., Fang*, S., Li, S., and Zhe, S.
\newblock Dynamic tensor decomposition via neural diffusion-reaction processes.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Wen et~al.(2019)Wen, Gao, Song, Sun, Xu, and Zhu]{wen2019robuststl}
Wen, Q., Gao, J., Song, X., Sun, L., Xu, H., and Zhu, S.
\newblock Robuststl: A robust seasonal-trend decomposition algorithm for long
  time series.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pp.\  5409--5416, 2019.

\bibitem[Woo et~al.(2022)Woo, Liu, Sahoo, Kumar, and Hoi]{woo2022cost}
Woo, G., Liu, C., Sahoo, D., Kumar, A., and Hoi, S.
\newblock Cost: Contrastive learning of disentangled seasonal-trend
  representations for time series forecasting.
\newblock \emph{arXiv preprint arXiv:2202.01575}, 2022.

\bibitem[Yao et~al.(2021)Yao, Sun, Ho, Sun, and Zhang]{yao2021learning}
Yao, W., Sun, Y., Ho, A., Sun, C., and Zhang, K.
\newblock Learning temporally causal latent processes from general temporal
  data.
\newblock \emph{arXiv preprint arXiv:2110.05428}, 2021.

\bibitem[Yao et~al.(2022)Yao, Chen, and Zhang]{yao2022temporally}
Yao, W., Chen, G., and Zhang, K.
\newblock Temporally disentangled representation learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 26492--26503, 2022.

\bibitem[Yoon et~al.(2018)Yoon, Jordon, and Schaar]{yoon2018gain}
Yoon, J., Jordon, J., and Schaar, M.
\newblock Gain: Missing data imputation using generative adversarial nets.
\newblock In \emph{International conference on machine learning}, pp.\
  5689--5698. PMLR, 2018.

\bibitem[Zhu et~al.(2023)Zhu, Chen, Xia, Zhou, Niu, Peng, Wang, Liu, Ma, Wen,
  et~al.]{zhu2023eforecaster}
Zhu, Z., Chen, W., Xia, R., Zhou, T., Niu, P., Peng, B., Wang, W., Liu, H., Ma,
  Z., Wen, Q., et~al.
\newblock eforecaster: Unifying electricity forecasting with robust, flexible,
  and explainable machine learning algorithms.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~37, pp.\  15630--15638, 2023.

\end{thebibliography}
