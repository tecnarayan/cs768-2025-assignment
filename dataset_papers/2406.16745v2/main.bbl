\begin{thebibliography}{67}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi-Yadkori(2013)]{abbasi2013online}
Yasin Abbasi-Yadkori.
\newblock \emph{Online learning for linearly parametrized control problems}.
\newblock PhD thesis, University of Alberta, 2013.

\bibitem[Ailon et~al.(2014)Ailon, Karnin, and Joachims]{ailon2014reducing}
Nir Ailon, Zohar Karnin, and Thorsten Joachims.
\newblock Reducing dueling bandits to cardinal bandits.
\newblock In \emph{International Conference on Machine Learning}, pages 856--864. PMLR, 2014.

\bibitem[Aiolli and Sperduti(2004)]{aiolli2004learning}
Fabio Aiolli and Alessandro Sperduti.
\newblock Learning preferences for multiclass problems.
\newblock \emph{Advances in neural information processing systems}, 17, 2004.

\bibitem[Axler(2020)]{axler2020measure}
Sheldon Axler.
\newblock \emph{Measure, integration \& real analysis}.
\newblock Springer Nature, 2020.

\bibitem[Bengs et~al.(2021)Bengs, Busa-Fekete, El~Mesaoudi-Paul, and H{\"u}llermeier]{bengs2021preference}
Viktor Bengs, R{\'o}bert Busa-Fekete, Adil El~Mesaoudi-Paul, and Eyke H{\"u}llermeier.
\newblock Preference-based online learning with dueling bandits: A survey.
\newblock \emph{The Journal of Machine Learning Research}, 2021.

\bibitem[Beygelzimer et~al.(2019)Beygelzimer, Pal, Szorenyi, Thiruvenkatachari, Wei, and Zhang]{beygelzimer2019bandit}
Alina Beygelzimer, David Pal, Balazs Szorenyi, Devanathan Thiruvenkatachari, Chen-Yu Wei, and Chicheng Zhang.
\newblock Bandit multiclass linear classification: Efficient algorithms for the separable case.
\newblock In \emph{International Conference on Machine Learning}, pages 624--633. PMLR, 2019.

\bibitem[Bradbury et~al.(2018)Bradbury, Frostig, Hawkins, Johnson, Leary, Maclaurin, Necula, Paszke, VanderPlas, Wanderman-Milne, et~al.]{jax2018github}
James Bradbury, Roy Frostig, Peter Hawkins, Matthew~James Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, et~al.
\newblock {JAX}: composable transformations of {P}ython+ {N}um{P}y programs, 2018.
\newblock URL \url{http://github.com/google/jax}.

\bibitem[Bradley and Terry(1952)]{bradley1952rank}
Ralph~Allan Bradley and Milton~E Terry.
\newblock Rank analysis of incomplete block designs: I. the method of paired comparisons.
\newblock \emph{Biometrika}, 1952.

\bibitem[Brochu et~al.(2010)Brochu, Cora, and De~Freitas]{brochu2010tutorial}
Eric Brochu, Vlad~M Cora, and Nando De~Freitas.
\newblock A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning.
\newblock \emph{arXiv preprint}, 2010.

\bibitem[Camacho-Vallejo et~al.(2023)Camacho-Vallejo, Corpus, and Villegas]{camacho2023metaheuristics}
Jos{\'e}-Fernando Camacho-Vallejo, Carlos Corpus, and Juan~G Villegas.
\newblock Metaheuristics for bilevel optimization: A comprehensive review.
\newblock \emph{Computers \& Operations Research}, page 106410, 2023.

\bibitem[Casper et~al.(2023)Casper, Davies, Shi, Gilbert, Scheurer, Rando, Freedman, Korbak, Lindner, Freire, et~al.]{casper2023open}
Stephen Casper, Xander Davies, Claudia Shi, Thomas~Krendl Gilbert, J{\'e}r{\'e}my Scheurer, Javier Rando, Rachel Freedman, Tomasz Korbak, David Lindner, Pedro Freire, et~al.
\newblock Open problems and fundamental limitations of reinforcement learning from human feedback.
\newblock \emph{Transactions on Machine Learning Research}, 2023.

\bibitem[Chen and Frazier(2017)]{chen2017dueling}
Bangrui Chen and Peter~I Frazier.
\newblock Dueling bandits with weak regret.
\newblock In \emph{International Conference on Machine Learning}, pages 731--739. PMLR, 2017.

\bibitem[Chowdhury and Gopalan(2017)]{chowdhury2017kernelized}
Sayak~Ray Chowdhury and Aditya Gopalan.
\newblock On kernelized multi-armed bandits.
\newblock In \emph{International Conference on Machine Learning}, pages 844--853. PMLR, 2017.

\bibitem[Christiano et~al.(2017)Christiano, Leike, Brown, Martic, Legg, and Amodei]{christiano2017deep}
Paul~F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and Dario Amodei.
\newblock Deep reinforcement learning from human preferences.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Chu and Ghahramani(2005)]{chu2005preference}
Wei Chu and Zoubin Ghahramani.
\newblock Preference learning with gaussian processes.
\newblock In \emph{Proceedings of the 22nd international conference on Machine learning}, pages 137--144, 2005.

\bibitem[Dagr{\'e}ou et~al.(2022)Dagr{\'e}ou, Ablin, Vaiter, and Moreau]{dagreou2022framework}
Mathieu Dagr{\'e}ou, Pierre Ablin, Samuel Vaiter, and Thomas Moreau.
\newblock A framework for bilevel optimization that enables stochastic and global variance reduction algorithms.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 26698--26710, 2022.

\bibitem[Dud{\'\i}k et~al.(2015)Dud{\'\i}k, Hofmann, Schapire, Slivkins, and Zoghi]{dudik2015contextual}
Miroslav Dud{\'\i}k, Katja Hofmann, Robert~E Schapire, Aleksandrs Slivkins, and Masrour Zoghi.
\newblock Contextual dueling bandits.
\newblock In \emph{Conference on Learning Theory}, pages 563--587. PMLR, 2015.

\bibitem[Falahatgar et~al.(2017)Falahatgar, Orlitsky, Pichapati, and Suresh]{falahatgar2017maximum}
Moein Falahatgar, Alon Orlitsky, Venkatadheeraj Pichapati, and Ananda~Theertha Suresh.
\newblock Maximum selection and ranking under noisy comparisons.
\newblock In \emph{International Conference on Machine Learning}, pages 1088--1096. PMLR, 2017.

\bibitem[Faury et~al.(2020)Faury, Abeille, Calauz{\`e}nes, and Fercoq]{faury2020improved}
Louis Faury, Marc Abeille, Cl{\'e}ment Calauz{\`e}nes, and Olivier Fercoq.
\newblock Improved optimistic algorithms for logistic bandits.
\newblock In \emph{International Conference on Machine Learning}, pages 3052--3060. PMLR, 2020.

\bibitem[Faury et~al.(2022)Faury, Abeille, Jun, and Calauz{\`e}nes]{faury2022jointly}
Louis Faury, Marc Abeille, Kwang-Sung Jun, and Cl{\'e}ment Calauz{\`e}nes.
\newblock Jointly efficient and optimal algorithms for logistic bandits.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 546--580. PMLR, 2022.

\bibitem[Filippi et~al.(2010)Filippi, Cappe, Garivier, and Szepesv{\'a}ri]{filippi2010parametric}
Sarah Filippi, Olivier Cappe, Aur{\'e}lien Garivier, and Csaba Szepesv{\'a}ri.
\newblock Parametric bandits: The generalized linear case.
\newblock \emph{Advances in neural information processing systems}, 2010.

\bibitem[Foster and Krishnamurthy(2018)]{foster2018contextual}
Dylan~J Foster and Akshay Krishnamurthy.
\newblock Contextual bandits with surrogate losses: Margin bounds and efficient algorithms.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Ghadimi and Wang(2018)]{ghadimi2018approximation}
Saeed Ghadimi and Mengdi Wang.
\newblock Approximation methods for bilevel programming.
\newblock \emph{arXiv preprint arXiv:1802.02246}, 2018.

\bibitem[Gonz{\'a}lez et~al.(2017)Gonz{\'a}lez, Dai, Damianou, and Lawrence]{gonzalez2017preferential}
Javier Gonz{\'a}lez, Zhenwen Dai, Andreas Damianou, and Neil~D Lawrence.
\newblock Preferential bayesian optimization.
\newblock In \emph{International Conference on Machine Learning}, pages 1282--1291. PMLR, 2017.

\bibitem[Houlsby et~al.(2011)Houlsby, Husz{\'a}r, Ghahramani, and Lengyel]{houlsby2011bayesian}
Neil Houlsby, Ferenc Husz{\'a}r, Zoubin Ghahramani, and M{\'a}t{\'e} Lengyel.
\newblock Bayesian active learning for classification and preference learning.
\newblock \emph{arXiv preprint arXiv:1112.5745}, 2011.

\bibitem[Jamieson and Nowak(2011)]{jamieson2011active}
Kevin~G Jamieson and Robert Nowak.
\newblock Active ranking using pairwise comparisons.
\newblock \emph{Advances in neural information processing systems}, 24, 2011.

\bibitem[Jamil and Yang(2013)]{jamil2013literature}
Momin Jamil and Xin-She Yang.
\newblock A literature survey of benchmark functions for global optimisation problems.
\newblock \emph{International Journal of Mathematical Modelling and Numerical Optimisation}, 4\penalty0 (2):\penalty0 150--194, 2013.

\bibitem[Jeroslow(1985)]{jeroslow1985polynomial}
Robert~G Jeroslow.
\newblock The polynomial hierarchy and a simple model for competitive analysis.
\newblock \emph{Mathematical programming}, 32\penalty0 (2):\penalty0 146--164, 1985.

\bibitem[Ji et~al.(2023)Ji, Wang, Chen, Zhao, and Wang]{ji2023provable}
Xiang Ji, Huazheng Wang, Minshuo Chen, Tuo Zhao, and Mengdi Wang.
\newblock Provable benefits of policy learning from human preferences in contextual bandit problems.
\newblock \emph{arXiv preprint arXiv:2307.12975}, 2023.

\bibitem[Kirschner and Krause(2021)]{kirschner2021bias}
Johannes Kirschner and Andreas Krause.
\newblock Bias-robust bayesian optimization via dueling bandits.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2021.

\bibitem[Kirschner et~al.(2020)Kirschner, Lattimore, and Krause]{kirschner2020information}
Johannes Kirschner, Tor Lattimore, and Andreas Krause.
\newblock Information directed sampling for linear partial monitoring.
\newblock In \emph{Conference on Learning Theory}, pages 2328--2369. PMLR, 2020.

\bibitem[Komiyama et~al.(2015)Komiyama, Honda, and Nakagawa]{komiyama2015optimal}
Junpei Komiyama, Junya Honda, and Hiroshi Nakagawa.
\newblock Optimal regret analysis of thompson sampling in stochastic multi-armed bandit problem with multiple plays.
\newblock In \emph{International Conference on Machine Learning}, pages 1152--1161. PMLR, 2015.

\bibitem[Kumagai(2017)]{kumagai2017regret}
Wataru Kumagai.
\newblock Regret analysis for continuous dueling bandit.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Lattimore and Szepesv{\'a}ri(2020)]{lattimore2020bandit}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock \emph{Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem[Lax(2002)]{lax2002functional}
Peter~D Lax.
\newblock \emph{Functional analysis}, volume~55.
\newblock John Wiley \& Sons, 2002.

\bibitem[Lee et~al.(2024)Lee, Yun, and Jun]{lee2024improved}
Junghyun Lee, Se-Young Yun, and Kwang-Sung Jun.
\newblock Improved regret bounds of (multinomial) logistic bandits via regret-to-confidence-set conversion.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 4474--4482. PMLR, 2024.

\bibitem[Mehta et~al.(2023{\natexlab{a}})Mehta, Das, Neopane, Dai, Bogunovic, Schneider, and Neiswanger]{mehta2023sample}
Viraj Mehta, Vikramjeet Das, Ojash Neopane, Yijia Dai, Ilija Bogunovic, Jeff Schneider, and Willie Neiswanger.
\newblock Sample efficient reinforcement learning from human feedback via active exploration.
\newblock \emph{arXiv preprint}, 2023{\natexlab{a}}.

\bibitem[Mehta et~al.(2023{\natexlab{b}})Mehta, Neopane, Das, Lin, Schneider, and Neiswanger]{mehta2023kernelized}
Viraj Mehta, Ojash Neopane, Vikramjeet Das, Sen Lin, Jeff Schneider, and Willie Neiswanger.
\newblock Kernelized offline contextual dueling bandits.
\newblock \emph{arXiv preprint}, 2023{\natexlab{b}}.

\bibitem[Mikkola et~al.(2020)Mikkola, Todorovi{\'c}, J{\"a}rvi, Rinke, and Kaski]{mikkola2020projective}
Petrus Mikkola, Milica Todorovi{\'c}, Jari J{\"a}rvi, Patrick Rinke, and Samuel Kaski.
\newblock Projective preferential bayesian optimization.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2020.

\bibitem[Munos et~al.(2023)Munos, Valko, Calandriello, Azar, Rowland, Guo, Tang, Geist, Mesnard, Michi, et~al.]{munos2023nash}
R{\'e}mi Munos, Michal Valko, Daniele Calandriello, Mohammad~Gheshlaghi Azar, Mark Rowland, Zhaohan~Daniel Guo, Yunhao Tang, Matthieu Geist, Thomas Mesnard, Andrea Michi, et~al.
\newblock Nash learning from human feedback.
\newblock \emph{arXiv preprint}, 2023.

\bibitem[Nguyen et~al.(2024)Nguyen, Zhang, Yang, Lee, Bornschein, Miao, Perel, Chen, and Song]{nguyen2024predicting}
Tung Nguyen, Qiuyi Zhang, Bangding Yang, Chansoo Lee, Jorg Bornschein, Yingjie Miao, Sagi Perel, Yutian Chen, and Xingyou Song.
\newblock Predicting from strings: Language model embeddings for bayesian optimization.
\newblock \emph{arXiv preprint}, 2024.

\bibitem[Saha(2021)]{saha2021optimal}
Aadirupa Saha.
\newblock Optimal algorithms for stochastic contextual preference bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 30050--30062, 2021.

\bibitem[Saha and Krishnamurthy(2022)]{saha2022efficient}
Aadirupa Saha and Akshay Krishnamurthy.
\newblock Efficient and optimal algorithms for contextual dueling bandits under realizability.
\newblock In \emph{International Conference on Algorithmic Learning Theory}. PMLR, 2022.

\bibitem[Saha et~al.(2023)Saha, Pacchiano, and Lee]{pacchiano2021dueling}
Aadirupa Saha, Aldo Pacchiano, and Jonathan Lee.
\newblock Dueling rl: Reinforcement learning with trajectory preferences.
\newblock In \emph{Proceedings of The 26th International Conference on Artificial Intelligence and Statistics}. PMLR, 2023.

\bibitem[Schafer et~al.(2007)Schafer, Frankowski, Herlocker, and Sen]{schafer2007collaborative}
J~Ben Schafer, Dan Frankowski, Jon Herlocker, and Shilad Sen.
\newblock Collaborative filtering recommender systems.
\newblock In \emph{The adaptive web: methods and strategies of web personalization}, pages 291--324. Springer, 2007.

\bibitem[Sch{\"o}lkopf et~al.(2001)Sch{\"o}lkopf, Herbrich, and Smola]{scholkopf2001generalized}
Bernhard Sch{\"o}lkopf, Ralf Herbrich, and Alex~J Smola.
\newblock A generalized representer theorem.
\newblock In \emph{International conference on computational learning theory}, pages 416--426. Springer, 2001.

\bibitem[Sinha et~al.(2017)Sinha, Malo, and Deb]{sinha2017review}
Ankur Sinha, Pekka Malo, and Kalyanmoy Deb.
\newblock A review on bilevel optimization: From classical to evolutionary approaches and applications.
\newblock \emph{IEEE transactions on evolutionary computation}, 22\penalty0 (2):\penalty0 276--295, 2017.

\bibitem[Srinivas et~al.(2010)Srinivas, Krause, Kakade, and Seeger]{srinivas2009gaussian}
Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger.
\newblock Gaussian process optimization in the bandit setting: No regret and experimental design.
\newblock In \emph{Proceedings of the 27th International Conference on International Conference on Machine Learning}, 2010.

\bibitem[Stackelberg(1952)]{stackelberg1952theory}
Heinrich~von Stackelberg.
\newblock \emph{Theory of the market economy}.
\newblock Oxford University Press, 1952.

\bibitem[Sui et~al.(2017)Sui, Zhuang, Burdick, and Yue]{sui2017multi}
Yanan Sui, Vincent Zhuang, Joel~W Burdick, and Yisong Yue.
\newblock Multi-dueling bandits with dependent arms.
\newblock \emph{arXiv preprint arXiv:1705.00253}, 2017.

\bibitem[Takeno et~al.(2023)Takeno, Nomura, and Karasuyama]{takeno2023towards}
Shion Takeno, Masahiro Nomura, and Masayuki Karasuyama.
\newblock Towards practical preferential bayesian optimization with skew gaussian processes.
\newblock In \emph{International Conference on Machine Learning}, pages 33516--33533. PMLR, 2023.

\bibitem[Tucker et~al.(2020)Tucker, Novoseller, Kann, Sui, Yue, Burdick, and Ames]{tucker2020preference}
Maegan Tucker, Ellen Novoseller, Claudia Kann, Yanan Sui, Yisong Yue, Joel~W Burdick, and Aaron~D Ames.
\newblock Preference-based learning for exoskeleton gait optimization.
\newblock In \emph{2020 IEEE international conference on robotics and automation (ICRA)}. IEEE, 2020.

\bibitem[Urvoy et~al.(2013)Urvoy, Clerot, F{\'e}raud, and Naamane]{urvoy2013generic}
Tanguy Urvoy, Fabrice Clerot, Raphael F{\'e}raud, and Sami Naamane.
\newblock Generic exploration and k-armed voting bandits.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2013.

\bibitem[Vakili et~al.(2021)Vakili, Khezeli, and Picheny]{vakili2021information}
Sattar Vakili, Kia Khezeli, and Victor Picheny.
\newblock On information gain and regret bounds in gaussian process bandits.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 82--90. PMLR, 2021.

\bibitem[Valko et~al.(2013)Valko, Korda, Munos, Flaounas, and Cristianini]{valko2013finite}
Michal Valko, Nathaniel Korda, R{\'e}mi Munos, Ilias Flaounas, and Nelo Cristianini.
\newblock Finite-time analysis of kernelised contextual bandits.
\newblock \emph{arXiv preprint arXiv:1309.6869}, 2013.

\bibitem[Wainwright(2019)]{wainwright2019high}
Martin~J Wainwright.
\newblock \emph{High-dimensional statistics: A non-asymptotic viewpoint}, volume~48.
\newblock Cambridge university press, 2019.

\bibitem[Whitehouse et~al.(2023)Whitehouse, Wu, and Ramdas]{whitehouse2023improved}
Justin Whitehouse, Zhiwei~Steven Wu, and Aaditya Ramdas.
\newblock Improved self-normalized concentration in hilbert spaces: Sublinear regret for gp-ucb.
\newblock \emph{arXiv preprint arXiv:2307.07539}, 2023.

\bibitem[Wu and Liu(2016)]{wu2016double}
Huasen Wu and Xin Liu.
\newblock Double thompson sampling for dueling bandits.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Xu et~al.(2024)Xu, Wang, Jiang, Svetozarevic, and Jones]{xu2024principled}
Wenjie Xu, Wenbin Wang, Yuning Jiang, Bratislav Svetozarevic, and Colin~N Jones.
\newblock Principled preferential bayesian optimization.
\newblock \emph{arXiv preprint arXiv:2402.05367}, 2024.

\bibitem[Xu et~al.(2020)Xu, Joshi, Singh, and Dubrawski]{xu2020zeroth}
Yichong Xu, Aparna Joshi, Aarti Singh, and Artur Dubrawski.
\newblock Zeroth order non-convex optimization with dueling-choice bandits.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}. PMLR, 2020.

\bibitem[Yue and Joachims(2009)]{yue2009interactively}
Yisong Yue and Thorsten Joachims.
\newblock Interactively optimizing information retrieval systems as a dueling bandits problem.
\newblock In \emph{Proceedings of the 26th Annual International Conference on Machine Learning}, 2009.

\bibitem[Yue et~al.(2012)Yue, Broder, Kleinberg, and Joachims]{yue2012k}
Yisong Yue, Josef Broder, Robert Kleinberg, and Thorsten Joachims.
\newblock The k-armed dueling bandits problem.
\newblock \emph{Journal of Computer and System Sciences}, 2012.

\bibitem[Zhan et~al.(2023)Zhan, Uehara, Kallus, Lee, and Sun]{zhan2023provable}
Wenhao Zhan, Masatoshi Uehara, Nathan Kallus, Jason~D Lee, and Wen Sun.
\newblock Provable offline reinforcement learning with human feedback.
\newblock \emph{arXiv preprint}, 2023.

\bibitem[Zhu et~al.(2023)Zhu, Jordan, and Jiao]{zhu2024principled}
Banghua Zhu, Michael Jordan, and Jiantao Jiao.
\newblock Principled reinforcement learning with human feedback from pairwise or k-wise comparisons.
\newblock In \emph{International Conference on Machine Learning}, pages 43037--43067. PMLR, 2023.

\bibitem[Zimmert and Seldin(2018)]{zimmert2018factored}
Julian Zimmert and Yevgeny Seldin.
\newblock Factored bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Zoghi et~al.(2014{\natexlab{a}})Zoghi, Whiteson, Munos, and Rijke]{zoghi2014relative}
Masrour Zoghi, Shimon Whiteson, Remi Munos, and Maarten Rijke.
\newblock Relative upper confidence bound for the k-armed dueling bandit problem.
\newblock In \emph{International conference on machine learning}. PMLR, 2014{\natexlab{a}}.

\bibitem[Zoghi et~al.(2014{\natexlab{b}})Zoghi, Whiteson, De~Rijke, and Munos]{zoghi2014relative2}
Masrour Zoghi, Shimon~A Whiteson, Maarten De~Rijke, and Remi Munos.
\newblock Relative confidence sampling for efficient on-line ranker evaluation.
\newblock In \emph{Proceedings of the 7th ACM international conference on Web search and data mining}, 2014{\natexlab{b}}.

\end{thebibliography}
