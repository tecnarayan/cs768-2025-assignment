\begin{thebibliography}{31}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alaoui and Mahoney(2015)]{alaoui2015fast}
Ahmed~El Alaoui and Michael~W. Mahoney.
\newblock Fast randomized kernel methods with statistical guarantees, 2015.

\bibitem[Allen-Zhu et~al.(2017)Allen-Zhu, Li, Singh, and Wang]{allen2017near}
Zeyuan Allen-Zhu, Yuanzhi Li, Aarti Singh, and Yining Wang.
\newblock Near-optimal design of experiments via regret minimization.
\newblock In \emph{International Conference on Machine Learning}, pages
  126--135. PMLR, 2017.

\bibitem[Atkinson et~al.(2007)Atkinson, Donev, and Tobias]{atkinson2007optimum}
Anthony Atkinson, Alexander Donev, and Randall Tobias.
\newblock \emph{Optimum experimental designs, with SAS}, volume~34.
\newblock Oxford University Press, 2007.

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, and Fischer]{auer2002finite}
Peter Auer, Nicol√≤ Cesa-Bianchi, and Paul Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock \emph{Machine Learning}, 47:\penalty0 235--256, 05 2002.
\newblock \doi{10.1023/A:1013689704352}.

\bibitem[Bach(2015)]{bach2015equivalence}
Francis Bach.
\newblock On the equivalence between kernel quadrature rules and random feature
  expansions, 2015.

\bibitem[Bogunovic et~al.(2020)Bogunovic, Krause, and
  Scarlett]{bogunovic2020corruptiontolerant}
Ilija Bogunovic, Andreas Krause, and Jonathan Scarlett.
\newblock Corruption-tolerant gaussian process bandit optimization, 2020.

\bibitem[Chaloner and Verdinelli(1995)]{chaloner1995bayesian}
Kathryn Chaloner and Isabella Verdinelli.
\newblock Bayesian experimental design: A review.
\newblock \emph{Statistical Science}, pages 273--304, 1995.

\bibitem[Chowdhury and Gopalan(2017)]{chowdhury2017kernelized}
Sayak~Ray Chowdhury and Aditya Gopalan.
\newblock On kernelized multi-armed bandits, 2017.

\bibitem[Degenne et~al.(2020)Degenne, M{\'e}nard, Shang, and
  Valko]{degenne2020gamification}
R{\'e}my Degenne, Pierre M{\'e}nard, Xuedong Shang, and Michal Valko.
\newblock Gamification of pure exploration for linear bandits.
\newblock In \emph{International Conference on Machine Learning}, pages
  2432--2442. PMLR, 2020.

\bibitem[Derezinski et~al.(2020)Derezinski, Liang, and
  Mahoney]{derezinski2020bayesian}
Michal Derezinski, Feynman Liang, and Michael Mahoney.
\newblock Bayesian experimental design using regularized determinantal point
  processes.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 3197--3207. PMLR, 2020.

\bibitem[Desautels et~al.(2012)Desautels, Krause, and
  Burdick]{desautels2012parallelizing}
Thomas Desautels, Andreas Krause, and Joel Burdick.
\newblock Parallelizing exploration-exploitation tradeoffs with gaussian
  process bandit optimization, 2012.

\bibitem[Fiez et~al.(2019)Fiez, Jain, Jamieson, and Ratliff]{fiez2019}
Tanner Fiez, Lalit Jain, Kevin Jamieson, and Lillian Ratliff.
\newblock Sequential experimental design for transductive linear bandits.
\newblock \emph{NeurIPS}, 2019.

\bibitem[Frazier(2018)]{frazier2018tutorial}
Peter~I Frazier.
\newblock A tutorial on bayesian optimization.
\newblock \emph{arXiv preprint arXiv:1807.02811}, 2018.

\bibitem[Gr{\"u}new{\"a}lder et~al.(2010)Gr{\"u}new{\"a}lder, Audibert, Opper,
  and Shawe-Taylor]{grunewalder2010regret}
Steffen Gr{\"u}new{\"a}lder, Jean-Yves Audibert, Manfred Opper, and John
  Shawe-Taylor.
\newblock Regret bounds for gaussian process bandit problems.
\newblock In \emph{Proceedings of the Thirteenth International Conference on
  Artificial Intelligence and Statistics}, pages 273--280. JMLR Workshop and
  Conference Proceedings, 2010.

\bibitem[Gupta et~al.(2019)Gupta, Koren, and Talwar]{gupta2019better}
Anupam Gupta, Tomer Koren, and Kunal Talwar.
\newblock Better algorithms for stochastic bandits with adversarial
  corruptions.
\newblock In \emph{Conference on Learning Theory}, pages 1562--1578. PMLR,
  2019.

\bibitem[Katz-Samuels et~al.(2020)Katz-Samuels, Jain, Jamieson,
  et~al.]{katz2020empirical}
Julian Katz-Samuels, Lalit Jain, Kevin~G Jamieson, et~al.
\newblock An empirical process approach to the union bound: Practical
  algorithms for combinatorial and linear bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Lattimore and Szepesv{\'a}ri(2020)]{lattimore2020bandit}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock \emph{Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem[Lattimore et~al.(2020)Lattimore, Szepesvari, and
  Weisz]{lattimore2020learning}
Tor Lattimore, Csaba Szepesvari, and Gellert Weisz.
\newblock Learning with good feature representations in bandits and in rl with
  a generative model, 2020.

\bibitem[Lee et~al.(2021)Lee, Luo, Wei, Zhang, and Zhang]{lee2021achieving}
Chung-Wei Lee, Haipeng Luo, Chen-Yu Wei, Mengxiao Zhang, and Xiaojin Zhang.
\newblock Achieving near instance-optimality and minimax-optimality in
  stochastic and adversarial linear bandits simultaneously, 2021.

\bibitem[Lugosi and Mendelson(2019)]{lugosi2019mean}
G{\'a}bor Lugosi and Shahar Mendelson.
\newblock Mean estimation and regression under heavy-tailed distributions: A
  survey.
\newblock \emph{Foundations of Computational Mathematics}, 19\penalty0
  (5):\penalty0 1145--1190, 2019.

\bibitem[Nikolov et~al.(2019)Nikolov, Singh, and
  Tantipongpipat]{nikolov2019proportional}
Aleksandar Nikolov, Mohit Singh, and Uthaipon~Tao Tantipongpipat.
\newblock Proportional volume sampling and approximation algorithms for
  a-optimal design.
\newblock In \emph{Proceedings of the Thirtieth Annual ACM-SIAM Symposium on
  Discrete Algorithms}, pages 1369--1386. SIAM, 2019.

\bibitem[Pukelsheim(2006)]{pukelsheim2006optimal}
Friedrich Pukelsheim.
\newblock \emph{Optimal design of experiments}.
\newblock SIAM, 2006.

\bibitem[Rizk et~al.(2020)Rizk, Colin, Thomas, and Draief]{rizk2020refined}
Geovani Rizk, Igor Colin, Albert Thomas, and Moez Draief.
\newblock Refined bounds for randomized experimental design.
\newblock \emph{arXiv preprint arXiv:2012.15726}, 2020.

\bibitem[Soare et~al.(2014)Soare, Lazaric, and Munos]{soare2014best}
Marta Soare, Alessandro Lazaric, and R{\'e}mi Munos.
\newblock Best-arm identification in linear bandits.
\newblock \emph{arXiv preprint arXiv:1409.6110}, 2014.

\bibitem[Srinivas et~al.(2009)Srinivas, Krause, Kakade, and
  Seeger]{srinivas2009gaussian}
Niranjan Srinivas, Andreas Krause, Sham~M Kakade, and Matthias Seeger.
\newblock Gaussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock \emph{arXiv preprint arXiv:0912.3995}, 2009.

\bibitem[Tao et~al.(2018)Tao, Blanco, and Zhou]{tao2018best}
Chao Tao, Sa{\'u}l Blanco, and Yuan Zhou.
\newblock Best arm identification in linear bandits with linear dimension
  dependency.
\newblock In \emph{International Conference on Machine Learning}, pages
  4877--4886, 2018.

\bibitem[Tirinzoni et~al.(2020)Tirinzoni, Pirotta, Restelli, and
  Lazaric]{tirinzoni2020asymptotically}
Andrea Tirinzoni, Matteo Pirotta, Marcello Restelli, and Alessandro Lazaric.
\newblock An asymptotically optimal primal-dual incremental algorithm for
  contextual linear bandits.
\newblock \emph{arXiv preprint arXiv:2010.12247}, 2020.

\bibitem[Todd(2016)]{todd2016minimum}
Michael~J Todd.
\newblock \emph{Minimum-volume ellipsoids: Theory and algorithms}.
\newblock SIAM, 2016.

\bibitem[Valko et~al.(2013)Valko, Korda, Munos, Flaounas, and
  Cristianini]{valko2013finitetime}
Michal Valko, Nathaniel Korda, Remi Munos, Ilias Flaounas, and Nelo
  Cristianini.
\newblock Finite-time analysis of kernelised contextual bandits, 2013.

\bibitem[Wagenmaker et~al.(2021)Wagenmaker, Katz-Samuels, and
  Jamieson]{wagenmaker2021experimental}
Andrew Wagenmaker, Julian Katz-Samuels, and Kevin Jamieson.
\newblock Experimental design for regret minimization in linear bandits.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 3088--3096. PMLR, 2021.

\bibitem[Wu and Frazier(2018)]{wu2018parallel}
Jian Wu and Peter~I. Frazier.
\newblock The parallel knowledge gradient method for batch bayesian
  optimization, 2018.

\end{thebibliography}
