\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye2018obfuscated}
Anish Athalye, Nicholas Carlini, and David Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock \emph{arXiv preprint arXiv:1802.00420}, 2018.

\bibitem[Aydemir et~al.(2018)Aydemir, Temizel, and Temizel]{aydemir2018effects}
Ayse~Elvan Aydemir, Alptekin Temizel, and Tugba~Taskaya Temizel.
\newblock The effects of jpeg and jpeg2000 compression on attacks using
  adversarial examples.
\newblock \emph{arXiv preprint arXiv:1803.10418}, 2018.

\bibitem[Azulay \& Weiss(2018)Azulay and Weiss]{azulay2018deep}
Aharon Azulay and Yair Weiss.
\newblock Why do deep convolutional networks generalize so poorly to small
  image transformations?
\newblock \emph{arXiv preprint arXiv:1805.12177}, 2018.

\bibitem[Biggio \& Roli(2018)Biggio and Roli]{biggio2018wild}
Battista Biggio and Fabio Roli.
\newblock Wild patterns: Ten years after the rise of adversarial machine
  learning.
\newblock \emph{Pattern Recognition}, 84:\penalty0 317--331, 2018.

\bibitem[Borell(1975)]{borell1975brunn}
Christer Borell.
\newblock The {B}runn-{M}inkowski inequality in {G}auss space.
\newblock \emph{Inventiones mathematicae}, 30\penalty0 (2):\penalty0 207--216,
  1975.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{carlini2017adversarial}
Nicholas Carlini and David Wagner.
\newblock Adversarial examples are not easily detected: Bypassing ten detection
  methods.
\newblock \emph{arXiv preprint arXiv:1705.07263}, 2017.

\bibitem[Cubuk et~al.(2018)Cubuk, Zoph, Mane, Vasudevan, and
  Le]{cubuk2018autoaugment}
Ekin~D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc~V Le.
\newblock Autoaugment: Learning augmentation policies from data.
\newblock \emph{arXiv preprint arXiv:1805.09501}, 2018.

\bibitem[Dalvi et~al.(2004)Dalvi, Domingos, Sanghai, Verma,
  et~al.]{dalvi2004adversarial}
Nilesh Dalvi, Pedro Domingos, Sumit Sanghai, Deepak Verma, et~al.
\newblock Adversarial classification.
\newblock In \emph{Proceedings of the tenth ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pp.\  99--108. ACM, 2004.

\bibitem[Das et~al.(2017)Das, Shanbhogue, Chen, Hohman, Chen, Kounavis, and
  Chau]{das2017keeping}
Nilaksh Das, Madhuri Shanbhogue, Shang-Tse Chen, Fred Hohman, Li~Chen,
  Michael~E Kounavis, and Duen~Horng Chau.
\newblock Keeping the bad guys out: Protecting and vaccinating deep learning
  with jpeg compression.
\newblock \emph{arXiv preprint arXiv:1705.02900}, 2017.

\bibitem[Das et~al.(2018)Das, Shanbhogue, Chen, Hohman, Li, Chen, Kounavis, and
  Chau]{das2018shield}
Nilaksh Das, Madhuri Shanbhogue, Shang-Tse Chen, Fred Hohman, Siwei Li,
  Li~Chen, Michael~E Kounavis, and Duen~Horng Chau.
\newblock Shield: Fast, practical defense and vaccination for deep learning
  using jpeg compression.
\newblock \emph{arXiv preprint arXiv:1802.06816}, 2018.

\bibitem[Dodge \& Karam(2017)Dodge and Karam]{dodge2017study}
Samuel Dodge and Lina Karam.
\newblock A study and comparison of human and deep learning recognition
  performance under visual distortions.
\newblock In \emph{Computer Communication and Networks (ICCCN), 2017 26th
  International Conference on}, pp.\  1--7. IEEE, 2017.

\bibitem[Dohmatob(2018)]{dohmatob2018limitations}
Elvis Dohmatob.
\newblock Limitations of adversarial robustness: strong no free lunch theorem.
\newblock \emph{arXiv preprint arXiv:1810.04065}, 2018.

\bibitem[Dziugaite et~al.(2016)Dziugaite, Ghahramani, and
  Roy]{dziugaite2016study}
Gintare~Karolina Dziugaite, Zoubin Ghahramani, and Daniel~M Roy.
\newblock A study of the effect of jpg compression on adversarial images.
\newblock \emph{arXiv preprint arXiv:1608.00853}, 2016.

\bibitem[Fawzi et~al.(2016)Fawzi, Moosavi-Dezfooli, and
  Frossard]{fawzi2016robustness}
Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard.
\newblock Robustness of classifiers: from adversarial to random noise.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1632--1640, 2016.

\bibitem[Fawzi et~al.(2018{\natexlab{a}})Fawzi, Fawzi, and
  Fawzi]{fawzi2018adversarial}
Alhussein Fawzi, Hamza Fawzi, and Omar Fawzi.
\newblock Adversarial vulnerability for any classifier.
\newblock \emph{arXiv preprint arXiv:1802.08686}, 2018{\natexlab{a}}.

\bibitem[Fawzi et~al.(2018{\natexlab{b}})Fawzi, Moosavi-Dezfooli, Frossard, and
  Soatto]{fawzi2018empirical}
Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard, and Stefano
  Soatto.
\newblock Empirical study of the topology and geometry of deep networks.
\newblock In \emph{IEEE CVPR}, number CONF, 2018{\natexlab{b}}.

\bibitem[Geirhos et~al.(2018)Geirhos, Rubisch, Michaelis, Bethge, Wichmann, and
  Brendel]{geirhos2018imagenet}
Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix~A
  Wichmann, and Wieland Brendel.
\newblock Imagenet-trained cnns are biased towards texture; increasing shape
  bias improves accuracy and robustness.
\newblock \emph{arXiv preprint arXiv:1811.12231}, 2018.

\bibitem[Gilmer et~al.(2018{\natexlab{a}})Gilmer, Adams, Goodfellow, Andersen,
  and Dahl]{gilmer2018motivating}
Justin Gilmer, Ryan~P Adams, Ian Goodfellow, David Andersen, and George~E Dahl.
\newblock Motivating the rules of the game for adversarial example research.
\newblock \emph{arXiv preprint arXiv:1807.06732}, 2018{\natexlab{a}}.

\bibitem[Gilmer et~al.(2018{\natexlab{b}})Gilmer, Metz, Faghri, Schoenholz,
  Raghu, Wattenberg, and Goodfellow]{gilmer2018adversarial}
Justin Gilmer, Luke Metz, Fartash Faghri, Samuel~S Schoenholz, Maithra Raghu,
  Martin Wattenberg, and Ian Goodfellow.
\newblock Adversarial spheres.
\newblock \emph{arXiv preprint arXiv:1801.02774}, 2018{\natexlab{b}}.

\bibitem[Guo et~al.(2017)Guo, Rana, Cisse, and van~der
  Maaten]{guo2017countering}
Chuan Guo, Mayank Rana, Moustapha Cisse, and Laurens van~der Maaten.
\newblock Countering adversarial images using input transformations.
\newblock \emph{arXiv preprint arXiv:1711.00117}, 2017.

\bibitem[Hendrycks \& Dietterich(2018)Hendrycks and
  Dietterich]{hendrycks2018benchmarking}
Dan Hendrycks and Thomas~G Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  surface variations.
\newblock \emph{arXiv preprint arXiv:1807.01697}, 2018.

\bibitem[Katz et~al.(2017)Katz, Barrett, Dill, Julian, and
  Kochenderfer]{katz2017reluplex}
Guy Katz, Clark Barrett, David~L Dill, Kyle Julian, and Mykel~J Kochenderfer.
\newblock Reluplex: An efficient smt solver for verifying deep neural networks.
\newblock In \emph{International Conference on Computer Aided Verification},
  pp.\  97--117. Springer, 2017.

\bibitem[Liao et~al.(2018)Liao, Liang, Dong, Pang, Zhu, and
  Hu]{liao2018defense}
Fangzhou Liao, Ming Liang, Yinpeng Dong, Tianyu Pang, Jun Zhu, and Xiaolin Hu.
\newblock Defense against adversarial attacks using high-level representation
  guided denoiser.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  1778--1787, 2018.

\bibitem[Liu et~al.(2018)Liu, Liu, Liu, Wang, and Wen]{liu2018feature}
Zihao Liu, Qi~Liu, Tao Liu, Yanzhi Wang, and Wujie Wen.
\newblock Feature distillation: Dnn-oriented jpeg compression against
  adversarial examples.
\newblock \emph{arXiv preprint arXiv:1803.05787}, 2018.

\bibitem[Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017advexamples}
Aleksander Madry, Aleksander Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial examples.
\newblock \emph{arXiv preprint arXiv:1706.06083}, 2017.

\bibitem[Mahloujifar et~al.(2018)Mahloujifar, Diochnos, and
  Mahmoody]{mahloujifar2018curse}
Saeed Mahloujifar, Dimitrios~I Diochnos, and Mohammad Mahmoody.
\newblock The curse of concentration in robust learning: Evasion and poisoning
  attacks from concentration of measure.
\newblock \emph{arXiv preprint arXiv:1809.03063}, 2018.

\bibitem[Prakash et~al.(2018)Prakash, Moran, Garber, DiLillo, and
  Storer]{prakash2018deflecting}
Aaditya Prakash, Nick Moran, Solomon Garber, Antonella DiLillo, and James
  Storer.
\newblock Deflecting adversarial attacks with pixel deflection.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  8571--8580, 2018.

\bibitem[Rosenfeld et~al.(2018)Rosenfeld, Zemel, and
  Tsotsos]{rosenfeld2018elephant}
Amir Rosenfeld, Richard Zemel, and John~K Tsotsos.
\newblock The elephant in the room.
\newblock \emph{arXiv preprint arXiv:1808.03305}, 2018.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  M{\k{a}}dry]{schmidt2018adversarially}
Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, and
  Aleksander M{\k{a}}dry.
\newblock Adversarially robust generalization requires more data.
\newblock \emph{arXiv preprint arXiv:1804.11285}, 2018.

\bibitem[Sharma \& Chen(2017)Sharma and Chen]{chen2017madry}
Yash Sharma and Pin-Yu Chen.
\newblock Breaking the madry defense model with l1-based adversarial examples.
\newblock \emph{arXiv preprint arXiv:1710.10733}, 2017.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{Szegedy14}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2014.
\newblock URL \url{http://arxiv.org/abs/1312.6199}.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy16}
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew
  Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2818--2826, 2016.

\bibitem[Tram{\`e}r et~al.(2017)Tram{\`e}r, Kurakin, Papernot, Boneh, and
  McDaniel]{tramer2017ensemble}
Florian Tram{\`e}r, Alexey Kurakin, Nicolas Papernot, Dan Boneh, and Patrick
  McDaniel.
\newblock Ensemble adversarial training: Attacks and defenses.
\newblock \emph{arXiv preprint arXiv:1705.07204}, 2017.

\bibitem[Tsipras et~al.(2018)Tsipras, Santurkar, Engstrom, Turner, and
  Madry]{tsipras2018robustness}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
  Aleksander Madry.
\newblock Robustness may be at odds with accuracy.
\newblock \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=SyxAb30cY7}.

\bibitem[Wang \& Bovik(2009)Wang and Bovik]{MSELoveItOrLeaveIt2009}
Z.~Wang and A.~C. Bovik.
\newblock Mean squared error: Love it or leave it? a new look at signal
  fidelity measures.
\newblock \emph{IEEE Signal Processing Magazine}, 26\penalty0 (1):\penalty0
  98--117, 2009.

\bibitem[Xiao et~al.(2018)Xiao, Zhu, Li, He, Liu, and Song]{xiao2018spatially}
Chaowei Xiao, Jun-Yan Zhu, Bo~Li, Warren He, Mingyan Liu, and Dawn Song.
\newblock Spatially transformed adversarial examples.
\newblock \emph{arXiv preprint arXiv:1801.02612}, 2018.

\bibitem[Xie et~al.(2017)Xie, Wang, Zhang, Ren, and Yuille]{xie2017mitigating}
Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, and Alan Yuille.
\newblock Mitigating adversarial effects through randomization.
\newblock \emph{arXiv preprint arXiv:1711.01991}, 2017.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and
  Komodakis]{zagoruyko2016wide}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock \emph{arXiv preprint arXiv:1605.07146}, 2016.

\bibitem[Zantedeschi et~al.(2017)Zantedeschi, Nicolae, and
  Rawat]{zantedeschi2017efficient}
Valentina Zantedeschi, Maria-Irina Nicolae, and Ambrish Rawat.
\newblock Efficient defenses against adversarial attacks.
\newblock In \emph{Proceedings of the 10th ACM Workshop on Artificial
  Intelligence and Security}, pp.\  39--49. ACM, 2017.

\end{thebibliography}
