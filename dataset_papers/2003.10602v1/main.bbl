\begin{thebibliography}{40}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2015)Abadi, Agarwal, Barham, Brevdo, Chen, Citro,
  Corrado, Davis, Dean, Devin, Ghemawat, Goodfellow, Harp, Irving, Isard, Jia,
  Jozefowicz, Kaiser, Kudlur, Levenberg, Man\'{e}, Monga, Moore, Murray, Olah,
  Schuster, Shlens, Steiner, Sutskever, Talwar, Tucker, Vanhoucke, Vasudevan,
  Vi\'{e}gas, Vinyals, Warden, Wattenberg, Wicke, Yu, and
  Zheng]{tensorflow2015-whitepaper}
Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado,
  G.~S., Davis, A., Dean, J., Devin, M., Ghemawat, S., Goodfellow, I., Harp,
  A., Irving, G., Isard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M.,
  Levenberg, J., Man\'{e}, D., Monga, R., Moore, S., Murray, D., Olah, C.,
  Schuster, M., Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker, P.,
  Vanhoucke, V., Vasudevan, V., Vi\'{e}gas, F., Vinyals, O., Warden, P.,
  Wattenberg, M., Wicke, M., Yu, Y., and Zheng, X.
\newblock {TensorFlow}: Large-scale machine learning on heterogeneous systems,
  2015.
\newblock URL \url{http://tensorflow.org/}.
\newblock Software available from tensorflow.org.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye2018obfuscated}
Athalye, A., Carlini, N., and Wagner, D.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock \emph{arXiv preprint arXiv:1802.00420}, 2018.

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and
  Wierstra]{blundell2015weight}
Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D.
\newblock Weight uncertainty in neural networks.
\newblock \emph{arXiv preprint arXiv:1505.05424}, 2015.

\bibitem[Buckman et~al.(2018)Buckman, Roy, Raffel, and
  Goodfellow]{buckman2018thermometer}
Buckman, J., Roy, A., Raffel, C., and Goodfellow, I.
\newblock Thermometer encoding: One hot way to resist adversarial examples.
\newblock 2018.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{carlini2017towards}
Carlini, N. and Wagner, D.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{2017 ieee symposium on security and privacy (sp)}, pp.\
  39--57. IEEE, 2017.

\bibitem[Ciss{\'e} et~al.(2017)Ciss{\'e}, Bojanowski, Grave, Dauphin, and
  Usunier]{Ciss2017ParsevalNI}
Ciss{\'e}, M., Bojanowski, P., Grave, E., Dauphin, Y., and Usunier, N.
\newblock Parseval networks: Improving robustness to adversarial examples.
\newblock In \emph{ICML}, 2017.

\bibitem[Das et~al.(2017)Das, Shanbhogue, Chen, Hohman, Chen, Kounavis, and
  Chau]{das2017keeping}
Das, N., Shanbhogue, M., Chen, S.-T., Hohman, F., Chen, L., Kounavis, M.~E.,
  and Chau, D.~H.
\newblock Keeping the bad guys out: Protecting and vaccinating deep learning
  with jpeg compression.
\newblock \emph{arXiv preprint arXiv:1705.02900}, 2017.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Dhillon et~al.(2018)Dhillon, Azizzadenesheli, Lipton, Bernstein,
  Kossaifi, Khanna, and Anandkumar]{dhillon2018stochastic}
Dhillon, G.~S., Azizzadenesheli, K., Lipton, Z.~C., Bernstein, J., Kossaifi,
  J., Khanna, A., and Anandkumar, A.
\newblock Stochastic activation pruning for robust adversarial defense.
\newblock \emph{arXiv preprint arXiv:1803.01442}, 2018.

\bibitem[Dillon et~al.(2017)Dillon, Langmore, Tran, Brevdo, Vasudevan, Moore,
  Patton, Alemi, Hoffman, and Saurous]{DBLP:journals/corr/abs-1711-10604}
Dillon, J.~V., Langmore, I., Tran, D., Brevdo, E., Vasudevan, S., Moore, D.,
  Patton, B., Alemi, A., Hoffman, M.~D., and Saurous, R.~A.
\newblock Tensorflow distributions.
\newblock \emph{CoRR}, abs/1711.10604, 2017.
\newblock URL \url{http://arxiv.org/abs/1711.10604}.

\bibitem[Elsayed et~al.(2018)Elsayed, Shankar, Cheung, Papernot, Kurakin,
  Goodfellow, and Sohl-Dickstein]{elsayed2018adversarial}
Elsayed, G., Shankar, S., Cheung, B., Papernot, N., Kurakin, A., Goodfellow,
  I., and Sohl-Dickstein, J.
\newblock Adversarial examples that fool both computer vision and time-limited
  humans.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3910--3920, 2018.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Guo et~al.(2017)Guo, Rana, Cisse, and Van
  Der~Maaten]{guo2017countering}
Guo, C., Rana, M., Cisse, M., and Van Der~Maaten, L.
\newblock Countering adversarial images using input transformations.
\newblock \emph{arXiv preprint arXiv:1711.00117}, 2017.

\bibitem[Hazan et~al.(2016)Hazan, Papandreou, and
  Tarlow]{hazan2016perturbations}
Hazan, T., Papandreou, G., and Tarlow, D.
\newblock \emph{Perturbations, Optimization, and Statistics}.
\newblock MIT Press, 2016.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Hornik et~al.(1989)Hornik, Stinchcombe, and
  White]{journals/nn/HornikSW89}
Hornik, K., Stinchcombe, M.~B., and White, H.
\newblock Multilayer feedforward networks are universal approximators.
\newblock \emph{Neural Networks}, 2\penalty0 (5):\penalty0 359--366, 1989.
\newblock URL
  \url{http://dblp.uni-trier.de/db/journals/nn/nn2.html#HornikSW89}.

\bibitem[Kingma \& Welling(2014)Kingma and
  Welling]{DBLP:journals/corr/KingmaW13}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock In Bengio, Y. and LeCun, Y. (eds.), \emph{2nd International
  Conference on Learning Representations, {ICLR} 2014, Banff, AB, Canada, April
  14-16, 2014, Conference Track Proceedings}, 2014.
\newblock URL \url{http://arxiv.org/abs/1312.6114}.

\bibitem[Krizhevsky et~al.()Krizhevsky, Nair, and Hinton]{cifar10_citation}
Krizhevsky, A., Nair, V., and Hinton, G.
\newblock Cifar-10 (canadian institute for advanced research).
\newblock URL \url{http://www.cs.toronto.edu/~kriz/cifar.html}.

\bibitem[LeCun \& Cortes(2010)LeCun and
  Cortes]{lecun-mnisthandwrittendigit-2010}
LeCun, Y. and Cortes, C.
\newblock {MNIST} handwritten digit database.
\newblock 2010.
\newblock URL \url{http://yann.lecun.com/exdb/mnist/}.

\bibitem[Liu et~al.(2018{\natexlab{a}})Liu, Cheng, Zhang, and
  Hsieh]{liu2018towards}
Liu, X., Cheng, M., Zhang, H., and Hsieh, C.-J.
\newblock Towards robust neural networks via random self-ensemble.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  369--385, 2018{\natexlab{a}}.

\bibitem[Liu et~al.(2018{\natexlab{b}})Liu, Li, Wu, and Hsieh]{liu2018adv}
Liu, X., Li, Y., Wu, C., and Hsieh, C.-J.
\newblock Adv-bnn: Improved adversarial defense through robust bayesian neural
  network.
\newblock \emph{arXiv preprint arXiv:1810.01279}, 2018{\natexlab{b}}.

\bibitem[Liu et~al.(2016)Liu, Chen, Liu, and Song]{liu2016delving}
Liu, Y., Chen, X., Liu, C., and Song, D.
\newblock Delving into transferable adversarial examples and black-box attacks.
\newblock \emph{arXiv preprint arXiv:1611.02770}, 2016.

\bibitem[Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \emph{arXiv preprint arXiv:1706.06083}, 2017.

\bibitem[Moosavi-Dezfooli et~al.(2016)Moosavi-Dezfooli, Fawzi, and
  Frossard]{moosavi2016deepfool}
Moosavi-Dezfooli, S.-M., Fawzi, A., and Frossard, P.
\newblock Deepfool: a simple and accurate method to fool deep neural networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2574--2582, 2016.

\bibitem[Nicolae et~al.(2018)Nicolae, Sinn, Tran, Buesser, Rawat, Wistuba,
  Zantedeschi, Baracaldo, Chen, Ludwig, Molloy, and Edwards]{art2018}
Nicolae, M.-I., Sinn, M., Tran, M.~N., Buesser, B., Rawat, A., Wistuba, M.,
  Zantedeschi, V., Baracaldo, N., Chen, B., Ludwig, H., Molloy, I., and
  Edwards, B.
\newblock Adversarial robustness toolbox v1.1.0.
\newblock \emph{CoRR}, 1807.01069, 2018.
\newblock URL \url{https://arxiv.org/pdf/1807.01069}.

\bibitem[Papernot et~al.(2016)Papernot, McDaniel, Jha, Fredrikson, Celik, and
  Swami]{papernot2016limitations}
Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.~B., and Swami,
  A.
\newblock The limitations of deep learning in adversarial settings.
\newblock In \emph{2016 IEEE European symposium on security and privacy
  (EuroS\&P)}, pp.\  372--387. IEEE, 2016.

\bibitem[Ross \& Doshi-Velez(2018)Ross and Doshi-Velez]{ross2018improving}
Ross, A.~S. and Doshi-Velez, F.
\newblock Improving the adversarial robustness and interpretability of deep
  neural networks by regularizing their input gradients.
\newblock In \emph{Thirty-second AAAI conference on artificial intelligence},
  2018.

\bibitem[Sharma \& Chen(2017)Sharma and Chen]{sharma2017attacking}
Sharma, Y. and Chen, P.-Y.
\newblock Attacking the madry defense model with $ l\_1 $-based adversarial
  examples.
\newblock \emph{arXiv preprint arXiv:1710.10733}, 2017.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van
  Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot,
  et~al.]{silver2016mastering}
Silver, D., Huang, A., Maddison, C.~J., Guez, A., Sifre, L., Van Den~Driessche,
  G., Schrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M.,
  et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{nature}, 529\penalty0 (7587):\penalty0 484, 2016.

\bibitem[Silver et~al.(2017)Silver, Schrittwieser, Simonyan, Antonoglou, Huang,
  Guez, Hubert, Baker, Lai, Bolton, et~al.]{silver2017mastering}
Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez,
  A., Hubert, T., Baker, L., Lai, M., Bolton, A., et~al.
\newblock Mastering the game of go without human knowledge.
\newblock \emph{Nature}, 550\penalty0 (7676):\penalty0 354--359, 2017.

\bibitem[Song et~al.(2017)Song, Kim, Nowozin, Ermon, and
  Kushman]{song2017pixeldefend}
Song, Y., Kim, T., Nowozin, S., Ermon, S., and Kushman, N.
\newblock Pixeldefend: Leveraging generative models to understand and defend
  against adversarial examples.
\newblock \emph{arXiv preprint arXiv:1710.10766}, 2017.

\bibitem[Tram{\`e}r et~al.(2017{\natexlab{a}})Tram{\`e}r, Kurakin, Papernot,
  Goodfellow, Boneh, and McDaniel]{tramer2017ensemble}
Tram{\`e}r, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., and
  McDaniel, P.
\newblock Ensemble adversarial training: Attacks and defenses.
\newblock \emph{arXiv preprint arXiv:1705.07204}, 2017{\natexlab{a}}.

\bibitem[Tram{\`e}r et~al.(2017{\natexlab{b}})Tram{\`e}r, Papernot, Goodfellow,
  Boneh, and McDaniel]{tramer2017space}
Tram{\`e}r, F., Papernot, N., Goodfellow, I., Boneh, D., and McDaniel, P.
\newblock The space of transferable adversarial examples.
\newblock \emph{arXiv preprint arXiv:1704.03453}, 2017{\natexlab{b}}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  5998--6008, 2017.

\bibitem[Wang et~al.(2018)Wang, Wang, Zhao, Wen, Kaeli, Chin, and
  Lin]{wang2018defensive}
Wang, S., Wang, X., Zhao, P., Wen, W., Kaeli, D., Chin, P., and Lin, X.
\newblock Defensive dropout for hardening deep neural networks under
  adversarial attacks.
\newblock In \emph{Proceedings of the International Conference on
  Computer-Aided Design}, pp.\  1--8, 2018.

\bibitem[Wang et~al.(2019)Wang, Wang, Chen, Wang, Kulis, Lin, and
  Chin]{wang2019protecting}
Wang, X., Wang, S., Chen, P.-Y., Wang, Y., Kulis, B., Lin, X., and Chin, P.
\newblock Protecting neural networks with hierarchical random switching:
  Towards better robustness-accuracy trade-off for stochastic defenses.
\newblock \emph{arXiv preprint arXiv:1908.07116}, 2019.

\bibitem[Wen et~al.(2018)Wen, Vicol, Ba, Tran, and
  Grosse]{DBLP:journals/corr/abs-1803-04386}
Wen, Y., Vicol, P., Ba, J., Tran, D., and Grosse, R.~B.
\newblock Flipout: Efficient pseudo-independent weight perturbations on
  mini-batches.
\newblock \emph{CoRR}, abs/1803.04386, 2018.
\newblock URL \url{http://arxiv.org/abs/1803.04386}.

\bibitem[Xie et~al.(2019)Xie, Wu, Maaten, Yuille, and He]{xie2019feature}
Xie, C., Wu, Y., Maaten, L. v.~d., Yuille, A.~L., and He, K.
\newblock Feature denoising for improving adversarial robustness.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  501--509, 2019.

\bibitem[Zantedeschi et~al.(2017)Zantedeschi, Nicolae, and
  Rawat]{zantedeschi2017efficient}
Zantedeschi, V., Nicolae, M.-I., and Rawat, A.
\newblock Efficient defenses against adversarial attacks.
\newblock In \emph{Proceedings of the 10th ACM Workshop on Artificial
  Intelligence and Security}, pp.\  39--49, 2017.

\bibitem[Zhang et~al.(2019)Zhang, Chen, Song, Boning, Dhillon, and
  Hsieh]{zhang2019limitations}
Zhang, H., Chen, H., Song, Z., Boning, D., Dhillon, I.~S., and Hsieh, C.-J.
\newblock The limitations of adversarial training and the blind-spot attack.
\newblock \emph{arXiv preprint arXiv:1901.04684}, 2019.

\end{thebibliography}
