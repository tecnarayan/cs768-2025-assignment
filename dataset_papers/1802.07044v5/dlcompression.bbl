\begin{thebibliography}{45}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achille and Soatto(2017)]{Achille2017}
A.~Achille and S.~Soatto.
\newblock {On the Emergence of Invariance and Disentangling in Deep
  Representations}.
\newblock \emph{arXiv preprint arXiv:1706.01350}, jun 2017.
\newblock URL \url{http://arxiv.org/abs/1706.01350}.

\bibitem[Arora et~al.(2018)Arora, Ge, Neyshabur, and Zhang]{Arora}
S.~Arora, R.~Ge, B.~Neyshabur, and Y.~Zhang.
\newblock {Stronger generalization bounds for deep nets via a compression
  approach}.
\newblock \emph{arXiv preprint arXiv:1802.05296}, 2018.

\bibitem[Ba and Caruana(2014)]{Ba2013}
L.~J. Ba and R.~Caruana.
\newblock {Do Deep Nets Really Need to be Deep?}
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2654--2662, 2014.

\bibitem[Barron and Yang(1999)]{Barron1999}
A.~Barron and Y.~Yang.
\newblock {Information-theoretic determination of minimax rates of
  convergence}.
\newblock \emph{The Annals of Statistics}, 27\penalty0 (5):\penalty0
  1564--1599, 1999.

\bibitem[Blum and Langford(2003)]{Blum2003}
A.~Blum and J.~Langford.
\newblock {PAC-MDL Bounds}.
\newblock In B.~Sch{\"{o}}lkopf and M.~K. Warmuth, editors, \emph{Learning
  Theory and Kernel Machines}, pages 344--357, Berlin, Heidelberg, 2003.
  Springer Berlin Heidelberg.
\newblock ISBN 978-3-540-45167-9.

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and
  Wierstra]{Blundell}
C.~Blundell, J.~Cornebise, K.~Kavukcuoglu, and D.~Wierstra.
\newblock {Weight Uncertainty in Neural Networks}.
\newblock In \emph{International Conference on Machine Learning}, pages
  1613--1622, 2015.

\bibitem[Chaitin(2007)]{Chaitin2002}
G.~J. Chaitin.
\newblock {On the intelligibility of the universe and the notions of
  simplicity, complexity and irreducibility}.
\newblock In \emph{Thinking about Godel and Turing: Essays on Complexity,
  1970-2007}. World scientific, 2007.

\bibitem[Dawid(1984)]{Dawid1984}
A.~P. Dawid.
\newblock {Present Position and Potential Developments: Some Personal Views:
  Statistical Theory: The Prequential Approach}.
\newblock \emph{Journal of the Royal Statistical Society. Series A (General)},
  147\penalty0 (2):\penalty0 278, 1984.

\bibitem[Dziugaite and Roy(2017)]{Dziugaite2017}
G.~K. Dziugaite and D.~M. Roy.
\newblock {Computing Nonvacuous Generalization Bounds for Deep (Stochastic)
  Neural Networks with Many More Parameters than Training Data}.
\newblock In \emph{Proceedings of the Thirty-Third Conference on Uncertainty in
  Artificial Intelligence}, Sydney, 2017.

\bibitem[Foster and George(1994)]{Foster1994}
D.~P. Foster and E.~I. George.
\newblock {The Risk Inflation Criterion for Multiple Regression}.
\newblock \emph{The Annals of Statistics}, 22\penalty0 (4):\penalty0
  1947--1975, dec 1994.

\bibitem[Gao and Jojic(2016)]{Gao2016}
T.~Gao and V.~Jojic.
\newblock {Degrees of Freedom in Deep Neural Networks}.
\newblock \emph{arXiv preprint arXiv:1603.09260}, mar 2016.

\bibitem[Graves(2011)]{Graves2011}
A.~Graves.
\newblock {Practical Variational Inference for Neural Networks}.
\newblock In \emph{Neural Information Processing Systems}, 2011.

\bibitem[Gr{\"{u}}nwald(2007)]{Grunwald}
P.~D. Gr{\"{u}}nwald.
\newblock \emph{{The Minimum Description Length principle}}.
\newblock MIT press, 2007.

\bibitem[Han et~al.(2015{\natexlab{a}})Han, Mao, and Dally]{Han2015}
S.~Han, H.~Mao, and W.~J. Dally.
\newblock {Deep Compression: Compressing Deep Neural Networks with Pruning,
  Trained Quantization and Huffman Coding}.
\newblock \emph{arXiv preprint arXiv:1510.00149}, 2015{\natexlab{a}}.

\bibitem[Han et~al.(2015{\natexlab{b}})Han, Pool, Tran, and Dally]{Han2015a}
S.~Han, J.~Pool, J.~Tran, and W.~J. Dally.
\newblock {Learning both Weights and Connections for Efficient Neural
  Networks}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2015{\natexlab{b}}.

\bibitem[Hinton and {Van Camp}(1993)]{Hinton}
G.~E. Hinton and D.~{Van Camp}.
\newblock {Keeping Neural Networks Simple by Minimizing the Description Length
  of the Weights}.
\newblock In \emph{Proceedings of the sixth annual conference on Computational
  learning theory}. ACM, 1993.

\bibitem[Honkela and Valpola(2004)]{Honkela2004}
A.~Honkela and H.~Valpola.
\newblock {Variational Learning and Bits-Back Coding: An Information-Theoretic
  View to Bayesian Learning}.
\newblock \emph{IEEE transactions on Neural Networks}, 15\penalty0 (4), 2004.

\bibitem[Hutter(2007)]{Hutter2007}
M.~Hutter.
\newblock {On Universal Prediction and Bayesian Confirmation}.
\newblock \emph{Theoretical Computer Science}, 384\penalty0 (1), sep 2007.

\bibitem[Ioffe and Szegedy(2015)]{Ioffe2015}
S.~Ioffe and C.~Szegedy.
\newblock {Batch Normalization: Accelerating Deep Network Training by Reducing
  Internal Covariate Shift}.
\newblock In \emph{International Conference on Machine Learning}, pages
  448--456, 2015.

\bibitem[Kingma and Welling(2013)]{Kingma2013}
D.~P. Kingma and M.~Welling.
\newblock {Auto-Encoding Variational Bayes}.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Krizhevsky(2009)]{Krizhevsky2009}
A.~Krizhevsky.
\newblock {Learning Multiple Layers of Features from Tiny Images}.
\newblock 2009.

\bibitem[Kucukelbir et~al.(2017)Kucukelbir, Tran, Ranganath, Gelman, and
  Blei]{Kucukelbir2017}
A.~Kucukelbir, D.~Tran, R.~Ranganath, A.~Gelman, and D.~M. Blei.
\newblock {Automatic Differentiation Variational Inference}.
\newblock \emph{Journal of Machine Learning Research}, 18:\penalty0 1--45,
  2017.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and Haffner]{lecun1988}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner.
\newblock {Gradient-Based Learning Applied to Document Recognition}.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11), 1998.

\bibitem[LeCun et~al.(2015)LeCun, Bengio, and Hinton]{LeCun2015}
Y.~LeCun, Y.~Bengio, and G.~Hinton.
\newblock {Deep learning}.
\newblock \emph{Nature}, 521\penalty0 (7553):\penalty0 436--444, 2015.

\bibitem[Li et~al.(2018)Li, Farkhoor, Liu, and Yosinski]{Li2018}
C.~Li, H.~Farkhoor, R.~Liu, and J.~Yosinski.
\newblock {Measuring the Intrinsic Dimension of Objective Landscapes}.
\newblock \emph{arXiv preprint arXiv:1804.08838}, apr 2018.

\bibitem[Li and Vit{\'{a}}nyi(2008)]{Li2008a}
M.~Li and P.~Vit{\'{a}}nyi.
\newblock \emph{{An introduction to Kolmogorov complexity}}.
\newblock Springer, 2008.

\bibitem[Louizos et~al.(2017)Louizos, Ullrich, and Welling]{Louizos}
C.~Louizos, K.~Ullrich, and M.~Welling.
\newblock {Bayesian compression for deep learning}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3290--3300, 2017.

\bibitem[Mackay(2003)]{Mackay}
D.~J.~C. Mackay.
\newblock \emph{{Information Theory, Inference, and Learning Algorithms}}.
\newblock Cambridge University Press, cambridge edition, 2003.

\bibitem[Ollivier(2014)]{Ollivier2014a}
Y.~Ollivier.
\newblock {Auto-encoders: reconstruction versus compression}.
\newblock \emph{arXiv preprint arXiv:1403.7752}, mar 2014.
\newblock URL \url{http://arxiv.org/abs/1403.7752}.

\bibitem[Rissanen(2007)]{rissanen2007information}
J.~Rissanen.
\newblock \emph{Information and complexity in statistical modeling}.
\newblock Springer Science \& Business Media, 2007.

\bibitem[Rissanen et~al.(1992)Rissanen, Speed, and Yu]{Rissanen1992}
J.~Rissanen, T.~Speed, and B.~Yu.
\newblock {Density estimation by stochastic complexity}.
\newblock \emph{IEEE Transactions on Information Theory}, 38\penalty0
  (2):\penalty0 315--323, 1992.

\bibitem[Romero et~al.(2015)Romero, Ballas, Kahou, Chassang, Gatta, and
  Bengio]{Romero2015}
A.~Romero, N.~Ballas, S.~E. Kahou, A.~Chassang, C.~Gatta, and Y.~Bengio.
\newblock {Fitnets: Hints for thin deep nets}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations}, 2015.

\bibitem[Schmidhuber(1997)]{Schmidhuber1997}
J.~Schmidhuber.
\newblock {Discovering Neural Nets with Low Kolmogorov Complexity and High
  Generalization Capability}.
\newblock \emph{Neural Networks}, 10\penalty0 (5):\penalty0 857--873, jul 1997.

\bibitem[See et~al.(2016)See, Luong, and Manning]{See}
A.~See, M.-T. Luong, and C.~D. Manning.
\newblock {Compression of Neural Machine Translation Models via Pruning}.
\newblock \emph{arXiv preprint arXiv:1606.09274}, 2016.

\bibitem[Shannon(1948)]{Shannon2001}
C.~Shannon.
\newblock {A mathematical theory of communication}.
\newblock \emph{The Bell System Technical Journal}, 27, 1948.

\bibitem[Shwartz-Ziv and Tishby(2017)]{Shwartz-Ziv}
R.~Shwartz-Ziv and N.~Tishby.
\newblock {Opening the Black Box of Deep Neural Networks via Information}.
\newblock \emph{arXiv preprint arXiv:1703.00810}, 2017.

\bibitem[Simonyan and Zisserman(2014)]{Simonyan2014}
K.~Simonyan and A.~Zisserman.
\newblock {Very Deep Convolutional Networks for Large-Scale Image Recognition}.
\newblock \emph{arXiv preprint arXiv:1409.1556}, sep 2014.

\bibitem[Solomonoff(1964)]{Solomonoff1964}
R.~Solomonoff.
\newblock {A formal theory of inductive inference.}
\newblock \emph{Information and control}, 1964.

\bibitem[Tallec and Blier(2018)]{Tallec2018}
C.~Tallec and L.~Blier.
\newblock {Pyvarinf : Variational Inference for PyTorch}, 2018.
\newblock URL \url{https://github.com/ctallec/pyvarinf}.

\bibitem[Tishby and Zaslavsky(2015)]{Tishby2015}
N.~Tishby and N.~Zaslavsky.
\newblock {Deep Learning and the Information Bottleneck Principle}.
\newblock In \emph{Information Theory Workshop}, pages 1--5. IEEE, 2015.

\bibitem[Ullrich et~al.(2017)Ullrich, Meeds, and Welling]{Ullrich2017}
K.~Ullrich, E.~Meeds, and M.~Welling.
\newblock {Soft Weight-Sharing for Neural Network Compression}.
\newblock \emph{arXiv preprint arXiv:1702.04008}, 2017.

\bibitem[{Van Erven} et~al.(2012){Van Erven}, Gr{\"{u}}nwald, and {De
  Rooij}]{VanErven2011}
T.~{Van Erven}, P.~Gr{\"{u}}nwald, and S.~{De Rooij}.
\newblock {Catching Up Faster by Switching Sooner: A predictive approach to
  adaptive estimation with an application to the AIC-BIC Dilemma}.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 74\penalty0 (3):\penalty0 361--417, 2012.

\bibitem[Xu et~al.(2017)Xu, Yang, Zhang, and Liu]{Xu2017}
T.-B. Xu, P.~Yang, X.-Y. Zhang, and C.-L. Liu.
\newblock {Margin-Aware Binarized Weight Networks for Image Classification}.
\newblock In \emph{International Conference on Image and Graphics}, pages
  590--601. Springer, Cham, sep 2017.

\bibitem[Zagoruyko(2015)]{Zagoruyko2015}
S.~Zagoruyko.
\newblock {92.45{\%} on CIFAR-10 in Torch}, 2015.
\newblock URL \url{http://torch.ch/blog/2015/07/30/cifar.html}.

\bibitem[Zhang et~al.(2017)Zhang, Bengio, Hardt, Recht, and Vinyals]{Zhang2016}
C.~Zhang, S.~Bengio, M.~Hardt, B.~Recht, and O.~Vinyals.
\newblock {Understanding deep learning requires rethinking generalization}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations}, 2017.

\end{thebibliography}
