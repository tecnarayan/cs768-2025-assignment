\begin{thebibliography}{10}

\bibitem{ACFH2019square}
Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion, and Matthias Hein.
\newblock Square attack: a query-efficient black-box adversarial attack via random search.
\newblock In {\em ECCV}, 2020.

\bibitem{bai2021are}
Yutong Bai, Jieru Mei, Alan Yuille, and Cihang Xie.
\newblock Are transformers more robust than {CNN}s?
\newblock In {\em NeurIPS}, 2021.

\bibitem{CarEtAl19}
Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, John~C Duchi, and Percy~S Liang.
\newblock Unlabeled data improves adversarial robustness.
\newblock In {\em NeurIPS}, 2019.

\bibitem{caron2021emerging}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\'e J\'egou, Julien Mairal, Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In {\em ICCV}, 2021.

\bibitem{chen2020adversarial}
Tianlong Chen, Sijia Liu, Shiyu Chang, Yu~Cheng, Lisa Amini, and Zhangyang Wang.
\newblock Adversarial robustness: From self-supervised pre-training to fine-tuning.
\newblock In {\em CVPR}, 2020.

\bibitem{croce2020robustbench}
Francesco Croce, Maksym Andriushchenko, Vikash Sehwag, Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein.
\newblock Robustbench: a standardized adversarial robustness benchmark.
\newblock In {\em NeurIPS Datasets and Benchmarks Track}, 2021.

\bibitem{CroHei2019}
Francesco Croce and Matthias Hein.
\newblock Minimally distorted adversarial examples with a fast adaptive boundary attack.
\newblock In {\em ICML}, 2020.

\bibitem{croce2020reliable}
Francesco Croce and Matthias Hein.
\newblock Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks.
\newblock In {\em ICML}, 2020.

\bibitem{croce2021mind}
Francesco Croce and Matthias Hein.
\newblock Mind the box: $l_1$-apgd for sparse adversarial attacks on image classifiers.
\newblock In {\em ICML}, 2021.

\bibitem{Croce2022Adv}
Francesco Croce and Matthias Hein.
\newblock Adversarial robustness against multiple and single $l_p$-threat models via quick fine-tuning of robust classifiers.
\newblock In {\em ICML}, 2022.

\bibitem{croce2023robust}
Francesco Croce, Naman~D Singh, and Matthias Hein.
\newblock Robust semantic segmentation: Strong adversarial attacks and fast training of robust models.
\newblock {\em arXiv preprint, arXiv:2306.12941}, 2023.

\bibitem{cubuk2020randaugment}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock Randaugment: Practical automated data augmentation with a reduced search space.
\newblock In {\em CVPR}, 2020.

\bibitem{dai2021coatnet}
Zihang Dai, Hanxiao Liu, Quoc~V. Le, and Mingxing Tan.
\newblock Coatnet: Marrying convolution and attention for all data sizes.
\newblock In {\em NeurIPS}, 2021.

\bibitem{debenedetti2022light}
Edoardo Debenedetti, Vikash Sehwag, and Prateek Mittal.
\newblock A light recipe to train robust vision transformers.
\newblock In {\em First IEEE Conference on Secure and Trustworthy Machine Learning}, 2023.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em CVPR}, 2009.

\bibitem{dosovitskiy2021an}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In {\em ICLR}, 2021.

\bibitem{el2021xcit}
Alaaeldin El-Nouby, Hugo Touvron, Mathilde Caron, Piotr Bojanowski, Matthijs Douze, Armand Joulin, Ivan Laptev, Natalia Neverova, Gabriel Synnaeve, Jakob Verbeek, et~al.
\newblock Xcit: Cross-covariance image transformers.
\newblock In {\em NeurIPS}, 2021.

\bibitem{fu2022patchfool}
Yonggan Fu, Shunyao Zhang, Shang Wu, Cheng Wan, and Yingyan Lin.
\newblock Patch-fool: Are vision transformers always robust against adversarial perturbations?
\newblock In {\em ICLR}, 2022.

\bibitem{gowal2020uncovering}
Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, and Pushmeet Kohli.
\newblock Uncovering the limits of adversarial training against norm-bounded adversarial examples.
\newblock {\em arXiv preprint arXiv:2010.03593v2}, 2020.

\bibitem{gowal2021improving}
Sven Gowal, Sylvestre-Alvise Rebuffi, Olivia Wiles, Florian Stimberg, Dan~Andrei Calian, and Timothy Mann.
\newblock Improving robustness using generated data.
\newblock In {\em NeurIPS}, 2021.

\bibitem{gu2022vision}
Jindong Gu, Volker Tresp, and Yao Qin.
\newblock Are vision transformers robust to patch perturbations?
\newblock In {\em ECCV}, 2022.

\bibitem{he2016identity}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Identity mappings in deep residual networks.
\newblock In {\em ECCV}, 2016.

\bibitem{hendrycks2016gaussian}
Dan Hendrycks and Kevin Gimpel.
\newblock Gaussian error linear units (gelus).
\newblock {\em arXiv preprint arXiv:1606.08415}, 2016.

\bibitem{hendrycks2019using}
Dan Hendrycks, Kimin Lee, and Mantas Mazeika.
\newblock Using pre-training can improve model robustness and uncertainty.
\newblock In {\em ICML}, 2019.

\bibitem{imagenette}
Jeremy Howard.
\newblock Imagenette, 2019.

\bibitem{huang2021exploring}
Hanxun Huang, Yisen Wang, Sarah Erfani, Quanquan Gu, James Bailey, and Xingjun Ma.
\newblock Exploring architectural ingredients of adversarially robust deep neural networks.
\newblock In {\em NeurIPS}, 2021.

\bibitem{jeddi2020simple}
Ahmadreza Jeddi, Mohammad~Javad Shafiee, and Alexander Wong.
\newblock A simple fine-tuning is all you need: Towards robust deep learning via adversarial fine-tuning.
\newblock {\em arXiv preprint, arXiv:2012.13628}, 2020.

\bibitem{kang2019testing}
Daniel Kang, Yi~Sun, Dan Hendrycks, Tom Brown, and Jacob Steinhardt.
\newblock Testing robustness against unforeseen adversaries.
\newblock {\em arXiv preprint arXiv:1908.08016}, 2019.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock {\em Toronto, ON, Canada}, 2009.

\bibitem{laidlaw2021perceptual}
Cassidy Laidlaw, Sahil Singla, and Soheil Feizi.
\newblock Perceptual adversarial robustness: Defense against unseen threat models.
\newblock In {\em ICLR}, 2021.

\bibitem{li2022data}
Lin Li and Michael~W Spratling.
\newblock Data augmentation alone can improve adversarial training.
\newblock In {\em ICLR}, 2023.

\bibitem{liu2023comprehensive}
Chang Liu, Yinpeng Dong, Wenzhao Xiang, Xiao Yang, Hang Su, Jun Zhu, Yuefeng Chen, Yuan He, Hui Xue, and Shibao Zheng.
\newblock A comprehensive study on robustness of image classification models: Benchmarking and rethinking.
\newblock {\em arXiv preprint, arXiv:2302.14301}, 2023.

\bibitem{liu2021Swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted windows.
\newblock In {\em ICCV}, 2021.

\bibitem{liu2022convnet}
Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, and Saining Xie.
\newblock A convnet for the 2020s.
\newblock In {\em CVPR}, 2022.

\bibitem{loshchilov2018decoupled}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In {\em ICLR}, 2018.

\bibitem{MadEtAl2018}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In {\em ICLR}, 2018.

\bibitem{mao2022easyrobust}
Xiaofeng Mao, Yuefeng Chen, Xiaodan Li, Gege Qi, Ranjie Duan, Rong Zhang, and Hui Xue.
\newblock Easyrobust: A comprehensive and easy-to-use toolkit for robust computer vision.
\newblock \url{https://github.com/alibaba/easyrobust}, 2022.

\bibitem{mo2022when}
Yichuan Mo, Dongxian Wu, Yifei Wang, Yiwen Guo, and Yisen Wang.
\newblock When adversarial training meets vision transformers: Recipes from training to architecture.
\newblock In {\em NeurIPS}, 2022.

\bibitem{Nilsback08}
Maria-Elena Nilsback and Andrew Zisserman.
\newblock Automated flower classification over a large number of classes.
\newblock In {\em Indian Conference on Computer Vision, Graphics and Image Processing}, 2008.

\bibitem{pang2022robustness}
Tianyu Pang, Min Lin, Xiao Yang, Junyi Zhu, and Shuicheng Yan.
\newblock Robustness and accuracy could be reconcilable by (proper) definition.
\newblock In {\em ICML}, 2022.

\bibitem{pang2021bag}
Tianyu Pang, Xiao Yang, Yinpeng Dong, Hang Su, and Jun Zhu.
\newblock Bag of tricks for adversarial training.
\newblock In {\em ICLR}, 2021.

\bibitem{peng2023robarch}
ShengYun Peng, Weilin Xu, Cory Cornelius, Kevin Li, Rahul Duggal, Duen~Horng Chau, and Jason Martin.
\newblock Robarch: Designing robust architectures against adversarial attacks.
\newblock {\em arXiv preprint arXiv:2301.03110}, 2023.

\bibitem{rade2022reducing}
Rahul Rade and Seyed-Mohsen Moosavi-Dezfooli.
\newblock Reducing excessive margin to achieve a better accuracy vs. robustness trade-off.
\newblock In {\em ICLR}, 2022.

\bibitem{rebuffi2022revisiting}
Sylvestre-Alvise Rebuffi, Francesco Croce, and Sven Gowal.
\newblock Revisiting adapters with adversarial training.
\newblock In {\em ICLR}, 2023.

\bibitem{rebuffi2021data}
Sylvestre-Alvise Rebuffi, Sven Gowal, Dan~A. Calian, Florian Stimberg, Olivia Wiles, and Timothy Mann.
\newblock Data augmentation can improve robustness.
\newblock In {\em NeurIPS}, 2021.

\bibitem{salman2020adversarially}
Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, and Aleksander Madry.
\newblock Do adversarially robust imagenet models transfer better?
\newblock In {\em NeurIPS}, 2020.

\bibitem{tan2021efficientnetv2}
Mingxing Tan and Quoc Le.
\newblock Efficientnetv2: Smaller models and faster training.
\newblock In {\em ICML}, 2021.

\bibitem{tang2022exploring}
Shiyu Tang, Siyuan Liang, Ruihao Gong, Aishan Liu, Xianglong Liu, and Dacheng Tao.
\newblock Exploring the relationship between architecture and adversarially robust generalization.
\newblock {\em arXiv preprint arXiv:2209.14105}, 2022.

\bibitem{tolstikhin2021mlp}
Ilya~O Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Thomas Unterthiner, Jessica Yung, Andreas Steiner, Daniel Keysers, Jakob Uszkoreit, et~al.
\newblock Mlp-mixer: An all-mlp architecture for vision.
\newblock In {\em NeurIPS}, 2021.

\bibitem{touvron2021training}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herv{\'e} J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through attention.
\newblock In {\em ICML}, 2021.

\bibitem{touvron2022deit}
Hugo Touvron, Matthieu Cord, and Herv{\'e} J{\'e}gou.
\newblock Deit iii: Revenge of the vit.
\newblock In {\em ECCV}, 2022.

\bibitem{touvron2019fixing}
Hugo Touvron, Andrea Vedaldi, Matthijs Douze, and Herv{\'e} J{\'e}gou.
\newblock Fixing the train-test resolution discrepancy.
\newblock In {\em NeurIPS}, 2019.

\bibitem{TraBon2019}
Florian Tramèr and Dan Boneh.
\newblock Adversarial training and robustness for multiple perturbations.
\newblock In {\em NeurIPS}, 2019.

\bibitem{trockman2022patches}
Asher Trockman and J~Zico Kolter.
\newblock Patches are all you need?
\newblock {\em Transactions on Machine Learning Research}, 2023.

\bibitem{tu2022maxvit}
Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, and Yinxiao Li.
\newblock Maxvit: Multi-axis vision transformer.
\newblock In {\em ECCV}, 2022.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, 2017.

\bibitem{wang2023internimage}
Wenhai Wang, Jifeng Dai, Zhe Chen, Zhenhang Huang, Zhiqi Li, Xizhou Zhu, Xiaowei Hu, Tong Lu, Lewei Lu, Hongsheng Li, et~al.
\newblock Internimage: Exploring large-scale vision foundation models with deformable convolutions.
\newblock In {\em CVPR}, 2023.

\bibitem{rw2019timm}
Ross Wightman.
\newblock Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem{wightman2021resnet}
Ross Wightman, Hugo Touvron, and Herv{\'e} J{\'e}gou.
\newblock Resnet strikes back: An improved training procedure in timm.
\newblock {\em arXiv preprint arXiv:2110.00476}, 2021.

\bibitem{wu2021wider}
Boxi Wu, Jinghui Chen, Deng Cai, Xiaofei He, and Quanquan Gu.
\newblock Do wider neural networks really help adversarial robustness?
\newblock In {\em NeurIPS}, 2021.

\bibitem{wu2020adversarial}
Dongxian Wu, {Shu-tao} Xia, and Yisen Wang.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock In {\em NeurIPS}, 2020.

\bibitem{xiao2021early}
Tete Xiao, Mannat Singh, Eric Mintun, Trevor Darrell, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Early convolutions help transformers see better.
\newblock In {\em NeurIPS}, 2021.

\bibitem{xie2020smooth}
Cihang Xie, Mingxing Tan, Boqing Gong, Alan Yuille, and Quoc~V Le.
\newblock Smooth adversarial training.
\newblock {\em arXiv preprint arXiv:2006.14536}, 2020.

\bibitem{yu2022metaformer}
Weihao Yu, Mi~Luo, Pan Zhou, Chenyang Si, Yichen Zhou, Xinchao Wang, Jiashi Feng, and Shuicheng Yan.
\newblock Metaformer is actually what you need for vision.
\newblock In {\em CVPR}, 2022.

\bibitem{yun2019cutmix}
Sangdoo Yun, Dongyoon Han, Seong~Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo.
\newblock Cutmix: Regularization strategy to train strong classifiers with localizable features.
\newblock In {\em CVPR}, 2019.

\bibitem{ZhaEtAl2019}
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El~Ghaoui, and Michael Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In {\em ICML}, 2019.

\bibitem{zhang2018mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock In {\em ICLR}, 2018.

\bibitem{zhong2020random}
Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, and Yi~Yang.
\newblock Random erasing data augmentation.
\newblock In {\em AAAI}, 2020.

\end{thebibliography}
