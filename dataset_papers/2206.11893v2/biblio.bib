% LMU
@article{voelker2018improving,
  title={Improving spiking dynamical networks: Accurate delays, higher-order synapses, and time cells},
  author={Voelker, Aaron R and Eliasmith, Chris},
  journal={Neural computation},
  volume={30},
  number={3},
  pages={569--609},
  year={2018},
  publisher={MIT Press}
}

@phdthesis{voelker2019dynamical,
  title={Dynamical systems in spiking neuromorphic hardware},
  author={Voelker, Aaron Russell},
  year={2019},
  school={University of Waterloo}
}

@inproceedings{voelker2019legendre,
  title={Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks},
  author={Voelker, Aaron and Kaji{\'c}, Ivana and Eliasmith, Chris},
  booktitle={Advances in Neural Information Processing Systems},
  pages={15544--15553},
  year={2019}
}

@inproceedings{chen2018neural,
  title={Neural ordinary differential equations},
  author={Chen, Tian Qi and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  booktitle={Advances in neural information processing systems},
  pages={6571--6583},
  year={2018}
}



% RNN Related Work
@article{lstm,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{jaeger2004harnessing,
  title={Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication},
  author={Jaeger, Herbert and Haas, Harald},
  journal={Science},
  volume={304},
  number={5667},
  pages={78--80},
  year={2004},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{bengio2013advances,
  title={Advances in optimizing recurrent networks},
  author={Bengio, Yoshua and Boulanger-Lewandowski, Nicolas and Pascanu, Razvan},
  booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={8624--8628},
  year={2013},
  organization={IEEE}
}

@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013}
}

@inproceedings{cho2014learning,
  title={Learning phrase representations using {RNN} encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2014}
}

@article{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.3555},
  year={2014}
}

@inproceedings{koutnik2014clockwork,
  title={A clockwork rnn},
  author={Koutnik, Jan and Greff, Klaus and Gomez, Faustino and Schmidhuber, Juergen},
  booktitle={International Conference on Machine Learning},
  pages={1863--1871},
  year={2014},
  organization={PMLR}
}

@inproceedings{neil2016phased,
  title={Phased lstm: Accelerating recurrent network training for long or event-based sequences},
  author={Neil, Daniel and Pfeiffer, Michael and Liu, Shih-Chii},
  booktitle = {Advances in Neural Information Processing Systems ({NeurIPS})},
  year={2016}
}

@inproceedings{chang2017dilated,
  title={Dilated recurrent neural networks},
  author={Chang, Shiyu and Zhang, Yang and Han, Wei and Yu, Mo and Guo, Xiaoxiao and Tan, Wei and Cui, Xiaodong and Witbrock, Michael and Hasegawa-Johnson, Mark and Huang, Thomas S},
  booktitle = {Advances in Neural Information Processing Systems ({NeurIPS})},
  year={2017}
}

@article{dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@inproceedings{jozefowicz2015empirical,
  title={An empirical exploration of recurrent network architectures},
  author={Jozefowicz, Rafal and Zaremba, Wojciech and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={2342--2350},
  year={2015}
}

@article{le2015simple,
  title={A simple way to initialize recurrent networks of rectified linear units},
  author={Le, Quoc V and Jaitly, Navdeep and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1504.00941},
  year={2015}
}

@article{greff2016lstm,
  title={{LSTM}: A search space odyssey},
  author={Greff, Klaus and Srivastava, Rupesh K and Koutn{\'\i}k, Jan and Steunebrink, Bas R and Schmidhuber, J{\"u}rgen},
  journal={IEEE transactions on neural networks and learning systems},
  volume={28},
  number={10},
  pages={2222--2232},
  year={2016},
  publisher={IEEE}
}

@inproceedings{gulcehre2016noisy,
  title={Noisy activation functions},
  author={Gulcehre, Caglar and Moczulski, Marcin and Denil, Misha and Bengio, Yoshua},
  booktitle={The International Conference on Machine Learning (ICML)},
  pages={3059--3068},
  year={2016}
}

@article{krueger2016zoneout,
  title={Zoneout: Regularizing {RNN}s by randomly preserving hidden activations},
  author={Krueger, David and Maharaj, Tegan and Kram{\'a}r, J{\'a}nos and Pezeshki, Mohammad and Ballas, Nicolas and Ke, Nan Rosemary and Goyal, Anirudh and Bengio, Yoshua and Courville, Aaron and Pal, Chris},
  journal={arXiv preprint arXiv:1606.01305},
  year={2016}
}

@inproceedings{tallec2018can,
  title={Can recurrent neural networks warp time?},
  author={Tallec, Corentin and Ollivier, Yann},
  booktitle={The International Conference on Learning Representations ({ICLR})},
  year={2018}
}

@inproceedings{zhang2018learning,
  title={Learning long term dependencies via {F}ourier recurrent units},
  author={Zhang, Jiong and Lin, Yibo and Song, Zhao and Dhillon, Inderjit S},
  booktitle={The International Conference on Machine Learning (ICML)},
  year={2018}
}

@inproceedings{chandar2019towards,
  title={Towards non-saturating recurrent units for modelling long-term dependencies},
  author={Chandar, Sarath and Sankar, Chinnadhurai and Vorontsov, Eugene and Kahou, Samira Ebrahimi and Bengio, Yoshua},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={3280--3287},
  year={2019}
}

@inproceedings{gu2020improving,
  title={Improving the Gating Mechanism of Recurrent Neural Networks},
  author={Gu, Albert and Gulcehre, Caglar and Paine, Tom Le and Hoffman, Matt and Pascanu, Razvan},
  booktitle = {The International Conference on Machine Learning ({ICML})},
  year={2020},
}

@inproceedings{rusch2021coupled,
  title={Coupled Oscillatory Recurrent Neural Network (coRNN): An accurate and (gradient) stable architecture for learning long time dependencies},
  author={Rusch, T. Konstantin and Mishra, Siddhartha},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{chang2019antisymmetricrnn,
  title={AntisymmetricRNN: A dynamical system view on recurrent neural networks},
  author={Chang, Bo and Chen, Minmin and Haber, Eldad and Chi, Ed H},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{kag2020rnns,
  title={Rnns incrementally evolving on an equilibrium manifold: A panacea for vanishing and exploding gradients?},
  author={Kag, Anil and Zhang, Ziming and Saligrama, Venkatesh},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{erichson2021lipschitz,
  title={Lipschitz recurrent neural networks},
  author={Erichson, N Benjamin and Azencot, Omri and Queiruga, Alejandro and Hodgkinson, Liam and Mahoney, Michael W},
  booktitle={International Conference on Learning Representations},
  year={2021}
}




%% Orthogonal RNNs
@inproceedings{arjovsky2016unitary,
  title={Unitary evolution recurrent neural networks},
  author={Arjovsky, Martin and Shah, Amar and Bengio, Yoshua},
  booktitle={The International Conference on Machine Learning (ICML)},
  pages={1120--1128},
  year={2016}
}

@inproceedings{henaff2016recurrent,
  title={Recurrent orthogonal networks and long-memory tasks},
  author={Henaff, Mikael and Szlam, Arthur and LeCun, Yann},
  booktitle={The International Conference on Machine Learning (ICML)},
  year={2016}
}

@inproceedings{mhammedi2017efficient,
  title={Efficient orthogonal parametrisation of recurrent neural networks using householder reflections},
  author={Mhammedi, Zakaria and Hellicar, Andrew and Rahman, Ashfaqur and Bailey, James},
  booktitle={International Conference on Machine Learning},
  pages={2401--2409},
  year={2017},
  organization={PMLR}
}

@inproceedings{vorontsov2017orthogonality,
  title={On orthogonality and learning recurrent networks with long term dependencies},
  author={Vorontsov, Eugene and Trabelsi, Chiheb and Kadoury, Samuel and Pal, Chris},
  booktitle={International Conference on Machine Learning},
  pages={3570--3578},
  year={2017},
  organization={PMLR}
}

@inproceedings{lezcano2019cheap,
  title={Cheap orthogonal constraints in neural networks: A simple parametrization of the orthogonal and unitary group},
  author={Lezcano-Casado, Mario and Mart{\'\i}nez-Rubio, David},
  booktitle={The International Conference on Machine Learning (ICML)},
  year={2019}
}

% Imputation methods
@article{che2018recurrent,
  title={Recurrent neural networks for multivariate time series with missing values},
  author={Che, Zhengping and Purushotham, Sanjay and Cho, Kyunghyun and Sontag, David and Liu, Yan},
  journal={Scientific reports},
  volume={8},
  number={1},
  pages={1--12},
  year={2018},
  publisher={Nature Publishing Group}
}

@inproceedings{rubanova2019latent,
  title={Latent Ordinary Differential Equations for Irregularly-Sampled Time Series},
  author={Rubanova, Yulia and Chen, Tian Qi and Duvenaud, David K},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5321--5331},
  year={2019}
}

@inproceedings{de2019gru,
  title={GRU-ODE-Bayes: Continuous modeling of sporadically-observed time series},
  author={De Brouwer, Edward and Simm, Jaak and Arany, Adam and Moreau, Yves},
  booktitle = {Advances in Neural Information Processing Systems ({NeurIPS})},
  year={2019}
}

@article{lechner2020learning,
  title={Learning long-term dependencies in irregularly-sampled time series},
  author={Lechner, Mathias and Hasani, Ramin},
  journal={arXiv preprint arXiv:2006.04418},
  year={2020}
}

@article{kidger2020neural,
  title={Neural Controlled Differential Equations for Irregular Time Series},
  author={Kidger, Patrick and Morrill, James and Foster, James and Lyons, Terry},
  journal={arXiv preprint arXiv:2005.08926},
  year={2020}
}

@article{morrill2021neural,
  title={Neural Rough Differential Equations for Long Time Series},
  author={Morrill, James and Salvi, Cristopher and Kidger, Patrick and Foster, James and Lyons, Terry},
  journal={The International Conference on Machine Learning (ICML)},
  year={2021}
}



% MNIST baselines
@inproceedings{indrnn,
  title={Independently recurrent neural network ({IndRNN}): Building a longer and deeper {RNN}},
  author={Li, Shuai and Li, Wanqing and Cook, Chris and Zhu, Ce and Gao, Yanbo},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5457--5466},
  year={2018}
}

@inproceedings{trinh2018learning,
  title={Learning longer-term dependencies in {RNNs} with auxiliary losses},
  author={Trinh, Trieu H and Dai, Andrew M and Luong, Minh-Thang and Le, Quoc V},
  booktitle = {The International Conference on Machine Learning ({ICML})},
  year={2018}
}

@article{bai2018empirical,
  title={An empirical evaluation of generic convolutional and recurrent networks for sequence modeling},
  author={Bai, Shaojie and Kolter, J Zico and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1803.01271},
  year={2018}
}

@inproceedings{trellisnet,
  title={Trellis networks for sequence modeling},
  author={Bai, Shaojie and Kolter, J Zico and Koltun, Vladlen},
  booktitle={The International Conference on Learning Representations ({ICLR})},
  year={2019}
}

@inproceedings{vaswani2017attention,
title={Attention Is All You Need},
author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
year={2017},
booktitle = {Advances in Neural Information Processing Systems ({NeurIPS})},
}

@inproceedings{dai2019transformer,
  title={Transformer-{XL}: Attentive language models beyond a fixed-length context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V and Salakhutdinov, Ruslan},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics},
  year={2019}
}

@article{child2019generating,
  title={Generating long sequences with sparse transformers},
  author={Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1904.10509},
  year={2019}
}

@inproceedings{wu2019pay,
  title={Pay less attention with lightweight and dynamic convolutions},
  author={Wu, Felix and Fan, Angela and Baevski, Alexei and Dauphin, Yann N and Auli, Michael},
  booktitle={The International Conference on Learning Representations ({ICLR})},
  year={2019}
}

@inproceedings{sukhbaatar2019adaptive,
  title={Adaptive attention span in transformers},
  author={Sukhbaatar, Sainbayar and Grave, Edouard and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of the Annual Meeting of the Association for Computational Linguistics},
  year={2019}
}

@inproceedings{rae2019compressive,
  title={Compressive Transformers for Long-Range Sequence Modelling},
  author={Rae, Jack W and Potapenko, Anna and Jayakumar, Siddhant M and Lillicrap, Timothy P},
  booktitle={The International Conference on Learning Representations ({ICLR})},
  year={2020}
}

@inproceedings{kitaev2020reformer,
  title={Reformer: The Efficient Transformer},
  author={Kitaev, Nikita and Kaiser, {\L}ukasz and Levskaya, Anselm},
  booktitle = {The International Conference on Machine Learning ({ICML})},
  year={2020}
}

@article{roy2020efficient,
  title={Efficient Content-Based Sparse Attention with Routing Transformers},
  author={Roy, Aurko and Saffar, Mohammad and Vaswani, Ashish and Grangier, David},
  journal={arXiv preprint arXiv:2003.05997},
  year={2020}
}

@inproceedings{katharopoulos2020transformers,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={International Conference on Machine Learning},
  pages={5156--5165},
  year={2020},
  organization={PMLR}
}

@inproceedings{choromanski2020rethinking,
  title={Rethinking attention with performers},
  author={Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and others},
  booktitle={The International Conference on Learning Representations ({ICLR})},
  year={2020}
}

%%% Orthogonal Polynomials, discrete transforms

@book{chihara,
  title={An introduction to orthogonal polynomials},
  author={Chihara, T. S.},
  isbn={9780486479293},
  lccn={2010043412},
  series={Dover Books on Mathematics},
  year={2011},
  publisher={Dover Publications}
}

@book{trefethen2019approximation,
  title={Approximation theory and approximation practice},
  author={Trefethen, Lloyd N},
  volume={164},
  year={2019},
  publisher={SIAM}
}

@book{szego,
  title={Orthogonal Polynomials},
  author={Szeg{\"o}, G.},
  number={v.23},
  isbn={9780821889527},
  lccn={lc39033497},
  series={American Mathematical Society colloquium publications},
  year={1967},
  publisher={American Mathematical Society}
}

@book{szego1975orthogonal,
  title={Orthogonal Polynomials},
  author={Szeg{\H{o}}, G.},
  isbn={9780821810231},
  lccn={77476087},
  series={American Mathematical Society: Colloquium publications},
  year={1975},
  publisher={American Mathematical Society}
}

@book{proakis2001digital,
  title={Digital signal processing: principles algorithms and applications},
  author={Proakis, John G},
  year={2001},
  publisher={Pearson Education India}
}

@book{korner1989fourier,
  title={{F}ourier analysis},
  author={K{\"o}rner, Thomas William},
  year={1989},
  publisher={Cambridge university press}
}

@book{boyd2001chebyshev,
  title={Chebyshev and Fourier spectral methods},
  author={Boyd, John P},
  year={2001},
  publisher={Courier Corporation}
}

@book{arfken2005mathematical,
  title={Mathematical methods for physicists},
  author={Arfken, George B and Weber, Hans J},
  year={2005},
  publisher={Elsevier Academic Press}
}

% OP Related Work
@inproceedings{defferrard2016convolutional,
  title={Convolutional neural networks on graphs with fast localized spectral filtering},
  author={Defferrard, Micha{\"e}l and Bresson, Xavier and Vandergheynst, Pierre},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={3844--3852},
  year={2016}
}

@inproceedings{dao2017gaussian,
  title = {{G}aussian Quadrature for Kernel Features},
  author = {Dao, Tri and De Sa, Christopher M and R\'{e}, Christopher},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  pages = {6107--6117},
  year = {2017}
}

@inproceedings{de2018two,
  title={A two-pronged progress in structured dense matrix vector multiplication},
  author={De Sa, Christopher and Gu, Albert and Puttagunta, Rohan and R{\'e}, Christopher and Rudra, Atri},
  booktitle={Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={1060--1079},
  year={2018},
  organization={SIAM}
}

@inproceedings{thomas2018learning,
  title={Learning compressed transforms with low displacement rank},
  author={Thomas, Anna and Gu, Albert and Dao, Tri and Rudra, Atri and R{\'e}, Christopher},
  booktitle={Advances in neural information processing systems},
  pages={9052--9060},
  year={2018}
}

@inproceedings{dao2019learning,
  title={Learning Fast Algorithms for Linear Transforms Using Butterfly Factorizations},
  author={Dao, Tri and Gu, Albert and Eichhorn, Matthew and Rudra, Atri and R{\'e}, Christopher},
  booktitle = {The International Conference on Machine Learning ({ICML})},
  year={2019},
}

@inproceedings{alizadeh2019butterfly,
  title={Butterfly Transform: An Efficient {FFT} Based Neural Architecture Design},
  author={Alizadeh, Keivan and Farhadi, Ali and Rastegari, Mohammad},
  booktitle = {The Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020},
}

@inproceedings{dao2020kaleidoscope,
  title={Kaleidoscope: An Efficient, Learnable Representation For All Structured Linear Maps},
  author={Dao, Tri and Sohoni, Nimit and Gu, Albert and Eichhorn, Matthew and Blonder, Amit and Leszczynski, Megan and Rudra, Atri and Ré, Christopher},
  booktitle={The International Conference on Learning Representations ({ICLR})},
  year={2020}
}

@inproceedings{yang2019mean,
  title={A mean field theory of batch normalization},
  author={Yang, Greg and Pennington, Jeffrey and Rao, Vinay and Sohl-Dickstein, Jascha and Schoenholz, Samuel S},
  booktitle={The International Conference on Learning Representations ({ICLR})},
  year={2019}
}

@article{berthier2020accelerated,
  title={Accelerated Gossip in Networks of Given Dimension using {J}acobi Polynomial Iterations},
  author={Berthier, Rapha{\"e}l and Bach, Francis and Gaillard, Pierre},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={2},
  number={1},
  pages={24--47},
  year={2020},
  publisher={SIAM}
}

% sliding transforms

@article{chen2015fast,
  title={Fast computation of sliding discrete {T}chebichef moments and its application in duplicated regions detection},
  author={Chen, Beijing and Coatrieux, Gouenou and Wu, Jiasong and Dong, Zhifang and Coatrieux, Jean Louis and Shu, Huazhong},
  journal={IEEE Transactions on Signal Processing},
  volume={63},
  number={20},
  pages={5424--5436},
  year={2015},
  publisher={IEEE}
}

@article{farhang1994generalized,
  title={Generalized sliding {FFT} and its application to implementation of block {LMS} adaptive filters},
  author={Farhang-Boroujeny, Behrouz and Gazor, Saeed},
  journal={IEEE Transactions on Signal Processing},
  volume={42},
  number={3},
  pages={532--538},
  year={1994},
  publisher={IEEE}
}

@article{jacobsen2003sliding,
  title={The sliding {DFT}},
  author={Jacobsen, Eric and Lyons, Richard},
  journal={IEEE Signal Processing Magazine},
  volume={20},
  number={2},
  pages={74--80},
  year={2003},
  publisher={IEEE}
}

@article{jacobsen2004update,
  title={An update to the sliding {DFT}},
  author={Jacobsen, Eric and Lyons, Richard},
  journal={IEEE Signal Processing Magazine},
  volume={21},
  number={1},
  pages={110--111},
  year={2004},
  publisher={IEEE}
}

@article{duda2010accurate,
  title={Accurate, guaranteed stable, sliding discrete {F}ourier transform [{DSP} tips \& tricks]},
  author={Duda, Krzysztof},
  journal={IEEE Signal Processing Magazine},
  volume={27},
  number={6},
  pages={124--127},
  year={2010},
  publisher={IEEE}
}

@article{kober2004fast,
  title={Fast algorithms for the computation of sliding discrete sinusoidal transforms},
  author={Kober, Vitaly},
  journal={IEEE transactions on signal processing},
  volume={52},
  number={6},
  pages={1704--1710},
  year={2004},
  publisher={IEEE}
}

@article{kober2007fast,
  title={Fast algorithms for the computation of sliding discrete {H}artley transforms},
  author={Kober, Vitaly},
  journal={IEEE transactions on signal processing},
  volume={55},
  number={6},
  pages={2937--2944},
  year={2007},
  publisher={IEEE}
}

@inproceedings{mozafari2007efficient,
  title={An efficient recursive algorithm and an explicit formula for calculating update vectors of running {W}alsh-{H}adamard transform},
  author={Mozafari, Barzan and Savoji, Mohammad H},
  booktitle={2007 9th International Symposium on Signal Processing and Its Applications},
  pages={1--4},
  year={2007},
  organization={IEEE}
}
@article{ouyang2009fast,
  title={Fast algorithm for {W}alsh {H}adamard transform on sliding windows},
  author={Ouyang, Wanli and Cham, Wai-Kuen},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={32},
  number={1},
  pages={165--171},
  year={2009},
  publisher={IEEE}
}
@article{wu2012sliding,
  title={Sliding conjugate symmetric sequency-ordered complex {H}adamard transform: fast algorithm and applications},
  author={Wu, Jiasong and Wang, Lu and Yang, Guanyu and Senhadji, Lotfi and Luo, Limin and Shu, Huazhong},
  journal={IEEE Transactions on Circuits and Systems I: Regular Papers},
  volume={59},
  number={6},
  pages={1321--1334},
  year={2012},
  publisher={IEEE}
}

@article{macias2005efficient,
  title={Efficient computation of the running discrete {H}aar transform},
  author={Macias, Jose A Rosendo and Exposito, Antonio Gomez},
  journal={IEEE transactions on power delivery},
  volume={21},
  number={1},
  pages={504--505},
  year={2005},
  publisher={IEEE}
}

% EEG citation
@article{saab2020weak,
  title={Weak supervision as an efficient approach for automated seizure detection in electroencephalography},
  author={Saab, Khaled and Dunnmon, Jared and R{\'e}, Christopher and Rubin, Daniel and Lee-Messer, Christopher},
  journal={{NPJ} Digital Medicine},
  volume={3},
  number={1},
  pages={1--12},
  year={2020},
  publisher={Nature Publishing Group}
}
@article{shah2018temple,
  title={The {T}emple {U}niversity hospital seizure detection corpus},
  author={Shah, Vinit and Von Weltin, Eva and Lopez, Silvia and McHugh, James Riley and Veloso, Lillian and Golmohammadi, Meysam and Obeid, Iyad and Picone, Joseph},
  journal={Frontiers in neuroinformatics},
  volume={12},
  pages={83},
  year={2018},
  publisher={Frontiers}
}

% ODEs and discretization
@book{iserles2009first,
  title={A first course in the numerical analysis of differential equations},
  author={Iserles, Arieh},
  number={44},
  year={2009},
  publisher={Cambridge university press}
}

@inproceedings{dupont2019augmented,
  title={Augmented neural {ODE}s},
  author={Dupont, Emilien and Doucet, Arnaud and Teh, Yee Whye},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3134--3144},
  year={2019}
}

@inproceedings{quaglino2020snode,
  title={{SNODE}: Spectral Discretization of Neural {ODE}s for System Identification},
  author={Quaglino, Alessio and Gallieri, Marco and Masci, Jonathan and Koutn{\'\i}k, Jan},
  booktitle={The International Conference on Learning Representations ({ICLR})},
  year={2020}
}

@inproceedings{finlay2020train,
  title={How to train your neural {ODE}: the world of {J}acobian and kinetic regularization},
  author={Finlay, Chris and Jacobsen, J{\"o}rn-Henrik and Nurbekyan, Levon and Oberman, Adam M},
  booktitle = {The International Conference on Machine Learning ({ICML})},
  year={2020},
}

@article{massaroli2020stable,
  title={Stable Neural Flows},
  author={Massaroli, Stefano and Poli, Michael and Bin, Michelangelo and Park, Jinkyoo and Yamashita, Atsushi and Asama, Hajime},
  journal={arXiv preprint arXiv:2003.08063},
  year={2020}
}

@inproceedings{zhang2019approximation,
  title={Approximation capabilities of neural ordinary differential equations},
  author={Zhang, Han and Gao, Xi and Unterman, Jacob and Arodz, Tom},
  booktitle = {The International Conference on Machine Learning ({ICML})},
  year={2020},
}

@article{zhang2007performance,
  title={Performance recovery in digital implementation of analogue systems},
  author={Zhang, Guofeng and Chen, Tongwen and Chen, Xiang},
  journal={{SIAM} journal on control and optimization},
  volume={45},
  number={6},
  pages={2207--2223},
  year={2007},
  publisher={SIAM}
}

@book{decarlo1989linear,
  title={Linear systems: A state variable approach with numerical implementation},
  author={DeCarlo, Raymond A},
  year={1989},
  publisher={Prentice-Hall, Inc.}
}

@article{funahashi1993approximation,
  title={Approximation of dynamical systems by continuous time recurrent neural networks},
  author={Funahashi, Ken-ichi and Nakamura, Yuichi},
  journal={Neural networks},
  volume={6},
  number={6},
  pages={801--806},
  year={1993},
  publisher={Elsevier}
}

@article{zhang2014comprehensive,
  title={A comprehensive review of stability analysis of continuous-time recurrent neural networks},
  author={Zhang, Huaguang and Wang, Zhanshan and Liu, Derong},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  volume={25},
  number={7},
  pages={1229--1262},
  year={2014},
  publisher={IEEE}
}

@article{niu2019recurrent,
  title={Recurrent neural networks in the eye of differential equations},
  author={Niu, Murphy Yuezhen and Horesh, Lior and Chuang, Isaac},
  journal={arXiv preprint arXiv:1904.12933},
  year={2019}
}

@article{jordan2021gated,
  title={Gated recurrent units viewed through the lens of continuous time dynamical systems},
  author={Jordan, Ian D and Sok{\'o}{\l}, Piotr Aleksander and Park, Il Memming},
  journal={Frontiers in computational neuroscience},
  pages={67},
  year={2021},
  publisher={Frontiers}
}

@article{friston2003dynamic,
  title={Dynamic causal modelling},
  author={Friston, Karl J and Harrison, Lee and Penny, Will},
  journal={Neuroimage},
  volume={19},
  number={4},
  pages={1273--1302},
  year={2003},
  publisher={Elsevier}
}

@inproceedings{hasani2021liquid,
  title={Liquid time-constant networks},
  author={Hasani, Ramin and Lechner, Mathias and Amini, Alexander and Rus, Daniela and Grosu, Radu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2021}
}

@article{hasani2021closed,
  title={Closed-form Continuous-Depth Models},
  author={Hasani, Ramin and Lechner, Mathias and Amini, Alexander and Liebenwein, Lucas and Tschaikowski, Max and Teschl, Gerald and Rus, Daniela},
  journal={arXiv preprint arXiv:2106.13898},
  year={2021}
}

%%% Datasets

@article{bagnall2018uea,
  title={The {UEA} multivariate time series classification archive, 2018},
  author={Bagnall, Anthony and Dau, Hoang Anh and Lines, Jason and Flynn, Michael and Large, James and Bostrom, Aaron and Southam, Paul and Keogh, Eamonn},
  journal={arXiv preprint arXiv:1811.00075},
  year={2018}
}

@misc{Dua:2019,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@inproceedings{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={The International Conference on Learning Representations ({ICLR})},
  year={2015}
}

@article{mackey1977oscillation,
  title={Oscillation and chaos in physiological control systems},
  author={Mackey, Michael C and Glass, Leon},
  journal={Science},
  volume={197},
  number={4300},
  pages={287--289},
  year={1977},
  publisher={American Association for the Advancement of Science}
}

@InProceedings{maas-EtAl:2011:ACL-HLT2011,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}



%%%%%%%% Recent papers: sort them and add conferences (ICML2021)

@article{chilkuri2021parallelizing,
  title={Parallelizing Legendre Memory Unit Training},
  author={Chilkuri, Narsimha and Eliasmith, Chris},
  journal={The International Conference on Machine Learning (ICML)},
  year={2021}
}

@article{rusch2021unicornn,
  title={UnICORNN: A recurrent model for learning very long time dependencies},
  author={Rusch, T Konstantin and Mishra, Siddhartha},
  journal={The International Conference on Machine Learning (ICML)},
  year={2021}
}

@article{romero2021ckconv,
  title={CKConv: Continuous Kernel Convolution For Sequential Data},
  author={Romero, David W and Kuzina, Anna and Bekkers, Erik J and Tomczak, Jakub M and Hoogendoorn, Mark},
  journal={arXiv preprint arXiv:2102.02611},
  year={2021}
}

@inproceedings{romero2022flexconv,
  title={Flexconv: Continuous kernel convolutions with differentiable kernel sizes},
  author={Romero, David W and Bruintjes, Robert-Jan and Tomczak, Jakub M and Bekkers, Erik J and Hoogendoorn, Mark and van Gemert, Jan C},
  booktitle={The International Conference on Learning Representations ({ICLR})},
  year={2022}
}

@inproceedings{gu2020hippo,
  title     = {HiPPO: Recurrent Memory with Optimal Polynomial Projections},
  author    = {Gu, Albert and Dao, Tri and Ermon, Stefano and Rudra, Atri and R{\'{e}}, Christopher},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2020}
}

@article{
  Tan2020TSER,
  title={Time Series Extrinsic Regression}, 
  author={Tan, Chang Wei and Bergmeir, Christoph and Petitjean, Francois and Webb, Geoffrey I},
  journal={Data Mining and Knowledge Discovery},
  pages={1--29},
  year={2021},
  publisher={Springer},
  doi={https://doi.org/10.1007/s10618-021-00745-9}
}

@book{golub2013matrix,
  title={Matrix computations},
  author={Golub, Gene H and Van Loan, Charles F},
  volume={3},
  year={2013},
  publisher={JHU press}
}

@article{van2021deep,
  title={Deep learning in histopathology: the path to the clinic},
  author={van der Laak, Jeroen and Litjens, Geert and Ciompi, Francesco},
  journal={Nature Medicine},
  volume={27},
  number={5},
  pages={775--784},
  year={2021},
  publisher={Nature Publishing Group}
}

@book{shoup2009computational,
  title={A computational introduction to number theory and algebra},
  author={Shoup, Victor},
  year={2009},
  publisher={Cambridge university press}
}

@inproceedings{pytorch-kaldi,
  title    = {The PyTorch-Kaldi Speech Recognition Toolkit},
  author    = {M. Ravanelli and T. Parcollet and Y. Bengio},
  booktitle    = {In Proc. of ICASSP},
  year    = {2019}
}

@book{williams2007linear,
  title={Linear state-space control systems},
  author={Williams, Robert L and Lawrence, Douglas A and others},
  year={2007},
  publisher={Wiley Online Library}
}

@article{lei2017simple,
  title={Simple recurrent units for highly parallelizable recurrence},
  author={Lei, Tao and Zhang, Yu and Wang, Sida I and Dai, Hui and Artzi, Yoav},
  journal={arXiv preprint arXiv:1709.02755},
  year={2017}
}

@article{bradbury2016quasi,
  title={Quasi-recurrent neural networks},
  author={Bradbury, James and Merity, Stephen and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1611.01576},
  year={2016}
}

@article{merity2018scalable,
  title={Scalable Language Modeling: WikiText-103 on a Single GPU in 12 hours},
  author={Merity, Stephen and Keskar, Nitish Shirish and Bradbury, James and Socher, Richard},
  journal={SysML},
  year={2018}
}

@inproceedings{dauphin2017language,
  title={Language modeling with gated convolutional networks},
  author={Dauphin, Yann N and Fan, Angela and Auli, Michael and Grangier, David},
  booktitle={International conference on machine learning},
  pages={933--941},
  year={2017},
  organization={PMLR}
}

@article{shazeer2020glu,
  title={GLU variants improve transformer},
  author={Shazeer, Noam},
  journal={arXiv preprint arXiv:2002.05202},
  year={2020}
}

@article{rae2018fast,
  title={Fast Parametric Learning with Activation Memorization},
  author={Rae, Jack and Dyer, Chris and Dayan, Peter and Lillicrap, Timothy},
  journal={The International Conference on Machine Learning (ICML)},
  year={2018}
}

@article{baevski2018adaptive,
  title={Adaptive input representations for neural language modeling},
  author={Baevski, Alexei and Auli, Michael},
  journal={arXiv preprint arXiv:1809.10853},
  year={2018}
}

@inproceedings{lioutas2020time,
  title={Time-aware large kernel convolutions},
  author={Lioutas, Vasileios and Guo, Yuhong},
  booktitle={International Conference on Machine Learning},
  pages={6172--6183},
  year={2020},
  organization={PMLR}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{tolstikhin2021mlp,
  title={Mlp-mixer: An all-mlp architecture for vision},
  author={Tolstikhin, Ilya and Houlsby, Neil and Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Unterthiner, Thomas and Yung, Jessica and Keysers, Daniel and Uszkoreit, Jakob and Lucic, Mario and others},
  journal={arXiv preprint arXiv:2105.01601},
  year={2021}
}

%%% Generation baselines
@article{salimans2017pixelcnn++,
  title={Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications},
  author={Salimans, Tim and Karpathy, Andrej and Chen, Xi and Kingma, Diederik P},
  journal={arXiv preprint arXiv:1701.05517},
  year={2017}
}

@article{ramachandran2017fast,
  title={Fast generation for convolutional autoregressive models},
  author={Ramachandran, Prajit and Paine, Tom Le and Khorrami, Pooya and Babaeizadeh, Mohammad and Chang, Shiyu and Zhang, Yang and Hasegawa-Johnson, Mark A and Campbell, Roy H and Huang, Thomas S},
  journal={arXiv preprint arXiv:1704.06001},
  year={2017}
}

@inproceedings{liu2015image,
  added-at = {2018-10-09T00:00:00.000+0200},
  author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  biburl = {https://www.bibsonomy.org/bibtex/250e4959be61db325d2f02c1d8cd7bfbb/dblp},
  booktitle = {ICCV},
  ee = {http://doi.ieeecomputersociety.org/10.1109/ICCV.2015.425},
  interhash = {3f735aaa11957e73914bbe2ca9d5e702},
  intrahash = {50e4959be61db325d2f02c1d8cd7bfbb},
  isbn = {978-1-4673-8391-2},
  keywords = {dblp},
  pages = {3730-3738},
  publisher = {IEEE Computer Society},
  timestamp = {2018-10-11T11:43:28.000+0200},
  title = {Deep Learning Face Attributes in the Wild.},
  url = {http://dblp.uni-trier.de/db/conf/iccv/iccv2015.html#LiuLWT15},
  year = 2015
}

@inproceedings{pernet2016computing,
  title={Computing with quasiseparable matrices},
  author={Pernet, Cl{\'e}ment},
  booktitle={Proceedings of the ACM on International Symposium on Symbolic and Algebraic Computation},
  pages={389--396},
  year={2016}
}

%%% Atri OP citations

@book{ArfkenGeorgeB.GeorgeBrown2013Mmfp,
abstract = {"Now in its 7th edition, Mathematical Methods for Physicists continues to provide all the mathematical methods that aspiring scientists and engineers are likely to encounter as students and beginning researchers. This bestselling text provides mathematical relations and their proofs essential to the study of physics and related fields. While retaining the key features of the 6th edition, the new edition provides a more careful balance of explanation, theory, and examples. Taking a problem-solving-skills approach to incorporating theorems with applications, the book's improved focus will help students succeed throughout their academic careers and well into their professions. Some notable enhancements include more refined and focused content in important topics, improved organization, updated notations, extensive explanations and intuitive exercise sets, a wider range of problem solutions, improvement in the placement, and a wider range of difficulty of exercises"--Publisher's description},
publisher = {Academic Press},
booktitle = {Mathematical methods for physicists : a comprehensive guide},
isbn = {0-12-384654-4},
year = {2013},
title = {Mathematical methods for physicists : a comprehensive guide / George B. Arfken, Hans J. Weber, Frank E. Harris},
edition = {7th ed.},
language = {eng},
address = {Amsterdam},
author = {Arfken, George B. (George Brown) and Weber, Hans Jürgen and Harris, Frank E},
keywords = {Mathematics; Mathematical physics; Mathematics; Physical Sciences & Mathematics; Mathematics - General},
}

@Inbook{Shen2011,
author="Shen, Jie
and Tang, Tao
and Wang, Li-Lian",
title="Orthogonal Polynomials and Related Approximation Results",
bookTitle="Spectral Methods: Algorithms, Analysis and Applications",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="47--140",
abstract="The Fourier spectral method is only appropriate for problems with periodic boundary conditions. If a Fourier method is applied to a non-periodic problem, it inevitably induces the so-called Gibbs phenomenon, and reduces the global convergence rate to O(N-1) (cf. Gottlieb and Orszag (1977)). Consequently, one should not apply a Fourier method to problems with non-periodic boundary conditions. Instead, one should use orthogonal polynomials which are eigenfunctions of some singular Sturm-Liouville problems. The commonly used orthogonal polynomials include the Legendre, Chebyshev, Hermite and Laguerre polynomials.",
isbn="978-3-540-71041-7",
doi="10.1007/978-3-540-71041-7_3",
url="https://doi.org/10.1007/978-3-540-71041-7_3"
}

@article{EG99,
author="Eidelman, Y. and Gohberg, I.",
title="On a new class of structured matrices",
journal="Integral Equations and Operator Theory",
volume="34",
year="1999"}

@article{woodbury1950,
  title={Inverting modified matrices},
  author={Woodbury, Max A},
  journal={Memorandum report},
  volume={42},
  pages={106},
  year={1950},
  publisher={Statistical Research Group, Princeton University}
}

@book{butcher2008numerical,
  title={Numerical methods for ordinary differential equations},
  author={Butcher, John Charles and Goodwin, Nicolette},
  volume={2},
  year={2008},
  publisher={Wiley Online Library}
}

@article{petersen2012matrix,
  title={The matrix cookbook, version 20121115},
  author={Petersen, KB and Pedersen, MS},
  journal={Technical Univ. Denmark, Kongens Lyngby, Denmark, Tech. Rep},
  volume={3274},
  year={2012}
}

@article{liu2020understanding,
  title={Understanding the difficulty of training transformers},
  author={Liu, Liyuan and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu and Han, Jiawei},
  journal={The International Conference on Machine Learning (ICML)},
  year={2020}
}

@inproceedings{davis2021catformer,
  title={Catformer: Designing Stable Transformers via Sensitivity Analysis},
  author={Davis, Jared Quincy and Gu, Albert and Dao, Tri and Choromanski, Krzysztof and R\'e, Christopher and Liang, Percy and Finn, Chelsea},
  booktitle={The International Conference on Machine Learning (ICML)},
  year={2021}
}

@article{oord2016wavenet,
  title={Wavenet: A generative model for raw audio},
  author={Oord, Aaron van den and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1609.03499},
  year={2016}
}


@inproceedings{gu2021lssl,
  title = {Combining recurrent, convolutional, and continuous-time models with the structured learnable linear state space layer},
  author = {Gu, Albert and Johnson, Isys and Goel, Karan and Saab, Khaled and Dao, Tri and Rudra, Atri and R\'{e}, Christopher},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2021}
}

@book{pan2001structured,
  title={Structured matrices and polynomials: unified superfast algorithms},
  author={Pan, Victor},
  year={2001},
  publisher={Springer Science \& Business Media}
}

@article{pan2015transformations,
  title={Transformations of matrix structures work again},
  author={Pan, Victor Y},
  journal={Linear Algebra and Its Applications},
  volume={465},
  pages={107--138},
  year={2015},
  publisher={Elsevier}
}

@article{pan2016bad,
  title={How bad are Vandermonde matrices?},
  author={Pan, Victor Y},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={37},
  number={2},
  pages={676--694},
  year={2016},
  publisher={SIAM}
}


@article{pan2017fast,
  title={Fast approximate computations with Cauchy matrices and polynomials},
  author={Pan, Victor},
  journal={Mathematics of Computation},
  volume={86},
  number={308},
  pages={2799--2826},
  year={2017}
}


@inproceedings{tay2021long,
    title={Long Range Arena : A Benchmark for Efficient Transformers },
    author={Yi Tay and Mostafa Dehghani and Samira Abnar and Yikang Shen and Dara Bahri and Philip Pham and Jinfeng Rao and Liu Yang and Sebastian Ruder and Donald Metzler},
    booktitle={International Conference on Learning Representations},
    year={2021},
    url={https://openreview.net/forum?id=qVyeW-grC2k}
}

@inproceedings{Donahue2019AdversarialAS,
  title={Adversarial Audio Synthesis},
  author={Chris Donahue and Julian McAuley and Miller Puckette},
  booktitle={ICLR},
  year={2019}
}

@article{tustin1947method,
  title={A method of analysing the behaviour of linear systems in terms of time series},
  author={Tustin, Arnold},
  journal={Journal of the Institution of Electrical Engineers-Part IIA: Automatic Regulators and Servo Mechanisms},
  volume={94},
  number={1},
  pages={130--142},
  year={1947},
  publisher={IET}
}

@article{Warden2018SpeechCA,
  title={Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition},
  author={Pete Warden},
  journal={ArXiv},
  year={2018},
  volume={abs/1804.03209}
}

@inproceedings{haoyietal-informer-2021,
  author    = {Haoyi Zhou and
               Shanghang Zhang and
               Jieqi Peng and
               Shuai Zhang and
               Jianxin Li and
               Hui Xiong and
               Wancai Zhang},
  title     = {Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting},
  booktitle = {The Thirty-Fifth {AAAI} Conference on Artificial Intelligence, {AAAI} 2021, Virtual Conference},
  volume    = {35},
  number    = {12},
  pages     = {11106--11115},
  publisher = {{AAAI} Press},
  year      = {2021},
}

@inproceedings{gu2022efficiently,
  title={Efficiently Modeling Long Sequences with Structured State Spaces},
  author={Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  booktitle={The International Conference on Learning Representations ({ICLR})},
  year={2022}
}

@article{goel2022sashimi,
  title={It's Raw! Audio Generation with State-Space Models},
  author={Goel, Karan and Gu, Albert and Donahue, Chris and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2202.09729},
  year={2022}
}

@article{gupta2022diagonal,
  title={Diagonal State Spaces are as Effective as Structured State Spaces},
  author={Gupta, Ankit},
  journal={arXiv preprint arXiv:2203.14343},
  year={2022}
}

% Normalization stuff

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={PMLR}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@misc{he2015delving,
      title={Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1502.01852},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{hochreiter1991untersuchungen,
  title={Untersuchungen zu dynamischen neuronalen Netzen},
  author={Hochreiter, Sepp},
  journal={Diploma, Technische Universit{\"a}t M{\"u}nchen},
  volume={91},
  number={1},
  year={1991}
}

@book{ralston2001first,
  title={A first course in numerical analysis},
  author={Ralston, Anthony and Rabinowitz, Philip},
  year={2001},
  publisher={Courier Corporation}
}

@article{gu2022hippo,
  title={How to Train Your HiPPO: State Space Models with Generalized Basis Projections},
  author={Gu, Albert and Johnson, Isys and Timalsina, Aman and Rudra, Atri and R\'e, Christopher},
  journal={arXiv preprint arXiv:2206.12037},
  year={2022}
}


@article{gu2022s4d,
  title={On the Parameterization and Initialization of Diagonal State Space Models},
  author={Gu, Albert and Gupta, Ankit and Goel, Karan and R\'e, Christopher},
  journal={arXiv preprint arXiv:2206.11893},
  year={2022}
}

@inproceedings{nonaka2021depth,
  title={In-depth benchmarking of deep neural network architectures for ECG diagnosis},
  author={Nonaka, Naoki and Seita, Jun},
  booktitle={Machine Learning for Healthcare Conference},
  pages={414--439},
  year={2021},
  organization={PMLR}
}
