\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Guidotti et~al.(2018)Guidotti, Monreale, Ruggieri, Turini, Giannotti,
  and Pedreschi]{guidotti2018survey}
Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini, Fosca
  Giannotti, and Dino Pedreschi.
\newblock A survey of methods for explaining black box models.
\newblock \emph{ACM computing surveys (CSUR)}, 51\penalty0 (5):\penalty0 1--42,
  2018.

\bibitem[Adadi and Berrada(2018)]{adadi2018peeking}
Amina Adadi and Mohammed Berrada.
\newblock Peeking inside the black-box: a survey on explainable artificial
  intelligence (xai).
\newblock \emph{IEEE access}, 6:\penalty0 52138--52160, 2018.

\bibitem[Arrieta et~al.(2020)Arrieta, D{\'\i}az-Rodr{\'\i}guez, Del~Ser,
  Bennetot, Tabik, Barbado, Garc{\'\i}a, Gil-L{\'o}pez, Molina, Benjamins,
  et~al.]{arrieta2020explainable}
Alejandro~Barredo Arrieta, Natalia D{\'\i}az-Rodr{\'\i}guez, Javier Del~Ser,
  Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garc{\'\i}a, Sergio
  Gil-L{\'o}pez, Daniel Molina, Richard Benjamins, et~al.
\newblock Explainable artificial intelligence (xai): Concepts, taxonomies,
  opportunities and challenges toward responsible ai.
\newblock \emph{Information fusion}, 58:\penalty0 82--115, 2020.

\bibitem[Koh et~al.(2020)Koh, Nguyen, Tang, Mussmann, Pierson, Kim, and
  Liang]{koh2020concept}
Pang~Wei Koh, Thao Nguyen, Yew~Siang Tang, Stephen Mussmann, Emma Pierson, Been
  Kim, and Percy Liang.
\newblock Concept bottleneck models.
\newblock In \emph{International conference on machine learning}, pages
  5338--5348. PMLR, 2020.

\bibitem[Alvarez~Melis and Jaakkola(2018)]{alvarez2018towards}
David Alvarez~Melis and Tommi Jaakkola.
\newblock Towards robust interpretability with self-explaining neural networks.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Chen et~al.(2020)Chen, Bei, and Rudin]{chen2020concept}
Zhi Chen, Yijie Bei, and Cynthia Rudin.
\newblock Concept whitening for interpretable image recognition.
\newblock \emph{Nature Machine Intelligence}, 2\penalty0 (12):\penalty0
  772--782, 2020.

\bibitem[Zarlenga et~al.(2023)Zarlenga, Barbiero, Shams, Kazhdan, Bhatt,
  Weller, and Jamnik]{zarlenga2023towards}
Mateo~Espinosa Zarlenga, Pietro Barbiero, Zohreh Shams, Dmitry Kazhdan, Umang
  Bhatt, Adrian Weller, and Mateja Jamnik.
\newblock Towards robust metrics for concept representation evaluation.
\newblock \emph{arXiv preprint arXiv:2301.10367}, 2023.

\bibitem[Kim et~al.(2023)Kim, Jung, Park, Kim, and Yoon]{kim2023probabilistic}
Eunji Kim, Dahuin Jung, Sangha Park, Siwon Kim, and Sungroh Yoon.
\newblock Probabilistic concept bottleneck models.
\newblock \emph{arXiv preprint arXiv:2306.01574}, 2023.

\bibitem[Rudin(2019)]{rudin2019stop}
Cynthia Rudin.
\newblock Stop explaining black box machine learning models for high stakes
  decisions and use interpretable models instead.
\newblock \emph{Nature machine intelligence}, 1\penalty0 (5):\penalty0
  206--215, 2019.

\bibitem[Poeta et~al.(2023)Poeta, Ciravegna, Pastor, Cerquitelli, and
  Baralis]{poeta2023concept}
Eleonora Poeta, Gabriele Ciravegna, Eliana Pastor, Tania Cerquitelli, and Elena
  Baralis.
\newblock Concept-based explainable artificial intelligence: A survey.
\newblock \emph{arXiv preprint arXiv:2312.12936}, 2023.

\bibitem[Barbiero et~al.(2023)Barbiero, Ciravegna, Giannini, Zarlenga,
  Magister, Tonda, Lio', Precioso, Jamnik, and
  Marra]{barbiero2023interpretable}
Pietro Barbiero, Gabriele Ciravegna, Francesco Giannini, Mateo~Espinosa
  Zarlenga, Lucie~Charlotte Magister, Alberto Tonda, Pietro Lio', Frederic
  Precioso, Mateja Jamnik, and Giuseppe Marra.
\newblock Interpretable neural-symbolic concept reasoning.
\newblock In \emph{ICML}, 2023.

\bibitem[Weston et~al.(2014)Weston, Chopra, and Bordes]{weston2014memory}
Jason Weston, Sumit Chopra, and Antoine Bordes.
\newblock Memory networks.
\newblock \emph{arXiv preprint arXiv:1410.3916}, 2014.

\bibitem[Hornik et~al.(1989)Hornik, Stinchcombe, and
  White]{hornik1989multilayer}
Kurt Hornik, Maxwell Stinchcombe, and Halbert White.
\newblock Multilayer feedforward networks are universal approximators.
\newblock \emph{Neural networks}, 2\penalty0 (5):\penalty0 359--366, 1989.

\bibitem[Rosch(1978)]{rosch1978principles}
Eleanor Rosch.
\newblock Principles of categorization.
\newblock In \emph{Cognition and categorization}, pages 27--48. Routledge,
  1978.

\bibitem[Rudin et~al.(2022)Rudin, Chen, Chen, Huang, Semenova, and
  Zhong]{rudin2022interpretable}
Cynthia Rudin, Chaofan Chen, Zhi Chen, Haiyang Huang, Lesia Semenova, and Chudi
  Zhong.
\newblock Interpretable machine learning: Fundamental principles and 10 grand
  challenges.
\newblock \emph{Statistic Surveys}, 16:\penalty0 1--85, 2022.

\bibitem[Li et~al.(2018)Li, Liu, Chen, and Rudin]{li2018deep}
Oscar Li, Hao Liu, Chaofan Chen, and Cynthia Rudin.
\newblock Deep learning for case-based reasoning through prototypes: A neural
  network that explains its predictions.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem[Chen et~al.(2019)Chen, Li, Tao, Barnett, Rudin, and Su]{chen2019looks}
Chaofan Chen, Oscar Li, Daniel Tao, Alina Barnett, Cynthia Rudin, and
  Jonathan~K Su.
\newblock This looks like that: deep learning for interpretable image
  recognition.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Diligenti et~al.(2017)Diligenti, Gori, and
  Sacca]{diligenti2017semantic}
Michelangelo Diligenti, Marco Gori, and Claudio Sacca.
\newblock Semantic-based regularization for learning and inference.
\newblock \emph{Artificial Intelligence}, 244:\penalty0 143--165, 2017.

\bibitem[Kusner et~al.(2017)Kusner, Loftus, Russell, and Silva]{Kusner2017}
Matt~J Kusner, Joshua Loftus, Chris Russell, and Ricardo Silva.
\newblock Counterfactual fairness.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Cussens(2001)]{cussens2001parameter}
James Cussens.
\newblock Parameter estimation in stochastic logic programs.
\newblock \emph{Machine Learning}, 44:\penalty0 245--271, 2001.

\bibitem[Winters et~al.(2022)Winters, Marra, Manhaeve, and
  Raedt]{Winters_Marra_Manhaeve_Raedt_2022}
Thomas Winters, Giuseppe Marra, Robin Manhaeve, and Luc~De Raedt.
\newblock Deepstochlog: Neural stochastic logic programming.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  36\penalty0 (9):\penalty0 10090--10100, Jun. 2022.
\newblock \doi{10.1609/aaai.v36i9.21248}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/21248}.

\bibitem[Manhaeve et~al.(2018)Manhaeve, Dumancic, Kimmig, Demeester, and
  Raedt]{manhaeve2018deepproblog}
Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, and
  Luc~De Raedt.
\newblock {DeepProbLog: Neural Probabilistic Logic Programming}.
\newblock In \emph{NeurIPS}, pages 3753--3763, 2018.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{liu2015faceattributes}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{ICCV}, 2015.

\bibitem[Welinder et~al.(2010)Welinder, Branson, Mita, Wah, Schroff, Belongie,
  and Perona]{cub}
Peter Welinder, Steve Branson, Takeshi Mita, Catherine Wah, Florian Schroff,
  Serge Belongie, and Pietro Perona.
\newblock Caltech-ucsd birds 200.
\newblock Technical Report CNS-TR-201, Caltech, 2010.
\newblock URL \url{/se3/wp-content/uploads/2014/09/WelinderEtal10_CUB-200.pdf,
  http://www.vision.caltech.edu/visipedia/CUB-200.html}.

\bibitem[Abraham et~al.(2022)Abraham, D'Oosterlinck, Feder, Gat, Geiger, Potts,
  Reichart, and Wu]{abraham2022cebab}
Eldar~D Abraham, Karel D'Oosterlinck, Amir Feder, Yair Gat, Atticus Geiger,
  Christopher Potts, Roi Reichart, and Zhengxuan Wu.
\newblock Cebab: Estimating the causal effects of real-world concepts on nlp
  model behavior.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 17582--17596, 2022.

\bibitem[Hand and Till(2001)]{10.1023/A:1010920819831}
David~J. Hand and Robert~J. Till.
\newblock A simple generalisation of the area under the roc curve for multiple
  class classification problems.
\newblock \emph{Mach. Learn.}, 45\penalty0 (2):\penalty0 171â€“186, oct 2001.
\newblock ISSN 0885-6125.
\newblock \doi{10.1023/A:1010920819831}.
\newblock URL \url{https://doi.org/10.1023/A:1010920819831}.

\bibitem[Espinosa~Zarlenga et~al.(2022)Espinosa~Zarlenga, Barbiero, Ciravegna,
  Marra, Giannini, Diligenti, Shams, Precioso, Melacci, Weller, Lio, and
  Jamnik]{EspinosaZarlenga2022cem}
Mateo Espinosa~Zarlenga, Pietro Barbiero, Gabriele Ciravegna, Giuseppe Marra,
  Francesco Giannini, Michelangelo Diligenti, Zohreh Shams, Frederic Precioso,
  Stefano Melacci, Adrian Weller, Pietro Lio, and Mateja Jamnik.
\newblock Concept embedding models: Beyond the accuracy-explainability
  trade-off.
\newblock \emph{Advances in Neural Information Processing Systems}, 35, 2022.

\bibitem[Marconato et~al.(2022)Marconato, Passerini, and
  Teso]{marconato2022glancenets}
Emanuele Marconato, Andrea Passerini, and Stefano Teso.
\newblock Glancenets: Interpretable, leak-proof concept-based models.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 21212--21227, 2022.

\bibitem[Havasi et~al.(2022)Havasi, Parbhoo, and
  Doshi-Velez]{havasi2022addressing}
Marton Havasi, Sonali Parbhoo, and Finale Doshi-Velez.
\newblock Addressing leakage in concept bottleneck models.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 23386--23397, 2022.

\bibitem[Kindermans et~al.(2019)Kindermans, Hooker, Adebayo, Alber, Sch{\"u}tt,
  D{\"a}hne, Erhan, and Kim]{kindermans2019reliability}
Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber, Kristof~T
  Sch{\"u}tt, Sven D{\"a}hne, Dumitru Erhan, and Been Kim.
\newblock The (un) reliability of saliency methods.
\newblock \emph{Explainable AI: Interpreting, explaining and visualizing deep
  learning}, pages 267--280, 2019.

\bibitem[Ghorbani et~al.(2019{\natexlab{a}})Ghorbani, Abid, and
  Zou]{ghorbani2019interpretation}
Amirata Ghorbani, Abubakar Abid, and James Zou.
\newblock Interpretation of neural networks is fragile.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, volume~33, pages 3681--3688, 2019{\natexlab{a}}.

\bibitem[Adebayo et~al.(2018)Adebayo, Gilmer, Muelly, Goodfellow, Hardt, and
  Kim]{adebayo2018sanity}
Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt,
  and Been Kim.
\newblock Sanity checks for saliency maps.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Poursabzi-Sangdeh et~al.(2021)Poursabzi-Sangdeh, Goldstein, Hofman,
  Wortman~Vaughan, and Wallach]{poursabzi2021manipulating}
Forough Poursabzi-Sangdeh, Daniel~G Goldstein, Jake~M Hofman, Jennifer~Wortman
  Wortman~Vaughan, and Hanna Wallach.
\newblock Manipulating and measuring model interpretability.
\newblock In \emph{Proceedings of the 2021 CHI conference on human factors in
  computing systems}, pages 1--52, 2021.

\bibitem[Kim et~al.(2018)Kim, Wattenberg, Gilmer, Cai, Wexler, Viegas,
  et~al.]{kim2018interpretability}
Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda
  Viegas, et~al.
\newblock Interpretability beyond feature attribution: Quantitative testing
  with concept activation vectors (tcav).
\newblock In \emph{International conference on machine learning}, pages
  2668--2677. PMLR, 2018.

\bibitem[Ghorbani et~al.(2019{\natexlab{b}})Ghorbani, Wexler, Zou, and
  Kim]{ghorbani2019towards}
Amirata Ghorbani, James Wexler, James~Y Zou, and Been Kim.
\newblock Towards automatic concept-based explanations.
\newblock \emph{Advances in neural information processing systems}, 32,
  2019{\natexlab{b}}.

\bibitem[Garcez et~al.(2022)Garcez, Bader, Bowman, Lamb, de~Penning, Illuminoo,
  Poon, and Zaverucha]{garcez2022neural}
Artur~dâ€™Avila Garcez, Sebastian Bader, Howard Bowman, Luis~C Lamb, Leo
  de~Penning, BV~Illuminoo, Hoifung Poon, and COPPE~Gerson Zaverucha.
\newblock Neural-symbolic learning and reasoning: A survey and interpretation.
\newblock \emph{Neuro-Symbolic Artificial Intelligence: The State of the Art},
  342\penalty0 (1):\penalty0 327, 2022.

\bibitem[Marra et~al.(2024)Marra, Duman{\v{c}}i{\'c}, Manhaeve, and
  De~Raedt]{marra2024statistical}
Giuseppe Marra, Sebastijan Duman{\v{c}}i{\'c}, Robin Manhaeve, and Luc
  De~Raedt.
\newblock From statistical relational to neurosymbolic artificial intelligence:
  A survey.
\newblock \emph{Artificial Intelligence}, page 104062, 2024.

\bibitem[Xu et~al.(2018)Xu, Zhang, Friedman, Liang, and Broeck]{xu2018semantic}
Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, and Guy Broeck.
\newblock A semantic loss function for deep learning with symbolic knowledge.
\newblock In \emph{International conference on machine learning}, pages
  5502--5511. PMLR, 2018.

\bibitem[Badreddine et~al.(2022)Badreddine, Garcez, Serafini, and
  Spranger]{badreddine2022logic}
Samy Badreddine, Artur~d'Avila Garcez, Luciano Serafini, and Michael Spranger.
\newblock Logic tensor networks.
\newblock \emph{Artificial Intelligence}, 303:\penalty0 103649, 2022.

\bibitem[Sourek et~al.(2018)Sourek, Aschenbrenner, Zelezny, Schockaert, and
  Kuzelka]{sourek2018lifted}
Gustav Sourek, Vojtech Aschenbrenner, Filip Zelezny, Steven Schockaert, and
  Ondrej Kuzelka.
\newblock Lifted relational neural networks: Efficient learning of latent
  relational structures.
\newblock \emph{Journal of Artificial Intelligence Research}, 62:\penalty0
  69--100, 2018.

\bibitem[Tang and Ellis(2023)]{tang2023perception}
Hao Tang and Kevin Ellis.
\newblock From perception to programs: regularize, overparameterize, and
  amortize.
\newblock In \emph{International Conference on Machine Learning}, pages
  33616--33631. PMLR, 2023.

\bibitem[Daniele et~al.(2022)Daniele, Campari, Malhotra, and
  Serafini]{daniele2022deep}
Alessandro Daniele, Tommaso Campari, Sagar Malhotra, and Luciano Serafini.
\newblock Deep symbolic learning: Discovering symbols and rules from
  perceptions.
\newblock \emph{arXiv preprint arXiv:2208.11561}, 2022.

\bibitem[Evans and Grefenstette(2018)]{evans2018learning}
Richard Evans and Edward Grefenstette.
\newblock Learning explanatory rules from noisy data.
\newblock \emph{Journal of Artificial Intelligence Research}, 61:\penalty0
  1--64, 2018.

\bibitem[Lecun et~al.(1998)Lecun, Bottou, Bengio, and Haffner]{mnistLecun}
Y.~Lecun, L.~Bottou, Y.~Bengio, and P.~Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.
\newblock \doi{10.1109/5.726791}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Wolf et~al.(2020)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, Davison, Shleifer, von Platen, Ma, Jernite, Plu, Xu,
  Scao, Gugger, Drame, Lhoest, and Rush]{wolf-etal-2020-transformers}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
  Anthony Moi, Pierric Cistac, Tim Rault, RÃ©mi Louf, Morgan Funtowicz, Joe
  Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
  Plu, Canwen Xu, Teven~Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
  and Alexander~M. Rush.
\newblock Transformers: State-of-the-art natural language processing.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}, pages 38--45, Online,
  October 2020. Association for Computational Linguistics.
\newblock URL \url{https://www.aclweb.org/anthology/2020.emnlp-demos.6}.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, KÃ¶pf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas KÃ¶pf, Edward Yang, Zach DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library,
  2019.

\bibitem[Pedregosa et~al.(2018)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, MÃ¼ller, Nothman, Louppe, Prettenhofer, Weiss, Dubourg,
  Vanderplas, Passos, Cournapeau, Brucher, Perrot, and Ã‰douard
  Duchesnay]{pedregosa2018scikitlearn}
Fabian Pedregosa, GaÃ«l Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand
  Thirion, Olivier Grisel, Mathieu Blondel, Andreas MÃ¼ller, Joel Nothman,
  Gilles Louppe, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake
  Vanderplas, Alexandre Passos, David Cournapeau, Matthieu Brucher, Matthieu
  Perrot, and Ã‰douard Duchesnay.
\newblock Scikit-learn: Machine learning in python, 2018.

\bibitem[Hunter(2007)]{Hunter:2007}
J.~D. Hunter.
\newblock Matplotlib: A 2d graphics environment.
\newblock \emph{Computing in Science \& Engineering}, 9\penalty0 (3):\penalty0
  90--95, 2007.
\newblock \doi{10.1109/MCSE.2007.55}.

\end{thebibliography}
