@article{fan2001variable,
  title={Variable selection via nonconcave penalized likelihood and its oracle properties},
  author={Fan, Jianqing and Li, Runze},
  journal={Journal of the American statistical Association},
  volume={96},
  number={456},
  pages={1348--1360},
  year={2001},
  publisher={Taylor \& Francis}
}

@inproceedings{glorot2011deep,
  title={Deep sparse rectifier neural networks},
  author={Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
  booktitle={AISTATS},
  year={2011},
}

@book{nesterov2018lectures,
  title={Lectures on convex optimization},
  author={Nesterov, Yurii},
  volume={137},
  year={2018},
  publisher={Springer}
}

@article{zhang2010nearly,
  title={Nearly unbiased variable selection under minimax concave penalty},
  author={Zhang, Cun-Hui},
  journal={The Annals of statistics},
  volume={38},
  number={2},
  pages={894--942},
  year={2010},
  publisher={Institute of Mathematical Statistics}
}

@article{zhang2006gene,
  title={Gene selection using support vector machines with non-convex penalty},
  author={Zhang, Hao Helen and Ahn, Jeongyoun and Lin, Xiaodong and Park, Cheolwoo},
  journal={bioinformatics},
  volume={22},
  number={1},
  pages={88--95},
  year={2006},
  publisher={Oxford University Press}
}

@article{mazumder2011sparsenet,
  title={Sparsenet: Coordinate descent with nonconvex penalties},
  author={Mazumder, Rahul and Friedman, Jerome H and Hastie, Trevor},
  journal={Journal of the American Statistical Association},
  volume={106},
  number={495},
  pages={1125--1138},
  year={2011},
  publisher={Taylor \& Francis}
}


@article{bubeck2015convex,
  title={Convex optimization: Algorithms and complexity},
  author={Bubeck, S{\'e}bastien and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={8},
  number={3-4},
  pages={231--357},
  year={2015},
  publisher={Now Publishers, Inc.}
}

@book{rockafellar2009variational,
  title={Variational analysis},
  author={Rockafellar, R Tyrrell and Wets, Roger J-B},
  volume={317},
  year={2009},
  publisher={Springer Science \& Business Media}
}

@inproceedings{nair2010rectified,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={ICML},
  year={2010}
}

@inproceedings{zhang2020complexity,
  title={Complexity of finding stationary points of nonsmooth nonconvex functions},
  author={Zhang, Jingzhao and Lin, Hongzhou and Jegelka, Stefanie and Sra, Suvrit and Jadbabaie, Ali},
  booktitle={ICML},
  year={2020}
}

@inproceedings{li2021page,
  title={{PAGE}: A simple and optimal probabilistic gradient estimator for nonconvex optimization},
  author={Li, Zhize and Bao, Hongyan and Zhang, Xiangliang and Richt{\'a}rik, Peter},
  booktitle={ICML},
  year={2021}
}


@inproceedings{fang2018spider,
  title={{SPIDER}: Near-optimal non-convex optimization via stochastic path-integrated differential estimator},
  author={Fang, Cong and Li, Chris Junchi and Lin, Zhouchen and Zhang, Tong},
  booktitle={NeurIPS},
  year={2018}
}

@book{clarke1990optimization,
  title={Optimization and nonsmooth analysis},
  author={Clarke, Frank H.},
  year={1990},
  publisher={SIAM}
}

@article{goldstein1977optimization,
  title={Optimization of Lipschitz continuous functions},
  author={Goldstein,A.},
  journal={Mathematical Programming},
  volume={13},
  number={1},
  pages={14--22},
  year={1977}
}

@article{lin2022gradient,
  title={Gradient-Free Methods for Deterministic and Stochastic Nonsmooth Nonconvex Optimization},
  author={Lin, Tianyi and Zheng, Zeyu and Jordan, Michael I},
  journal={arXiv preprint arXiv:2209.05045},
  year={2022}
}

@inproceedings{nguyen2017sarah,
  title={{SARAH}: A novel method for machine learning problems using stochastic recursive gradient},
  author={Nguyen, Lam M and Liu, Jie and Scheinberg, Katya and Tak{\'a}{\v{c}}, Martin},
  booktitle={ICML},
  year={2017}
}

@inproceedings{cutkosky2019momentum,
  title={Momentum-based variance reduction in non-convex {SGD}},
  author={Cutkosky, Ashok and Orabona, Francesco},
  booktitle={NeurIPS},
  year={2019}
}


@inproceedings{tian2022finite,
  title={On the Finite-Time Complexity and Practical Computation of Approximate Stationarity Concepts of Lipschitz Functions},
  author={Tian, Lai and Zhou, Kaiwen and So, Anthony Man-Cho},
  booktitle={ICML},
  year={2022}
}


@article{jordan2022complexity,
  title={On the Complexity of Deterministic Nonsmooth and Nonconvex Optimization},
  author={Jordan, Michael I and Lin, Tianyi and Zampetakis, Manolis},
  journal={arXiv preprint arXiv:2209.12463},
  year={2022}
}


@inproceedings{wang2018stochastic,
  title={Stochastic zeroth-order optimization in high dimensions},
  author={Wang, Yining and Du, Simon and Balakrishnan, Sivaraman and Singh, Aarti},
  booktitle={AISTATS},
  year={2018}
}


@article{flaxman2004online,
  title={Online convex optimization in the bandit setting: gradient descent without a gradient},
  author={Flaxman, Abraham D and Kalai, Adam Tauman and McMahan, H Brendan},
  journal={arXiv preprint cs/0408007},
  year={2004}
}

@article{duchi2015optimal,
  title={Optimal rates for zero-order convex optimization: The power of two function evaluations},
  author={Duchi, John C and Jordan, Michael I and Wainwright, Martin J and Wibisono, Andre},
  journal={IEEE Transactions on Information Theory},
  volume={61},
  number={5},
  pages={2788--2806},
  year={2015},
  publisher={IEEE}
}

@inproceedings{li2019ssrgd,
  title={{SSRGD}: Simple stochastic recursive gradient descent for escaping saddle points},
  author={Li, Zhize},
  booktitle={NeurIPS},
  year={2019}
}

@article{pham2020proxsarah,
  title={{ProxSARAH}: An Efficient Algorithmic Framework for Stochastic Composite Nonconvex Optimization.},
  author={Pham, Nhan H and Nguyen, Lam M. and Phan, Dzung T. and Tran-Dinh, Quoc},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={110},
  pages={1--48},
  year={2020}
}

@article{horvath2022adaptivity,
  title={Adaptivity of stochastic gradient methods for nonconvex optimization},
  author={Horv{\'a}th, Samuel and Lei, Lihua and Richt{\'a}rik, Peter and Jordan, Michael I},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={4},
  number={2},
  pages={634--648},
  year={2022}
}

@article{zhou2020stochastic,
  title={Stochastic nested variance reduction for nonconvex optimization},
  author={Zhou, Dongruo and Xu, Pan and Gu, Quanquan},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={4130--4192},
  year={2020}
}

@inproceedings{wang2019spiderboost,
  title={Spider{B}oost and momentum: Faster variance reduction algorithms},
  author={Wang, Zhe and Ji, Kaiyi and Zhou, Yi and Liang, Yingbin and Tarokh, Vahid},
  booktitle={NeurIPS},
  year={2019}
}

@article{burke2020gradient,
  title={Gradient sampling methods for nonsmooth optimization},
  author={Burke, James V and Curtis, Frank E and Lewis, Adrian S and Overton, Michael L and Sim{\~o}es, Lucas EA},
  journal={Numerical Nonsmooth Optimization},
  pages={201--225},
  year={2020}
}

@inproceedings{ji2020history,
  title={History-gradient aided batch size adaptation for variance reduced algorithms},
  author={Ji, Kaiyi and Wang, Zhe and Weng, Bowen and Zhou, Yi and Zhang, Wei and Liang, Yingbin},
  booktitle={ICML},
  year={2020}
}

@inproceedings{choromanski2018structured,
  title={Structured evolution with compact architectures for scalable policy optimization},
  author={Choromanski, Krzysztof and Rowland, Mark and Sindhwani, Vikas and Turner, Richard and Weller, Adrian},
  booktitle={ICML},
  year={2018}
}

@inproceedings{papernot2017practical,
  title={Practical black-box attacks against machine learning},
  author={Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram},
  booktitle={ASIACCS},
  year={2017}
}

@article{ghadimi2012optimal,
  title={Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization i: A generic algorithmic framework},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={4},
  pages={1469--1492},
  year={2012}
}

@article{ghadimi2013optimal,
  title={Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization, II: shrinking procedures and optimal algorithms},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={4},
  pages={2061--2089},
  year={2013}
}

@article{arjevani2022lower,
  title={Lower bounds for non-convex stochastic optimization},
  author={Arjevani, Yossi and Carmon, Yair and Duchi, John C and Foster, Dylan J and Srebro, Nathan and Woodworth, Blake},
  journal={Mathematical Programming},
  pages={1--50},
  year={2022}
}


@article{hazan2014beyond,
  title={Beyond the regret minimization barrier: optimal algorithms for stochastic strongly-convex optimization},
  author={Hazan, Elad and Kale, Satyen},
  journal={Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={2489--2512},
  year={2014}
}

@article{shamir2017optimal,
  title={An optimal algorithm for bandit and zero-order convex optimization with two-point feedback},
  author={Shamir, Ohad},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={1703--1713},
  year={2017}
}

@article{duchi2012randomized,
  title={Randomized smoothing for stochastic optimization},
  author={Duchi, John C and Bartlett, Peter L and Wainwright, Martin J},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={2},
  pages={674--701},
  year={2012}
}

@book{cesa2006prediction,
  title={Prediction, learning, and games},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  year={2006},
  publisher={Cambridge university press}
}

@article{kornowski2021oracle,
  title={Oracle complexity in nonsmooth nonconvex optimization},
  author={Kornowski, Guy and Shamir, Ohad},
  journal={NeurIPS},
  year={2021}
}

@inproceedings{davis2021gradient,
  title={A gradient sampling method with complexity guarantees for {Lipschitz} functions in high and low dimensions},
  author={Davis, Damek and Drusvyatskiy, Dmitriy and Lee, Yin Tat and Padmanabhan, Swati and Ye, Guanghao},
  booktitle={NeurIPS},
  year={2022}
}


@inproceedings{levy2021storm+,
  title={{STORM${}^+$}: Fully adaptive {SGD} with recursive momentum for nonconvex optimization},
  author={Levy, Kfir and Kavis, Ali and Cevher, Volkan},
  booktitle={NeurIPS},
  year={2021}
}


@article{fang2018spiderArxiv,
  title={Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator},
  author={Fang, Cong and Li, Chris Junchi and Lin, Zhouchen and Zhang, Tong},
  journal={arXiv preprint arXiv:1807.01695},
  year={2018}
}


@inproceedings{ji2019improved,
  title={Improved zeroth-order variance reduced algorithms and analysis for nonconvex optimization},
  author={Ji, Kaiyi and Wang, Zhe and Zhou, Yi and Liang, Yingbin},
  booktitle={ICML},
  year={2019}
}

@article{ghadimi2013stochastic,
  title={Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={4},
  pages={2341--2368},
  year={2013}
}

@inproceedings{liu2018zeroth,
  title={Zeroth-order stochastic variance reduction for nonconvex optimization},
  author={Liu, Sijia and Kailkhura, Bhavya and Chen, Pin-Yu and Ting, Paishun and Chang, Shiyu and Amini, Lisa},
  booktitle={NeurIPS},
  year={2018}
}

@article{hong2015discrete,
  title={Discrete optimization via simulation},
  author={Hong, L Jeff and Nelson, Barry L and Xu, Jie},
  journal={Handbook of simulation optimization},
  pages={9--44},
  year={2015}
}

@article{nelson2010optimization,
  title={Optimization via simulation over discrete decision variables},
  author={Nelson, Barry L},
  journal={Risk and optimization in an uncertain world},
  pages={193--207},
  year={2010}
}


@article{kurakin2016adversarial,
  title={Adversarial machine learning at scale},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  journal={arXiv preprint arXiv:1611.01236},
  year={2016}
}

@inproceedings{taskar2005learning,
  title={Learning structured prediction models: A large margin approach},
  author={Taskar, Ben and Chatalbashev, Vassil and Koller, Daphne and Guestrin, Carlos},
  booktitle={ICML},
  year={2005}
}

@inproceedings{suh2022differentiable,
  title={Do differentiable simulators give better policy gradients?},
  author={Suh, Hyung Ju and Simchowitz, Max and Zhang, Kaiqing and Tedrake, Russ},
  booktitle={ICML},
  year={2022}
}

@article{gu2021optimizing,
  title={Optimizing large-scale hyperparameters via automated learning algorithm},
  author={Gu, Bin and Liu, Guodong and Zhang, Yanfu and Geng, Xiang and Huang, Heng},
  journal={arXiv preprint arXiv:2102.09026},
  year={2021}
}


@inproceedings{jamieson2012query,
  title={Query complexity of derivative-free optimization},
  author={Jamieson, Kevin G and Nowak, Robert and Recht, Ben},
  booktitle={NeurIPS},
  year={2012}
}

% zeroth order
@article{nesterov2017random,
  title={Random gradient-free minimization of convex functions},
  author={Nesterov, Yurii and Spokoiny, Vladimir},
  journal={Foundations of Computational Mathematics},
  volume={17},
  number={2},
  pages={527--566},
  year={2017}
}

@inproceedings{attouch1993approximation,
  title={Approximation and regularization of arbitrary functions in Hilbert spaces by the Lasry-Lions method},
  author={Attouch, H{\'e}dy and Aze, Dominique},
  booktitle={Annales de l'Institut Henri Poincar{\'e} C, Analyse non lin{\'e}aire},
  volume={10},
  number={3},
  pages={289--312},
  year={1993}
}

@inproceedings{kovalev2020don,
  title={Don’t jump through hoops and remove those loops: {SVRG} and Katyusha are better without the outer loop},
  author={Kovalev, Dmitry and Horv{\'a}th, Samuel and Richt{\'a}rik, Peter},
  booktitle={ALT},
  year={2020}
}

@inproceedings{reddi2016stochastic,
  title={Stochastic variance reduction for nonconvex optimization},
  author={Reddi, Sashank J and Hefny, Ahmed and Sra, Suvrit and P{\'o}czos, Barnab{\'a}s and Smola, Alex},
  booktitle={ICML},
  year={2016},
}

@inproceedings{ge2019stabilized,
  title={Stabilized {SVRG}: Simple variance reduction for nonconvex optimization},
  author={Ge, Rong and Li, Zhize and Wang, Weiyao and Wang, Xiang},
  booktitle={COLT},
  year={2019}
}

@inproceedings{allen2016improved,
  title={Improved {SVRG} for non-strongly-convex or sum-of-non-convex objectives},
  author={Allen-Zhu, Zeyuan and Yuan, Yang},
  booktitle={ICML},
  year={2016}
}


@inproceedings{j2016proximal,
  title={Proximal stochastic methods for nonsmooth nonconvex finite-sum optimization},
  author={Reddi, Sashank J. and Sra, Suvrit and Poczos, Barnabas and Smola, Alexander J.},
  booktitle={NIPS},
  year={2016}
}

@inproceedings{johnson2013accelerating,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  booktitle={NeurIPS},
  year={2013}
}

@article{xiao2014proximal,
  title={A proximal stochastic gradient method with progressive variance reduction},
  author={Xiao, Lin and Zhang, Tong},
  journal={SIAM Journal on Optimization},
  volume={24},
  number={4},
  pages={2057--2075},
  year={2014}
}


@article{schmidt2017minimizing,
  title={Minimizing finite sums with the stochastic average gradient},
  author={Schmidt, Mark and Le Roux, Nicolas and Bach, Francis},
  journal={Mathematical Programming},
  volume={162},
  number={1},
  pages={83--112},
  year={2017}
}

@article{allen2017katyusha,
  title={Katyusha: The first direct acceleration of stochastic gradient methods},
  author={Allen-Zhu, Zeyuan},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={8194--8244},
  year={2017}
}

@article{allen2018katyusha,
  title={Katyusha {X}: Practical momentum method for stochastic sum-of-nonconvex optimization},
  author={Allen-Zhu, Zeyuan},
  journal={arXiv preprint arXiv:1802.03866},
  year={2018}
}


@inproceedings{li2018simple,
  title={A simple proximal stochastic gradient method for nonsmooth nonconvex optimization},
  author={Li, Zhize and Li, Jian},
  booktitle={NeurIPS},
  year={2018}
}

@article{li2022simple,
  title={Simple and Optimal Stochastic Gradient Methods for Nonsmooth Nonconvex Optimization},
  author={Li, Zhize and Li, Jian},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={239},
  pages={1--61},
  year={2022}
}

@inproceedings{chen2017zoo,
  title={{ZOO}: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models},
  author={Chen, Pin-Yu and Zhang, Huan and Sharma, Yash and Yi, Jinfeng and Hsieh, Cho-Jui},
  booktitle={Workshop on AISec},
  pages={15--26},
  year={2017}
}

@article{zhang2010analysis,
  title={Analysis of multi-stage convex relaxation for sparse regularization.},
  author={Zhang, Tong},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={3},
  year={2010}
}

@inproceedings{guan2018efficient,
  title={An efficient ADMM-based algorithm to nonconvex penalized support vector machines},
  author={Guan, Lei and Qiao, Linbo and Li, Dongsheng and Sun, Tao and Ge, Keshi and Lu, Xicheng},
  booktitle={2018 IEEE International Conference on Data Mining Workshops (ICDMW)},
  pages={1209--1216},
  year={2018},
  organization={IEEE}
}

@article{chang2011libsvm,
  title={{LIBSVM}: A library for support vector machines},
  author={Chang, Chih-Chung and Lin, Chih-Jen},
  journal={ACM transactions on intelligent systems and technology},
  volume={2},
  number={3},
  pages={1--27},
  year={2011},
  url={https://www.csie.ntu.edu.tw/~cjlin/libsvm/}
}

% zeroth order

@inproceedings{shamir2013complexity,
  title={On the complexity of bandit and derivative-free stochastic convex optimization},
  author={Shamir, Ohad},
  booktitle={COLT},
  year={2013},
  organization={PMLR}
}

@inproceedings{gu2018faster,
  title={Faster derivative-free stochastic algorithm for shared memory machines},
  author={Gu, Bin and Huo, Zhouyuan and Deng, Cheng and Huang, Heng},
  booktitle={ICML},
  year={2018},
  organization={PMLR}
}

@inproceedings{bubeck2012towards,
  title={Towards minimax policies for online linear optimization with bandit feedback},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and Kakade, Sham M},
  booktitle={COLT},
  year={2012}
}

@inproceedings{audibert2011minimax,
  title={Minimax policies for combinatorial prediction games},
  author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien and Lugosi, G{\'a}bor},
  booktitle={COLT},
  year={2011}
}

@inproceedings{agarwal2010optimal,
  title={Optimal Algorithms for Online Convex Optimization with Multi-Point Bandit Feedback.},
  author={Agarwal, Alekh and Dekel, Ofer},
  booktitle={COLT},
  year={2010}
}

@article{ye2018hessian,
  title={Hessian-aware zeroth-order optimization for black-box adversarial attack},
  author={Ye, Haishan and Huang, Zhichao and Fang, Cong and Li, Chris Junchi and Zhang, Tong},
  journal={arXiv preprint arXiv:1812.11377},
  year={2018}
}

@article{tang2020distributed,
  title={Distributed zero-order algorithms for nonconvex multiagent optimization},
  author={Tang, Yujie and Zhang, Junshan and Li, Na},
  journal={IEEE Transactions on Control of Network Systems},
  volume={8},
  number={1},
  pages={269--281},
  year={2020},
  publisher={IEEE}
}

@inproceedings{bach2016highly,
  title={Highly-smooth zero-th order online optimization},
  author={Bach, Francis and Perchet, Vianney},
  booktitle={COLT},
  year={2016},
  organization={PMLR}
}

@inproceedings{huang2020accelerated,
  title={Accelerated stochastic gradient-free and projection-free methods},
  author={Huang, Feihu and Tao, Lue and Chen, Songcan},
  booktitle={ICML},
  year={2020},
  organization={PMLR}
}

@article{xu2022zeroth,
  title={Zeroth-Order Alternating Gradient Descent Ascent Algorithms for a Class of Nonconvex-Nonconcave Minimax Problems},
  author={Xu, Zi and Wang, Zi-Qi and Wang, Jun-Lin and Dai, Yu-Hong},
  journal={arXiv preprint arXiv:2211.13668},
  year={2022}
}

@article{lian2016comprehensive,
  title={A comprehensive linear speedup analysis for asynchronous stochastic parallel optimization from zeroth-order to first-order},
  author={Lian, Xiangru and Zhang, Huan and Hsieh, Cho-Jui and Huang, Yijun and Liu, Ji},
  journal={NeurIPS},
  year={2016}
}

@inproceedings{chen2020frank,
  title={A frank-wolfe framework for efficient and effective adversarial attacks},
  author={Chen, Jinghui and Zhou, Dongruo and Yi, Jinfeng and Gu, Quanquan},
  booktitle={AAAI},
  year={2020}
}

@inproceedings{sahu2019towards,
  title={Towards gradient free and projection free stochastic optimization},
  author={Sahu, Anit Kumar and Zaheer, Manzil and Kar, Soummya},
  booktitle={AISTATS},
  year={2019},
  organization={PMLR}
}

@article{roy2022stochastic,
  title={Stochastic Zeroth-Order Optimization under Nonstationarity and Nonconvexity},
  author={Roy, Abhishek and Balasubramanian, Krishnakumar and Ghadimi, Saeed and Mohapatra, Prasant},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={64},
  pages={1--47},
  year={2022}
}

@article{bubeck2016kernel,
  title={Kernel-based methods for bandit convex optimization},
  author={Bubeck, S{\'e}bastien and Eldan, Ronen and Lee, Yin Tat},
  journal={arXiv preprint arXiv:1607.03084},
  year={2016}
}

@article{berthet2017fast,
  title={Fast rates for bandit optimization with upper-confidence Frank-Wolfe},
  author={Berthet, Quentin and Perchet, Vianney},
  journal={NIPS},
  year={2017}
}

@article{akhavan2020exploiting,
  title={Exploiting higher order smoothness in derivative-free optimization and continuous bandits},
  author={Akhavan, Arya and Pontil, Massimiliano and Tsybakov, Alexandre},
  journal={NeurIPS},
  year={2020}
}

@article{jing2021asynchronous,
  title={Asynchronous distributed reinforcement learning for LQR control via zeroth-order block coordinate descent},
  author={Jing, Gangshan and Bai, He and George, Jemin and Chakrabortty, Aranya and Sharma, Piyush K},
  journal={arXiv preprint arXiv:2107.12416},
  year={2021}
}

@article{balasubramanian2018zeroth,
  title={Zeroth-order (non)-convex stochastic optimization via conditional gradient and gradient updates},
  author={Balasubramanian, Krishnakumar and Ghadimi, Saeed},
  journal={NeurIPS},
  year={2018}
}

@inproceedings{malik2019derivative,
  title={Derivative-free methods for policy optimization: Guarantees for linear quadratic systems},
  author={Malik, Dhruv and Pananjady, Ashwin and Bhatia, Kush and Khamaru, Koulik and Bartlett, Peter and Wainwright, Martin},
  booktitle={AISTATS},
  year={2019},
  organization={PMLR}
}

@article{chen2019zo,
  title={Zo-adamm: Zeroth-order adaptive momentum method for black-box optimization},
  author={Chen, Xiangyi and Liu, Sijia and Xu, Kaidi and Li, Xingguo and Lin, Xue and Hong, Mingyi and Cox, David},
  journal={NeurIPS},
  year={2019}
}

@inproceedings{zhang2020one,
  title={One sample stochastic frank-wolfe},
  author={Zhang, Mingrui and Shen, Zebang and Mokhtari, Aryan and Hassani, Hamed and Karbasi, Amin},
  booktitle={AISTATS},
  year={2020},
  organization={PMLR}
}

@inproceedings{gao2020can,
  title={Can stochastic zeroth-order Frank-Wolfe method converge faster for non-convex problems?},
  author={Gao, Hongchang and Huang, Heng},
  booktitle={ICML},
  year={2020},
  organization={PMLR}
}


@article{vlatakis2019efficiently,
  title={Efficiently avoiding saddle points with zero order methods: No gradients required},
  author={Vlatakis-Gkaragkounis, Emmanouil-Vasileios and Flokas, Lampros and Piliouras, Georgios},
  journal={NeurIPS},
  year={2019}
}

@article{lucchi2021second,
  title={On the Second-order Convergence Properties of Random Search Methods},
  author={Lucchi, Aurelien and Orvieto, Antonio and Solomou, Adamos},
  journal={NeurIPS},
  year={2021}
}

@article{li2021anita,
  title={ANITA: An Optimal Loopless Accelerated Variance-Reduced Gradient Method},
  author={Li, Zhize},
  journal={arXiv preprint arXiv:2103.11333},
  year={2021}
}

@article{arjevani2017limitations,
  title={Limitations on variance-reduction and acceleration schemes for finite sums optimization},
  author={Arjevani, Yossi},
  journal={NeurIPS},
  year={2017}
}

@inproceedings{alacaoglu2022stochastic,
  title={Stochastic variance reduction for variational inequality methods},
  author={Alacaoglu, Ahmet and Malitsky, Yura},
  booktitle={COLT},
  year={2022},
  organization={PMLR}
}

@article{dubey2016variance,
  title={Variance reduction in stochastic gradient Langevin dynamics},
  author={Dubey, Kumar Avinava and J Reddi, Sashank and Williamson, Sinead A and Poczos, Barnabas and Smola, Alexander J and Xing, Eric P},
  journal={NeurIPS},
  year={2016}
}

@inproceedings{zou2018stochastic,
  title={Stochastic variance-reduced hamilton monte carlo methods},
  author={Zou, Difan and Xu, Pan and Gu, Quanquan},
  booktitle={ICML},
  year={2018},
  organization={PMLR}
}


@inproceedings{chatterji2018theory,
  title={On the theory of variance reduction for stochastic gradient Monte Carlo},
  author={Chatterji, Niladri and Flammarion, Nicolas and Ma, Yian and Bartlett, Peter and Jordan, Michael},
  booktitle={ICML},
  year={2018},
  organization={PMLR}
}

@inproceedings{zhou2019lower,
  title={Lower bounds for smooth nonconvex finite-sum optimization},
  author={Zhou, Dongruo and Gu, Quanquan},
  booktitle={ICML},
  year={2019},
  organization={PMLR}
}


@article{huang2022accelerated,
  title={Accelerated Zeroth-Order and First-Order Momentum Methods from Mini to Minimax Optimization},
  author={Huang, Feihu and Gao, Shangqian and Pei, Jian and Huang, Heng},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={36},
  pages={1--70},
  year={2022}
}

@article{tran2019hybrid,
  title={Hybrid stochastic gradient descent algorithms for stochastic nonconvex optimization},
  author={Tran-Dinh, Quoc and Pham, Nhan H and Phan, Dzung T and Nguyen, Lam M},
  journal={arXiv preprint arXiv:1905.05920},
  year={2019}
}

@article{davis2018stochastic,
  title={Stochastic subgradient method converges at the rate $\mathcal{O}(k^{-1/4}) $ on weakly convex functions},
  author={Davis, Damek and Drusvyatskiy, Dmitriy},
  journal={arXiv preprint arXiv:1802.02988},
  year={2018}
}

@article{allen2018make,
  title={How to make the gradients small stochastically: Even faster convex and nonconvex {SGD}},
  author={Allen-Zhu, Zeyuan},
  journal={NeurIPS},
  year={2018}
}

@article{carmon2020lower,
  title={Lower bounds for finding stationary points I},
  author={Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, Aaron},
  journal={Mathematical Programming},
  volume={184},
  number={1},
  pages={71--120},
  year={2020},
  publisher={Springer}
}

@article{bian2015complexity,
  title={Complexity analysis of interior point algorithms for non-Lipschitz and nonconvex minimization},
  author={Bian, Wei and Chen, Xiaojun and Ye, Yinyu},
  journal={Mathematical Programming},
  volume={149},
  number={1},
  pages={301--327},
  year={2015},
  publisher={Springer}
}

@article{majewski2018analysis,
  title={Analysis of nonsmooth stochastic approximation: the differential inclusion approach},
  author={Majewski, Szymon and Miasojedow, B{\l}a{\.z}ej and Moulines, Eric},
  journal={arXiv preprint arXiv:1805.01916},
  year={2018}
}

@article{daniilidis2020pathological,
  title={Pathological subgradient dynamics},
  author={Daniilidis, Aris and Drusvyatskiy, Dmitriy},
  journal={SIAM Journal on Optimization},
  volume={30},
  number={2},
  pages={1327--1338},
  year={2020},
  publisher={SIAM}
}

@article{davis2020stochastic,
  title={Stochastic subgradient method converges on tame functions},
  author={Davis, Damek and Drusvyatskiy, Dmitriy and Kakade, Sham and Lee, Jason D},
  journal={Foundations of computational mathematics},
  volume={20},
  number={1},
  pages={119--154},
  year={2020},
  publisher={Springer}
}


@book{duffie2010dynamic,
  title={Dynamic asset pricing theory},
  author={Duffie, Darrell},
  year={2010},
  publisher={Princeton University Press}
}

@article{stadtler2008supply,
  title={Supply chain management—an overview},
  author={Stadtler, Hartmut},
  journal={Supply chain management and advanced planning},
  pages={9--36},
  year={2008},
  publisher={Springer}
}

@article{mania2018simple,
  title={Simple random search provides a competitive approach to reinforcement learning},
  author={Mania, Horia and Guy, Aurelia and Recht, Benjamin},
  journal={arXiv preprint arXiv:1803.07055},
  year={2018}
}


@article{kornowski2022complexity,
  title={On the Complexity of Finding Small Subgradients in Nonsmooth Optimization},
  author={Kornowski, Guy and Shamir, Ohad},
  journal={arXiv preprint arXiv:2209.10346},
  year={2022}
}

@inproceedings{tian2021hardness,
  title={On the hardness of computing near-approximate stationary points of Clarke regular nonsmooth nonconvex problems and certain {DC} programs},
  author={Tian, Lai and So, Anthony Man-Cho},
  booktitle={ICML Workshop on Beyond First-Order Methods in ML Systems},
  year={2021}
}

@article{shalev2012stochastic,
  title={Stochastic dual coordinate ascent methods for regularized loss minimization},
  author={Shalev-Shwartz, Shai and Zhang, Tong},
  journal={arXiv preprint arXiv:1209.1873},
  year={2012}
}

@article{nesterov2012make,
  title={How to make the gradients small},
  author={Nesterov, Yurii},
  journal={Optima. Mathematical Optimization Society Newsletter},
  volume ={88},
  pages={10--11},
  year={2012}
}

@article{lee2021geometric,
  title={A geometric structure of acceleration and its role in making gradients small fast},
  author={Lee, Jongmin and Park, Chanwoo and Ryu, Ernest},
  journal={NeurIPS},
  year={2021}
}

@article{davis2018complexity,
  title={Complexity of finding near-stationary points of convex functions stochastically},
  author={Davis, Damek and Drusvyatskiy, Dmitriy},
  journal={arXiv preprint arXiv:1802.08556},
  year={2018}
}

@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={IEEE Symposium on Security and Privacy},
  year={2017}
}

@article{kungurtsev2021zeroth,
  title={A zeroth order method for stochastic weakly convex optimization},
  author={Kungurtsev, Vyacheslav and Rinaldi, Francesco},
  journal={Computational Optimization and Applications},
  volume={80},
  number={3},
  pages={731--753},
  year={2021},
  publisher={Springer}
}

@article{wong2020fast,
  title={Fast is better than free: Revisiting adversarial training},
  author={Wong, Eric and Rice, Leslie and Kolter, J Zico},
  journal={arXiv preprint arXiv:2001.03994},
  year={2020}
}

@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

@article{foret2020sharpness,
  title={Sharpness-aware minimization for efficiently improving generalization},
  author={Foret, Pierre and Kleiner, Ariel and Mobahi, Hossein and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2010.01412},
  year={2020}
}

@article{devries2017improved,
  title={Improved regularization of convolutional neural networks with cutout},
  author={DeVries, Terrance and Taylor, Graham W},
  journal={arXiv preprint arXiv:1708.04552},
  year={2017}
}

@article{muller2019does,
  title={When does label smoothing help?},
  author={M{\"u}ller, Rafael and Kornblith, Simon and Hinton, Geoffrey E},
  journal={NeurIPS},
  year={2019}
}

@inproceedings{metel2019simple,
  title={Simple stochastic gradient methods for non-smooth non-convex regularized optimization},
  author={Metel, Michael and Takeda, Akiko},
  booktitle={ICML},
  year={2019}
}

@inproceedings{xu2019stochastic,
  title={Stochastic optimization for {DC} functions and non-smooth non-convex regularizers with non-asymptotic convergence},
  author={Xu, Yi and Qi, Qi and Lin, Qihang and Jin, Rong and Yang, Tianbao},
  booktitle={ICML},
  year={2019}
}

@article{ghadimi2016mini,
  title={Mini-batch stochastic approximation methods for nonconvex stochastic composite optimization},
  author={Ghadimi, Saeed and Lan, Guanghui and Zhang, Hongchao},
  journal={Mathematical Programming},
  volume={155},
  number={1},
  pages={267--305},
  year={2016},
  publisher={Springer}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@article{cutkosky2023optimal,
  title={Optimal Stochastic Non-smooth Non-convex Optimization through Online-to-Non-convex Conversion},
  author={Cutkosky, Ashok and Mehta, Harsh and Orabona, Francesco},
  journal={arXiv preprint arXiv:2302.03775},
  year={2023}
}

@article{tian2022no,
  title={No Dimension-Free Deterministic Algorithm Computes Approximate Stationarities of Lipschitzians},
  author={Tian, Lai and So, Anthony Man-Cho},
  journal={arXiv preprint arXiv:2210.06907},
  year={2022}
}