\begin{thebibliography}{35}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Azuma(1967)]{azuma1967weighted}
Azuma, K.
\newblock Weighted sums of certain dependent random variables.
\newblock \emph{Tohoku Mathematical Journal, Second Series}, 19\penalty0
  (3):\penalty0 357--367, 1967.

\bibitem[Ben-Tal et~al.(2009)Ben-Tal, El~Ghaoui, and Nemirovski]{ben2009robust}
Ben-Tal, A., El~Ghaoui, L., and Nemirovski, A.
\newblock \emph{Robust optimization}.
\newblock Princeton university press, 2009.

\bibitem[Bhagoji et~al.(2019)Bhagoji, Cullina, and Mittal]{bhagoji2019lower}
Bhagoji, A.~N., Cullina, D., and Mittal, P.
\newblock Lower bounds on adversarial robustness from optimal transport.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Bhattacharjee et~al.(2021)Bhattacharjee, Jha, and
  Chaudhuri]{bhattacharjee2021sample}
Bhattacharjee, R., Jha, S., and Chaudhuri, K.
\newblock Sample complexity of robust linear classification on separated data.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  884--893, 2021.

\bibitem[Blum et~al.(2020)Blum, Dick, Manoj, and Zhang]{blum2020random}
Blum, A., Dick, T., Manoj, N., and Zhang, H.
\newblock Random smoothing might be unable to certify $\ell_\infty$ robustness
  for high-dimensional images.
\newblock \emph{Journal of Machine Learning Research}, 21:\penalty0 1--21,
  2020.

\bibitem[Bubeck \& Sellke(2023)Bubeck and Sellke]{bubeck2021universal}
Bubeck, S. and Sellke, M.
\newblock A universal law of robustness via isoperimetry.
\newblock \emph{Journal of the ACM}, 70\penalty0 (2):\penalty0 1--18, 2023.

\bibitem[Bubeck et~al.(2021)Bubeck, Li, and Nagaraj]{pmlr-v134-bubeck21a}
Bubeck, S., Li, Y., and Nagaraj, D.~M.
\newblock A law of robustness for two-layers neural networks.
\newblock In \emph{Annual Conference on Learning Theory}, volume 134, pp.\
  804--820, 2021.

\bibitem[Case et~al.(2019)Case, Gallagher, and Gao]{case2019note}
Case, B.~M., Gallagher, C., and Gao, S.
\newblock A note on sub-gaussian random variables.
\newblock \emph{Cryptology ePrint Archive}, 2019.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{cohen2019certified}
Cohen, J.~M., Rosenfeld, E., and Kolter, J.~Z.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock \emph{ICML}, 2019.

\bibitem[Cullina et~al.(2018)Cullina, Bhagoji, and Mittal]{cullina2018pac}
Cullina, D., Bhagoji, A.~N., and Mittal, P.
\newblock {PAC}-learning in the presence of evasion adversaries.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  230--241, 2018.

\bibitem[Dan et~al.(2020)Dan, Wei, and Ravikumar]{dan2020sharp}
Dan, C., Wei, Y., and Ravikumar, P.
\newblock Sharp statistical guaratees for adversarially robust gaussian
  classification.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2345--2355, 2020.

\bibitem[Dobriban et~al.(2020)Dobriban, Hassani, Hong, and
  Robey]{dobriban2020provable}
Dobriban, E., Hassani, H., Hong, D., and Robey, A.
\newblock Provable tradeoffs in adversarially robust classification.
\newblock \emph{arXiv preprint arXiv:2006.05161}, 2020.

\bibitem[Gao et~al.(2019)Gao, Cai, Li, Hsieh, Wang, and
  Lee]{gao2019convergence}
Gao, R., Cai, T., Li, H., Hsieh, C.-J., Wang, L., and Lee, J.~D.
\newblock Convergence of adversarial training in overparametrized neural
  networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 13029--13040, 2019.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Huber(2004)]{huber2004robust}
Huber, P.~J.
\newblock \emph{Robust statistics}, volume 523.
\newblock John Wiley \& Sons, 2004.

\bibitem[Kumar et~al.(2020)Kumar, Levine, Goldstein, and Feizi]{kumar2020curse}
Kumar, A., Levine, A., Goldstein, T., and Feizi, S.
\newblock Curse of dimensionality on randomized smoothing for certifiable
  robustness.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5458--5467, 2020.

\bibitem[Li et~al.(2019)Li, Chen, Wang, and Carin]{li2019certified}
Li, B., Chen, C., Wang, W., and Carin, L.
\newblock Certified adversarial robustness with additive noise.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  9464--9474, 2019.

\bibitem[Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Mendelson \& Vershynin(2003)Mendelson and
  Vershynin]{mendelson2003entropy}
Mendelson, S. and Vershynin, R.
\newblock Entropy and the combinatorial dimension.
\newblock \emph{Inventiones mathematicae}, 152\penalty0 (1):\penalty0 37--55,
  2003.

\bibitem[Montasser et~al.(2019)Montasser, Hanneke, and Srebro]{montasser2019vc}
Montasser, O., Hanneke, S., and Srebro, N.
\newblock {VC} classes are adversarially robustly learnable, but only
  improperly.
\newblock In \emph{Annual Conference on Learning Theory}, pp.\  2512--2530,
  2019.

\bibitem[Northcutt et~al.(2021)Northcutt, Athalye, and
  Mueller]{northcutt2021pervasive}
Northcutt, C.~G., Athalye, A., and Mueller, J.
\newblock Pervasive label errors in test sets destabilize machine learning
  benchmarks.
\newblock In \emph{NeurIPS 2021 Datasets and Benchmarks Track}, 2021.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  Madry]{schmidt2018adversarially}
Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., and Madry, A.
\newblock Adversarially robust generalization requires more data.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Shalev-Shwartz \& Ben-David(2014)Shalev-Shwartz and
  Ben-David]{shalev2014understanding}
Shalev-Shwartz, S. and Ben-David, S.
\newblock \emph{Understanding machine learning: From theory to algorithms}.
\newblock Cambridge university press, 2014.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[von Luxburg \& Bousquet(2004)von Luxburg and
  Bousquet]{von2004distance}
von Luxburg, U. and Bousquet, O.
\newblock Distance-based classification with {Lipschitz} functions.
\newblock \emph{Journal of Machine Learning Research}, 5:\penalty0 669--695,
  2004.

\bibitem[Wu et~al.(2022{\natexlab{a}})Wu, Huang, Hu, and Huang]{wu2022faster}
Wu, X., Huang, F., Hu, Z., and Huang, H.
\newblock Faster adaptive federated learning.
\newblock \emph{arXiv preprint arXiv:2212.00974}, 2022{\natexlab{a}}.

\bibitem[Wu et~al.(2023)Wu, Hu, and Huang]{wu2023decentralized}
Wu, X., Hu, Z., and Huang, H.
\newblock Decentralized riemannian algorithm for nonconvex minimax problems.
\newblock \emph{arXiv preprint arXiv:2302.03825}, 2023.

\bibitem[Wu et~al.(2021)Wu, Bojchevski, Kuvshinov, and
  G{\"u}nnemann]{wu2021completing}
Wu, Y., Bojchevski, A., Kuvshinov, A., and G{\"u}nnemann, S.
\newblock Completing the picture: Randomized smoothing suffers from the curse
  of dimensionality for a large family of distributions.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  3763--3771. PMLR, 2021.

\bibitem[Wu et~al.(2022{\natexlab{b}})Wu, Bojchevski, and
  Huang]{wu2022adversarial}
Wu, Y., Bojchevski, A., and Huang, H.
\newblock Adversarial weight perturbation improves generalization in graph
  neural network.
\newblock \emph{arXiv preprint arXiv:2212.04983}, 2022{\natexlab{b}}.

\bibitem[Wu et~al.(2022{\natexlab{c}})Wu, Li, Kerschbaum, Huang, and
  Zhang]{wu2022towards}
Wu, Y., Li, X., Kerschbaum, F., Huang, H., and Zhang, H.
\newblock Towards robust dataset learning.
\newblock \emph{arXiv preprint arXiv:2211.10752}, 2022{\natexlab{c}}.

\bibitem[Wu et~al.(2022{\natexlab{d}})Wu, Zhang, and
  Huang]{wu2022retrievalguard}
Wu, Y., Zhang, H., and Huang, H.
\newblock Retrievalguard: Provably robust 1-nearest neighbor image retrieval.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  24266--24279. PMLR, 2022{\natexlab{d}}.

\bibitem[Yang et~al.(2020{\natexlab{a}})Yang, Duan, Hu, Salman, Razenshteyn,
  and Li]{yang2020randomized}
Yang, G., Duan, T., Hu, J.~E., Salman, H., Razenshteyn, I., and Li, J.
\newblock Randomized smoothing of all shapes and sizes.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  10693--10705, 2020{\natexlab{a}}.

\bibitem[Yang et~al.(2020{\natexlab{b}})Yang, Rashtchian, Zhang, Salakhutdinov,
  and Chaudhuri]{yang2020closer}
Yang, Y.-Y., Rashtchian, C., Zhang, H., Salakhutdinov, R., and Chaudhuri, K.
\newblock A closer look at accuracy vs. robustness.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2020{\natexlab{b}}.

\bibitem[Yin et~al.(2019)Yin, Kannan, and Bartlett]{yin2019rademacher}
Yin, D., Kannan, R., and Bartlett, P.
\newblock Rademacher complexity for adversarially robust generalization.
\newblock In \emph{International conference on machine learning}, pp.\
  7085--7094, 2019.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, El~Ghaoui, and
  Jordan]{zhang2019theoretically}
Zhang, H., Yu, Y., Jiao, J., Xing, E., El~Ghaoui, L., and Jordan, M.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7472--7482, 2019.

\end{thebibliography}
