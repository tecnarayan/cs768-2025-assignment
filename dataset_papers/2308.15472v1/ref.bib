@String(PAMI   = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV   = {Int. J. Comput. Vis.})
@String(CVPR   = {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(CVPRW  = {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(ICCV   = {Int. Conf. Comput. Vis.})
@String(ICCVW  = {Int. Conf. Comput. Vis. Worksh.})
@String(ECCV   = {Eur. Conf. Comput. Vis.})
@String(ECCVW  = {Eur. Conf. Comput. Vis. Worksh.})
@String(NIPS   = {Adv. Neural Inform. Process. Syst.})
@String(NIPSW  = {Adv. Neural Inform. Process. Syst. Worksh.})
@String(ICML   = {Int. Conf. Mach. Learn.})
@String(ICMLW  = {Int. Conf. Mach. Learn. Worksh.})
@String(ICLR   = {Int. Conf. Learn. Represent.})
@String(ICLRW  = {Int. Conf. Learn. Represent. Worksh.})
@String(AAAI   = {Assoc. Adv. Artif. Intell.})
@String(IJCAI  = {Int. Joint Conf. Artif. Intell.})
@String(BMVC   = {Brit. Mach. Vis. Conf.})
@String(ACCV   = {Asian Conf. Comput. Vis.})
@String(ICPR   = {Int. Conf. Pattern Recog.})
@String(TOG    = {ACM Trans. Graph.})
@String(TIP    = {IEEE Trans. Image Process.})
@String(TVCG   = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM    = {IEEE Trans. Multimedia})
@String(ACMMM  = {ACM Int. Conf. Multimedia})
@String(ICME   = {Int. Conf. Multimedia and Expo})
@String(ICASSP = {ICASSP})
@String(ICIP   = {IEEE Int. Conf. Image Process.})
@String(PR     = {Pattern Recog.})
@String(CSVT   = {IEEE Trans. Circuit Syst. Video Technol.})
@String(SPL	   = {IEEE Sign. Process. Letters})
@String(VR     = {Vis. Res.})
@String(JOV	   = {J. Vis.})
@String(TVC    = {The Vis. Comput.})
@String(JCST   = {J. Comput. Sci. Tech.})
@String(CGF    = {Comput. Graph. Forum})
@String(CVM    = {Computational Visual Media})
@String(WACV   = {IEEE Winter Conf. Appl. Comput. Vis.})
@String(JMLR   = {JMLR})
@String(SIGGRAPH   = {SIGGRAPH})

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{van2016conditional,
  title={Conditional image generation with pixelcnn decoders},
  author={Van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and Vinyals, Oriol and Graves, Alex and others},
  journal=NIPS,
  volume={29},
  year={2016}
}

@inproceedings{van2016pixel,
  title={Pixel recurrent neural networks},
  author={Van Den Oord, A{\"a}ron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
  booktitle=ICML,
  pages={1747--1756},
  year={2016},
  organization={PMLR}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal=NIPS,
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle=ICML,
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}

@inproceedings{huang2017arbitrary,
  title={Arbitrary style transfer in real-time with adaptive instance normalization},
  author={Huang, Xun and Belongie, Serge},
  booktitle=ICCV,
  year={2017}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle=ICML,
  year={2021}
}

@inproceedings{kynkaanniemi2022role,
  title={The Role of {ImageNet} Classes in Fr$\backslash$'echet Inception Distance},
  author={Kynk{\"a}{\"a}nniemi, Tuomas and Karras, Tero and Aittala, Miika and Aila, Timo and Lehtinen, Jaakko},
  booktitle=ICLR,
  year={2023}
}

@inproceedings{nash2021generating,
  title={Generating images with sparse representations},
  author={Nash, Charlie and Menick, Jacob and Dieleman, Sander and Battaglia, Peter W},
  booktitle=ICML,
  year={2021}
}

@inproceedings{heusel2017gans,
  title={{GAN}s trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  booktitle=NIPS,
  year={2017}
}

@article{yu2015lsun,
  title={{LSUN}: Construction of a large-scale image dataset using deep learning with humans in the loop},
  author={Yu, Fisher and Seff, Ari and Zhang, Yinda and Song, Shuran and Funkhouser, Thomas and Xiao, Jianxiong},
  journal={arXiv preprint arXiv:1506.03365},
  year={2015}
}

@inproceedings{deng2009imagenet,
  title={{ImageNet}: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle=CVPR,
  year={2009}
}

@article{yang2021semantic,
  title={Semantic hierarchy emerges in deep generative representations for scene synthesis},
  author={Yang, Ceyuan and Shen, Yujun and Zhou, Bolei},
  journal=IJCV,
  year={2021}
}

@inproceedings{wang2022internimage,
  title={{InternImage}: Exploring large-scale vision foundation models with deformable convolutions},
  author={Wang, Wenhai and Dai, Jifeng and Chen, Zhe and Huang, Zhenhang and Li, Zhiqi and Zhu, Xizhou and Hu, Xiaowei and Lu, Tong and Lu, Lewei and Li, Hongsheng and others},
  booktitle=CVPR,
  year={2023}
}

@inproceedings{zhu2019deformable,
  title={Deformable convnets v2: More deformable, better results},
  author={Zhu, Xizhou and Hu, Han and Lin, Stephen and Dai, Jifeng},
  booktitle=CVPR,
  year={2019}
}

@inproceedings{dai2017deformable,
  title={Deformable convolutional networks},
  author={Dai, Jifeng and Qi, Haozhi and Xiong, Yuwen and Li, Yi and Zhang, Guodong and Hu, Han and Wei, Yichen},
  booktitle=ICCV,
  year={2017}
}

@inproceedings{jaderberg2015spatial,
  title={Spatial transformer networks},
  author={Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and others},
  booktitle=NIPS,
  year={2015}
}

@inproceedings{gan,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle=NIPS,
  year={2014}
}

@article{walton2022stylenat,
  title={{StyleNAT}: Giving Each Head a New Perspective},
  author={Walton, Steven and Hassani, Ali and Xu, Xingqian and Wang, Zhangyang and Shi, Humphrey},
  journal={arXiv preprint arXiv:2211.05770},
  year={2022}
}

@inproceedings{sauer2023stylegan,
  title={{StyleGAN-T}: Unlocking the power of {GAN}s for fast large-scale text-to-image synthesis},
  author={Sauer, Axel and Karras, Tero and Laine, Samuli and Geiger, Andreas and Aila, Timo},
  booktitle=ICML,
  year={2023}
}

@inproceedings{kang2023scaling,
  title={Scaling up {GAN}s for text-to-image synthesis},
  author={Kang, Minguk and Zhu, Jun-Yan and Zhang, Richard and Park, Jaesik and Shechtman, Eli and Paris, Sylvain and Park, Taesung},
  booktitle=CVPR,
  year={2023}
}

@article{mirza2014conditional,
  title={Conditional generative adversarial nets},
  author={Mirza, Mehdi and Osindero, Simon},
  journal={arXiv preprint arXiv:1411.1784},
  year={2014}
}

@inproceedings{radford2015unsupervised,
  title={Unsupervised representation learning with deep convolutional generative adversarial networks},
  author={Radford, Alec and Metz, Luke and Chintala, Soumith},
  booktitle=ICLR,
  year={2016}
}

@inproceedings{gulrajani2017improved,
  title={Improved training of wasserstein {GAN}s},
  author={Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
  booktitle=NIPS,
  year={2017}
}

@inproceedings{brock2018biggan,
  title={Large scale {GAN} training for high fidelity natural image synthesis},
  author={Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
  booktitle=ICLR,
  year={2019}
}

@inproceedings{karras2017progressive,
  title={Progressive growing of {GAN}s for improved quality, stability, and variation},
  author={Karras, Tero and Aila, Timo and Laine, Samuli and Lehtinen, Jaakko},
  booktitle=ICLR,
  year={2018}
}

@inproceedings{karras2019stylegan,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle=CVPR,
  year={2019}
}

@inproceedings{karras2020stylegan2,
  title={Analyzing and improving the image quality of {StyleGAN}},
  author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  booktitle=CVPR,
  year={2020}
}

@inproceedings{karras2020training,
  title={Training generative adversarial networks with limited data},
  author={Karras, Tero and Aittala, Miika and Hellsten, Janne and Laine, Samuli and Lehtinen, Jaakko and Aila, Timo},
  booktitle=NIPS,
  year={2020}
}

@inproceedings{liu2021FastGAN,
  title={Towards faster and stabilized {GAN} training for high-fidelity few-shot image synthesis},
  author={Liu, Bingchen and Zhu, Yizhe and Song, Kunpeng and Elgammal, Ahmed},
  booktitle=ICLR,
  year={2021}
}

@inproceedings{karras2021alias,
  title={Alias-free generative adversarial networks},
  author={Karras, Tero and Aittala, Miika and Laine, Samuli and H{\"a}rk{\"o}nen, Erik and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  booktitle=NIPS,
  year={2021}
}

@inproceedings{esser2021taming,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle=CVPR,
  year={2021}
}

@inproceedings{sauer2022stylegan,
  title={{StyleGAN-XL}: Scaling {StyleGAN} to large diverse datasets},
  author={Sauer, Axel and Schwarz, Katja and Geiger, Andreas},
  booktitle=SIGGRAPH,
  year={2022}
}

@inproceedings{bai2022glead,
  title={{GLeaD}: Improving {GAN}s with A Generator-Leading Task},
  author={Bai, Qingyan and Yang, Ceyuan and Xu, Yinghao and Liu, Xihui and Yang, Yujiu and Shen, Yujun},
  booktitle=CVPR,
  year={2023}
}

@inproceedings{jolicoeur2018relativistic,
  title={The relativistic discriminator: a key element missing from standard {GAN}},
  author={Jolicoeur-Martineau, Alexia},
  booktitle = ICLR,
  year={2019}
}


@inproceedings{yang2021insgen,
  title={Data-efficient instance generation from instance discrimination},
  author={Yang, Ceyuan and Shen, Yujun and Xu, Yinghao and Zhou, Bolei},
  booktitle=NIPS,
  year={2021}
}

@inproceedings{yang2022improving,
  title={Improving {GAN}s with A Dynamic Discriminator},
  author={Yang, Ceyuan and Shen, Yujun and Xu, Yinghao and Zhao, Deli and Dai, Bo and Zhou, Bolei},
  booktitle=NIPS,
  year={2022}
}

@inproceedings{lee2022ggdr,
  title={Generator Knows What Discriminator Should Learn in Unconditional {GAN}s},
  author={Lee, Gayoung and Kim, Hyunsu and Kim, Junho and Kim, Seonghyeon and Ha, Jung-Woo and Choi, Yunjey},
  booktitle=ECCV,
  year={2022}
}

@inproceedings{chen2019self,
  title={Self-supervised {GAN}s via auxiliary rotation loss},
  author={Chen, Ting and Zhai, Xiaohua and Ritter, Marvin and Lucic, Mario and Houlsby, Neil},
  booktitle=CVPR,
  year={2019}
}

@inproceedings{tran2019self,
  title={Self-supervised {GAN}: Analysis and improvement with multi-class minimax game},
  author={Tran, Ngoc-Trung and Tran, Viet-Hung and Nguyen, Ngoc-Bao and Yang, Linxiao and Cheung, Ngai-Man},
  booktitle=NIPS,
  year={2019}
}

@inproceedings{zhang2019consistency,
  title={Consistency regularization for generative adversarial networks},
  author={Zhang, Han and Zhang, Zizhao and Odena, Augustus and Lee, Honglak},
  booktitle=ICLR,
  year={2020}
}

@inproceedings{zhao2020improved,
  title={Improved consistency regularization for {GAN}s},
  author={Zhao, Zhengli and Singh, Sameer and Lee, Honglak and Zhang, Zizhao and Odena, Augustus and Zhang, Han},
  booktitle=AAAI,
  year={2020}
}

@inproceedings{jeong2021training,
  title={Training {GAN}s with Stronger Augmentations via Contrastive Discriminator},
  author={Jeong, Jongheon and Shin, Jinwoo},
  booktitle=ICLR,
  year={2021}
}

@inproceedings{kang2020contragan,
  title={{ContraGAN}: Contrastive Learning for Conditional Image Generation},
  author={Kang, Minguk and Park, Jaesik},
  booktitle=NIPS,
  year={2020}
}

@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle=ICML,
  pages={214--223},
  year={2017}
}

@inproceedings{mescheder2018training,
  title={Which training methods for {GAN}s do actually converge?},
  author={Mescheder, Lars and Geiger, Andreas and Nowozin, Sebastian},
  booktitle=ICML,
  year={2018},
}

@inproceedings{zhao2022generative,
  title={Generative multiplane images: Making a 2d {GAN} 3d-aware},
  author={Zhao, Xiaoming and Ma, Fangchang and G{\"u}era, David and Ren, Zhile and Schwing, Alexander G and Colburn, Alex},
  booktitle=ECCV,
  year={2022}
}

@inproceedings{xu2022discoscene,
  title={{DisCoScene}: Spatially Disentangled Generative Radiance Fields for Controllable 3D-aware Scene Synthesis},
  author={Xu, Yinghao and Chai, Menglei and Shi, Zifan and Peng, Sida and Skorokhodov, Ivan and Siarohin, Aliaksandr and Yang, Ceyuan and Shen, Yujun and Lee, Hsin-Ying and Zhou, Bolei and others},
  booktitle=CVPR,
  year={2023}
}

@inproceedings{nguyen2019hologan,
  title={{HoloGAN}: Unsupervised learning of 3d representations from natural images},
  author={Nguyen-Phuoc, Thu and Li, Chuan and Theis, Lucas and Richardt, Christian and Yang, Yong-Liang},
  booktitle=ICCV,
  year={2019}
}

@article{zhou2021cips,
  title={{CIPS-3D}: A 3d-aware generator of {GAN}s based on conditionally-independent pixel synthesis},
  author={Zhou, Peng and Xie, Lingxi and Ni, Bingbing and Tian, Qi},
  journal={arXiv preprint arXiv:2110.09788},
  year={2021}
}

@inproceedings{chan2021pi,
  title={{$\pi$-GAN}: Periodic implicit generative adversarial networks for 3d-aware image synthesis},
  author={Chan, Eric R and Monteiro, Marco and Kellnhofer, Petr and Wu, Jiajun and Wetzstein, Gordon},
  booktitle=CVPR,
  year={2021}
}

@inproceedings{gu2021stylenerf,
  title={Stylenerf: A style-based 3d-aware generator for high-resolution image synthesis},
  author={Gu, Jiatao and Liu, Lingjie and Wang, Peng and Theobalt, Christian},
  booktitle=ICLR,
  year={2022}
}

@inproceedings{xu2022volumeGAN,
  title={3d-aware image synthesis via learning structural and textural representations},
  author={Xu, Yinghao and Peng, Sida and Yang, Ceyuan and Shen, Yujun and Zhou, Bolei},
  booktitle=CVPR,
  year={2022}
}

@inproceedings{shi20223daware,
  title   = {3D-Aware Indoor Scene Synthesis with Depth Priors},
  author  = {Shi, Zifan and Shen, Yujun and Zhu, Jiapeng and Yeung, Dit-Yan and Chen, Qifeng},
  booktitle = ECCV,
  year    = {2022}
}

@inproceedings{chan2022efficient,
  title={Efficient geometry-aware 3D generative adversarial networks},
  author={Chan, Eric R and Lin, Connor Z and Chan, Matthew A and Nagano, Koki and Pan, Boxiao and De Mello, Shalini and Gallo, Orazio and Guibas, Leonidas J and Tremblay, Jonathan and Khamis, Sameh and others},
  booktitle=CVPR,
  year={2022}
}

@inproceedings{peebles2020hessian,
  title={The hessian penalty: A weak prior for unsupervised disentanglement},
  author={Peebles, William and Peebles, John and Zhu, Jun-Yan and Efros, Alexei and Torralba, Antonio},
  booktitle=ECCV,
  year={2020},
}

@inproceedings{he2021eigengan,
  title={{EigenGAN}: Layer-wise eigen-learning for {GAN}s},
  author={He, Zhenliang and Kan, Meina and Shan, Shiguang},
  booktitle=ICCV,
  year={2021}
}

@article{zhu2023linkgan,
  title={{LinkGAN}: Linking {GAN} Latents to Pixels for Controllable Image Synthesis},
  author={Zhu, Jiapeng and Yang, Ceyuan and Shen, Yujun and Shi, Zifan and Zhao, Deli and Chen, Qifeng},
  journal={arXiv preprint arXiv:2301.04604},
  year={2023}
}

@inproceedings{wang2022improving,
  title={Improving {GAN} equilibrium by raising spatial awareness},
  author={Wang, Jianyuan and Yang, Ceyuan and Xu, Yinghao and Shen, Yujun and Li, Hongdong and Zhou, Bolei},
  booktitle=CVPR,
  year={2022}
}

@inproceedings{zhang2022towards,
  title={Towards Smooth Video Composition},
  author={Zhang, Qihang and Yang, Ceyuan and Shen, Yujun and Xu, Yinghao and Zhou, Bolei},
  booktitle=ICLR,
  year={2023}
}

@inproceedings{tian2021mocoganhd,
  title={A good image generator is what you need for high-resolution video synthesis},
  author={Tian, Yu and Ren, Jian and Chai, Menglei and Olszewski, Kyle and Peng, Xi and Metaxas, Dimitris N and Tulyakov, Sergey},
  booktitle=ICLR,
  year={2021}
}

@inproceedings{saito2017tgan,
  title={Temporal generative adversarial nets with singular value clipping},
  author={Saito, Masaki and Matsumoto, Eiichi and Saito, Shunta},
  booktitle=ICCV,
  year={2017}
}

@inproceedings{tulyakov2018mocogan,
  title={{MoCoGAN}: Decomposing motion and content for video generation},
  author={Tulyakov, Sergey and Liu, Ming-Yu and Yang, Xiaodong and Kautz, Jan},
  booktitle=CVPR,
  year={2018}
}

@inproceedings{skorokhodov2022stylegan,
  title={{Stylegan-V}: A continuous video generator with the price, image quality and perks of {StyleGAN2}},
  author={Skorokhodov, Ivan and Tulyakov, Sergey and Elhoseiny, Mohamed},
  booktitle=CVPR,
  year={2022}
}

@inproceedings{brooks2022generating,
  title={Generating Long Videos of Dynamic Scenes},
  author={Brooks, Tim and Hellsten, Janne and Aittala, Miika and Wang, Ting-Chun and Aila, Timo and Lehtinen, Jaakko and Liu, Ming-Yu and Efros, Alexei A and Karras, Tero},
  booktitle=NIPS,
  year={2022}
}

@inproceedings{lin2019tsm,
  title={{TSM}: Temporal shift module for efficient video understanding},
  author={Lin, Ji and Gan, Chuang and Han, Song},
  booktitle=ICCV,
  year={2019}
}

@inproceedings{dcgan,
  title={Unsupervised representation learning with deep convolutional generative adversarial networks},
  author={Radford, Alec and Metz, Luke and Chintala, Soumith},
  booktitle=ICLR,
  year={2016}
}

@inproceedings{biggan,
  title={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},
  author={Andrew Brock and Jeff Donahue and Karen Simonyan},
  booktitle=ICLR,
  year={2019}
}

@inproceedings{stylegan2,
  title={Analyzing and Improving the Image Quality of StyleGAN},
  author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  booktitle=CVPR,
  year={2020}
}

@inproceedings{fox2021stylevideogan,
  title={{StyleVideoGAN}: A temporal generative model using a pretrained {StyleGAN}},
  author={Fox, Gereon and Tewari, Ayush and Elgharib, Mohamed and Theobalt, Christian},
  booktitle=BMVC,
  year={2021}
}

@inproceedings{yu2022dign,
  title={Generating videos with dynamics-aware implicit generative adversarial networks},
  author={Yu, Sihyun and Tack, Jihoon and Mo, Sangwoo and Kim, Hyunsu and Kim, Junho and Ha, Jung-Woo and Shin, Jinwoo},
  booktitle=ICLR,
  year={2022}
}

@article{yan2021videogpt,
  title={{VideoGPT}: Video generation using {VQ-VAE} and transformers},
  author={Yan, Wilson and Zhang, Yunzhi and Abbeel, Pieter and Srinivas, Aravind},
  journal={arXiv preprint arXiv:2104.10157},
  year={2021}
}

@inproceedings{kalchbrenner2017videopixel,
  title={Video pixel networks},
  author={Kalchbrenner, Nal and Oord, A{\"a}ron and Simonyan, Karen and Danihelka, Ivo and Vinyals, Oriol and Graves, Alex and Kavukcuoglu, Koray},
  booktitle=ICML,
  year={2017},
}

@article{walker2021prediction,
  title={Predicting video with {VQVAE}},
  author={Walker, Jacob and Razavi, Ali and Oord, A{\"a}ron van den},
  journal={arXiv preprint arXiv:2103.01950},
  year={2021}
}

@inproceedings{weissenborn2019scaling,
  title={Scaling autoregressive video models},
  author={Weissenborn, Dirk and T{\"a}ckstr{\"o}m, Oscar and Uszkoreit, Jakob},
  booktitle=ICLR,
  year={2020}
}

@inproceedings{van2016pixelcnn,
  title={Conditional image generation with pixelcnn decoders},
  author={Van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and Vinyals, Oriol and Graves, Alex and others},
  journal=NIPS,
  year={2016},
}

@inproceedings{ho2022videodiffusion,
  title={Video diffusion models},
  author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
  booktitle=NIPS,
  year={2022}
}

@article{yang2022diffusion,
  title={Diffusion probabilistic modeling for video generation},
  author={Yang, Ruihan and Srivastava, Prakhar and Mandt, Stephan},
  journal={arXiv preprint arXiv:2203.09481},
  year={2022}
}

@inproceedings{babaeizadeh2017stochastic,
  title={Stochastic variational video prediction},
  author={Babaeizadeh, Mohammad and Finn, Chelsea and Erhan, Dumitru and Campbell, Roy H and Levine, Sergey},
  booktitle=ICLR,
  year={2018}
}

@inproceedings{kumar2019videoflow,
  title={{VideoFlow}: A conditional flow-based model for stochastic video generation},
  author={Kumar, Manoj and Babaeizadeh, Mohammad and Erhan, Dumitru and Finn, Chelsea and Levine, Sergey and Dinh, Laurent and Kingma, Durk},
  booktitle=ICLR,
  year={2020}
}

@article{lee2018stochastic,
  title={Stochastic adversarial video prediction},
  author={Lee, Alex X and Zhang, Richard and Ebert, Frederik and Abbeel, Pieter and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:1804.01523},
  year={2018}
}

@article{luc2020transformation,
  title={Transformation-based adversarial video prediction on large-scale data},
  author={Luc, Pauline and Clark, Aidan and Dieleman, Sander and Casas, Diego de Las and Doron, Yotam and Cassirer, Albin and Simonyan, Karen},
  journal={arXiv preprint arXiv:2003.04035},
  year={2020}
}

@inproceedings{nash2022transframer,
  title={Transframer: Arbitrary Frame Prediction with Generative Models},
  author={Nash, Charlie and Carreira, Jo{\~a}o and Walker, Jacob and Barr, Iain and Jaegle, Andrew and Malinowski, Mateusz and Battaglia, Peter},
  booktitle=TMLR,
  year={2023}
}

@inproceedings{finn2016unsupervised,
  title={Unsupervised learning for physical interaction through video prediction},
  author={Finn, Chelsea and Goodfellow, Ian and Levine, Sergey},
  booktitle=NIPS,
  year={2016}
}

@inproceedings{Yang_2018_ECCV,
  author={Yang, Ceyuan and Wang, Zhe and Zhu, Xinge and Huang, Chen and Shi, Jianping and Lin, Dahua},
  title={Pose Guided Human Video Generation},
  booktitle=ECCV,
  year = {2018}
}

@inproceedings{wang2018video,
  title={Video-to-video synthesis},
  author={Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Liu, Guilin and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
  booktitle=NIPS,
  year={2018}
}

@inproceedings{ren2022look,
  title={Look Outside the Room: Synthesizing A Consistent Long-Term 3D Scene Video from A Single Image},
  author={Ren, Xuanchi and Wang, Xiaolong},
  booktitle=CVPR,
  year={2022}
}

@inproceedings{liu2021infinite,
  title={Infinite nature: Perpetual view generation of natural scenes from a single image},
  author={Liu, Andrew and Tucker, Richard and Jampani, Varun and Makadia, Ameesh and Snavely, Noah and Kanazawa, Angjoo},
  booktitle=CVPR,
  year={2021}
}

@inproceedings{li2022infinitenature,
  title={InfiniteNature-Zero: Learning Perpetual View Generation of Natural Scenes from Single Images},
  author={Li, Zhengqi and Wang, Qianqian and Snavely, Noah and Kanazawa, Angjoo},
  booktitle=ECCV,
  year={2022}
}

@inproceedings{hong2022cogvideo,
  title={CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers},
  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
  booktitle=ICLR,
  year={2023}
}

@article{wu2021godiva,
  title={Godiva: Generating open-domain videos from natural descriptions},
  author={Wu, Chenfei and Huang, Lun and Zhang, Qianxi and Li, Binyang and Ji, Lei and Yang, Fan and Sapiro, Guillermo and Duan, Nan},
  journal={arXiv preprint arXiv:2104.14806},
  year={2021}
}

@inproceedings{wu2021n,
  title={N$\backslash$" uwa: Visual synthesis pre-training for neural visual world creation},
  author={Wu, Chenfei and Liang, Jian and Ji, Lei and Yang, Fan and Fang, Yuejian and Jiang, Daxin and Duan, Nan},
  booktitle=ECCV,
  year={2022}
}

@inproceedings{chan2019everybody,
  title={Everybody dance now},
  author={Chan, Caroline and Ginosar, Shiry and Zhou, Tinghui and Efros, Alexei A},
  booktitle=ICCV,
  year={2019}
}

@inproceedings{ren2020human,
  title={Human motion transfer from poses in the wild},
  author={Ren, Jian and Chai, Menglei and Tulyakov, Sergey and Fang, Chen and Shen, Xiaohui and Yang, Jianchao},
  booktitle=ECCV,
  year={2020},
}

@inproceedings{ge2022long,
  title={Long video generation with time-agnostic {VQGAN} and time-sensitive transformer},
  author={Ge, Songwei and Hayes, Thomas and Yang, Harry and Yin, Xi and Pang, Guan and Jacobs, David and Huang, Jia-Bin and Parikh, Devi},
  booktitle=ECCV,
  year={2022}
}

@article{vondrick2016generating,
  title={Generating videos with scene dynamics},
  author={Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  journal=NIPS,
  year={2016}
}

@article{saito2020train,
  title={Train sparsely, generate densely: Memory-efficient unsupervised training of high-resolution temporal gan},
  author={Saito, Masaki and Saito, Shunta and Koyama, Masanori and Kobayashi, Sosuke},
  journal=IJCV,
  year={2020},
}

@article{rakhimov2020latent,
  title={Latent video transformer},
  author={Rakhimov, Ruslan and Volkhonskiy, Denis and Artemov, Alexey and Zorin, Denis and Burnaev, Evgeny},
  journal={arXiv preprint arXiv:2006.10704},
  year={2020}
}

@article{clark2019adversarial,
  title={Adversarial video generation on complex datasets},
  author={Clark, Aidan and Donahue, Jeff and Simonyan, Karen},
  journal={arXiv preprint arXiv:1907.06571},
  year={2019}
}

@inproceedings{wang2022latent,
  title={Latent Image Animator: Learning to Animate Images via Latent Space Navigation},
  author={Wang, Yaohui and Yang, Di and Bremond, Francois and Dantcheva, Antitza},
  booktitle=ICLR,
  year={2022}
}


@inproceedings{pan2019video,
  title={Video generation from single semantic label map},
  author={Pan, Junting and Wang, Chengyu and Jia, Xu and Shao, Jing and Sheng, Lu and Yan, Junjie and Wang, Xiaogang},
  booktitle=CVPR,
  year={2019}
}


@inproceedings{Siarohin_2019_NeurIPS,
  author={Siarohin, Aliaksandr and Lathuilière, Stéphane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu},
  title={First Order Motion Model for Image Animation},
  booktitle = NIPS,
  year = {2019}
}

@article{shen2020interfacegan,
  title   = {{InterFaceGAN}: Interpreting the Disentangled Face Representation Learned by {GAN}s},
  author  = {Shen, Yujun and Yang, Ceyuan and Tang, Xiaoou and Zhou, Bolei},
  journal = PAMI,
  year    = {2020}
}

@inproceedings{Siarohin_2019_CVPR,
  author={Siarohin, Aliaksandr and Lathuilière, Stéphane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu},
  title={Animating Arbitrary Objects via Deep Motion Transfer},
  booktitle = CVPR,
  year = {2019}
}

@inproceedings{jahanian2019steerability,
  title={On the" steerability" of generative adversarial networks},
  author={Jahanian, Ali and Chai, Lucy and Isola, Phillip},
  booktitle=ICLR,
  year={2020}
}

@inproceedings{Kim2021_DriveGAN,
  author = {Seung Wook Kim and and Jonah Philion and Antonio Torralba and Sanja Fidler},
  title = {{DriveGAN}: Towards a Controllable High-Quality Neural Simulation},
  year = {2021},
  booktitle = CVPR, 
}


@inproceedings{Kim2020_GameGan,
  author = {Seung Wook Kim and Yuhao Zhou and Jonah Philion and Antonio Torralba and Sanja Fidler},
  title = {{Learning to Simulate Dynamic Environments with GameGAN}},
  year = {2020},
  booktitle = CVPR,
}

@inproceedings{ha2018worldmodels,
  title={Recurrent World Models Facilitate Policy Evolution},
  author={Ha, David and Schmidhuber, J{\"u}rgen},
  booktitle=NIPS,
  year={2018},
}

@inproceedings{goetschalckx2019ganalyze,
  title={Ganalyze: Toward visual definitions of cognitive image properties},
  author={Goetschalckx, Lore and Andonian, Alex and Oliva, Aude and Isola, Phillip},
  booktitle=ICCV,
  year={2019}
}

@techreport{de1971subroutine,
  title={SUBROUTINE PACKAGE FOR CALCULATING WITH B-SPLINES.},
  author={de Boor, Carl},
  year={1971},
  institution={Los Alamos National Lab.(LANL), Los Alamos, NM (United States)}
}

@inproceedings{bau2020rewriting,
  title={Rewriting a deep generative model},
  author={Bau, David and Liu, Steven and Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio},
  booktitle=ECCV,
  year={2020},
}

@article{wang2022rewriting,
  title={Rewriting geometric rules of a GAN},
  author={Wang, Sheng-Yu and Bau, David and Zhu, Jun-Yan},
  journal=TOG,
  year={2022},
}

@inproceedings{karras2020analyzing,
  title={Analyzing and improving the image quality of stylegan},
  author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  booktitle=CVPR,
  year={2020}
}

@article{unterthiner2018towards,
  title={Towards accurate generative models of video: A new metric \& challenges},
  author={Unterthiner, Thomas and van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Raphael and Michalski, Marcin and Gelly, Sylvain},
  journal={arXiv preprint arXiv:1812.01717},
  year={2018}
}

@inproceedings{zhao2020differentiable,
  title={Differentiable augmentation for data-efficient {GAN} training},
  author={Zhao, Shengyu and Liu, Zhijian and Lin, Ji and Zhu, Jun-Yan and Han, Song},
  booktitle=NIPS,
  year={2020}
}

@article{qiu2022stylefacev,
  title={{StyleFaceV}: Face Video Generation via Decomposing and Recomposing Pretrained {StyleGAN3}},
  author={Qiu, Haonan and Jiang, Yuming and Zhou, Hang and Wu, Wayne and Liu, Ziwei},
  journal={arXiv preprint arXiv:2208.07862},
  year={2022}
}

@inproceedings{alaluf2022third,
  title={Third Time's the Charm? Image and Video Editing with {StyleGAN3}},
  author={Alaluf, Yuval and Patashnik, Or and Wu, Zongze and Zamir, Asif and Shechtman, Eli and Lischinski, Dani and Cohen-Or, Daniel},
  booktitle=ECCVW,
  year={2022}
}

@inproceedings{brock2018large,
  title={Large scale {GAN} training for high fidelity natural image synthesis},
  author={Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
  booktitle=ICLR,
  year={2018}
}

@inproceedings{yang2021data,
  title={Data-efficient instance generation from instance discrimination},
  author={Yang, Ceyuan and Shen, Yujun and Xu, Yinghao and Zhou, Bolei},
  booktitle=NIPS,
  year={2021}
}

@inproceedings{jiang2021deceive,
  title={Deceive D: Adaptive Pseudo Augmentation for {GAN} Training with Limited Data},
  author={Jiang, Liming and Dai, Bo and Wu, Wayne and Loy, Chen Change},
  booktitle=NIPS,
  year={2021}
}

@inproceedings{xiong2018learning,
  title={Learning to generate time-lapse videos using multi-stage dynamic generative adversarial networks},
  author={Xiong, Wei and Luo, Wenhan and Ma, Lin and Liu, Wei and Luo, Jiebo},
  booktitle=CVPR,
  year={2018}
}


@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={JMLR},
  year={2008}
}

@inproceedings{zhang2022learning,
  title={Learning to Drive by Watching YouTube Videos: Action-Conditioned Contrastive Policy Pretraining},
  author={Zhang, Qihang and Peng, Zhenghao and Zhou, Bolei},
  booktitle=ECCV,
  year={2022}
}

