\begin{thebibliography}{51}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Brandolini et~al.(2020)Brandolini, Colzani, Robins, and
  Travaglini]{Brandolini2020PicksTA}
Brandolini, L., Colzani, L., Robins, S., and Travaglini, G.
\newblock Pickâ€™s theorem and convergence of multiple fourier series.
\newblock \emph{Am. Math. Mon.}, 2020.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and
  Amodei]{NEURIPS2020_1457c0d6}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S.,
  Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler,
  D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray,
  S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever,
  I., and Amodei, D.
\newblock Language models are few-shot learners.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Brunton et~al.(2021)Brunton, Budisic, Kaiser, and
  Kutz]{Brunton2021ModernKT}
Brunton, S.~L., Budisic, M., Kaiser, E., and Kutz, J.~N.
\newblock Modern koopman theory for dynamical systems.
\newblock \emph{SIAM Rev.}, 2021.

\bibitem[Cao(2021)]{Cao2021ChooseAT}
Cao, S.
\newblock Choose a transformer: Fourier or galerkin.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Chen \& Chen(1995)Chen and Chen]{Chen1995UniversalAT}
Chen, T. and Chen, H.
\newblock Universal approximation to nonlinear operators by neural networks
  with arbitrary activation functions and its application to dynamical systems.
\newblock \emph{IEEE Trans. Neural Netw. Learn. Syst.}, 1995.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova]{Devlin2019BERTPO}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{NAACL}, 2019.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{dosovitskiy2021an}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S.,
  Uszkoreit, J., and Houlsby, N.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{ICLR}, 2021.

\bibitem[Dyachenko(1995)]{dyachenko1995rate}
Dyachenko, M.
\newblock The rate of u-convergence of multiple fourier series.
\newblock \emph{Acta Mathematica Hungarica}, 1995.

\bibitem[Evans(2010)]{evans2010partial}
Evans, L.~C.
\newblock \emph{Partial differential equations}.
\newblock American Mathematical Soc., 2010.

\bibitem[Fanaskov \& Oseledets(2022)Fanaskov and
  Oseledets]{Fanaskov2022SpectralNO}
Fanaskov, V. and Oseledets, I.
\newblock Spectral neural operators.
\newblock \emph{arXiv preprint arXiv:2205.10573}, 2022.

\bibitem[Fornberg(1998)]{fornberg1998practical}
Fornberg, B.
\newblock \emph{A practical guide to pseudospectral methods}.
\newblock Cambridge university press, 1998.

\bibitem[Gottlieb \& Orszag(1977)Gottlieb and Orszag]{gottlieb1977numerical}
Gottlieb, D. and Orszag, S.~A.
\newblock \emph{Numerical analysis of spectral methods: theory and
  applications}.
\newblock SIAM, 1977.

\bibitem[Grossmann et~al.(2007)Grossmann, Roos, and
  Stynes]{grossmann2007numerical}
Grossmann, C., Roos, H.-G., and Stynes, M.
\newblock \emph{Numerical treatment of partial differential equations}.
\newblock Springer, 2007.

\bibitem[Gupta et~al.(2021)Gupta, Xiao, and
  Bogdan]{Gupta2021MultiwaveletbasedOL}
Gupta, G., Xiao, X., and Bogdan, P.
\newblock Multiwavelet-based operator learning for differential equations.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Han et~al.(2017)Han, Jentzen, and E]{Han2017SolvingHP}
Han, J., Jentzen, A., and E, W.
\newblock Solving high-dimensional partial differential equations using deep
  learning.
\newblock \emph{PNAS}, 2017.

\bibitem[Hao et~al.(2022)Hao, Liu, Zhang, Ying, Feng, Su, and
  Zhu]{Hao2022PhysicsInformedML}
Hao, Z., Liu, S., Zhang, Y., Ying, C., Feng, Y., Su, H., and Zhu, J.
\newblock Physics-informed machine learning: A survey on problems, methods and
  applications.
\newblock \emph{arXiv preprint arXiv:2211.08064}, 2022.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{He2016DeepRL}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock \emph{CVPR}, 2016.

\bibitem[Jackson(1934)]{Jackson1934TheCO}
Jackson, D.
\newblock The convergence of fourier series.
\newblock \emph{American Mathematical Monthly}, 1934.

\bibitem[Jolliffe \& Cadima(2016)Jolliffe and Cadima]{jolliffe2016principal}
Jolliffe, I.~T. and Cadima, J.
\newblock Principal component analysis: a review and recent developments.
\newblock \emph{Philosophical Transactions of the Royal Society A:
  Mathematical, Physical and Engineering Sciences}, 2016.

\bibitem[Karniadakis et~al.(2021)Karniadakis, Kevrekidis, Lu, Perdikaris, Wang,
  and Yang]{karniadakis2021physics}
Karniadakis, G.~E., Kevrekidis, I.~G., Lu, L., Perdikaris, P., Wang, S., and
  Yang, L.
\newblock Physics-informed machine learning.
\newblock \emph{Nat. Rev. Phys.}, 2021.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{DBLP:journals/corr/KingmaB14}
Kingma, D.~P. and Ba, J.
\newblock Adam: {A} method for stochastic optimization.
\newblock In \emph{ICLR}, 2015.

\bibitem[Kopriva(2009)]{kopriva2009implementing}
Kopriva, D.~A.
\newblock \emph{Implementing spectral methods for partial differential
  equations: Algorithms for scientists and engineers}.
\newblock Springer Science \& Business Media, 2009.

\bibitem[Li et~al.(2021)Li, Kovachki, Azizzadenesheli, liu, Bhattacharya,
  Stuart, and Anandkumar]{li2021fourier}
Li, Z., Kovachki, N.~B., Azizzadenesheli, K., liu, B., Bhattacharya, K.,
  Stuart, A., and Anandkumar, A.
\newblock Fourier neural operator for parametric partial differential
  equations.
\newblock In \emph{ICLR}, 2021.

\bibitem[Li et~al.(2020)Li, Kovachki, Azizzadenesheli, Liu, Bhattacharya,
  Stuart, and Anandkumar]{Li2020NeuralOG}
Li, Z.-Y., Kovachki, N.~B., Azizzadenesheli, K., Liu, B., Bhattacharya, K.,
  Stuart, A., and Anandkumar, A.
\newblock Neural operator: Graph kernel network for partial differential
  equations.
\newblock \emph{arXiv preprint arXiv:2003.03485}, 2020.

\bibitem[Li et~al.(2022)Li, Huang, Liu, and Anandkumar]{Li2022FourierNO}
Li, Z.-Y., Huang, D.~Z., Liu, B., and Anandkumar, A.
\newblock Fourier neural operator with learned deformations for pdes on general
  geometries.
\newblock \emph{arXiv preprint arXiv:2207.05209}, 2022.

\bibitem[Liu et~al.(2022)Liu, Xu, and Zhang]{anonymous2023htnet}
Liu, X., Xu, B., and Zhang, L.
\newblock {HT}-net: Hierarchical transformer based operator learning model for
  multiscale {PDE}s.
\newblock \emph{arXiv preprint arXiv:2210.10890}, 2022.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and
  Guo]{liu2021Swin}
Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S. C.-F., and Guo,
  B.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock \emph{ICCV}, 2021.

\bibitem[Lu et~al.(2021)Lu, Jin, Pang, Zhang, and Karniadakis]{lu2021learning}
Lu, L., Jin, P., Pang, G., Zhang, Z., and Karniadakis, G.~E.
\newblock Learning nonlinear operators via deeponet based on the universal
  approximation theorem of operators.
\newblock \emph{Nat. Mach. Intell}, 2021.

\bibitem[McLean(2012)]{mclean2012continuum}
McLean, D.
\newblock Continuum fluid mechanics and the navier-stokes equations.
\newblock \emph{Understanding Aerodynamics: Arguing from the Real Physics},
  2012.

\bibitem[Morrison(2013)]{morrison2013introduction}
Morrison, F.~A.
\newblock \emph{An introduction to fluid mechanics}.
\newblock Cambridge University Press, 2013.

\bibitem[Nayak et~al.(2014)Nayak, Das, and Ray]{nayak2014estimate}
Nayak, L., Das, G., and Ray, B.
\newblock An estimate of the rate of convergence of fourier series in the
  generalized h{\"o}lder metric by deferred ces{\`a}ro mean.
\newblock \emph{J. Math. Anal. Appl}, 2014.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, K{\"o}pf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{Paszke2019PyTorchAI}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., K{\"o}pf, A., Yang,
  E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang,
  L., Bai, J., and Chintala, S.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, Liu, et~al.]{raffel2020exploring}
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou,
  Y., Li, W., Liu, P.~J., et~al.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock \emph{J. Mach. Learn. Res.}, 2020.

\bibitem[Rahman et~al.(2022)Rahman, Ross, and Azizzadenesheli]{rahman2022u}
Rahman, M.~A., Ross, Z.~E., and Azizzadenesheli, K.
\newblock U-no: U-shaped neural operators.
\newblock \emph{arXiv preprint arXiv:2204.11127}, 2022.

\bibitem[Raissi et~al.(2019)Raissi, Perdikaris, and
  Karniadakis]{Raissi2019PhysicsinformedNN}
Raissi, M., Perdikaris, P., and Karniadakis, G.~E.
\newblock Physics-informed neural networks: A deep learning framework for
  solving forward and inverse problems involving nonlinear partial differential
  equations.
\newblock \emph{J. Comput. Phys.}, 2019.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and
  Brox]{ronneberger2015u}
Ronneberger, O., Fischer, P., and Brox, T.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{MICCAI}, 2015.

\bibitem[Roub{\'\i}{\v{c}}ek(2013)]{roubivcek2013nonlinear}
Roub{\'\i}{\v{c}}ek, T.
\newblock \emph{Nonlinear partial differential equations with applications}.
\newblock Springer Science \& Business Media, 2013.

\bibitem[{\^S}ol{\'\i}n(2005)]{solin2005partial}
{\^S}ol{\'\i}n, P.
\newblock \emph{Partial differential equations and the finite element method}.
\newblock John Wiley \& Sons, 2005.

\bibitem[Temam(2001)]{temam2001navier}
Temam, R.
\newblock \emph{Navier-Stokes equations: theory and numerical analysis}.
\newblock American Mathematical Soc., 2001.

\bibitem[Tolstov(2012)]{tolstov2012fourier}
Tolstov, G.~P.
\newblock \emph{Fourier series}.
\newblock Courier Corporation, 2012.

\bibitem[Tran et~al.(2023)Tran, Mathews, Xie, and Ong]{anonymous2023factorized}
Tran, A., Mathews, A., Xie, L., and Ong, C.~S.
\newblock Factorized fourier neural operators.
\newblock In \emph{ICLR}, 2023.

\bibitem[Trunk(1979)]{Trunk1979APO}
Trunk, G.~V.
\newblock A problem of dimensionality: A simple example.
\newblock \emph{TPAMI}, 1979.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{NIPS2017_3f5ee243}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, L.~u., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Wang et~al.(2019)Wang, Kashinath, Mustafa, Albert, and
  Yu]{Wang2019TowardsPD}
Wang, R., Kashinath, K., Mustafa, M., Albert, A., and Yu, R.
\newblock Towards physics-informed deep learning for turbulent flow prediction.
\newblock \emph{KDD}, 2019.

\bibitem[Wang et~al.(2020{\natexlab{a}})Wang, Teng, and
  Perdikaris]{Wang2020UnderstandingAM}
Wang, S., Teng, Y., and Perdikaris, P.
\newblock Understanding and mitigating gradient pathologies in physics-informed
  neural networks.
\newblock \emph{SIAM J. Sci. Comput.}, 2020{\natexlab{a}}.

\bibitem[Wang et~al.(2020{\natexlab{b}})Wang, Yu, and
  Perdikaris]{Wang2020WhenAW}
Wang, S., Yu, X., and Perdikaris, P.
\newblock When and why pinns fail to train: A neural tangent kernel
  perspective.
\newblock \emph{J. Comput. Phys.}, 2020{\natexlab{b}}.

\bibitem[Wazwaz(2002)]{Wazwaz2002PartialDE}
Wazwaz, A.~M.
\newblock Partial differential equations : methods and applications.
\newblock 2002.

\bibitem[Weinan \& Yu(2017)Weinan and Yu]{Weinan2017TheDR}
Weinan, E. and Yu, T.
\newblock The deep ritz method: A deep learning-based numerical algorithm for
  solving variational problems.
\newblock \emph{Commun. Math. Stat.}, 2017.

\bibitem[Wen et~al.(2021)Wen, Li, Azizzadenesheli, Anandkumar, and
  Benson]{Wen2021UFNOA}
Wen, G., Li, Z.-Y., Azizzadenesheli, K., Anandkumar, A., and Benson, S.~M.
\newblock U-fno - an enhanced fourier neural operator based-deep learning model
  for multiphase flow.
\newblock \emph{arXiv preprint arXiv:2109.03697}, 2021.

\bibitem[Xiong et~al.(2023{\natexlab{a}})Xiong, Huang, Zhang, Deng, Sun, and
  Tian]{anonymous2023koopman}
Xiong, W., Huang, X., Zhang, Z., Deng, R., Sun, P., and Tian, Y.
\newblock Koopman neural operator as a mesh-free solver of non-linear partial
  differential equations.
\newblock \emph{arXiv preprint arXiv:2301.10022}, 2023{\natexlab{a}}.

\bibitem[Xiong et~al.(2023{\natexlab{b}})Xiong, Ma, Huang, Zhang, Sun, and
  Tian]{xiong2023koopmanlab}
Xiong, W., Ma, M., Huang, X., Zhang, Z., Sun, P., and Tian, Y.
\newblock Koopmanlab: machine learning for solving complex physics equations.
\newblock \emph{arXiv preprint arXiv:2301.01104}, 2023{\natexlab{b}}.

\end{thebibliography}
