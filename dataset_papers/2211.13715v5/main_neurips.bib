@article{scherrer2021learning,
  title={Learning neural causal models with active interventions},
  author={Scherrer, Nino and Bilaniuk, Olexa and Annadani, Yashas and Goyal, Anirudh and Schwab, Patrick and Sch{\"o}lkopf, Bernhard and Mozer, Michael C and Bengio, Yoshua and Bauer, Stefan and Ke, Nan Rosemary},
  journal={arXiv preprint arXiv:2109.02429},
  year={2021}
}

@inproceedings{lippe2021efficient,
  author    = {Phillip Lippe and
               Taco Cohen and
               Efstratios Gavves},
  title     = {Efficient Neural Causal Discovery without Acyclicity Constraints},
  booktitle = {The Tenth International Conference on Learning Representations, {ICLR}
               2022, Virtual Event, April 25-29, 2022},
  publisher = {OpenReview.net},
  year      = {2022},
  url       = {https://openreview.net/forum?id=eYciPrLuUhG},
  timestamp = {Sun, 02 Oct 2022 16:05:32 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/LippeCG22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lorch2021dibs,
  title={Dibs: Differentiable bayesian structure learning},
  author={Lorch, Lars and Rothfuss, Jonas and Sch{\"o}lkopf, Bernhard and Krause, Andreas},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={24111--24123},
  year={2021}
}

@misc{https://doi.org/10.48550/arxiv.1703.02910,
  doi = {10.48550/ARXIV.1703.02910},
  
  url = {https://arxiv.org/abs/1703.02910},
  
  author = {Gal, Yarin and Islam, Riashat and Ghahramani, Zoubin},
  
  keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Deep Bayesian Active Learning with Image Data},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{DBLP:conf/iclr/AshZK0A20,
  author    = {Jordan T. Ash and
               Chicheng Zhang and
               Akshay Krishnamurthy and
               John Langford and
               Alekh Agarwal},
  title     = {Deep Batch Active Learning by Diverse, Uncertain Gradient Lower Bounds},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  url       = {https://openreview.net/forum?id=ryghZJBKPS},
  timestamp = {Thu, 07 May 2020 17:11:48 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/AshZK0A20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/icml/GravesBMMK17,
  author    = {Alex Graves and
               Marc G. Bellemare and
               Jacob Menick and
               R{\'{e}}mi Munos and
               Koray Kavukcuoglu},
  editor    = {Doina Precup and
               Yee Whye Teh},
  title     = {Automated Curriculum Learning for Neural Networks},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning,
               {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017},
  series    = {Proceedings of Machine Learning Research},
  volume    = {70},
  pages     = {1311--1320},
  publisher = {{PMLR}},
  year      = {2017},
  url       = {http://proceedings.mlr.press/v70/graves17a.html},
  timestamp = {Wed, 29 May 2019 08:41:45 +0200},
  biburl    = {https://dblp.org/rec/conf/icml/GravesBMMK17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

%comp. biology 
@article{friedman2000using,
  title={Using Bayesian networks to analyze expression data},
  author={Friedman, Nir and Linial, Michal and Nachman, Iftach and Pe'er, Dana},
  journal={Journal of computational biology},
  volume={7},
  number={3-4},
  pages={601--620},
  year={2000},
  publisher={Mary Ann Liebert, Inc.}
}

@article{glymour2019review,
  title={Review of causal discovery methods based on graphical models},
  author={Glymour, Clark and Zhang, Kun and Spirtes, Peter},
  journal={Frontiers in genetics},
  volume={10},
  pages={524},
  year={2019},
  publisher={Frontiers Media SA}
}


@article{triantafillou2017predicting,
  title={Predicting causal relationships from biological data: Applying automated causal discovery on mass cytometry data of human immune cells},
  author={Triantafillou, Sofia and Lagani, Vincenzo and Heinze-Deml, Christina and Schmidt, Angelika and Tegner, Jesper and Tsamardinos, Ioannis},
  journal={Scientific reports},
  volume={7},
  number={1},
  pages={1--11},
  year={2017},
  publisher={Nature Publishing Group}
}


% climate science
@article{ebert2012causal,
  title={Causal discovery for climate research using graphical models},
  author={Ebert-Uphoff, Imme and Deng, Yi},
  journal={Journal of Climate},
  volume={25},
  number={17},
  pages={5648--5665},
  year={2012},
  publisher={American Meteorological Society}
}

% neuro science
@article{sanchez2019estimating,
  title={Estimating feedforward and feedback effective connections from fMRI time series: Assessments of statistical methods},
  author={Sanchez-Romero, Ruben and Ramsey, Joseph D and Zhang, Kun and Glymour, Madelyn RK and Huang, Biwei and Glymour, Clark},
  journal={Network Neuroscience},
  volume={3},
  number={2},
  pages={274--306},
  year={2019},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}


%alzheimer
@article{shen2020challenges,
  title={Challenges and opportunities with causal discovery algorithms: application to Alzheimer’s pathophysiology},
  author={Shen, Xinpeng and Ma, Sisi and Vemuri, Prashanthi and Simon, Gyorgy},
  journal={Scientific reports},
  volume={10},
  number={1},
  pages={1--12},
  year={2020},
  publisher={Nature Publishing Group}
}

%actionable healthcare
@article{prosperi2020causal,
  title={Causal inference and counterfactual prediction in machine learning for actionable healthcare},
  author={Prosperi, Mattia and Guo, Yi and Sperrin, Matt and Koopman, James S and Min, Jae S and He, Xing and Rich, Shannan and Wang, Mo and Buchan, Iain E and Bian, Jiang},
  journal={Nature Machine Intelligence},
  volume={2},
  number={7},
  pages={369--375},
  year={2020},
  publisher={Nature Publishing Group}
}

%diabetes
@article{shen2021novel,
  title={A novel method for causal structure discovery from EHR data and its application to type-2 diabetes mellitus},
  author={Shen, Xinpeng and Ma, Sisi and Vemuri, Prashanthi and Castro, M Regina and Caraballo, Pedro J and Simon, Gyorgy J},
  journal={Scientific reports},
  volume={11},
  number={1},
  pages={1--9},
  year={2021},
  publisher={Nature Publishing Group}
}

%epidemiology
@article{vandenbroucke2016causality,
  title={Causality and causal inference in epidemiology: the need for a pluralistic approach},
  author={Vandenbroucke, Jan P and Broadbent, Alex and Pearce, Neil},
  journal={International journal of epidemiology},
  volume={45},
  number={6},
  pages={1776--1786},
  year={2016},
  publisher={Oxford University Press}
}

@inproceedings{bengio_meta_transfer,
  author    = {Yoshua Bengio and
               Tristan Deleu and
               Nasim Rahaman and
               Nan Rosemary Ke and
               S{\'{e}}bastien Lachapelle and
               Olexa Bilaniuk and
               Anirudh Goyal and
               Christopher J. Pal},
  title     = {A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  url       = {https://openreview.net/forum?id=ryxWIgBFPS},
  timestamp = {Thu, 07 May 2020 17:11:48 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/BengioDRKLBGP20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{ke_sdi,
  doi = {10.48550/ARXIV.1910.01075},
  
  url = {https://arxiv.org/abs/1910.01075},
  
  author = {Ke, Nan Rosemary and Bilaniuk, Olexa and Goyal, Anirudh and Bauer, Stefan and Larochelle, Hugo and Schölkopf, Bernhard and Mozer, Michael C. and Pal, Chris and Bengio, Yoshua},
  
  keywords = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Learning Neural Causal Models from Unknown Interventions},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={229--256},
  year={1992},
  publisher={Springer}
}


@misc{tigas2022,
  doi = {10.48550/ARXIV.2203.02016},
  
  url = {https://arxiv.org/abs/2203.02016},
  
  author = {Tigas, Panagiotis and Annadani, Yashas and Jesson, Andrew and Schölkopf, Bernhard and Gal, Yarin and Bauer, Stefan},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Interventions, Where and How? Experimental Design for Causal Models at Scale},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@book{peters2017elements,
  title={Elements of causal inference: foundations and learning algorithms},
  author={Peters, Jonas and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  year={2017},
  publisher={The MIT Press}
}



@article{houlsby2011,
  author    = {Neil Houlsby and
               Ferenc Huszar and
               Zoubin Ghahramani and
               M{\'{a}}t{\'{e}} Lengyel},
  title     = {Bayesian Active Learning for Classification and Preference Learning},
  journal   = {CoRR},
  volume    = {abs/1112.5745},
  year      = {2011},
  url       = {http://arxiv.org/abs/1112.5745},
  eprinttype = {arXiv},
  eprint    = {1112.5745},
  timestamp = {Mon, 13 Aug 2018 16:48:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1112-5745.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{Triantafillou2017,
author={Triantafillou, Sofia
and Lagani, Vincenzo
and Heinze-Deml, Christina
and Schmidt, Angelika
and Tegner, Jesper
and Tsamardinos, Ioannis},
title={Predicting Causal Relationships from Biological Data: Applying Automated Causal Discovery on Mass Cytometry Data of Human Immune Cells},
journal={Scientific Reports},
year={2017},
month={Oct},
day={05},
volume={7},
number={1},
pages={12724},
abstract={Learning the causal relationships that define a molecular system allows us to predict how the system will respond to different interventions. Distinguishing causality from mere association typically requires randomized experiments. Methods for automated  causal discovery from limited experiments exist, but have so far rarely been tested in systems biology applications. In this work, we apply state-of-the art causal discovery methods on a large collection of public mass cytometry data sets, measuring intra-cellular signaling proteins of the human immune system and their response to several perturbations. We show how different experimental conditions can be used to facilitate causal discovery, and apply two fundamental methods that produce context-specific causal predictions. Causal predictions were reproducible across independent data sets from two different studies, but often disagree with the KEGG pathway databases. Within this context, we discuss the caveats we need to overcome for automated causal discovery to become a part of the routine data analysis in systems biology.},
issn={2045-2322},
doi={10.1038/s41598-017-08582-x},
url={https://doi.org/10.1038/s41598-017-08582-x}
}

@Article{Wu2022,
author={Wu, Ji Q.
and Horeweg, Nanda
and de Bruyn, Marco
and Nout, Remi A.
and J{\"u}rgenliemk-Schulz, Ina M.
and Lutgens, Ludy C. H. W.
and Jobsen, Jan J.
and van der Steen-Banasik, Elzbieta M.
and Nijman, Hans W.
and Smit, Vincent T. H. B. M.
and Bosse, Tjalling
and Creutzberg, Carien L.
and Koelzer, Viktor H.},
title={Automated causal inference in application to randomized controlled clinical trials},
journal={Nature Machine Intelligence},
year={2022},
month={May},
day={01},
volume={4},
number={5},
pages={436-444},
abstract={Randomized controlled trials (RCTs) are considered the gold standard for testing causal hypotheses in the clinical domain; however, the investigation of prognostic variables of patient outcome in a hypothesized cause--effect route is not feasible using standard statistical methods. Here we propose a new automated causal inference method (AutoCI) built on the invariant causal prediction (ICP) framework for the causal reinterpretation of clinical trial data. Compared with existing methods, we show that the proposed AutoCI allows one to clearly determine the causal variables of two real-world RCTs of patients with endometrial cancer with mature outcome and extensive clinicopathological and molecular data. This is achieved via suppressing the causal probability of non-causal variables by a wide margin. In ablation studies, we further demonstrate that the assignment of causal probabilities by AutoCI remains consistent in the presence of confounders. In conclusion, these results confirm the robustness and feasibility of AutoCI for future applications in real-world clinical analysis.},
issn={2522-5839},
doi={10.1038/s42256-022-00470-y},
url={https://doi.org/10.1038/s42256-022-00470-y}
}

@article{cogni,
    author = {Weichwald, Sebastian and Peters, Jonas},
    title = "{Causality in Cognitive Neuroscience: Concepts, Challenges, and Distributional Robustness}",
    journal = {Journal of Cognitive Neuroscience},
    volume = {33},
    number = {2},
    pages = {226-247},
    year = {2021},
    month = {02},
    abstract = "{Whereas probabilistic models describe the dependence structure between observed variables, causal models go one step further: They predict, for example, how cognitive functions are affected by external interventions that perturb neuronal activity. In this review and perspective article, we introduce the concept of causality in the context of cognitive neuroscience and review existing methods for inferring causal relationships from data. Causal inference is an ambitious task that is particularly challenging in cognitive neuroscience. We discuss two difficulties in more detail: the scarcity of interventional data and the challenge of finding the right variables. We argue for distributional robustness as a guiding principle to tackle these problems. Robustness (or invariance) is a fundamental principle underlying causal methodology. A (correctly specified) causal model of a target variable generalizes across environments or subjects as long as these environments leave the causal mechanisms of the target intact. Consequently, if a candidate model does not generalize, then either it does not consist of the target variable's causes or the underlying variables do not represent the correct granularity of the problem. In this sense, assessing generalizability may be useful when defining relevant variables and can be used to partially compensate for the lack of interventional data.}",
    issn = {0898-929X},
    doi = {10.1162/jocn_a_01623},
    url = {https://doi.org/10.1162/jocn\_a\_01623},
    eprint = {https://direct.mit.edu/jocn/article-pdf/33/2/226/1862506/jocn\_a\_01623.pdf},
}

@book{Pearl09,
  abstract = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. Cited in more than 2,100 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research.},
  added-at = {2018-09-17T16:24:20.000+0200},
  address = {Cambridge, UK},
  author = {Pearl, Judea},
  biburl = {https://www.bibsonomy.org/bibtex/2378bd006b231f81cddd091429ceb0f80/flint63},
  doi = {10.1017/CBO9780511803161},
  edition = 2,
  file = {2009/Pearl09.pdf},
  interhash = {e7828b9bdefba2511eb63114c0c32b1b},
  intrahash = {378bd006b231f81cddd091429ceb0f80},
  isbn = {978-0-521-89560-6},
  isbn10 = {052189560X},
  keywords = {01901 103 ai algorithm book knowledge numerical processing theory},
  language = {american},
  owner = {flint},
  publisher = {Cambridge University Press},
  sortdate = {2009-12-01},
  subtitle = {Models, Reasoning, and Inference},
  timestamp = {2018-09-17T16:24:20.000+0200},
  title = {Causality},
  year = 2009
}

@book{Spirtes2000,
  added-at = {2009-09-12T19:19:34.000+0200},
  author = {Spirtes, P. and Glymour, C. and Scheines, R.},
  biburl = {https://www.bibsonomy.org/bibtex/2e2b107e8fd3469c8b0e944ca37a559f3/mozaher},
  edition = {2nd},
  interhash = {559e17fcd12a76214629ba6c4efe3f9a},
  intrahash = {e2b107e8fd3469c8b0e944ca37a559f3},
  keywords = {imported},
  owner = {Mozaherul Hoque},
  publisher = {MIT press},
  review = {PC algorithm},
  timestamp = {2009-09-12T19:19:43.000+0200},
  title = {Causation, Prediction, and Search},
  year = 2000
}

@article{Lindley1956OnAM,
  title={On a Measure of the Information Provided by an Experiment},
  author={David Lindley},
  journal={Annals of Mathematical Statistics},
  year={1956},
  volume={27},
  pages={986-1005}
}



% NEURAL CAUSAL DISCOVERY APPROACHES
@article{geffner2022deep,
  title={Deep End-to-end Causal Inference},
  author={Geffner, Tomas and Antoran, Javier and Foster, Adam and Gong, Wenbo and Ma, Chao and Kiciman, Emre and Sharma, Amit and Lamb, Angus and Kukla, Martin and Pawlowski, Nick and others},
  journal={arXiv preprint arXiv:2202.02195},
  year={2022}
}


@inproceedings{brouillard2020differentiable,
    author = {Brouillard, Philippe and Lachapelle, S\'{e}bastien and Lacoste, Alexandre and Lacoste-Julien, Simon and Drouin, Alexandre},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
    pages = {21865--21877},
    publisher = {Curran Associates, Inc.},
    title = {Differentiable Causal Discovery from Interventional Data},
    volume = {33},
    year = {2020}
}

@article{ke2022learning,
  title={Learning to Induce Causal Structure},
  author={Ke, Nan Rosemary and Chiappa, Silvia and Wang, Jane and Bornschein, Jorg and Weber, Theophane and Goyal, Anirudh and Botvinic, Matthew and Mozer, Michael and Rezende, Danilo Jimenez},
  journal={arXiv preprint arXiv:2204.04875},
  year={2022}
}

@inproceedings{deleu2022bayesian,
  author    = {Tristan Deleu and
               Ant{\'{o}}nio G{\'{o}}is and
               Chris Emezue and
               Mansi Rankawat and
               Simon Lacoste{-}Julien and
               Stefan Bauer and
               Yoshua Bengio},
  editor    = {James Cussens and
               Kun Zhang},
  title     = {Bayesian structure learning with generative flow networks},
  booktitle = {Uncertainty in Artificial Intelligence, Proceedings of the Thirty-Eighth
               Conference on Uncertainty in Artificial Intelligence, {UAI} 2022,
               1-5 August 2022, Eindhoven, The Netherlands},
  series    = {Proceedings of Machine Learning Research},
  volume    = {180},
  pages     = {518--528},
  publisher = {{PMLR}},
  year      = {2022},
  url       = {https://proceedings.mlr.press/v180/deleu22a.html},
  timestamp = {Sat, 15 Oct 2022 12:08:13 +0200},
  biburl    = {https://dblp.org/rec/conf/uai/DeleuGERLBB22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{lorch2022amortized,
	author = {Lorch, Lars and Sussex, Scott and Rothfuss, Jonas and Krause, Andreas and Sch{\"o}lkopf, Bernhard},
	journal = {arXiv preprint arXiv:2205.12934},
	title = {Amortized Inference for Causal Structure Learning},
	year = {2022}}
	
@article{cundy2021bcd,
  title={BCD Nets: Scalable Variational Approaches for Bayesian Causal Discovery},
  author={Cundy, Chris and Grover, Aditya and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{annadani2021variational,
  title={Variational Causal Networks: Approximate Bayesian Inference over Causal Structures},
  author={Annadani, Yashas and Rothfuss, Jonas and Lacoste, Alexandre and Scherrer, Nino and Goyal, Anirudh and Bengio, Yoshua and Bauer, Stefan},
  journal={arXiv preprint arXiv:2106.07635},
  year={2021}
}



@article{sachs2005causal,
  title={Causal protein-signaling networks derived from multiparameter single-cell data},
  author={Sachs, Karen and Perez, Omar and Pe'er, Dana and Lauffenburger, Douglas A and Nolan, Garry P},
  journal={Science},
  volume={308},
  number={5721},
  pages={523--529},
  year={2005},
  publisher={American Association for the Advancement of Science}
}


@article{peters2016causal,
  title={Causal inference by using invariant prediction: identification and confidence intervals},
  author={Peters, Jonas and B{\"u}hlmann, Peter and Meinshausen, Nicolai},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={78},
  number={5},
  pages={947--1012},
  year={2016},
  publisher={Wiley Online Library}
}

@article{castro2020causality,
  title={Causality matters in medical imaging},
  author={Castro, Daniel C and Walker, Ian and Glocker, Ben},
  journal={Nature Communications},
  volume={11},
  number={1},
  pages={1--10},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{LEE2022,
title = {Causal Determinants of Postoperative Length of Stay in Cardiac Surgery using Causal Graphical Learning},
journal = {The Journal of Thoracic and Cardiovascular Surgery},
year = {2022},
issn = {0022-5223},
doi = {https://doi.org/10.1016/j.jtcvs.2022.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S002252232200900X},
author = {Jaron J.R. Lee and Ranjani Srinivasan and Chin Siang Ong and Diane Alejo and Stefano Schena and Ilya Shpitser and Marc Sussman and Glenn J.R. Whitman and Daniel Malinsky},
keywords = {Postoperative Length of Stay, CABG, AVR, Causality, Causal Graph Learning},
}




@article{scherrer2022generalization,
  title={On the Generalization and Adaption Performance of Causal Models},
  author={Scherrer, Nino and Goyal, Anirudh and Bauer, Stefan and Bengio, Yoshua and Ke, Nan Rosemary},
  journal={arXiv preprint arXiv:2206.04620},
  year={2022}
}



@article{friedman2000using,
  title={Using Bayesian networks to analyze expression data},
  author={Friedman, Nir and Linial, Michal and Nachman, Iftach and Pe'er, Dana},
  journal={Journal of computational biology},
  volume={7},
  number={3-4},
  pages={601--620},
  year={2000},
  publisher={Mary Ann Liebert, Inc.}
}

@book{spirtes2000causation,
  title={Causation, prediction, and search},
  author={Spirtes, Peter and Glymour, Clark N and Scheines, Richard and Heckerman, David and Meek, Christopher and Cooper, Gregory and Richardson, Thomas},
  year={2000},
  publisher={MIT press}
}

@article{murphy2001active,
  title={Active learning of causal Bayes net structure},
  author={Murphy, Kevin P},
  year={2001},
  publisher={Citeseer}
}

@article{bnlearn,
 title={Learning Bayesian Networks with the bnlearn R Package},
 volume={35},
 url={https://www.jstatsoft.org/index.php/jss/article/view/v035i03},
 doi={10.18637/jss.v035.i03},
 abstract={&amp;lt;b&amp;gt;bnlearn&amp;lt;/b&amp;gt; is an &amp;lt;b&amp;gt;R&amp;lt;/b&amp;gt; package (R Development Core Team 2010) which includes several algorithms for learning the structure of Bayesian networks with either discrete or continuous variables. Both constraint-based and score-based algorithms are implemented, and can use the functionality provided by the &amp;lt;b&amp;gt;snow&amp;lt;/b&amp;gt; package (Tierney et al. 2008) to improve their performance via parallel computing. Several network scores and conditional independence algorithms are available for both the learning algorithms and independent use. Advanced plotting options are provided by the &amp;lt;b&amp;gt;Rgraphviz&amp;lt;/b&amp;gt; package (Gentry et al. 2010).},
 number={3},
 journal={Journal of Statistical Software},
 author={Scutari, Marco},
 year={2010},
 pages={1–22}
}

@Article{Tsamardinos2006,
author={Tsamardinos, Ioannis
and Brown, Laura E.
and Aliferis, Constantin F.},
title={The max-min hill-climbing Bayesian network structure learning algorithm},
journal={Machine Learning},
year={2006},
month={Oct},
day={01},
volume={65},
number={1},
pages={31-78},
abstract={We present a new algorithm for Bayesian network structure learning, called Max-Min Hill-Climbing (MMHC). The algorithm combines ideas from local learning, constraint-based, and search-and-score techniques in a principled and effective way. It first reconstructs the skeleton of a Bayesian network and then performs a Bayesian-scoring greedy hill-climbing search to orient the edges. In our extensive empirical evaluation MMHC outperforms on average and in terms of various metrics several prototypical and state-of-the-art algorithms, namely the PC, Sparse Candidate, Three Phase Dependency Analysis, Optimal Reinsertion, Greedy Equivalence Search, and Greedy Search. These are the first empirical results simultaneously comparing most of the major Bayesian network algorithms against each other. MMHC offers certain theoretical advantages, specifically over the Sparse Candidate algorithm, corroborated by our experiments. MMHC and detailed results of our study are publicly available at http://www.dsl-lab.org/supplements/mmhc{\_}paper/mmhc{\_}index.html.},
issn={1573-0565},
doi={10.1007/s10994-006-6889-7},
url={https://doi.org/10.1007/s10994-006-6889-7}
}



@article{eberhardt2007interventions,
  title={Interventions and causal inference},
  author={Eberhardt, Frederick and Scheines, Richard},
  journal={Philosophy of science},
  volume={74},
  number={5},
  pages={981--995},
  year={2007},
  publisher={The University of Chicago Press}
}


@inproceedings{eberhardt2012almost,
  author    = {Frederick Eberhardt},
  editor    = {David A. McAllester and
               Petri Myllym{\"{a}}ki},
  title     = {Almost Optimal Intervention Sets for Causal Discovery},
  booktitle = {{UAI} 2008, Proceedings of the 24th Conference in Uncertainty in Artificial
               Intelligence, Helsinki, Finland, July 9-12, 2008},
  pages     = {161--168},
  publisher = {{AUAI} Press},
  year      = {2008},
  url       = {https://dslpitt.org/uai/displayArticleDetails.jsp?mmnu=1\&smnu=2\&article\_id=1948\&proceeding\_id=24},
  timestamp = {Wed, 03 Feb 2021 11:09:52 +0100},
  biburl    = {https://dblp.org/rec/conf/uai/Eberhardt08.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{tong2001active,
  author    = {Simon Tong and
               Daphne Koller},
  editor    = {Bernhard Nebel},
  title     = {Active Learning for Structure in Bayesian Networks},
  booktitle = {Proceedings of the Seventeenth International Joint Conference on Artificial
               Intelligence, {IJCAI} 2001, Seattle, Washington, USA, August 4-10,
               2001},
  pages     = {863--869},
  publisher = {Morgan Kaufmann},
  year      = {2001},
  timestamp = {Tue, 20 Aug 2019 16:18:14 +0200},
  biburl    = {https://dblp.org/rec/conf/ijcai/TongK01.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{hauser2012characterization,
  title={Characterization and greedy learning of interventional Markov equivalence classes of directed acyclic graphs},
  author={Hauser, Alain and B{\"u}hlmann, Peter},
  journal={The Journal of Machine Learning Research},
  volume={13},
  number={1},
  pages={2409--2464},
  year={2012},
  publisher={JMLR. org}
}

@article{JMLR:v9:he08a,
  author  = {Yang-Bo He and Zhi Geng},
  title   = {Active Learning of Causal Networks with Intervention Experiments and Optimal Designs},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
  volume  = {9},
  number  = {84},
  pages   = {2523--2547},
  url     = {http://jmlr.org/papers/v9/he08a.html}
}

@misc{Eberhardt12,
  doi = {10.48550/ARXIV.1206.3250},
  
  url = {https://arxiv.org/abs/1206.3250},
  
  author = {Eberhardt, Frederick},
  
  keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Almost Optimal Intervention Sets for Causal Discovery},
  
  publisher = {arXiv},
  
  year = {2012},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{Squires20,
  author    = {Chandler Squires and
               Sara Magliacane and
               Kristjan H. Greenewald and
               Dmitriy Katz and
               Murat Kocaoglu and
               Karthikeyan Shanmugam},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {Active Structure Learning of Causal DAGs via Directed Clique Trees},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual},
  year      = {2020},
  url       = {https://proceedings.neurips.cc/paper/2020/hash/f57bd0a58e953e5c43cd4a4e5af46138-Abstract.html},
  timestamp = {Tue, 19 Jan 2021 15:56:58 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/SquiresMGKKS20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{NEURIPS2019_5ee56059,
 author = {Greenewald, Kristjan and Katz, Dmitriy and Shanmugam, Karthikeyan and Magliacane, Sara and Kocaoglu, Murat and Boix Adsera, Enric and Bresler, Guy},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Sample Efficient Active Learning of Causal Trees},
 url = {https://proceedings.neurips.cc/paper/2019/file/5ee5605917626676f6a285fa4c10f7b0-Paper.pdf},
 volume = {32},
 year = {2019}
}


@InProceedings{pmlr-v80-ghassami18a,
  title = 	 {Budgeted Experiment Design for Causal Structure Learning},
  author =       {Ghassami, AmirEmad and Salehkaleybar, Saber and Kiyavash, Negar and Bareinboim, Elias},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1724--1733},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/ghassami18a/ghassami18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/ghassami18a.html},
  abstract = 	 {We study the problem of causal structure learning when the experimenter is limited to perform at most $k$ non-adaptive experiments of size $1$. We formulate the problem of finding the best intervention target set as an optimization problem, which aims to maximize the average number of edges whose directions are resolved. We prove that the corresponding objective function is submodular and a greedy algorithm suffices to achieve $(1-\frac{1}{e})$-approximation of the optimal value. We further present an accelerated variant of the greedy algorithm, which can lead to orders of magnitude performance speedup. We validate our proposed approach on synthetic and real graphs. The results show that compared to the purely observational setting, our algorithm orients the majority of the edges through a considerably small number of interventions.}
}

@article{ghassami2019,
  author    = {AmirEmad Ghassami and
               Saber Salehkaleybar and
               Negar Kiyavash},
  title     = {Interventional Experiment Design for Causal Structure Learning},
  journal   = {CoRR},
  volume    = {abs/1910.05651},
  year      = {2019},
  url       = {http://arxiv.org/abs/1910.05651},
  eprinttype = {arXiv},
  eprint    = {1910.05651},
  timestamp = {Wed, 16 Oct 2019 16:25:53 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1910-05651.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{NIPS2017_291d43c6,
 author = {Kocaoglu, Murat and Shanmugam, Karthikeyan and Bareinboim, Elias},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Experimental Design for Learning Causal Graphs with Latent Variables},
 url = {https://proceedings.neurips.cc/paper/2017/file/291d43c696d8c3704cdbe0a72ade5f6c-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{Lindgren2018,
  author    = {Erik M. Lindgren and
               Murat Kocaoglu and
               Alexandros G. Dimakis and
               Sriram Vishwanath},
  editor    = {Samy Bengio and
               Hanna M. Wallach and
               Hugo Larochelle and
               Kristen Grauman and
               Nicol{\`{o}} Cesa{-}Bianchi and
               Roman Garnett},
  title     = {Experimental Design for Cost-Aware Learning of Causal Graphs},
  booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
               on Neural Information Processing Systems 2018, NeurIPS 2018, December
               3-8, 2018, Montr{\'{e}}al, Canada},
  pages     = {5284--5294},
  year      = {2018},
  url       = {https://proceedings.neurips.cc/paper/2018/hash/ba3e9b6a519cfddc560b5d53210df1bd-Abstract.html},
  timestamp = {Mon, 16 May 2022 15:41:51 +0200},
  biburl    = {https://dblp.org/rec/conf/nips/LindgrenKDV18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{DBLP:conf/aistats/AgrawalSYSU19,
  author    = {Raj Agrawal and
               Chandler Squires and
               Karren D. Yang and
               Karthikeyan Shanmugam and
               Caroline Uhler},
  editor    = {Kamalika Chaudhuri and
               Masashi Sugiyama},
  title     = {ABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure
               Discovery},
  booktitle = {The 22nd International Conference on Artificial Intelligence and Statistics,
               {AISTATS} 2019, 16-18 April 2019, Naha, Okinawa, Japan},
  series    = {Proceedings of Machine Learning Research},
  volume    = {89},
  pages     = {3400--3409},
  publisher = {{PMLR}},
  year      = {2019},
  url       = {http://proceedings.mlr.press/v89/agrawal19b.html},
  timestamp = {Wed, 24 Jul 2019 12:42:41 +0200},
  biburl    = {https://dblp.org/rec/conf/aistats/AgrawalSYSU19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{NIPS2016_b3ba8f1b,
 author = {Liu, Qiang and Wang, Dilin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm},
 url = {https://proceedings.neurips.cc/paper/2016/file/b3ba8f1bee1238a2f37603d90b58898d-Paper.pdf},
 volume = {29},
 year = {2016}
}

@inproceedings{NEURIPS2018_e347c514,
 author = {Zheng, Xun and Aragam, Bryon and Ravikumar, Pradeep K and Xing, Eric P},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {DAGs with NO TEARS: Continuous Optimization for Structure Learning},
 url = {https://proceedings.neurips.cc/paper/2018/file/e347c51419ffb23ca3fd5050202f9c3d-Paper.pdf},
 volume = {31},
 year = {2018}
}

@inproceedings{Settles2007,
 author = {Settles, Burr and Craven, Mark and Ray, Soumya},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Platt and D. Koller and Y. Singer and S. Roweis},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Multiple-Instance Active Learning},
 url = {https://proceedings.neurips.cc/paper/2007/file/a1519de5b5d44b31a01de013b9b51a80-Paper.pdf},
 volume = {20},
 year = {2007}
}


@inproceedings{krause,
author = {Krause, Andreas and Guestrin, Carlos},
title = {Near-Optimal Nonmyopic Value of Information in Graphical Models},
year = {2005},
isbn = {0974903914},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
abstract = {A fundamental issue in real-world systems, such as sensor networks, is the selection of observations which most effectively reduce uncertainty. More specifically, we address the long standing problem of nonmyopically selecting the most informative subset of variables in a graphical model. We present the first efficient randomized algorithm providing a constant factor (1 - 1/e – ε) approximation guarantee for any ε > 0 with high confidence. The algorithm leverages the theory of submodular functions, in combination with a polynomial bound on sample complexity. We furthermore prove that no polynomial time algorithm can provide a constant factor approximation better than (1 - 1/e) unless P = NP. Finally, we provide extensive evidence of the effectiveness of our method on two complex real-world datasets.},
booktitle = {Proceedings of the Twenty-First Conference on Uncertainty in Artificial Intelligence},
pages = {324–331},
numpages = {8},
location = {Edinburgh, Scotland},
series = {UAI'05}
}

@Article{Nemhauser1978,
author={Nemhauser, G. L.
and Wolsey, L. A.
and Fisher, M. L.},
title={An analysis of approximations for maximizing submodular set functions---I},
journal={Mathematical Programming},
year={1978},
month={Dec},
day={01},
volume={14},
number={1},
pages={265-294},
abstract={LetN be a finite set andz be a real-valued function defined on the set of subsets ofN that satisfies z(S)+z(T)≥z(S⋃T)+z(S⋂T) for allS, T inN. Such a function is called submodular. We consider the problem maxS⊂N{\{}a(S):|S|≤K,z(S) submodular{\}}.},
issn={1436-4646},
doi={10.1007/BF01588971},
url={https://doi.org/10.1007/BF01588971}
}

