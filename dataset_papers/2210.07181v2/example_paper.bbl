\begin{thebibliography}{89}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agrawal et~al.(2015)Agrawal, Carreira, and Malik]{agrawal2015learning}
Agrawal, P., Carreira, J., and Malik, J.
\newblock Learning to see by moving.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  37--45, 2015.

\bibitem[Chen et~al.(2021)Chen, Xu, Zhao, Zhang, Xiang, Yu, and
  Su]{chen2021mvsnerf}
Chen, A., Xu, Z., Zhao, F., Zhang, X., Xiang, F., Yu, J., and Su, H.
\newblock Mvsnerf: Fast generalizable radiance field reconstruction from
  multi-view stereo.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  14124--14133, 2021.

\bibitem[Chen et~al.(2016{\natexlab{a}})Chen, Fu, Yang, and
  Deng]{chen2016single}
Chen, W., Fu, Z., Yang, D., and Deng, J.
\newblock Single-image depth perception in the wild.
\newblock \emph{Advances in neural information processing systems}, 29,
  2016{\natexlab{a}}.

\bibitem[Chen et~al.(2016{\natexlab{b}})Chen, Duan, Houthooft, Schulman,
  Sutskever, and Abbeel]{chen2016infogan}
Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., and Abbeel, P.
\newblock Infogan: Interpretable representation learning by information
  maximizing generative adversarial nets.
\newblock \emph{Advances in neural information processing systems}, 29,
  2016{\natexlab{b}}.

\bibitem[Dai et~al.(2017)Dai, Chang, Savva, Halber, Funkhouser, and
  Nie{\ss}ner]{dai2017scannet}
Dai, A., Chang, A.~X., Savva, M., Halber, M., Funkhouser, T., and Nie{\ss}ner,
  M.
\newblock Scannet: Richly-annotated 3d reconstructions of indoor scenes.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  5828--5839, 2017.

\bibitem[Denton et~al.(2017)]{denton2017unsupervised}
Denton, E.~L. et~al.
\newblock Unsupervised learning of disentangled representations from video.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Dosovitskiy et~al.(2015)Dosovitskiy, Tobias~Springenberg, and
  Brox]{dosovitskiy2015learning}
Dosovitskiy, A., Tobias~Springenberg, J., and Brox, T.
\newblock Learning to generate chairs with convolutional neural networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  1538--1546, 2015.

\bibitem[Eigen et~al.(2014)Eigen, Puhrsch, and Fergus]{eigen2014depth}
Eigen, D., Puhrsch, C., and Fergus, R.
\newblock Depth map prediction from a single image using a multi-scale deep
  network.
\newblock \emph{Advances in neural information processing systems}, 27, 2014.

\bibitem[Eslami et~al.(2018)Eslami, Jimenez~Rezende, Besse, Viola, Morcos,
  Garnelo, Ruderman, Rusu, Danihelka, Gregor, et~al.]{eslami2018neural}
Eslami, S.~A., Jimenez~Rezende, D., Besse, F., Viola, F., Morcos, A.~S.,
  Garnelo, M., Ruderman, A., Rusu, A.~A., Danihelka, I., Gregor, K., et~al.
\newblock Neural scene representation and rendering.
\newblock \emph{Science}, 360\penalty0 (6394):\penalty0 1204--1210, 2018.

\bibitem[Godard et~al.(2017)Godard, Mac~Aodha, and
  Brostow]{godard2017unsupervised}
Godard, C., Mac~Aodha, O., and Brostow, G.~J.
\newblock Unsupervised monocular depth estimation with left-right consistency.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  270--279, 2017.

\bibitem[Godard et~al.(2019)Godard, Mac~Aodha, Firman, and
  Brostow]{godard2019digging}
Godard, C., Mac~Aodha, O., Firman, M., and Brostow, G.~J.
\newblock Digging into self-supervised monocular depth estimation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  3828--3838, 2019.

\bibitem[Gordon et~al.(2019)Gordon, Li, Jonschkowski, and
  Angelova]{gordon2019depth}
Gordon, A., Li, H., Jonschkowski, R., and Angelova, A.
\newblock Depth from videos in the wild: Unsupervised monocular depth learning
  from unknown cameras.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  8977--8986, 2019.

\bibitem[Han et~al.(2019)Han, Xie, and Zisserman]{han2019video}
Han, T., Xie, W., and Zisserman, A.
\newblock Video representation learning by dense predictive coding.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision Workshops}, pp.\  0--0, 2019.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Hou et~al.(2019)Hou, Kannala, and Solin]{hou2019multi}
Hou, Y., Kannala, J., and Solin, A.
\newblock Multi-view stereo by temporal nonparametric fusion.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  2651--2660, 2019.

\bibitem[Huang et~al.(2018)Huang, Liu, Belongie, and
  Kautz]{huang2018multimodal}
Huang, X., Liu, M.-Y., Belongie, S., and Kautz, J.
\newblock Multimodal unsupervised image-to-image translation.
\newblock In \emph{Proceedings of the European conference on computer vision
  (ECCV)}, pp.\  172--189, 2018.

\bibitem[Im et~al.(2019)Im, Jeon, Lin, and Kweon]{im2019dpsnet}
Im, S., Jeon, H.-G., Lin, S., and Kweon, I.~S.
\newblock Dpsnet: End-to-end deep plane sweep stereo.
\newblock \emph{arXiv preprint arXiv:1905.00538}, 2019.

\bibitem[Jabri et~al.(2020)Jabri, Owens, and Efros]{jabri2020space}
Jabri, A., Owens, A., and Efros, A.
\newblock Space-time correspondence as a contrastive random walk.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 19545--19560, 2020.

\bibitem[Jha et~al.(2018)Jha, Anand, Singh, and
  Veeravasarapu]{jha2018disentangling}
Jha, A.~H., Anand, S., Singh, M., and Veeravasarapu, V.
\newblock Disentangling factors of variation with cycle-consistent variational
  auto-encoders.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  805--820, 2018.

\bibitem[Jimenez~Rezende et~al.(2016)Jimenez~Rezende, Eslami, Mohamed,
  Battaglia, Jaderberg, and Heess]{jimenez2016unsupervised}
Jimenez~Rezende, D., Eslami, S., Mohamed, S., Battaglia, P., Jaderberg, M., and
  Heess, N.
\newblock Unsupervised learning of 3d structure from images.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Kar et~al.(2017)Kar, H{\"a}ne, and Malik]{kar2017learning}
Kar, A., H{\"a}ne, C., and Malik, J.
\newblock Learning a multi-view stereo machine.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Karras et~al.(2019)Karras, Laine, and Aila]{karras2019style}
Karras, T., Laine, S., and Aila, T.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  4401--4410, 2019.

\bibitem[Kendall et~al.(2017)Kendall, Martirosyan, Dasgupta, Henry, Kennedy,
  Bachrach, and Bry]{kendall2017end}
Kendall, A., Martirosyan, H., Dasgupta, S., Henry, P., Kennedy, R., Bachrach,
  A., and Bry, A.
\newblock End-to-end learning of geometry and context for deep stereo
  regression.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  66--75, 2017.

\bibitem[Lai et~al.(2021)Lai, Liu, Efros, and Wang]{lai2021video}
Lai, Z., Liu, S., Efros, A.~A., and Wang, X.
\newblock Video autoencoder: self-supervised disentanglement of static 3d
  structure and motion.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  9730--9740, 2021.

\bibitem[Laina et~al.(2016)Laina, Rupprecht, Belagiannis, Tombari, and
  Navab]{laina2016deeper}
Laina, I., Rupprecht, C., Belagiannis, V., Tombari, F., and Navab, N.
\newblock Deeper depth prediction with fully convolutional residual networks.
\newblock In \emph{2016 Fourth international conference on 3D vision (3DV)},
  pp.\  239--248. IEEE, 2016.

\bibitem[Lee et~al.(2020)Lee, Tseng, Mao, Huang, Lu, Singh, and
  Yang]{lee2020drit++}
Lee, H.-Y., Tseng, H.-Y., Mao, Q., Huang, J.-B., Lu, Y.-D., Singh, M., and
  Yang, M.-H.
\newblock Drit++: Diverse image-to-image translation via disentangled
  representations.
\newblock \emph{International Journal of Computer Vision}, 128\penalty0
  (10):\penalty0 2402--2417, 2020.

\bibitem[Li et~al.(2020)Li, Gordon, Zhao, Casser, and
  Angelova]{li2020unsupervised}
Li, H., Gordon, A., Zhao, H., Casser, V., and Angelova, A.
\newblock Unsupervised monocular depth learning in dynamic scenes.
\newblock \emph{arXiv preprint arXiv:2010.16404}, 2020.

\bibitem[Li et~al.(2021)Li, Feng, She, Ding, Wang, and Lee]{li2021mine}
Li, J., Feng, Z., She, Q., Ding, H., Wang, C., and Lee, G.~H.
\newblock Mine: Towards continuous depth mpi with nerf for novel view
  synthesis.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  12578--12588, 2021.

\bibitem[Li et~al.(2022)Li, Li, Sitzmann, Agrawal, and Torralba]{li20223d}
Li, Y., Li, S., Sitzmann, V., Agrawal, P., and Torralba, A.
\newblock 3d neural scene representations for visuomotor control.
\newblock In \emph{Conference on Robot Learning}, pp.\  112--123. PMLR, 2022.

\bibitem[Li \& Snavely(2018)Li and Snavely]{li2018megadepth}
Li, Z. and Snavely, N.
\newblock Megadepth: Learning single-view depth prediction from internet
  photos.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  2041--2050, 2018.

\bibitem[Liu et~al.(2020)Liu, Ginosar, Zhou, Efros, and
  Snavely]{liu2020learning}
Liu, A., Ginosar, S., Zhou, T., Efros, A.~A., and Snavely, N.
\newblock Learning to factorize and relight a city.
\newblock In \emph{European Conference on Computer Vision}, pp.\  544--561.
  Springer, 2020.

\bibitem[Mahjourian et~al.(2018)Mahjourian, Wicke, and
  Angelova]{mahjourian2018unsupervised}
Mahjourian, R., Wicke, M., and Angelova, A.
\newblock Unsupervised learning of depth and ego-motion from monocular video
  using 3d geometric constraints.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  5667--5675, 2018.

\bibitem[Martin-Brualla et~al.(2021)Martin-Brualla, Radwan, Sajjadi, Barron,
  Dosovitskiy, and Duckworth]{martin2021nerf}
Martin-Brualla, R., Radwan, N., Sajjadi, M.~S., Barron, J.~T., Dosovitskiy, A.,
  and Duckworth, D.
\newblock Nerf in the wild: Neural radiance fields for unconstrained photo
  collections.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  7210--7219, 2021.

\bibitem[Meng et~al.(2021)Meng, Chen, Luo, Wu, Su, Xu, He, and
  Yu]{meng2021gnerf}
Meng, Q., Chen, A., Luo, H., Wu, M., Su, H., Xu, L., He, X., and Yu, J.
\newblock Gnerf: Gan-based neural radiance field without posed camera.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  6351--6361, 2021.

\bibitem[Mildenhall et~al.(2020)Mildenhall, Srinivasan, Tancik, Barron,
  Ramamoorthi, and Ng]{mildenhall2020nerf}
Mildenhall, B., Srinivasan, P.~P., Tancik, M., Barron, J.~T., Ramamoorthi, R.,
  and Ng, R.
\newblock Nerf: Representing scenes as neural radiance fields for view
  synthesis.
\newblock In \emph{European conference on computer vision}, pp.\  405--421.
  Springer, 2020.

\bibitem[Minderer et~al.(2019)Minderer, Sun, Villegas, Cole, Murphy, and
  Lee]{minderer2019unsupervised}
Minderer, M., Sun, C., Villegas, R., Cole, F., Murphy, K.~P., and Lee, H.
\newblock Unsupervised learning of object structure and dynamics from videos.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Misra et~al.(2016)Misra, Zitnick, and Hebert]{misra2016shuffle}
Misra, I., Zitnick, C.~L., and Hebert, M.
\newblock Shuffle and learn: unsupervised learning using temporal order
  verification.
\newblock In \emph{European Conference on Computer Vision}, pp.\  527--544.
  Springer, 2016.

\bibitem[Murez et~al.(2020)Murez, As, Bartolozzi, Sinha, Badrinarayanan, and
  Rabinovich]{murez2020atlas}
Murez, Z., As, T.~v., Bartolozzi, J., Sinha, A., Badrinarayanan, V., and
  Rabinovich, A.
\newblock Atlas: End-to-end 3d scene reconstruction from posed images.
\newblock In \emph{European Conference on Computer Vision}, pp.\  414--431.
  Springer, 2020.

\bibitem[Mustikovela et~al.(2020)Mustikovela, Jampani, Mello, Liu, Iqbal,
  Rother, and Kautz]{mustikovela2020self}
Mustikovela, S.~K., Jampani, V., Mello, S.~D., Liu, S., Iqbal, U., Rother, C.,
  and Kautz, J.
\newblock Self-supervised viewpoint learning from image collections.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  3971--3981, 2020.

\bibitem[Nathan~Silberman \& Fergus(2012)Nathan~Silberman and
  Fergus]{Silberman_ECCV12}
Nathan~Silberman, Derek~Hoiem, P.~K. and Fergus, R.
\newblock Indoor segmentation and support inference from rgbd images.
\newblock In \emph{ECCV}, 2012.

\bibitem[Nguyen-Phuoc et~al.(2019)Nguyen-Phuoc, Li, Theis, Richardt, and
  Yang]{nguyen2019hologan}
Nguyen-Phuoc, T., Li, C., Theis, L., Richardt, C., and Yang, Y.-L.
\newblock Hologan: Unsupervised learning of 3d representations from natural
  images.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  7588--7597, 2019.

\bibitem[Niemeyer et~al.(2020)Niemeyer, Mescheder, Oechsle, and
  Geiger]{niemeyer2020differentiable}
Niemeyer, M., Mescheder, L., Oechsle, M., and Geiger, A.
\newblock Differentiable volumetric rendering: Learning implicit 3d
  representations without 3d supervision.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  3504--3515, 2020.

\bibitem[Niklaus et~al.(2019)Niklaus, Mai, Yang, and Liu]{niklaus20193d}
Niklaus, S., Mai, L., Yang, J., and Liu, F.
\newblock 3d ken burns effect from a single image.
\newblock \emph{ACM Transactions on Graphics (ToG)}, 38\penalty0 (6):\penalty0
  1--15, 2019.

\bibitem[Park et~al.(2020)Park, Zhu, Wang, Lu, Shechtman, Efros, and
  Zhang]{park2020swapping}
Park, T., Zhu, J.-Y., Wang, O., Lu, J., Shechtman, E., Efros, A., and Zhang, R.
\newblock Swapping autoencoder for deep image manipulation.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 7198--7211, 2020.

\bibitem[Pidhorskyi et~al.(2020)Pidhorskyi, Adjeroh, and
  Doretto]{pidhorskyi2020adversarial}
Pidhorskyi, S., Adjeroh, D.~A., and Doretto, G.
\newblock Adversarial latent autoencoders.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  14104--14113, 2020.

\bibitem[Ranftl et~al.(2020)Ranftl, Lasinger, Hafner, Schindler, and
  Koltun]{ranftl2020towards}
Ranftl, R., Lasinger, K., Hafner, D., Schindler, K., and Koltun, V.
\newblock Towards robust monocular depth estimation: Mixing datasets for
  zero-shot cross-dataset transfer.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 2020.

\bibitem[Rockwell et~al.(2021)Rockwell, Fouhey, and
  Johnson]{rockwell2021pixelsynth}
Rockwell, C., Fouhey, D.~F., and Johnson, J.
\newblock Pixelsynth: Generating a 3d-consistent experience from a single
  image.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  14104--14113, 2021.

\bibitem[Sch{\"o}nberger et~al.(2016)Sch{\"o}nberger, Zheng, Frahm, and
  Pollefeys]{schonberger2016pixelwise}
Sch{\"o}nberger, J.~L., Zheng, E., Frahm, J.-M., and Pollefeys, M.
\newblock Pixelwise view selection for unstructured multi-view stereo.
\newblock In \emph{European Conference on Computer Vision}, pp.\  501--518.
  Springer, 2016.

\bibitem[Schwarz et~al.(2020)Schwarz, Liao, Niemeyer, and
  Geiger]{schwarz2020graf}
Schwarz, K., Liao, Y., Niemeyer, M., and Geiger, A.
\newblock Graf: Generative radiance fields for 3d-aware image synthesis.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 20154--20166, 2020.

\bibitem[Simeonov et~al.(2022)Simeonov, Du, Yen-Chen, Rodriguez, Kaelbling,
  Lozano-Perez, and Agrawal]{simeonov2022se}
Simeonov, A., Du, Y., Yen-Chen, L., Rodriguez, A., Kaelbling, L.~P.,
  Lozano-Perez, T., and Agrawal, P.
\newblock Se (3)-equivariant relational rearrangement with neural descriptor
  fields.
\newblock \emph{arXiv preprint arXiv:2211.09786}, 2022.

\bibitem[Simonyan \& Zisserman(2014)Simonyan and Zisserman]{simonyan2014very}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Sitzmann et~al.(2019{\natexlab{a}})Sitzmann, Thies, Heide,
  Nie{\ss}ner, Wetzstein, and Zollhofer]{sitzmann2019deepvoxels}
Sitzmann, V., Thies, J., Heide, F., Nie{\ss}ner, M., Wetzstein, G., and
  Zollhofer, M.
\newblock Deepvoxels: Learning persistent 3d feature embeddings.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  2437--2446, 2019{\natexlab{a}}.

\bibitem[Sitzmann et~al.(2019{\natexlab{b}})Sitzmann, Zollh{\"o}fer, and
  Wetzstein]{sitzmann2019scene}
Sitzmann, V., Zollh{\"o}fer, M., and Wetzstein, G.
\newblock Scene representation networks: Continuous 3d-structure-aware neural
  scene representations.
\newblock \emph{Advances in Neural Information Processing Systems}, 32,
  2019{\natexlab{b}}.

\bibitem[Srinivasan et~al.(2019)Srinivasan, Tucker, Barron, Ramamoorthi, Ng,
  and Snavely]{srinivasan2019pushing}
Srinivasan, P.~P., Tucker, R., Barron, J.~T., Ramamoorthi, R., Ng, R., and
  Snavely, N.
\newblock Pushing the boundaries of view extrapolation with multiplane images.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  175--184, 2019.

\bibitem[Tan et~al.(2019)Tan, Chen, Pang, Vasudevan, Sandler, Howard, and
  Le]{tan2019mnasnet}
Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le,
  Q.~V.
\newblock Mnasnet: Platform-aware neural architecture search for mobile.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  2820--2828, 2019.

\bibitem[Trevithick \& Yang(2021)Trevithick and Yang]{trevithick2021grf}
Trevithick, A. and Yang, B.
\newblock Grf: Learning a general radiance field for 3d representation and
  rendering.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  15182--15192, 2021.

\bibitem[Tucker \& Snavely(2020)Tucker and Snavely]{tucker2020single}
Tucker, R. and Snavely, N.
\newblock Single-view view synthesis with multiplane images.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  551--560, 2020.

\bibitem[Tulsiani et~al.(2017)Tulsiani, Zhou, Efros, and
  Malik]{tulsiani2017multi}
Tulsiani, S., Zhou, T., Efros, A.~A., and Malik, J.
\newblock Multi-view supervision for single-view reconstruction via
  differentiable ray consistency.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2626--2634, 2017.

\bibitem[Tung et~al.(2019)Tung, Cheng, and Fragkiadaki]{tung2019learning}
Tung, H.-Y.~F., Cheng, R., and Fragkiadaki, K.
\newblock Learning spatial common sense with geometry-aware recurrent networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  2595--2603, 2019.

\bibitem[Umeyama(1991)]{umeyama1991least}
Umeyama, S.
\newblock Least-squares estimation of transformation parameters between two
  point patterns.
\newblock \emph{IEEE Transactions on Pattern Analysis \& Machine Intelligence},
  13\penalty0 (04):\penalty0 376--380, 1991.

\bibitem[Venkat et~al.(2023)Venkat, Agarwal, Singh, and
  Tulsiani]{venkat2023geometry}
Venkat, N., Agarwal, M., Singh, M., and Tulsiani, S.
\newblock Geometry-biased transformers for novel view synthesis.
\newblock \emph{arXiv preprint arXiv:2301.04650}, 2023.

\bibitem[Vijayanarasimhan et~al.(2017)Vijayanarasimhan, Ricco, Schmid,
  Sukthankar, and Fragkiadaki]{vijayanarasimhan2017sfm}
Vijayanarasimhan, S., Ricco, S., Schmid, C., Sukthankar, R., and Fragkiadaki,
  K.
\newblock Sfm-net: Learning of structure and motion from video.
\newblock \emph{arXiv preprint arXiv:1704.07804}, 2017.

\bibitem[Wang \& Shen(2018)Wang and Shen]{wang2018mvdepthnet}
Wang, K. and Shen, S.
\newblock Mvdepthnet: Real-time multiview depth estimation neural network.
\newblock In \emph{2018 International conference on 3d vision (3DV)}, pp.\
  248--257. IEEE, 2018.

\bibitem[Wang et~al.(2021{\natexlab{a}})Wang, Liu, Liu, Theobalt, Komura, and
  Wang]{wang2021neus}
Wang, P., Liu, L., Liu, Y., Theobalt, C., Komura, T., and Wang, W.
\newblock Neus: Learning neural implicit surfaces by volume rendering for
  multi-view reconstruction.
\newblock \emph{NeurIPS}, 2021{\natexlab{a}}.

\bibitem[Wang et~al.(2022)Wang, Chen, Chen, Venugopalan, Wang,
  et~al.]{wang2022attention}
Wang, P., Chen, X., Chen, T., Venugopalan, S., Wang, Z., et~al.
\newblock Is attention all nerf needs?
\newblock \emph{arXiv preprint arXiv:2207.13298}, 2022.

\bibitem[Wang et~al.(2021{\natexlab{b}})Wang, Wang, Genova, Srinivasan, Zhou,
  Barron, Martin-Brualla, Snavely, and Funkhouser]{wang2021ibrnet}
Wang, Q., Wang, Z., Genova, K., Srinivasan, P., Zhou, H., Barron, J.~T.,
  Martin-Brualla, R., Snavely, N., and Funkhouser, T.
\newblock Ibrnet: Learning multi-view image-based rendering.
\newblock In \emph{CVPR}, 2021{\natexlab{b}}.

\bibitem[Wang \& Gupta(2015)Wang and Gupta]{wang2015unsupervised}
Wang, X. and Gupta, A.
\newblock Unsupervised learning of visual representations using videos.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  2794--2802, 2015.

\bibitem[Wang et~al.(2019)Wang, Jabri, and Efros]{wang2019learning}
Wang, X., Jabri, A., and Efros, A.~A.
\newblock Learning correspondence from the cycle-consistency of time.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  2566--2576, 2019.

\bibitem[Wang et~al.(2004)Wang, Bovik, Sheikh, and Simoncelli]{wang2004image}
Wang, Z., Bovik, A.~C., Sheikh, H.~R., and Simoncelli, E.~P.
\newblock Image quality assessment: from error visibility to structural
  similarity.
\newblock \emph{IEEE transactions on image processing}, 13\penalty0
  (4):\penalty0 600--612, 2004.

\bibitem[Wang et~al.(2021{\natexlab{c}})Wang, Wu, Xie, Chen, and
  Prisacariu]{wang2021nerf}
Wang, Z., Wu, S., Xie, W., Chen, M., and Prisacariu, V.~A.
\newblock Nerf--: Neural radiance fields without known camera parameters.
\newblock \emph{arXiv preprint arXiv:2102.07064}, 2021{\natexlab{c}}.

\bibitem[Wang et~al.(2021{\natexlab{d}})Wang, Wu, Xie, Chen, and
  Prisacariu]{wang2021nerfmm}
Wang, Z., Wu, S., Xie, W., Chen, M., and Prisacariu, V.~A.
\newblock Ne{RF}$--$: Neural radiance fields without known camera parameters.
\newblock \emph{arXiv preprint arXiv:2102.07064}, 2021{\natexlab{d}}.

\bibitem[Watson et~al.(2021)Watson, Aodha, Prisacariu, Brostow, and
  Firman]{watson2021temporal}
Watson, J., Aodha, O.~M., Prisacariu, V., Brostow, G., and Firman, M.
\newblock {The Temporal Opportunist: Self-Supervised Multi-Frame Monocular
  Depth}.
\newblock In \emph{Computer Vision and Pattern Recognition (CVPR)}, 2021.

\bibitem[Wiles et~al.(2018)Wiles, Koepke, and Zisserman]{wiles2018self}
Wiles, O., Koepke, A., and Zisserman, A.
\newblock Self-supervised learning of a facial attribute embedding from video.
\newblock \emph{arXiv preprint arXiv:1808.06882}, 2018.

\bibitem[Wiles et~al.(2020)Wiles, Gkioxari, Szeliski, and
  Johnson]{wiles2020synsin}
Wiles, O., Gkioxari, G., Szeliski, R., and Johnson, J.
\newblock Synsin: End-to-end view synthesis from a single image.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  7467--7477, 2020.

\bibitem[Xue et~al.(2016)Xue, Wu, Bouman, and Freeman]{xue2016visual}
Xue, T., Wu, J., Bouman, K., and Freeman, B.
\newblock Visual dynamics: Probabilistic future frame synthesis via cross
  convolutional networks.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Yang et~al.(2018)Yang, Wang, Wang, Xu, and Nevatia]{yang2018lego}
Yang, Z., Wang, P., Wang, Y., Xu, W., and Nevatia, R.
\newblock Lego: Learning edge with geometry all at once by watching videos.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  225--234, 2018.

\bibitem[Yariv et~al.(2021)Yariv, Gu, Kasten, and Lipman]{yariv2021volume}
Yariv, L., Gu, J., Kasten, Y., and Lipman, Y.
\newblock Volume rendering of neural implicit surfaces.
\newblock In \emph{Thirty-Fifth Conference on Neural Information Processing
  Systems}, 2021.

\bibitem[Yin et~al.(2021)Yin, Zhang, Wang, Niklaus, Mai, Chen, and
  Shen]{yin2021learning}
Yin, W., Zhang, J., Wang, O., Niklaus, S., Mai, L., Chen, S., and Shen, C.
\newblock Learning to recover 3d scene shape from a single image.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  204--213, 2021.

\bibitem[Yin \& Shi(2018)Yin and Shi]{yin2018geonet}
Yin, Z. and Shi, J.
\newblock Geonet: Unsupervised learning of dense depth, optical flow and camera
  pose.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  1983--1992, 2018.

\bibitem[Yu et~al.(2021)Yu, Ye, Tancik, and Kanazawa]{yu2021pixelnerf}
Yu, A., Ye, V., Tancik, M., and Kanazawa, A.
\newblock pixelnerf: Neural radiance fields from one or few images.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  4578--4587, 2021.

\bibitem[Yu et~al.(2020)Yu, Jin, and Gao]{yu2020p}
Yu, Z., Jin, L., and Gao, S.
\newblock P$^2$net: Patch-match and plane-regularization for unsupervised
  indoor depth estimation.
\newblock In \emph{European Conference on Computer Vision}, pp.\  206--222.
  Springer, 2020.

\bibitem[Zhang et~al.(2021)Zhang, Yang, Tulsiani, and Ramanan]{zhang2021ners}
Zhang, J., Yang, G., Tulsiani, S., and Ramanan, D.
\newblock Ners: neural reflectance surfaces for sparse-view 3d reconstruction
  in the wild.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 29835--29847, 2021.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and
  Wang]{zhang2018perceptual}
Zhang, R., Isola, P., Efros, A.~A., Shechtman, E., and Wang, O.
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In \emph{CVPR}, 2018.

\bibitem[Zhi et~al.(2021)Zhi, Laidlow, Leutenegger, and
  Davison]{Zhi:etal:ICCV2021}
Zhi, S., Laidlow, T., Leutenegger, S., and Davison, A.~J.
\newblock In-place scene labelling and understanding with implicit scene
  representation.
\newblock In \emph{Int. Conf. Comput. Vis.}, 2021.

\bibitem[Zhou et~al.(2019)Zhou, Wang, Qin, and Zeng]{zhou2019moving}
Zhou, J., Wang, Y., Qin, K., and Zeng, W.
\newblock Moving indoor: Unsupervised video depth learning in challenging
  environments.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  8618--8627, 2019.

\bibitem[Zhou et~al.(2016)Zhou, Tulsiani, Sun, Malik, and Efros]{zhou2016view}
Zhou, T., Tulsiani, S., Sun, W., Malik, J., and Efros, A.~A.
\newblock View synthesis by appearance flow.
\newblock In \emph{European conference on computer vision}, pp.\  286--301.
  Springer, 2016.

\bibitem[Zhou et~al.(2017)Zhou, Brown, Snavely, and Lowe]{zhou2017unsupervised}
Zhou, T., Brown, M., Snavely, N., and Lowe, D.~G.
\newblock Unsupervised learning of depth and ego-motion from video.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  1851--1858, 2017.

\bibitem[Zhou et~al.(2018)Zhou, Tucker, Flynn, Fyffe, and
  Snavely]{zhou2018stereo}
Zhou, T., Tucker, R., Flynn, J., Fyffe, G., and Snavely, N.
\newblock Stereo magnification: Learning view synthesis using multiplane
  images.
\newblock \emph{arXiv preprint arXiv:1805.09817}, 2018.

\bibitem[Zhu et~al.(2018)Zhu, Zhang, Zhang, Wu, Torralba, Tenenbaum, and
  Freeman]{zhu2018visual}
Zhu, J.-Y., Zhang, Z., Zhang, C., Wu, J., Torralba, A., Tenenbaum, J., and
  Freeman, B.
\newblock Visual object networks: Image generation with disentangled 3d
  representations.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\end{thebibliography}
