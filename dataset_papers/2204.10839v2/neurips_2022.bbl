\begin{thebibliography}{49}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Addepalli et~al.(2021)Addepalli, Jain, Sriramanan, and
  Babu]{Addepalli_2021_CVPR}
Sravanti Addepalli, Samyak Jain, Gaurang Sriramanan, and R.~Venkatesh Babu.
\newblock Boosting adversarial robustness using feature level stochastic
  smoothing.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR) Workshops}, pages 93--102, 2021.

\bibitem[Akhtar and Mian(2018)]{survey_adv_vision}
Naveed Akhtar and Ajmal Mian.
\newblock Threat of adversarial attacks on deep learning in computer vision: A
  survey.
\newblock \emph{IEEE Access}, 6:\penalty0 14410--14430, 2018.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and Wagner]{obfuscated_grad}
Anish Athalye, Nicholas Carlini, and David~A. Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning (ICML)}, pages 274--283, 2018.

\bibitem[Bender et~al.(2020)Bender, Li, Shi, Reiter, and
  Oliva]{diverse_directions_bender20a}
Christopher Bender, Yang Li, Yifeng Shi, Michael~K. Reiter, and Junier Oliva.
\newblock Defense through diverse directions.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning (ICML)}, pages 756--766, 2020.

\bibitem[Biggio et~al.(2013)Biggio, Corona, Maiorca, Nelson,
  {\v{S}}rndi{\'{c}}, Laskov, Giacinto, and Roli]{biggio_adv_att}
Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim
  {\v{S}}rndi{\'{c}}, Pavel Laskov, Giorgio Giacinto, and Fabio Roli.
\newblock Evasion attacks against machine learning at test time.
\newblock In Hendrik Blockeel, Kristian Kersting, Siegfried Nijssen, and Filip
  {\v{Z}}elezn{\'y}, editors, \emph{Machine Learning and Knowledge Discovery in
  Databases}, pages 387--402. Springer Berlin Heidelberg, 2013.

\bibitem[Bubeck(2015)]{bubeck2015convex}
Sébastien Bubeck.
\newblock Convex optimization: Algorithms and complexity.
\newblock In \emph{arXiv preprint \url{https://arxiv.org/pdf/1405.4980}}, 2015.

\bibitem[Cai et~al.(2013)Cai, Fan, and Jiang]{cai_dist_angle}
Tony Cai, Jianqing Fan, and Tiefeng Jiang.
\newblock Distributions of angles in random packing on spheres.
\newblock \emph{Journal of Machine Learning Research}, 14\penalty0
  (21):\penalty0 1837--1864, 2013.

\bibitem[Carbone et~al.(2020)Carbone, Wicker, Laurenti, Patane\textquotesingle,
  Bortolussi, and Sanguinetti]{carbone2020robustness}
Ginevra Carbone, Matthew Wicker, Luca Laurenti, Andrea Patane\textquotesingle,
  Luca Bortolussi, and Guido Sanguinetti.
\newblock Robustness of bayesian neural networks to gradient-based attacks.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~33, pages 15602--15613, 2020.

\bibitem[Carlini and Wagner(2017{\natexlab{a}})]{carlini2017evaluating}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{IEEE Symposium on Security and Privacy (SP)}, pages 39--57,
  2017{\natexlab{a}}.

\bibitem[Carlini and Wagner(2017{\natexlab{b}})]{carlini_bypassing}
Nicholas Carlini and David Wagner.
\newblock \emph{Adversarial Examples Are Not Easily Detected: Bypassing Ten
  Detection Methods}, page 3–14.
\newblock Association for Computing Machinery, 2017{\natexlab{b}}.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{cohen2019certified}
Jeremy Cohen, Elan Rosenfeld, and Zico Kolter.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning (ICML)}, volume~97, pages 1310--1320, 2019.

\bibitem[Croce and Hein(2020)]{Croce2020Provable}
Francesco Croce and Matthias Hein.
\newblock Provable robustness against all adversarial $l_p$-perturbations for
  $p\geq 1$.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Croce et~al.(2019)Croce, Andriushchenko, and
  Hein]{croce_max_lin_regions}
Francesco Croce, Maksym Andriushchenko, and Matthias Hein.
\newblock Provable robustness of relu networks via maximization of linear
  regions.
\newblock In \emph{Proceedings of the Twenty-Second International Conference on
  Artificial Intelligence and Statistics (AISTATS)}, volume~89, pages
  2057--2066, 2019.

\bibitem[Dabouei et~al.(2020)Dabouei, Soleymani, Taherkhani, Dawson, and
  Nasrabadi]{cvpr_robust}
Ali Dabouei, Sobhan Soleymani, Fariborz Taherkhani, Jeremy Dawson, and
  Nasser~M. Nasrabadi.
\newblock Exploiting joint robustness to adversarial perturbations.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 1119--1128, 2020.

\bibitem[Daxberger et~al.(2021)Daxberger, Kristiadi, Immer, Eschenhagen, Bauer,
  and Hennig]{laplace2021}
Erik Daxberger, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen,
  Matthias Bauer, and Philipp Hennig.
\newblock Laplace redux--effortless {B}ayesian deep learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2021.

\bibitem[Däubener and Fischer(2020)]{daubener2020investigating}
Sina Däubener and Asja Fischer.
\newblock Investigating maximum likelihood based training of infinite mixtures
  for uncertainty quantification.
\newblock In \emph{arXiv preprint \url{https://arxiv.org/abs/2008.03209}},
  2020.

\bibitem[Eustratiadis et~al.(2021)Eustratiadis, Gouk, Li, and
  Hospedales]{weight_covariance-eustratiadis21a}
Panagiotis Eustratiadis, Henry Gouk, Da~Li, and Timothy Hospedales.
\newblock Weight-covariance alignment for adversarially robust neural networks.
\newblock In \emph{Proceedings of the 38th International Conference on Machine
  Learning (ICML)}, volume 139, pages 3047--3056, 2021.

\bibitem[Gal and Ghahramani(2016)]{mc_dropout_gal}
Yarin Gal and Zoubin Ghahramani.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{Proceedings of The 33rd International Conference on Machine
  Learning (ICML)}, volume~48, pages 1050--1059, 2016.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{Goodfellow_fgsm}
Ian~J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{3rd International Conference on Learning Representations,
  (ICLR)}, 2015.

\bibitem[Gowal et~al.(2020)Gowal, Qin, Uesato, Mann, and
  Kohli]{gowal2020uncovering}
Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, and Pushmeet Kohli.
\newblock Uncovering the limits of adversarial training against norm-bounded
  adversarial examples.
\newblock \emph{arXiv preprint}, 2020.
\newblock URL \url{https://arxiv.org/pdf/2010.03593}.

\bibitem[He et~al.(2019)He, Rakin, and Fan]{He_2019_CVPR}
Zhezhi He, Adnan~Siraj Rakin, and Deliang Fan.
\newblock Parametric noise injection: Trainable randomness to improve deep
  neural network robustness against adversarial attack.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, 2019.

\bibitem[Hein and Andriushchenko(2017)]{hein_formal_gurantees}
Matthias Hein and Maksym Andriushchenko.
\newblock Formal guarantees on the robustness of a classifier against
  adversarial manipulation.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~30, 2017.

\bibitem[Jeddi et~al.(2020)Jeddi, Shafiee, Karg, Scharfenberger, and
  Wong]{learn2perturb}
Ahmadreza Jeddi, Mohammad~Javad Shafiee, Michelle Karg, Christian
  Scharfenberger, and Alexander Wong.
\newblock Learn2perturb: An end-to-end feature perturbation learning to improve
  adversarial robustness.
\newblock In \emph{2020 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 1238--1247, 2020.

\bibitem[Kingma and Ba(2015)]{adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In \emph{3rd International Conference on Learning Representations
  (ICLR)}, 2015.

\bibitem[Krizhevsky et~al.({\natexlab{a}})Krizhevsky, Nair, and
  Hinton]{cifar10}
Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.
\newblock Cifar-10 (canadian institute for advanced research).
\newblock In \emph{\url{http://www.cs.toronto.edu/~kriz/cifar.html}},
  {\natexlab{a}}.

\bibitem[Krizhevsky et~al.({\natexlab{b}})Krizhevsky, Nair, and
  Hinton]{cifar10-100}
Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.
\newblock Cifar-10, cifar-100 (canadian institute for advanced research).
\newblock In \emph{\url{http://www.cs.toronto.edu/~kriz/cifar.html}},
  {\natexlab{b}}.

\bibitem[L{\'{e}}cuyer et~al.(2019)L{\'{e}}cuyer, Atlidakis, Geambasu, Hsu, and
  Jana]{lecuyer2019certified}
Mathias L{\'{e}}cuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and
  Suman Jana.
\newblock Certified robustness to adversarial examples with differential
  privacy.
\newblock In \emph{IEEE Symposium on Security and Privacy (SP)}, pages
  656--672, 2019.

\bibitem[Lee et~al.(2022)Lee, Kim, and Lee]{GradDiv}
Sungyoon Lee, Hoki Kim, and Jaewook Lee.
\newblock Graddiv: Adversarial robustness of randomized neural networks via
  gradient diversity regularization.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, pages 1--1, 2022.

\bibitem[Liu et~al.(2018)Liu, Cheng, Zhang, and Hsieh]{liu_selfensemble}
Xuanqing Liu, Minhao Cheng, Huan Zhang, and Cho-Jui Hsieh.
\newblock Towards robust neural networks via random self-ensemble.
\newblock In \emph{Computer Vision -- ECCV}, pages 381--397, 2018.

\bibitem[Louizos and Welling(2016)]{louizos16}
Christos Louizos and Max Welling.
\newblock Structured and efficient variational deep learning with matrix
  gaussian posteriors.
\newblock In \emph{Proceedings of The 33rd International Conference on Machine
  Learning (ICML)}, volume~48, pages 1708--1716, 2016.

\bibitem[MacKay(1992)]{mackay92}
David J.~C. MacKay.
\newblock A practical bayesian framework for backpropagation networks.
\newblock \emph{Neural Comput.}, 4\penalty0 (3):\penalty0 448–472, 1992.
\newblock ISSN 0899-7667.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Neal(1996)]{neal}
Radford~M. Neal.
\newblock \emph{Bayesian Learning for Neural Networks}.
\newblock Springer-Verlag, Berlin, Heidelberg, 1996.

\bibitem[Papernot et~al.(2016)Papernot, McDaniel, Wu, Jha, and
  Swami]{papernot_distillation}
Nicolas Papernot, Patrick McDaniel, Xi~Wu, Somesh Jha, and Ananthram Swami.
\newblock Distillation as a defense to adversarial perturbations against deep
  neural networks.
\newblock In \emph{IEEE Symposium on Security and Privacy (SP)}, pages
  582--597, 2016.

\bibitem[Papernot et~al.(2018)Papernot, Faghri, Carlini, Goodfellow, Feinman,
  Kurakin, Xie, Sharma, Brown, Roy, Matyasko, Behzadan, Hambardzumyan, Zhang,
  Juang, Li, Sheatsley, Garg, Uesato, Gierke, Dong, Berthelot, Hendricks,
  Rauber, and Long]{papernot2018cleverhans}
Nicolas Papernot, Fartash Faghri, Nicholas Carlini, Ian Goodfellow, Reuben
  Feinman, Alexey Kurakin, Cihang Xie, Yash Sharma, Tom Brown, Aurko Roy,
  Alexander Matyasko, Vahid Behzadan, Karen Hambardzumyan, Zhishuai Zhang,
  Yi-Lin Juang, Zhi Li, Ryan Sheatsley, Abhibhav Garg, Jonathan Uesato, Willi
  Gierke, Yinpeng Dong, David Berthelot, Paul Hendricks, Jonas Rauber, and
  Rujun Long.
\newblock Technical report on the cleverhans v2.1.0 adversarial examples
  library.
\newblock In \emph{arXiv preprint \url{https://arxiv.org/abs/1610.00768}},
  2018.

\bibitem[Pinot et~al.(2019)Pinot, Meunier, Araujo, Kashima, Yger, Gouy-Pailler,
  and Atif]{nips19_theory_robustness_randomization}
Rafael Pinot, Laurent Meunier, Alexandre Araujo, Hisashi Kashima, Florian Yger,
  Cedric Gouy-Pailler, and Jamal Atif.
\newblock Theoretical evidence for adversarial robustness through
  randomization.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~32, 2019.

\bibitem[Raff et~al.(2019)Raff, Sylvester, Forsyth, and McLean]{BART}
Edward Raff, Jared Sylvester, Steven Forsyth, and Mark McLean.
\newblock Barrage of random transforms for adversarially robust defense.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 6521--6530, 2019.

\bibitem[Ross and Doshi-Velez(2018)]{Ross_Doshi-Velez_2018}
Andrew Ross and Finale Doshi-Velez.
\newblock Improving the adversarial robustness and interpretability of deep
  neural networks by regularizing their input gradients.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  32\penalty0 (1), 2018.

\bibitem[Salman et~al.(2019)Salman, Li, Razenshteyn, Zhang, Zhang, Bubeck, and
  Yang]{nips_smoothness_bound}
Hadi Salman, Jerry Li, Ilya Razenshteyn, Pengchuan Zhang, Huan Zhang, Sebastien
  Bubeck, and Greg Yang.
\newblock Provably robust deep learning via adversarially trained smoothed
  classifiers.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, volume~32, 2019.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{intruding_Szegedy}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian~J. Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{2nd International Conference on Learning Representations
  (ICLR)}, 2014.

\bibitem[Uesato et~al.(2018)Uesato, O'Donoghue, Kohli, and van~den
  Oord]{obscurity_robustness}
Jonathan Uesato, Brendan O'Donoghue, Pushmeet Kohli, and A{\"{a}}ron van~den
  Oord.
\newblock Adversarial risk and the dangers of evaluating against weak attacks.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning (ICML)}, volume~80, pages 5032--5041, 2018.

\bibitem[Wicker et~al.(2020)Wicker, Laurenti, Patane, and
  Kwiatkowska]{wicker2020probabilistic}
Matthew Wicker, Luca Laurenti, Andrea Patane, and Marta Kwiatkowska.
\newblock Probabilistic safety for bayesian neural networks.
\newblock In \emph{Proceedings of the Thirty-Sixth Conference on Uncertainty in
  Artificial Intelligence (UAI)}, volume 124, pages 1198--1207, 2020.

\bibitem[Wicker et~al.(2021)Wicker, Laurenti, Patane, Chen, Zhang, and
  Kwiatkowska]{wicker_adv_train_BNN}
Matthew Wicker, Luca Laurenti, Andrea Patane, Zhuotong Chen, Zheng Zhang, and
  Marta Kwiatkowska.
\newblock Bayesian inference with certifiable adversarial robustness.
\newblock In \emph{Proceedings of The 24th International Conference on
  Artificial Intelligence and Statistics (AISTATS)}, volume 130, pages
  2431--2439, 2021.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{fashionmnist}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock In \emph{arXiv preprint \url{https://arxiv.org/abs/1708.07747}},
  2017.

\bibitem[Xie et~al.(2018)Xie, Wang, Zhang, Ren, and Yuille]{xie2018mitigating}
Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, and Alan Yuille.
\newblock Mitigating adversarial effects through randomization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Yang et~al.(2022)Yang, Li, Xu, Kailkhura, Xie, and
  Li]{yang2021ensemble_robust}
Zhuolin Yang, Linyi Li, Xiaojun Xu, Bhavya Kailkhura, Tao Xie, and Bo~Li.
\newblock On the certified robustness for ensemble models and beyond.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2022.

\bibitem[Yu et~al.(2021)Yu, Yang, Li, Hospedales, and Xiang]{simpleSNN}
Tianyuan Yu, Yongxin Yang, Da~Li, Timothy Hospedales, and Tao Xiang.
\newblock Simple and effective stochastic neural networks.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  35\penalty0 (4):\penalty0 3252--3260, 2021.

\bibitem[Zagoruyko and Komodakis(2017)]{zagoruyko2017wide}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock In \emph{arXiv preprint \url{https://arxiv.org/abs/1605.07146}},
  2017.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, Ghaoui, and Jordan]{trades}
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent~El Ghaoui, and
  Michael Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning (ICML)}, volume~97, pages 7472--7482, 2019.

\end{thebibliography}
