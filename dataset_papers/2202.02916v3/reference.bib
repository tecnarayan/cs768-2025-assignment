@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@article{da_reg,
  title={Data augmentation instead of explicit regularization},
  author={Hern{\'a}ndez-Garc{\'\i}a, Alex and K{\"o}nig, Peter},
  journal={arXiv preprint arXiv:1806.03852},
  year={2018}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@inproceedings{imagenet_cnn,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@article{visual_complexity,
  title={A standardized set of 260 pictures: norms for name agreement, image agreement, familiarity, and visual complexity.},
  author={Snodgrass, Joan G and Vanderwart, Mary},
  journal={Journal of experimental psychology: Human learning and memory},
  volume={6},
  number={2},
  pages={174},
  year={1980},
  publisher={American Psychological Association}
}

@article{nlp_2012,
  title={Deep neural networks for acoustic modeling in speech recognition},
  author={Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Kingsbury, Brian and others},
  journal={IEEE Signal processing magazine},
  volume={29},
  year={2012}
}

@article{adversarial_example,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@article{fgsm_attack,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@inproceedings{
defensegan,
title={Defense-{GAN}: Protecting Classifiers Against Adversarial Attacks Using Generative Models},
author={Pouya Samangouei and Maya Kabkab and Rama Chellappa},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=BkJ3ibb0-},
}

@inproceedings{sap,
title={Stochastic activation pruning for robust adversarial defense},
author={Guneet S. Dhillon and Kamyar Azizzadenesheli and Jeremy D. Bernstein and Jean Kossaifi and Aran Khanna and Zachary C. Lipton and Animashree Anandkumar},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=H1uR4GZRZ},
}

@article{gpt2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya}
}

@inproceedings{cw_attack,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2017 IEEE Symposium on Security and Privacy (SP)},
  pages={39--57},
  year={2017},
  organization={IEEE}
}

@article{pgd_attack,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}

@inproceedings{jsma_attack,
  title={The limitations of deep learning in adversarial settings},
  author={Papernot, Nicolas and McDaniel, Patrick and Jha, Somesh and Fredrikson, Matt and Celik, Z Berkay and Swami, Ananthram},
  booktitle={2016 IEEE European Symposium on Security and Privacy (EuroS\&P)},
  pages={372--387},
  year={2016},
  organization={IEEE}
}

@inproceedings{deepfool_attack,
  title={Deepfool: a simple and accurate method to fool deep neural networks},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2574--2582},
  year={2016}
}

@article{bim_attack,
  title={Adversarial examples in the physical world},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  journal={arXiv preprint arXiv:1607.02533},
  year={2016}
}

@inproceedings{universal_attack,
  title={Universal adversarial perturbations},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1765--1773},
  year={2017}
}

@inproceedings{substitute_attack,
  title={Practical black-box attacks against machine learning},
  author={Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram},
  booktitle={Proceedings of the 2017 ACM on Asia conference on computer and communications security},
  pages={506--519},
  year={2017},
  organization={ACM}
}

@inproceedings{zoo_attack,
  title={Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models},
  author={Chen, Pin-Yu and Zhang, Huan and Sharma, Yash and Yi, Jinfeng and Hsieh, Cho-Jui},
  booktitle={Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
  pages={15--26},
  year={2017},
  organization={ACM}
}

@inproceedings{jigsaw,
  title={Unsupervised learning of visual representations by solving jigsaw puzzles},
  author={Noroozi, Mehdi and Favaro, Paolo},
  booktitle={European Conference on Computer Vision},
  pages={69--84},
  year={2016},
  organization={Springer}
}

@article{boundary_attack,
  title={Decision-based adversarial attacks: Reliable attacks against black-box machine learning models},
  author={Brendel, Wieland and Rauber, Jonas and Bethge, Matthias},
  journal={arXiv preprint arXiv:1712.04248},
  year={2017}
}

@article{singlepixel_attack,
  title={One pixel attack for fooling deep neural networks},
  author={Su, Jiawei and Vargas, Danilo Vasconcellos and Sakurai, Kouichi},
  journal={IEEE Transactions on Evolutionary Computation},
  year={2019},
  publisher={IEEE}
}

@article{nes_attack,
  title={Black-box adversarial attacks with limited queries and information},
  author={Ilyas, Andrew and Engstrom, Logan and Athalye, Anish and Lin, Jessy},
  journal={arXiv preprint arXiv:1804.08598},
  year={2018}
}

@article{simba_attack,
  title={Simple black-box adversarial attacks},
  author={Guo, Chuan and Gardner, Jacob R and You, Yurong and Wilson, Andrew Gordon and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:1905.07121},
  year={2019}
}

@inproceedings{distillation_defense,
  title={Distillation as a defense to adversarial perturbations against deep neural networks},
  author={Papernot, Nicolas and McDaniel, Patrick and Wu, Xi and Jha, Somesh and Swami, Ananthram},
  booktitle={2016 IEEE Symposium on Security and Privacy (SP)},
  pages={582--597},
  year={2016},
  organization={IEEE}
}

@article{alp_defense,
  title={Adversarial logit pairing},
  author={Kannan, Harini and Kurakin, Alexey and Goodfellow, Ian},
  journal={arXiv preprint arXiv:1803.06373},
  year={2018}
}

@article{translation,
  title={Discriminative unsupervised feature learning with exemplar convolutional neural networks},
  author={Dosovitskiy, Alexey and Fischer, Philipp and Springenberg, Jost Tobias and Riedmiller, Martin and Brox, Thomas},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={38},
  number={9},
  pages={1734--1747},
  year={2015},
  publisher={IEEE}
}

@incollection{overfitting_adv,
 abstract = {It is common practice in deep learning to use overparameterized networks and train for as long as possible; there are numerous studies that show, both theoretically and empirically, that such practices surprisingly do not unduly harm the generalization performance of the classifier. In this paper, we empirically study this phenomenon in the setting of adversarially trained deep networks, which are trained to minimize the loss under worst-case adversarial perturbations. We find that overfitting to the training set does in fact harm robust performance to a very large degree in adversarially robust training across multiple datasets (SVHN, CIFAR-10, CIFAR-100, and ImageNet) and perturbation models (L-infinity and L-2). Based upon this observed effect, we show that the performance gains of virtually all recent algorithmic improvements upon adversarial training can be matched by simply using early stopping. We also show that effects such as the double descent curve do still occur in adversarially trained models, yet fail to explain the observed overfitting.  Finally, we study several classical and modern deep learning remedies for overfitting, including regularization and data augmentation, and find that no approach in isolation improves significantly upon the gains achieved by early stopping. },
 author = {Wong, Eric and Rice, Leslie and Kolter, Zico},
 booktitle = {Proceedings of Machine Learning and Systems 2020},
 pages = {5304--5315},
 title = {Overfitting in adversarially robust deep learning},
 year = {2020}
}

@inproceedings{synthesis_robust_classifier,
  title={Image synthesis with a single (robust) classifier},
  author={Santurkar, Shibani and Ilyas, Andrew and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1262--1273},
  year={2019}
}

@inproceedings{double_backprop_defense,
  title={Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients},
  author={Ross, Andrew Slavin and Doshi-Velez, Finale},
  booktitle={Thirty-second AAAI conference on artificial intelligence},
  year={2018}
}

@inproceedings{trades_defense,
  title = 	 {Theoretically Principled Trade-off between Robustness and Accuracy},
  author = 	 {Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and Ghaoui, Laurent El and Jordan, Michael},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {7472--7482},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Long Beach, California, USA},
  month = 	 {09--15 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/zhang19p/zhang19p.pdf},
  url = 	 {http://proceedings.mlr.press/v97/zhang19p.html},
  abstract = 	 {We identify a trade-off between robustness and accuracy that serves as a guiding principle in the design of defenses against adversarial examples. Although this problem has been widely studied empirically, much remains unknown concerning the theory underlying this trade-off. In this work, we decompose the prediction error for adversarial examples (robust error) as the sum of the natural (classification) error and boundary error, and provide a differentiable upper bound using the theory of classification-calibrated loss, which is shown to be the tightest possible upper bound uniform over all probability distributions and measurable predictors. Inspired by our theoretical analysis, we also design a new defense method, TRADES, to trade adversarial robustness off against accuracy. Our proposed algorithm performs well experimentally in real-world datasets. The methodology is the foundation of our entry to the NeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of  2,000 submissions, surpassing the runner-up approach by 11.41 in terms of mean L_2 perturbation distance.}, 
  note="\url{https://github.com/yaodongyu/TRADES}"
}

@article{virtual_defense,
  title={Virtual adversarial training: a regularization method for supervised and semi-supervised learning},
  author={Miyato, Takeru and Maeda, Shin-ichi and Koyama, Masanori and Ishii, Shin},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={8},
  pages={1979--1993},
  year={2018},
  publisher={IEEE}
}

@article{detecting_defense,
  title={On detecting adversarial perturbations},
  author={Metzen, Jan Hendrik and Genewein, Tim and Fischer, Volker and Bischoff, Bastian},
  journal={arXiv preprint arXiv:1702.04267},
  year={2017}
}

@inproceedings{magnet_defense,
  title={Magnet: a two-pronged defense against adversarial examples},
  author={Meng, Dongyu and Chen, Hao},
  booktitle={Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  pages={135--147},
  year={2017},
  organization={ACM}
}

@article{feature_squeezing_defense,
  title={Feature squeezing: Detecting adversarial examples in deep neural networks},
  author={Xu, Weilin and Evans, David and Qi, Yanjun},
  journal={arXiv preprint arXiv:1704.01155},
  year={2017}
}


@article{break-even_point,
  title={The Break-Even Point on Optimization Trajectories of Deep Neural Networks},
  author={Jastrzebski, Stanislaw and Szymczak, Maciej and Fort, Stanislav and Arpit, Devansh and Tabor, Jacek and Cho, Kyunghyun and Geras, Krzysztof},
  journal={arXiv preprint arXiv:2002.09572},
  year={2020}
}

@article{early3,
  title={Critical learning periods in deep neural networks},
  author={Achille, Alessandro and Rovere, Matteo and Soatto, Stefano},
  journal={arXiv preprint arXiv:1711.08856},
  year={2017}
}

@article{early2,
  title={Empirical analysis of the hessian of over-parametrized neural networks},
  author={Sagun, Levent and Evci, Utku and Guney, V Ugur and Dauphin, Yann and Bottou, Leon},
  journal={arXiv preprint arXiv:1706.04454},
  year={2017}
}

@inproceedings{topmoumoute,
  title={Topmoumoute online natural gradient algorithm},
  author={Roux, Nicolas L and Manzagol, Pierre-Antoine and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={849--856},
  year={2008}
}

@article{early1,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1609.04836},
  year={2016}
}

@article{fantastic,
  title={Fantastic Generalization Measures and Where to Find Them},
  author={Jiang, Yiding and Neyshabur, Behnam and Mobahi, Hossein and Krishnan, Dilip and Bengio, Samy},
  journal={arXiv preprint arXiv:1912.02178},
  year={2019}
}

@article{gsnr,
  title={Understanding Why Neural Networks Generalize Well Through GSNR of Parameters},
  author={Liu, Jinlong and Jiang, Guoqing and Bai, Yunzhi and Chen, Ting and Wang, Huayan},
  journal={arXiv preprint arXiv:2001.07384},
  year={2020}
}

@inproceedings{cutmix,
  title={Cutmix: Regularization strategy to train strong classifiers with localizable features},
  author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={6023--6032},
  year={2019}
}

@inproceedings{feature_denoising_defense,
  title={Feature denoising for improving adversarial robustness},
  author={Xie, Cihang and Wu, Yuxin and Maaten, Laurens van der and Yuille, Alan L and He, Kaiming},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={501--509},
  year={2019}
}

@incollection{feature_scattering_defense,
title = {Defense Against Adversarial Attacks Using Feature Scattering-based Adversarial Training},
author = {Zhang, Haichao and Wang, Jianyu},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {1829--1839},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8459-defense-against-adversarial-attacks-using-feature-scattering-based-adversarial-training.pdf},
note= "\url{https://github.com/Haichao-Zhang/FeatureScatter}"
}

@article{obfuscated_adversarial,
  title={Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples},
  author={Athalye, Anish and Carlini, Nicholas and Wagner, David},
  journal={arXiv preprint arXiv:1802.00420},
  year={2018}
}

@inproceedings{more_data_adversarial,
  title={Adversarially robust generalization requires more data},
  author={Schmidt, Ludwig and Santurkar, Shibani and Tsipras, Dimitris and Talwar, Kunal and Madry, Aleksander},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5014--5026},
  year={2018}
}

@article{sphere_adversarial,
  title={Adversarial spheres},
  author={Gilmer, Justin and Metz, Luke and Faghri, Fartash and Schoenholz, Samuel S and Raghu, Maithra and Wattenberg, Martin and Goodfellow, Ian},
  journal={arXiv preprint arXiv:1801.02774},
  year={2018}
}

@article{polytope_adversarial,
  title={Provable defenses against adversarial examples via the convex outer adversarial polytope},
  author={Wong, Eric and Kolter, J Zico},
  journal={arXiv preprint arXiv:1711.00851},
  year={2017}
}

@article{rethinking_generalization,
  title={Understanding deep learning requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1611.03530},
  year={2016}
}

@article{distance_from_init_2,
  title={Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data},
  author={Dziugaite, Gintare Karolina and Roy, Daniel M},
  journal={arXiv preprint arXiv:1703.11008},
  year={2017}
}

@article{odds_with_accuracy,
  title={Robustness may be at odds with accuracy},
  author={Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
  journal={arXiv preprint arXiv:1805.12152},
  year={2018}
}

@article{not_bugs_are_features,
  title={Adversarial examples are not bugs, they are features},
  author={Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
  journal={arXiv preprint arXiv:1905.02175},
  year={2019}
}

@inproceedings{inception,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

@article{mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1710.09412},
  year={2017}
}

@article{mnist_dataset,
  title={The MNIST database of handwritten digits},
  author={LeCun, Yann},
  journal={http://yann. lecun. com/exdb/mnist/},
  year={1998}
}

@techreport{cifar_dataset,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  institution={Citeseer}
}

@article{distance_from_init_param,
  title={Generalization in deep networks: The role of distance from initialization},
  author={Nagarajan, Vaishnavh and Kolter, J Zico},
  journal={arXiv preprint arXiv:1901.01672},
  year={2019}
}

@article{multitask_adv,
  title={Multitask Learning Strengthens Adversarial Robustness},
  author={Mao, Chengzhi and Gupta, Amogh and Nitin, Vikram and Ray, Baishakhi and Song, Shuran and Yang, Junfeng and Vondrick, Carl},
  journal={arXiv preprint arXiv:2007.07236},
  year={2020}
}

@article{svhn_dataset,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  year={2011}
}

@article{stiffness,
  title={Stiffness: A new perspective on generalization in neural networks},
  author={Fort, Stanislav and Nowak, Pawe{\l} Krzysztof and Jastrzebski, Stanislaw and Narayanan, Srini},
  journal={arXiv preprint arXiv:1901.09491},
  year={2019}
}

@inproceedings{imagenet_dataset,
        AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
        TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
        BOOKTITLE = {CVPR09},
        YEAR = {2009},
        BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"}


@article{local_linearization,
  title={Adversarial Robustness through Local Linearization},
  author={Qin, Chongli and Martens, James and Gowal, Sven and Krishnan, Dilip and Fawzi, Alhussein and De, Soham and Stanforth, Robert and Kohli, Pushmeet and others},
  journal={arXiv preprint arXiv:1907.02610},
  year={2019}
}

@inproceedings{likelihood,
  title={Likelihood ratios for out-of-distribution detection},
  author={Ren, Jie and Liu, Peter J and Fertig, Emily and Snoek, Jasper and Poplin, Ryan and Depristo, Mark and Dillon, Joshua and Lakshminarayanan, Balaji},
  booktitle={Advances in Neural Information Processing Systems},
  pages={14680--14691},
  year={2019}
}


@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{wide_resnet,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

@inproceedings{preact_resnet,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={European conference on computer vision},
  pages={630--645},
  year={2016},
  organization={Springer}
}

@article{soft_label_reg,
  title={Regularizing neural networks by penalizing confident output distributions},
  author={Pereyra, Gabriel and Tucker, George and Chorowski, Jan and Kaiser, {\L}ukasz and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:1701.06548},
  year={2017}
}

@article{label_leak,
  title={Adversarial machine learning at scale},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  journal={arXiv preprint arXiv:1611.01236},
  year={2016}
}


@inproceedings{what_is_being_transferred,
 author = {Neyshabur, Behnam and Sedghi, Hanie and Zhang, Chiyuan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {512--523},
 publisher = {Curran Associates, Inc.},
 title = {What is being transferred in transfer learning? },
 url = {https://proceedings.neurips.cc/paper/2020/file/0607f4c705595b911a4f3e7a127b44e0-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{fid,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{transferability_adv,
  title={Cross-domain transferability of adversarial perturbations},
  author={Naseer, Muhammad Muzammal and Khan, Salman H and Khan, Muhammad Haris and Khan, Fahad Shahbaz and Porikli, Fatih},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12885--12895},
  year={2019}
}

@inproceedings{universal_adv,
  title={Universal adversarial perturbations},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1765--1773},
  year={2017}
}

@inproceedings{gan_adv,
  title={Generative adversarial perturbations},
  author={Poursaeed, Omid and Katsman, Isay and Gao, Bicheng and Belongie, Serge},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4422--4431},
  year={2018}
}

@inproceedings{incomplete_adv,
  title={Robustness to adversarial perturbations in learning from incomplete data},
  author={Najafi, Amir and Maeda, Shin-ichi and Koyama, Masanori and Miyato, Takeru},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5542--5552},
  year={2019}
}

@inproceedings{unlabeled_adv,
  title={Unlabeled data improves adversarial robustness},
  author={Carmon, Yair and Raghunathan, Aditi and Schmidt, Ludwig and Duchi, John C and Liang, Percy S},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11190--11201},
  year={2019}
}

@inproceedings{
oat,
title={Removing Undesirable Feature Contributions Using Out-of-Distribution Data},
author={Saehyung Lee and Changhwa Park and Hyungyu Lee and Jihun Yi and Jonghyun Lee and Sungroh Yoon},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=eIHYL6fpbkA}
}

@article{are_labels_adv,
  title={Are labels required for improving adversarial robustness?},
  author={Stanforth, Robert and Fawzi, Alhussein and Kohli, Pushmeet and others},
  journal={arXiv preprint arXiv:1905.13725},
  year={2019}
}

@article{distributionally_robust_learning,
  title={Robust solutions of optimization problems affected by uncertain probabilities},
  author={Ben-Tal, Aharon and Den Hertog, Dick and De Waegenaere, Anja and Melenberg, Bertrand and Rennen, Gijs},
  journal={Management Science},
  volume={59},
  number={2},
  pages={341--357},
  year={2013},
  publisher={INFORMS}
}

@article{gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@InProceedings{cscores,
  title = 	 {Characterizing Structural Regularities of Labeled Data in Overparameterized Models},
  author =       {Jiang, Ziheng and Zhang, Chiyuan and Talwar, Kunal and Mozer, Michael C},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {5034--5044},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/jiang21k/jiang21k.pdf},
  url = 	 {https://proceedings.mlr.press/v139/jiang21k.html},
  abstract = 	 {Humans are accustomed to environments that contain both regularities and exceptions. For example, at most gas stations, one pays prior to pumping, but the occasional rural station does not accept payment in advance. Likewise, deep neural networks can generalize across instances that share common patterns or structures, yet have the capacity to memorize rare or irregular forms. We analyze how individual instances are treated by a model via a consistency score. The score characterizes the expected accuracy for a held-out instance given training sets of varying size sampled from the data distribution. We obtain empirical estimates of this score for individual instances in multiple data sets, and we show that the score identifies out-of-distribution and mislabeled examples at one end of the continuum and strongly regular examples at the other end. We identify computationally inexpensive proxies to the consistency score using statistics collected during training. We apply the score toward understanding the dynamics of representation learning and to filter outliers during training.}
}


@article{vgg,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{alexnet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  pages={1097--1105},
  year={2012}
}

@article{lenet,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@inproceedings{convnet,
  title={Dynamic few-shot visual learning without forgetting},
  author={Gidaris, Spyros and Komodakis, Nikos},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4367--4375},
  year={2018}
}

@article{catastrophic_forgetting,
  title={An empirical investigation of catastrophic forgetting in gradient-based neural networks},
  author={Goodfellow, Ian J and Mirza, Mehdi and Xiao, Da and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1312.6211},
  year={2013}
}

@article{nsml2,
  title={Nsml: Meet the mlaas platform with a real-world case study},
  author={Kim, Hanjoo and Kim, Minkyu and Seo, Dongjoo and Kim, Jinwoong and Park, Heungseok and Park, Soeun and Jo, Hyunwoo and Kim, KyungHyun and Yang, Youngil and Kim, Youngkwan and others},
  journal={arXiv preprint arXiv:1810.09957},
  year={2018}
}

@article{nsml1,
  title={Nsml: A machine learning platform that enables you to focus on your models},
  author={Sung, Nako and Kim, Minkyu and Jo, Hyunwoo and Yang, Youngil and Kim, Jingwoong and Lausen, Leonard and Kim, Youngkwan and Lee, Gayoung and Kwak, Donghyun and Ha, Jung-Woo and others},
  journal={arXiv preprint arXiv:1712.05902},
  year={2017}
}

@inproceedings{kip,
  title={Dataset Meta-Learning from Kernel Ridge-Regression},
  author={Nguyen, Timothy and Chen, Zhourong and Lee, Jaehoon},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@book{wordnet,
  title={WordNet: An electronic lexical database},
  author={Miller, George A},
  year={1998},
  publisher={MIT press}
}

@inproceedings{
dd_infinite,
title={Dataset Distillation with Infinitely Wide Convolutional Networks},
author={Timothy Nguyen and Roman Novak and Lechao Xiao and Jaehoon Lee},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=hXWPpJedrVP}
}

@article{kernel_velocity,
  title={Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the Neural Tangent Kernel},
  author={Fort, Stanislav and Dziugaite, Gintare Karolina and Paul, Mansheej and Kharaghani, Sepideh and Roy, Daniel M and Ganguli, Surya},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{dd,
  title={Dataset distillation},
  author={Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio and Efros, Alexei A},
  journal={arXiv preprint arXiv:1811.10959},
  year={2018}
}

@InProceedings{gradmatch_coreset,
  title = 	 {GRAD-MATCH: Gradient Matching based Data Subset Selection for Efficient Deep Model Training},
  author =       {Killamsetty, Krishnateja and S, Durga and Ramakrishnan, Ganesh and De, Abir and Iyer, Rishabh},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {5464--5474},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/killamsetty21a/killamsetty21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/killamsetty21a.html},
  abstract = 	 {The great success of modern machine learning models on large datasets is contingent on extensive computational resources with high financial and environmental costs. One way to address this is by extracting subsets that generalize on par with the full data. In this work, we propose a general framework, GRAD-MATCH, which finds subsets that closely match the gradient of the \emph{training or validation} set. We find such subsets effectively using an orthogonal matching pursuit algorithm. We show rigorous theoretical and convergence guarantees of the proposed algorithm and, through our extensive experiments on real-world datasets, show the effectiveness of our proposed framework. We show that GRAD-MATCH significantly and consistently outperforms several recent data-selection algorithms and achieves the best accuracy-efficiency trade-off. GRAD-MATCH is available as a part of the CORDS toolkit: \url{https://github.com/decile-team/cords}.}
}


@InProceedings{coresets_for_efficient,
  title = 	 {Coresets for Data-efficient Training of Machine Learning Models},
  author =       {Mirzasoleiman, Baharan and Bilmes, Jeff and Leskovec, Jure},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {6950--6960},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/mirzasoleiman20a/mirzasoleiman20a.pdf},
  url = 	 {https://proceedings.mlr.press/v119/mirzasoleiman20a.html},
  abstract = 	 {Incremental gradient (IG) methods, such as stochastic gradient descent and its variants are commonly used for large scale optimization in machine learning. Despite the sustained effort to make IG methods more data-efficient, it remains an open question how to select a training data subset that can theoretically and practically perform on par with the full dataset. Here we develop CRAIG, a method to select a weighted subset (or coreset) of training data that closely estimates the full gradient by maximizing a submodular function. We prove that applying IG to this subset is guaranteed to converge to the (near)optimal solution with the same convergence rate as that of IG for convex optimization. As a result, CRAIG achieves a speedup that is inversely proportional to the size of the subset. To our knowledge, this is the first rigorous method for data-efficient training of general machine learning models. Our extensive set of experiments show that CRAIG, while achieving practically the same solution, speeds up various IG methods by up to 6x for logistic regression and 3x for training deep neural networks.}
}


@inproceedings{
dc,
title={Dataset Condensation with Gradient Matching},
author={Bo Zhao and Konda Reddy Mopuri and Hakan Bilen},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=mSAKhLYLSsl}
}

@inproceedings{
dsa,
title={Dataset Condensation with Differentiable Siamese Augmentation},
author={Zhao, Bo and Bilen, Hakan},
booktitle={International Conference on Machine Learning},
year={2021}
}

@article{diet,
  title={Deep Learning on a Data Diet: Finding Important Examples Early in Training},
  author={Paul, Mansheej and Ganguli, Surya and Dziugaite, Gintare Karolina},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@misc{visda2017,
    Author = {Xingchao Peng and Ben Usman and Neela Kaushik and Judy Hoffman and Dequan Wang and Kate Saenko},
    Title = {VisDA: The Visual Domain Adaptation Challenge},
    Year = {2017},
    Eprint = {arXiv:1710.06924},
}

@inproceedings{gan,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}

@article{80mti,
  title={80 million tiny images: A large data set for nonparametric object and scene recognition},
  author={Torralba, Antonio and Fergus, Rob and Freeman, William T},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={30},
  number={11},
  pages={1958--1970},
  year={2008},
  publisher={IEEE}
}
@article{places365,
  title={Places: A 10 million Image Database for Scene Recognition},
  author={Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2017},
  publisher={IEEE}
}

@article{vapnik,
  title={Statistical learning theory Wiley},
  author={Vapnik, Vladimir and Vapnik, Vlamimir},
  journal={New York},
  volume={1},
  year={1998}
}

@inproceedings{autoaugment,
  title={Autoaugment: Learning augmentation strategies from data},
  author={Cubuk, Ekin D and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={113--123},
  year={2019}
}

@article{adv_multitask,
  title={Adversarial multi-task learning for text classification},
  author={Liu, Pengfei and Qiu, Xipeng and Huang, Xuanjing},
  journal={arXiv preprint arXiv:1704.05742},
  year={2017}
}

@inproceedings{pareto_multitask,
  title={Pareto multi-task learning},
  author={Lin, Xi and Zhen, Hui-Ling and Li, Zhenhua and Zhang, Qing-Fu and Kwong, Sam},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12060--12070},
  year={2019}
}

@incollection{adaptive_multitask,
 abstract = {Adversarial Multi-task Representation Learning (AMTRL) methods are able to boost the performance of Multi-task Representation Learning (MTRL) models. However, the theoretical mechanism behind AMTRL is less investigated. To fill this gap, we study the generalization error bound of AMTRL through the lens of Lagrangian duality . Based on the duality, we proposed an novel adaptive AMTRL algorithm which improves the performance of original AMTRL methods. The extensive experiments back up our theoretical analysis and validate the superiority of our proposed algorithm.},
 author = {MAO, YUREN and Liu, Weiwei and Lin, Xuemin},
 booktitle = {Proceedings of Machine Learning and Systems 2020},
 pages = {1832--1841},
 title = {Adaptive Adversarial Multi-task Representation Learning},
 year = {2020}
}


@article{curse_of_dimension,
  title={Curse of dimensionality},
  author={Bellman, Robert},
  journal={Adaptive control processes: a guided tour. Princeton, NJ},
  volume={3},
  pages={2},
  year={1961}
}
@article{selftraining,
  title={Self-training with Noisy Student improves ImageNet classification},
  author={Xie, Qizhe and Hovy, Eduard and Luong, Minh-Thang and Le, Quoc V},
  journal={arXiv preprint arXiv:1911.04252},
  year={2019}
}

@misc{simpson_dataset,
author = {Alexandre Attia},
title = {The Simpsons Characters Data},
year = {2018},
note={data retrieved from Kaggle, \url{ https://www.kaggle.com/alexattia/the-simpsons-characters-dataset}},
}

@misc{fashion_dataset,
author = {Param Aggarwal},
title = {Fashion Product Images (Small)},
year = {2018},
note={data retrieved from Kaggle, \url{ https://www.kaggle.com/paramaggarwal/fashion-product-images-small}},
}

@misc{crack_dataset,
author = {Özgenel, C F and Gönenç Sorguç, A.},
title = {Performance Comparison of Pretrained Convolutional Neural Networks on Crack Detection in Buildings},
year = {2018},
note={data retrieved from Kaggle, \url{ https://www.kaggle.com/arunrk7/surface-crack-detection}},
}

@inproceedings{
adv_transfer,
title={Adversarially robust transfer learning},
author={Ali Shafahi and Parsa Saadatpanah and Chen Zhu and Amin Ghiasi and Christoph Studer and David Jacobs and Tom Goldstein},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=ryebG04YvB}
}


@inproceedings{pretrain_hendrycks,
  title={Using pre-training can improve model robustness and uncertainty},
  author={Hendrycks, Dan and Lee, Kimin and Mazeika, Mantas},
  booktitle={International Conference on Machine Learning},
  pages={2712--2721},
  year={2019},
  organization={PMLR}
}

@incollection{selfsupervision_hendrycks,
title = {Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty},
author = {Hendrycks, Dan and Mazeika, Mantas and Kadavath, Saurav and Song, Dawn},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {15663--15674},
year = {2019},
publisher = {Curran Associates, Inc.}
}


@article{outlier,
  title={Deep anomaly detection with outlier exposure},
  author={Hendrycks, Dan and Mazeika, Mantas and Dietterich, Thomas},
  journal={arXiv preprint arXiv:1812.04606},
  year={2018}
}
@article{uniformlabel,
  title={Training confidence-calibrated classifiers for detecting out-of-distribution samples},
  author={Lee, Kimin and Lee, Honglak and Lee, Kibok and Shin, Jinwoo},
  journal={arXiv preprint arXiv:1711.09325},
  year={2017}
}
@article{input_complexity,
  title={Input complexity and out-of-distribution detection with likelihood-based generative models},
  author={Serr{\`a}, Joan and {\'A}lvarez, David and G{\'o}mez, Vicen{\c{c}} and Slizovskaia, Olga and N{\'u}{\~n}ez, Jos{\'e} F and Luque, Jordi},
  journal={arXiv preprint arXiv:1909.11480},
  year={2019}
}

@article{multidomain2,
  title={Multi-domain learning by confidence-weighted parameter combination},
  author={Dredze, Mark and Kulesza, Alex and Crammer, Koby},
  journal={Machine Learning},
  volume={79},
  number={1-2},
  pages={123--149},
  year={2010},
  publisher={Springer}
}

@inproceedings{multidomain3,
  title={Multi-domain learning: when do domains matter?},
  author={Joshi, Mahesh and Dredze, Mark and Cohen, William and Rose, Carolyn},
  booktitle={Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
  pages={1302--1312},
  year={2012}
}

@article{transformation_adv_defense,
  title={Countering adversarial images using input transformations},
  author={Guo, Chuan and Rana, Mayank and Cisse, Moustapha and Van Der Maaten, Laurens},
  journal={arXiv preprint arXiv:1711.00117},
  year={2017}
}

@inproceedings{office,
  title={Adapting visual category models to new domains},
  author={Saenko, Kate and Kulis, Brian and Fritz, Mario and Darrell, Trevor},
  booktitle={European conference on computer vision},
  pages={213--226},
  year={2010},
  organization={Springer}
}

@article{downsampled_imagenet,
  title={A downsampled variant of imagenet as an alternative to the cifar datasets},
  author={Chrabaszcz, Patryk and Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1707.08819},
  year={2017}
}


@inproceedings{
bag_of_tricks_adv,
title={Bag of Tricks for Adversarial Training},
author={Tianyu Pang and Xiao Yang and Yinpeng Dong and Hang Su and Jun Zhu},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=Xb8xvrtB8Ce}
}

@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  number={1},
  pages={41--75},
  year={1997},
  publisher={Springer}
}

@inproceedings{multidomain1,
  title={Learning multi-domain convolutional neural networks for visual tracking},
  author={Nam, Hyeonseob and Han, Bohyung},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4293--4302},
  year={2016}
}

@InProceedings{Alvin,
author = {Chan, Alvin and Tay, Yi and Ong, Yew-Soon},
title = {What It Thinks Is Important Is Important: Robustness Transfers Through Input Gradients},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@article{do_deep_generative,
  title={Do deep generative models know what they don't know?},
  author={Nalisnick, Eric and Matsukawa, Akihiro and Teh, Yee Whye and Gorur, Dilan and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1810.09136},
  year={2018}
}

@InProceedings{highfreqency,
author = {Wang, Haohan and Wu, Xindi and Huang, Zeyi and Xing, Eric P.},
title = {High-Frequency Component Helps Explain the Generalization of Convolutional Neural Networks},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@misc{imagenette,
    author    = "Jeremy Howard",
    title     = "Imagenette",
    url       = "https://github.com/fastai/imagenette/"
}

@inproceedings{res,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={European conference on computer vision},
  pages={630--645},
  year={2016},
  organization={Springer}
}

@article{your_classifier,
  title={Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One},
  author={Grathwohl, Will and Wang, Kuan-Chieh and Jacobsen, J{\"o}rn-Henrik and Duvenaud, David and Norouzi, Mohammad and Swersky, Kevin},
  journal={arXiv preprint arXiv:1912.03263},
  year={2019}
}

@article{rebias,
  title={Learning De-biased Representations with Biased Representations},
  author={Bahng, Hyojin and Chun, Sanghyuk and Yun, Sangdoo and Choo, Jaegul and Oh, Seong Joon},
  journal={arXiv preprint arXiv:1910.02806},
  year={2019}
}

@article{cnntexturebias,
  title={ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness},
  author={Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland},
  journal={arXiv preprint arXiv:1811.12231},
  year={2018}
}

@InProceedings{avmixup,
author = {Lee, Saehyung and Lee, Hyungyu and Yoon, Sungroh},
title = {Adversarial Vertex Mixup: Toward Better Adversarially Robust Generalization},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@inproceedings{bnb_attack,
  title={Accurate, reliable and fast robustness evaluation},
  author={Brendel, Wieland and Rauber, Jonas and K{\"u}mmerer, Matthias and Ustyuzhaninov, Ivan and Bethge, Matthias},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12841--12851},
  year={2019}
}

@article{spatial_attack,
  title={Spatially transformed adversarial examples},
  author={Xiao, Chaowei and Zhu, Jun-Yan and Li, Bo and He, Warren and Liu, Mingyan and Song, Dawn},
  journal={arXiv preprint arXiv:1801.02612},
  year={2018}
}

@article{randsmoothing_defense,
  title={Certified adversarial robustness via randomized smoothing},
  author={Cohen, Jeremy M and Rosenfeld, Elan and Kolter, J Zico},
  journal={arXiv preprint arXiv:1902.02918},
  year={2019}
}

@article{auto_attack,
  title={Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
  author={Croce, Francesco and Hein, Matthias},
  journal={arXiv preprint arXiv:2003.01690},
  year={2020}
}

@article{fab_attack,
  title={Minimally distorted adversarial examples with a fast adaptive boundary attack},
  author={Croce, Francesco and Hein, Matthias},
  journal={arXiv preprint arXiv:1907.02044},
  year={2019}
}

@article{square_attack,
  title={Square attack: a query-efficient black-box adversarial attack via random search},
  author={Andriushchenko, Maksym and Croce, Francesco and Flammarion, Nicolas and Hein, Matthias},
  journal={arXiv preprint arXiv:1912.00049},
  year={2019}
}

@inproceedings{dai2017good,
  title={Good semi-supervised learning that requires a bad gan},
  author={Dai, Zihang and Yang, Zhilin and Yang, Fan and Cohen, William W and Salakhutdinov, Russ R},
  booktitle={Advances in neural information processing systems},
  pages={6510--6520},
  year={2017}
}

@inproceedings{
hendrycks2018deep,
title={Deep Anomaly Detection with Outlier Exposure},
author={Dan Hendrycks and Mantas Mazeika and Thomas Dietterich},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HyxCxhRcY7},
}

@article{rotation,
  title={Unsupervised representation learning by predicting image rotations},
  author={Gidaris, Spyros and Singh, Praveer and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1803.07728},
  year={2018}
}

@article{darlow2018cinic,
  title={Cinic-10 is not imagenet or cifar-10},
  author={Darlow, Luke N and Crowley, Elliot J and Antoniou, Antreas and Storkey, Amos J},
  journal={arXiv preprint arXiv:1810.03505},
  year={2018}
}

@inproceedings{instagramnet,
  title={Exploring the limits of weakly supervised pretraining},
  author={Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and Van Der Maaten, Laurens},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={181--196},
  year={2018}
}

@article{align_google,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc V and Sung, Yunhsuan and Li, Zhen and Duerig, Tom},
  journal={arXiv preprint arXiv:2102.05918},
  year={2021}
}


@inproceedings{castro2018end,
  title={End-to-end incremental learning},
  author={Castro, Francisco M and Mar{\'\i}n-Jim{\'e}nez, Manuel J and Guil, Nicol{\'a}s and Schmid, Cordelia and Alahari, Karteek},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={233--248},
  year={2018}
}

@inproceedings{rebuffi2017icarl,
  title={icarl: Incremental classifier and representation learning},
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={2001--2010},
  year={2017}
}

@article{chaudhry2019tiny,
  title={On tiny episodic memories in continual learning},
  author={Chaudhry, Arslan and Rohrbach, Marcus and Elhoseiny, Mohamed and Ajanthan, Thalaiyasingam and Dokania, Puneet K and Torr, Philip HS and Ranzato, Marc'Aurelio},
  journal={arXiv preprint arXiv:1902.10486},
  year={2019}
}

@inproceedings{wang2020uniformity,
  title={Understanding contrastive representation learning through alignment and uniformity on the hypersphere},
  author={Wang, Tongzhou and Isola, Phillip},
  booktitle={International Conference on Machine Learning},
  pages={9929--9939},
  year={2020},
  organization={PMLR}
}

@inproceedings{stallkamp2011german,
  title={The German traffic sign recognition benchmark: a multi-class classification competition},
  author={Stallkamp, Johannes and Schlipsing, Marc and Salmen, Jan and Igel, Christian},
  booktitle={The 2011 international joint conference on neural networks},
  pages={1453--1460},
  year={2011},
  organization={IEEE}
}