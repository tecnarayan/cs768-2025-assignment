\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and Bottou]{Arjovsky2017-ko}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock Wasserstein {GAN}.
\newblock January 2017.

\bibitem[Cisse et~al.(2017)Cisse, Bojanowski, Grave, Dauphin, and
  Usunier]{Cisse2017-oz}
Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, and Nicolas
  Usunier.
\newblock Parseval networks: Improving robustness to adversarial examples.
\newblock April 2017.

\bibitem[Petzka et~al.(2017)Petzka, Fischer, and Lukovnicov]{Petzka2017-cf}
Henning Petzka, Asja Fischer, and Denis Lukovnicov.
\newblock On the regularization of wasserstein {GANs}.
\newblock September 2017.

\bibitem[Bartlett et~al.(2017)Bartlett, Foster, and Telgarsky]{Bartlett2017-od}
Peter Bartlett, Dylan~J Foster, and Matus Telgarsky.
\newblock Spectrally-normalized margin bounds for neural networks.
\newblock June 2017.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{Szegedy2013-yt}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock December 2013.

\bibitem[Weng et~al.(2018{\natexlab{a}})Weng, Zhang, Chen, Song, Hsieh, Boning,
  Dhillon, and Daniel]{Weng2018-gr}
Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Duane Boning,
  Inderjit~S Dhillon, and Luca Daniel.
\newblock Towards fast computation of certified robustness for {ReLU} networks.
\newblock April 2018{\natexlab{a}}.

\bibitem[Yang et~al.(2020)Yang, Rashtchian, Zhang, Salakhutdinov, and
  Chaudhuri]{yang2020adversarial}
Yao-Yuan Yang, Cyrus Rashtchian, Hongyang Zhang, Ruslan Salakhutdinov, and
  Kamalika Chaudhuri.
\newblock Adversarial robustness through local lipschitzness, 2020.

\bibitem[Yurochkin et~al.(2020)Yurochkin, Bower, and
  Sun]{yurochkin2020training}
Mikhail Yurochkin, Amanda Bower, and Yuekai Sun.
\newblock Training individually fair ml models with sensitive subspace
  robustness.
\newblock In \emph{International Conference on Learning Representations, Addis
  Ababa, Ethiopia}, 2020.

\bibitem[Dwork et~al.(2011)Dwork, Hardt, Pitassi, Reingold, and
  Zemel]{dwork2011fairness}
Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Rich Zemel.
\newblock Fairness through awareness, 2011.

\bibitem[Latorre et~al.(2019)Latorre, Rolland, and Cevher]{lipopt}
Fabian Latorre, Paul Rolland, and Volkan Cevher.
\newblock Lipschitz constant estimation of neural networks via sparse
  polynomial optimization.
\newblock September 2019.

\bibitem[Paulavi{\v c}ius and {\v Z}ilinskas(2006)]{Paulavicius2006-no}
Remigijus Paulavi{\v c}ius and Julius {\v Z}ilinskas.
\newblock Analysis of different norms and corresponding lipschitz constants for
  global optimization.
\newblock \emph{Ukio Technol. Ekonominis Vystymas}, 12\penalty0 (4):\penalty0
  301--306, January 2006.

\bibitem[Kakade and Lee(2018)]{kakade2018provably}
Sham~M Kakade and Jason~D Lee.
\newblock Provably correct automatic sub-differentiation for qualified
  programs.
\newblock In \emph{Advances in neural information processing systems}, pages
  7125--7135, 2018.

\bibitem[Virmaux and Scaman(2018)]{Virmaux2018-ti}
Aladin Virmaux and Kevin Scaman.
\newblock Lipschitz regularity of deep neural networks: analysis and efficient
  estimation.
\newblock In S~Bengio, H~Wallach, H~Larochelle, K~Grauman, N~Cesa-Bianchi, and
  R~Garnett, editors, \emph{Advances in Neural Information Processing Systems
  31}, pages 3835--3844. Curran Associates, Inc., 2018.

\bibitem[Weng et~al.(2018{\natexlab{b}})Weng, Zhang, Chen, Yi, and
  Daniel]{Weng2018-lf}
Tsui-Wei Weng, Huan Zhang, Pin-Yu Chen, Jinfeng Yi, and Luca Daniel.
\newblock Evaluating the robustness of neural networks: An extreme value theory
  approach.
\newblock January 2018{\natexlab{b}}.

\bibitem[Clarke(1975)]{clarke1975generalized}
Frank~H Clarke.
\newblock Generalized gradients and applications.
\newblock \emph{Transactions of the American Mathematical Society},
  205:\penalty0 247--262, 1975.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in pytorch.
\newblock In \emph{NIPS-W}, 2017.

\bibitem[Hanin and Rolnick(2019)]{Hanin2019-xv}
Boris Hanin and David Rolnick.
\newblock Deep {ReLU} networks have surprisingly few activation patterns.
\newblock June 2019.

\bibitem[{Impagliazzo} and {Paturi}(1999)]{impagliazzo-eth}
R.~{Impagliazzo} and R.~{Paturi}.
\newblock Complexity of k-sat.
\newblock In \emph{Proceedings. Fourteenth Annual IEEE Conference on
  Computational Complexity (Formerly: Structure in Complexity Theory
  Conference) (Cat.No.99CB36317)}, pages 237--240, 1999.

\bibitem[Lomuscio and Maganti(2017)]{Lomuscio2017-ol}
Alessio Lomuscio and Lalit Maganti.
\newblock An approach to reachability analysis for feed-forward {ReLU} neural
  networks.
\newblock June 2017.

\bibitem[Fischetti and Jo(2018)]{Fischetti2018-mi}
Matteo Fischetti and Jason Jo.
\newblock Deep neural networks and mixed integer linear optimization.
\newblock \emph{Constraints}, 23\penalty0 (3):\penalty0 296--309, July 2018.

\bibitem[Tjeng et~al.(2017)Tjeng, Xiao, and Tedrake]{Tjeng2017-qp}
Vincent Tjeng, Kai Xiao, and Russ Tedrake.
\newblock Evaluating robustness of neural networks with mixed integer
  programming.
\newblock November 2017.

\bibitem[Dutta et~al.(2017)Dutta, Jha, Sanakaranarayanan, and
  Tiwari]{Dutta2017-mn}
Souradeep Dutta, Susmit Jha, Sriram Sanakaranarayanan, and Ashish Tiwari.
\newblock Output range analysis for deep neural networks.
\newblock September 2017.

\bibitem[Cheng et~al.(2017)Cheng, N{\"u}hrenberg, and Ruess]{Cheng2017-xq}
Chih-Hong Cheng, Georg N{\"u}hrenberg, and Harald Ruess.
\newblock Maximum resilience of artificial neural networks.
\newblock April 2017.

\bibitem[Xiao et~al.(2018)Xiao, Tjeng, Shafiullah, and Madry]{Xiao2018-aj}
Kai~Y Xiao, Vincent Tjeng, Nur~Muhammad Shafiullah, and Aleksander Madry.
\newblock Training for faster adversarial robustness verification via inducing
  {ReLU} stability.
\newblock September 2018.

\bibitem[Griewank and Walther(2008)]{griewank2008evaluating}
Andreas Griewank and Andrea Walther.
\newblock \emph{Evaluating derivatives: principles and techniques of
  algorithmic differentiation}, volume 105.
\newblock Siam, 2008.

\bibitem[Khan and Barton(2013)]{khan2013evaluating}
Kamil~A Khan and Paul~I Barton.
\newblock Evaluating an element of the clarke generalized jacobian of a
  composite piecewise differentiable function.
\newblock \emph{ACM Transactions on Mathematical Software (TOMS)}, 39\penalty0
  (4):\penalty0 1--28, 2013.

\bibitem[{Singh} et~al.(2019){Singh}, {Gehr}, {P{\"u}schel}, and
  {Vechev}]{SinghGagandeep2019-ki}
{Singh}, {Gehr}, {P{\"u}schel}, and {Vechev}.
\newblock An abstract domain for certifying neural networks.
\newblock \emph{Proceedings of the ACM on Programming Languages}, January 2019.

\bibitem[Tran et~al.(2020)Tran, Bak, Xiang, and Johnson]{tran2020verification}
Hoang-Dung Tran, Stanley Bak, Weiming Xiang, and Taylor~T. Johnson.
\newblock Verification of deep convolutional neural networks using imagestars,
  2020.

\bibitem[Zico~Kolter and Wong(2017)]{Zico_Kolter2017-va}
J~Zico~Kolter and Eric Wong.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock November 2017.

\bibitem[Singh et~al.(2018)Singh, Gehr, Mirman, P{\"u}schel, and
  Vechev]{singh2018fast}
Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus P{\"u}schel, and Martin
  Vechev.
\newblock Fast and effective robustness certification.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  10802--10813, 2018.

\bibitem[Fazlyab et~al.(2019)Fazlyab, Robey, Hassani, Morari, and
  Pappas]{Fazlyab2019-im}
Mahyar Fazlyab, Alexander Robey, Hamed Hassani, Manfred Morari, and George
  Pappas.
\newblock Efficient and accurate estimation of lipschitz constants for deep
  neural networks.
\newblock In H~Wallach, H~Larochelle, A~Beygelzimer, F~d~Alche-Buc, E~Fox, and
  R~Garnett, editors, \emph{Advances in Neural Information Processing Systems
  32}, pages 11423--11434. Curran Associates, Inc., 2019.

\bibitem[Heinonen(2005)]{Heinonen2005-rp}
Juha Heinonen.
\newblock \emph{Lectures on Lipschitz analysis}.
\newblock University of Jyv{\"a}skyl{\"a}, 2005.

\bibitem[Williamson and Shmoys(2011)]{williamson2011design}
David~P Williamson and David~B Shmoys.
\newblock \emph{The design of approximation algorithms}.
\newblock Cambridge university press, 2011.

\bibitem[Hromkovi{\v{c}}(2013)]{hromkovivc2013algorithmics}
Juraj Hromkovi{\v{c}}.
\newblock \emph{Algorithmics for hard problems: introduction to combinatorial
  optimization, randomization, approximation, and heuristics}.
\newblock Springer Science \& Business Media, 2013.

\bibitem[Demaine(2014)]{demaine}
Erik Demaine.
\newblock 6.892 algorithmic lower bounds: Fun with hardness proofs (spring
  '19).
\newblock \url{http://courses.csail.mit.edu/6.892/spring19/}, 2014.
\newblock Accessed: 2020-2-01.

\bibitem[Zuckerman(2007)]{Zuckerman2007-dm}
David Zuckerman.
\newblock Linear degree extractors and the inapproximability of max clique and
  chromatic number.
\newblock \emph{Theory of Computing}, 3\penalty0 (6):\penalty0 103--128, 2007.

\bibitem[Raghunathan et~al.(2018)Raghunathan, Steinhardt, and
  Liang]{Raghunathan2018-zu}
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
\newblock Semidefinite relaxations for certifying robustness to adversarial
  examples.
\newblock November 2018.

\bibitem[Zhang et~al.(2018)Zhang, Weng, Chen, Hsieh, and Daniel]{Zhang2018-fl}
Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel.
\newblock Efficient neural network robustness certification with general
  activation functions.
\newblock November 2018.

\bibitem[Gurobi~Optimization(2020)]{gurobi}
LLC Gurobi~Optimization.
\newblock Gurobi optimizer reference manual, 2020.
\newblock URL \url{http://www.gurobi.com}.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{He2015-ns}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Delving deep into rectifiers: Surpassing {Human-Level} performance on
  {ImageNet} classification.
\newblock February 2015.

\bibitem[Kingma and Ba(2014)]{Kingma2014-au}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock December 2014.

\end{thebibliography}
