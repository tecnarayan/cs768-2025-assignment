\begin{thebibliography}{73}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Adebayo et~al.(2018)Adebayo, Gilmer, Muelly, Goodfellow, Hardt, and
  Kim]{sanity}
Adebayo, J., Gilmer, J., Muelly, M., Goodfellow, I., Hardt, M., and Kim, B.
\newblock Sanity checks for saliency maps.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~31. Curran Associates, Inc., 2018.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2018/file/294a8ed24b1ad22ec2e7efea049b8737-Paper.pdf}.

\bibitem[Agrawal et~al.(2019)Agrawal, Amos, Barratt, Boyd, Diamond, and
  Kolter]{convex_layer}
Agrawal, A., Amos, B., Barratt, S., Boyd, S., Diamond, S., and Kolter, J.~Z.
\newblock Differentiable convex optimization layers.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d\textquotesingle
  Alch\'{e}-Buc, F., Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/file/9ce3c52fc54362e22053399d3181c638-Paper.pdf}.

\bibitem[Amos \& Kolter(2017)Amos and Kolter]{amos}
Amos, B. and Kolter, J.~Z.
\newblock {O}pt{N}et: Differentiable optimization as a layer in neural
  networks.
\newblock In Precup, D. and Teh, Y.~W. (eds.), \emph{Proceedings of the 34th
  International Conference on Machine Learning}, volume~70 of \emph{Proceedings
  of Machine Learning Research}, pp.\  136--145. PMLR, 06--11 Aug 2017.
\newblock URL \url{http://proceedings.mlr.press/v70/amos17a.html}.

\bibitem[Ancona et~al.(2017)Ancona, Ceolini, {\"O}ztireli, and Gross]{towards}
Ancona, M., Ceolini, E., {\"O}ztireli, C., and Gross, M.
\newblock Towards better understanding of gradient-based attribution methods
  for deep neural networks.
\newblock \emph{arXiv preprint arXiv:1711.06104}, 2017.

\bibitem[Anderson et~al.(2018)Anderson, He, Buehler, Teney, Johnson, Gould, and
  Zhang]{vqa2}
Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., and
  Zhang, L.
\newblock Bottom-up and top-down attention for image captioning and visual
  question answering.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  6077--6086, 2018.

\bibitem[Bach et~al.(2015)Bach, Binder, Montavon, Klauschen, M{\"u}ller, and
  Samek]{lrp}
Bach, S., Binder, A., Montavon, G., Klauschen, F., M{\"u}ller, K.-R., and
  Samek, W.
\newblock On pixel-wise explanations for non-linear classifier decisions by
  layer-wise relevance propagation.
\newblock \emph{PloS one}, 10\penalty0 (7):\penalty0 e0130140, 2015.

\bibitem[Bahdanau et~al.(2014)Bahdanau, Cho, and Bengio]{bahdanau2014neural}
Bahdanau, D., Cho, K., and Bengio, Y.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock \emph{arXiv preprint arXiv:1409.0473}, 2014.

\bibitem[Bakas et~al.(2017)Bakas, Akbari, Sotiras, Bilello, Rozycki, Kirby,
  Freymann, Farahani, and Davatzikos]{brats2}
Bakas, S., Akbari, H., Sotiras, A., Bilello, M., Rozycki, M., Kirby, J.~S.,
  Freymann, J.~B., Farahani, K., and Davatzikos, C.
\newblock Advancing the cancer genome atlas glioma mri collections with expert
  segmentation labels and radiomic features.
\newblock \emph{Scientific data}, 4\penalty0 (1):\penalty0 1--13, 2017.

\bibitem[Bakas et~al.(2018)Bakas, Reyes, Jakab, Bauer, Rempfler, Crimi,
  Shinohara, Berger, Ha, Rozycki, et~al.]{brats3}
Bakas, S., Reyes, M., Jakab, A., Bauer, S., Rempfler, M., Crimi, A., Shinohara,
  R.~T., Berger, C., Ha, S.~M., Rozycki, M., et~al.
\newblock Identifying the best machine learning algorithms for brain tumor
  segmentation, progression assessment, and overall survival prediction in the
  brats challenge.
\newblock \emph{arXiv preprint arXiv:1811.02629}, 2018.

\bibitem[Balduzzi et~al.(2017)Balduzzi, Frean, Leary, Lewis, Ma, and
  McWilliams]{shatt}
Balduzzi, D., Frean, M., Leary, L., Lewis, J., Ma, K. W.-D., and McWilliams, B.
\newblock The shattered gradients problem: If resnets are the answer, then what
  is the question?
\newblock In \emph{International Conference on Machine Learning}, pp.\
  342--350. PMLR, 2017.

\bibitem[Bello et~al.(2019)Bello, Zoph, Vaswani, Shlens, and Le]{self_attn2}
Bello, I., Zoph, B., Vaswani, A., Shlens, J., and Le, Q.~V.
\newblock Attention augmented convolutional networks.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  3286--3295, 2019.

\bibitem[Berthet et~al.(2020)Berthet, Blondel, Teboul, Cuturi, Vert, and
  Bach]{berthet}
Berthet, Q., Blondel, M., Teboul, O., Cuturi, M., Vert, J.-P., and Bach, F.
\newblock Learning with differentiable pertubed optimizers.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.~F., and Lin,
  H. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  9508--9519. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/file/6bb56208f672af0dd65451f869fedfd9-Paper.pdf}.

\bibitem[Bynum et~al.(2021)Bynum, Hackebeil, Hart, Laird, Nicholson, Siirola,
  Watson, and Woodruff]{pyomo}
Bynum, M.~L., Hackebeil, G.~A., Hart, W.~E., Laird, C.~D., Nicholson, B.~L.,
  Siirola, J.~D., Watson, J.-P., and Woodruff, D.~L.
\newblock \emph{Pyomo--optimization modeling in python}, volume~67.
\newblock Springer Science \& Business Media, third edition, 2021.

\bibitem[Chefer et~al.(2020)Chefer, Gur, and Wolf]{chefer2020transformer}
Chefer, H., Gur, S., and Wolf, L.
\newblock Transformer interpretability beyond attention visualization.
\newblock \emph{arXiv preprint arXiv:2012.09838}, 2020.

\bibitem[Chen et~al.(2018)Chen, Song, Wainwright, and Jordan]{l2x}
Chen, J., Song, L., Wainwright, M., and Jordan, M.
\newblock Learning to explain: An information-theoretic perspective on model
  interpretation.
\newblock In Dy, J. and Krause, A. (eds.), \emph{Proceedings of the 35th
  International Conference on Machine Learning}, volume~80 of \emph{Proceedings
  of Machine Learning Research}, pp.\  883--892. PMLR, 10--15 Jul 2018.
\newblock URL \url{http://proceedings.mlr.press/v80/chen18j.html}.

\bibitem[Connor et~al.(2004)Connor, Egeth, and Yantis]{connor2004visual}
Connor, C.~E., Egeth, H.~E., and Yantis, S.
\newblock Visual attention: bottom-up versus top-down.
\newblock \emph{Current biology}, 14\penalty0 (19):\penalty0 R850--R852, 2004.

\bibitem[Dabkowski \& Gal(2017)Dabkowski and Gal]{saliency_gal}
Dabkowski, P. and Gal, Y.
\newblock Real time image saliency for black box classifiers.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2017/file/0060ef47b12160b9198302ebdb144dcf-Paper.pdf}.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Domke(2010)]{domke}
Domke, J.
\newblock Implicit differentiation by perturbation.
\newblock In Lafferty, J., Williams, C., Shawe-Taylor, J., Zemel, R., and
  Culotta, A. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~23. Curran Associates, Inc., 2010.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2010/file/6ecbdd6ec859d284dc13885a37ce8d81-Paper.pdf}.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, et~al.]{vit}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Feng et~al.(2018)Feng, Wallace, Grissom~II, Iyyer, Rodriguez, and
  Boyd-Graber]{path}
Feng, S., Wallace, E., Grissom~II, A., Iyyer, M., Rodriguez, P., and
  Boyd-Graber, J.
\newblock Pathologies of neural models make interpretations difficult.
\newblock \emph{arXiv preprint arXiv:1804.07781}, 2018.

\bibitem[Fong et~al.(2019)Fong, Patrick, and Vedaldi]{input_perturb}
Fong, R., Patrick, M., and Vedaldi, A.
\newblock Understanding deep networks via extremal perturbations and smooth
  masks.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  2950--2958, 2019.

\bibitem[Fong \& Vedaldi(2017)Fong and Vedaldi]{input_perturb2}
Fong, R.~C. and Vedaldi, A.
\newblock Interpretable explanations of black boxes by meaningful perturbation.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  3429--3437, 2017.

\bibitem[Gan et~al.(2019)Gan, Cheng, Kholy, Li, Liu, and Gao]{visdial}
Gan, Z., Cheng, Y., Kholy, A., Li, L., Liu, J., and Gao, J.
\newblock Multi-step reasoning via recurrent dual attention for visual dialog.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  6463--6474, Florence, Italy, July 2019.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P19-1648}.
\newblock URL \url{https://www.aclweb.org/anthology/P19-1648}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Hu et~al.(2019)Hu, Zhang, Xie, and Lin]{self_attn3}
Hu, H., Zhang, Z., Xie, Z., and Lin, S.
\newblock Local relation networks for image recognition.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  3464--3473, 2019.

\bibitem[Hu et~al.(2018)Hu, Shen, and Sun]{self_attn5}
Hu, J., Shen, L., and Sun, G.
\newblock Squeeze-and-excitation networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  7132--7141, 2018.

\bibitem[Jain \& Wallace(2019)Jain and Wallace]{attn_isnot}
Jain, S. and Wallace, B.~C.
\newblock Attention is not explanation.
\newblock \emph{arXiv preprint arXiv:1902.10186}, 2019.

\bibitem[Jain et~al.(2020)Jain, Wiegreffe, Pinter, and Wallace]{fresh}
Jain, S., Wiegreffe, S., Pinter, Y., and Wallace, B.~C.
\newblock Learning to faithfully rationalize by construction.
\newblock \emph{arXiv preprint arXiv:2005.00115}, 2020.

\bibitem[Jetley et~al.(2018)Jetley, Lord, Lee, and Torr]{ltpa}
Jetley, S., Lord, N.~A., Lee, N., and Torr, P.~H.
\newblock Learn to pay attention.
\newblock \emph{arXiv preprint arXiv:1804.02391}, 2018.

\bibitem[Jiang et~al.(2019)Jiang, He, Chen, Liu, Gao, and Zhao]{trans_jiang}
Jiang, H., He, P., Chen, W., Liu, X., Gao, J., and Zhao, T.
\newblock Smart: Robust and efficient fine-tuning for pre-trained natural
  language models through principled regularized optimization.
\newblock \emph{arXiv preprint arXiv:1911.03437}, 2019.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kokhlikyan et~al.(2020)Kokhlikyan, Miglani, Martin, Wang, Alsallakh,
  Reynolds, Melnikov, Kliushkina, Araya, Yan, and
  Reblitz-Richardson]{kokhlikyan2020captum}
Kokhlikyan, N., Miglani, V., Martin, M., Wang, E., Alsallakh, B., Reynolds, J.,
  Melnikov, A., Kliushkina, N., Araya, C., Yan, S., and Reblitz-Richardson, O.
\newblock Captum: A unified and generic model interpretability library for
  pytorch, 2020.

\bibitem[Lan et~al.(2019)Lan, Chen, Goodman, Gimpel, Sharma, and
  Soricut]{trans_lan}
Lan, Z., Chen, M., Goodman, S., Gimpel, K., Sharma, P., and Soricut, R.
\newblock Albert: A lite bert for self-supervised learning of language
  representations.
\newblock \emph{arXiv preprint arXiv:1909.11942}, 2019.

\bibitem[Lundberg \& Lee(2017)Lundberg and Lee]{shap}
Lundberg, S. and Lee, S.-I.
\newblock A unified approach to interpreting model predictions.
\newblock \emph{arXiv preprint arXiv:1705.07874}, 2017.

\bibitem[Mahendran \& Vedaldi(2016)Mahendran and Vedaldi]{saliency_mahendran}
Mahendran, A. and Vedaldi, A.
\newblock Visualizing deep convolutional neural networks using natural
  pre-images.
\newblock \emph{International Journal of Computer Vision}, 120\penalty0
  (3):\penalty0 233--255, 2016.

\bibitem[Mangasarian \& Fromovitz(1967)Mangasarian and Fromovitz]{fritz}
Mangasarian, O. and Fromovitz, S.
\newblock The fritz john necessary optimality conditions in the presence of
  equality and inequality constraints.
\newblock \emph{Journal of Mathematical Analysis and Applications}, 17\penalty0
  (1):\penalty0 37--47, 1967.
\newblock ISSN 0022-247X.
\newblock \doi{https://doi.org/10.1016/0022-247X(67)90163-1}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/0022247X67901631}.

\bibitem[Mehta et~al.(2020)Mehta, Ghazvininejad, Iyer, Zettlemoyer, and
  Hajishirzi]{trans_mehta}
Mehta, S., Ghazvininejad, M., Iyer, S., Zettlemoyer, L., and Hajishirzi, H.
\newblock Delight: Very deep and light-weight transformer.
\newblock \emph{arXiv preprint arXiv:2008.00623}, 2020.

\bibitem[Menze et~al.(2014)Menze, Jakab, Bauer, Kalpathy-Cramer, Farahani,
  Kirby, Burren, Porz, Slotboom, Wiest, et~al.]{brats1}
Menze, B.~H., Jakab, A., Bauer, S., Kalpathy-Cramer, J., Farahani, K., Kirby,
  J., Burren, Y., Porz, N., Slotboom, J., Wiest, R., et~al.
\newblock The multimodal brain tumor image segmentation benchmark (brats).
\newblock \emph{IEEE transactions on medical imaging}, 34\penalty0
  (10):\penalty0 1993--2024, 2014.

\bibitem[Montavon et~al.(2017)Montavon, Lapuschkin, Binder, Samek, and
  M{\"u}ller]{dtd}
Montavon, G., Lapuschkin, S., Binder, A., Samek, W., and M{\"u}ller, K.-R.
\newblock Explaining nonlinear classification decisions with deep taylor
  decomposition.
\newblock \emph{Pattern Recognition}, 65:\penalty0 211--222, 2017.

\bibitem[Oktay et~al.(2018)Oktay, Schlemper, Folgoc, Lee, Heinrich, Misawa,
  Mori, McDonagh, Hammerla, Kainz, et~al.]{oktay2018attention}
Oktay, O., Schlemper, J., Folgoc, L.~L., Lee, M., Heinrich, M., Misawa, K.,
  Mori, K., McDonagh, S., Hammerla, N.~Y., Kainz, B., et~al.
\newblock Attention u-net: Learning where to look for the pancreas.
\newblock \emph{arXiv preprint arXiv:1804.03999}, 2018.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E.,
  DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L.,
  Bai, J., and Chintala, S.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d\textquotesingle
  Alch\'{e}-Buc, F., Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 32}, pp.\  8024--8035. Curran Associates,
  Inc., 2019.

\bibitem[Paulus et~al.(2020)Paulus, Choi, Tarlow, Krause, and Maddison]{sst}
Paulus, M.~B., Choi, D., Tarlow, D., Krause, A., and Maddison, C.~J.
\newblock Gradient estimation with stochastic softmax tricks.
\newblock \emph{arXiv preprint arXiv:2006.08063}, 2020.

\bibitem[Raffel et~al.(2019)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu]{trans_raffel}
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou,
  Y., Li, W., and Liu, P.~J.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock \emph{arXiv preprint arXiv:1910.10683}, 2019.

\bibitem[Ramachandran et~al.(2019)Ramachandran, Parmar, Vaswani, Bello,
  Levskaya, and Shlens]{self_attn1}
Ramachandran, P., Parmar, N., Vaswani, A., Bello, I., Levskaya, A., and Shlens,
  J.
\newblock Stand-alone self-attention in vision models.
\newblock \emph{arXiv preprint arXiv:1906.05909}, 2019.

\bibitem[Ribeiro et~al.(2016)Ribeiro, Singh, and Guestrin]{lime}
Ribeiro, M.~T., Singh, S., and Guestrin, C.
\newblock " why should i trust you?" explaining the predictions of any
  classifier.
\newblock In \emph{Proceedings of the 22nd ACM SIGKDD international conference
  on knowledge discovery and data mining}, pp.\  1135--1144, 2016.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and Brox]{unet}
Ronneberger, O., Fischer, P., and Brox, T.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{International Conference on Medical image computing and
  computer-assisted intervention}, pp.\  234--241. Springer, 2015.

\bibitem[Rudin(2019)]{rudin2019stop}
Rudin, C.
\newblock Stop explaining black box machine learning models for high stakes
  decisions and use interpretable models instead.
\newblock \emph{Nature Machine Intelligence}, 1\penalty0 (5):\penalty0
  206--215, 2019.

\bibitem[Rush \& Collins(2012)Rush and Collins]{rush2012tutorial}
Rush, A.~M. and Collins, M.
\newblock A tutorial on dual decomposition and lagrangian relaxation for
  inference in natural language processing.
\newblock \emph{Journal of Artificial Intelligence Research}, 45:\penalty0
  305--362, 2012.

\bibitem[Samek et~al.(2016)Samek, Binder, Montavon, Lapuschkin, and
  M{\"u}ller]{negperturb}
Samek, W., Binder, A., Montavon, G., Lapuschkin, S., and M{\"u}ller, K.-R.
\newblock Evaluating the visualization of what a deep neural network has
  learned.
\newblock \emph{IEEE transactions on neural networks and learning systems},
  28\penalty0 (11):\penalty0 2660--2673, 2016.

\bibitem[Samek et~al.(2021)Samek, Montavon, Lapuschkin, Anders, and
  Müller]{xairev1}
Samek, W., Montavon, G., Lapuschkin, S., Anders, C.~J., and Müller, K.-R.
\newblock Explaining deep neural networks and beyond: A review of methods and
  applications.
\newblock \emph{Proceedings of the IEEE}, 109\penalty0 (3):\penalty0 247--278,
  2021.
\newblock \doi{10.1109/JPROC.2021.3060483}.

\bibitem[Schwartz et~al.(2017)Schwartz, Schwing, and Hazan]{high_order}
Schwartz, I., Schwing, A., and Hazan, T.
\newblock High-order attention models for visual question answering.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2017/file/051928341be67dcba03f0e04104d9047-Paper.pdf}.

\bibitem[Schwartz et~al.(2019{\natexlab{a}})Schwartz, Schwing, and
  Hazan]{aware}
Schwartz, I., Schwing, A.~G., and Hazan, T.
\newblock A simple baseline for audio-visual scene-aware dialog.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  12548--12558, 2019{\natexlab{a}}.

\bibitem[Schwartz et~al.(2019{\natexlab{b}})Schwartz, Yu, Hazan, and
  Schwing]{fga}
Schwartz, I., Yu, S., Hazan, T., and Schwing, A.~G.
\newblock Factor graph attention.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  2039--2048, 2019{\natexlab{b}}.

\bibitem[Selvaraju et~al.(2017)Selvaraju, Cogswell, Das, Vedantam, Parikh, and
  Batra]{gradcam}
Selvaraju, R.~R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., and Batra,
  D.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based
  localization.
\newblock In \emph{2017 IEEE International Conference on Computer Vision
  (ICCV)}, pp.\  618--626, 2017.
\newblock \doi{10.1109/ICCV.2017.74}.

\bibitem[Shrikumar et~al.(2017)Shrikumar, Greenside, and Kundaje]{deeplift}
Shrikumar, A., Greenside, P., and Kundaje, A.
\newblock Learning important features through propagating activation
  differences.
\newblock In Precup, D. and Teh, Y.~W. (eds.), \emph{Proceedings of the 34th
  International Conference on Machine Learning}, volume~70 of \emph{Proceedings
  of Machine Learning Research}, pp.\  3145--3153. PMLR, 06--11 Aug 2017.
\newblock URL \url{http://proceedings.mlr.press/v70/shrikumar17a.html}.

\bibitem[Simonyan et~al.(2014)Simonyan, Vedaldi, and
  Zisserman]{saliency_simonyan}
Simonyan, K., Vedaldi, A., and Zisserman, A.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock 2014.

\bibitem[Smilkov et~al.(2017)Smilkov, Thorat, Kim, Vi{\'e}gas, and
  Wattenberg]{smoothgrad}
Smilkov, D., Thorat, N., Kim, B., Vi{\'e}gas, F., and Wattenberg, M.
\newblock Smoothgrad: removing noise by adding noise.
\newblock \emph{arXiv preprint arXiv:1706.03825}, 2017.

\bibitem[Sra et~al.(2012)Sra, Nowozin, and Wright]{sra2012optimization}
Sra, S., Nowozin, S., and Wright, S.~J.
\newblock \emph{Optimization for machine learning}.
\newblock Mit Press, 2012.

\bibitem[Srinivas \& Fleuret(2019)Srinivas and Fleuret]{fullgrad}
Srinivas, S. and Fleuret, F.
\newblock Full-gradient representation for neural network visualization.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d\textquotesingle
  Alch\'{e}-Buc, F., Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/file/80537a945c7aaa788ccfcdf1b99b5d8f-Paper.pdf}.

\bibitem[Sundararajan et~al.(2017)Sundararajan, Taly, and Yan]{intgrad}
Sundararajan, M., Taly, A., and Yan, Q.
\newblock Axiomatic attribution for deep networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3319--3328. PMLR, 2017.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{aiayn}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, L., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{arXiv preprint arXiv:1706.03762}, 2017.

\bibitem[Wang et~al.(2019)Wang, Gong, and Liu]{trans_wang}
Wang, D., Gong, C., and Liu, Q.
\newblock Improving neural language modeling via adversarial training.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  6555--6565. PMLR, 2019.

\bibitem[Wang et~al.(2017)Wang, Jiang, Qian, Yang, Li, Zhang, Wang, and
  Tang]{self_attn6}
Wang, F., Jiang, M., Qian, C., Yang, S., Li, C., Zhang, H., Wang, X., and Tang,
  X.
\newblock Residual attention network for image classification.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  3156--3164, 2017.

\bibitem[Wiegreffe \& Pinter(2019)Wiegreffe and Pinter]{attn_isnotnot}
Wiegreffe, S. and Pinter, Y.
\newblock Attention is not not explanation.
\newblock \emph{arXiv preprint arXiv:1908.04626}, 2019.

\bibitem[Wightman(2019)]{rw2019timm}
Wightman, R.
\newblock Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem[Yamada et~al.(2020)Yamada, Asai, Shindo, Takeda, and
  Matsumoto]{trans_luke}
Yamada, I., Asai, A., Shindo, H., Takeda, H., and Matsumoto, Y.
\newblock Luke: deep contextualized entity representations with entity-aware
  self-attention.
\newblock \emph{arXiv preprint arXiv:2010.01057}, 2020.

\bibitem[Yu et~al.(2017)Yu, Fu, Mei, and Rui]{vqa3}
Yu, D., Fu, J., Mei, T., and Rui, Y.
\newblock Multi-level attention networks for visual question answering.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  4709--4717, 2017.

\bibitem[Yu et~al.(2019)Yu, Chang, Zhang, and Jaakkola]{yu}
Yu, M., Chang, S., Zhang, Y., and Jaakkola, T.~S.
\newblock Rethinking cooperative rationalization: Introspective extraction and
  complement control.
\newblock \emph{arXiv preprint arXiv:1910.13294}, 2019.

\bibitem[Zeiler \& Fergus(2014)Zeiler and Fergus]{saliency_zeiler}
Zeiler, M.~D. and Fergus, R.
\newblock Visualizing and understanding convolutional networks.
\newblock In \emph{European conference on computer vision}, pp.\  818--833.
  Springer, 2014.

\bibitem[Zhang et~al.(2018)Zhang, Bargal, Lin, Brandt, Shen, and
  Sclaroff]{excit}
Zhang, J., Bargal, S.~A., Lin, Z., Brandt, J., Shen, X., and Sclaroff, S.
\newblock Top-down neural attention by excitation backprop.
\newblock \emph{International Journal of Computer Vision}, 126\penalty0
  (10):\penalty0 1084--1102, 2018.

\bibitem[Zhao et~al.(2018)Zhao, Zhang, Liu, Shi, Loy, Lin, and Jia]{self_attn4}
Zhao, H., Zhang, Y., Liu, S., Shi, J., Loy, C.~C., Lin, D., and Jia, J.
\newblock Psanet: Point-wise spatial attention network for scene parsing.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  267--283, 2018.

\bibitem[Zhou et~al.(2016)Zhou, Khosla, Lapedriza, Oliva, and
  Torralba]{saliency_zhou}
Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., and Torralba, A.
\newblock Learning deep features for discriminative localization.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2921--2929, 2016.

\end{thebibliography}
