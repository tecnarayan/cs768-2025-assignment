\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Xu et~al.(2022{\natexlab{a}})Xu, Zhu, Meng, Ying, Wang, Gu, Huang,
  et~al.]{xu2022a2}
Zhuoer Xu, Guanghui Zhu, Changhua Meng, Zhenzhe Ying, Weiqiang Wang, Ming Gu,
  Yihua Huang, et~al.
\newblock A2: Efficient automated attacker for boosting adversarial training.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 22844--22855, 2022{\natexlab{a}}.

\bibitem[Gu et~al.(2023)Gu, Xu, Chen, Lan, Meng, and Wang]{gu2023mobile}
Zhangxuan Gu, Zhuoer Xu, Haoxing Chen, Jun Lan, Changhua Meng, and Weiqiang
  Wang.
\newblock Mobile user interface element detection via adaptively prompt tuning.
\newblock In \emph{CVPR}, pages 11155--11164, 2023.

\bibitem[Zhang et~al.(2022{\natexlab{a}})Zhang, Li, Gao, and
  Chen]{zhang2022weakly}
Chao Zhang, Huaxiong Li, Yang Gao, and Chunlin Chen.
\newblock Weakly-supervised enhanced semantic-aware hashing for cross-modal
  retrieval.
\newblock \emph{{IEEE} Trans. Knowl. Data Eng.}, 35\penalty0 (6):\penalty0
  6475--6488, 2022{\natexlab{a}}.

\bibitem[Niu et~al.(2023)Niu, Cao, Cong, and Zhang]{niu2023deep}
Li~Niu, Junyan Cao, Wenyan Cong, and Liqing Zhang.
\newblock Deep image harmonization with learnable augmentation.
\newblock In \emph{ICCV}, pages 7482--7491, 2023.

\bibitem[Chen et~al.(2023)Chen, Gu, Li, Lan, Meng, Wang, and Li]{MM23_HDNet}
Haoxing Chen, Zhangxuan Gu, Yaohui Li, Jun Lan, Changhua Meng, Weiqiang Wang,
  and Huaxiong Li.
\newblock Hierarchical dynamic image harmonization.
\newblock In \emph{ACM MM}, 2023.

\bibitem[Feng et~al.(2022)Feng, Feng, Li, and Lin]{CIC_II}
Tingliang Feng, Wei Feng, Weiqi Li, and Di~Lin.
\newblock Cross-image context for single image inpainting.
\newblock In \emph{NeurIPS}, 2022.

\bibitem[Zhang et~al.(2022{\natexlab{b}})Zhang, Xu, Li, Han, Wang, Tai, and
  Liu]{SCSNet}
Jiangning Zhang, Chao Xu, Jian Li, Yue Han, Yabiao Wang, Ying Tai, and Yong
  Liu.
\newblock Scsnet: An efficient paradigm for learning simultaneously image
  colorization and super-resolution.
\newblock In \emph{AAAI}, pages 3271--3279, 2022{\natexlab{b}}.

\bibitem[Kwon and Ye(2022)]{CLIPstyler}
Gihyun Kwon and Jong~Chul Ye.
\newblock Clipstyler: Image style transfer with a single text condition.
\newblock In \emph{CVPR}, pages 18041--18050, 2022.

\bibitem[Brack et~al.(2023)Brack, Friedrich, Hintersdorf, Struppek,
  Schramowski, and Kersting]{SEGA}
Manuel Brack, Felix Friedrich, Dominik Hintersdorf, Lukas Struppek, Patrick
  Schramowski, and Kristian Kersting.
\newblock Sega: Instructing diffusion using semantic dimensions.
\newblock \emph{arXiv preprint arXiv:2301.12247}, 2023.

\bibitem[Brooks et~al.(2023)Brooks, Holynski, and Efros]{Instructpix2pix}
Tim Brooks, Aleksander Holynski, and Alexei~A Efros.
\newblock Instructpix2pix: Learning to follow image editing instructions.
\newblock In \emph{CVPR}, 2023.

\bibitem[Saharia et~al.(2022{\natexlab{a}})Saharia, Chan, Saxena, Li, Whang,
  Denton, Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans,
  et~al.]{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L
  Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim
  Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock In \emph{NeurIPS}, volume~35, pages 36479--36494, 2022{\natexlab{a}}.

\bibitem[Wu et~al.(2019)Wu, Zhang, Liu, Han, Liu, Ding, and Bai]{srnet}
Liang Wu, Chengquan Zhang, Jiaming Liu, Junyu Han, Jingtuo Liu, Errui Ding, and
  Xiang Bai.
\newblock Editing text in the wild.
\newblock In \emph{ACM MM}, pages 1500--1508, 2019.

\bibitem[Qu et~al.(2023)Qu, Tan, Xie, Xu, Wang, and Zhang]{Mostel_STE}
Yadong Qu, Qingfeng Tan, Hongtao Xie, Jianjun Xu, Yuxin Wang, and Yongdong
  Zhang.
\newblock Exploring stroke-level modifications for scene text editing.
\newblock In \emph{AAAI}, 2023.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{sd}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{CVPR}, pages 10684--10695, 2022.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and Brox]{UNET}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{MICCAI}, pages 234--241, 2015.

\bibitem[Zhang and Agrawala(2023)]{controlnet}
Lvmin Zhang and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock 2023.

\bibitem[Mou et~al.(2023)Mou, Wang, Xie, Zhang, Qi, Shan, and Qie]{T2i}
Chong Mou, Xintao Wang, Liangbin Xie, Jian Zhang, Zhongang Qi, Ying Shan, and
  Xiaohu Qie.
\newblock T2i-adapter: Learning adapters to dig out more controllable ability
  for text-to-image diffusion models.
\newblock \emph{arXiv preprint arXiv:2302.08453}, 2023.

\bibitem[Cheng et~al.(2023)Cheng, Chen, Chiu, Tseng, and
  Lee]{cheng2023adaptively}
Shin-I Cheng, Yu-Jie Chen, Wei-Chen Chiu, Hung-Yu Tseng, and Hsin-Ying Lee.
\newblock Adaptively-realistic image generation from stroke and sketch with
  diffusion model.
\newblock In \emph{WACV}, pages 4054--4062, 2023.

\bibitem[Liu et~al.(2022{\natexlab{a}})Liu, Garrette, Saharia, Chan, Roberts,
  Narang, Blok, Mical, Norouzi, and Constant]{CAM}
Rosanne Liu, Dan Garrette, Chitwan Saharia, William Chan, Adam Roberts, Sharan
  Narang, Irina Blok, RJ~Mical, Mohammad Norouzi, and Noah Constant.
\newblock Character-aware models improve visual text rendering.
\newblock \emph{arXiv preprint arXiv:2212.10562}, 2022{\natexlab{a}}.

\bibitem[Li et~al.(2023)Li, Lv, Chen, Cui, Lu, Florencio, Zhang, Li, and
  Wei]{TROCR}
Minghao Li, Tengchao Lv, Jingye Chen, Lei Cui, Yijuan Lu, Dinei Florencio, Cha
  Zhang, Zhoujun Li, and Furu Wei.
\newblock Trocr: Transformer-based optical character recognition with
  pre-trained models.
\newblock In \emph{AAAI}, 2023.

\bibitem[Zeng et~al.(2023)Zeng, Liu, Du, Wang, Lai, Ding, Yang, Xu, Zheng, Xia,
  Tam, Ma, Xue, Zhai, Chen, Liu, Zhang, Dong, and Tang]{zeng2023glm-130b}
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi
  Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng~Lam Tam, Zixuan Ma, Yufei Xue,
  Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong, and Jie
  Tang.
\newblock {GLM}-130b: An open bilingual pre-trained model.
\newblock In \emph{ICLR}, 2023.

\bibitem[Song et~al.(2020)Song, Meng, and Ermon]{ddim}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock In \emph{ICLR}, 2020.

\bibitem[Li()]{CLDA}
Hang Li.
\newblock Cdla: A chinese document layout analysis (cdla) dataset.
\newblock [Online]. Available: \url{https://github.com/buptlihang/CDLA}.
\newblock Accessed 2021.

\bibitem[Xu et~al.(2022{\natexlab{b}})Xu, Lv, Cui, Wang, Lu, Florencio, Zhang,
  and Wei]{xu2022xfund}
Yiheng Xu, Tengchao Lv, Lei Cui, Guoxin Wang, Yijuan Lu, Dinei Florencio, Cha
  Zhang, and Furu Wei.
\newblock Xfund: A benchmark dataset for multilingual visually rich form
  understanding.
\newblock In \emph{Findings of ACL}, pages 3214--3224, 2022{\natexlab{b}}.

\bibitem[Zhong et~al.(2019)Zhong, Tang, and Yepes]{zhong2019publaynet}
Xu~Zhong, Jianbin Tang, and Antonio~Jimeno Yepes.
\newblock Publaynet: largest dataset ever for document layout analysis.
\newblock In \emph{ICDAR}, pages 1015--1022, 2019.

\bibitem[Zhang et~al.(2019)Zhang, Zhou, Jiang, Song, Li, Zhou, Wang, Wang,
  Liao, Yang, et~al.]{zhang2019icdar}
Rui Zhang, Yongsheng Zhou, Qianyi Jiang, Qi~Song, Nan Li, Kai Zhou, Lei Wang,
  Dong Wang, Minghui Liao, Mingkun Yang, et~al.
\newblock Icdar 2019 robust reading challenge on reading chinese text on
  signboard.
\newblock In \emph{ICDAR}, pages 1577--1581, 2019.

\bibitem[Nayef et~al.(2019)Nayef, Patel, Busta, Chowdhury, Karatzas, Khlif,
  Matas, Pal, Burie, Liu, et~al.]{nayef2019icdar2019}
Nibal Nayef, Yash Patel, Michal Busta, Pinaki~Nath Chowdhury, Dimosthenis
  Karatzas, Wafa Khlif, Jiri Matas, Umapada Pal, Jean-Christophe Burie,
  Cheng-lin Liu, et~al.
\newblock Icdar2019 robust reading challenge on multi-lingual scene text
  detection and recognitionâ€”rrc-mlt-2019.
\newblock In \emph{ICDAR}, pages 1582--1587, 2019.

\bibitem[Karatzas et~al.(2015)Karatzas, Gomez{-}Bigorda, Nicolaou, Ghosh,
  Bagdanov, Iwamura, Matas, Neumann, Chandrasekhar, Lu, Shafait, Uchida, and
  Valveny]{icdar2015}
Dimosthenis Karatzas, Lluis Gomez{-}Bigorda, Anguelos Nicolaou, Suman~K. Ghosh,
  Andrew~D. Bagdanov, Masakazu Iwamura, Jiri Matas, Lukas Neumann,
  Vijay~Ramaseshan Chandrasekhar, Shijian Lu, Faisal Shafait, Seiichi Uchida,
  and Ernest Valveny.
\newblock {ICDAR} 2015 competition on robust reading.
\newblock In \emph{ICDAR}, pages 1156--1160, 2015.

\bibitem[Chng et~al.(2019)Chng, Liu, Sun, Ng, Luo, Ni, Fang, Zhang, Han, Ding,
  et~al.]{Icdarart}
Chee~Kheng Chng, Yuliang Liu, Yipeng Sun, Chun~Chet Ng, Canjie Luo, Zihan Ni,
  ChuanMing Fang, Shuaitao Zhang, Junyu Han, Errui Ding, et~al.
\newblock Icdar2019 robust reading challenge on arbitrary-shaped text-rrc-art.
\newblock In \emph{ICDAR}, pages 1571--1576, 2019.

\bibitem[Singh et~al.(2021)Singh, Pang, Toh, Huang, Galuba, and
  Hassner]{singh2021textocr}
Amanpreet Singh, Guan Pang, Mandy Toh, Jing Huang, Wojciech Galuba, and Tal
  Hassner.
\newblock Textocr: Towards large-scale end-to-end reasoning for
  arbitrary-shaped scene text.
\newblock In \emph{CVPR}, pages 8802--8812, 2021.

\bibitem[Fang et~al.(2021)Fang, Xie, Wang, Mao, and Zhang]{fang2021read}
Shancheng Fang, Hongtao Xie, Yuxin Wang, Zhendong Mao, and Yongdong Zhang.
\newblock Read like humans: Autonomous, bidirectional and iterative language
  modeling for scene text recognition.
\newblock In \emph{CVPR}, pages 7098--7107, 2021.

\bibitem[Isola et~al.(2017)Isola, Zhu, Zhou, and Efros]{pix2pix}
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei~A Efros.
\newblock Image-to-image translation with conditional adversarial networks.
\newblock In \emph{CVPR}, pages 1125--1134, 2017.

\bibitem[Ji et~al.(2023)Ji, Zhang, Wang, Hou, Zhang, Price, and
  Chang]{ji2023improving}
Jiabao Ji, Guanhua Zhang, Zhaowen Wang, Bairu Hou, Zhifei Zhang, Brian Price,
  and Shiyu Chang.
\newblock Improving diffusion models for scene text editing with dual encoders.
\newblock \emph{arXiv preprint arXiv:2304.05568}, 2023.

\bibitem[Yim et~al.(2021)Yim, Kim, Cho, and Park]{yim2021synthtiger}
Moonbin Yim, Yoonsik Kim, Han-Cheol Cho, and Sungrae Park.
\newblock Synthtiger: Synthetic text image generator towards better text
  recognition models.
\newblock In \emph{ICDAR}, pages 109--124, 2021.

\bibitem[Roy et~al.(2020)Roy, Bhattacharya, Ghosh, and Pal]{STEFANN}
Prasun Roy, Saumik Bhattacharya, Subhankar Ghosh, and Umapada Pal.
\newblock Stefann: scene text editor using font adaptive neural network.
\newblock In \emph{CVPR}, pages 13228--13237, 2020.

\bibitem[Huang et~al.(2022)Huang, Fu, Qiao, et~al.]{GenText}
Qirui Huang, Bin Fu, Yu~Qiao, et~al.
\newblock Gentext: Unsupervised artistic text generation via decoupled font and
  texture manipulation.
\newblock \emph{arXiv preprint arXiv:2207.09649}, 2022.

\bibitem[Kong et~al.(2022)Kong, Luo, Ma, Zhu, Zhu, Yuan, and
  Jin]{one_shot_fg_cd}
Yuxin Kong, Canjie Luo, Weihong Ma, Qiyuan Zhu, Shenggao Zhu, Nicholas Yuan,
  and Lianwen Jin.
\newblock Look closer to supervise better: One-shot font generation via
  component-based discriminator.
\newblock In \emph{CVPR}, pages 13482--13491, 2022.

\bibitem[Lee et~al.(2021)Lee, Kim, Kim, Yim, Shin, Lee, and Park]{RewriteNet}
Junyeop Lee, Yoonsik Kim, Seonghyeon Kim, Moonbin Yim, Seung Shin, Gayoung Lee,
  and Sungrae Park.
\newblock Rewritenet: Reliable scene text editing with implicit decomposition
  of text contents and styles.
\newblock \emph{arXiv preprint arXiv:2107.11041}, 2021.

\bibitem[Shimoda et~al.(2021)Shimoda, Haraguchi, Uchida, and
  Yamaguchi]{De-rendering}
Wataru Shimoda, Daichi Haraguchi, Seiichi Uchida, and Kota Yamaguchi.
\newblock De-rendering stylized texts.
\newblock In \emph{ICCV}, pages 1076--1085, 2021.

\bibitem[Yang et~al.(2020)Yang, Huang, and Lin]{Swaptext}
Qiangpeng Yang, Jun Huang, and Wei Lin.
\newblock Swaptext: Image based texts transfer in scenes.
\newblock In \emph{CVPR}, pages 14700--14709, 2020.

\bibitem[Zhan et~al.(2019)Zhan, Zhu, and Lu]{SFGAN}
Fangneng Zhan, Hongyuan Zhu, and Shijian Lu.
\newblock Spatial fusion gan for image synthesis.
\newblock In \emph{CVPR}, pages 3653--3662, 2019.

\bibitem[Bau et~al.(2021)Bau, Andonian, Cui, Park, Jahanian, Oliva, and
  Torralba]{PbW}
David Bau, Alex Andonian, Audrey Cui, YeonHwan Park, Ali Jahanian, Aude Oliva,
  and Antonio Torralba.
\newblock Paint by word.
\newblock \emph{arXiv preprint arXiv:2103.10951}, 2021.

\bibitem[Gal et~al.(2021)Gal, Patashnik, Maron, Chechik, and
  Cohen-Or]{gal2021stylegan}
Rinon Gal, Or~Patashnik, Haggai Maron, Gal Chechik, and Daniel Cohen-Or.
\newblock Stylegan-nada: Clip-guided domain adaptation of image generators.
\newblock \emph{arXiv preprint arXiv:2108.00946}, 2021.

\bibitem[P{\'e}rez et~al.(2003)P{\'e}rez, Gangnet, and Blake]{poisson_ie}
Patrick P{\'e}rez, Michel Gangnet, and Andrew Blake.
\newblock Poisson image editing.
\newblock In \emph{ACM SIGGRAPH}, pages 313--318. 2003.

\bibitem[Saharia et~al.(2022{\natexlab{b}})Saharia, Chan, Chang, Lee, Ho,
  Salimans, Fleet, and Norouzi]{Palette}
Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim
  Salimans, David Fleet, and Mohammad Norouzi.
\newblock Palette: Image-to-image diffusion models.
\newblock In \emph{ACM SIGGRAPH}, pages 1--10, 2022{\natexlab{b}}.

\bibitem[Ruiz et~al.(2023)Ruiz, Li, Jampani, Pritch, Rubinstein, and
  Aberman]{Dreambooth}
Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and
  Kfir Aberman.
\newblock Dreambooth: Fine tuning text-to-image diffusion models for
  subject-driven generation.
\newblock 2023.

\bibitem[Liu et~al.(2022{\natexlab{b}})Liu, Garrette, Saharia, Chan, Roberts,
  Narang, Blok, Mical, Norouzi, and Constant]{liu2022character}
Rosanne Liu, Dan Garrette, Chitwan Saharia, William Chan, Adam Roberts, Sharan
  Narang, Irina Blok, RJ~Mical, Mohammad Norouzi, and Noah Constant.
\newblock Character-aware models improve visual text rendering.
\newblock \emph{arXiv preprint arXiv:2212.10562}, 2022{\natexlab{b}}.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock In \emph{NeurIPS}, volume~33, pages 1877--1901, 2020.

\bibitem[Taylor et~al.(2022)Taylor, Kardas, Cucurull, Scialom, Hartshorn,
  Saravia, Poulton, Kerkez, and Stojnic]{taylor2022galactica}
Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony
  Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic.
\newblock Galactica: A large language model for science.
\newblock \emph{arXiv preprint arXiv:2211.09085}, 2022.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux,
  Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
  Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric
  Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{NAACL-HLT}, 2018.

\bibitem[Xue et~al.(2021)Xue, Constant, Roberts, Kale, Al-Rfou, Siddhant,
  Barua, and Raffel]{xue2020mt5}
Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya
  Siddhant, Aditya Barua, and Colin Raffel.
\newblock mt5: A massively multilingual pre-trained text-to-text transformer.
\newblock In \emph{ACL}, 2021.

\end{thebibliography}
