\begin{thebibliography}{104}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdar et~al.(2021)Abdar, Pourpanah, Hussain, Rezazadegan, Liu, Ghavamzadeh, Fieguth, Cao, Khosravi, Acharya, Makarenkov, and Nahavandi]{Abdar:21}
M.~Abdar, F.~Pourpanah, S.~Hussain, D.~Rezazadegan, L.~Liu, M.~Ghavamzadeh, P.~Fieguth, X.~Cao, A.~Khosravi, U.~R. Acharya, V.~Makarenkov, and S.~Nahavandi.
\newblock A review of uncertainty quantification in deep learning: Techniques, applications and challenges.
\newblock \emph{Information Fusion}, 76:\penalty0 243--297, 2021.

\bibitem[Adler et~al.(2008)Adler, Youmaran, and Lionheart]{Adler:08}
A.~Adler, R.~Youmaran, and W.~R.~B. Lionheart.
\newblock A measure of the information content of {EIT} data.
\newblock \emph{Physiological Measurement}, 29\penalty0 (6):\penalty0 S101--S109, 2008.

\bibitem[Akyildiz and Míguez(2021)]{Akyildiz:21}
\"{O}.~D. Akyildiz and J.~Míguez.
\newblock Convergence rates for optimised adaptive importance samplers.
\newblock \emph{Statistics and Computing}, 31\penalty0 (12), 2021.

\bibitem[Angelo and Fortuin(2021)]{DAngelo:21}
F.~D\textquotesingle Angelo and V.~Fortuin.
\newblock Repulsive deep ensembles are bayesian.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman Vaughan, editors, \emph{Advances in Neural Information Processing Systems}, volume~34, pages 3451--3465. Curran Associates, Inc., 2021.

\bibitem[Antor\'{a}an et~al.(2022)Antor\'{a}an, Janz, Allingham, Daxberger, Barbano, Nalisnick, and Hern\'{a}ndez-Lobato]{Antoran:22}
J.~Antor\'{a}an, D.~Janz, J.~U. Allingham, E.~Daxberger, R.~Barbano, E.~Nalisnick, and J.~M. Hern\'{a}ndez-Lobato.
\newblock Adapting the linearised {Laplace} model evidence for modern deep learning.
\newblock \emph{ArXiv}, 2206.08900, 2022.

\bibitem[Apostolakis(1991)]{Apostolakis:90}
G.~Apostolakis.
\newblock The concept of probability if safety assessments of technological systems.
\newblock \emph{Science}, 250\penalty0 (4986):\penalty0 1359--1364, 1991.

\bibitem[Band et~al.(2022)Band, Rudner, Feng, Filos, Nado, Dusenberry, Jerfel, Tran, and Gal]{Band:22}
N.~Band, T.~G.~J. Rudner, Q.~Feng, A.~Filos, Z.~Nado, M.~W. Dusenberry, G.~Jerfel, D.~Tran, and Y.~Gal.
\newblock Benchmarking bayesian deep learning on diabetic retinopathy detection tasks.
\newblock \emph{ArXiv}, 2211.12717, 2022.

\bibitem[Biggio et~al.(2013)Biggio, Corona, Maiorca, Nelson, {\v{S}}rndi{\'{c}}, Laskov, Giacinto, and Roli]{Biggio:13}
B.~Biggio, I.~Corona, D.~Maiorca, B.~Nelson, N.~{\v{S}}rndi{\'{c}}, P.~Laskov, G.~Giacinto, and F.~Roli.
\newblock Evasion attacks against machine learning at test time.
\newblock In H.~Blockeel, K.~Kersting, S.~Nijssen, and F.~{\v{Z}}elezn{\'y}, editors, \emph{Machine Learning and Knowledge Discovery in Databases}, pages 387--402, Berlin, Heidelberg, 2013. Springer Berlin Heidelberg.

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and Wierstra]{Blundell:15}
C.~Blundell, J.~Cornebise, K.~Kavukcuoglu, and D.~Wierstra.
\newblock Weight uncertainty in neural network.
\newblock In F.~Bach and D.~Blei, editors, \emph{Proceedings of the 32nd International Conference on Machine Learning}, volume~37 of \emph{Proceedings of Machine Learning Research}, pages 1613--1622, 2015.

\bibitem[Bradshaw et~al.(2017)Bradshaw, de~G.~Matthews, and Ghahramani]{Bradshaw:17}
J.~Bradshaw, A.~G. de~G.~Matthews, and Z.~Ghahramani.
\newblock Adversarial examples, uncertainty, and transfer testing robustness in gaussian process hybrid deep networks.
\newblock \emph{ArXiv}, 1707.02476, 2017.

\bibitem[Caldeira and Nord(2020)]{Caldeira:20}
J.~Caldeira and B.~Nord.
\newblock Deeply uncertain: comparing methods of uncertainty quantification in deep learning algorithms.
\newblock \emph{Machine Learning: Science and Technology}, 2\penalty0 (1):\penalty0 015002, 2020.

\bibitem[Capp\'{e} et~al.(2004)Capp\'{e}, Guillin, Marin, and Robert]{Cappe:04}
O.~Capp\'{e}, A.~Guillin, J.-M. Marin, and C.~P. Robert.
\newblock Population {Monte Carlo}.
\newblock \emph{Journal of Computational and Graphical Statistics}, 13\penalty0 (4):\penalty0 907--929, 2004.

\bibitem[Chen et~al.(2014)Chen, Fox, and Guestrin]{Chen:14}
T.~Chen, E.~Fox, and C.~Guestrin.
\newblock Stochastic gradient {Hamiltonian} {Monte Carlo}.
\newblock In \emph{International Conference on Machine Learning}, pages 1683--1691. Proceedings of Machine Learning Research, 2014.

\bibitem[Clanuwat et~al.(2018)Clanuwat, Bober-Irizar, Kitamoto, Lamb, Yamamoto, and Ha]{Clanuwat:18}
T.~Clanuwat, M.~Bober-Irizar, A.~Kitamoto, A.~Lamb, K.~Yamamoto, and D.~Ha.
\newblock Deep learning for classical japanese literature.
\newblock \emph{ArXiv}, 1812.01718, 2018.

\bibitem[Cobb and Jalaian(2021)]{Cobb:21}
A.~D. Cobb and B.~Jalaian.
\newblock Scaling hamiltonian monte carlo inference for bayesian neural networks with symmetric splitting.
\newblock \emph{Uncertainty in Artificial Intelligence}, 2021.

\bibitem[Cohen et~al.(2017)Cohen, Afshar, Tapson, and Schaik]{Cohen:17}
G.~Cohen, S.~Afshar, J.~Tapson, and A.~Van Schaik.
\newblock Emnist: Extending mnist to handwritten letters.
\newblock In \emph{2017 international joint conference on neural networks}. IEEE, 2017.

\bibitem[Cover and Thomas(2006)]{Cover:06}
T.~M. Cover and J.~A. Thomas.
\newblock \emph{Elements of Information Theory}.
\newblock Wiley Series in Telecommunications and Signal Processing. Wiley-Interscience, 2nd edition, 2006.
\newblock ISBN 0471241954.

\bibitem[Daxberger et~al.(2021)Daxberger, Kristiadi, Immer, Eschenhagen, Bauer, and Hennig]{Daxberger:21}
E.~Daxberger, A.~Kristiadi, A.~Immer, R.~Eschenhagen, M.~Bauer, and P.~Hennig.
\newblock Laplace redux-effortless bayesian deep learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 20089--20103, 2021.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{Deng:09}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern recognition}. IEEE, 2009.

\bibitem[Depeweg et~al.(2018)Depeweg, Hern{\'{a}}ndez{-}Lobato, Doshi{-}Velez, and Udluft]{Depeweg:18}
S.~Depeweg, J.~M. Hern{\'{a}}ndez{-}Lobato, F.~Doshi{-}Velez, and S.~Udluft.
\newblock Decomposition of uncertainty in {Bayesian} deep learning for efficient and risk-sensitive learning.
\newblock In \emph{Proceedings of the 35th International Conference on Machine Learning}, volume~80 of \emph{Proceedings of Machine Learning Research}, pages 1192--1201, 2018.

\bibitem[Durasov et~al.(2021)Durasov, Bagautdinov, Baque, and Fua]{Durasov:21}
N.~Durasov, T.~Bagautdinov, P.~Baque, and P.~Fua.
\newblock Masksembles for uncertainty estimation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 13539--13548, 2021.

\bibitem[Elvira et~al.(2015)Elvira, Martino, Luengo, and Bugallo]{Elvira:15}
V.~Elvira, L.~Martino, D.~Luengo, and M.~F. Bugallo.
\newblock Efficient multiple importance sampling estimators.
\newblock \emph{{IEEE} Signal Processing Letters}, 22\penalty0 (10):\penalty0 1757--1761, 2015.

\bibitem[Elvira et~al.(2019)Elvira, Martino, Luengo, and Bugallo]{Elvira:19}
V.~Elvira, L.~Martino, D.~Luengo, and M.~F. Bugallo.
\newblock Generalized multiple importance sampling.
\newblock \emph{Statistical Science}, 34\penalty0 (1), 2019.

\bibitem[Eschenhagen et~al.(2021)Eschenhagen, Daxberger, Hennig, and Kristiadi]{Eschenhagen:21}
R.~Eschenhagen, E.~Daxberger, P.~Hennig, and A.~Kristiadi.
\newblock Mixtures of laplace approximations for improved post-hoc uncertainty in deep learning.
\newblock \emph{arXiv}, 2111.03577, 2021.

\bibitem[Fiacco and McCormick(1990)]{Fiacco:90}
A.~V. Fiacco and G.~P. McCormick.
\newblock \emph{Nonlinear programming: sequential unconstrained minimization techniques}.
\newblock Society for Industrial and Applied Mathematics, 1990.

\bibitem[Filos et~al.(2019)Filos, Farquhar, Gomez, Rudner, Kenton, Smith, Alizadeh, Kroon, and Gal]{Filos:19}
A.~Filos, S.~Farquhar, A.~N. Gomez, T.~G.~J. Rudner, Z.~Kenton, L.~Smith, M.~Alizadeh, A.~De Kroon, and Y.~Gal.
\newblock A systematic comparison of bayesian deep learning robustness in diabetic retinopathy tasks.
\newblock \emph{ArXiv}, 1912.10481, 2019.

\bibitem[Fort et~al.(2019)Fort, Hu, and Lakshminarayanan]{Fort:19}
S.~Fort, H.~Hu, and B.~Lakshminarayanan.
\newblock Deep ensembles: A loss landscape perspective.
\newblock \emph{ArXiv}, 1912.02757, 2019.

\bibitem[Gal(2016)]{Gal:16thesis}
Y.~Gal.
\newblock \emph{Uncertainty in Deep Learning}.
\newblock PhD thesis, Department of Engineering, University of Cambridge, 2016.

\bibitem[Gal and Ghahramani(2016)]{Gal:16}
Y.~Gal and Z.~Ghahramani.
\newblock Dropout as a {Bayesian} approximation: Representing model uncertainty in deep learning.
\newblock In \emph{Proceedings of the 33nd International Conference on Machine Learning}, 2016.

\bibitem[Gawlikowski et~al.(2021)Gawlikowski, Tassi, Ali, Lee, Humt, Feng, Kruspe, Triebel, Jung, Roscher, Shahzad, Yang, Bamler, and Zhu]{Gawlikowski:21}
J.~Gawlikowski, C.~R.~N. Tassi, M.~Ali, J.~Lee, M.~Humt, J.~Feng, A.~Kruspe, R.~Triebel, P.~Jung, R.~Roscher, M.~Shahzad, W.~Yang, R.~Bamler, and X.~X. Zhu.
\newblock A survey of uncertainty in deep neural networks.
\newblock \emph{ArXiv}, 2107.03342, 2021.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville, and Bengio]{Goodfellow:14}
I.~J. Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair, A.~Courville, and Y.~Bengio.
\newblock Generative adversarial nets.
\newblock In Z.~Ghahramani, M.~Welling, C.~Cortes, N.~Lawrence, and K.Q. Weinberger, editors, \emph{Advances in Neural Information Processing Systems}, volume~27. Curran Associates, Inc., 2014.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{Goodfellow:15}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv}, 1412.6572, 2015.

\bibitem[Graves(2011)]{Graves:11}
A.~Graves.
\newblock Practical variational inference for neural networks.
\newblock In J.~Shawe-Taylor, R.~Zemel, P.~Bartlett, F.~Pereira, and K.Q. Weinberger, editors, \emph{Advances in Neural Information Processing Systems}, volume~24. Curran Associates, Inc., 2011.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{Guo:17}
C.~Guo, G.~Pleiss, Y.~Sun, and K.~Q. Weinberger.
\newblock On calibration of modern neural networks.
\newblock In D.~Precup and Y.~W. Teh, editors, \emph{Proceedings of the 34th International Conference on Machine Learning}, volume~70 of \emph{Proceedings of Machine Learning Research}, pages 1321--1330, 2017.

\bibitem[Gustafsson et~al.(2020)Gustafsson, Danelljan, and Sch{\"o}n]{Gustafsson:20}
F.~K. Gustafsson, M.~Danelljan, and T.~B. Sch{\"o}n.
\newblock Evaluating scalable bayesian deep learning methods for robust computer vision.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops}, June 2020.

\bibitem[Hale(2001)]{Hale:01}
J.~Hale.
\newblock A probabilistic earley parser as a psycholinguistic model.
\newblock In \emph{Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics}, pages 1--8. Association for Computational Linguistics, 2001.

\bibitem[Helton(1993)]{Helton:93}
J.~C. Helton.
\newblock Risk, uncertainty in risk, and the {EPA} release limits for radioactive waste disposal.
\newblock \emph{Nuclear Technology}, 101\penalty0 (1):\penalty0 18--39, 1993.

\bibitem[Helton(1997)]{Helton:97}
J.~C. Helton.
\newblock Uncertainty and sensitivity analysis in the presence of stochastic and subjective uncertainty.
\newblock \emph{Journal of Statistical Computation and Simulation}, 57\penalty0 (1-4):\penalty0 3--76, 1997.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Zhao, Basart, Steinhardt, and Song]{Hendrycks:21}
D.~Hendrycks, K.~Zhao, S.~Basart, J.~Steinhardt, and D.~Song.
\newblock Natural adversarial examples.
\newblock \emph{IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021.

\bibitem[Hesterberg(1995)]{Hesterberg:95}
T.~Hesterberg.
\newblock Weighted average importance sampling and defensive mixture distributions.
\newblock \emph{Technometrics}, 37\penalty0 (2):\penalty0 185--194, 1995.

\bibitem[Hesterberg(1996)]{Hesterberg:96}
T.~Hesterberg.
\newblock Estimates and confidence intervals for importance sampling sensitivity analysis.
\newblock \emph{Mathematical and Computer Modelling}, 23\penalty0 (8):\penalty0 79--85, 1996.

\bibitem[Houlsby et~al.(2011)Houlsby, Huszar, Ghahramani, and Lengyel]{Houlsby:11}
N.~Houlsby, F.~Huszar, Z.~Ghahramani, and M.~Lengyel.
\newblock Bayesian active learning for classification and preference learning.
\newblock \emph{ArXiv}, 1112.5745, 2011.

\bibitem[Houlsby et~al.(2019)Houlsby, Giurgiu, Jastrzebski, Morrone, Laroussilhe, Gesmundo, Attariyan, and Gelly]{Houlsby:19}
N.~Houlsby, A.~Giurgiu, S.~Jastrzebski, B.~Morrone, Q.~De Laroussilhe, A.~Gesmundo, M.~Attariyan, and S.~Gelly.
\newblock Parameter-efficient transfer learning for nlp.
\newblock In \emph{International Conference on Machine Learning}. Proceedings of Machine Learning Research, 2019.

\bibitem[Hu et~al.(2021)Hu, Shen, Wallis, Allen-Zhu, Li, Wang, Wang, and Chen]{Hu:21}
E.~J. Hu, Y.~Shen, P.~Wallis, Z.~Allen-Zhu, Y.~Li, S.~Wang, L.~Wang, and W.~Chen.
\newblock Lora: Low-rank adaptation of large language models.
\newblock \emph{ArXiv}, 2106.09685, 2021.

\bibitem[Huang et~al.(2017)Huang, Li, Pleiss, Liu, Hopcroft, and Weinberger]{Huang:17}
G.~Huang, Y.~Li, G.~Pleiss, Z.~Liu, J.~E. Hopcroft, and K.~Q. Weinberger.
\newblock Snapshot ensembles: Train 1, get m for free.
\newblock \emph{ArXiv}, 1704.00109, 2017.

\bibitem[H\"{u}llermeier and Waegeman(2021)]{Huellermeier:21}
E.~H\"{u}llermeier and W.~Waegeman.
\newblock Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods.
\newblock \emph{Machine Learning}, 3\penalty0 (110):\penalty0 457--506, 2021.

\bibitem[Izmailov et~al.(2021)Izmailov, Vikram, Hoffman, and Wilson]{Izmailov:21}
P.~Izmailov, S.~Vikram, M.~D. Hoffman, and A.~G. Wilson.
\newblock What are {Bayesian} neural network posteriors really like?
\newblock In \emph{Proceedings of the 38th International Conference on Machine Learning}, pages 4629--4640, 2021.

\bibitem[Jaynes(1957)]{Jaynes:57}
E.~T. Jaynes.
\newblock Information theory and statistical mechanics.
\newblock \emph{Phys. Rev.}, 106:\penalty0 620--630, 1957.

\bibitem[Kapoor(2023)]{Kapoor:23}
S.~Kapoor.
\newblock torch-sgld: Sgld as pytorch optimizer.
\newblock \url{https://pypi.org/project/torch-sgld/}, 2023.
\newblock Accessed: 12-05-2023.

\bibitem[Karush(1939)]{Karush:39}
W.~Karush.
\newblock Minima of functions of several variables with inequalities as side conditions.
\newblock Master's thesis, University of Chicago, 1939.

\bibitem[Kendall and Gal(2017)]{Kendall:17}
A.~Kendall and Y.~Gal.
\newblock What uncertainties do we need in {Bayesian} deep learning for computer vision?
\newblock In \emph{Advances in Neural Information Processing Systems}, volume~30, 2017.

\bibitem[Kingma and Ba(2014)]{Kingma:14b}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{ArXiv}, 1412.6980, 2014.

\bibitem[Kingma and Welling(2014)]{Kingma:14}
D.~P. Kingma and M.~Welling.
\newblock Auto-encoding variational {Bayes}.
\newblock In \emph{2nd International Conference on Learning Representations}, 2014.

\bibitem[Kirichenko et~al.(2022)Kirichenko, Izmailov, and Wilson]{Kirichenko:22}
P.~Kirichenko, P.~Izmailov, and A.~G. Wilson.
\newblock Last layer re-training is sufficient for robustness to spurious correlations.
\newblock \emph{ArXiv}, 2204.02937, 2022.

\bibitem[Kuhn and Tucker(1950)]{Kuhn:50}
H.~W. Kuhn and A.~W. Tucker.
\newblock Nonlinear programming.
\newblock In J.~Neyman, editor, \emph{Second Berkeley Symposium on Mathematical Statistics and Probability}, pages 481--492, Berkeley, 1950. University of California Press.

\bibitem[Kviman et~al.(2022)Kviman, Melin, Koptagel, Elvira, and Lagergren]{Kviman:22}
O.~Kviman, H.~Melin, H.~Koptagel, V.~Elvira, and J.~Lagergren.
\newblock Multiple importance sampling {ELBO }and deep ensembles of variational approximations.
\newblock In \emph{Proceedings of the 25th International Conference on Artificial Intelligence and Statistics}, volume 151 of \emph{Proceedings of Machine Learning Research}, pages 10687--10702, 2022.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and Tenenbaum]{Lake:15}
B.~M. Lake, R.~Salakhutdinov, and J.~B. Tenenbaum.
\newblock Human-level concept learning through probabilistic program induction.
\newblock \emph{Science}, 2015.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and Blundell]{Lakshminarayanan:17}
B.~Lakshminarayanan, A.~Pritzel, and C.~Blundell.
\newblock Simple and scalable predictive uncertainty estimation using deep ensembles.
\newblock In \emph{Proceedings of the 31st International Conference on Neural Information Processing Systems}, page 6405–6416. Curran Associates Inc., 2017.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and Haffner]{LeCun:98}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0 2278--2324, 1998.

\bibitem[Li et~al.(2016)Li, Chen, Carlson, and Carin]{Li:16}
C.~Li, C.~Chen, D.~Carlson, and L.~Carin.
\newblock Preconditioned stochastic gradient {Langevin} dynamics for deep neural networks.
\newblock In \emph{Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI)}, page 1788–1794. AAAI Press, 2016.

\bibitem[Liu et~al.(2020)Liu, Lin, Padhy, Tran, Weiss, and Lakshminarayanan]{Liu:20}
J.~Liu, Z.~Lin, S.~Padhy, D.~Tran, T.~Bedrax Weiss, and B.~Lakshminarayanan.
\newblock Simple and principled uncertainty estimation with deterministic deep learning via distance awareness.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 7498--7512, 2020.

\bibitem[Lubana et~al.(2022)Lubana, Bigelow, Dick, Krueger, and Tanaka]{Lubana:22}
E.~S. Lubana, E.~J. Bigelow, R.~P. Dick, D.~Krueger, and H.~Tanaka.
\newblock Mechanistic mode connectivity.
\newblock \emph{ArXiv}, 2211.08422, 2022.

\bibitem[Luenberger and Ye(2016)]{Luenberger:16}
D.~G. Luenberger and Y.~Ye.
\newblock \emph{Linear and nonlinear programming}.
\newblock International Series in Operations Research and Management Science. Springer, 2016.

\bibitem[MacKay(1992)]{MacKay:92b}
D.~J.~C. MacKay.
\newblock A practical {Bayesian} framework for backprop networks.
\newblock \emph{Neural Computation}, 4:\penalty0 448--472, 1992.

\bibitem[Maddox et~al.(2019)Maddox, Izmailov, Garipov, Vetrov, and Wilson]{Maddox:19}
W.~J. Maddox, P.~Izmailov, T.~Garipov, D.~P. Vetrov, and A.~G. Wilson.
\newblock A simple baseline for {Bayesian} uncertainty in deep learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Malinin and Gales(2018)]{Malinin:18}
A.~Malinin and M.~Gales.
\newblock Predictive uncertainty estimation via prior networks.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[May(2020)]{May:20}
R.~May.
\newblock A simple proof of the {Karush-Kuhn-Tucker} theorem with finite number of equality and inequality constraints.
\newblock \emph{ArXiv}, 2007.12483, 2020.

\bibitem[McKone(1994)]{McKone:94}
T.~E. McKone.
\newblock Uncertainty and variability in human exposures to soil contaminants through home-grown food: A monte carlo assessment.
\newblock \emph{Risk Analysis}, 14, 1994.

\bibitem[Mobiny et~al.(2021)Mobiny, Yuan, Moulik, Garg, Wu, and VanNguyen]{Mobiny:21}
A.~Mobiny, P.~Yuan, S.~K. Moulik, N.~Garg, C.~C. Wu, and H.~VanNguyen.
\newblock {DropConnect} is effective in modeling uncertainty of {Bayesian} deep networks.
\newblock \emph{Scientific Reports}, 11:\penalty0 5458, 2021.

\bibitem[Mukhoti et~al.(2021)Mukhoti, Kirsch, vanAmersfoort, Torr, and Gal]{Mukhoti:21}
J.~Mukhoti, A.~Kirsch, J.~vanAmersfoort, P.~H.~S. Torr, and Y.~Gal.
\newblock Deep deterministic uncertainty: A simple baseline.
\newblock \emph{ArXiv}, 2102.11582, 2021.

\bibitem[Neal(1996)]{Neal:96}
R.~Neal.
\newblock \emph{Bayesian Learning for Neural Networks}.
\newblock Springer Verlag, New York, 1996.

\bibitem[Oleksiienko et~al.(2022)Oleksiienko, Tran, and Iosifidis]{Oleksiienko:22}
I.~Oleksiienko, D.~T. Tran, and A.~Iosifidis.
\newblock Variational neural networks.
\newblock \emph{ArXiv}, 2207.01524, 2022.

\bibitem[Osband et~al.(2021)Osband, Wen, Asghari, Dwaracherla, Ibrahimi, Lu, and VanRoy]{Osband:21}
I.~Osband, Z.~Wen, S.~M. Asghari, V.~Dwaracherla, M.~Ibrahimi, X.~Lu, and B.~VanRoy.
\newblock Weight uncertainty in neural networks.
\newblock \emph{ArXiv}, 2107.08924, 2021.

\bibitem[Ovadia et~al.(2019)Ovadia, Fertig, Ren, Nado, Sculley, Nowozin, Dillon, Lakshminarayanan, and Snoek]{Ovadia:19}
Y.~Ovadia, E.~Fertig, J.~Ren, Z.~Nado, D.~Sculley, S.~Nowozin, J.~Dillon, B.~Lakshminarayanan, and J.~Snoek.
\newblock Can you trust your model's uncertainty? evaluating predictive uncertainty under dataset shift.
\newblock In \emph{Advances in Neural Information Processing Systems}, volume~32, 2019.

\bibitem[Owen and Zhou(2000)]{Owen:00}
A.~Owen and Y.~Zhou.
\newblock Safe and effective importance sampling.
\newblock \emph{Journal of the American Statistical Association}, 95\penalty0 (449):\penalty0 135--143, 2000.

\bibitem[Parker-Holder et~al.(2020)Parker-Holder, Metz, Resnick, Hu, Lerer, Letcher, Peysakhovich, Pacchiano, and Foerster]{ParkerHolder:20}
J.~Parker-Holder, L.~Metz, C.~Resnick, H.~Hu, A.~Lerer, A.~Letcher, A.~Peysakhovich, A.~Pacchiano, and J.~Foerster.
\newblock Ridge rider: Finding diverse solutions by following eigenvectors of the hessian.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin, editors, \emph{Advances in Neural Information Processing Systems}, volume~33, pages 753--765. Curran Associates, Inc., 2020.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan, Killeen, Lin, Gimelshein, Antiga, et~al.]{Paszke:19}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen, Z.~Lin, N.~Gimelshein, L.~Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, et~al.]{Pedregosa:11}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel, M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, et~al.
\newblock Scikit-learn: Machine learning in python.
\newblock \emph{The Journal of Machine Learning Research}, 12:\penalty0 2825--2830, 2011.

\bibitem[Postels et~al.(2021)Postels, Segu, Sun, Gool, Yu, and Tombari]{Postels:21}
J.~Postels, M.~Segu, T.~Sun, L.~Van Gool, F.~Yu, and F.~Tombari.
\newblock On the practicality of deterministic epistemic uncertainty.
\newblock \emph{ArXiv}, 2107.00649, 2021.

\bibitem[Raftery and Bao(2010)]{Raftery:10}
A.~E. Raftery and L.~Bao.
\newblock Estimating and projecting trends in {HIV/AIDS} generalized epidemics using incremental mixture importance sampling.
\newblock \emph{Biometrics}, 66, 2010.

\bibitem[Rigter et~al.(2022)Rigter, Lacerda, and Hawes]{Rigter:22}
M.~Rigter, B.~Lacerda, and N.~Hawes.
\newblock Rambo-rl: Robust adversarial model-based offline reinforcement learning.
\newblock In S.~Koyejo, S.~Mohamed, A.~Agarwal, D.~Belgrave, K.~Cho, and A.~Oh, editors, \emph{Advances in Neural Information Processing Systems}, volume~35, pages 16082--16097. Curran Associates, Inc., 2022.

\bibitem[Scimeca et~al.(2022)Scimeca, Oh, Chun, Poli, and Yun]{Scimeca:21}
L.~Scimeca, S.~J. Oh, S.~Chun, M.~Poli, and S.~Yun.
\newblock Which shortcut cues will dnns choose? a study from the parameter-space perspective.
\newblock \emph{arXiv}, 2110.03095, 2022.

\bibitem[Seidenfeld(1986)]{Seidenfeld:86}
T.~Seidenfeld.
\newblock Entropy and uncertainty.
\newblock \emph{Philosophy of Science}, 53\penalty0 (4):\penalty0 467--491, 1986.

\bibitem[Shah et~al.(2020)Shah, Tamuly, Raghunathan, Jain, and Netrapalli]{Shah:20}
H.~Shah, K.~Tamuly, A.~Raghunathan, P.~Jain, and P.~Netrapalli.
\newblock The pitfalls of simplicity bias in neural networks.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin, editors, \emph{Advances in Neural Information Processing Systems}, volume~33, pages 9573--9585. Curran Associates, Inc., 2020.

\bibitem[Shannon and Elwood(1948)]{Shannon:48}
C.~E. Shannon and C.~Elwood.
\newblock A mathematical theory of communication.
\newblock \emph{The Bell System Technical Journal}, 27:\penalty0 379--423, 1948.

\bibitem[Smith and Gal(2018)]{Smith:18}
L.~Smith and Y.~Gal.
\newblock Understanding measures of uncertainty for adversarial example detection.
\newblock In A.~Globerson and R.~Silva, editors, \emph{Proceedings of the Thirty-Fourth Conference on Uncertainty in Artificial Intelligence}, pages 560--569. AUAI Press, 2018.

\bibitem[Steele et~al.(2006)Steele, Raftery, and Emond]{Steele:06}
R.~J. Steele, A.~E. Raftery, and M.~J. Emond.
\newblock Computing normalizing constants for finite mixture models via incremental mixture importance sampling {(IMIS)}.
\newblock \emph{Journal of Computational and Graphical Statistics}, 15, 2006.

\bibitem[Sundararajan et~al.(2017)Sundararajan, Taly, and Yan]{Sundararajan:17}
M.~Sundararajan, A.~Taly, and Q.~Yan.
\newblock Axiomatic attribution for deep networks.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan, Goodfellow, and Fergus]{Szegedy:13}
C.~Szegedy, W.~Zaremba, I.~Sutskever, J.~Bruna, D.~Erhan, I.~J. Goodfellow, and R.~Fergus.
\newblock Intriguing properties of neural networks.
\newblock \emph{ArXiv}, 1312.6199, 2013.

\bibitem[Tan and Le(2019)]{Tan:19}
M.~Tan and Q.~Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural networks.
\newblock In \emph{International conference on machine learning}, pages 6105--6114. Proceedings of Machine Learning Research, 2019.

\bibitem[Tribus(1961)]{Tribus:61}
M.~Tribus.
\newblock \emph{Thermostatics and Thermodynamics: An Introduction to Energy, Information and States of Matter, with Engineering Applications}.
\newblock University series in basic engineering. Van Nostrand, 1961.

\bibitem[van Amersfoort et~al.(2020)van Amersfoort, Smith, Teh, and Gal]{vAmersfoort:20}
J.~van Amersfoort, L.~Smith, Y.~W. Teh, and Y.~Gal.
\newblock Uncertainty estimation using a single deep deterministic neural network.
\newblock In \emph{International Conference on Machine Learning}, pages 9690--9700. Proceedings of Machine Learning Research, 2020.

\bibitem[van Amersfoort et~al.(2021)van Amersfoort, Smith, Jesson, Key, and Gal]{vAmersfoort:21}
J.~van Amersfoort, L.~Smith, A.~Jesson, O.~Key, and Y.~Gal.
\newblock On feature collapse and deep kernel learning for single forward pass uncertainty.
\newblock \emph{ArXiv}, 2102.11409, 2021.

\bibitem[Veach and Guibas(1995)]{Veach:95}
E.~Veach and L.~J. Guibas.
\newblock Optimally combining sampling techniques for {Monte Carlo} rendering.
\newblock In \emph{Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques}, pages 419--428. Association for Computing Machinery, 1995.

\bibitem[Vesely and Rasmuson(1984)]{Vesely:84}
W.~E. Vesely and D.~M. Rasmuson.
\newblock Uncertainties in nuclear probabilistic risk analyses.
\newblock \emph{Risk Analysis}, 4, 1984.

\bibitem[Weinzierl(2000)]{Weinzierl:00}
S.~Weinzierl.
\newblock Introduction to {Monte Carlo} methods.
\newblock \emph{ArXiv}, hep-ph/0006269, 2000.

\bibitem[Welling and Teh(2011)]{Welling:11}
M.~Welling and Y.~W. Teh.
\newblock Bayesian learning via stochastic gradient {Langevin} dynamics.
\newblock In \emph{Proceedings of the 28th International Conference on Machine Learning}, page 681–688, Madison, WI, USA, 2011. Omnipress.

\bibitem[Wilson and Izmailov(2020)]{Wilson:20}
A.~G. Wilson and P.~Izmailov.
\newblock Bayesian deep learning and a probabilistic perspective of generalization.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 4697--4708, 2020.

\bibitem[Wursthorn et~al.(2022)Wursthorn, Hillemann, and M.~Ulrich]{Wursthorn:22}
K.~Wursthorn, M.~Hillemann, and M.~M.~Ulrich.
\newblock Comparison of uncertainty quantification methods for {CNN}-based regression.
\newblock \emph{The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences}, XLIII-B2-2022:\penalty0 721--728, 2022.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{Xiao:17}
H.~Xiao, K.~Rasul, and R.~Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.
\newblock \emph{ArXiv}, 1708.07747, 2017.

\bibitem[Zangwill(1967)]{Zangwill:67}
W.~I. Zangwill.
\newblock Non-linear programming via penalty functions.
\newblock \emph{Management Science}, 13\penalty0 (5):\penalty0 344--358, 1967.

\bibitem[Zhang et~al.(2020)Zhang, Li, Zhang, Chen, and Wilson]{Zhang:20}
R.~Zhang, C.~Li, J.~Zhang, C.~Chen, and A.~G. Wilson.
\newblock Cyclical stochastic gradient {MCMC} for {Bayesian} deep learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Zhang et~al.(2022)Zhang, Wilson, and DeSa]{Zhang:22}
R.~Zhang, A.~G. Wilson, and C.~DeSa.
\newblock Low-precision stochastic gradient {Langevin} dynamics.
\newblock \emph{ArXiv}, 2206.09909, 2022.

\bibitem[Zidek and vanEeden(2003)]{Zidek:03}
J.~V. Zidek and C.~vanEeden.
\newblock Uncertainty, entropy, variance and the effect of partial information.
\newblock \emph{Lecture Notes-Monograph Series}, 42:\penalty0 155–167, 2003.

\end{thebibliography}
