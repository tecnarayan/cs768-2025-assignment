\begin{thebibliography}{79}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aamand et~al.(2019)Aamand, Indyk, and Vakilian]{aamand2019learned}
Aamand, A., Indyk, P., and Vakilian, A.
\newblock (learned) frequency estimation algorithms under zipfian distribution.
\newblock \emph{arXiv preprint arXiv:1908.05198}, 2019.

\bibitem[Aeron et~al.(2010)Aeron, Saligrama, and Zhao]{aeron2010information}
Aeron, S., Saligrama, V., and Zhao, M.
\newblock Information theoretic bounds for compressed sensing.
\newblock \emph{IEEE Transactions on Information Theory}, 56\penalty0
  (10):\penalty0 5111--5130, 2010.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
Arjovsky, M., Chintala, S., and Bottou, L.
\newblock Wasserstein gan.
\newblock \emph{arXiv preprint arXiv:1701.07875}, 2017.

\bibitem[Asim et~al.(2018)Asim, Shamshad, and Ahmed]{asim2018blind}
Asim, M., Shamshad, F., and Ahmed, A.
\newblock Blind image deconvolution using deep generative priors.
\newblock \emph{arXiv preprint arXiv:1802.04073}, 2018.

\bibitem[Asim et~al.(2019)Asim, Ahmed, and Hand]{asim2019invertible}
Asim, M., Ahmed, A., and Hand, P.
\newblock Invertible generative models for inverse problems: mitigating
  representation error and dataset bias.
\newblock \emph{arXiv preprint arXiv:1905.11672}, 2019.

\bibitem[Aubin et~al.(2019)Aubin, Loureiro, Baker, Krzakala, and
  Zdeborov{\'a}]{aubin2019exact}
Aubin, B., Loureiro, B., Baker, A., Krzakala, F., and Zdeborov{\'a}, L.
\newblock Exact asymptotics for phase retrieval and compressed sensing with
  random generative priors.
\newblock \emph{arXiv preprint arXiv:1912.02008}, 2019.

\bibitem[Baraniuk \& Wakin(2009)Baraniuk and Wakin]{baraniuk2009random}
Baraniuk, R.~G. and Wakin, M.~B.
\newblock Random projections of smooth manifolds.
\newblock \emph{Foundations of computational mathematics}, 9\penalty0
  (1):\penalty0 51--77, 2009.

\bibitem[Baraniuk et~al.(2010)Baraniuk, Cevher, Duarte, and
  Hegde]{baraniuk2010model}
Baraniuk, R.~G., Cevher, V., Duarte, M.~F., and Hegde, C.
\newblock Model-based compressive sensing.
\newblock \emph{IEEE Transactions on Information Theory}, 56\penalty0
  (4):\penalty0 1982--2001, 2010.

\bibitem[Barbier et~al.(2019)Barbier, Krzakala, Macris, Miolane, and
  Zdeborov{\'a}]{barbier2019optimal}
Barbier, J., Krzakala, F., Macris, N., Miolane, L., and Zdeborov{\'a}, L.
\newblock Optimal errors and phase transitions in high-dimensional generalized
  linear models.
\newblock \emph{Proceedings of the National Academy of Sciences}, 116\penalty0
  (12):\penalty0 5451--5460, 2019.

\bibitem[Bickel et~al.(2009)Bickel, Ritov, and
  Tsybakov]{bickel2009simultaneous}
Bickel, P.~J., Ritov, Y., and Tsybakov, A.~B.
\newblock Simultaneous analysis of lasso and dantzig selector.
\newblock \emph{The Annals of Statistics}, 37\penalty0 (4):\penalty0
  1705--1732, 2009.

\bibitem[Bora et~al.(2017)Bora, Jalal, Price, and Dimakis]{bora2017compressed}
Bora, A., Jalal, A., Price, E., and Dimakis, A.~G.
\newblock Compressed sensing using generative models.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  537--546. JMLR. org, 2017.

\bibitem[Candes(2008)]{candes2008restricted}
Candes, E.~J.
\newblock The restricted isometry property and its implications for compressed
  sensing.
\newblock \emph{Comptes rendus mathematique}, 346\penalty0 (9-10):\penalty0
  589--592, 2008.

\bibitem[Candes \& Davenport(2013)Candes and Davenport]{candes2013well}
Candes, E.~J. and Davenport, M.~A.
\newblock How well can we estimate a sparse vector?
\newblock \emph{Applied and Computational Harmonic Analysis}, 34\penalty0
  (2):\penalty0 317--323, 2013.

\bibitem[Candes et~al.(2006)Candes, Romberg, and Tao]{candes2006stable}
Candes, E.~J., Romberg, J.~K., and Tao, T.
\newblock Stable signal recovery from incomplete and inaccurate measurements.
\newblock \emph{Communications on Pure and Applied Mathematics: A Journal
  Issued by the Courant Institute of Mathematical Sciences}, 59\penalty0
  (8):\penalty0 1207--1223, 2006.

\bibitem[Champion et~al.(2008)Champion, De~Pascale, and
  Juutinen]{champion2008wasserstein}
Champion, T., De~Pascale, L., and Juutinen, P.
\newblock The $\infty$-{W}asserstein distance: Local solutions and existence of
  optimal transport maps.
\newblock \emph{SIAM Journal on Mathematical Analysis}, 40\penalty0
  (1):\penalty0 1--20, 2008.

\bibitem[Chen \& Huang(2012)Chen and Huang]{chen12}
Chen, C. and Huang, J.
\newblock Compressive sensing mri with wavelet tree sparsity.
\newblock In Pereira, F., Burges, C. J.~C., Bottou, L., and Weinberger, K.~Q.
  (eds.), \emph{Advances in Neural Information Processing Systems 25}, pp.\
  1115--1123. Curran Associates, Inc., 2012.

\bibitem[Chen et~al.(2010)Chen, Silva, Paisley, Wang, Dunson, and
  Carin]{chen2010compressive}
Chen, M., Silva, J., Paisley, J., Wang, C., Dunson, D., and Carin, L.
\newblock Compressive sensing on manifolds using a nonparametric mixture of
  factor analyzers: Algorithm and performance bounds.
\newblock \emph{IEEE Transactions on Signal Processing}, 58\penalty0
  (12):\penalty0 6140--6155, 2010.

\bibitem[Cover \& Thomas(2012)Cover and Thomas]{cover2012elements}
Cover, T.~M. and Thomas, J.~A.
\newblock \emph{Elements of information theory}.
\newblock John Wiley \& Sons, 2012.

\bibitem[Dhar et~al.(2018)Dhar, Grover, and Ermon]{dhar2018modeling}
Dhar, M., Grover, A., and Ermon, S.
\newblock Modeling sparse deviations for compressed sensing using generative
  models.
\newblock \emph{arXiv preprint arXiv:1807.01442}, 2018.

\bibitem[Donoho(2006)]{donoho2006compressed}
Donoho, D.~L.
\newblock Compressed sensing.
\newblock \emph{IEEE Transactions on information theory}, 52\penalty0
  (4):\penalty0 1289--1306, 2006.

\bibitem[Duarte et~al.(2008)Duarte, Davenport, Takhar, Laska, Sun, Kelly, and
  Baraniuk]{duarte2008single}
Duarte, M.~F., Davenport, M.~A., Takhar, D., Laska, J.~N., Sun, T., Kelly,
  K.~F., and Baraniuk, R.~G.
\newblock Single-pixel imaging via compressive sampling.
\newblock \emph{IEEE signal processing magazine}, 25\penalty0 (2):\penalty0
  83--91, 2008.

\bibitem[Eldar \& Mishali(2009)Eldar and Mishali]{eldar2009robust}
Eldar, Y.~C. and Mishali, M.
\newblock Robust recovery of signals from a structured union of subspaces.
\newblock \emph{IEEE Transactions on Information Theory}, 55\penalty0
  (11):\penalty0 5302--5316, 2009.

\bibitem[Fletcher et~al.(2018{\natexlab{a}})Fletcher, Pandit, Rangan, Sarkar,
  and Schniter]{fletcher2018plug}
Fletcher, A.~K., Pandit, P., Rangan, S., Sarkar, S., and Schniter, P.
\newblock Plug-in estimation in high-dimensional linear inverse problems: A
  rigorous analysis.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  7440--7449, 2018{\natexlab{a}}.

\bibitem[Fletcher et~al.(2018{\natexlab{b}})Fletcher, Rangan, and
  Schniter]{fletcher2018inference}
Fletcher, A.~K., Rangan, S., and Schniter, P.
\newblock Inference in deep networks in high dimensions.
\newblock In \emph{2018 IEEE International Symposium on Information Theory
  (ISIT)}, pp.\  1884--1888. IEEE, 2018{\natexlab{b}}.

\bibitem[G{\'o}mez et~al.(2019)G{\'o}mez, Eftekhari, and Cevher]{gomez2019fast}
G{\'o}mez, F.~L., Eftekhari, A., and Cevher, V.
\newblock Fast and provable admm for learning with generative priors.
\newblock \emph{arXiv preprint arXiv:1907.03343}, 2019.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2672--2680, 2014.

\bibitem[Hand \& Joshi(2019)Hand and Joshi]{hand2019global}
Hand, P. and Joshi, B.
\newblock Global guarantees for blind demodulation with generative priors.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  11531--11541, 2019.

\bibitem[Hand \& Voroninski(2017)Hand and Voroninski]{hand2017global}
Hand, P. and Voroninski, V.
\newblock Global guarantees for enforcing deep generative priors by empirical
  risk.
\newblock \emph{arXiv preprint arXiv:1705.07576}, 2017.

\bibitem[Hand et~al.(2018)Hand, Leong, and Voroninski]{hand2018phase}
Hand, P., Leong, O., and Voroninski, V.
\newblock Phase retrieval under a generative prior.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  9136--9146, 2018.

\bibitem[Heckel \& Hand(2018)Heckel and Hand]{heckel2018deep}
Heckel, R. and Hand, P.
\newblock Deep decoder: Concise image representations from untrained
  non-convolutional networks.
\newblock \emph{arXiv preprint arXiv:1810.03982}, 2018.

\bibitem[Heckel \& Soltanolkotabi(2020)Heckel and
  Soltanolkotabi]{heckel2020compressive}
Heckel, R. and Soltanolkotabi, M.
\newblock Compressive sensing with un-trained neural networks: Gradient descent
  finds the smoothest approximation.
\newblock \emph{arXiv preprint arXiv:2005.03991}, 2020.

\bibitem[Hegde(2018)]{hegde2018algorithmic}
Hegde, C.
\newblock Algorithmic aspects of inverse problems using generative models.
\newblock In \emph{2018 56th Annual Allerton Conference on Communication,
  Control, and Computing (Allerton)}, pp.\  166--172. IEEE, 2018.

\bibitem[Hegde et~al.(2008)Hegde, Wakin, and Baraniuk]{hegde2008random}
Hegde, C., Wakin, M., and Baraniuk, R.~G.
\newblock Random projections for manifold learning.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  641--648, 2008.

\bibitem[Hegde et~al.(2009)Hegde, Duarte, and Cevher]{hegde2009compressive}
Hegde, C., Duarte, M.~F., and Cevher, V.
\newblock Compressive sensing recovery of spike trains using a structured
  sparsity model.
\newblock In \emph{SPARS'09-Signal Processing with Adaptive Sparse Structured
  Representations}, 2009.

\bibitem[Hsu et~al.(2018)Hsu, Indyk, Katabi, and Vakilian]{hsu2018learning}
Hsu, C.-Y., Indyk, P., Katabi, D., and Vakilian, A.
\newblock Learning-based frequency estimation algorithms.
\newblock 2018.

\bibitem[Indyk et~al.(2019)Indyk, Vakilian, and Yuan]{indyk2019learning}
Indyk, P., Vakilian, A., and Yuan, Y.
\newblock Learning-based low-rank approximations.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  7400--7410, 2019.

\bibitem[Iwen \& Tewfik(2010)Iwen and Tewfik]{iwen2010adaptive}
Iwen, M. and Tewfik, A.
\newblock Adaptive group testing strategies for target detection and
  localization in noisy environments.
\newblock 2010.

\bibitem[Jagatap \& Hegde(2019)Jagatap and Hegde]{jagatap2019phase}
Jagatap, G. and Hegde, C.
\newblock Phase retrieval using untrained neural network priors.
\newblock 2019.

\bibitem[Jalal et~al.(2020)Jalal, Liu, Dimakis, and Caramanis]{jalal2020robust}
Jalal, A., Liu, L., Dimakis, A.~G., and Caramanis, C.
\newblock Robust compressed sensing using generative models.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Jalali \& Yuan(2019)Jalali and Yuan]{jalali2019solving}
Jalali, S. and Yuan, X.
\newblock Solving linear inverse problems using generative models.
\newblock In \emph{2019 IEEE International Symposium on Information Theory
  (ISIT)}, pp.\  512--516. IEEE, 2019.

\bibitem[Kabkab et~al.(2018)Kabkab, Samangouei, and Chellappa]{kabkab2018task}
Kabkab, M., Samangouei, P., and Chellappa, R.
\newblock Task-aware compressed sensing with generative adversarial networks.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Kamath et~al.(2019)Kamath, Karmalkar, and Price]{kamath2019lower}
Kamath, A., Karmalkar, S., and Price, E.
\newblock Lower bounds for compressed sensing with generative models.
\newblock \emph{arXiv preprint arXiv:1912.02938}, 2019.

\bibitem[Karras et~al.(2017)Karras, Aila, Laine, and
  Lehtinen]{karras2017progressive}
Karras, T., Aila, T., Laine, S., and Lehtinen, J.
\newblock Progressive growing of gans for improved quality, stability, and
  variation.
\newblock \emph{arXiv preprint arXiv:1710.10196}, 2017.

\bibitem[Karras et~al.(2019)Karras, Laine, and Aila]{karras2019style}
Karras, T., Laine, S., and Aila, T.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  4401--4410, 2019.

\bibitem[Kingma \& Dhariwal(2018)Kingma and Dhariwal]{kingma2018glow}
Kingma, D.~P. and Dhariwal, P.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  10215--10224, 2018.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{kingma2013auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Lei et~al.(2019)Lei, Jalal, Dhillon, and Dimakis]{lei2019inverting}
Lei, Q., Jalal, A., Dhillon, I.~S., and Dimakis, A.~G.
\newblock Inverting deep generative models, one layer at a time.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  13910--13919, 2019.

\bibitem[Lindgren et~al.(2020)Lindgren, Whang, and
  Dimakis]{lindgren2020conditional}
Lindgren, E.~M., Whang, J., and Dimakis, A.~G.
\newblock Conditional sampling from invertible generative models with
  applications to inverse problems.
\newblock \emph{arXiv preprint arXiv:2002.11743}, 2020.

\bibitem[Liu \& Scarlett(2019)Liu and Scarlett]{liu2019information}
Liu, Z. and Scarlett, J.
\newblock Information-theoretic lower bounds for compressive sensing with
  generative models.
\newblock \emph{arXiv preprint arXiv:1908.10744}, 2019.

\bibitem[Liu et~al.(2018)Liu, Luo, Wang, and Tang]{liu2018large}
Liu, Z., Luo, P., Wang, X., and Tang, X.
\newblock Large-scale celebfaces attributes (celeba) dataset.
\newblock \emph{Retrieved August}, 15:\penalty0 2018, 2018.

\bibitem[Liu et~al.(2020)Liu, Gomes, Tiwari, and Scarlett]{liu2020sample}
Liu, Z., Gomes, S., Tiwari, A., and Scarlett, J.
\newblock Sample complexity bounds for 1-bit compressive sensing and binary
  stable embeddings with generative priors.
\newblock \emph{arXiv preprint arXiv:2002.01697}, 2020.

\bibitem[Lustig et~al.(2007)Lustig, Donoho, and Pauly]{lustig2007sparse}
Lustig, M., Donoho, D., and Pauly, J.~M.
\newblock Sparse mri: The application of compressed sensing for rapid mr
  imaging.
\newblock \emph{Magnetic Resonance in Medicine: An Official Journal of the
  International Society for Magnetic Resonance in Medicine}, 58\penalty0
  (6):\penalty0 1182--1195, 2007.

\bibitem[Lustig et~al.(2008)Lustig, Donoho, Santos, and
  Pauly]{lustig2008compressed}
Lustig, M., Donoho, D.~L., Santos, J.~M., and Pauly, J.~M.
\newblock Compressed sensing mri.
\newblock \emph{IEEE signal processing magazine}, 25\penalty0 (2):\penalty0
  72--82, 2008.

\bibitem[Mardani et~al.(2018)Mardani, Gong, Cheng, Vasanawala, Zaharchuk, Xing,
  and Pauly]{mardani2018deep}
Mardani, M., Gong, E., Cheng, J.~Y., Vasanawala, S.~S., Zaharchuk, G., Xing,
  L., and Pauly, J.~M.
\newblock Deep generative adversarial neural networks for compressive sensing
  mri.
\newblock \emph{IEEE transactions on medical imaging}, 38\penalty0
  (1):\penalty0 167--179, 2018.

\bibitem[Metzler et~al.(2017)Metzler, Mousavi, and
  Baraniuk]{metzler2017learned}
Metzler, C., Mousavi, A., and Baraniuk, R.
\newblock Learned d-amp: Principled neural network based compressive image
  recovery.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1772--1783, 2017.

\bibitem[Mosser et~al.(2020)Mosser, Dubrule, and Blunt]{mosser2020stochastic}
Mosser, L., Dubrule, O., and Blunt, M.~J.
\newblock Stochastic seismic waveform inversion using generative adversarial
  networks as a geological prior.
\newblock \emph{Mathematical Geosciences}, 52\penalty0 (1):\penalty0 53--79,
  2020.

\bibitem[Ongie et~al.(2020)Ongie, Jalal, Metzler, Baraniuk, Dimakis, and
  Willett]{ongie2020deep}
Ongie, G., Jalal, A., Metzler, C.~A., Baraniuk, R.~G., Dimakis, A.~G., and
  Willett, R.
\newblock Deep learning techniques for inverse problems in imaging.
\newblock \emph{arXiv preprint arXiv:2005.06001}, 2020.

\bibitem[Oord et~al.(2016)Oord, Kalchbrenner, and Kavukcuoglu]{oord2016pixel}
Oord, A. v.~d., Kalchbrenner, N., and Kavukcuoglu, K.
\newblock Pixel recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1601.06759}, 2016.

\bibitem[Pandit et~al.(2019)Pandit, Sahraee-Ardakan, Rangan, Schniter, and
  Fletcher]{pandit2019inference}
Pandit, P., Sahraee-Ardakan, M., Rangan, S., Schniter, P., and Fletcher, A.~K.
\newblock Inference with deep generative priors in high dimensions.
\newblock \emph{arXiv preprint arXiv:1911.03409}, 2019.

\bibitem[Pesin(2008)]{pesin2008dimension}
Pesin, Y.~B.
\newblock \emph{Dimension theory in dynamical systems: contemporary views and
  applications}.
\newblock University of Chicago Press, 2008.

\bibitem[Polyanskiy \& Wu(2014)Polyanskiy and Wu]{polyanskiy2014lecture}
Polyanskiy, Y. and Wu, Y.
\newblock Lecture notes on information theory.
\newblock \emph{Lecture Notes for ECE563 (UIUC) and}, 6\penalty0
  (2012-2016):\penalty0 7, 2014.

\bibitem[Price \& Woodruff(2011)Price and Woodruff]{price20111+}
Price, E. and Woodruff, D.~P.
\newblock (1+ eps)-approximate sparse recovery.
\newblock In \emph{2011 IEEE 52nd Annual Symposium on Foundations of Computer
  Science}, pp.\  295--304. IEEE, 2011.

\bibitem[Qiu et~al.(2019)Qiu, Wei, and Yang]{qiu2019robust}
Qiu, S., Wei, X., and Yang, Z.
\newblock Robust one-bit recovery via relu generative networks: Improved
  statistical rates and global landscape analysis.
\newblock \emph{arXiv preprint arXiv:1908.05368}, 2019.

\bibitem[Reeves \& Gastpar(2012)Reeves and Gastpar]{reeves2012sampling}
Reeves, G. and Gastpar, M.
\newblock The sampling rate-distortion tradeoff for sparsity pattern recovery
  in compressed sensing.
\newblock \emph{IEEE Transactions on Information Theory}, 58\penalty0
  (5):\penalty0 3065--3092, 2012.

\bibitem[Rick~Chang et~al.(2017)Rick~Chang, Li, Poczos, Vijaya~Kumar, and
  Sankaranarayanan]{rick2017one}
Rick~Chang, J., Li, C.-L., Poczos, B., Vijaya~Kumar, B., and Sankaranarayanan,
  A.~C.
\newblock One network to solve them all--solving linear inverse problems using
  deep projection models.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  5888--5897, 2017.

\bibitem[Scarlett \& Cevher(2016)Scarlett and Cevher]{scarlett2016limits}
Scarlett, J. and Cevher, V.
\newblock Limits on support recovery with probabilistic models: An
  information-theoretic framework.
\newblock \emph{IEEE Transactions on Information Theory}, 63\penalty0
  (1):\penalty0 593--620, 2016.

\bibitem[Shannon(1948)]{shannon1948mathematical}
Shannon, C.~E.
\newblock A mathematical theory of communication.
\newblock \emph{Bell system technical journal}, 27\penalty0 (3):\penalty0
  379--423, 1948.

\bibitem[Song et~al.(2019)Song, Fan, and Lafferty]{song2019surfing}
Song, G., Fan, Z., and Lafferty, J.
\newblock Surfing: Iterative optimization over incrementally trained deep
  networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  15008--15017, 2019.

\bibitem[Song \& Ermon(2019)Song and Ermon]{song2019generative}
Song, Y. and Ermon, S.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  11918--11930, 2019.

\bibitem[Song \& Ermon(2020)Song and Ermon]{song2020improved}
Song, Y. and Ermon, S.
\newblock Improved techniques for training score-based generative models.
\newblock \emph{arXiv preprint arXiv:2006.09011}, 2020.

\bibitem[Tibshirani(1996)]{tibshirani1996regression}
Tibshirani, R.
\newblock Regression shrinkage and selection via the lasso.
\newblock \emph{Journal of the Royal Statistical Society. Series B
  (Methodological)}, pp.\  267--288, 1996.

\bibitem[Villani(2008)]{villani2008optimal}
Villani, C.
\newblock \emph{Optimal transport: old and new}, volume 338.
\newblock Springer Science \& Business Media, 2008.

\bibitem[Whang et~al.(2020)Whang, Lei, and Dimakis]{whang2020compressed}
Whang, J., Lei, Q., and Dimakis, A.~G.
\newblock Compressed sensing with invertible generative models and dependent
  noise.
\newblock \emph{arXiv preprint arXiv:2003.08089}, 2020.

\bibitem[Wu(2011)]{wu2011shannon}
Wu, Y.
\newblock \emph{Shannon theory for compressed sensing}.
\newblock Citeseer, 2011.

\bibitem[Wu \& Verd{\'u}(2012)Wu and Verd{\'u}]{wu2012optimal}
Wu, Y. and Verd{\'u}, S.
\newblock Optimal phase transitions in compressed sensing.
\newblock \emph{IEEE Transactions on Information Theory}, 58\penalty0
  (10):\penalty0 6241--6263, 2012.

\bibitem[Xu \& Hassibi(2008)Xu and Hassibi]{xu2008compressed}
Xu, W. and Hassibi, B.
\newblock Compressed sensing over the grassmann manifold: A unified analytical
  framework.
\newblock In \emph{2008 46th Annual Allerton Conference on Communication,
  Control, and Computing}, pp.\  562--567. IEEE, 2008.

\bibitem[Xu et~al.(2011)Xu, Mallada, and Tang]{xu2011compressive}
Xu, W., Mallada, E., and Tang, A.
\newblock Compressive sensing over graphs.
\newblock In \emph{2011 Proceedings IEEE INFOCOM}, pp.\  2087--2095. IEEE,
  2011.

\bibitem[Zdeborov{\'a} \& Krzakala(2016)Zdeborov{\'a} and
  Krzakala]{zdeborova2016statistical}
Zdeborov{\'a}, L. and Krzakala, F.
\newblock Statistical physics of inference: Thresholds and algorithms.
\newblock \emph{Advances in Physics}, 65\penalty0 (5):\penalty0 453--552, 2016.

\bibitem[Zhou et~al.(2014)Zhou, Liu, and Fang]{zhou2014bayesian}
Zhou, Z., Liu, K., and Fang, J.
\newblock Bayesian compressive sensing using normal product priors.
\newblock \emph{IEEE Signal Processing Letters}, 22\penalty0 (5):\penalty0
  583--587, 2014.

\end{thebibliography}
