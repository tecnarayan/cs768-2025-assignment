\begin{thebibliography}{10}

\bibitem{AD}
A.~Agarwal and J.~Duchi.
\newblock Distributed delayed stochastic optimization.
\newblock Technical report, arXiv, 2011.

\bibitem{BeckTeb03}
A.~Beck and M.~Teboulle.
\newblock Mirror descent and nonlinear projected subgradient methods for convex
  optimization.
\newblock {\em Operations Research Letters}, 31(3):167 -- 175, 2003.

\bibitem{BotBou07}
L.~Bottou and O.~Bousquet.
\newblock The tradeoffs of large scale learning.
\newblock In {\em NIPS}, 2007.

\bibitem{DMB}
O.~Dekel, R.~Gilad Bachrach, O.~Shamir, and L.~Xiao.
\newblock Optimal distributed online prediction using mini-batches.
\newblock Technical report, arXiv, 2010.

\bibitem{Lan09}
G.~Lan.
\newblock An optimal method for stochastic convex optimization.
\newblock Technical report, Georgia Institute of Technology, 2009.

\bibitem{NemirovskiJuLaSh09}
A.~Nemirovski, A.~Juditsky, G.~Lan, and A.~Shapiro.
\newblock Robust stochastic approximation approach to stochastic programming.
\newblock {\em SIAM Journal on Optimization}, 19(4):1574--1609, 2009.

\bibitem{Nesterov83}
Y.~Nesterov.
\newblock A method for unconstrained convex minimization problem with the rate
  of convergence $o(1/k^2)$.
\newblock {\em Doklady AN SSSR}, 269:543--547, 1983.

\bibitem{Nesterov05}
Y.~Nesterov.
\newblock Smooth minimization of non-smooth functions.
\newblock {\em Math. Program.}, 103(1):127--152, 2005.

\bibitem{Nesterov09}
Y.~Nesterov.
\newblock Primal-dual subgradient methods for convex problems.
\newblock {\em Mathematical Programming}, 120(1):221--259, August 2009.

\bibitem{DekelGilShamXia11}
O.~Shamir O.~Dekel, R. Gilad-Bachrach and L.~Xiao.
\newblock Optimal distributed online prediction.
\newblock In {\em ICML}, 2011.

\bibitem{ShalSiSreCo11}
S.~Shalev-Shwartz, Y.~Singer, N.~Srebro, and A.~Cotter.
\newblock Pegasos: primal estimated sub-gradient solver for {SVM}.
\newblock {\em Math. Program.}, 127(1):3--30, 2011.

\bibitem{ShalSre08}
S.~Shalev-Shwartz and N.~Srebro.
\newblock {SVM} optimization: inverse dependence on training set size.
\newblock In {\em ICML}, 2008.

\bibitem{SreSriTew10}
N.~Srebro, K.~Sridharan, and A.~Tewari.
\newblock Smoothness, low noise and fast rates.
\newblock In {\em NIPS}, 2010.

\bibitem{Shalev07}
S.Shalev-Shwartz.
\newblock {\em Online Learning: Theory, Algorithms, and Applications}.
\newblock PhD thesis, Hebrew University of Jerusalem, 2007.

\bibitem{Tseng08}
P.~Tseng.
\newblock On accelerated proximal gradient methods for convex-concave
  optimization.
\newblock {\em Submitted to SIAM Journal on Optimization}, 2008.

\bibitem{Xiao10}
L.~Xiao.
\newblock Dual averaging methods for regularized stochastic learning and online
  optimization.
\newblock {\em Journal of Machine Learning Research}, 11:2543--2596, 2010.

\end{thebibliography}
