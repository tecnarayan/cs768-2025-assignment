\begin{thebibliography}{67}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Cranmer et~al.(2020)Cranmer, Brehmer, and Louppe]{cranmer2020frontier}
Kyle Cranmer, Johann Brehmer, and Gilles Louppe.
\newblock The frontier of simulation-based inference.
\newblock \emph{Proceedings of the National Academy of Sciences}, 2020.

\bibitem[Lavin et~al.(2021)Lavin, Zenil, Paige, et~al.]{lavin2021simulation}
Alexander Lavin, Hector Zenil, Brooks Paige, et~al.
\newblock Simulation intelligence: Towards a new generation of scientific
  methods.
\newblock \emph{arXiv preprint}, 2021.

\bibitem[Radev et~al.(2021{\natexlab{a}})Radev, Graw, Chen, Mutters, Eichel,
  B{\"a}rnighausen, and K{\"o}the]{radev2021outbreakflow}
Stefan~T Radev, Frederik Graw, Simiao Chen, Nico~T Mutters, Vanessa~M Eichel,
  Till B{\"a}rnighausen, and Ullrich K{\"o}the.
\newblock Outbreakflow: Model-based bayesian inference of disease outbreak
  dynamics with invertible neural networks and its application to the covid-19
  pandemics in germany.
\newblock \emph{PLoS computational biology}, 2021{\natexlab{a}}.

\bibitem[Shiono(2021)]{bayesflow_agent}
Takashi Shiono.
\newblock {Estimation of agent-based models using Bayesian deep learning
  approach of BayesFlow}.
\newblock \emph{Journal of Economic Dynamics and Control}, 125:\penalty0
  104082, 2021.

\bibitem[Gon{\c{c}}alves et~al.(2020)Gon{\c{c}}alves, Lueckmann, Deistler,
  et~al.]{gonccalves2020training}
Pedro~J Gon{\c{c}}alves, Jan-Matthis Lueckmann, Michael Deistler, et~al.
\newblock Training deep neural density estimators to identify mechanistic
  models of neural dynamics.
\newblock \emph{Elife}, 2020.

\bibitem[Wehenkel et~al.(2023)Wehenkel, Behrmann, Miller, Sapiro, Sener,
  Cuturi, and Jacobsen]{wehenkel2023sbicardio}
Antoine Wehenkel, Jens Behrmann, Andrew~C. Miller, Guillermo Sapiro, Ozan
  Sener, Marco Cuturi, and Jörn-Henrik Jacobsen.
\newblock Simulation-based inference for cardiovascular models, 2023.

\bibitem[von Krause et~al.(2022)von Krause, Radev, and
  Voss]{von_krause_mental_2022}
Mischa von Krause, Stefan~T. Radev, and Andreas Voss.
\newblock Mental speed is high until age 60 as revealed by analysis of over a
  million participants.
\newblock \emph{Nature Human Behaviour}, 6\penalty0 (5):\penalty0 700--708, May
  2022.
\newblock \doi{10.1038/s41562-021-01282-7}.

\bibitem[Papamakarios et~al.(2021)Papamakarios, Nalisnick, Rezende, Mohamed,
  and Lakshminarayanan]{papamakarios2021}
George Papamakarios, Eric Nalisnick, Danilo~Jimenez Rezende, Shakir Mohamed,
  and Balaji Lakshminarayanan.
\newblock Normalizing flows for probabilistic modeling and inference.
\newblock \emph{J. Mach. Learn. Res.}, 22\penalty0 (1), jan 2021.
\newblock ISSN 1532-4435.

\bibitem[Geffner et~al.(2022)Geffner, Papamakarios, and
  Mnih]{geffner2022diffusionsbi}
Tomas Geffner, George Papamakarios, and Andriy Mnih.
\newblock Compositional score modeling for simulation-based inference, 2022.

\bibitem[Sharrock et~al.(2022)Sharrock, Simons, Liu, and
  Beaumont]{sharrock2022diffusionsbi}
Louis Sharrock, Jack Simons, Song Liu, and Mark Beaumont.
\newblock Sequential neural score estimation: Likelihood-free inference with
  conditional score based diffusion models, 2022.

\bibitem[Wildberger et~al.(2023)Wildberger, Dax, Buchholz, Green, Macke, and
  Sch{\"o}lkopf]{wildberger2023FlowMatchingScalable}
Jonas Wildberger, Maximilian Dax, Simon Buchholz, Stephen Green, Jakob~H Macke,
  and Bernhard Sch{\"o}lkopf.
\newblock Flow matching for scalable simulation-based inference.
\newblock In A.~Oh, T.~Naumann, A.~Globerson, K.~Saenko, M.~Hardt, and
  S.~Levine, editors, \emph{Advances in Neural Information Processing Systems},
  volume~36, pages 16837--16864, 2023.

\bibitem[Song et~al.(2021)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and
  Poole]{song2021diffusion}
Yang Song, Jascha Sohl-Dickstein, Diederik~P. Kingma, Abhishek Kumar, Stefano
  Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and
  Ommer]{Rombach_2022_CVPR}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\"orn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 10684--10695, 2022.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pages 6840--6851, 2020.

\bibitem[Batzolis et~al.(2021)Batzolis, Stanczuk, Schönlieb, and
  Etmann]{batzolis2021}
Georgios Batzolis, Jan Stanczuk, Carola-Bibiane Schönlieb, and Christian
  Etmann.
\newblock Conditional image generation with score-based diffusion models, 2021.

\bibitem[Lipman et~al.(2023)Lipman, Chen, Ben-Hamu, Nickel, and
  Le]{lipman2023flow}
Yaron Lipman, Ricky T.~Q. Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew
  Le.
\newblock Flow matching for generative modeling.
\newblock In \emph{The 11th International Conference on Learning
  Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=PqvMRDCJT9t}.

\bibitem[Liu et~al.(2022)Liu, Gong, and Liu]{liu2022rectified}
Xingchao Liu, Chengyue Gong, and Qiang Liu.
\newblock Flow straight and fast: Learning to generate and transfer data with
  rectified flow, 2022.

\bibitem[Song et~al.(2023)Song, Dhariwal, Chen, and
  Sutskever]{song2023consistency}
Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever.
\newblock Consistency models.
\newblock In \emph{International Conference on Machine Learning}, 2023.

\bibitem[Jagiella et~al.(2017)Jagiella, Rickert, Theis, and
  Hasenauer]{jagiella2017parallelization}
Nick Jagiella, Dennis Rickert, Fabian~J Theis, and Jan Hasenauer.
\newblock Parallelization and high-performance computing enables automated
  statistical inference of multi-scale models.
\newblock \emph{Cell systems}, 4\penalty0 (2):\penalty0 194--206, 2017.

\bibitem[Ghaderi-Kangavari et~al.(2023)Ghaderi-Kangavari, Rad, and
  Nunez]{ghaderi-kangavari_general_2023}
Amin Ghaderi-Kangavari, Jamal~Amani Rad, and Michael~D. Nunez.
\newblock A general integrative neurocognitive modeling framework to jointly
  describe {EEG} and decision-making on single trials.
\newblock \emph{Computational Brain and Behavior}, 2023.
\newblock \doi{10.1007/s42113-023-00167-4}.

\bibitem[Dax et~al.(2023)Dax, Green, Gair, P\"{u}rrer, Wildberger, Macke,
  Buonanno, and Sch\"{o}lkopf]{Dax2023importancesampling}
Maximilian Dax, Stephen~R. Green, Jonathan Gair, Michael P\"{u}rrer, Jonas
  Wildberger, Jakob~H. Macke, Alessandra Buonanno, and Bernhard Sch\"{o}lkopf.
\newblock Neural importance sampling for rapid and reliable gravitational-wave
  inference.
\newblock \emph{Physical Review Letters}, 130\penalty0 (17), April 2023.
\newblock ISSN 1079-7114.
\newblock \doi{10.1103/physrevlett.130.171403}.
\newblock URL \url{http://dx.doi.org/10.1103/PhysRevLett.130.171403}.

\bibitem[Rubin(1984)]{rubin1984bayesianly}
Donald~B Rubin.
\newblock Bayesianly justifiable and relevant frequency calculations for the
  applied statistician.
\newblock \emph{The Annals of Statistics}, pages 1151--1172, 1984.

\bibitem[Tavar{\'e} et~al.(1997)Tavar{\'e}, Balding, Griffiths, and
  Donnelly]{tavare1997inferring}
Simon Tavar{\'e}, David~J Balding, Robert~C Griffiths, and Peter Donnelly.
\newblock Inferring coalescence times from dna sequence data.
\newblock \emph{Genetics}, 145\penalty0 (2):\penalty0 505--518, 1997.

\bibitem[Diggle and Gratton(1984)]{diggle1984monte}
Peter~J Diggle and Richard~J Gratton.
\newblock Monte carlo methods of inference for implicit statistical models.
\newblock \emph{Journal of the Royal Statistical Society Series B: Statistical
  Methodology}, 46\penalty0 (2):\penalty0 193--212, 1984.

\bibitem[Papamakarios and Murray(2016)]{papamakarios2016fast}
George Papamakarios and Iain Murray.
\newblock Fast $\varepsilon$-free inference of simulation models with bayesian
  conditional density estimation.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Lueckmann et~al.(2017)Lueckmann, Gon{\c{c}}alves, Bassetto, {\"O}cal,
  Nonnenmacher, and Macke]{lueckmann2017flexible}
Jan-Matthis Lueckmann, Pedro~J Gon{\c{c}}alves, Giacomo Bassetto, Kaan
  {\"O}cal, Marcel Nonnenmacher, and Jakob~H Macke.
\newblock Flexible statistical inference for mechanistic models of neural
  dynamics.
\newblock In \emph{31st NeurIPS Conference Proceedings}, 2017.

\bibitem[Greenberg et~al.(2019)Greenberg, Nonnenmacher, and
  Macke]{greenberg2019automatic}
David Greenberg, Marcel Nonnenmacher, and Jakob Macke.
\newblock Automatic posterior transformation for likelihood-free inference.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Durkan et~al.(2020)Durkan, Murray, and
  Papamakarios]{durkan2020contrastive}
Conor Durkan, Iain Murray, and George Papamakarios.
\newblock On contrastive learning for likelihood-free inference.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2020.

\bibitem[Deistler et~al.(2022)Deistler, Goncalves, and
  Macke]{deistler2022truncated}
Michael Deistler, Pedro~J Goncalves, and Jakob~H Macke.
\newblock Truncated proposals for scalable and hassle-free simulation-based
  inference.
\newblock \emph{arXiv preprint}, 2022.

\bibitem[Ardizzone et~al.(2019)Ardizzone, Kruse, Wirkert, Rahner, Pellegrini,
  Klessen, Maier-Hein, Rother, and K{\"o}the]{ardizzone2018analyzing}
Lynton Ardizzone, Jakob Kruse, Sebastian Wirkert, Daniel Rahner, Eric~W
  Pellegrini, Ralf~S Klessen, Lena Maier-Hein, Carsten Rother, and Ullrich
  K{\"o}the.
\newblock Analyzing inverse problems with invertible neural networks.
\newblock In \emph{Intl. Conf. on Learning Representations}, 2019.

\bibitem[Radev et~al.(2020)Radev, Mertens, Voss, Ardizzone, and
  K{\"o}the]{radev2020bayesflow}
Stefan~T Radev, Ulf~K Mertens, Andreas Voss, Lynton Ardizzone, and Ullrich
  K{\"o}the.
\newblock Bayesflow: Learning complex stochastic models with invertible neural
  networks.
\newblock \emph{IEEE transactions on neural networks and learning systems},
  2020.

\bibitem[Pacchiardi and Dutta(2022)]{pacchiardi2022score}
Lorenzo Pacchiardi and Ritabrata Dutta.
\newblock Score matched neural exponential families for likelihood-free
  inference.
\newblock \emph{J. Mach. Learn. Res.}, 23:\penalty0 38--1, 2022.

\bibitem[Avecilla et~al.(2022)Avecilla, Chuong, Li, Sherlock, Gresham, and
  Ram]{avecilla2022neural}
Grace Avecilla, Julie~N Chuong, Fangfei Li, Gavin Sherlock, David Gresham, and
  Yoav Ram.
\newblock Neural networks enable efficient and accurate simulation-based
  inference of evolutionary parameters from adaptation dynamics.
\newblock \emph{PLoS Biology}, 20\penalty0 (5):\penalty0 e3001633, 2022.

\bibitem[Radev et~al.(2021{\natexlab{b}})Radev, D'Alessandro, Mertens, Voss,
  K{\"o}the, and B{\"u}rkner]{radev2021amortized}
Stefan~T Radev, Marco D'Alessandro, Ulf~K Mertens, Andreas Voss, Ullrich
  K{\"o}the, and Paul-Christian B{\"u}rkner.
\newblock Amortized bayesian model comparison with evidential deep learning.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  2021{\natexlab{b}}.

\bibitem[Elsemüller et~al.(2023{\natexlab{a}})Elsemüller, Schnuerch,
  Bürkner, and Radev]{elsemuller2023hierarchical}
Lasse Elsemüller, Martin Schnuerch, Paul-Christian Bürkner, and Stefan~T.
  Radev.
\newblock A deep learning method for comparing bayesian hierarchical models,
  2023{\natexlab{a}}.

\bibitem[Schmitt et~al.(2023{\natexlab{a}})Schmitt, Radev, and
  Bürkner]{Schmitt2023multimodal}
Marvin Schmitt, Stefan~T. Radev, and Paul-Christian Bürkner.
\newblock Fuse it or lose it: Deep fusion for multimodal simulation-based
  inference, 2023{\natexlab{a}}.
\newblock arXiv:2311.10671.

\bibitem[Elsemüller et~al.(2023{\natexlab{b}})Elsemüller, Olischläger,
  Schmitt, Bürkner, Köthe, and Radev]{elsemuller2023sensitivity}
Lasse Elsemüller, Hans Olischläger, Marvin Schmitt, Paul-Christian Bürkner,
  Ullrich Köthe, and Stefan~T. Radev.
\newblock Sensitivity-aware amortized {Bayesian} inference, 2023{\natexlab{b}}.
\newblock arXiv:2310.11122.

\bibitem[Schröder and Macke(2023)]{schroeder2023simultaneous}
Cornelius Schröder and Jakob~H. Macke.
\newblock Simultaneous identification of models and parameters of scientific
  simulators, 2023.

\bibitem[Rezende and Mohamed(2015)]{rezende2015}
Danilo~Jimenez Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In \emph{Proceedings of the 32nd International Conference on
  International Conference on Machine Learning - Volume 37}, ICML'15, page
  1530–1538. JMLR.org, 2015.

\bibitem[Dinh et~al.(2016)Dinh, Sohl-Dickstein, and Bengio]{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real nvp.
\newblock \emph{arXiv preprint arXiv:1605.08803}, 2016.

\bibitem[Durkan et~al.(2019)Durkan, Bekasov, Murray, and
  Papamakarios]{durkan2019neural}
Conor Durkan, Artur Bekasov, Iain Murray, and George Papamakarios.
\newblock Neural spline flows.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Villani(2009)]{villaniOptimalTransport2009}
C{\'e}dric Villani.
\newblock \emph{Optimal {{Transport}}}, volume 338 of \emph{Grundlehren Der
  Mathematischen {{Wissenschaften}}}.
\newblock Springer, Berlin, Heidelberg, 2009.
\newblock ISBN 978-3-540-71049-3 978-3-540-71050-9.
\newblock \doi{10.1007/978-3-540-71050-9}.

\bibitem[Peyré and Cuturi(2020)]{peyre2020computationaloptimaltransport}
Gabriel Peyré and Marco Cuturi.
\newblock Computational optimal transport, 2020.
\newblock URL \url{https://arxiv.org/abs/1803.00567}.

\bibitem[Song and Ermon(2019)]{song2019diffusion}
Yang Song and Stefano Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock In \emph{Proceedings of the 33rd International Conference on Neural
  Information Processing Systems}, 2019.

\bibitem[Karras et~al.(2022)Karras, Aittala, Aila, and
  Laine]{karras2022elucidating}
Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 26565--26577, 2022.

\bibitem[Song and Dhariwal(2024)]{song2024improved}
Yang Song and Prafulla Dhariwal.
\newblock Improved techniques for training consistency models.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=WNzy9bRDvG}.

\bibitem[Heringhaus et~al.(2022)Heringhaus, Zhang, Zimmermann, and
  Mikelsons]{Heringhaus2022}
Monika~E. Heringhaus, Yi~Zhang, André Zimmermann, and Lars Mikelsons.
\newblock Towards reliable parameter extraction in mems final module testing
  using bayesian inference.
\newblock \emph{Sensors}, 22\penalty0 (14):\penalty0 5408, July 2022.
\newblock ISSN 1424-8220.
\newblock \doi{10.3390/s22145408}.
\newblock URL \url{http://dx.doi.org/10.3390/s22145408}.

\bibitem[Kadupitiya et~al.(2020)Kadupitiya, Sun, Fox, and
  Jadhao]{Kadupitiya2020}
J.C.S Kadupitiya, Fanbo Sun, Geoffrey Fox, and Vikram Jadhao.
\newblock Machine learning surrogates for molecular dynamics simulations of
  soft materials.
\newblock \emph{Journal of Computational Science}, 42:\penalty0 101107, 2020.
\newblock \doi{10.1016/j.jocs.2020.101107}.

\bibitem[Radev et~al.(2023{\natexlab{a}})Radev, Schmitt, Pratz, Picchini,
  K\"othe, and B\"urkner]{radev2023jana}
Stefan~T. Radev, Marvin Schmitt, Valentin Pratz, Umberto Picchini, Ullrich
  K\"othe, and Paul-Christian B\"urkner.
\newblock {JANA: Jointly Amortized Neural Approximation of Complex Bayesian
  Models}.
\newblock In Robin~J. Evans and Ilya Shpitser, editors, \emph{Proceedings of
  the 39th Conference on Uncertainty in Artificial Intelligence}, volume 216 of
  \emph{Proceedings of Machine Learning Research}, pages 1695--1706. PMLR,
  2023{\natexlab{a}}.

\bibitem[Schmitt et~al.(2023{\natexlab{b}})Schmitt, Habermann, B{\"u}rkner,
  Koethe, and Radev]{schmitt2023selfconsistency}
Marvin Schmitt, Daniel Habermann, Paul-Christian B{\"u}rkner, Ullrich Koethe,
  and Stefan~T. Radev.
\newblock Leveraging self-consistency for data-efficient amortized {B}ayesian
  inference.
\newblock In \emph{{NeurIPS UniReps}: the First Workshop on Unifying
  Representations in Neural Models}, 2023{\natexlab{b}}.

\bibitem[K{\"o}the(2023)]{kothe2023review}
Ullrich K{\"o}the.
\newblock A review of change of variable formulas for generative modeling.
\newblock \emph{arXiv preprint arXiv:2308.02652}, 2023.

\bibitem[Lueckmann et~al.(2021)Lueckmann, Boelts, Greenberg, Gonçalves, and
  Macke]{lueckmann2021benchmarking}
Jan-Matthis Lueckmann, Jan Boelts, David~S. Greenberg, Pedro~J. Gonçalves, and
  Jakob~H. Macke.
\newblock Benchmarking simulation-based inference.
\newblock \emph{arXiv preprint}, 2021.

\bibitem[Kruse et~al.(2021)Kruse, Ardizzone, Rother, and
  Köthe]{kruse2021benchmarkinginn}
Jakob Kruse, Lynton Ardizzone, Carsten Rother, and Ullrich Köthe.
\newblock Benchmarking invertible architectures on inverse problems.
\newblock 2021.
\newblock Workshop on Invertible Neural Networks and Normalizing Flows (ICML
  2019).

\bibitem[Ramesh et~al.(2022)Ramesh, Lueckmann, Boelts, Tejero-Cantero,
  Greenberg, Gon{\c{c}}alves, and Macke]{ramesh2022gatsbi}
Poornima Ramesh, Jan-Matthis Lueckmann, Jan Boelts, {\'A}lvaro Tejero-Cantero,
  David~S Greenberg, Pedro~J Gon{\c{c}}alves, and Jakob~H Macke.
\newblock Gatsbi: Generative adversarial training for simulation-based
  inference.
\newblock \emph{arXiv preprint arXiv:2203.06481}, 2022.

\bibitem[Radev et~al.(2023{\natexlab{b}})Radev, Schmitt, Schumacher,
  Elsemüller, Pratz, Schälte, Köthe, and Bürkner]{Radev2023joss}
Stefan~T. Radev, Marvin Schmitt, Lukas Schumacher, Lasse Elsemüller, Valentin
  Pratz, Yannik Schälte, Ullrich Köthe, and Paul-Christian Bürkner.
\newblock Bayesflow: Amortized bayesian workflows with neural networks.
\newblock \emph{Journal of Open Source Software}, 8\penalty0 (89):\penalty0
  5702, 2023{\natexlab{b}}.
\newblock \doi{10.21105/joss.05702}.
\newblock URL \url{https://doi.org/10.21105/joss.05702}.

\bibitem[Gretton et~al.(2012)Gretton, Borgwardt, Rasch, Schölkopf, and
  Smola]{Gretton2012}
A~Gretton, K.~Borgwardt, Malte Rasch, Bernhard Schölkopf, and AJ~Smola.
\newblock {A Kernel Two-Sample Test}.
\newblock \emph{The Journal of Machine Learning Research}, 13:\penalty0
  723--773, 2012.

\bibitem[Talts et~al.(2018)Talts, Betancourt, Simpson, Vehtari, and
  Gelman]{talts2018validating}
Sean Talts, Michael Betancourt, Daniel Simpson, Aki Vehtari, and Andrew Gelman.
\newblock Validating bayesian inference algorithms with simulation-based
  calibration.
\newblock \emph{arXiv preprint}, 2018.

\bibitem[Zaheer et~al.(2017)Zaheer, Kottur, Ravanbakhsh, Poczos, Salakhutdinov,
  and Smola]{zaheer2017deepsets}
Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan
  Salakhutdinov, and Alexander Smola.
\newblock Deep sets, 2017.

\bibitem[Wiqvist et~al.(2021)Wiqvist, Frellsen, and
  Picchini]{wiqvist2021sequential}
Samuel Wiqvist, Jes Frellsen, and Umberto Picchini.
\newblock Sequential neural posterior and likelihood approximation.
\newblock \emph{arXiv preprint}, 2021.

\bibitem[H\"{u}llermeier and Waegeman(2021)]{huellermeier2021}
Eyke H\"{u}llermeier and Willem Waegeman.
\newblock Aleatoric and epistemic uncertainty in machine learning: an
  introduction to concepts and methods.
\newblock \emph{Machine Learning}, 110\penalty0 (3):\penalty0 457–506, 2021.
\newblock ISSN 1573-0565.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017fashionmnist}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms, 2017.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and
  Brox]{ronneberger2015unet}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In Nassir Navab, Joachim Hornegger, William~M. Wells, and
  Alejandro~F. Frangi, editors, \emph{Medical Image Computing and
  Computer-Assisted Intervention -- MICCAI 2015}, pages 234--241, Cham, 2015.
  Springer International Publishing.
\newblock ISBN 978-3-319-24574-4.

\bibitem[LeCun et~al.(2015)LeCun, Bengio, and Hinton]{LeCun2015}
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.
\newblock Deep learning.
\newblock \emph{Nature}, 521\penalty0 (7553):\penalty0 436–444, 2015.
\newblock ISSN 1476-4687.
\newblock \doi{10.1038/nature14539}.
\newblock URL \url{http://dx.doi.org/10.1038/nature14539}.

\bibitem[Nain(2022)]{Nain2022}
Aakash~Kumar Nain.
\newblock Keras documentation: Denoising diffusion probabilistic model.
\newblock \url{https://keras.io/examples/generative/ddpm/}, 2022.
\newblock Accessed: 2023-11-27.

\bibitem[pyABC(2017)]{pyabc}
pyABC.
\newblock {pyABC documentation, multi-scale model: Tumor spheroid growth}.
\newblock
  https://pyabc.readthedocs.io/en/latest/examples/\\multiscale\_agent\_based.html,
  2017.
\newblock Accessed: 2023-12-07.

\bibitem[Kim et~al.(2024)Kim, Lai, Liao, Murata, Takida, Uesaka, He, Mitsufuji,
  and Ermon]{kim2024ctm}
Dongjun Kim, Chieh-Hsin Lai, Wei-Hsiang Liao, Naoki Murata, Yuhta Takida,
  Toshimitsu Uesaka, Yutong He, Yuki Mitsufuji, and Stefano Ermon.
\newblock Consistency trajectory models: Learning probability flow {ODE}
  trajectory of diffusion.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=ymjI8feDTD}.

\bibitem[Dax et~al.(2021)Dax, Green, Gair, Macke, Buonanno, and
  Schölkopf]{dax2021dingo}
Maximilian Dax, Stephen~R. Green, Jonathan Gair, Jakob~H. Macke, Alessandra
  Buonanno, and Bernhard Schölkopf.
\newblock Real-time gravitational wave science with neural posterior
  estimation.
\newblock \emph{Physical Review Letters}, 127\penalty0 (24), 2021.
\newblock ISSN 1079-7114.
\newblock \doi{10.1103/physrevlett.127.241103}.
\newblock URL \url{http://dx.doi.org/10.1103/PhysRevLett.127.241103}.

\end{thebibliography}
