@string{cvpr = "Proc. CVPR"}
@string{iccv = "Proc. ICCV"}
@string{eccv = "Proc. ECCV"}
@string{iclr = "Proc. ICLR"}
@string{nips = "Proc. NeurIPS"}
@string{icml = "Proc. ICML"}

@string{cvpr = "{IEEE/CVF} Conference on Computer Vision and Pattern Recognition (CVPR)"}
@string{iccv = "{IEEE/CVF} International Conference on Computer Vision (ICCV)"}
@string{eccv = "European Conference on Computer Vision (ECCV)"}
@string{iclr = "International Conference on Learning Representations (ICLR)"}
@string{nips = "Advances in Neural Information Processing Systems (NeurIPS)"}
@string{icml = "International Conference on Machine Learning (ICML)"}
@string{gecco = "Genetic and Evolutionary Computation Conference (GECCO)"}
@string{aaai = "AAAI Conference on Artificial Intelligence (AAAI)"}
@string{uai = "Conference on Uncertainty in Artificial Intelligence (UAI)"}
@string{ppsn = "International Conference on Parallel Problem Solving from Nature (PPSN)"}
@string{aistats = "International Conference on Artificial Intelligence and Statistics (AISTATS)"}
@string{emo = "International Conference on Evolutionary Multi-Criterion Optimization (EMO)"}
@string{wcci = "IEEE World Congress on Computational Intelligence (WCCI)"}
@string{cec = "IEEE Congress on Evolutionary Computation (CEC)"}
@string{sac = "ACM Symposium on Applied Computing (SAC)"}
@string{ijcai = "International Joint Conferences on Artificial Intelligence (IJCAI)"}

% 还有 workshop  +w吧
@string{iccvw = "{IEEE/CVF} International Conference on Computer Vision (ICCV) Workshops"}
@string{iclrw = "International Conference on Learning Representations (ICLR) Workshops"}
@string{nipsw = "Advances in Neural Information Processing Systems (NeurIPS)) Workshops"}

@string{pami = "IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)"}
% 对于重复定义，注释无效，先后顺序才有效


% Gaussian Process





%%%% Classical Model-based Optimization %%%
@article{jones1998efficient,
  title={Efficient global optimization of expensive black-box functions},
  author={Jones, Donald R and Schonlau, Matthias and Welch, William J},
  journal={Journal of Global Optimization},
  volume={13},
  number={4},
  pages={455--492},
  year={1998},
  publisher={Springer}
}

@inproceedings{cox1992statistical,
  title={A statistical method for global optimization},
  author={Cox, Dennis D and John, Susan},
  booktitle={[Proceedings] 1992 IEEE International Conference on Systems, Man, and Cybernetics},
  pages={1241--1246},
  year={1992},
  organization={IEEE}
}


%%% Bayesian Optimization %%%
%BO
@book{garnett2022bayesian,
  author    = {Garnett, Roman},
  title     = {{Bayesian Optimization}},
  year      = {2022},
  publisher = {Cambridge University Press},
  note      = {in preparation}
}

@article{kushner1964new,
  title={A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise},
  author={Kushner, Harold J},
  journal={Journal of Basic Engineering},
  volume={86},
  number={1},
  pages={97–106},
  year={1964}
}


@book{mockus1989bayesian,
  title={Bayesian approach to global optimization: theory and applications},
  author={Mockus, Jonas},
  year={1989},
  publisher={Kluwer Academic Publishers.}
}

@inproceedings{pelikan1999boa,
  title={BOA: The Bayesian optimization algorithm},
  author={Pelikan, Martin and Goldberg, David E and Cant{\'u}-Paz, Erick and others},
  booktitle=gecco,
  year={1999},
  //volume={1},
  //pages={525--532},
  //organization={Citeseer}
}

@article{jones2001taxonomy,
  title={A taxonomy of global optimization methods based on response surfaces},
  author={Jones, Donald R},
  journal={Journal of global optimization},
  volume={21},
  number={4},
  pages={345--383},
  year={2001},
  publisher={Springer}
}

@article{keane2006statistical,
  title={Statistical improvement criteria for use in multiobjective design optimization},
  author={Keane, Andy J},
  journal={AIAA journal},
  volume={44},
  number={4},
  pages={879--891},
  year={2006}
}

@article{brochu2010tutorial,
  title={A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning},
  author={Brochu, Eric and Cora, Vlad M and De Freitas, Nando},
  journal={arXiv preprint arXiv:1012.2599},
  year={2010}
}

@article{shahriari2016taking,
  title={Taking the human out of the loop: A review of bayesian optimization},
  author={Shahriari, B and Swersky, K and Wang, Z and Adams, R and De Freitas, N},
  journal={Proceedings of the IEEE},
  volume={104},
  number={1},
  pages={148--175},
  year={2016},
  publisher={IEEE}
}

@article{frazier2018tutorial,
  title={A tutorial on Bayesian optimization},
  author={Frazier, Peter I},
  journal={arXiv preprint arXiv:1807.02811},
  year={2018}
}

@inproceedings{snoek2012practical,
  title={Practical bayesian optimization of machine learning algorithms},
  author={Snoek, J and Larochelle, H and Adams, R},
  booktitle=nips,
  //pages={2951--2959},
  year={2012}
}

@inproceedings{wang2013bayesian,
  title={Bayesian optimization in high dimensions via random embeddings},
  author={Wang, Ziyu and Zoghi, Masrour and Hutter, Frank and Matheson, David and De Freitas, Nando},
  booktitle=ijcai,
  year={2013}
}

@article{wang2016bayesian,
  title={Bayesian optimization in a billion dimensions via random embeddings},
  author={Wang, Ziyu and Hutter, Frank and Zoghi, Masrour and Matheson, David and de Feitas, Nando},
  journal={Journal of Artificial Intelligence Research},
  volume={55},
  pages={361--387},
  year={2016}
}

@inproceedings{wu2016parallel,
  title={The parallel knowledge gradient method for batch Bayesian optimization},
  author={Wu, Jian and Frazier, Peter},
  booktitle=nips,
  year={2016},
  //volume={29},
  //pages={3126--3134},
}

@inproceedings{wu2017bayesian,
  title={Bayesian optimization with gradients},
  author={Wu, J and Poloczek, M and Wilson, A and Frazier, P},
  booktitle=nips,
  //pages={5273--5284},
  year={2017}
}

@article{wilson2017reparameterization,
  title={The reparameterization trick for acquisition functions},
  author={Wilson, James T and Moriconi, Riccardo and Hutter, Frank and Deisenroth, Marc Peter},
  journal={arXiv preprint arXiv:1712.00424},
  year={2017}
}

@inproceedings{wilson2018maximizing,
  title={Maximizing acquisition functions for Bayesian optimization},
  author={Wilson, James and Hutter, Frank and Deisenroth, Marc},
  booktitle=nips,
  volume={31},
  year={2018}
}


@inproceedings{bergstra2011algorithms,
  title={Algorithms for hyper-parameter optimization},
  author={Bergstra, James S and Bardenet, R{\'e}mi and Bengio, Yoshua and K{\'e}gl, Bal{\'a}zs},
  booktitle=nips,
  //pages={2546--2554},
  year={2011}
}

% acquisition

% Predicted Mean
@inproceedings{rehbach2020expected,
  title={Expected improvement versus predicted value in surrogate-based optimization},
  author={Rehbach, Frederik and Zaefferer, Martin and Naujoks, Boris and Bartz-Beielstein, Thomas},
  booktitle=gecco,
  year={2020}
}

@article{de2021greed,
  title={Greed is good: Exploration and exploitation trade-offs in Bayesian optimisation},
  author={De Ath, George and Everson, Richard M and Rahat, Alma AM and Fieldsend, Jonathan E},
  journal={ACM Transactions on Evolutionary Learning and Optimization},
  volume={1},
  number={1},
  pages={1--22},
  year={2021},
  publisher={ACM New York, NY}
}

% UCB
@inproceedings{srinivas2009gaussian,
  title={Gaussian process optimization in the bandit setting: No regret and experimental design},
  author={Srinivas, Niranjan and Krause, Andreas and Kakade, Sham M and Seeger, Matthias},
  booktitle=icml,
  year={2010}
}

% EI
@inproceedings{movckus1975bayesian,
  title={On Bayesian methods for seeking the extremum},
  author={Mo{\v{c}}kus, Jonas},
  booktitle={Optimization techniques IFIP technical conference},
  pages={400--404},
  year={1975},
  organization={Springer}
}

% algorithm profile

@article{steponavivce2017dynamic,
  title={Dynamic algorithm selection for pareto optimal set approximation},
  author={Steponavi{\v{c}}{\.e}, Ingrida and Hyndman, Rob J and Smith-Miles, Kate and Villanova, Laura},
  journal={Journal of Global Optimization},
  volume={67},
  number={1},
  pages={263--282},
  year={2017},
  publisher={Springer}
}

% Scalable BO
@inproceedings{snoek2015scalable,
  title={Scalable bayesian optimization using deep neural networks},
  author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Mostofa and Prabhat, Mr and Adams, Ryan},
  booktitle=icml,
  //pages={2171--2180},
  year={2015}
}

@inproceedings{springenberg2016bayesian,
  title={Bayesian optimization with robust bayesian neural networks},
  author={Springenberg, Jost Tobias and Klein, Aaron and Falkner, Stefan and Hutter, Frank},
  booktitle=nips,
  //pages={4134--4142},
  year={2016}
}

@inproceedings{wang2018batched,
  title={Batched large-scale bayesian optimization in high-dimensional spaces},
  author={Wang, Zi and Gehring, Clement and Kohli, Pushmeet and Jegelka, Stefanie},
  booktitle=aistats,
  //pages={745--754},
  year={2018}
}

@inproceedings{eriksson2019scalable,
  title={Scalable global optimization via local bayesian optimization},
  author={Eriksson, David and Pearce, Michael and Gardner, Jacob and Turner, Ryan D and Poloczek, Matthias},
  booktitle=nips,
  year={2019}
}


%Batch BO

@inproceedings{contal2013parallel,
  title={Parallel gaussian process optimization with upper confidence bound and pure exploration},
  author={Contal, E and Buffoni, D and Robicquet, A and Vayatis, N},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={225--240},
  year={2013},
  organization={Springer}
}

@article{desautels2014parallelizing,
  title={Parallelizing exploration-exploitation tradeoffs in gaussian process bandit optimization},
  author={Desautels, T and Krause, A and Burdick, J},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={3873--3923},
  year={2014},
  publisher={JMLR. org}
}

% entropy guided BO
@article{villemonteix2009informational,
  title={An informational approach to the global optimization of expensive-to-evaluate functions},
  author={Villemonteix, Julien and Vazquez, Emmanuel and Walter, Eric},
  journal={Journal of Global Optimization},
  volume={44},
  number={4},
  pages={509--534},
  year={2009},
  publisher={Springer}
}

@article{hennig2012entropy,
  title={Entropy Search for Information-Efficient Global Optimization},
  author={Hennig, Philipp and Schuler, Christian J},
  journal={Journal of Machine Learning Research},
  volume={13},
  number={6},
  year={2012}
}

@inproceedings{hernandez2014predictive,
  title={Predictive Entropy Search for Efficient Global Optimization of Black-box Functions},
  author={Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Hoffman, Matthew W and Ghahramani, Zoubin},
  booktitle=nips,
  //volume={27},
  //pages={918--926},
  year={2014}
}

@inproceedings{hoffman2015output,
  title={Output-space predictive entropy search for flexible global optimization},
  author={Hoffman, Matthew W and Ghahramani, Zoubin},
  booktitle={NeurIPS Workshop on Bayesian Optimization},
  year={2015}
}

@inproceedings{wang2017max,
  title={Max-value entropy search for efficient Bayesian optimization},
  author={Wang, Zi and Jegelka, Stefanie},
  booktitle=icml,
  //pages={3627--3635},
  //organization={PMLR},
  year={2017}
}

% Theory for BO
@inproceedings{kawaguchi2015bayesian,
  title={Bayesian optimization with exponential convergence},
  author={Kawaguchi, Kenji and Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
  year={2015},
  booktitle=nips,
}


%%% Classical MOBO %%%
@inproceedings{khan2002multi,
  title={Multi-objective Bayesian optimization algorithm},
  author={Khan, Nazan and Goldberg, David E and Pelikan, Martin},
  booktitle=gecco,
  pages={684--684},
  year={2002},
  organization={Citeseer}
}

@inproceedings{laumanns2002bayesian,
  title={Bayesian optimization algorithms for multi-objective optimization},
  author={Laumanns, Marco and Ocenasek, Jiri},
  booktitle=ppsn,
  //pages={298--307},
  year={2002},
  //organization={Springer}
}

%%% MOBO in EC %%%
@article{knowles2006parego,
  title={{ParEGO}: A hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems},
  author={Knowles, J},
  journal={IEEE Transactions on Evolutionary Computation},
  volume={10},
  number={1},
  pages={50--66},
  year={2006},
  publisher={IEEE}
}

@article{emmerich2006single,
  title={Single-and multiobjective evolutionary optimization assisted by Gaussian random field metamodels},
  author={Emmerich, M and Giannakoglou, K and Naujoks, B},
  journal={IEEE Transactions on Evolutionary Computation},
  volume={10},
  number={4},
  pages={421--439},
  year={2006},
  publisher={IEEE}
}


@article{emmerich2008computation,
  title={The computation of the expected improvement in dominated hypervolume of Pareto front approximations},
  author={Emmerich, M and Klinkenberg, J},
  journal={Rapport technique, Leiden University},
  volume={34},
  year={2008}
}

@inproceedings{ponweiser2008multiobjective,
  title={Multiobjective Optimization on a Limited Budget of Evaluations Using Model-Assisted S-Metric Selection},
  author={Ponweiser, Wolfgang and Wagner, Tobias and Biermann, Dirk and Vincze, Markus},
  booktitle=ppsn,
  //pages={784--794},
  year={2008},
  //organization={Springer}
}

@article{zhang2010expensive,
  title={Expensive multiobjective optimization by MOEA/D with Gaussian process model},
  author={Zhang, Qingfu and Liu, Wudong and Tsang, Edward and Virginas, Botond},
  journal={IEEE Transactions on Evolutionary Computation},
  volume={14},
  number={3},
  pages={456--474},
  year={2010},
  publisher={IEEE}
}

@inproceedings{lin2017efficient,
  title={An efficient batch expensive multi-objective evolutionary algorithm based on Decomposition},
  author={Lin, Xi and Zhang, Qingfu and Kwong, Sam},
  booktitle={IEEE Congress on Evolutionary Computation},
  pages={1343--1349},
  year={2017},
}


%%% MOBO in ML %%%

@inproceedings{zuluaga2013active,
  title={Active learning for multi-objective optimization},
  author={Zuluaga, Marcela and Sergent, Guillaume and Krause, Andreas and P{\"u}schel, Markus},
  booktitle=icml,
  //pages={462--470},
  year={2013}
}

@article{zuluaga2016varepsilon,
  title={$\varepsilon$-pal: an active learning approach to the multi-objective optimization problem},
  author={Zuluaga, Marcela and Krause, Andreas and P{\"u}schel, Markus},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={3619--3650},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{auer2016pareto,
  title={Pareto front identification from stochastic bandit feedback},
  author={Auer, Peter and Chiang, Chao-Kai and Ortner, Ronald and Drugan, Madalina},
  booktitle={Artificial Intelligence and Statistics},
  pages={939--947},
  year={2016}
}

@inproceedings{shah2016pareto,
  title={Pareto frontier learning with expensive correlated objectives},
  author={Shah, Amar and Ghahramani, Zoubin},
  booktitle=icml,
  year={2016},
  //pages={1919--1927},
}



@inproceedings{paria2020flexible,
  title={A flexible framework for multi-objective bayesian optimization using random scalarizations},
  author={Paria, Biswajit and Kandasamy, Kirthevasan and P{\'o}czos, Barnab{\'a}s},
  booktitle=uai,
  year={2020},
  //pages={766--776},
  //organization={PMLR}
}

@inproceedings{hernandez2016predictive,
  title={Predictive entropy search for multi-objective bayesian optimization},
  author={Hern{\'a}ndez-Lobato, Daniel and Hernandez-Lobato, Jose and Shah, Amar and Adams, Ryan},
  booktitle=icml,
  year={2016},
  //pages={1492--1501},
  //organization={PMLR}
}

@inproceedings{belakaria2019max,
  title={Max-value entropy search for multi-objective bayesian optimization},
  author={Belakaria, Syrine and Deshwal, Aryan},
  booktitle=nips,
  year={2019}
}

@inproceedings{suzuki2020multi,
  title={Multi-objective Bayesian optimization using Pareto-frontier entropy},
  author={Suzuki, Shinya and Takeno, Shion and Tamura, Tomoyuki and Shitara, Kazuki and Karasuyama, Masayuki},
  booktitle=icml,
  year={2020},
  //pages={9279--9288},
  //organization={PMLR}
}

% Multi-Fidelity BO
@inproceedings{wu2020practical,
  title={Practical multi-fidelity bayesian optimization for hyperparameter tuning},
  author={Wu, Jian and Toscano-Palmerin, Saul and Frazier, Peter I and Wilson, Andrew Gordon},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={788--798},
  year={2020},
  organization={PMLR}
}

% Thompson Sampling
@article{bradford2018efficient,
  title={Efficient multiobjective optimization employing Gaussian processes, spectral sampling and a genetic algorithm},
  author={Bradford, Eric and Schweidtmann, Artur M and Lapkin, Alexei},
  journal={Journal of global optimization},
  volume={71},
  number={2},
  pages={407--438},
  year={2018},
  publisher={Springer}
}

% Uncertainty
@inproceedings{belakaria2020uncertainty,
  title={Uncertainty-aware search framework for multi-objective Bayesian optimization},
  author={Belakaria, Syrine and Deshwal, Aryan and Jayakodi, Nitthilan Kannappan and Doppa, Janardhan Rao},
  booktitle=aaai,
  //volume={34},
  //pages={10044--10052},
  year={2020}
}

@inproceedings{abdolshah2019multi,
 title = {Multi-objective Bayesian optimisation with preferences over objectives},
 author = {Abdolshah, Majid and Shilton, Alistair and Rana, Santu and Gupta, Sunil and Venkatesh, Svetha},
 booktitle = nips,
 year = {2019}
}

@inproceedings{astudillo2020multi,
  title={Multi-attribute Bayesian optimization with interactive preference learning},
  author={Astudillo, Raul and Frazier, Peter},
  booktitle=aistats,
  //pages={4496--4507},
  year={2020}
}

@inproceedings{lukovic2020diversity,
  title={Diversity-Guided Multi-Objective Bayesian Optimization With Batch Evaluations},
  author={Lukovic, Mina Konakovic and Tian, Yunsheng and Matusik, Wojciech},
  booktitle=nips,
  year={2020},
  //volume={33},
  //pages={6--12},
}

@inproceedings{daulton2020differentiable,
  title={Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization},
  author={Daulton, Samuel and Balandat, Maximilian and Bakshy, Eytan},
  booktitle=nips,
  year={2020},
  //volume={33},
}

@inproceedings{daulton2021parallel,
  title={Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement},
  author={Daulton, Samuel and Balandat, Maximilian and Bakshy, Eytan},
  booktitle=nips,
  year={2021}
}

@inproceedings{malkomes2021beyond,
  title={Beyond the Pareto Efficient Frontier: Constraint Active Search for Multiobjective Experimental Design},
  author={Malkomes, Gustavo and Cheng, Bolong and Lee, Eric H and Mccourt, Mike},
  booktitle=icml,
  year={2021},
  //pages={7423--7434},
  //organization={PMLR}
}

@inproceedings{daulton2022robust,
  title={Robust Multi-Objective Bayesian Optimization Under Input Noise},
  author={Daulton, Samuel and Cakmak, Sait and Balandat, Maximilian and Osborne, Michael A and Zhou, Enlu and Bakshy, Eytan},
  booktitle=icml,
  year={2022}
}

@inproceedings{daulton2022multi,
  title={Multi-objective bayesian optimization over high-dimensional search spaces},
  author={Daulton, Samuel and Eriksson, David and Balandat, Maximilian and Bakshy, Eytan},
  booktitle=uai,
  pages={507--517},
  year={2022},
  organization={PMLR}
}



%%% Models %%%

% Structure Model

@inproceedings{lopez2018easing,
  title={Easing non-convex optimization with neural networks},
  author={Lopez-Paz, David and Sagun, Levent},
  booktitle=iclrw,
  year={2018}
}

@inproceedings{sener2020learning,
  title={Learning to Guide Random Search},
  author={Sener, Ozan and Koltun, Vladlen},
  booktitle=iclr,
  year={2020}
}

@inproceedings{wang2020learning,
 author = {Wang, Linnan and Fonseca, Rodrigo and Tian, Yuandong},
 booktitle = nips,
 //pages = {19511--19522},
 title = {Learning Search Space Partition for Black-box Optimization using Monte Carlo Tree Search},
 //volume = {33},
 year = {2020}
}

@inproceedings{zhao2022multi,
  title={Multi-objective Optimization by Learning Space Partitions},
  author={Zhao, Yiyang and Wang, Linnan and Yang, Kevin and Zhang, Tianjun and Guo, Tian and Tian, Yuandong},
  booktitle = iclr,
  year={2022}
}

% latent space
@article{gomez2018automatic,
  title={Automatic chemical design using a data-driven continuous representation of molecules},
  author={G{\'o}mez-Bombarelli, Rafael and Wei, Jennifer N and Duvenaud, David and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and S{\'a}nchez-Lengeling, Benjam{\'\i}n and Sheberla, Dennis and Aguilera-Iparraguirre, Jorge and Hirzel, Timothy D and Adams, Ryan P and Aspuru-Guzik, Al{\'a}n},
  journal={ACS central science},
  volume={4},
  number={2},
  pages={268--276},
  year={2018},
  publisher={ACS Publications}
}

@inproceedings{tripp2020sample,
  title={Sample-efficient optimization in the latent space of deep generative models via weighted retraining},
  author={Tripp, Austin and Daxberger, Erik and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel},
  booktitle=nips,
  //volume={33},
  year={2020}
}

% Gaussian Process
@book{rasmussen2006gaussian,
  title={Gaussian processes for machine learning},
  author={Rasmussen, Carl Edward and Williams, Christopher KI},
  year={2006},
  publisher={{MIT} Press}
}

%GP with Gradient
@inproceedings{solak2003derivative,
  title={Derivative observations in Gaussian process models of dynamic systems},
  author={Solak, E and Murray-Smith, R and Leithead, W and Leith, D and Rasmussen, C},
  booktitle=nips,
  //pages={1057--1064},
  year={2003}
}

@article{wu2017exploiting,
  title={Exploiting gradients and Hessians in Bayesian optimization and Bayesian quadrature},
  author={Wu, A and Aoi, M and Pillow, J},
  journal={arXiv preprint arXiv:1704.00060},
  year={2017}
}

@article{ahmed2016we,
  title={Do we need “harmless” bayesian optimization and “first-order” bayesian optimization},
  author={Ahmed, Mohamed Osama and Shahriari, Bobak and Schmidt, Mark},
  journal=nipsw,
  year={2016}
}

%Scalable GP:
@inproceedings{deisenroth2015distributed,
  title={Distributed Gaussian Processes},
  author={Deisenroth, Marc and Ng, Jun Wei},
  booktitle={International Conference on Machine Learning},
  pages={1481--1490},
  year={2015}
}

@inproceedings{wilson2016deep,
  title={Deep kernel learning},
  author={Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P},
  booktitle={Artificial Intelligence and Statistics},
  pages={370--378},
  year={2016}
}

@article{gardner2018product,
  title={Product Kernel Interpolation for Scalable Gaussian Processes},
  author={Gardner, Jacob R and Pleiss, Geoff and Wu, Ruihan and Weinberger, Kilian Q and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:1802.08903},
  year={2018}
}


%%% DNN for GP %%%
@inproceedings{lee2018deep,
	title="Deep Neural Networks as Gaussian Processes",
	author="Jaehoon {Lee} and Jascha {Sohl-dickstein} and Jeffrey {Pennington} and Roman {Novak} and Sam {Schoenholz} and Yasaman {Bahri}",
	booktitle="ICLR 2018 : International Conference on Learning Representations 2018",
	year="2018"
}

@inproceedings{khan2019approximate,
	title="Approximate Inference Turns Deep Networks into Gaussian Processes",
	author="Mohammad Emtiyaz {Khan} and Alexander {Immer} and Ehsan {Abedi} and Maciej Jan {Korzepa}",
	booktitle="NeurIPS 2019 : Thirty-third Conference on Neural Information Processing Systems",
	year="2019"
}

%Bayesian NN
@article{mackay1992practical,
  title={A practical Bayesian framework for backpropagation networks},
  author={MacKay, D},
  journal={Neural computation},
  volume={4},
  number={3},
  pages={448--472},
  year={1992},
  publisher={MIT Press}
}

@book{neal2012bayesian,
  title={Bayesian learning for neural networks},
  author={Neal, R},
  volume={118},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@inproceedings{graves2011practical,
  title={Practical variational inference for neural networks},
  author={Graves, A},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2348--2356},
  year={2011}
}

@article{blundell2015weight,
  title={Weight uncertainty in neural networks},
  author={Blundell, C and Cornebise, J and Kavukcuoglu, K and Wierstra, D},
  journal={arXiv preprint arXiv:1505.05424},
  year={2015}
}

@inproceedings{kingma2015variational,
  title={Variational dropout and the local reparameterization trick},
  author={Kingma, D and Salimans, T and Welling, M},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2575--2583},
  year={2015}
}

@inproceedings{gal2016dropout,
  title={Dropout as a Bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Y and Ghahramani, Z},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016}
}

@article{gal2016uncertainty,
  title={Uncertainty in deep learning},
  author={Gal, Y},
  journal={University of Cambridge},
  year={2016}
}

%%% BO Applications %%%

% materials design
@inbook{frazier2016bayesian,
  title={Bayesian optimization for materials design},
  author={Frazier, Peter I and Wang, Jialei},
  booktitle={Information science for materials discovery and design},
  pages={45--75},
  year={2016},
  publisher={Springer}
}

% could machine learning 

@inproceedings{golovin2017google,
  title={Google vizier: A service for black-box optimization},
  author={Golovin, Daniel and Solnik, Benjamin and Moitra, Subhodeep and Kochanski, Greg and Karro, John and Sculley, David},
  booktitle={Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1487--1495},
  year={2017}
}

% Online System
@article{letham2019bayesian,
  title={Bayesian Optimization for Policy Search via Online-Offline Experimentation.},
  author={Letham, Benjamin and Bakshy, Eytan},
  journal={J. Mach. Learn. Res.},
  volume={20},
  pages={145--1},
  year={2019}
}

% chemical synthesis
@article{shields2021bayesian,
  title={Bayesian reaction optimization as a tool for chemical synthesis},
  author={Shields, Benjamin J and Stevens, Jason and Li, Jun and Parasram, Marvin and Damani, Farhan and Alvarado, Jesus I Martinez and Janey, Jacob M and Adams, Ryan P and Doyle, Abigail G},
  journal={Nature},
  volume={590},
  number={7844},
  pages={89--96},
  year={2021},
  publisher={Nature Publishing Group}
}

%%% MOBO Applications %%%

% MO-NAS
@article{eriksson2021latency,
  title={Latency-Aware Neural Architecture Search with Multi-Objective Bayesian Optimization},
  author={Eriksson, David and Chuang, Pierce I-Jen and Daulton, Sam and Aly, Ahmed and Babu, Arun and Shrivastava, Akshat and Xia, Peng and Zhao, Shicong and Venkatesh, Ganesh and Balandat, Maximilian},
  journal={arXiv preprint arXiv:2106.11890},
  year={2021}
}

% particle accelerator tuning
@article{roussel2021multiobjective,
  title={Multiobjective Bayesian optimization for online accelerator tuning},
  author={Roussel, Ryan and Hanuka, Adi and Edelen, Auralee},
  journal={Physical Review Accelerators and Beams},
  volume={24},
  number={6},
  pages={062801},
  year={2021},
  publisher={APS}
}

% material design
@article{jablonka2021bias,
  title={Bias free multiobjective active learning for materials design and discovery},
  author={Jablonka, Kevin Maik and Jothiappan, Giriprasad Melpatti and Wang, Shefang and Smit, Berend and Yoo, Brian},
  journal={Nature Communications},
  volume={12},
  number={1},
  pages={1--10},
  year={2021},
  publisher={Nature Publishing Group}
}


% packages

@article{balandat2020botorch,
  title={BoTorch: A framework for efficient Monte-Carlo Bayesian optimization},
  author={Balandat, Maximilian and Karrer, Brian and Jiang, Daniel and Daulton, Samuel and Letham, Benjamin and Wilson, Andrew Gordon and Bakshy, Eytan},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2020}
}


% Latin hypercube sampling 
@article{mckay2000comparison,
  title={A comparison of three methods for selecting values of input variables in the analysis of output from a computer code},
  author={McKay, Michael D and Beckman, Richard J and Conover, William J},
  journal={Technometrics},
  volume={42},
  number={1},
  pages={55--61},
  year={2000},
  publisher={Taylor \& Francis}
}