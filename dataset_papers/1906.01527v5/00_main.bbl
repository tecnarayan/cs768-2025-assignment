\begin{thebibliography}{10}

\bibitem{bartlett2017spectrally}
Peter~L Bartlett, Dylan~J Foster, and Matus~J Telgarsky.
\newblock Spectrally-normalized margin bounds for neural networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6241--6250, 2017.

\bibitem{bertsimas2018characterization}
Dimitris Bertsimas and Martin~S Copenhaver.
\newblock Characterization of the equivalence of robustification and
  regularization in linear and matrix regression.
\newblock {\em European Journal of Operational Research}, 270(3):931--942,
  2018.

\bibitem{bietti2019kernel}
Alberto Bietti, Gr{\'e}goire Mialon, Dexiong Chen, and Julien Mairal.
\newblock A kernel perspective for regularizing deep neural networks.
\newblock In {\em International Conference on Machine Learning}, pages
  664--674. PMLR, 2019.

\bibitem{biggio2013evasion}
Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim Srndic,
  Pavel Laskov, Giorgio Giacinto, and Fabio Roli.
\newblock Evasion attacks against machine learning at test time.
\newblock In {\em Joint European conference on machine learning and knowledge
  discovery in databases}, pages 387--402. Springer, 2013.

\bibitem{boyd1974power}
David~W Boyd.
\newblock The power method for lp norms.
\newblock {\em Linear Algebra and its Applications}, 9:95--101, 1974.

\bibitem{bubeck2019adversarial}
S{\'e}bastien Bubeck, Yin~Tat Lee, Eric Price, and Ilya Razenshteyn.
\newblock Adversarial examples from computational constraints.
\newblock In {\em International Conference on Machine Learning}, pages
  831--840, 2019.

\bibitem{carlini2017adversarial}
Nicholas Carlini and David Wagner.
\newblock Adversarial examples are not easily detected: Bypassing ten detection
  methods.
\newblock In {\em Proceedings of the 10th ACM Workshop on Artificial
  Intelligence and Security}, pages 3--14. ACM, 2017.

\bibitem{cisse2017parseval}
Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, and Nicolas
  Usunier.
\newblock Parseval networks: Improving robustness to adversarial examples.
\newblock In {\em International Conference on Machine Learning}, pages
  854--863, 2017.

\bibitem{el1997robust}
Laurent El~Ghaoui and Herv{\'e} Lebret.
\newblock Robust solutions to least-squares problems with uncertain data.
\newblock {\em SIAM Journal on matrix analysis and applications},
  18(4):1035--1064, 1997.

\bibitem{farnia2018generalizable}
Farzan Farnia, Jesse~M Zhang, and David Tse.
\newblock Generalizable adversarial training via spectral normalization.
\newblock {\em arXiv preprint arXiv:1811.07457}, 2018.

\bibitem{fawzi2018adversarial}
Alhussein Fawzi, Hamza Fawzi, and Omar Fawzi.
\newblock Adversarial vulnerability for any classifier.
\newblock In {\em Advances in neural information processing systems}, pages
  1178--1187, 2018.

\bibitem{fawzi2018analysis}
Alhussein Fawzi, Omar Fawzi, and Pascal Frossard.
\newblock Analysis of classifiersâ€™ robustness to adversarial perturbations.
\newblock {\em Springer Machine Learning}, 107(3):481--508, 2018.

\bibitem{fawzi2016robustness}
Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard.
\newblock Robustness of classifiers: from adversarial to random noise.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1632--1640, 2016.

\bibitem{feinman2017detecting}
Reuben Feinman, Ryan~R Curtin, Saurabh Shintre, and Andrew~B Gardner.
\newblock Detecting adversarial samples from artifacts.
\newblock {\em arXiv preprint arXiv:1703.00410}, 2017.

\bibitem{gao2016distributionally}
Rui Gao and Anton~J Kleywegt.
\newblock Distributionally robust stochastic optimization with wasserstein
  distance.
\newblock {\em arXiv preprint arXiv:1604.02199}, 2016.

\bibitem{gilmer2018adversarial}
Justin Gilmer, Luke Metz, Fartash Faghri, Samuel~S Schoenholz, Maithra Raghu,
  Martin Wattenberg, and Ian Goodfellow.
\newblock Adversarial spheres.
\newblock {\em arXiv preprint arXiv:1801.02774}, 2018.

\bibitem{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em arXiv preprint arXiv:1412.6572}, 2014.

\bibitem{grosse2017statistical}
Kathrin Grosse, Praveen Manoharan, Nicolas Papernot, Michael Backes, and
  Patrick McDaniel.
\newblock On the (statistical) detection of adversarial examples.
\newblock {\em arXiv preprint arXiv:1702.06280}, 2017.

\bibitem{gu2014towards}
Shixiang Gu and Luca Rigazio.
\newblock Towards deep neural network architectures robust to adversarial
  examples.
\newblock {\em arXiv preprint arXiv:1412.5068}, 2014.

\bibitem{hein2017formal}
Matthias Hein and Maksym Andriushchenko.
\newblock Formal guarantees on the robustness of a classifier against
  adversarial manipulation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2266--2276, 2017.

\bibitem{higham1992estimating}
Nicholas~J Higham.
\newblock Estimating the matrixp-norm.
\newblock {\em Numerische Mathematik}, 62(1):539--555, 1992.

\bibitem{kannan2018adversarial}
Harini Kannan, Alexey Kurakin, and Ian Goodfellow.
\newblock Adversarial logit pairing.
\newblock {\em arXiv preprint arXiv:1803.06373}, 2018.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky and Geoffrey Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{kurakin2016adversarial}
Alexey Kurakin, Ian Goodfellow, and Samy Bengio.
\newblock Adversarial examples in the physical world.
\newblock {\em arXiv preprint arXiv:1607.02533}, 2016.

\bibitem{lyu2015unified}
Chunchuan Lyu, Kaizhu Huang, and Hai-Ning Liang.
\newblock A unified gradient regularization family for adversarial examples.
\newblock In {\em 2015 IEEE International Conference on Data Mining}, pages
  301--309. IEEE, 2015.

\bibitem{madry2018towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{metzen2017detecting}
Jan~Hendrik Metzen, Tim Genewein, Volker Fischer, and Bastian Bischoff.
\newblock On detecting adversarial perturbations.
\newblock {\em arXiv preprint arXiv:1702.04267}, 2017.

\bibitem{miyato2018spectral}
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida.
\newblock Spectral normalization for generative adversarial networks.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{miyato2018virtual}
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii.
\newblock Virtual adversarial training: a regularization method for supervised
  and semi-supervised learning.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  41(8):1979--1993, 2018.

\bibitem{miyato2015distributional}
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, Ken Nakae, and Shin Ishii.
\newblock Distributional smoothing with virtual adversarial training.
\newblock {\em arXiv preprint arXiv:1507.00677}, 2015.

\bibitem{moosavi2016deepfool}
Seyed~Mohsen Moosavi~Dezfooli, Alhussein Fawzi, and Pascal Frossard.
\newblock Deepfool: a simple and accurate method to fool deep neural networks.
\newblock In {\em Proceedings of 2016 IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, number EPFL-CONF-218057, 2016.

\bibitem{namkoong2017variance}
Hongseok Namkoong and John~C Duchi.
\newblock Variance-based regularization with convex objectives.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2975--2984, 2017.

\bibitem{novak2018sensitivity}
Roman Novak, Yasaman Bahri, Daniel~A Abolafia, Jeffrey Pennington, and Jascha
  Sohl-Dickstein.
\newblock Sensitivity and generalization in neural networks: an empirical
  study.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{papernot2017cleverhans}
Nicolas Papernot, Nicholas Carlini, Ian Goodfellow, Reuben Feinman, Fartash
  Faghri, Alexander Matyasko, Karen Hambardzumyan, Yi-Lin Juang, Alexey
  Kurakin, Ryan Sheatsley, Abhibhav Garg, and Yen-Chen Lin.
\newblock cleverhans v2.0.0: an adversarial machine learning library.
\newblock {\em arXiv preprint arXiv:1610.00768}, 2017.

\bibitem{papernot2016transferability}
Nicolas Papernot, Patrick McDaniel, and Ian Goodfellow.
\newblock Transferability in machine learning: from phenomena to black-box
  attacks using adversarial samples.
\newblock {\em arXiv preprint arXiv:1605.07277}, 2016.

\bibitem{raghu2017expressive}
Maithra Raghu, Ben Poole, Jon Kleinberg, Surya Ganguli, and Jascha~Sohl
  Dickstein.
\newblock On the expressive power of deep neural networks.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 2847--2854. JMLR. org, 2017.

\bibitem{raghunathan2018certified}
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
\newblock Certified defenses against adversarial examples.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{roth2019odds}
Kevin Roth, Yannic Kilcher, and Thomas Hofmann.
\newblock The odds are odd: A statistical test for detecting adversarial
  examples.
\newblock In {\em International Conference on Machine Learning}, pages
  5498--5507, 2019.

\bibitem{sabour2015adversarial}
Sara Sabour, Yanshuai Cao, Fartash Faghri, and David~J Fleet.
\newblock Adversarial manipulation of deep representations.
\newblock {\em arXiv preprint arXiv:1511.05122}, 2015.

\bibitem{schmidt2018adversarially}
Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, and
  Aleksander Madry.
\newblock Adversarially robust generalization requires more data.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5014--5026, 2018.

\bibitem{shaham2018understanding}
Uri Shaham, Yutaro Yamada, and Sahand Negahban.
\newblock Understanding adversarial training: Increasing local stability of
  supervised models through robust optimization.
\newblock {\em Neurocomputing}, 307:195--204, 2018.

\bibitem{sinha2018certifying}
Aman Sinha, Hongseok Namkoong, and John Duchi.
\newblock Certifying some distributional robustness with principled adversarial
  training.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock {\em arXiv preprint arXiv:1312.6199}, 2013.

\bibitem{tanay2016boundary}
Thomas Tanay and Lewis Griffin.
\newblock A boundary tilting persepective on the phenomenon of adversarial
  examples.
\newblock {\em arXiv preprint arXiv:1608.07690}, 2016.

\bibitem{tropp2004topics}
Joel~Aaron Tropp.
\newblock {\em Topics in sparse approximation}.
\newblock PhD thesis, 2004.

\bibitem{tsuzuku2018lipschitz}
Yusuke Tsuzuku, Issei Sato, and Masashi Sugiyama.
\newblock Lipschitz-margin training: Scalable certification of perturbation
  invariance for deep neural networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6541--6550, 2018.

\bibitem{wong2019wasserstein}
Eric Wong, Frank Schmidt, and Zico Kolter.
\newblock Wasserstein adversarial examples via projected sinkhorn iterations.
\newblock In {\em International Conference on Machine Learning}, pages
  6808--6817, 2019.

\bibitem{xu2009robustness}
Huan Xu, Constantine Caramanis, and Shie Mannor.
\newblock Robustness and regularization of support vector machines.
\newblock {\em Journal of Machine Learning Research}, 10(Jul):1485--1510, 2009.

\bibitem{xu2017feature}
Weilin Xu, David Evans, and Yanjun Qi.
\newblock Feature squeezing: Detecting adversarial examples in deep neural
  networks.
\newblock {\em arXiv preprint arXiv:1704.01155}, 2017.

\bibitem{yoshida2017spectral}
Yuichi Yoshida and Takeru Miyato.
\newblock Spectral norm regularization for improving the generalizability of
  deep learning.
\newblock {\em arXiv preprint arXiv:1705.10941}, 2017.

\bibitem{zagoruyko2016wide}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock {\em arXiv preprint arXiv:1605.07146}, 2016.

\end{thebibliography}
