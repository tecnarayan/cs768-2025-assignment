\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Agarwal, Barham, Brevdo, Chen, Citro,
  Corrado, Davis, Dean, Devin, et~al.]{abadi2016tensorflow}
Abadi, Mart{\'\i}n, Agarwal, Ashish, Barham, Paul, Brevdo, Eugene, Chen,
  Zhifeng, Citro, Craig, Corrado, Greg~S, Davis, Andy, Dean, Jeffrey, Devin,
  Matthieu, et~al.
\newblock Tensorflow: Large-scale machine learning on heterogeneous distributed
  systems.
\newblock \emph{arXiv preprint arXiv:1603.04467}, 2016.

\bibitem[Baker et~al.(2016)Baker, Gupta, Naik, and Raskar]{baker2016designing}
Baker, Bowen, Gupta, Otkrist, Naik, Nikhil, and Raskar, Ramesh.
\newblock Designing neural network architectures using reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.02167}, 2016.

\bibitem[Bayer et~al.(2009)Bayer, Wierstra, Togelius, and
  Schmidhuber]{bayer2009evolving}
Bayer, Justin, Wierstra, Daan, Togelius, Julian, and Schmidhuber, J{\"u}rgen.
\newblock Evolving memory cell structures for sequence learning.
\newblock In \emph{International Conference on Artificial Neural Networks},
  pp.\  755--764. Springer, 2009.

\bibitem[Bergstra \& Bengio(2012)Bergstra and Bengio]{bergstra2012random}
Bergstra, James and Bengio, Yoshua.
\newblock Random search for hyper-parameter optimization.
\newblock \emph{Journal of Machine Learning Research}, 13\penalty0
  (Feb):\penalty0 281--305, 2012.

\bibitem[Breuel \& Shafait(2010)Breuel and Shafait]{breuel2010automlp}
Breuel, Thomas and Shafait, Faisal.
\newblock Automlp: Simple, effective, fully automated learning rate and size
  adjustment.
\newblock In \emph{The Learning Workshop}. Utah, 2010.

\bibitem[Fernando et~al.(2016)Fernando, Banarse, Reynolds, Besse, Pfau,
  Jaderberg, Lanctot, and Wierstra]{fernando2016convolution}
Fernando, Chrisantha, Banarse, Dylan, Reynolds, Malcolm, Besse, Frederic, Pfau,
  David, Jaderberg, Max, Lanctot, Marc, and Wierstra, Daan.
\newblock Convolution by evolution: Differentiable pattern producing networks.
\newblock In \emph{Proceedings of the 2016 on Genetic and Evolutionary
  Computation Conference}, pp.\  109--116. ACM, 2016.

\bibitem[Goldberg \& Deb(1991)Goldberg and Deb]{goldberg1991comparative}
Goldberg, David~E and Deb, Kalyanmoy.
\newblock A comparative analysis of selection schemes used in genetic
  algorithms.
\newblock \emph{Foundations of genetic algorithms}, 1:\penalty0 69--93, 1991.

\bibitem[Goldberg et~al.(1987)Goldberg, Richardson,
  et~al.]{goldberg1987genetic}
Goldberg, David~E, Richardson, Jon, et~al.
\newblock Genetic algorithms with sharing for multimodal function optimization.
\newblock In \emph{Genetic algorithms and their applications: Proceedings of
  the Second International Conference on Genetic Algorithms}, pp.\  41--49.
  Hillsdale, NJ: Lawrence Erlbaum, 1987.

\bibitem[Goodfellow et~al.(2013)Goodfellow, Warde-Farley, Mirza, Courville, and
  Bengio]{goodfellow2013maxout}
Goodfellow, Ian~J, Warde-Farley, David, Mirza, Mehdi, Courville, Aaron~C, and
  Bengio, Yoshua.
\newblock Maxout networks.
\newblock \emph{International Conference on Machine Learning}, 28:\penalty0
  1319--1327, 2013.

\bibitem[Gruau(1993)]{gruau1993genetic}
Gruau, Frederic.
\newblock Genetic synthesis of modular neural networks.
\newblock In \emph{Proceedings of the 5th International Conference on Genetic
  Algorithms}, pp.\  318--325. Morgan Kaufmann Publishers Inc., 1993.

\bibitem[Han et~al.(2015)Han, Pool, Tran, and Dally]{han2015learning}
Han, Song, Pool, Jeff, Tran, John, and Dally, William.
\newblock Learning both weights and connections for efficient neural network.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1135--1143, 2015.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{he2015delving}
He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, and Sun, Jian.
\newblock Delving deep into rectifiers: Surpassing human-level performance on
  imagenet classification.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  1026--1034, 2015.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, and Sun, Jian.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  770--778, 2016.

\bibitem[Huang et~al.(2016{\natexlab{a}})Huang, Liu, Weinberger, and van~der
  Maaten]{huang2016densely}
Huang, Gao, Liu, Zhuang, Weinberger, Kilian~Q, and van~der Maaten, Laurens.
\newblock Densely connected convolutional networks.
\newblock \emph{arXiv preprint arXiv:1608.06993}, 2016{\natexlab{a}}.

\bibitem[Huang et~al.(2016{\natexlab{b}})Huang, Sun, Liu, Sedra, and
  Weinberger]{huang2016deep}
Huang, Gao, Sun, Yu, Liu, Zhuang, Sedra, Daniel, and Weinberger, Kilian~Q.
\newblock Deep networks with stochastic depth.
\newblock In \emph{European Conference on Computer Vision}, pp.\  646--661.
  Springer, 2016{\natexlab{b}}.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{ioffe2015batch}
Ioffe, Sergey and Szegedy, Christian.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{arXiv preprint arXiv:1502.03167}, 2015.

\bibitem[Kim \& Rigazio(2015)Kim and Rigazio]{kim2015deep}
Kim, Minyoung and Rigazio, Luca.
\newblock Deep clustered convolutional kernels.
\newblock \emph{arXiv preprint arXiv:1503.01824}, 2015.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and
  Hinton]{krizhevsky2009learning}
Krizhevsky, Alex and Hinton, Geoffrey.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Krizhevsky, Alex, Sutskever, Ilya, and Hinton, Geoffrey~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1097--1105, 2012.

\bibitem[LeCun et~al.(1998)LeCun, Cortes, and Burges]{lecun1998mnist}
LeCun, Yann, Cortes, Corinna, and Burges, Christopher~JC.
\newblock The mnist database of handwritten digits, 1998.

\bibitem[Lee et~al.(2015)Lee, Xie, Gallagher, Zhang, and Tu]{lee2015deeply}
Lee, Chen-Yu, Xie, Saining, Gallagher, Patrick~W, Zhang, Zhengyou, and Tu,
  Zhuowen.
\newblock Deeply-supervised nets.
\newblock In \emph{AISTATS}, volume~2, pp.\ ~5, 2015.

\bibitem[Lin et~al.(2013)Lin, Chen, and Yan]{lin2013network}
Lin, Min, Chen, Qiang, and Yan, Shuicheng.
\newblock Network in network.
\newblock \emph{arXiv preprint arXiv:1312.4400}, 2013.

\bibitem[Miller et~al.(1989)Miller, Todd, and Hegde]{miller1989designing}
Miller, Geoffrey~F, Todd, Peter~M, and Hegde, Shailesh~U.
\newblock Designing neural networks using genetic algorithms.
\newblock In \emph{Proceedings of the third international conference on Genetic
  algorithms}, pp.\  379--384. Morgan Kaufmann Publishers Inc., 1989.

\bibitem[Morse \& Stanley(2016)Morse and Stanley]{morse2016simple}
Morse, Gregory and Stanley, Kenneth~O.
\newblock Simple evolutionary optimization can rival stochastic gradient
  descent in neural networks.
\newblock In \emph{Proceedings of the 2016 on Genetic and Evolutionary
  Computation Conference}, pp.\  477--484. ACM, 2016.

\bibitem[Pugh \& Stanley(2013)Pugh and Stanley]{pugh2013evolving}
Pugh, Justin~K and Stanley, Kenneth~O.
\newblock Evolving multimodal controllers with hyperneat.
\newblock In \emph{Proceedings of the 15th annual conference on Genetic and
  evolutionary computation}, pp.\  735--742. ACM, 2013.

\bibitem[Rumelhart et~al.(1988)Rumelhart, Hinton, and
  Williams]{rumelhart1988learning}
Rumelhart, David~E, Hinton, Geoffrey~E, and Williams, Ronald~J.
\newblock Learning representations by back-propagating errors.
\newblock \emph{Cognitive Modeling}, 5\penalty0 (3):\penalty0 1, 1988.

\bibitem[Saxena \& Verbeek(2016)Saxena and Verbeek]{saxena2016convolutional}
Saxena, Shreyas and Verbeek, Jakob.
\newblock Convolutional neural fabrics.
\newblock In \emph{Advances In Neural Information Processing Systems}, pp.\
  4053--4061, 2016.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van
  Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot,
  et~al.]{silver2016mastering}
Silver, David, Huang, Aja, Maddison, Chris~J, Guez, Arthur, Sifre, Laurent, Van
  Den~Driessche, George, Schrittwieser, Julian, Antonoglou, Ioannis,
  Panneershelvam, Veda, Lanctot, Marc, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{Nature}, 529\penalty0 (7587):\penalty0 484--489, 2016.

\bibitem[Simmons et~al.(2011)Simmons, Nelson, and Simonsohn]{simmons2011false}
Simmons, Joseph~P, Nelson, Leif~D, and Simonsohn, Uri.
\newblock False-positive psychology: Undisclosed flexibility in data collection
  and analysis allows presenting anything as significant.
\newblock \emph{Psychological Science}, 22\penalty0 (11):\penalty0 1359--1366,
  2011.

\bibitem[Simonyan \& Zisserman(2014)Simonyan and Zisserman]{simonyan2014very}
Simonyan, Karen and Zisserman, Andrew.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{snoek2012practical}
Snoek, Jasper, Larochelle, Hugo, and Adams, Ryan~P.
\newblock Practical bayesian optimization of machine learning algorithms.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2951--2959, 2012.

\bibitem[Springenberg et~al.(2014)Springenberg, Dosovitskiy, Brox, and
  Riedmiller]{springenberg2014striving}
Springenberg, Jost~Tobias, Dosovitskiy, Alexey, Brox, Thomas, and Riedmiller,
  Martin.
\newblock Striving for simplicity: The all convolutional net.
\newblock \emph{arXiv preprint arXiv:1412.6806}, 2014.

\bibitem[Srivastava et~al.(2015)Srivastava, Greff, and
  Schmidhuber]{srivastava2015highway}
Srivastava, Rupesh~Kumar, Greff, Klaus, and Schmidhuber, J{\"u}rgen.
\newblock Highway networks.
\newblock \emph{arXiv preprint arXiv:1505.00387}, 2015.

\bibitem[Stanley(2007)]{stanley2007compositional}
Stanley, Kenneth~O.
\newblock Compositional pattern producing networks: A novel abstraction of
  development.
\newblock \emph{Genetic programming and evolvable machines}, 8\penalty0
  (2):\penalty0 131--162, 2007.

\bibitem[Stanley \& Miikkulainen(2002)Stanley and
  Miikkulainen]{stanley2002evolving}
Stanley, Kenneth~O and Miikkulainen, Risto.
\newblock Evolving neural networks through augmenting topologies.
\newblock \emph{Evolutionary Computation}, 10\penalty0 (2):\penalty0 99--127,
  2002.

\bibitem[Stanley et~al.(2009)Stanley, D'Ambrosio, and
  Gauci]{stanley2009hypercube}
Stanley, Kenneth~O, D'Ambrosio, David~B, and Gauci, Jason.
\newblock A hypercube-based encoding for evolving large-scale neural networks.
\newblock \emph{Artificial Life}, 15\penalty0 (2):\penalty0 185--212, 2009.

\bibitem[Sutskever et~al.(2013)Sutskever, Martens, Dahl, and
  Hinton]{sutskever2013importance}
Sutskever, Ilya, Martens, James, Dahl, George~E, and Hinton, Geoffrey~E.
\newblock On the importance of initialization and momentum in deep learning.
\newblock \emph{ICML (3)}, 28:\penalty0 1139--1147, 2013.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{szegedy2015going}
Szegedy, Christian, Liu, Wei, Jia, Yangqing, Sermanet, Pierre, Reed, Scott,
  Anguelov, Dragomir, Erhan, Dumitru, Vanhoucke, Vincent, and Rabinovich,
  Andrew.
\newblock Going deeper with convolutions.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  1--9, 2015.

\bibitem[Tuson \& Ross(1998)Tuson and Ross]{tuson1998adapting}
Tuson, Andrew and Ross, Peter.
\newblock Adapting operator settings in genetic algorithms.
\newblock \emph{Evolutionary computation}, 6\penalty0 (2):\penalty0 161--184,
  1998.

\bibitem[Verbancsics \& Harguess(2013)Verbancsics and
  Harguess]{verbancsics2013generative}
Verbancsics, Phillip and Harguess, Josh.
\newblock Generative neuroevolution for deep learning.
\newblock \emph{arXiv preprint arXiv:1312.5355}, 2013.

\bibitem[Weinreich \& Chao(2005)Weinreich and Chao]{weinreich2005rapid}
Weinreich, Daniel~M and Chao, Lin.
\newblock Rapid evolutionary escape by large populations from local fitness
  peaks is likely in nature.
\newblock \emph{Evolution}, 59\penalty0 (6):\penalty0 1175--1182, 2005.

\bibitem[Weyand et~al.(2016)Weyand, Kostrikov, and Philbin]{weyand2016planet}
Weyand, Tobias, Kostrikov, Ilya, and Philbin, James.
\newblock Planet-photo geolocation with convolutional neural networks.
\newblock In \emph{European Conference on Computer Vision}, pp.\  37--55.
  Springer, 2016.

\bibitem[Wu et~al.(2016)Wu, Schuster, Chen, Le, Norouzi, et~al.]{wu2016google}
Wu, Yonghui, Schuster, Mike, Chen, Zhifeng, Le, Quoc~V., Norouzi, Mohammad,
  et~al.
\newblock Google's neural machine translation system: Bridging the gap between
  human and machine translation.
\newblock \emph{arXiv preprint arXiv:1609.08144}, 2016.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and
  Komodakis]{zagoruyko2016wide}
Zagoruyko, Sergey and Komodakis, Nikos.
\newblock Wide residual networks.
\newblock \emph{arXiv preprint arXiv:1605.07146}, 2016.

\bibitem[Zaremba(2015)]{zaremba2015empirical}
Zaremba, Wojciech.
\newblock An empirical exploration of recurrent network architectures.
\newblock 2015.

\bibitem[Zoph \& Le(2016)Zoph and Le]{zoph2016neural}
Zoph, Barret and Le, Quoc~V.
\newblock Neural architecture search with reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.01578}, 2016.

\end{thebibliography}
