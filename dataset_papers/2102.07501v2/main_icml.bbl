\begin{thebibliography}{}

\bibitem[Akyildiz and M{\'\i}guez, 2020]{akyildiz2020nudging}
Akyildiz, {\"O}.~D. and M{\'\i}guez, J. (2020).
\newblock Nudging the particle filter.
\newblock {\em Statistics and Computing}, 30(2):305--330.

\bibitem[Barash et~al., 2017]{barash2017gpu}
Barash, L.~Y., Weigel, M., Borovsk{\`y}, M., Janke, W., and Shchur, L.~N.
  (2017).
\newblock {GPU} accelerated population annealing algorithm.
\newblock {\em Computer Physics Communications}, 220:341--350.

\bibitem[Beskos et~al., 2016]{Beskos:2016}
Beskos, A., Jasra, A., Kantas, N., and Thiery, A. (2016).
\newblock On the convergence of adaptive sequential {M}onte {C}arlo methods.
\newblock {\em The Annals of Applied Probability}, 26(2):1111--1146.

\bibitem[Beskos et~al., 2011]{Beskos:2011}
Beskos, A., Pinski, F., Sanz-Serna, J., and Stuart, A. (2011).
\newblock Hybrid {M}onte {C}arlo on {H}ilbert spaces.
\newblock {\em Stochastic Processes and their Applications}, 121(10):2201 --
  2230.

\bibitem[Bradbury et~al., 2018]{Bradbury:2018}
Bradbury, J., Frostig, R., Hawkins, P., Johnson, M.~J., Leary, C., Maclaurin,
  D., Necula, G., Paszke, A., Vander{P}las, J., Wanderman-{M}ilne, S., and
  Zhang, Q. (2018).
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs.

\bibitem[Buchholz et~al., 2021]{buchholz2020adaptive}
Buchholz, A., Chopin, N., and Jacob, P.~E. (2021).
\newblock Adaptive tuning of {H}amiltonian {M}onte {C}arlo within sequential
  {M}onte {C}arlo.
\newblock {\em Bayesian Analysis to appear - arXiv preprint arXiv:1808.07730}.

\bibitem[Caterini et~al., 2018]{caterini2018hamiltonian}
Caterini, A.~L., Doucet, A., and Sejdinovic, D. (2018).
\newblock Hamiltonian variational auto-encoder.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  8167--8177.

\bibitem[Choi, 2019]{Choi:2019}
Choi, M.~C. (2019).
\newblock Universality of the {L}angevin diffusion as scaling limit of a family
  of {M}etropolis--{H}astings processes i: fixed dimension.
\newblock {\em arXiv preprint arXiv:1907.10318}.

\bibitem[Chopin, 2002]{chopin2002sequential}
Chopin, N. (2002).
\newblock A sequential particle filter method for static models.
\newblock {\em Biometrika}, 89(3):539--552.

\bibitem[Chopin, 2004]{chopin2004central}
Chopin, N. (2004).
\newblock Central limit theorem for sequential {M}onte {C}arlo methods and its
  application to {B}ayesian inference.
\newblock {\em The Annals of Statistics}, 32(6):2385--2411.

\bibitem[Crooks, 1998]{crooks1998nonequilibrium}
Crooks, G.~E. (1998).
\newblock Nonequilibrium measurements of free energy differences for
  microscopically reversible {M}arkovian systems.
\newblock {\em Journal of Statistical Physics}, 90(5-6):1481--1487.

\bibitem[Dai et~al., 2020]{dai2020invitation}
Dai, C., Heng, J., Jacob, P.~E., and Whiteley, N. (2020).
\newblock An invitation to sequential {M}onte {C}arlo samplers.
\newblock {\em arXiv preprint arXiv:2007.11936}.

\bibitem[Dalalyan, 2017]{Dalalyan:2014}
Dalalyan, A.~S. (2017).
\newblock Theoretical guarantees for approximate sampling from smooth and
  log-concave densities.
\newblock {\em Journal of the Royal Statistical Society: Series \textup{B}},
  3(79):651--676.

\bibitem[Del~Moral, 2004]{del2004feynman}
Del~Moral, P. (2004).
\newblock {\em Feynman-{K}ac Formulae: Genealogical and Interacting Particle
  Approximations}.
\newblock Springer.

\bibitem[Del~Moral et~al., 2006]{Del-Moral:2006}
Del~Moral, P., Doucet, A., and Jasra, A. (2006).
\newblock Sequential {M}onte {C}arlo samplers.
\newblock {\em Journal of the Royal Statistical Society: Series \textup{B}},
  68(3):411--436.

\bibitem[Del~Moral et~al., 2012a]{delmoral2012adaptive}
Del~Moral, P., Doucet, A., and Jasra, A. (2012a).
\newblock An adaptive sequential {M}onte {C}arlo method for approximate
  {B}ayesian computation.
\newblock {\em Statistics and Computing}, 22(5):1009--1020.

\bibitem[Del~Moral et~al., 2012b]{Del-Moral:2012}
Del~Moral, P., Doucet, A., and Jasra, A. (2012b).
\newblock On adaptive resampling strategies for sequential {M}onte {C}arlo
  methods.
\newblock {\em Bernoulli}, 18(1):252--278.

\bibitem[{Dillon} et~al., 2017]{Dillon:2017}
{Dillon}, J.~V., {Langmore}, I., {Tran}, D., {Brevdo}, E., {Vasudevan}, S.,
  {Moore}, D., {Patton}, B., {Alemi}, A., {Hoffman}, M., and {Saurous}, R.~A.
  (2017).
\newblock {TensorFlow Distributions}.
\newblock {\em arXiv preprint arXiv:1711.10604}.

\bibitem[Domke and Sheldon, 2018]{domke2018importance}
Domke, J. and Sheldon, D.~R. (2018).
\newblock Importance weighting and variational inference.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4470--4479.

\bibitem[Douc and Moulines, 2008]{Douc:2007}
Douc, R. and Moulines, E. (2008).
\newblock Limit theorems for weighted samples with applications to sequential
  {M}onte {C}arlo methods.
\newblock {\em The Annals of Statistics}, 36(5):2344--2376.

\bibitem[Dudley, 2018]{Dudley:2018}
Dudley, R.~M. (2018).
\newblock {\em Real analysis and Probability}.
\newblock CRC Press.

\bibitem[Durkan et~al., 2019]{Durkan:2019}
Durkan, C., Bekasov, A., Murray, I., and Papamakarios, G. (2019).
\newblock Neural spline flows.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[El~Moselhy and Marzouk, 2012]{Marzouk2012bayesian}
El~Moselhy, T.~A. and Marzouk, Y.~M. (2012).
\newblock Bayesian inference with optimal maps.
\newblock {\em Journal of Computational Physics}, 231(23):7815--7850.

\bibitem[Everitt et~al., 2020]{everitt2020sequential}
Everitt, R.~G., Culliford, R., Medina-Aguayo, F., and Wilson, D.~J. (2020).
\newblock Sequential {M}onte {C}arlo with transformations.
\newblock {\em Statistics and Computing}, 30(3):663--676.

\bibitem[Gao et~al., 2020]{gao2020flow}
Gao, C., Isaacson, J., and Krause, C. (2020).
\newblock i-flow: High-dimensional {I}ntegration and {S}ampling with
  normalizing flows.
\newblock {\em arXiv preprint arXiv:2001.05486}.

\bibitem[Gelfand and Mitter, 1991]{Gelfand:1991}
Gelfand, S.~B. and Mitter, S.~K. (1991).
\newblock Weak convergence of {M}arkov chain sampling methods and annealing
  algorithms to diffusions.
\newblock {\em Journal of Optimization Theory and Applications},
  68(3):483--498.

\bibitem[Germain et~al., 2015]{Germain:15}
Germain, M., Gregor, K., Murray, I., and Larochelle, H. (2015).
\newblock Made: Masked autoencoder for distribution estimation.
\newblock In Bach, F. and Blei, D., editors, {\em Proceedings of the 32nd
  International Conference on Machine Learning}, volume~37 of {\em Proceedings
  of Machine Learning Research}, pages 881--889, Lille, France. PMLR.

\bibitem[Gilks and Berzuini, 2001]{gilks2001following}
Gilks, W.~R. and Berzuini, C. (2001).
\newblock Following a moving target - {M}onte {C}arlo inference for dynamic
  {B}ayesian models.
\newblock {\em Journal of the Royal Statistical Society: Series B},
  63(1):127--146.

\bibitem[Goyal et~al., 2017]{goyal2017variational}
Goyal, A. G. A.~P., Ke, N.~R., Ganguli, S., and Bengio, Y. (2017).
\newblock Variational walkback: Learning a transition operator as a stochastic
  recurrent net.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4392--4402.

\bibitem[Guarniero et~al., 2017]{guarniero2017iterated}
Guarniero, P., Johansen, A.~M., and Lee, A. (2017).
\newblock The iterated auxiliary particle filter.
\newblock {\em Journal of the American Statistical Association},
  112(520):1636--1647.

\bibitem[Han and Liu, 2017]{han2017stein}
Han, J. and Liu, Q. (2017).
\newblock Stein variational adaptive importance sampling.
\newblock {\em Uncertainty in Artificial Intelligence}.

\bibitem[Heng et~al., 2020]{heng2017controlled}
Heng, J., Bishop, A.~N., Deligiannidis, G., and Doucet, A. (2020).
\newblock Controlled sequential {M}onte {C}arlo.
\newblock {\em The Annals of Statistics}, 48(5):2904--2929.

\bibitem[Heng et~al., 2021]{heng2015gibbs}
Heng, J., Doucet, A., and Pokern, Y. (2021).
\newblock Gibbs flow for approximate transport with applications to {B}ayesian
  computation.
\newblock {\em Journal of the Royal Statistical Society Series \textup{B}},
  83(1):156--187.

\bibitem[Hennigan et~al., 2020]{Hennigan:2020}
Hennigan, T., Cai, T., Norman, T., and Babuschkin, I. (2020).
\newblock {H}aiku: {S}onnet for {JAX}.

\bibitem[Hessel et~al., 2020]{optax2020github}
Hessel, M., Budden, D., Viola, F., Rosca, M., Sezener, E., and Hennigan, T.
  (2020).
\newblock Optax: composable gradient transformation and optimisation, in jax.

\bibitem[Hoffman, 2017]{Hoffman:2017}
Hoffman, M.~D. (2017).
\newblock Learning deep latent {G}aussian models with {M}arkov chain {M}onte
  {C}arlo.
\newblock In Precup, D. and Teh, Y.~W., editors, {\em Proceedings of the 34th
  International Conference on Machine Learning}, volume~70 of {\em Proceedings
  of Machine Learning Research}, pages 1510--1519. PMLR.

\bibitem[Huang et~al., 2018]{huang2018improving}
Huang, C.-W., Tan, S., Lacoste, A., and Courville, A.~C. (2018).
\newblock Improving explorability in variational inference with annealed
  variational objectives.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  9701--9711.

\bibitem[Huang et~al., 2020]{huang2020evaluating}
Huang, S., Makhzani, A., Cao, Y., and Grosse, R. (2020).
\newblock Evaluating lossy compression rates of deep generative models.
\newblock In {\em International Conference on Machine Learning}, pages
  4444--4454. PMLR.

\bibitem[Hukushima and Iba, 2003]{hukushima2003population}
Hukushima, K. and Iba, Y. (2003).
\newblock Population annealing and its application to a spin glass.
\newblock In {\em AIP Conference Proceedings}, volume 690, pages 200--206.
  American Institute of Physics.

\bibitem[Jarzynski, 1997]{jarzynski1997nonequilibrium}
Jarzynski, C. (1997).
\newblock Nonequilibrium equality for free energy differences.
\newblock {\em Physical Review Letters}, 78(14):2690--2963.

\bibitem[Jasra et~al., 2011]{jasra2011inference}
Jasra, A., Stephens, D.~A., Doucet, A., and Tsagaris, T. (2011).
\newblock Inference for {L}{\'e}vy-driven stochastic volatility models via
  adaptive sequential {M}onte {C}arlo.
\newblock {\em Scandinavian Journal of Statistics}, 38(1):1--22.

\bibitem[Kappen and Ruiz, 2016]{kappen2016adaptive}
Kappen, H.~J. and Ruiz, H.~C. (2016).
\newblock Adaptive importance sampling for control and inference.
\newblock {\em Journal of Statistical Physics}, 162(5):1244--1266.

\bibitem[Kingma and Ba, 2014]{Kingma:2014}
Kingma, D.~P. and Ba, J. (2014).
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}.

\bibitem[Kingma et~al., 2016]{Kingma:2016}
Kingma, D.~P., Salimans, T., Jozefowicz, R., Chen, X., Sutskever, I., and
  Welling, M. (2016).
\newblock Improved variational inference with inverse autoregressive flow.
\newblock In Lee, D., Sugiyama, M., Luxburg, U., Guyon, I., and Garnett, R.,
  editors, {\em Advances in Neural Information Processing Systems}, volume~29.
  Curran Associates, Inc.

\bibitem[Kingma and Welling, 2014]{kingma+welling:2014}
Kingma, D.~P. and Welling, M. (2014).
\newblock Auto-encoding variational {B}ayes.
\newblock {\em ICLR}.

\bibitem[Kitagawa, 1996]{kitagawa1996monte}
Kitagawa, G. (1996).
\newblock Monte {C}arlo filter and smoother for non-{G}aussian nonlinear state
  space models.
\newblock {\em Journal of Computational and Graphical Statistics}, 5(1):1--25.

\bibitem[K{\"u}nsch, 2005]{kunsch2005recursive}
K{\"u}nsch, H.~R. (2005).
\newblock Recursive {M}onte {C}arlo filters: algorithms and theoretical
  analysis.
\newblock {\em The Annals of Statistics}, 33(5):1983--2021.

\bibitem[Le et~al., 2018]{le2017auto}
Le, T.~A., Igl, M., Rainforth, T., Jin, T., and Wood, F. (2018).
\newblock Auto-encoding sequential {M}onte {C}arlo.
\newblock In {\em ICLR}.

\bibitem[Lee et~al., 2010]{lee2010utility}
Lee, A., Yau, C., Giles, M.~B., Doucet, A., and Holmes, C.~C. (2010).
\newblock On the utility of graphics cards to perform massively parallel
  simulation of advanced monte carlo methods.
\newblock {\em Journal of Computational and Graphical Statistics},
  19(4):769--789.

\bibitem[{Lei Ba} et~al., 2016]{Ba2016}
{Lei Ba}, J., {Kiros}, J.~R., and {Hinton}, G.~E. (2016).
\newblock {Layer Normalization}.
\newblock {\em arXiv e-prints}.

\bibitem[Leli\`evre et~al., 2010]{lelievreroussetstoltz2010free}
Leli\`evre, T., Rousset, M., and Stoltz, G. (2010).
\newblock {\em Free Energy Computations: A Mathematical Perspective}.
\newblock World Scientific.

\bibitem[Li and Chen, 2019]{li2019rate}
Li, Q. and Chen, Y. (2019).
\newblock Rate distortion via deep learning.
\newblock {\em IEEE Transactions on Communications}, 68(1):456--465.

\bibitem[Liu et~al., 2019]{liu2019understanding}
Liu, C., Zhuo, J., Cheng, P., Zhang, R., and Zhu, J. (2019).
\newblock Understanding and accelerating particle-based variational inference.
\newblock In {\em International Conference on Machine Learning}, pages
  4082--4092.

\bibitem[Liu and Chen, 1995]{liuchen1995}
Liu, J.~S. and Chen, R. (1995).
\newblock Blind deconvolution via sequential imputations.
\newblock {\em Journal of the American Statistical Association},
  90(430):567--576.

\bibitem[Liu and Wang, 2016]{liu2016stein}
Liu, Q. and Wang, D. (2016).
\newblock Stein variational gradient descent: a general purpose {B}ayesian
  inference algorithm.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Llorente et~al., 2020]{llorente2020marginal}
Llorente, F., Martino, L., Delgado, D., and Lopez-Santiago, J. (2020).
\newblock Marginal likelihood computation for model selection and hypothesis
  testing: an extensive review.
\newblock {\em arXiv preprint arXiv:2005.08334}.

\bibitem[MacEachern et~al., 1999]{maceachern1999sequential}
MacEachern, S.~N., Clyde, M., and Liu, J.~S. (1999).
\newblock Sequential importance sampling for nonparametric {B}ayes models: The
  next generation.
\newblock {\em Canadian Journal of Statistics}, 27(2):251--267.

\bibitem[Maddison et~al., 2017]{maddison2017filtering}
Maddison, C.~J., Lawson, J., Tucker, G., Heess, N., Norouzi, M., Mnih, A.,
  Doucet, A., and Teh, Y. (2017).
\newblock Filtering variational objectives.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6573--6583.

\bibitem[Marzouk et~al., 2016]{marzouk2016sampling}
Marzouk, Y., Moselhy, T., Parno, M., and Spantini, A. (2016).
\newblock Sampling via measure transport: An introduction.
\newblock {\em Handbook of Uncertainty Quantification}, pages 1--41.

\bibitem[Mnih and Rezende, 2016]{mnih2016variational}
Mnih, A. and Rezende, D. (2016).
\newblock Variational inference for {M}onte {C}arlo objectives.
\newblock In {\em International Conference on Machine Learning}, pages
  2188--2196. PMLR.

\bibitem[M{\o}ller et~al., 1998]{Moller:1998}
M{\o}ller, J., Syversveen, A.~R., and Waagepetersen, R.~P. (1998).
\newblock Log {G}aussian {C}ox processes.
\newblock {\em Scandinavian Journal of Statistics}, 25(3):451--482.

\bibitem[Naesseth et~al., 2018]{naesseth2017variational}
Naesseth, C.~A., Linderman, S.~W., Ranganath, R., and Blei, D.~M. (2018).
\newblock Variational sequential {M}onte {C}arlo.
\newblock In {\em AISTATS}.

\bibitem[Neal, 2011]{Neal2011}
Neal, R. (2011).
\newblock {MCMC} using {H}amiltonian dynamics.
\newblock {\em Handbook of Markov chain Monte Carlo}.

\bibitem[Neal, 2001]{neal2001annealed}
Neal, R.~M. (2001).
\newblock Annealed importance sampling.
\newblock {\em Statistics and Computing}, 11(2):125--139.

\bibitem[Neal, 2003]{Neal:2003}
Neal, R.~M. (2003).
\newblock Slice sampling.
\newblock {\em The Annals of Statistics}, 31(3):705--767.

\bibitem[Nicoli et~al., 2020]{nicoli2020asymptotically}
Nicoli, K.~A., Nakajima, S., Strodthoff, N., Samek, W., M{\"u}ller, K.-R., and
  Kessel, P. (2020).
\newblock Asymptotically unbiased estimation of physical observables with
  neural samplers.
\newblock {\em Physical Review E}, 101(2):023304.

\bibitem[No{\'e} et~al., 2019]{noe2019boltzmann}
No{\'e}, F., Olsson, S., K{\"o}hler, J., and Wu, H. (2019).
\newblock Boltzmann generators: Sampling equilibrium states of many-body
  systems with deep learning.
\newblock {\em Science}, 365(6457):eaaw1147.

\bibitem[Olmez et~al., 2020]{olmez2020deep}
Olmez, S.~Y., Taghvaei, A., and Mehta, P.~G. (2020).
\newblock Deep fpf: Gain function approximation in high-dimensional setting.
\newblock In {\em 59th IEEE Conference on Decision and Control (CDC)}, pages
  4790--4795. IEEE.

\bibitem[Papamakarios et~al., 2019]{papamakarios2019normalizing}
Papamakarios, G., Nalisnick, E., Rezende, D.~J., Mohamed, S., and
  Lakshminarayanan, B. (2019).
\newblock Normalizing flows for probabilistic modeling and inference.
\newblock {\em arXiv preprint arXiv:1912.02762}.

\bibitem[Reich, 2011]{reich2011}
Reich, S. (2011).
\newblock A dynamical systems framework for intermittent data assimilation.
\newblock {\em BIT Numerical Mathematics}, 51(1):235--249.

\bibitem[Reich and Weissmann, 2021]{reich2021fokker}
Reich, S. and Weissmann, S. (2021).
\newblock Fokker--{P}lanck particle systems for {B}ayesian inference:
  Computational approaches.
\newblock {\em SIAM/ASA Journal on Uncertainty Quantification}, 9(2):446--482.

\bibitem[Rezende and Mohamed, 2015]{Rezende:2015}
Rezende, D.~J. and Mohamed, S. (2015).
\newblock Variational inference with normalizing flows.
\newblock In {\em Proceedings of the 32nd {International} {Conference} on
  {Machine} {Learning} - {Volume} 37}, {ICML}'15, pages 1530--1538. JMLR.org.

\bibitem[Rezende et~al., 2014]{rezende+al:2014:icml}
Rezende, D.~J., Mohamed, S., and Wierstra, D. (2014).
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In {\em ICML}, pages 1278--1286.

\bibitem[Richard and Zhang, 2007]{richard2007efficient}
Richard, J.-F. and Zhang, W. (2007).
\newblock Efficient high-dimensional importance sampling.
\newblock {\em Journal of Econometrics}, 141(2):1385--1411.

\bibitem[Rousset and Stoltz, 2006]{Rousset:2006}
Rousset, M. and Stoltz, G. (2006).
\newblock Equilibrium sampling from nonequilibrium dynamics.
\newblock {\em Journal of Statistical Physics}, 123(6):1251--1272.

\bibitem[Salakhutdinov and Murray, 2008]{Salakhutdinov:2008}
Salakhutdinov, R. and Murray, I. (2008).
\newblock On the quantitative analysis of {D}eep {B}elief {N}etworks.
\newblock In {\em Proceedings of the 25th Annual International Conference on
  Machine Learning (ICML 2008)}, pages 872--879.

\bibitem[Salimans et~al., 2015]{salimans2015markov}
Salimans, T., Kingma, D., and Welling, M. (2015).
\newblock Markov chain {M}onte {C}arlo and variational inference: Bridging the
  gap.
\newblock In {\em International Conference on Machine Learning}, pages
  1218--1226.

\bibitem[Sch{\"a}fer and Chopin, 2013]{chopinschafer2013sequential}
Sch{\"a}fer, C. and Chopin, N. (2013).
\newblock Sequential {M}onte {C}arlo on large binary sampling spaces.
\newblock {\em Statistics and Computing}, 23(2):163--184.

\bibitem[Sen, 2018]{Sen:2018a}
Sen, B. (2018).
\newblock A gentle introduction to empirical process theory and applications.
\newblock {\em Lecture Notes, Columbia University}.

\bibitem[Taghvaei et~al., 2020]{taghvaei2020diffusion}
Taghvaei, A., Mehta, P.~G., and Meyn, S.~P. (2020).
\newblock Diffusion map-based algorithm for gain function approximation in the
  feedback particle filter.
\newblock {\em SIAM/ASA Journal on Uncertainty Quantification},
  8(3):1090--1117.

\bibitem[Thin et~al., 2021]{thin2021MCVAE}
Thin, A., Kotelevskii, N., Durmus, A., Panov, M., Moulines, E., and Doucet, A.
  (2021).
\newblock Monte {C}arlo variational auto-encoders.
\newblock {\em International Conference on Machine Learning}.

\bibitem[Turner and Sahani, 2011]{turner+sahani:2011a}
Turner, R.~E. and Sahani, M. (2011).
\newblock Two problems with variational expectation maximisation for
  time-series models.
\newblock In Barber, D., Cemgil, T., and Chiappa, S., editors, {\em Bayesian
  Time Series Models}, chapter~5, pages 109--130. Cambridge University Press.

\bibitem[Vaikuntanathan and Jarzynski, 2008]{vaikuntanathan2008escorted}
Vaikuntanathan, S. and Jarzynski, C. (2008).
\newblock Escorted free energy simulations: Improving convergence by reducing
  dissipation.
\newblock {\em Physical Review Letters}, 100(19):190601.

\bibitem[Vaikuntanathan and Jarzynski, 2011]{vaikuntanathan2011escorted}
Vaikuntanathan, S. and Jarzynski, C. (2011).
\newblock Escorted free energy simulations.
\newblock {\em The Journal of Chemical Physics}, 134(5):054107.

\bibitem[Van~der Vaart, 2000]{Van-der-Vaart:2000}
Van~der Vaart, A.~W. (2000).
\newblock {\em Asymptotic Statistics}.
\newblock Cambridge University Press.

\bibitem[Wang and Li, 2019]{wang2019accelerated}
Wang, Y. and Li, W. (2019).
\newblock Accelerated information gradient flow.
\newblock {\em arXiv preprint arXiv:1909.02102}.

\bibitem[Wirnsberger et~al., 2020]{wirnsbergertargetetNF2020}
Wirnsberger, P., Ballard, A.~J., Papamakarios, G., Abercrombie, S.,
  Racani\`ere, S., Pritzel, A., Rezende, D., and Blundell, C. (2020).
\newblock Targeted free energy estimation via learned mappings.
\newblock {\em The Journal of Chemical Physics}, 153(14):144112.

\bibitem[Wu et~al., 2020]{wunoe2020stochastic}
Wu, H., K{\"o}hler, J., and No{\'e}, F. (2020).
\newblock Stochastic normalizing flows.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Wu et~al., 2017]{Wu:2017}
Wu, Y., Burda, Y., Salakhutdinov, R., and Grosse, R.~B. (2017).
\newblock On the quantitative analysis of decoder-based generative models.
\newblock In {\em 5th International Conference on Learning Representations,
  {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track
  Proceedings}.

\bibitem[Zhou et~al., 2016]{ZhouJohansen2016}
Zhou, Y., Johansen, A.~M., and Aston, J.~A. (2016).
\newblock Toward automatic model comparison: An adaptive sequential {M}onte
  {C}arlo approach.
\newblock {\em Journal of Computational and Graphical Statistics},
  25(3):701--726.

\bibitem[Zhu et~al., 2020]{zhu2020variance}
Zhu, M., Liu, C., and Zhu, J. (2020).
\newblock Variance reduction and quasi-{N}ewton for particle-based variational
  inference.
\newblock In {\em International Conference on Machine Learning}, pages
  11576--11587.

\end{thebibliography}
