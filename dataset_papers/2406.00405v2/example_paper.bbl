\begin{thebibliography}{78}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amir et~al.(2017)Amir, Taba, Berg, Melano, McKinstry, Di~Nolfo, Nayak, Andreopoulos, Garreau, Mendoza, et~al.]{dvs128}
Amir, A., Taba, B., Berg, D., Melano, T., McKinstry, J., Di~Nolfo, C., Nayak, T., Andreopoulos, A., Garreau, G., Mendoza, M., et~al.
\newblock A low power, fully event-based gesture recognition system.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pp.\  7243--7252, 2017.

\bibitem[Bacci \& Huguenard(2006)Bacci and Huguenard]{au10}
Bacci, A. and Huguenard, J.~R.
\newblock Enhancement of spike-timing precision by autaptic transmission in neocortical inhibitory interneurons.
\newblock \emph{Neuron}, 49\penalty0 (1):\penalty0 119--130, 2006.

\bibitem[Bacci et~al.(2003)Bacci, Huguenard, and Prince]{au9}
Bacci, A., Huguenard, J.~R., and Prince, D.~A.
\newblock Functional autaptic neurotransmission in fast-spiking interneurons: a novel form of feedback inhibition in the neocortex.
\newblock \emph{Journal of Neuroscience}, 23\penalty0 (3):\penalty0 859--866, 2003.

\bibitem[Bellec et~al.(2018)Bellec, Salaj, Subramoney, Legenstein, and Maass]{r19}
Bellec, G., Salaj, D., Subramoney, A., Legenstein, R., and Maass, W.
\newblock Long short-term memory and learning-to-learn in networks of spiking neurons.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Bi \& Poo(1998)Bi and Poo]{r2}
Bi, G.-q. and Poo, M.-m.
\newblock Synaptic modifications in cultured hippocampal neurons: dependence on spike timing, synaptic strength, and postsynaptic cell type.
\newblock \emph{Journal of Neuroscience}, 18\penalty0 (24):\penalty0 10464--10472, 1998.

\bibitem[Bu et~al.(2022{\natexlab{a}})Bu, Ding, Yu, and Huang]{r9}
Bu, T., Ding, J., Yu, Z., and Huang, T.
\newblock Optimized potential initialization for low-latency spiking neural networks.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~36, pp.\  11--20, 2022{\natexlab{a}}.

\bibitem[Bu et~al.(2022{\natexlab{b}})Bu, Fang, Ding, Dai, Yu, and Huang]{bu2021optimal}
Bu, T., Fang, W., Ding, J., Dai, P., Yu, Z., and Huang, T.
\newblock Optimal {ANN-SNN} conversion for high-accuracy and ultra-low-latency spiking neural networks.
\newblock In \emph{International Conference on Learning Representations}, pp.\  1--19, 2022{\natexlab{b}}.

\bibitem[Chen et~al.(2022)Chen, Scherr, and Maass]{i6}
Chen, G., Scherr, F., and Maass, W.
\newblock A data-based large-scale model for primary visual cortex enables brain-like robust and versatile visual processing.
\newblock \emph{Science Advances}, 8\penalty0 (44):\penalty0 eabq7592, 2022.

\bibitem[Cobb et~al.(1997)Cobb, Halasy, Vida, Ny{\i}́ri, Tam{\'a}s, Buhl, and Somogyi]{au8}
Cobb, S., Halasy, K., Vida, I., Ny{\i}́ri, G., Tam{\'a}s, G., Buhl, E., and Somogyi, P.
\newblock Synaptic effects of identified interneurons innervating both interneurons and pyramidal cells in the rat hippocampus.
\newblock \emph{Neuroscience}, 79\penalty0 (3):\penalty0 629--648, 1997.

\bibitem[De~Wit \& Ghosh(2016)De~Wit and Ghosh]{i18}
De~Wit, J. and Ghosh, A.
\newblock Specification of synaptic connectivity by cell surface interactions.
\newblock \emph{Nature Reviews Neuroscience}, 17\penalty0 (1):\penalty0 4--4, 2016.

\bibitem[Deng \& Gu(2021)Deng and Gu]{deng2021optimal}
Deng, S. and Gu, S.
\newblock Optimal conversion of conventional artificial neural networks to spiking neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Deng et~al.(2022)Deng, Li, Zhang, and Gu]{i10}
Deng, S., Li, Y., Zhang, S., and Gu, S.
\newblock Temporal efficient training of spiking neural network via gradient re-weighting.
\newblock \emph{arXiv preprint arXiv:2202.11946}, 2022.

\bibitem[Deng et~al.(2023)Deng, Lin, Li, and Gu]{r14}
Deng, S., Lin, H., Li, Y., and Gu, S.
\newblock Surrogate module learning: Reduce the gradient error accumulation in training spiking neural networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\  7645--7657. PMLR, 2023.

\bibitem[Diehl \& Cook(2015)Diehl and Cook]{r3}
Diehl, P.~U. and Cook, M.
\newblock Unsupervised learning of digit recognition using spike-timing-dependent plasticity.
\newblock \emph{Frontiers in Computational Neuroscience}, 9:\penalty0 99, 2015.

\bibitem[Diehl et~al.(2015)Diehl, Neil, Binas, Cook, Liu, and Pfeiffer]{r7}
Diehl, P.~U., Neil, D., Binas, J., Cook, M., Liu, S.-C., and Pfeiffer, M.
\newblock Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing.
\newblock In \emph{2015 International Joint Conference on Neural Networks (IJCNN)}, pp.\  1--8. ieee, 2015.

\bibitem[Duan et~al.(2022)Duan, Ding, Chen, Yu, and Huang]{r17}
Duan, C., Ding, J., Chen, S., Yu, Z., and Huang, T.
\newblock Temporal effective batch normalization in spiking neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 34377--34390, 2022.

\bibitem[Fang et~al.(2021{\natexlab{a}})Fang, Yu, Chen, Huang, Masquelier, and Tian]{i9}
Fang, W., Yu, Z., Chen, Y., Huang, T., Masquelier, T., and Tian, Y.
\newblock Deep residual learning in spiking neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 21056--21069, 2021{\natexlab{a}}.

\bibitem[Fang et~al.(2021{\natexlab{b}})Fang, Yu, Chen, Masquelier, Huang, and Tian]{plif}
Fang, W., Yu, Z., Chen, Y., Masquelier, T., Huang, T., and Tian, Y.
\newblock Incorporating learnable membrane time constant to enhance learning of spiking neural networks.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  2661--2671, 2021{\natexlab{b}}.

\bibitem[Fang et~al.(2023)Fang, Chen, Ding, Yu, Masquelier, Chen, Huang, Zhou, Li, and Tian]{fang2023spikingjelly}
Fang, W., Chen, Y., Ding, J., Yu, Z., Masquelier, T., Chen, D., Huang, L., Zhou, H., Li, G., and Tian, Y.
\newblock Spikingjelly: An open-source machine learning infrastructure platform for spike-based intelligence.
\newblock \emph{Science Advances}, 9\penalty0 (40):\penalty0 eadi1480, 2023.

\bibitem[Gast et~al.(2024)Gast, Solla, and Kennedy]{i23}
Gast, R., Solla, S.~A., and Kennedy, A.
\newblock Neural heterogeneity controls computations in spiking neural networks.
\newblock \emph{Proceedings of the National Academy of Sciences}, 121\penalty0 (3):\penalty0 e2311885121, 2024.

\bibitem[Gerstner \& Kistler(2002)Gerstner and Kistler]{i13}
Gerstner, W. and Kistler, W.~M.
\newblock \emph{Spiking neuron models: Single neurons, populations, plasticity}.
\newblock Cambridge university press, 2002.

\bibitem[Gerstner et~al.(2014)Gerstner, Kistler, Naud, and Paninski]{gerstner2014neuronal}
Gerstner, W., Kistler, W.~M., Naud, R., and Paninski, L.
\newblock \emph{Neuronal Dynamics: From single neurons to networks and models of cognition}.
\newblock Cambridge University Press, 2014.

\bibitem[Golomb \& Rinzel(1993)Golomb and Rinzel]{i20}
Golomb, D. and Rinzel, J.
\newblock Dynamics of globally coupled inhibitory neurons with heterogeneity.
\newblock \emph{Physical Review E}, 48\penalty0 (6):\penalty0 4810, 1993.

\bibitem[Goyal et~al.(2017)Goyal, Doll{\'a}r, Girshick, Noordhuis, Wesolowski, Kyrola, Tulloch, Jia, and He]{warmup}
Goyal, P., Doll{\'a}r, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., Tulloch, A., Jia, Y., and He, K.
\newblock Accurate, large minibatch sgd: Training imagenet in 1 hour.
\newblock \emph{arXiv preprint arXiv:1706.02677}, 2017.

\bibitem[Guo et~al.(2017)Guo, Yu, Deng, Hu, and Chen]{guo2017hierarchical}
Guo, S., Yu, Z., Deng, F., Hu, X., and Chen, F.
\newblock Hierarchical {B}ayesian inference and learning in spiking neural networks.
\newblock \emph{IEEE Transactions on Cybernetics}, 49\penalty0 (1):\penalty0 133--145, 2017.

\bibitem[Guo et~al.(2022)Guo, Zhang, Chen, Tong, Liu, Wang, Huang, and Ma]{i11}
Guo, Y., Zhang, L., Chen, Y., Tong, X., Liu, X., Wang, Y., Huang, X., and Ma, Z.
\newblock Real spike: Learning real-valued spikes for spiking neural networks.
\newblock In \emph{European Conference on Computer Vision}, pp.\  52--68. Springer, 2022.

\bibitem[Han et~al.(2020)Han, Srinivasan, and Roy]{han2020rmp}
Han, B., Srinivasan, G., and Roy, K.
\newblock Rmp-snn: Residual membrane potential neuron for enabling deeper high-accuracy and low-latency spiking neural network.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  13558--13567, 2020.

\bibitem[Hao et~al.(2023{\natexlab{a}})Hao, Ding, Bu, Huang, and Yu]{hao2023bridging}
Hao, Z., Ding, J., Bu, T., Huang, T., and Yu, Z.
\newblock Bridging the gap between anns and snns by calibrating offset spikes.
\newblock In \emph{International Conference on Learning Representations}, 2023{\natexlab{a}}.

\bibitem[Hao et~al.(2023{\natexlab{b}})Hao, Shi, Huang, Bu, Yu, and Huang]{lmh}
Hao, Z., Shi, X., Huang, Z., Bu, T., Yu, Z., and Huang, T.
\newblock A progressive training framework for spiking neural networks with learnable multi-hierarchical model.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2023{\natexlab{b}}.

\bibitem[Harris \& Shepherd(2015)Harris and Shepherd]{i16}
Harris, K.~D. and Shepherd, G.~M.
\newblock The neocortical circuit: themes and variations.
\newblock \emph{Nature Neuroscience}, 18\penalty0 (2):\penalty0 170--181, 2015.

\bibitem[Hebb(2005)]{r1}
Hebb, D.~O.
\newblock \emph{The organization of behavior: A neuropsychological theory}.
\newblock Psychology Press, 2005.

\bibitem[Hutt et~al.(2023)Hutt, Rich, Valiante, and Lefebvre]{i22}
Hutt, A., Rich, S., Valiante, T.~A., and Lefebvre, J.
\newblock Intrinsic neural diversity quenches the dynamic volatility of neural networks.
\newblock \emph{Proceedings of the National Academy of Sciences}, 120\penalty0 (28):\penalty0 e2218841120, 2023.

\bibitem[Kim \& Panda(2021)Kim and Panda]{r18.5}
Kim, Y. and Panda, P.
\newblock Revisiting batch normalization for training low-latency deep spiking neural networks from scratch.
\newblock \emph{Frontiers in Neuroscience}, 15:\penalty0 773954, 2021.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Koch \& Laurent(1999)Koch and Laurent]{i14}
Koch, C. and Laurent, G.
\newblock Complexity and the nervous system.
\newblock \emph{Science}, 284\penalty0 (5411):\penalty0 96--98, 1999.

\bibitem[Lee et~al.(2018)Lee, Panda, Srinivasan, and Roy]{r4}
Lee, C., Panda, P., Srinivasan, G., and Roy, K.
\newblock Training deep spiking convolutional neural networks with stdp-based unsupervised pre-training followed by supervised fine-tuning.
\newblock \emph{Frontiers in Neuroscience}, 12:\penalty0 435, 2018.

\bibitem[Lee et~al.(2020)Lee, Sarwar, Panda, Srinivasan, and Roy]{r18.4}
Lee, C., Sarwar, S.~S., Panda, P., Srinivasan, G., and Roy, K.
\newblock Enabling spike-based backpropagation for training deep neural network architectures.
\newblock \emph{Frontiers in Neuroscience}, pp.\  119, 2020.

\bibitem[Liu \& Yue(2018)Liu and Yue]{r5}
Liu, D. and Yue, S.
\newblock Event-driven continuous stdp learning with deep structure for visual pattern recognition.
\newblock \emph{IEEE Transactions on Cybernetics}, 49\penalty0 (4):\penalty0 1377--1390, 2018.

\bibitem[Loshchilov \& Hutter(2016)Loshchilov and Hutter]{cos}
Loshchilov, I. and Hutter, F.
\newblock Sgdr: Stochastic gradient descent with warm restarts.
\newblock \emph{arXiv preprint arXiv:1608.03983}, 2016.

\bibitem[Lu \& Sengupta(2023)Lu and Sengupta]{r6}
Lu, S. and Sengupta, A.
\newblock Deep unsupervised learning using spike-timing-dependent plasticity.
\newblock \emph{arXiv preprint arXiv:2307.04054}, 2023.

\bibitem[L{\"u}bke et~al.(1996)L{\"u}bke, Markram, Frotscher, and Sakmann]{au5}
L{\"u}bke, J., Markram, H., Frotscher, M., and Sakmann, B.
\newblock Frequency and dendritic distribution of autapses established by layer 5 pyramidal neurons in the developing rat neocortex: comparison with synaptic innervation of adjacent neurons of the same class.
\newblock \emph{Journal of Neuroscience}, 16\penalty0 (10):\penalty0 3209--3218, 1996.

\bibitem[Maass(1997)]{i1}
Maass, W.
\newblock Networks of spiking neurons: The third generation of neural network models.
\newblock \emph{Neural Networks}, 10\penalty0 (9):\penalty0 1659--1671, 1997.

\bibitem[Neftci et~al.(2019)Neftci, Mostafa, and Zenke]{i8}
Neftci, E.~O., Mostafa, H., and Zenke, F.
\newblock Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to spiking neural networks.
\newblock \emph{IEEE Signal Processing Magazine}, 36\penalty0 (6):\penalty0 51--63, 2019.

\bibitem[Park et~al.(1980)Park, Lighthall, and Kitai]{au2}
Park, M.~R., Lighthall, J.~W., and Kitai, S.~T.
\newblock Recurrent inhibition in the rat neostriatum.
\newblock \emph{Brain Research}, 194\penalty0 (2):\penalty0 359--369, 1980.

\bibitem[Pei et~al.(2019)Pei, Deng, Song, Zhao, Zhang, Wu, Wang, Zou, Wu, He, et~al.]{i4}
Pei, J., Deng, L., Song, S., Zhao, M., Zhang, Y., Wu, S., Wang, G., Zou, Z., Wu, Z., He, W., et~al.
\newblock Towards artificial general intelligence with hybrid tianjic chip architecture.
\newblock \emph{Nature}, 572\penalty0 (7767):\penalty0 106--111, 2019.

\bibitem[Preston et~al.(1980)Preston, Bishop, and Kitai]{au3}
Preston, R., Bishop, G., and Kitai, S.
\newblock Medium spiny neuron projection from the rat striatum: an intracellular horseradish peroxidase study.
\newblock \emph{Brain Research}, 183\penalty0 (2):\penalty0 253--263, 1980.

\bibitem[Rathi \& Roy(2021)Rathi and Roy]{r20}
Rathi, N. and Roy, K.
\newblock Diet-snn: A low-latency spiking neural network with direct input encoding and leakage and threshold optimization.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems}, 2021.

\bibitem[Rich et~al.(2022)Rich, Chameh, Lefebvre, and Valiante]{i21}
Rich, S., Chameh, H.~M., Lefebvre, J., and Valiante, T.~A.
\newblock Loss of neuronal heterogeneity in epileptogenic human tissue impairs network resilience to sudden changes in synchrony.
\newblock \emph{Cell Reports}, 39\penalty0 (8), 2022.

\bibitem[Roy et~al.(2019)Roy, Jaiswal, and Panda]{i3}
Roy, K., Jaiswal, A., and Panda, P.
\newblock Towards spike-based machine intelligence with neuromorphic computing.
\newblock \emph{Nature}, 575\penalty0 (7784):\penalty0 607--617, 2019.

\bibitem[Rueckauer et~al.(2017)Rueckauer, Lungu, Hu, Pfeiffer, and Liu]{rueckauer2017conversion}
Rueckauer, B., Lungu, I.-A., Hu, Y., Pfeiffer, M., and Liu, S.-C.
\newblock Conversion of continuous-valued deep networks to efficient event-driven networks for image classification.
\newblock \emph{Frontiers in Neuroscience}, 11:\penalty0 682, 2017.

\bibitem[Sanes \& Zipursky(2020)Sanes and Zipursky]{i19}
Sanes, J.~R. and Zipursky, S.~L.
\newblock Synaptic specificity, recognition molecules, and assembly of neural circuits.
\newblock \emph{Cell}, 181\penalty0 (3):\penalty0 536--556, 2020.

\bibitem[Schuldt et~al.(2004)Schuldt, Laptev, and Caputo]{kth}
Schuldt, C., Laptev, I., and Caputo, B.
\newblock Recognizing human actions: a local svm approach.
\newblock In \emph{International Conference on Pattern Recognition, 2004. ICPR 2004.}, volume~3, pp.\  32--36. IEEE, 2004.

\bibitem[Shi \& Rayport(1994)Shi and Rayport]{au4}
Shi, W.-X. and Rayport, S.
\newblock Gaba synapses formed in vitro by local axon collaterals of nucleus accumbens neurons.
\newblock \emph{Journal of Neuroscience}, 14\penalty0 (7):\penalty0 4548--4560, 1994.

\bibitem[Shi et~al.(2024)Shi, Ding, Hao, and Yu]{shi2023towards}
Shi, X., Ding, J., Hao, Z., and Yu, Z.
\newblock Towards energy efficient spiking neural networks: An unstructured pruning framework.
\newblock In \emph{International Conference on Learning Representations}, 2024.

\bibitem[Srivastava et~al.(2015)Srivastava, Mansimov, and Salakhudinov]{mmnist}
Srivastava, N., Mansimov, E., and Salakhudinov, R.
\newblock Unsupervised learning of video representations using lstms.
\newblock In \emph{International Conference on Machine Learning}, pp.\  843--852. PMLR, 2015.

\bibitem[Stewart \& Neftci(2022)Stewart and Neftci]{r18.3}
Stewart, K.~M. and Neftci, E.~O.
\newblock Meta-learning spiking neural networks with surrogate gradient descent.
\newblock \emph{Neuromorphic Computing and Engineering}, 2\penalty0 (4):\penalty0 044002, 2022.

\bibitem[Tamas et~al.(1997)Tamas, Buhl, and Somogyi]{au7}
Tamas, G., Buhl, E.~H., and Somogyi, P.
\newblock Massive autaptic self-innervation of gabaergic neurons in cat visual cortex.
\newblock \emph{Journal of Neuroscience}, 17\penalty0 (16):\penalty0 6352--6364, 1997.

\bibitem[Tan et~al.(2023)Tan, Li, Gao, Guan, Wang, Liu, Wu, and Li]{tan2023openstl}
Tan, C., Li, S., Gao, Z., Guan, W., Wang, Z., Liu, Z., Wu, L., and Li, S.~Z.
\newblock Openstl: A comprehensive benchmark of spatio-temporal predictive learning.
\newblock In \emph{Conference on Neural Information Processing Systems Datasets and Benchmarks Track}, 2023.

\bibitem[Thomson et~al.(1996)Thomson, West, Hahn, and Deuchars]{au6}
Thomson, A.~M., West, D.~C., Hahn, J., and Deuchars, J.
\newblock Single axon ipsps elicited in pyramidal cells by three classes of interneurones in slices of rat neocortex.
\newblock \emph{The Journal of Physiology}, 496\penalty0 (1):\penalty0 81--102, 1996.

\bibitem[Van Der~Loos \& Glaser(1972)Van Der~Loos and Glaser]{au1}
Van Der~Loos, H. and Glaser, E.~M.
\newblock Autapses in neocortex cerebri: synapses between a pyramidal cell's axon and its own dendrites.
\newblock \emph{Brain Research}, 48:\penalty0 355--360, 1972.

\bibitem[Wang et~al.(2023)Wang, Jiang, Lian, Yan, and Tang]{r13}
Wang, Z., Jiang, R., Lian, S., Yan, R., and Tang, H.
\newblock Adaptive smoothing gradient learning for spiking neural networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\  35798--35816. PMLR, 2023.

\bibitem[Wu \& He(2018)Wu and He]{gn}
Wu, Y. and He, K.
\newblock Group normalization.
\newblock In \emph{Proceedings of the European Conference on Computer Vision (ECCV)}, pp.\  3--19, 2018.

\bibitem[Wu et~al.(2018)Wu, Deng, Li, Zhu, and Shi]{i7}
Wu, Y., Deng, L., Li, G., Zhu, J., and Shi, L.
\newblock Spatio-temporal backpropagation for training high-performance spiking neural networks.
\newblock \emph{Frontiers in Neuroscience}, 12:\penalty0 331, 2018.

\bibitem[Wu et~al.(2019)Wu, Deng, Li, Zhu, Xie, and Shi]{r15}
Wu, Y., Deng, L., Li, G., Zhu, J., Xie, Y., and Shi, L.
\newblock Direct training for spiking neural networks: Faster, larger, better.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~33, pp.\  1311--1318, 2019.

\bibitem[Wu et~al.(2021)Wu, Zhang, Lin, Li, Wang, and Tang]{r22}
Wu, Z., Zhang, H., Lin, Y., Li, G., Wang, M., and Tang, Y.
\newblock Liaf-net: Leaky integrate and analog fire network for lightweight and efficient spatiotemporal information processing.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems}, 33\penalty0 (11):\penalty0 6249--6262, 2021.

\bibitem[Xiao et~al.(2022)Xiao, Meng, Zhang, He, and Lin]{r18.6}
Xiao, M., Meng, Q., Zhang, Z., He, D., and Lin, Z.
\newblock Online training through time for spiking neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 20717--20730, 2022.

\bibitem[Yao et~al.(2022)Yao, Li, Mo, and Cheng]{glif}
Yao, X., Li, F., Mo, Z., and Cheng, J.
\newblock Glif: A unified gated leaky integrate-and-fire neuron for spiking neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 32160--32171, 2022.

\bibitem[Yao et~al.(2021)Yao, van Velthoven, Nguyen, Goldy, Sedeno-Cortes, Baftizadeh, Bertagnolli, Casper, Chiang, Crichton, et~al.]{i17}
Yao, Z., van Velthoven, C.~T., Nguyen, T.~N., Goldy, J., Sedeno-Cortes, A.~E., Baftizadeh, F., Bertagnolli, D., Casper, T., Chiang, M., Crichton, K., et~al.
\newblock A taxonomy of transcriptomic cell types across the isocortex and hippocampal formation.
\newblock \emph{Cell}, 184\penalty0 (12):\penalty0 3222--3241, 2021.

\bibitem[Yin et~al.(2021)Yin, Corradi, and Boht{\'e}]{i12}
Yin, B., Corradi, F., and Boht{\'e}, S.~M.
\newblock Accurate and efficient time-domain classification with adaptive spiking recurrent neural networks.
\newblock \emph{Nature Machine Intelligence}, 3\penalty0 (10):\penalty0 905--913, 2021.

\bibitem[Yin et~al.(2018)Yin, Zheng, Ke, He, Zhang, Li, Wang, Mi, Long, Rasch, et~al.]{au11}
Yin, L., Zheng, R., Ke, W., He, Q., Zhang, Y., Li, J., Wang, B., Mi, Z., Long, Y.-s., Rasch, M.~J., et~al.
\newblock Autapses enhance bursting and coincidence detection in neocortical pyramidal cells.
\newblock \emph{Nature Communications}, 9\penalty0 (1):\penalty0 4890, 2018.

\bibitem[Yu et~al.(2018{\natexlab{a}})Yu, Guo, Deng, Yan, Huang, Liu, and Chen]{yu2018emergent}
Yu, Z., Guo, S., Deng, F., Yan, Q., Huang, K., Liu, J.~K., and Chen, F.
\newblock Emergent inference of hidden markov models in spiking neural networks through winner-take-all.
\newblock \emph{IEEE Transactions on Cybernetics}, 50\penalty0 (3):\penalty0 1347--1354, 2018{\natexlab{a}}.

\bibitem[Yu et~al.(2018{\natexlab{b}})Yu, Tian, Huang, and Liu]{yu2018winner}
Yu, Z., Tian, Y., Huang, T., and Liu, J.~K.
\newblock Winner-take-all as basic probabilistic inference unit of neuronal circuits.
\newblock \emph{arXiv preprint arXiv:1808.00675}, 2018{\natexlab{b}}.

\bibitem[Zenke \& Vogels(2021)Zenke and Vogels]{r18.2}
Zenke, F. and Vogels, T.~P.
\newblock The remarkable robustness of surrogate gradient learning for instilling complex function in spiking neural networks.
\newblock \emph{Neural Computation}, 33\penalty0 (4):\penalty0 899--925, 2021.

\bibitem[Zhang et~al.(2017)Zhang, Zheng, and Qi]{taxibj}
Zhang, J., Zheng, Y., and Qi, D.
\newblock Deep spatio-temporal residual networks for citywide crowd flows prediction.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~31, 2017.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Yang, Ma, Wu, Li, and Tan]{tclif}
Zhang, S., Yang, Q., Ma, C., Wu, J., Li, H., and Tan, K.~C.
\newblock Tc-lif: A two-compartment spiking neuron model for long-term sequential modelling.
\newblock \emph{arXiv preprint arXiv:2308.13250}, 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Cheng, Jia, Li, Poo, and Xu]{i5}
Zhang, T., Cheng, X., Jia, S., Li, C.~T., Poo, M.-m., and Xu, B.
\newblock A brain-inspired algorithm that mitigates catastrophic forgetting of artificial and spiking neural networks with low computational cost.
\newblock \emph{Science Advances}, 9\penalty0 (34):\penalty0 eadi2947, 2023{\natexlab{b}}.

\bibitem[Zheng et~al.(2021)Zheng, Wu, Deng, Hu, and Li]{r16}
Zheng, H., Wu, Y., Deng, L., Hu, Y., and Li, G.
\newblock Going deeper with directly-trained larger spiking neural networks.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~35, pp.\  11062--11070, 2021.

\bibitem[Zhu et~al.(2024)Zhu, Ding, Huang, Xie, and Yu]{zhuonline}
Zhu, Y., Ding, J., Huang, T., Xie, X., and Yu, Z.
\newblock Online stabilization of spiking neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2024.

\end{thebibliography}
