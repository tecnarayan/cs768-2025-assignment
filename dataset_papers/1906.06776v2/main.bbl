\begin{thebibliography}{10}

\bibitem{achlioptas2005spectral}
Dimitris Achlioptas and Frank McSherry.
\newblock {On spectral learning of mixtures of distributions}.
\newblock In {\em International Conference on Computational Learning Theory},
  pages 458--469. Springer, 2005.

\bibitem{an1997log}
Mark~Yuying An.
\newblock Log-concave probability distributions: Theory and statistical
  testing.
\newblock {\em Duke University Dept of Economics Working Paper}, (95-03), 1997.

\bibitem{bagnoli2005log}
Mark Bagnoli and Ted Bergstrom.
\newblock Log-concave probability and its applications.
\newblock {\em Economic theory}, 26(2):445--469, 2005.

\bibitem{balakrishnan2017statistical}
Sivaraman Balakrishnan, Martin~J. Wainwright, and Bin Yu.
\newblock Statistical guarantees for the {EM} algorithm: From population to
  sample-based analysis.
\newblock {\em The Annals of Statistics}, 45(1):77--120, 2017.

\bibitem{barazandeh2018behavior}
Babak Barazandeh and Meisam Razaviyayn.
\newblock On the behavior of the expectation-maximization algorithm for mixture
  models.
\newblock In {\em 2018 IEEE Global Conference on Signal and Information
  Processing (GlobalSIP)}, pages 61--65. IEEE, 2018.

\bibitem{barlow1975statistical}
Richard~E. Barlow and Frank Proschan.
\newblock Statistical theory of reliability and life testing: probability
  models.
\newblock Technical report, Florida State Univ Tallahassee, 1975.

\bibitem{billingsley2008probability}
Patrick Billingsley.
\newblock {\em Probability and measure}.
\newblock John Wiley \& Sons, 2008.

\bibitem{chaganty2013spectral}
Arun~Tejasvi Chaganty and Percy Liang.
\newblock Spectral experts for estimating mixtures of linear regressions.
\newblock In {\em International Conference on Machine Learning}, pages
  1040--1048, 2013.

\bibitem{chaudhuri2009kmeans}
Kamalika Chaudhuri, Sanjoy Dasgupta, and Andrea Vattani.
\newblock Learning mixtures of gaussians using the k-means algorithm.
\newblock {\em arXiv preprint arXiv:0912.0086}, 2009.

\bibitem{cule2010theoretical}
Madeleine Cule and Richard Samworth.
\newblock Theoretical properties of the log-concave maximum likelihood
  estimator of a multidimensional density.
\newblock {\em Electronic Journal of Statistics}, 4:254--270, 2010.

\bibitem{daskalakis2016ten}
Constantinos Daskalakis, Christos Tzamos, and Manolis Zampetakis.
\newblock {Ten steps of EM suffice for mixtures of two Gaussians}.
\newblock {\em arXiv preprint arXiv:1609.00368}, 2016.

\bibitem{dempster1977maximum}
Arthur~P. Dempster, Nan~M. Laird, and Donald~B. Rubin.
\newblock Maximum likelihood from incomplete data via the {EM} algorithm.
\newblock {\em Journal of the Royal Statistical Society: Series B
  (Methodological)}, 39(1):1--22, 1977.

\bibitem{diakonikolas2018polynomial}
Ilias Diakonikolas, Anastasios Sidiropoulos, and Alistair Stewart.
\newblock A polynomial time algorithm for maximum likelihood estimation of
  multivariate log-concave densities.
\newblock {\em arXiv preprint arXiv:1812.05524}, 2018.

\bibitem{gilks1992adaptive}
Walter~R. Gilks and Pascal Wild.
\newblock Adaptive rejection sampling for gibbs sampling.
\newblock {\em Journal of the Royal Statistical Society: Series C (Applied
  Statistics)}, 41(2):337--348, 1992.

\bibitem{hsu2013learning}
Daniel Hsu and Sham~M. Kakade.
\newblock Learning mixtures of spherical {Gaussians}: moment methods and
  spectral decompositions.
\newblock In {\em Proceedings of the 4th conference on Innovations in
  Theoretical Computer Science}, pages 11--20. ACM, 2013.

\bibitem{jin2016local}
Chi Jin, Yuchen Zhang, Sivaraman Balakrishnan, Martin~J. Wainwright, and
  Michael~I. Jordan.
\newblock Local maxima in the likelihood of {Gaussian} mixture models:
  Structural results and algorithmic consequences.
\newblock In {\em Advances in neural information processing systems}, pages
  4116--4124, 2016.

\bibitem{jongbloed1998iterative}
Geurt Jongbloed.
\newblock The iterative convex minorant algorithm for nonparametric estimation.
\newblock {\em Journal of Computational and Graphical Statistics},
  7(3):310--321, 1998.

\bibitem{klusowski2019estimating}
Jason~M. Klusowski, Dana Yang, and W.~D. Brinda.
\newblock Estimating the coefficients of a mixture of two linear regressions by
  expectation maximization.
\newblock {\em IEEE Transactions on Information Theory}, 2019.

\bibitem{kwon2018global}
Jeongyeol Kwon, Wei Qian, Constantine Caramanis, Yudong Chen, and Damek Davis.
\newblock {Global Convergence of {EM} Algorithm for Mixtures of Two Component
  Linear Regression}.
\newblock {\em arXiv preprint arXiv:1810.05752}, 2018.

\bibitem{lindsay1995mixture}
Bruce~G. Lindsay.
\newblock Mixture models: theory, geometry and applications.
\newblock In {\em NSF-CBMS regional conference series in probability and
  statistics}, pages i--163. JSTOR, 1995.

\bibitem{nagarajan2019convergence}
Sai~Ganesh Nagarajan and Ioannis Panageas.
\newblock On the convergence of {EM} for truncated mixtures of two {Gaussians}.
\newblock {\em arXiv preprint arXiv:1902.06958}, 2019.

\bibitem{ross2011fundamentals}
Nathan Ross.
\newblock {Fundamentals of Stein{\textquoteright}s method}.
\newblock {\em Probability Surveys}, 8:210--293, 2011.

\bibitem{rufibach2006log}
Kaspar Rufibach.
\newblock {\em Log-concave density estimation and bump hunting for IID
  observations}.
\newblock PhD thesis, Verlag nicht ermittelbar, 2006.

\bibitem{sanjeev2001learning}
Arora Sanjeev and Ravi Kannan.
\newblock Learning mixtures of arbitrary {Gaussians}.
\newblock In {\em Proceedings of the thirty-third annual ACM symposium on
  Theory of computing}, pages 247--257. ACM, 2001.

\bibitem{saumard2014log}
Adrien Saumard and Jon~A. Wellner.
\newblock {Log-concavity and strong log-concavity: a review}.
\newblock {\em Statistics surveys}, 8:45, 2014.

\bibitem{titterington1985statistical}
D.~Michael Titterington, Adrian F.~M. Smith, and Udi~E. Makov.
\newblock {\em Statistical analysis of finite mixture distributions}.
\newblock Wiley,, 1985.

\bibitem{vershynin2018high}
Roman Vershynin.
\newblock {\em High-dimensional probability: An introduction with applications
  in data science}, volume~47.
\newblock Cambridge University Press, 2018.

\bibitem{walther2002detecting}
Guenther Walther.
\newblock Detecting the presence of mixing with multiscale maximum likelihood.
\newblock {\em Journal of the American Statistical Association},
  97(458):508--513, 2002.

\bibitem{wu1983convergence}
CF~Jeff Wu.
\newblock On the convergence properties of the {EM} algorithm.
\newblock {\em The Annals of statistics}, 11(1):95--103, 1983.

\bibitem{xu2016global}
Ji~Xu, Daniel~J. Hsu, and Arian Maleki.
\newblock Global analysis of expectation maximization for mixtures of two
  {Gaussians}.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2676--2684, 2016.

\bibitem{yan2017convergence}
Bowei Yan, Mingzhang Yin, and Purnamrita Sarkar.
\newblock Convergence of gradient {EM} on multi-component mixture of
  {Gaussians}.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6956--6966, 2017.

\end{thebibliography}
