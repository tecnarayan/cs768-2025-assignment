@misc{kopf2023openassistant,
      title={OpenAssistant Conversations -- Democratizing Large Language Model Alignment}, 
      author={Andreas Köpf and Yannic Kilcher and Dimitri von Rütte and Sotiris Anagnostidis and Zhi-Rui Tam and Keith Stevens and Abdullah Barhoum and Nguyen Minh Duc and Oliver Stanley and Richárd Nagyfi and Shahul ES and Sameer Suri and David Glushkov and Arnav Dantuluri and Andrew Maguire and Christoph Schuhmann and Huu Nguyen and Alexander Mattick},
      year={2023},
      eprint={2304.07327},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{kasneci2023chatgpt,
title = {ChatGPT for good? On opportunities and challenges of large language models for education},
journal = {Learning and Individual Differences},
volume = {103},
pages = {102274},
year = {2023},
doi = {https://doi.org/10.1016/j.lindif.2023.102274},
author = {Enkelejda Kasneci and Kathrin Sessler and Stefan Küchemann and Maria Bannert and Daryna Dementieva and Frank Fischer and Urs Gasser and Georg Groh and Stephan Günnemann and Eyke Hüllermeier and Stepha Krusche and Gitta Kutyniok and Tilman Michaeli and Claudia Nerdel and Jürgen Pfeffer and Oleksandra Poquet and Michael Sailer and Albrecht Schmidt and Tina Seidel and Matthias Stadler and Jochen Weller and Jochen Kuhn and Gjergji Kasneci},
}

@misc{chen2023frugalgpt,
      title={FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance}, 
      author={Lingjiao Chen and Matei Zaharia and James Zou},
      year={2023},
      eprint={2305.05176},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{McDonald_2022,
	doi = {10.18653/v1/2022.findings-naacl.151},
  
	year = 2022,
	publisher = {Association for Computational Linguistics},
  
	author = {Joseph McDonald and Baolin Li and Nathan Frey and Devesh Tiwari and Vijay Gadepally and Siddharth Samsi},
  
	title = {Great Power, Great Responsibility: Recommendations for Reducing Energy for Training Language Models},
  
	booktitle = {Findings of the Association for Computational Linguistics: {NAACL} 2022}
}

@Article{eysenbach_2023_chatgpt,
author="Eysenbach, Gunther",
title="The Role of ChatGPT, Generative Language Models, and Artificial Intelligence in Medical Education: A Conversation With ChatGPT and a Call for Papers",
journal="JMIR Med Educ",
year="2023",
month="Mar",
day="6",
volume="9",
pages="e46885",
keywords="artificial intelligence; AI; ChatGPT; generative language model; medical education; interview; future of education",
issn="2369-3762",
doi="10.2196/46885",
url="https://mededu.jmir.org/2023/1/e46885",
url="https://doi.org/10.2196/46885",
url="http://www.ncbi.nlm.nih.gov/pubmed/36863937"
}

@inproceedings{bender_2021_parrots,
author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
title = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\,\raisebox{-2pt}{\includegraphics[scale=0.11]{parrot.png}}},
year = {2021},
isbn = {9781450383097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442188.3445922},
doi = {10.1145/3442188.3445922},
abstract = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
pages = {610–623},
numpages = {14},
location = {Virtual Event, Canada},
series = {FAccT '21}
}

@inproceedings{lucy-bamman-2021-gender,
    title = "Gender and Representation Bias in {GPT}-3 Generated Stories",
    author = "Lucy, Li  and
      Bamman, David",
    booktitle = "Proceedings of the Third Workshop on Narrative Understanding",
    month = jun,
    year = "2021",
    address = "Virtual",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.nuse-1.5",
    doi = "10.18653/v1/2021.nuse-1.5",
    pages = "48--55",
    abstract = "Using topic modeling and lexicon-based word similarity, we find that stories generated by GPT-3 exhibit many known gender stereotypes. Generated stories depict different topics and descriptions depending on GPT-3{'}s perceived gender of the character in a prompt, with feminine characters more likely to be associated with family and appearance, and described as less powerful than masculine characters, even when associated with high power verbs in a prompt. Our study raises questions on how one can avoid unintended social biases when using large language models for storytelling.",
}

@misc{nadeem2020stereoset,
      title={StereoSet: Measuring stereotypical bias in pretrained language models}, 
      author={Moin Nadeem and Anna Bethke and Siva Reddy},
      year={2020},
      eprint={2004.09456},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{Quach_2022, title={Researchers made an OpenAI GPT-3 medical chatbot as an experiment. it told a mock patient to kill themselves}, url={https://www.theregister.com/2020/10/28/gpt3_medical_chatbot_experiment/}, journal={The Register}, author={Quach, Katyanna}, year={2022}, month={Aug}} 

@Article{bickmore_2018_safety,
author="Bickmore, Timothy W
and Trinh, Ha
and Olafsson, Stefan
and O'Leary, Teresa K
and Asadi, Reza
and Rickles, Nathaniel M
and Cruz, Ricardo",
title="Patient and Consumer Safety Risks When Using Conversational Assistants for Medical Information: An Observational Study of Siri, Alexa, and Google Assistant",
journal="J Med Internet Res",
year="2018",
month="Sep",
day="04",
volume="20",
number="9",
issn="1438-8871",
doi="10.2196/11510",
url="http://www.jmir.org/2018/9/e11510/",
}

@inproceedings{carlini21extracting,
author = {Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and Oprea, Alina and Raffel, Colin},
title = {Extracting Training Data from Large Language Models},
booktitle = {USENIX Security Symposium},
year = {2021},
howpublished = {arXiv preprint arXiv:2012.07805},
url = {https://arxiv.org/abs/2012.07805}
}

@misc{mckee_bai_fiske_2021,
 title={Humans perceive warmth and competence in artificial intelligence},
 url={psyarxiv.com/5ursp},
 DOI={10.31234/osf.io/5ursp},
 publisher={PsyArXiv},
 author={McKee, Kevin R and Bai, Xuechunzi and Fiske, Susan},
 year={2021},
 month={Feb}
}

@misc{boiko2023emergent,
      title={Emergent autonomous scientific research capabilities of large language models}, 
      author={Daniil A. Boiko and Robert MacKnight and Gabe Gomes},
      year={2023},
      eprint={2304.05332},
      archivePrefix={arXiv},
      primaryClass={physics.chem-ph}
}

@misc{ranade2021generating,
      title={Generating Fake Cyber Threat Intelligence Using Transformer-Based Models}, 
      author={Priyanka Ranade and Aritran Piplai and Sudip Mittal and Anupam Joshi and Tim Finin},
      year={2021},
      eprint={2102.04351},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}