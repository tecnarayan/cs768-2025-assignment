\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{conf/iccv/AntolALMBZP15}
Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C.L., Parikh,
  D.: {VQA:} visual question answering. In: ICCV (2015)

\bibitem{atrey2010multimodal}
Atrey, P.K., Hossain, M.A., El~Saddik, A., Kankanhalli, M.S.: Multimodal fusion
  for multimedia analysis: a survey. In: Multimedia systems (2010)

\bibitem{conf/iccv/BalntasDSSKK17}
Balntas, V., Doumanoglou, A., Sahin, C., Sock, J., Kouskouridas, R., Kim, T.:
  Pose guided {RGBD} feature learning for 3d object pose estimation. In: ICCV
  (2017)

\bibitem{journals/pami/BaltrusaitisAM19}
Baltrusaitis, T., Ahuja, C., Morency, L.: Multimodal machine learning: {A}
  survey and taxonomy. In: {IEEE} Trans. PAMI (2019)

\bibitem{conf/iclr/BinkowskiSAG18}
Binkowski, M., Sutherland, D.J., Arbel, M., Gretton, A.: Demystifying {MMD}
  gans. In: ICLR (2018)

\bibitem{conf/nips/BousmalisTSKE16}
Bousmalis, K., Trigeorgis, G., Silberman, N., Krishnan, D., Erhan, D.: Domain
  separation networks. In: NIPS (2016)

\bibitem{bruni2014multimodal}
Bruni, E., Tran, N.K., Baroni, M.: Multimodal distributional semantics. In:
  Journal of Artificial Intelligence Research (2014)

\bibitem{conf/cvpr/ChangYSKH19}
Chang, W., You, T., Seo, S., Kwak, S., Han, B.: Domain-specific batch
  normalization for unsupervised domain adaptation. In: CVPR (2019)

\bibitem{conf/cvpr/ChengCLZH17}
Cheng, Y., Cai, R., Li, Z., Zhao, X., Huang, K.: Locality-sensitive
  deconvolution networks with gated fusion for {RGB-D} indoor semantic
  segmentation. In: CVPR (2017)

\bibitem{conf/cvpr/CordtsORREBFRS16}
Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R.,
  Franke, U., Roth, S., Schiele, B.: The cityscapes dataset for semantic urban
  scene understanding. In: CVPR (2016)

\bibitem{de2017guesswhat}
De~Vries, H., Strub, F., Chandar, S., Pietquin, O., Larochelle, H., Courville,
  A.: Guesswhat?! visual object discovery through multi-modal dialogue. In:
  CVPR (2017)

\bibitem{conf/cvpr/DuWWZW19}
Du, D., Wang, L., Wang, H., Zhao, K., Wu, G.: Translate-to-recognize networks
  for {RGB-D} scene recognition. In: CVPR (2019)

\bibitem{dumoulin2018feature}
Dumoulin, V., Perez, E., Schucher, N., Strub, F., Vries, H.d., Courville, A.,
  Bengio, Y.: Feature-wise transformations. In: Distill (2018)

\bibitem{fan2018end}
Fan, L., Huang, W., Gan, C., Ermon, S., Gong, B., Huang, J.: End-to-end
  learning of motion representation for video understanding. In: CVPR (2018)

\bibitem{conf/eccv/GarciaMM18}
Garcia, N.C., Morerio, P., Murino, V.: Modality distillation with multiple
  stream networks for action recognition. In: ECCV (2018)

\bibitem{journals/jmlr/GrettonBRSS12}
Gretton, A., Borgwardt, K.M., Rasch, M.J., Sch{\"{o}}lkopf, B., Smola, A.J.: A
  kernel two-sample test. In: JMLR (2012)

\bibitem{conf/cvpr/GuptaAM13}
Gupta, S., Arbelaez, P., Malik, J.: Perceptual organization and recognition of
  indoor scenes from {RGB-D} images. In: CVPR (2013)

\bibitem{hall1997introduction}
Hall, D.L., Llinas, J.: An introduction to multisensor data fusion. In:
  Proceedings of the IEEE (1997)

\bibitem{conf/accv/HazirbasMDC16}
Hazirbas, C., Ma, L., Domokos, C., Cremers, D.: Fusenet: Incorporating depth
  into semantic segmentation via fusion-based {CNN} architecture. In: ACCV
  (2016)

\bibitem{conf/cvpr/HeZRS16}
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image
  recognition. In: CVPR (2016)

\bibitem{conf/nips/HeuselRUNH17}
Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S.: Gans
  trained by a two time-scale update rule converge to a local nash equilibrium.
  In: NIPS (2017)

\bibitem{conf/icip/HuYFW19}
Hu, X., Yang, K., Fei, L., Wang, K.: {ACNET:} attention based network to
  exploit complementary features for {RGBD} semantic segmentation. In: ICIP
  (2019)

\bibitem{conf/nips/IlievskiF17}
Ilievski, I., Feng, J.: Multimodal learning and reasoning for visual question
  answering. In: NIPS (2017)

\bibitem{conf/icml/IoffeS15}
Ioffe, S., Szegedy, C.: Batch normalization: Accelerating deep network training
  by reducing internal covariate shift. In: ICML (2015)

\bibitem{conf/cvpr/IsolaZZE17}
Isola, P., Zhu, J., Zhou, T., Efros, A.A.: Image-to-image translation with
  conditional adversarial networks. In: CVPR (2017)

\bibitem{conf/iclr/JinYBJ19}
Jin, W., Yang, K., Barzilay, R., Jaakkola, T.S.: Learning multimodal
  graph-to-graph translation for molecule optimization. In: ICLR (2019)

\bibitem{kiela2017deep}
Kiela, D.: Deep embodiment: grounding semantics in perceptual modalities. In:
  Technical Report (2017)

\bibitem{lazaridou2014wampimuk}
Lazaridou, A., Bruni, E., Baroni, M.: Is this a wampimuk? cross-modal mapping
  between distributional semantics and the visual world. In: ACL (2014)

\bibitem{conf/iccv/LeePH17}
Lee, S., Park, S., Hong, K.: Rdfnet: {RGB-D} multi-level residual feature
  fusion for indoor semantic segmentation. In: ICCV (2017)

\bibitem{conf/iccv/LinCCHH17}
Lin, D., Chen, G., Cohen{-}Or, D., Heng, P., Huang, H.: Cascaded feature
  network for semantic segmentation of {RGB-D} images. In: ICCV (2017)

\bibitem{journals/tcyb/LinZJLH20}
Lin, D., Zhang, R., Ji, Y., Li, P., Huang, H.: {SCN:} switchable context
  network for semantic segmentation of {RGB-D} images. In: {IEEE} Trans.
  Cybern. (2020)

\bibitem{lin2019refinenet}
Lin, G., Liu, F., Milan, A., Shen, C., Reid, I.: Refinenet: Multi-path
  refinement networks for dense prediction. In: {IEEE} Trans. PAMI (2019)

\bibitem{conf/iccv/LiuLSHYZ17}
Liu, Z., Li, J., Shen, Z., Huang, G., Yan, S., Zhang, C.: Learning efficient
  convolutional networks through network slimming. In: ICCV (2017)

\bibitem{journals/corr/LongSD14}
Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic
  segmentation. In: CVPR (2015)

\bibitem{conf/icml/NgiamKKNLN11}
Ngiam, J., Khosla, A., Kim, M., Nam, J., Lee, H., Ng, A.Y.: Multimodal deep
  learning. In: ICML (2011)

\bibitem{conf/nips/PaszkeGMLBCKLGA19}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., K{\"{o}}pf, A., Yang,
  E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang,
  L., Bai, J., Chintala, S.: Pytorch: An imperative style, high-performance
  deep learning library. In: NeurIPS (2019)

\bibitem{conf/iccv/QiLJFU17}
Qi, X., Liao, R., Jia, J., Fidler, S., Urtasun, R.: 3d graph neural networks
  for {RGBD} semantic segmentation. In: ICCV (2017)

\bibitem{ramachandram2017deep}
Ramachandram, D., Taylor, G.W.: Deep multimodal learning: A survey on recent
  advances and trends. In: IEEE Signal Processing Magazine (2017)

\bibitem{journals/ijcv/RussakovskyDSKS15}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M.S., Berg, A.C., Li, F.: Imagenet large
  scale visual recognition challenge. In: IJCV (2015)

\bibitem{shao2020channel}
Shao, W., Tang, S., Pan, X., Tan, P., Wang, X., Luo, P.: Channel equilibrium
  networks for learning deep representation. In: ICML (2020)

\bibitem{conf/eccv/SilbermanHKF12}
Silberman, N., Hoiem, D., Kohli, P., Fergus, R.: Indoor segmentation and
  support inference from {RGBD} images. In: ECCV (2012)

\bibitem{snoek2005early}
Snoek, C.G., Worring, M., Smeulders, A.W.: Early versus late fusion in semantic
  video analysis. In: ACM MM (2005)

\bibitem{conf/cvpr/SongLX15}
Song, S., Lichtenberg, S.P., Xiao, J.: {SUN} {RGB-D:} {A} {RGB-D} scene
  understanding benchmark suite. In: CVPR (2015)

\bibitem{journals/tip/SongLLG20}
Song, S., Liu, J., Li, Y., Guo, Z.: Modality compensation network: Cross-modal
  adaptation for action recognition. In: {IEEE} Trans. Image Process. (2020)

\bibitem{journals/ijcv/ValadaMB20}
Valada, A., Mohan, R., Burgard, W.: Self-supervised model adaptation for
  multimodal semantic segmentation. In: IJCV (2020)

\bibitem{conf/nips/VriesSMLPC17}
de~Vries, H., Strub, F., Mary, J., Larochelle, H., Pietquin, O., Courville,
  A.C.: Modulating early visual processing by language. In: NIPS (2017)

\bibitem{conf/eccv/WangWTSW16}
Wang, J., Wang, Z., Tao, D., See, S., Wang, G.: Learning common and specific
  features for {RGB-D} semantic segmentation with deconvolutional networks. In:
  ECCV (2016)

\bibitem{wang2020asymfusion}
Wang, Y., Sun, F., Lu, M., Yao, A.: Learning deep multimodal feature
  representation with asymmetric multi-layer fusion. In: ACM MM (2020)

\bibitem{conf/iclr/YeL0W18}
Ye, J., Lu, X., Lin, Z., Wang, J.Z.: Rethinking the
  smaller-norm-less-informative assumption in channel pruning of convolution
  layers. In: ICLR (2018)

\bibitem{conf/cvpr/ZamirSSGMS18}
Zamir, A.R., Sax, A., Shen, W.B., Guibas, L.J., Malik, J., Savarese, S.:
  Taskonomy: Disentangling task transfer learning. In: CVPR (2018)

\bibitem{conf/cvpr/ZengTHYSCW19}
Zeng, J., Tong, Y., Huang, Y., Yan, Q., Sun, W., Chen, J., Wang, Y.: Deep
  surface normal estimation with hierarchical {RGB-D} fusion. In: CVPR (2019)

\bibitem{conf/iccv/ZhangZSWSL19}
Zhang, W., Zhou, H., Sun, S., Wang, Z., Shi, J., Loy, C.C.: Robust
  multi-modality multi-object tracking. In: ICCV (2019)

\bibitem{conf/cvpr/ZhangZLS18}
Zhang, X., Zhou, X., Lin, M., Sun, J.: Shufflenet: An extremely efficient
  convolutional neural network for mobile devices. In: CVPR (2018)

\bibitem{conf/cvpr/ZhaoSQWJ17}
Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network.
  In: CVPR (2017)

\end{thebibliography}
