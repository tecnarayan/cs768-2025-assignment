\begin{thebibliography}{85}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abu-El-Haija et~al.(2016)Abu-El-Haija, Kothari, Lee, Natsev, Toderici,
  Varadarajan, and Vijayanarasimhan]{abu2016youtube}
Sami Abu-El-Haija, Nisarg Kothari, Joonseok Lee, Paul Natsev, George Toderici,
  Balakrishnan Varadarajan, and Sudheendra Vijayanarasimhan.
\newblock Youtube-8m: A large-scale video classification benchmark.
\newblock \emph{arXiv preprint arXiv:1609.08675}, 2016.

\bibitem[Achlioptas et~al.(2021)Achlioptas, Ovsjanikov, Haydarov, Elhoseiny,
  and Guibas]{achlioptas2021artemis}
Panos Achlioptas, Maks Ovsjanikov, Kilichbek Haydarov, Mohamed Elhoseiny, and
  Leonidas~J Guibas.
\newblock Artemis: Affective language for visual art.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 11569--11579, 2021.

\bibitem[Anderson(2001)]{anderson2001symposium}
Elizabeth Anderson.
\newblock Symposium on amartya sen's philosophy: 2 unstrapping the straitjacket
  of ‘preference’: a comment on amartya sen's contributions to philosophy
  and economics.
\newblock \emph{Economics \& Philosophy}, 17\penalty0 (1):\penalty0 21--38,
  2001.

\bibitem[Anderson and Anderson(2011)]{Anderson2011MachineE}
Michael Anderson and Susan~Leigh Anderson.
\newblock Machine ethics.
\newblock 2011.

\bibitem[Bargal et~al.(2016)Bargal, Barsoum, Ferrer, and
  Zhang]{bargal2016emotion}
Sarah~Adel Bargal, Emad Barsoum, Cristian~Canton Ferrer, and Cha Zhang.
\newblock Emotion recognition in the wild from videos using images.
\newblock In \emph{Proceedings of the 18th ACM International Conference on
  Multimodal Interaction}, pages 433--436, 2016.

\bibitem[Barrett(2009)]{barrett2009variety}
Lisa~Feldman Barrett.
\newblock Variety is the spice of life: A psychological construction approach
  to understanding variability in emotion.
\newblock \emph{Cognition and Emotion}, 23\penalty0 (7):\penalty0 1284--1306,
  2009.

\bibitem[Baveye et~al.(2015)Baveye, Dellandrea, Chamaret, and
  Chen]{baveye2015liris}
Yoann Baveye, Emmanuel Dellandrea, Christel Chamaret, and Liming Chen.
\newblock Liris-accede: A video database for affective content analysis.
\newblock \emph{IEEE Transactions on Affective Computing}, 6\penalty0
  (1):\penalty0 43--55, 2015.

\bibitem[Caba~Heilbron et~al.(2015)Caba~Heilbron, Escorcia, Ghanem, and
  Carlos~Niebles]{caba2015activitynet}
Fabian Caba~Heilbron, Victor Escorcia, Bernard Ghanem, and Juan Carlos~Niebles.
\newblock Activitynet: A large-scale video benchmark for human activity
  understanding.
\newblock In \emph{Proceedings of the ieee conference on computer vision and
  pattern recognition}, pages 961--970, 2015.

\bibitem[Carstensen et~al.(2000)Carstensen, Pasupathi, Mayr, and
  Nesselroade]{carstensen2000emotional}
Laura~L Carstensen, Monisha Pasupathi, Ulrich Mayr, and John~R Nesselroade.
\newblock Emotional experience in everyday life across the adult life span.
\newblock \emph{Journal of personality and social psychology}, 79\penalty0
  (4):\penalty0 644, 2000.

\bibitem[Cowen and Keltner(2017)]{Cowen2017SelfreportC2}
Alan~S. Cowen and Dacher Keltner.
\newblock Self-report captures 27 distinct categories of emotion bridged by
  continuous gradients.
\newblock \emph{Proceedings of the National Academy of Sciences}, 2017.

\bibitem[de~Lazari-Radek and Singer(2017)]{LazariRadek2017UtilitarianismAV}
Katarzyna de~Lazari-Radek and Peter Singer.
\newblock Utilitarianism: A very short introduction.
\newblock 2017.

\bibitem[Demszky et~al.(2020)Demszky, Movshovitz-Attias, Ko, Cowen, Nemade, and
  Ravi]{demszky2020goemotions}
Dorottya Demszky, Dana Movshovitz-Attias, Jeongwoo Ko, Alan Cowen, Gaurav
  Nemade, and Sujith Ravi.
\newblock Goemotions: A dataset of fine-grained emotions.
\newblock \emph{arXiv preprint arXiv:2005.00547}, 2020.

\bibitem[Douglas-Cowie et~al.(2007)Douglas-Cowie, Cowie, Sneddon, Cox, Lowry,
  Mcrorie, Martin, Devillers, Abrilian, Batliner, et~al.]{douglas2007humaine}
Ellen Douglas-Cowie, Roddy Cowie, Ian Sneddon, Cate Cox, Orla Lowry, Margaret
  Mcrorie, Jean-Claude Martin, Laurence Devillers, Sarkis Abrilian, Anton
  Batliner, et~al.
\newblock The humaine database: Addressing the collection and annotation of
  naturalistic and induced emotional data.
\newblock In \emph{International conference on affective computing and
  intelligent interaction}, pages 488--500. Springer, 2007.

\bibitem[Ekman(1992)]{Ekman1992AnAF}
Paul Ekman.
\newblock An argument for basic emotions.
\newblock \emph{Cognition \& Emotion}, 6:\penalty0 169--200, 1992.

\bibitem[Epstein et~al.(2020)Epstein, Chen, and Vondrick]{epstein2020oops}
Dave Epstein, Boyuan Chen, and Carl Vondrick.
\newblock Oops! predicting unintentional action in video.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 919--929, 2020.

\bibitem[Facebook()]{fbupdate}
Facebook.
\newblock Bringing people closer together.
\newblock URL
  \url{https://about.fb.com/news/2018/01/news-feed-fyi-bringing-people-closer-together/}.

\bibitem[Feichtenhofer et~al.(2019)Feichtenhofer, Fan, Malik, and
  He]{feichtenhofer2019slowfast}
Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and Kaiming He.
\newblock Slowfast networks for video recognition.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 6202--6211, 2019.

\bibitem[FRED()]{fredrealgdp}
FRED.
\newblock U.s. bureau of economic analysis, real gross domestic product per
  capita [a939rx0q048sbea].
\newblock retrieved from FRED, Federal Reserve Bank of St. Louis;
  https://fred.stlouisfed.org/series/A939RX0Q048SBEA, October 14, 2022.

\bibitem[Frijda(1988)]{Frijda1988TheLO}
Nico~H. Frijda.
\newblock The laws of emotion.
\newblock \emph{The American psychologist}, 1988.

\bibitem[Garcia-Garcia et~al.(2018)Garcia-Garcia, Orts-Escolano, Oprea,
  Villena-Martinez, Martinez-Gonzalez, and Garcia-Rodriguez]{garcia2018survey}
Alberto Garcia-Garcia, Sergio Orts-Escolano, Sergiu Oprea, Victor
  Villena-Martinez, Pablo Martinez-Gonzalez, and Jose Garcia-Rodriguez.
\newblock A survey on deep learning techniques for image and video semantic
  segmentation.
\newblock \emph{Applied Soft Computing}, 70:\penalty0 41--65, 2018.

\bibitem[Ghadiyaram et~al.(2019)Ghadiyaram, Tran, and
  Mahajan]{ghadiyaram2019large}
Deepti Ghadiyaram, Du~Tran, and Dhruv Mahajan.
\newblock Large-scale weakly-supervised pre-training for video action
  recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 12046--12055, 2019.

\bibitem[Gorelick et~al.(2007)Gorelick, Blank, Shechtman, Irani, and
  Basri]{gorelick2007actions}
Lena Gorelick, Moshe Blank, Eli Shechtman, Michal Irani, and Ronen Basri.
\newblock Actions as space-time shapes.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 29\penalty0 (12):\penalty0 2247--2253, 2007.

\bibitem[Goyal et~al.(2017)Goyal, Ebrahimi~Kahou, Michalski, Materzynska,
  Westphal, Kim, Haenel, Fruend, Yianilos, Mueller-Freitag,
  et~al.]{goyal2017something}
Raghav Goyal, Samira Ebrahimi~Kahou, Vincent Michalski, Joanna Materzynska,
  Susanne Westphal, Heuna Kim, Valentin Haenel, Ingo Fruend, Peter Yianilos,
  Moritz Mueller-Freitag, et~al.
\newblock The" something something" video database for learning and evaluating
  visual common sense.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 5842--5850, 2017.

\bibitem[He et~al.(2020)He, Gkioxari, Doll{\'a}r, and Girshick]{He2020MaskR}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross~B. Girshick.
\newblock Mask r-cnn.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 42:\penalty0 386--397, 2020.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and
  Girshick]{he2022masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross
  Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 16000--16009, 2022.

\bibitem[Hendrycks and Mazeika(2022)]{hendrycks2022x}
Dan Hendrycks and Mantas Mazeika.
\newblock X-risk analysis for ai research.
\newblock \emph{arXiv preprint arXiv:2206.05862}, 2022.

\bibitem[Hendrycks et~al.(2020)Hendrycks, Burns, Basart, Critch, Li, Song, and
  Steinhardt]{hendrycks2020ethicsdataset}
Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song,
  and Jacob Steinhardt.
\newblock Aligning {AI} with shared human values, 2020.

\bibitem[Hendrycks et~al.(2021{\natexlab{a}})Hendrycks, Burns, Basart, Critch,
  Li, Song, and Steinhardt]{Hendrycks2021AligningAW}
Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song,
  and Jacob Steinhardt.
\newblock Aligning {AI} with shared human values.
\newblock \emph{ICLR}, 2021{\natexlab{a}}.

\bibitem[Hendrycks et~al.(2021{\natexlab{b}})Hendrycks, Carlini, Schulman, and
  Steinhardt]{hendrycks2021unsolved}
Dan Hendrycks, Nicholas Carlini, John Schulman, and Jacob Steinhardt.
\newblock Unsolved problems in ml safety.
\newblock \emph{arXiv preprint arXiv:2109.13916}, 2021{\natexlab{b}}.

\bibitem[Hendrycks et~al.(2021{\natexlab{c}})Hendrycks, Mazeika, Zou, Patel,
  Zhu, Navarro, Song, Li, and Steinhardt]{Hendrycks2021WhatWJ}
Dan Hendrycks, Mantas Mazeika, Andy Zou, Sahil Patel, Christine Zhu, Jesus
  Navarro, Dawn Song, Bo~Li, and Jacob Steinhardt.
\newblock What would jiminy cricket do? towards agents that behave morally.
\newblock \emph{NeurIPS}, 2021{\natexlab{c}}.

\bibitem[Hoerger and Quirk(2010)]{hoerger2010affective}
Michael Hoerger and Stuart~W Quirk.
\newblock Affective forecasting and the big five.
\newblock \emph{Personality and individual differences}, 49\penalty0
  (8):\penalty0 972--976, 2010.

\bibitem[Huang et~al.(2019)Huang, Wang, Huang, Huang, Wei, Shi, and
  Liu]{Huang2019CCNetCA}
Zilong Huang, Xinggang Wang, Lichao Huang, Chang Huang, Yunchao Wei, Humphrey
  Shi, and Wenyu Liu.
\newblock Ccnet: Criss-cross attention for semantic segmentation.
\newblock \emph{2019 IEEE/CVF International Conference on Computer Vision
  (ICCV)}, pages 603--612, 2019.

\bibitem[Hume(1739)]{hume}
David Hume.
\newblock \emph{A Treatise of Human Nature}.
\newblock 1739.

\bibitem[Jiang et~al.(2014)Jiang, Xu, and Xue]{jiang2014predicting}
Yu-Gang Jiang, Baohan Xu, and Xiangyang Xue.
\newblock Predicting emotions in user-generated videos.
\newblock In \emph{Twenty-Eighth AAAI Conference on Artificial Intelligence},
  2014.

\bibitem[Kahneman(2011)]{Kahneman2011ThinkingFA}
Daniel Kahneman.
\newblock Thinking, fast and slow.
\newblock 2011.

\bibitem[Kahneman and Deaton(2010)]{kahneman2010high}
Daniel Kahneman and Angus Deaton.
\newblock High income improves evaluation of life but not emotional well-being.
\newblock \emph{Proceedings of the national academy of sciences}, 107\penalty0
  (38):\penalty0 16489--16493, 2010.

\bibitem[Kahneman et~al.(1982)Kahneman, Slovic, Slovic, and
  Tversky]{kahneman1982judgment}
Daniel Kahneman, Stewart~Paul Slovic, Paul Slovic, and Amos Tversky.
\newblock \emph{Judgment under uncertainty: Heuristics and biases}.
\newblock Cambridge university press, 1982.

\bibitem[Kang and Wildes(2016)]{kang2016review}
Soo~Min Kang and Richard~P Wildes.
\newblock Review of action recognition and detection methods.
\newblock \emph{arXiv preprint arXiv:1610.06906}, 2016.

\bibitem[Karpathy et~al.(2014)Karpathy, Toderici, Shetty, Leung, Sukthankar,
  and Fei-Fei]{karpathy2014large}
Andrej Karpathy, George Toderici, Sanketh Shetty, Thomas Leung, Rahul
  Sukthankar, and Li~Fei-Fei.
\newblock Large-scale video classification with convolutional neural networks.
\newblock In \emph{Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, pages 1725--1732, 2014.

\bibitem[Kay et~al.(2017{\natexlab{a}})Kay, Carreira, Simonyan, Zhang, Hillier,
  Vijayanarasimhan, Viola, Green, Back, Natsev, Suleyman, and
  Zisserman]{Kay2017TheKH}
Will Kay, Jo{\~a}o Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier,
  Sudheendra Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Apostol
  Natsev, Mustafa Suleyman, and Andrew Zisserman.
\newblock The kinetics human action video dataset.
\newblock \emph{ArXiv}, 2017{\natexlab{a}}.

\bibitem[Kay et~al.(2017{\natexlab{b}})Kay, Carreira, Simonyan, Zhang, Hillier,
  Vijayanarasimhan, Viola, Green, Back, Natsev, et~al.]{kay2017kinetics}
Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra
  Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, et~al.
\newblock The kinetics human action video dataset.
\newblock \emph{arXiv preprint arXiv:1705.06950}, 2017{\natexlab{b}}.

\bibitem[Koelstra et~al.(2012)Koelstra, Muhl, Soleymani, Lee, Yazdani,
  Ebrahimi, Pun, Nijholt, and Patras]{koelstra2012deap}
Sander Koelstra, Christian Muhl, Mohammad Soleymani, Jong-Seok Lee, Ashkan
  Yazdani, Touradj Ebrahimi, Thierry Pun, Anton Nijholt, and Ioannis Patras.
\newblock Deap: A database for emotion analysis; using physiological signals.
\newblock \emph{IEEE transactions on affective computing}, 3\penalty0
  (1):\penalty0 18--31, 2012.

\bibitem[Kross et~al.(2013)Kross, Verduyn, Demiralp, Park, Lee, Lin, Shablack,
  Jonides, and Ybarra]{kross2013facebook}
Ethan Kross, Philippe Verduyn, Emre Demiralp, Jiyoung Park, David~Seungjae Lee,
  Natalie Lin, Holly Shablack, John Jonides, and Oscar Ybarra.
\newblock Facebook use predicts declines in subjective well-being in young
  adults.
\newblock \emph{PloS one}, 8\penalty0 (8):\penalty0 e69841, 2013.

\bibitem[Kuehne et~al.(2011)Kuehne, Jhuang, Garrote, Poggio, and
  Serre]{kuehne2011hmdb}
Hildegard Kuehne, Hueihan Jhuang, Est{\'\i}baliz Garrote, Tomaso Poggio, and
  Thomas Serre.
\newblock Hmdb: a large video database for human motion recognition.
\newblock In \emph{2011 International conference on computer vision}, pages
  2556--2563. IEEE, 2011.

\bibitem[Kurdi et~al.(2017)Kurdi, Lozano, and Banaji]{kurdi2017introducing}
Benedek Kurdi, Shayn Lozano, and Mahzarin~R Banaji.
\newblock Introducing the open affective standardized image set (oasis).
\newblock \emph{Behavior research methods}, 49\penalty0 (2):\penalty0 457--470,
  2017.

\bibitem[Lang and Bradley(2007)]{lang2007international}
Peter Lang and Margaret~M Bradley.
\newblock The international affective picture system (iaps) in the study of
  emotion and attention.
\newblock \emph{Handbook of emotion elicitation and assessment}, 29:\penalty0
  70--73, 2007.

\bibitem[Li and Deng(2020)]{li2020deep}
Shan Li and Weihong Deng.
\newblock Deep facial expression recognition: A survey.
\newblock \emph{IEEE transactions on affective computing}, 2020.

\bibitem[Lim(2016)]{LIM2016105}
Nangyeon Lim.
\newblock Cultural differences in emotion: differences in emotional arousal
  level between the east and the west.
\newblock \emph{Integrative Medicine Research}, 5\penalty0 (2):\penalty0
  105--109, 2016.
\newblock ISSN 2213-4220.

\bibitem[Lindquist and Barrett(2008)]{lindquist2008emotional}
Kristen~A Lindquist and Lisa~Feldman Barrett.
\newblock Emotional complexity.
\newblock 2008.

\bibitem[Lucey et~al.(2010)Lucey, Cohn, Kanade, Saragih, Ambadar, and
  Matthews]{lucey2010extended}
Patrick Lucey, Jeffrey~F Cohn, Takeo Kanade, Jason Saragih, Zara Ambadar, and
  Iain Matthews.
\newblock The extended cohn-kanade dataset (ck+): A complete dataset for action
  unit and emotion-specified expression.
\newblock In \emph{2010 ieee computer society conference on computer vision and
  pattern recognition-workshops}, pages 94--101. IEEE, 2010.

\bibitem[Lyons et~al.(1998)Lyons, Akamatsu, Kamachi, and
  Gyoba]{lyons1998coding}
Michael Lyons, Shigeru Akamatsu, Miyuki Kamachi, and Jiro Gyoba.
\newblock Coding facial expressions with gabor wavelets.
\newblock In \emph{Proceedings Third IEEE international conference on automatic
  face and gesture recognition}, pages 200--205. IEEE, 1998.

\bibitem[Magurran(2003)]{magurran2003measuring}
Anne~E Magurran.
\newblock \emph{Measuring biological diversity}.
\newblock John Wiley \& Sons, 2003.

\bibitem[Milan et~al.(2016)Milan, Leal-Taix{\'e}, Reid, Roth, and
  Schindler]{milan2016mot16}
Anton Milan, Laura Leal-Taix{\'e}, Ian Reid, Stefan Roth, and Konrad Schindler.
\newblock Mot16: A benchmark for multi-object tracking.
\newblock \emph{arXiv preprint arXiv:1603.00831}, 2016.

\bibitem[Monfort et~al.(2019)Monfort, Andonian, Zhou, Ramakrishnan, Bargal,
  Yan, Brown, Fan, Gutfreund, Vondrick, et~al.]{monfort2019moments}
Mathew Monfort, Alex Andonian, Bolei Zhou, Kandan Ramakrishnan, Sarah~Adel
  Bargal, Tom Yan, Lisa Brown, Quanfu Fan, Dan Gutfreund, Carl Vondrick, et~al.
\newblock Moments in time dataset: one million videos for event understanding.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 42\penalty0 (2):\penalty0 502--508, 2019.

\bibitem[NORC(2020)]{norc2020historic}
NORC.
\newblock Historic shift in americans’ happiness amid pandemic.
\newblock 2020.

\bibitem[Oatley et~al.(2006)Oatley, Keltner, and
  Jenkins]{Oatley2006UnderstandingE2}
Keith Oatley, Dacher Keltner, and Jennifer~M. Jenkins.
\newblock Understanding emotions, 2nd ed.
\newblock 2006.

\bibitem[Oberl{\"a}nder and Klinger(2018)]{oberlander2018analysis}
Laura Ana~Maria Oberl{\"a}nder and Roman Klinger.
\newblock An analysis of annotated corpora for emotion classification in text.
\newblock In \emph{Proceedings of the 27th International Conference on
  Computational Linguistics}, pages 2104--2119, 2018.

\bibitem[Pont-Tuset et~al.(2017)Pont-Tuset, Perazzi, Caelles, Arbel{\'a}ez,
  Sorkine-Hornung, and Van~Gool]{pont20172017}
Jordi Pont-Tuset, Federico Perazzi, Sergi Caelles, Pablo Arbel{\'a}ez, Alex
  Sorkine-Hornung, and Luc Van~Gool.
\newblock The 2017 davis challenge on video object segmentation.
\newblock \emph{arXiv preprint arXiv:1704.00675}, 2017.

\bibitem[Posner(1979)]{posner}
Richard~A. Posner.
\newblock Utilitarianism, economics, and legal theory.
\newblock \emph{The Journal of Legal Studies}, 1979.

\bibitem[Quoidbach et~al.(2014)Quoidbach, Gruber, Mikolajczak, Kogan, Kotsou,
  and Norton]{quoidbach2014emodiversity}
Jordi Quoidbach, June Gruber, Mo{\"\i}ra Mikolajczak, Alexsandr Kogan, Ilios
  Kotsou, and Michael~I Norton.
\newblock Emodiversity and the emotional ecosystem.
\newblock \emph{Journal of experimental psychology: General}, 143\penalty0
  (6):\penalty0 2057, 2014.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock \emph{arXiv preprint arXiv:2103.00020}, 2021.

\bibitem[Ridgway(1956)]{Ridgway1956DysfunctionalCO}
V.~Ridgway.
\newblock Dysfunctional consequences of performance measurements.
\newblock \emph{Administrative Science Quarterly}, 1956.

\bibitem[Russell(2019)]{Russell2019HumanCA}
Stuart Russell.
\newblock Human compatible: Artificial intelligence and the problem of control.
\newblock 2019.

\bibitem[Schaefer et~al.(2010)Schaefer, Nils, Sanchez, and
  Philippot]{schaefer2010assessing}
Alexandre Schaefer, Fr{\'e}d{\'e}ric Nils, Xavier Sanchez, and Pierre
  Philippot.
\newblock Assessing the effectiveness of a large database of emotion-eliciting
  films: A new tool for emotion researchers.
\newblock \emph{Cognition and Emotion}, 24\penalty0 (7):\penalty0 1153--1172,
  2010.

\bibitem[Scherer et~al.(2001)Scherer, Schorr, and
  Johnstone]{Scherer2001AppraisalPI}
Klaus~R. Scherer, Angela Schorr, and Tom Johnstone.
\newblock Appraisal processes in emotion: Theory, methods, research.
\newblock 2001.

\bibitem[Schuldt et~al.(2004)Schuldt, Laptev, and
  Caputo]{schuldt2004recognizing}
Christian Schuldt, Ivan Laptev, and Barbara Caputo.
\newblock Recognizing human actions: a local svm approach.
\newblock In \emph{Proceedings of the 17th International Conference on Pattern
  Recognition, 2004. ICPR 2004.}, volume~3, pages 32--36. IEEE, 2004.

\bibitem[Scott(1999)]{Scott1999SeeingLA}
James~C. Scott.
\newblock Seeing like a state: How certain schemes to improve the human
  condition have failed.
\newblock 1999.

\bibitem[Sharir et~al.(2021)Sharir, Noy, and Zelnik-Manor]{sharir2021image}
Gilad Sharir, Asaf Noy, and Lihi Zelnik-Manor.
\newblock An image is worth 16x16 words, what is a video worth?
\newblock \emph{arXiv preprint arXiv:2103.13915}, 2021.

\bibitem[Sidgwick(1907)]{sidgwick_1907}
Henry Sidgwick.
\newblock \emph{The Methods of Ethics}.
\newblock 1907.

\bibitem[Soomro et~al.(2012)Soomro, Zamir, and Shah]{soomro2012ucf101}
Khurram Soomro, Amir~Roshan Zamir, and Mubarak Shah.
\newblock Ucf101: A dataset of 101 human actions classes from videos in the
  wild.
\newblock \emph{arXiv preprint arXiv:1212.0402}, 2012.

\bibitem[Strapparava and Mihalcea(2007)]{strapparava2007semeval}
Carlo Strapparava and Rada Mihalcea.
\newblock Semeval-2007 task 14: Affective text.
\newblock In \emph{Proceedings of the Fourth International Workshop on Semantic
  Evaluations (SemEval-2007)}, pages 70--74, 2007.

\bibitem[Stray(2020)]{Stray2020AligningAO}
Jonathan Stray.
\newblock Aligning ai optimization to community well-being.
\newblock \emph{International Journal of Community Well-Being}, 2020.

\bibitem[Stray et~al.(2021)Stray, Vendrov, Nixon, Adler, and
  Hadfield-Menell]{Stray2021WhatAY}
Jonathan Stray, Ivan Vendrov, Jeremy Nixon, Steven Adler, and Dylan
  Hadfield-Menell.
\newblock What are you optimizing for? aligning recommender systems with human
  values.
\newblock \emph{ArXiv}, abs/2107.10939, 2021.

\bibitem[Sun et~al.(2020)Sun, Liu, Cowen, Schroff, Adam, and
  Prasad]{Sun2020EEVDP}
Jennifer~J. Sun, Ting Liu, Alan~S. Cowen, Florian Schroff, Hartwig Adam, and
  Gautam Prasad.
\newblock Eev dataset: Predicting expressions evoked by diverse videos.
\newblock \emph{ArXiv}, abs/2001.05488, 2020.

\bibitem[Tong et~al.(2022)Tong, Song, Wang, and Wang]{videomae}
Zhan Tong, Yibing Song, Jue Wang, and Limin Wang.
\newblock Videomae: Masked autoencoders are data-efficient learners for
  self-supervised video pre-training.
\newblock \emph{arXiv preprint arXiv:2203.12602}, 2022.

\bibitem[Tran et~al.(2015)Tran, Bourdev, Fergus, Torresani, and
  Paluri]{tran2015learning}
Du~Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, and Manohar Paluri.
\newblock Learning spatiotemporal features with 3d convolutional networks.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 4489--4497, 2015.

\bibitem[Tran et~al.(2018)Tran, Wang, Torresani, Ray, LeCun, and
  Paluri]{tran2018closer}
Du~Tran, Heng Wang, Lorenzo Torresani, Jamie Ray, Yann LeCun, and Manohar
  Paluri.
\newblock A closer look at spatiotemporal convolutions for action recognition.
\newblock In \emph{Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, pages 6450--6459, 2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{Vaswani2017AttentionIA}
Ashish Vaswani, Noam~M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{ArXiv}, abs/1706.03762, 2017.

\bibitem[Vondrick et~al.(2018)Vondrick, Shrivastava, Fathi, Guadarrama, and
  Murphy]{vondrick2018tracking}
Carl Vondrick, Abhinav Shrivastava, Alireza Fathi, Sergio Guadarrama, and Kevin
  Murphy.
\newblock Tracking emerges by colorizing videos.
\newblock In \emph{Proceedings of the European conference on computer vision
  (ECCV)}, pages 391--408, 2018.

\bibitem[Wang et~al.(2014)Wang, Qiao, and Tang]{wang2014action}
Limin Wang, Yu~Qiao, and Xiaoou Tang.
\newblock Action recognition and detection by combining motion and appearance
  features.
\newblock \emph{THUMOS14 Action Recognition Challenge}, 1\penalty0
  (2):\penalty0 2, 2014.

\bibitem[Xu et~al.(2018)Xu, Yang, Fan, Yue, Liang, Yang, and
  Huang]{xu2018youtube}
Ning Xu, Linjie Yang, Yuchen Fan, Dingcheng Yue, Yuchen Liang, Jianchao Yang,
  and Thomas Huang.
\newblock Youtube-vos: A large-scale video object segmentation benchmark.
\newblock \emph{arXiv preprint arXiv:1809.03327}, 2018.

\bibitem[Yilmaz et~al.(2006)Yilmaz, Javed, and Shah]{yilmaz2006object}
Alper Yilmaz, Omar Javed, and Mubarak Shah.
\newblock Object tracking: A survey.
\newblock \emph{Acm computing surveys (CSUR)}, 38\penalty0 (4):\penalty0
  13--es, 2006.

\bibitem[Zhang et~al.(2019)Zhang, Zhang, Zhong, Lei, Yang, Du, and
  Chen]{zhang2019comprehensive}
Hong-Bo Zhang, Yi-Xiang Zhang, Bineng Zhong, Qing Lei, Lijie Yang, Ji-Xiang Du,
  and Duan-Sheng Chen.
\newblock A comprehensive survey of vision-based human action recognition
  methods.
\newblock \emph{Sensors}, 19\penalty0 (5):\penalty0 1005, 2019.

\bibitem[Zhao et~al.(2021)Zhao, Bhat, Danelljan, Gool, and
  Timofte]{Zhao2021GeneratingMF}
Bin Zhao, Goutam Bhat, Martin Danelljan, Luc~Van Gool, and Radu Timofte.
\newblock Generating masks from boxes by mining spatio-temporal consistencies
  in videos.
\newblock \emph{ArXiv}, 2021.

\bibitem[Zlatintsi et~al.(2017)Zlatintsi, Koutras, Evangelopoulos, Malandrakis,
  Efthymiou, Pastra, Potamianos, and Maragos]{zlatintsi2017cognimuse}
Athanasia Zlatintsi, Petros Koutras, Georgios Evangelopoulos, Nikolaos
  Malandrakis, Niki Efthymiou, Katerina Pastra, Alexandros Potamianos, and
  Petros Maragos.
\newblock Cognimuse: A multimodal video database annotated with saliency,
  events, semantics and emotion with application to summarization.
\newblock \emph{EURASIP Journal on Image and Video Processing}, 2017\penalty0
  (1):\penalty0 54, 2017.

\end{thebibliography}
