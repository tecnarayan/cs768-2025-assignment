\begin{thebibliography}{68}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2020)Agarwal, Kakade, Krishnamurthy, and
  Sun]{agarwal2020flambe}
Agarwal, A., Kakade, S., Krishnamurthy, A., and Sun, W.
\newblock Flambe: Structural complexity and representation learning of low rank
  mdps.
\newblock \emph{arXiv preprint arXiv:2006.10814}, 2020.

\bibitem[Antos et~al.(2007)Antos, Munos, and Szepesv{\'a}ri]{antos2007fitted}
Antos, A., Munos, R., and Szepesv{\'a}ri, C.
\newblock Fitted q-iteration in continuous action-space mdps.
\newblock 2007.

\bibitem[Arbel et~al.(2020)Arbel, Zhou, and Gretton]{arbel2020generalized}
Arbel, M., Zhou, L., and Gretton, A.
\newblock Generalized energy based models.
\newblock \emph{arXiv preprint arXiv:2003.05033}, 2020.

\bibitem[Azar et~al.(2017)Azar, Osband, and Munos]{azar2017minimax}
Azar, M.~G., Osband, I., and Munos, R.
\newblock Minimax regret bounds for reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  263--272. PMLR, 2017.

\bibitem[Barreto et~al.(2016)Barreto, Dabney, Munos, Hunt, Schaul, Van~Hasselt,
  and Silver]{barreto2016successor}
Barreto, A., Dabney, W., Munos, R., Hunt, J.~J., Schaul, T., Van~Hasselt, H.,
  and Silver, D.
\newblock Successor features for transfer in reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1606.05312}, 2016.

\bibitem[Bartlett \& Mendelson(2002)Bartlett and
  Mendelson]{bartlett2002rademacher}
Bartlett, P.~L. and Mendelson, S.
\newblock Rademacher and gaussian complexities: Risk bounds and structural
  results.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0
  (Nov):\penalty0 463--482, 2002.

\bibitem[Bellman(1966)]{bellman1966dynamic}
Bellman, R.
\newblock Dynamic programming.
\newblock \emph{Science}, 153\penalty0 (3731):\penalty0 34--37, 1966.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{1606.01540}
Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang,
  J., and Zaremba, W.
\newblock Openai gym, 2016.

\bibitem[Castro(2020)]{castro2020scalable}
Castro, P.~S.
\newblock Scalable methods for computing state similarity in deterministic
  markov decision processes.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pp.\  10069--10076, 2020.

\bibitem[Chua et~al.(2018)Chua, Calandra, McAllister, and Levine]{chua2018deep}
Chua, K., Calandra, R., McAllister, R., and Levine, S.
\newblock Deep reinforcement learning in a handful of trials using
  probabilistic dynamics models.
\newblock \emph{arXiv preprint arXiv:1805.12114}, 2018.

\bibitem[Dai et~al.(2018)Dai, Shaw, Li, Xiao, He, Liu, Chen, and
  Song]{dai2018sbeed}
Dai, B., Shaw, A., Li, L., Xiao, L., He, N., Liu, Z., Chen, J., and Song, L.
\newblock Sbeed: Convergent reinforcement learning with nonlinear function
  approximation.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1125--1134. PMLR, 2018.

\bibitem[Dai et~al.(2019)Dai, Liu, Dai, He, Gretton, Song, and
  Schuurmans]{dai2019exponential}
Dai, B., Liu, Z., Dai, H., He, N., Gretton, A., Song, L., and Schuurmans, D.
\newblock Exponential family estimation via adversarial dynamics embedding.
\newblock \emph{arXiv preprint arXiv:1904.12083}, 2019.

\bibitem[Dann \& Brunskill(2015)Dann and Brunskill]{dann2015sample}
Dann, C. and Brunskill, E.
\newblock Sample complexity of episodic fixed-horizon reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1510.08906}, 2015.

\bibitem[Dayan(1993)]{dayan1993improving}
Dayan, P.
\newblock Improving generalization for temporal difference learning: The
  successor representation.
\newblock \emph{Neural Computation}, 5\penalty0 (4):\penalty0 613--624, 1993.

\bibitem[Du et~al.(2019)Du, Krishnamurthy, Jiang, Agarwal, Dudik, and
  Langford]{du2019provably}
Du, S., Krishnamurthy, A., Jiang, N., Agarwal, A., Dudik, M., and Langford, J.
\newblock Provably efficient rl with rich observations via latent state
  decoding.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1665--1674. PMLR, 2019.

\bibitem[Duan et~al.(2018)Duan, Ke, and Wang]{duan2018state}
Duan, Y., Ke, Z.~T., and Wang, M.
\newblock State aggregation learning from markov transition data.
\newblock \emph{arXiv preprint arXiv:1811.02619}, 2018.

\bibitem[Ferns et~al.(2004)Ferns, Panangaden, and Precup]{ferns2004metrics}
Ferns, N., Panangaden, P., and Precup, D.
\newblock Metrics for finite markov decision processes.
\newblock In \emph{UAI}, volume~4, pp.\  162--169, 2004.

\bibitem[Foster et~al.(2008)Foster, Kakade, and Zhang]{foster2008multi}
Foster, D.~P., Kakade, S.~M., and Zhang, T.
\newblock Multi-view dimensionality reduction via canonical correlation
  analysis.
\newblock 2008.

\bibitem[Fu et~al.(2020)Fu, Kumar, Nachum, Tucker, and Levine]{fu2020d4rl}
Fu, J., Kumar, A., Nachum, O., Tucker, G., and Levine, S.
\newblock D4rl: Datasets for deep data-driven reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2004.07219}, 2020.

\bibitem[Fujimoto et~al.(2019)Fujimoto, Meger, and Precup]{fujimoto2019off}
Fujimoto, S., Meger, D., and Precup, D.
\newblock Off-policy deep reinforcement learning without exploration.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2052--2062. PMLR, 2019.

\bibitem[Gelada et~al.(2019)Gelada, Kumar, Buckman, Nachum, and
  Bellemare]{gelada2019deepmdp}
Gelada, C., Kumar, S., Buckman, J., Nachum, O., and Bellemare, M.~G.
\newblock Deepmdp: Learning continuous latent space models for representation
  learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2170--2179. PMLR, 2019.

\bibitem[Gutmann \& Hyv{\"a}rinen(2010)Gutmann and
  Hyv{\"a}rinen]{gutmann2010noise}
Gutmann, M. and Hyv{\"a}rinen, A.
\newblock Noise-contrastive estimation: A new estimation principle for
  unnormalized statistical models.
\newblock In \emph{Proceedings of the thirteenth international conference on
  artificial intelligence and statistics}, pp.\  297--304. JMLR Workshop and
  Conference Proceedings, 2010.

\bibitem[Gutmann \& Hyv{\"a}rinen(2012)Gutmann and
  Hyv{\"a}rinen]{gutmann2012noise}
Gutmann, M.~U. and Hyv{\"a}rinen, A.
\newblock Noise-contrastive estimation of unnormalized statistical models, with
  applications to natural image statistics.
\newblock \emph{Journal of Machine Learning Research}, 13\penalty0 (2), 2012.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and
  Levine]{haarnoja2018soft}
Haarnoja, T., Zhou, A., Abbeel, P., and Levine, S.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In \emph{International conference on machine learning}, pp.\
  1861--1870. PMLR, 2018.

\bibitem[Hafner et~al.(2019)Hafner, Lillicrap, Fischer, Villegas, Ha, Lee, and
  Davidson]{hafner2019learning}
Hafner, D., Lillicrap, T., Fischer, I., Villegas, R., Ha, D., Lee, H., and
  Davidson, J.
\newblock Learning latent dynamics for planning from pixels.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2555--2565. PMLR, 2019.

\bibitem[Hinton(2002)]{hinton2002training}
Hinton, G.~E.
\newblock Training products of experts by minimizing contrastive divergence.
\newblock \emph{Neural computation}, 14\penalty0 (8):\penalty0 1771--1800,
  2002.

\bibitem[Hyv{\"a}rinen \& Dayan(2005)Hyv{\"a}rinen and
  Dayan]{hyvarinen2005estimation}
Hyv{\"a}rinen, A. and Dayan, P.
\newblock Estimation of non-normalized statistical models by score matching.
\newblock \emph{Journal of Machine Learning Research}, 6\penalty0 (4), 2005.

\bibitem[Jaksch et~al.(2010)Jaksch, Ortner, and Auer]{jaksch2010near}
Jaksch, T., Ortner, R., and Auer, P.
\newblock Near-optimal regret bounds for reinforcement learning.
\newblock \emph{Journal of Machine Learning Research}, 11\penalty0 (4), 2010.

\bibitem[Jin et~al.(2018)Jin, Allen-Zhu, Bubeck, and Jordan]{jin2018q}
Jin, C., Allen-Zhu, Z., Bubeck, S., and Jordan, M.~I.
\newblock Is q-learning provably efficient?
\newblock \emph{arXiv preprint arXiv:1807.03765}, 2018.

\bibitem[Jin et~al.(2020)Jin, Yang, Wang, and Jordan]{jin2020provably}
Jin, C., Yang, Z., Wang, Z., and Jordan, M.~I.
\newblock Provably efficient reinforcement learning with linear function
  approximation.
\newblock In \emph{Conference on Learning Theory}, pp.\  2137--2143. PMLR,
  2020.

\bibitem[Kulkarni et~al.(2016)Kulkarni, Saeedi, Gautam, and
  Gershman]{kulkarni2016deep}
Kulkarni, T.~D., Saeedi, A., Gautam, S., and Gershman, S.~J.
\newblock Deep successor reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1606.02396}, 2016.

\bibitem[Kumar et~al.(2019)Kumar, Fu, Tucker, and Levine]{kumar2019stabilizing}
Kumar, A., Fu, J., Tucker, G., and Levine, S.
\newblock Stabilizing off-policy q-learning via bootstrapping error reduction.
\newblock \emph{arXiv preprint arXiv:1906.00949}, 2019.

\bibitem[Kumar et~al.(2020)Kumar, Zhou, Tucker, and
  Levine]{kumar2020conservative}
Kumar, A., Zhou, A., Tucker, G., and Levine, S.
\newblock Conservative q-learning for offline reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2006.04779}, 2020.

\bibitem[Kurutach et~al.(2018)Kurutach, Clavera, Duan, Tamar, and
  Abbeel]{kurutach2018model}
Kurutach, T., Clavera, I., Duan, Y., Tamar, A., and Abbeel, P.
\newblock Model-ensemble trust-region policy optimization.
\newblock \emph{arXiv preprint arXiv:1802.10592}, 2018.

\bibitem[LeCun et~al.(2006)LeCun, Chopra, Hadsell, Ranzato, and
  Huang]{lecun2006tutorial}
LeCun, Y., Chopra, S., Hadsell, R., Ranzato, M., and Huang, F.
\newblock A tutorial on energy-based learning.
\newblock \emph{Predicting structured data}, 1\penalty0 (0), 2006.

\bibitem[Levine et~al.(2016)Levine, Finn, Darrell, and Abbeel]{levine2016end}
Levine, S., Finn, C., Darrell, T., and Abbeel, P.
\newblock End-to-end training of deep visuomotor policies.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 1334--1373, 2016.

\bibitem[Li et~al.(2019)Li, He, Wu, Katabi, and Torralba]{li2019learning}
Li, Y., He, H., Wu, J., Katabi, D., and Torralba, A.
\newblock Learning compositional koopman operators for model-based control.
\newblock \emph{arXiv preprint arXiv:1910.08264}, 2019.

\bibitem[Ma \& Collins(2018)Ma and Collins]{ma2018noise}
Ma, Z. and Collins, M.
\newblock Noise contrastive estimation and negative sampling for conditional
  models: Consistency and statistical efficiency.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  3698--3707, 2018.

\bibitem[Mahadevan \& Maggioni(2007)Mahadevan and Maggioni]{mahadevan2007proto}
Mahadevan, S. and Maggioni, M.
\newblock Proto-value functions: A laplacian framework for learning
  representation and control in markov decision processes.
\newblock \emph{Journal of Machine Learning Research}, 8\penalty0 (10), 2007.

\bibitem[Misra et~al.(2020)Misra, Henaff, Krishnamurthy, and
  Langford]{misra2020kinematic}
Misra, D., Henaff, M., Krishnamurthy, A., and Langford, J.
\newblock Kinematic state abstraction and provably efficient rich-observation
  reinforcement learning.
\newblock In \emph{International conference on machine learning}, pp.\
  6961--6971. PMLR, 2020.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Modi et~al.(2021)Modi, Chen, Krishnamurthy, Jiang, and
  Agarwal]{modi2021model}
Modi, A., Chen, J., Krishnamurthy, A., Jiang, N., and Agarwal, A.
\newblock Model-free representation learning and exploration in low-rank mdps.
\newblock \emph{arXiv preprint arXiv:2102.07035}, 2021.

\bibitem[Munos \& Szepesv{\'a}ri(2008)Munos and
  Szepesv{\'a}ri]{munos2008finite}
Munos, R. and Szepesv{\'a}ri, C.
\newblock Finite-time bounds for fitted value iteration.
\newblock \emph{Journal of Machine Learning Research}, 9\penalty0 (5), 2008.

\bibitem[Nachum \& Dai(2020)Nachum and Dai]{nachum2020reinforcement}
Nachum, O. and Dai, B.
\newblock Reinforcement learning via fenchel-rockafellar duality.
\newblock \emph{arXiv preprint arXiv:2001.01866}, 2020.

\bibitem[Nachum \& Yang(2021)Nachum and Yang]{nachum2021provable}
Nachum, O. and Yang, M.
\newblock Provable representation learning for imitation with contrastive
  fourier features.
\newblock \emph{arXiv preprint arXiv:2105.12272}, 2021.

\bibitem[Nachum et~al.(2017)Nachum, Norouzi, Xu, and
  Schuurmans]{nachum2017bridging}
Nachum, O., Norouzi, M., Xu, K., and Schuurmans, D.
\newblock Bridging the gap between value and policy based reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1702.08892}, 2017.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Oord, A. v.~d., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Osband \& Van~Roy(2016)Osband and Van~Roy]{osband2016lower}
Osband, I. and Van~Roy, B.
\newblock On lower bounds for regret in reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1608.02732}, 2016.

\bibitem[Puterman(2014)]{puterman2014markov}
Puterman, M.~L.
\newblock \emph{Markov decision processes: discrete stochastic dynamic
  programming}.
\newblock John Wiley \& Sons, 2014.

\bibitem[Qiu et~al.(2022)Qiu, Wang, Bai, Yang, and Wang]{qiu2022contrastive}
Qiu, S., Wang, L., Bai, C., Yang, Z., and Wang, Z.
\newblock Contrastive ucb: Provably efficient contrastive self-supervised
  learning in online reinforcement learning, 2022.

\bibitem[Ren et~al.(2021)Ren, Zhang, Szepesv{\'a}ri, and Dai]{ren2021free}
Ren, T., Zhang, T., Szepesv{\'a}ri, C., and Dai, B.
\newblock A free lunch from the noise: Provable and practical exploration for
  representation learning.
\newblock \emph{arXiv preprint arXiv:2111.11485}, 2021.

\bibitem[Riou-Durand \& Chopin(2018)Riou-Durand and Chopin]{riou2018noise}
Riou-Durand, L. and Chopin, N.
\newblock Noise contrastive estimation: Asymptotic properties, formal
  comparison with mc-mle.
\newblock \emph{Electronic Journal of Statistics}, 12\penalty0 (2):\penalty0
  3473--3518, 2018.

\bibitem[Sridharan \& Kakade(2008)Sridharan and
  Kakade]{sridharan2008information}
Sridharan, K. and Kakade, S.~M.
\newblock An information theoretic framework for multi-view learning.
\newblock 2008.

\bibitem[Sugiyama et~al.(2012)Sugiyama, Suzuki, and
  Kanamori]{sugiyama2012density}
Sugiyama, M., Suzuki, T., and Kanamori, T.
\newblock \emph{Density ratio estimation in machine learning}.
\newblock Cambridge University Press, 2012.

\bibitem[Tassa et~al.(2018)Tassa, Doron, Muldal, Erez, Li, Casas, Budden,
  Abdolmaleki, Merel, Lefrancq, et~al.]{tassa2018deepmind}
Tassa, Y., Doron, Y., Muldal, A., Erez, T., Li, Y., Casas, D. d.~L., Budden,
  D., Abdolmaleki, A., Merel, J., Lefrancq, A., et~al.
\newblock Deepmind control suite.
\newblock \emph{arXiv preprint arXiv:1801.00690}, 2018.

\bibitem[Tosh et~al.(2021)Tosh, Krishnamurthy, and Hsu]{tosh2021contrastive}
Tosh, C., Krishnamurthy, A., and Hsu, D.
\newblock Contrastive learning, multi-view redundancy, and linear models.
\newblock In \emph{Algorithmic Learning Theory}, pp.\  1179--1206. PMLR, 2021.

\bibitem[Uehara et~al.(2021)Uehara, Zhang, and Sun]{uehara2021representation}
Uehara, M., Zhang, X., and Sun, W.
\newblock Representation learning for online and offline rl in low-rank mdps.
\newblock \emph{arXiv preprint arXiv:2110.04652}, 2021.

\bibitem[Wang et~al.(2019)Wang, Bao, Clavera, Hoang, Wen, Langlois, Zhang,
  Zhang, Abbeel, and Ba]{wang2019benchmarking}
Wang, T., Bao, X., Clavera, I., Hoang, J., Wen, Y., Langlois, E., Zhang, S.,
  Zhang, G., Abbeel, P., and Ba, J.
\newblock Benchmarking model-based reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1907.02057}, 2019.

\bibitem[Watter et~al.(2015)Watter, Springenberg, Boedecker, and
  Riedmiller]{watter2015embed}
Watter, M., Springenberg, J.~T., Boedecker, J., and Riedmiller, M.
\newblock Embed to control: A locally linear latent dynamics model for control
  from raw images.
\newblock \emph{arXiv preprint arXiv:1506.07365}, 2015.

\bibitem[Wu et~al.(2018)Wu, Tucker, and Nachum]{wu2018laplacian}
Wu, Y., Tucker, G., and Nachum, O.
\newblock The laplacian in rl: Learning representations with efficient
  approximations.
\newblock \emph{arXiv preprint arXiv:1810.04586}, 2018.

\bibitem[Wu et~al.(2019)Wu, Tucker, and Nachum]{wu2019behavior}
Wu, Y., Tucker, G., and Nachum, O.
\newblock Behavior regularized offline reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1911.11361}, 2019.

\bibitem[Yang et~al.(2020)Yang, Zhang, Morcos, Pineau, Abbeel, and
  Calandra]{yang2020plan2vec}
Yang, G., Zhang, A., Morcos, A., Pineau, J., Abbeel, P., and Calandra, R.
\newblock Plan2vec: Unsupervised representation learning by latent plans.
\newblock In \emph{Learning for Dynamics and Control}, pp.\  935--946. PMLR,
  2020.

\bibitem[Yang \& Wang(2019)Yang and Wang]{yang2019sample}
Yang, L. and Wang, M.
\newblock Sample-optimal parametric q-learning using linearly additive
  features.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  6995--7004. PMLR, 2019.

\bibitem[Yang \& Wang(2020)Yang and Wang]{yang2020reinforcement}
Yang, L. and Wang, M.
\newblock Reinforcement learning in feature space: Matrix bandit, kernels, and
  regret bound.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  10746--10756. PMLR, 2020.

\bibitem[Yang et~al.(2021)Yang, Levine, and Nachum]{yang2021trail}
Yang, M., Levine, S., and Nachum, O.
\newblock Trail: Near-optimal imitation learning with suboptimal data.
\newblock \emph{arXiv preprint arXiv:2110.14770}, 2021.

\bibitem[Zhang et~al.(2020{\natexlab{a}})Zhang, Lyle, Sodhani, Filos,
  Kwiatkowska, Pineau, Gal, and Precup]{zhang2020invariant}
Zhang, A., Lyle, C., Sodhani, S., Filos, A., Kwiatkowska, M., Pineau, J., Gal,
  Y., and Precup, D.
\newblock Invariant causal prediction for block mdps.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  11214--11224. PMLR, 2020{\natexlab{a}}.

\bibitem[Zhang et~al.(2020{\natexlab{b}})Zhang, McAllister, Calandra, Gal, and
  Levine]{zhang2020learning}
Zhang, A., McAllister, R., Calandra, R., Gal, Y., and Levine, S.
\newblock Learning invariant representations for reinforcement learning without
  reconstruction.
\newblock \emph{arXiv preprint arXiv:2006.10742}, 2020{\natexlab{b}}.

\bibitem[Zhang(2002)]{zhang2002effective}
Zhang, T.
\newblock Effective dimension and generalization of kernel learning.
\newblock In \emph{NIPs}, volume~4, pp.\  454--461. Citeseer, 2002.

\end{thebibliography}
