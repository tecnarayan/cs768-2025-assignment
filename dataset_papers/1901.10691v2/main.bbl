\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aliprantis \& Border(2006)Aliprantis and
  Border]{aliprantis1999infinite}
Aliprantis, C.~D. and Border, K.~C.
\newblock Infinite dimensional analysis: a hitchhiker's guide.
\newblock 2006.

\bibitem[Arjovsky \& Bottou(2017)Arjovsky and Bottou]{arjovsky2017towards}
Arjovsky, M. and Bottou, L.
\newblock Towards principled methods for training generative adversarial
  networks.
\newblock \emph{arXiv preprint arXiv:1701.04862}, 2017.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
Arjovsky, M., Chintala, S., and Bottou, L.
\newblock Wasserstein {GAN}.
\newblock \emph{arXiv preprint arXiv:1701.07875}, 2017.

\bibitem[Bottou(2010)]{bottou2010large}
Bottou, L.
\newblock Large-scale machine learning with stochastic gradient descent.
\newblock In \emph{Proceedings of COMPSTAT'2010}, pp.\  177--186. Springer,
  2010.

\bibitem[Carmona \& Delarue(2018)Carmona and Delarue]{carmona2018probabilistic}
Carmona, R. and Delarue, F.
\newblock \emph{Probabilistic Theory of Mean Field Games with Applications
  I-II}.
\newblock Springer, 2018.

\bibitem[Chen \& Wang(2016)Chen and Wang]{chen2016stochastic}
Chen, Y. and Wang, M.
\newblock Stochastic primal-dual methods and sample complexity of reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1612.02516}, 2016.

\bibitem[Dai(2018)]{dai2018learning}
Dai, B.
\newblock \emph{Learning over Functions, Distributions and Dynamics via
  Stochastic Optimization}.
\newblock PhD thesis, Georgia Institute of Technology, 2018.

\bibitem[Dai et~al.(2014)Dai, Xie, He, Liang, Raj, Balcan, and
  Song]{dai2014scalable}
Dai, B., Xie, B., He, N., Liang, Y., Raj, A., Balcan, M.-F.~F., and Song, L.
\newblock Scalable kernel methods via doubly stochastic gradients.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3041--3049, 2014.

\bibitem[Dai et~al.(2016)Dai, He, Dai, and Song]{dai2016provable}
Dai, B., He, N., Dai, H., and Song, L.
\newblock Provable {B}ayesian inference via particle mirror descent.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  985--994,
  2016.

\bibitem[Dai et~al.(2017{\natexlab{a}})Dai, He, Pan, Boots, and
  Song]{dai2017learning}
Dai, B., He, N., Pan, Y., Boots, B., and Song, L.
\newblock Learning from conditional distributions via dual embeddings.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  1458--1467,
  2017{\natexlab{a}}.

\bibitem[Dai et~al.(2017{\natexlab{b}})Dai, Shaw, He, Li, and
  Song]{dai2017boosting}
Dai, B., Shaw, A., He, N., Li, L., and Song, L.
\newblock Boosting the actor with dual critic.
\newblock \emph{arXiv preprint arXiv:1712.10282}, 2017{\natexlab{b}}.

\bibitem[Dai et~al.(2018)Dai, Shaw, Li, Xiao, He, Liu, Chen, and
  Song]{dai2018sbeed}
Dai, B., Shaw, A., Li, L., Xiao, L., He, N., Liu, Z., Chen, J., and Song, L.
\newblock {SBEED}: Convergent reinforcement learning with nonlinear function
  approximation.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1133--1142, 2018.

\bibitem[Farnia \& Tse(2018)Farnia and Tse]{farnia2018convex}
Farnia, F. and Tse, D.
\newblock A convex duality framework for {GAN}s.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  5250--5259, 2018.

\bibitem[Fernholz(2012)]{fernholz2012mises}
Fernholz, L.~T.
\newblock \emph{Von Mises calculus for statistical functionals}, volume~19.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Frogner \& Poggio(2018)Frogner and Poggio]{frogner2018approximate}
Frogner, C. and Poggio, T.
\newblock Approximate inference with wasserstein gradient flows.
\newblock \emph{arXiv preprint arXiv:1806.04542}, 2018.

\bibitem[Gaivoronski(1986)]{gaivoronski1986linearization}
Gaivoronski, A.
\newblock Linearization methods for optimization of functionals which depend on
  probability measures.
\newblock In \emph{Stochastic Programming 84 Part II}, pp.\  157--181.
  Springer, 1986.

\bibitem[Glynn(1990)]{glynn1990likelihood}
Glynn, P.~W.
\newblock Likelihood ratio gradient estimation for stochastic systems.
\newblock \emph{Communications of the ACM}, 33\penalty0 (10):\penalty0 75--84,
  1990.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2672--2680, 2014.

\bibitem[Heess et~al.(2015)Heess, Wayne, Silver, Lillicrap, Erez, and
  Tassa]{heess2015learning}
Heess, N., Wayne, G., Silver, D., Lillicrap, T., Erez, T., and Tassa, Y.
\newblock Learning continuous control policies by stochastic value gradients.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2944--2952, 2015.

\bibitem[Ho \& Ermon(2016)Ho and Ermon]{ho2016generative}
Ho, J. and Ermon, S.
\newblock Generative adversarial imitation learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4565--4573, 2016.

\bibitem[Howard(1960)]{howard1960dynamic}
Howard, R.~A.
\newblock Dynamic programming and markov processes.
\newblock 1960.

\bibitem[Huszar(2016)]{huszar2016alternative}
Huszar, F.
\newblock An alternative update rule for generative adversarial networks.
\newblock \emph{Unpublished note (retrieved on 16 Jan 2019)}, 2016.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{kingma2013auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational {B}ayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kleijnen \& Rubinstein(1996)Kleijnen and
  Rubinstein]{kleijnen1996optimization}
Kleijnen, J.~P. and Rubinstein, R.~Y.
\newblock Optimization and sensitivity analysis of computer simulation models
  by the score function method.
\newblock \emph{European Journal of Operational Research}, 88\penalty0
  (3):\penalty0 413--427, 1996.

\bibitem[Konda \& Tsitsiklis(2000)Konda and Tsitsiklis]{konda2000actor}
Konda, V.~R. and Tsitsiklis, J.~N.
\newblock Actor-critic algorithms.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1008--1014, 2000.

\bibitem[Lin et~al.(2018)Lin, Li, Osher, and Mont{\'u}far]{lin2018wasserstein}
Lin, A.~T., Li, W., Osher, S., and Mont{\'u}far, G.
\newblock Wasserstein proximal of gans.
\newblock 2018.

\bibitem[Liu \& Wang(2016)Liu and Wang]{liu2016stein}
Liu, Q. and Wang, D.
\newblock Stein variational gradient descent: A general purpose {B}ayesian
  inference algorithm.
\newblock In \emph{Advances In Neural Information Processing Systems}, pp.\
  2378--2386, 2016.

\bibitem[Lucchetti(2006)]{lucchetti2006convexity}
Lucchetti, R.
\newblock \emph{Convexity and well-posed problems}.
\newblock Springer Science \& Business Media, 2006.

\bibitem[Luenberger \& Ye(2015)Luenberger and Ye]{luenberger2008linear}
Luenberger, D.~G. and Ye, Y.
\newblock Linear and nonlinear programming.
\newblock 2015.

\bibitem[Mescheder et~al.(2017)Mescheder, Nowozin, and
  Geiger]{mescheder2017adversarial}
Mescheder, L., Nowozin, S., and Geiger, A.
\newblock Adversarial variational {B}ayes: Unifying variational autoencoders
  and generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1701.04722}, 2017.

\bibitem[Milgrom \& Segal(2002)Milgrom and Segal]{milgrom2002envelope}
Milgrom, P. and Segal, I.
\newblock Envelope theorems for arbitrary choice sets.
\newblock \emph{Econometrica}, 70\penalty0 (2):\penalty0 583--601, 2002.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{mnih2016asynchronous}
Mnih, V., Badia, A.~P., Mirza, M., Graves, A., Lillicrap, T., Harley, T.,
  Silver, D., and Kavukcuoglu, K.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{International conference on machine learning}, pp.\
  1928--1937, 2016.

\bibitem[Molchanov \& Zuyev(2001)Molchanov and Zuyev]{molchanov2001variational}
Molchanov, I. and Zuyev, S.
\newblock Variational calculus in the space of measures and optimal design.
\newblock In \emph{Optimum Design 2000}, pp.\  79--90. Springer, 2001.

\bibitem[Nowozin et~al.(2016)Nowozin, Cseke, and Tomioka]{nowozin2016f}
Nowozin, S., Cseke, B., and Tomioka, R.
\newblock f-{GAN}: Training generative neural samplers using variational
  divergence minimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  271--279, 2016.

\bibitem[Penot(2012)]{penot2012calculus}
Penot, J.-P.
\newblock \emph{Calculus without derivatives}, volume 266.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Puterman(1994)]{puterman1994markov}
Puterman, M.
\newblock Markov decision processes: Discrete stochastic dynamic programming.
\newblock 1994.

\bibitem[Ranganath et~al.(2014)Ranganath, Gerrish, and
  Blei]{ranganath2014black}
Ranganath, R., Gerrish, S., and Blei, D.
\newblock Black box variational inference.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  814--822,
  2014.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Rezende, D.~J., Mohamed, S., and Wierstra, D.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock \emph{arXiv preprint arXiv:1401.4082}, 2014.

\bibitem[Richemond \& Maginnis(2017)Richemond and
  Maginnis]{richemond2017wasserstein}
Richemond, P.~H. and Maginnis, B.
\newblock On wasserstein reinforcement learning and the fokker-planck equation.
\newblock \emph{arXiv preprint arXiv:1712.07185}, 2017.

\bibitem[Rockafellar(1968)]{rockafellar1968general}
Rockafellar, R.
\newblock A general correspondence between dual minimax problems and convex
  programs.
\newblock \emph{Pacific Journal of Mathematics}, 25\penalty0 (3):\penalty0
  597--611, 1968.

\bibitem[Roeder et~al.(2017)Roeder, Wu, and Duvenaud]{roeder2017sticking}
Roeder, G., Wu, Y., and Duvenaud, D.~K.
\newblock Sticking the landing: Simple, lower-variance gradient estimators for
  variational inference.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6925--6934, 2017.

\bibitem[Ruderman et~al.(2012)Ruderman, Reid, Garc{\'\i}a-Garc{\'\i}a, and
  Petterson]{ruderman2012tighter}
Ruderman, A., Reid, M., Garc{\'\i}a-Garc{\'\i}a, D., and Petterson, J.
\newblock Tighter variational representations of f-divergences via restriction
  to probability measures.
\newblock \emph{arXiv preprint arXiv:1206.4664}, 2012.

\bibitem[Santambrogio(2015)]{santambrogio2015functionals}
Santambrogio, F.
\newblock Functionals on the space of probabilities.
\newblock In \emph{Optimal Transport for Applied Mathematicians}, pp.\
  249--284. Springer, 2015.

\bibitem[Schulman et~al.(2015)Schulman, Heess, Weber, and
  Abbeel]{schulman2015gradient}
Schulman, J., Heess, N., Weber, T., and Abbeel, P.
\newblock Gradient estimation using stochastic computation graphs.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3528--3536, 2015.

\bibitem[Silver et~al.(2014)Silver, Lever, Heess, Degris, Wierstra, and
  Riedmiller]{silver2014deterministic}
Silver, D., Lever, G., Heess, N., Degris, T., Wierstra, D., and Riedmiller, M.
\newblock Deterministic policy gradient algorithms.
\newblock In \emph{ICML}, 2014.

\bibitem[Sutton \& Barto(1998)Sutton and Barto]{sutton1998introduction}
Sutton, R.~S. and Barto, A.~G.
\newblock \emph{Introduction to reinforcement learning}, volume 135.
\newblock MIT Press Cambridge, 1998.

\bibitem[Sutton et~al.(2000)Sutton, McAllester, Singh, and
  Mansour]{sutton2000policy}
Sutton, R.~S., McAllester, D.~A., Singh, S.~P., and Mansour, Y.
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1057--1063, 2000.

\bibitem[Syed et~al.(2008)Syed, Bowling, and Schapire]{syed2008apprenticeship}
Syed, U., Bowling, M., and Schapire, R.~E.
\newblock Apprenticeship learning using linear programming.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, pp.\  1032--1039. ACM, 2008.

\bibitem[Villani(2008)]{villani2008optimal}
Villani, C.
\newblock \emph{Optimal transport: old and new}, volume 338.
\newblock Springer Science \& Business Media, 2008.

\bibitem[von Mises(1947)]{mises1947asymptotic}
von Mises, R.
\newblock On the asymptotic distribution of differentiable statistical
  functions.
\newblock \emph{The annals of mathematical statistics}, 18\penalty0
  (3):\penalty0 309--348, 1947.

\bibitem[Wang et~al.(2018)Wang, Vicol, Lucas, Gu, Grosse, and
  Zemel]{wang2018adversarial}
Wang, K.-C., Vicol, P., Lucas, J., Gu, L., Grosse, R., and Zemel, R.
\newblock Adversarial distillation of {B}ayesian neural network posteriors.
\newblock \emph{arXiv preprint arXiv:1806.10317}, 2018.

\bibitem[Williams(1992)]{williams1992simple}
Williams, R.~J.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 229--256, 1992.

\bibitem[Zalinescu(2002)]{zalinescu2002convex}
Zalinescu, C.
\newblock \emph{Convex analysis in general vector spaces}.
\newblock World scientific, 2002.

\bibitem[Zhang et~al.(2018)Zhang, Chen, Li, and Carin]{zhang2018policy}
Zhang, R., Chen, C., Li, C., and Carin, L.
\newblock Policy optimization as wasserstein gradient flows.
\newblock \emph{arXiv preprint arXiv:1808.03030}, 2018.

\end{thebibliography}
