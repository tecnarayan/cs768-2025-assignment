\begin{thebibliography}{73}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Assran et~al.(2022)Assran, Caron, Misra, Bojanowski, Bordes, Vincent, Joulin, Rabbat, and Ballas]{assran2022masked}
Mahmoud Assran, Mathilde Caron, Ishan Misra, Piotr Bojanowski, Florian Bordes, Pascal Vincent, Armand Joulin, Michael~G. Rabbat, and Nicolas Ballas.
\newblock {M}asked {S}iamese {N}etworks for {L}abel-efficient {L}earning.
\newblock \emph{CoRR}, abs/2204.07141, 2022.

\bibitem[Barron et~al.(2021{\natexlab{a}})Barron, Mildenhall, Tancik, Hedman, Martin{-}Brualla, and Srinivasan]{barron2021mip}
Jonathan~T. Barron, Ben Mildenhall, Matthew Tancik, Peter Hedman, Ricardo Martin{-}Brualla, and Pratul~P. Srinivasan.
\newblock {M}ip-{N}e{R}{F}: {A} {M}ultiscale {R}epresentation for {A}nti-aliasing {N}eural {R}adiance {F}ields.
\newblock \emph{CoRR}, abs/2103.13415, 2021{\natexlab{a}}.

\bibitem[Barron et~al.(2021{\natexlab{b}})Barron, Mildenhall, Verbin, Srinivasan, and Hedman]{barron2022mip}
Jonathan~T. Barron, Ben Mildenhall, Dor Verbin, Pratul~P. Srinivasan, and Peter Hedman.
\newblock {M}ip-{N}e{R}{F} 360: {U}nbounded {A}nti-aliased {N}eural {R}adiance {F}ields.
\newblock \emph{CoRR}, abs/2111.12077, 2021{\natexlab{b}}.

\bibitem[Bian et~al.(2019)Bian, Li, Wang, Zhan, Shen, Cheng, and Reid]{bian2019unsupervised}
Jia{-}Wang Bian, Zhichao Li, Naiyan Wang, Huangying Zhan, Chunhua Shen, Ming{-}Ming Cheng, and Ian~D. Reid.
\newblock {U}nsupervised {S}cale-consistent {D}epth and {E}go-motion {L}earning from {M}onocular {V}ideo.
\newblock \emph{CoRR}, abs/1908.10553, 2019.

\bibitem[Brox et~al.(2004)Brox, Bruhn, Papenberg, and Weickert]{brox2004high}
Thomas Brox, Andr{\'{e}}s Bruhn, Nils Papenberg, and Joachim Weickert.
\newblock {H}igh {A}ccuracy {O}ptical {F}low {E}stimation {B}ased on a {T}heory for {W}arping.
\newblock In \emph{Computer Vision - {ECCV} 2004, 8th European Conference on Computer Vision, Prague, Czech Republic, May 11-14, 2004. Proceedings, Part {IV}}, pages 25--36. Springer, 2004.

\bibitem[Charatan et~al.(2023)Charatan, Li, Tagliasacchi, and Sitzmann]{charatan2023pixelsplat}
David Charatan, Sizhe Li, Andrea Tagliasacchi, and Vincent Sitzmann.
\newblock pixel{S}plat: 3{D} {G}aussian {S}plats from {I}mage {P}airs for {S}calable {G}eneralizable 3{D} {R}econstruction.
\newblock \emph{CoRR}, abs/2312.12337, 2023.

\bibitem[Chen et~al.(2021)Chen, Xu, Zhao, Zhang, Xiang, Yu, and Su]{chen2021mvsnerf}
Anpei Chen, Zexiang Xu, Fuqiang Zhao, Xiaoshuai Zhang, Fanbo Xiang, Jingyi Yu, and Hao Su.
\newblock {M}{V}{S}{N}e{R}{F}: {F}ast {G}eneralizable {R}adiance {F}ield {R}econstruction from {M}ulti-view {S}tereo.
\newblock \emph{CoRR}, abs/2103.15595, 2021.

\bibitem[Chen and Wang(2024)]{chen2024survey}
Guikun Chen and Wenguan Wang.
\newblock {A} {S}urvey on 3{D} {G}aussian {S}platting.
\newblock \emph{CoRR}, abs/2401.03890, 2024.

\bibitem[Chen et~al.(2024)Chen, Xu, Zheng, Zhuang, Pollefeys, Geiger, Cham, and Cai]{chen2024mvsplat}
Yuedong Chen, Haofei Xu, Chuanxia Zheng, Bohan Zhuang, Marc Pollefeys, Andreas Geiger, Tat{-}Jen Cham, and Jianfei Cai.
\newblock {M}{V}{S}plat: {E}fficient 3{D} {G}aussian {S}platting from {S}parse {M}ulti-view {I}mages.
\newblock \emph{CoRR}, abs/2403.14627, 2024.

\bibitem[Cheng et~al.(2024)Cheng, Long, Yang, Yao, Yin, Ma, Wang, and Chen]{cheng2024gaussianpro}
Kai Cheng, Xiaoxiao Long, Kaizhi Yang, Yao Yao, Wei Yin, Yuexin Ma, Wenping Wang, and Xuejin Chen.
\newblock {G}aussian{P}ro: 3{D} {G}aussian {S}platting with {P}rogressive {P}ropagation.
\newblock \emph{CoRR}, abs/2402.14650, 2024.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and Houlsby]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock {A}n {I}mage is {W}orth 16x16 {W}ords: {T}ransformers for {I}mage {R}ecognition at {S}cale.
\newblock \emph{CoRR}, abs/2010.11929, 2020.

\bibitem[Du et~al.(2023)Du, Smith, Tewari, and Sitzmann]{du2023learning}
Yilun Du, Cameron Smith, Ayush Tewari, and Vincent Sitzmann.
\newblock {L}earning to {R}ender {N}ovel {V}iews from {W}ide-baseline {S}tereo {P}airs.
\newblock \emph{CoRR}, abs/2304.08463, 2023.

\bibitem[Feng et~al.(2023)Feng, Yang, Guo, and Li]{feng2023cvrecon}
Ziyue Feng, Leon Yang, Pengsheng Guo, and Bing Li.
\newblock {C}{V}{R}econ: {R}ethinking 3{D} {G}eometric {F}eature {L}earning {F}or {N}eural {R}econstruction.
\newblock \emph{CoRR}, abs/2304.14633, 2023.

\bibitem[Gan et~al.(2024)Gan, Quan, and Luo]{gan2024expavatar}
Yuan Gan, Ruijie Quan, and Yawei Luo.
\newblock Expavatar: High-fidelity avatar generation of unseen expressions with 3d face priors.
\newblock \emph{ACM Transactions on Multimedia Computing, Communications and Applications}, 2024.

\bibitem[Gu et~al.(2019)Gu, Fan, Zhu, Dai, Tan, and Tan]{gu2020cascade}
Xiaodong Gu, Zhiwen Fan, Siyu Zhu, Zuozhuo Dai, Feitong Tan, and Ping Tan.
\newblock {C}ascade {C}ost {V}olume for {H}igh-resolution {M}ulti-view {S}tereo and {S}tereo {M}atching.
\newblock \emph{CoRR}, abs/1912.06378, 2019.

\bibitem[He et~al.(2021)He, Chen, Xie, Li, Doll{\'{a}}r, and Girshick]{he2022masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'{a}}r, and Ross~B. Girshick.
\newblock {M}asked {A}utoencoders {A}re {S}calable {V}ision {L}earners.
\newblock \emph{CoRR}, abs/2111.06377, 2021.

\bibitem[He et~al.(2020)He, Yan, Fragkiadaki, and Yu]{he2020epipolar}
Yihui He, Rui Yan, Katerina Fragkiadaki, and Shoou{-}I Yu.
\newblock {E}pipolar {T}ransformers.
\newblock \emph{CoRR}, abs/2005.04551, 2020.

\bibitem[Huang et~al.(2024)Huang, Yu, Chen, Geiger, and Gao]{huang20242d}
Binbin Huang, Zehao Yu, Anpei Chen, Andreas Geiger, and Shenghua Gao.
\newblock 2{D} {G}aussian {S}platting for {G}eometrically {A}ccurate {R}adiance {F}ields.
\newblock \emph{CoRR}, abs/2403.17888, 2024.

\bibitem[Huang et~al.(2022)Huang, Shi, Zhang, Wang, Cheung, Qin, Dai, and Li]{huang2022flowformer}
Zhaoyang Huang, Xiaoyu Shi, Chao Zhang, Qiang Wang, Ka~Chun Cheung, Hongwei Qin, Jifeng Dai, and Hongsheng Li.
\newblock {F}low{F}ormer: {A} {T}ransformer {A}rchitecture for {O}ptical {F}low.
\newblock \emph{CoRR}, abs/2203.16194, 2022.

\bibitem[Jiang et~al.(2023)Jiang, Jiang, Zhao, and Huang]{jiang2023leap}
Hanwen Jiang, Zhenyu Jiang, Yue Zhao, and Qixing Huang.
\newblock Leap: Liberate sparse-view 3d modeling from camera poses.
\newblock \emph{arXiv preprint arXiv:2310.01410}, 2023.

\bibitem[Johari et~al.(2021)Johari, Lepoittevin, and Fleuret]{johari2022geonerf}
Mohammad~Mahdi Johari, Yann Lepoittevin, and Fran{\c{c}}ois Fleuret.
\newblock {G}eo{N}e{R}{F}: {G}eneralizing {N}e{R}{F} with {G}eometry {P}riors.
\newblock \emph{CoRR}, abs/2111.13539, 2021.

\bibitem[Kendall et~al.(2017)Kendall, Martirosyan, Dasgupta, Henry, Kennedy, Bachrach, and Bry]{kendall2017end}
Alex Kendall, Hayk Martirosyan, Saumitro Dasgupta, Peter Henry, Ryan Kennedy, Abraham Bachrach, and Adam Bry.
\newblock {E}nd-to-end {L}earning of {G}eometry and {C}ontext for {D}eep {S}tereo {R}egression.
\newblock \emph{CoRR}, abs/1703.04309, 2017.

\bibitem[Kerbl et~al.(2023)Kerbl, Kopanas, Leimk{\"{u}}hler, and Drettakis]{kerbl20233d}
Bernhard Kerbl, Georgios Kopanas, Thomas Leimk{\"{u}}hler, and George Drettakis.
\newblock 3{D} {G}aussian {S}platting for {R}eal-time {R}adiance {F}ield {R}endering.
\newblock \emph{CoRR}, abs/2308.04079, 2023.

\bibitem[Kingma and Ba(2015)]{kingma2014adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock {A}dam: {A} {M}ethod for {S}tochastic {O}ptimization.
\newblock In \emph{3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings}, 2015.

\bibitem[Li et~al.(2022)Li, Wang, Xiong, Cai, Yan, Yang, Liu, Fan, and Liu]{li2022practical}
Jiankun Li, Peisen Wang, Pengfei Xiong, Tao Cai, Ziwei Yan, Lei Yang, Jiangyu Liu, Haoqiang Fan, and Shuaicheng Liu.
\newblock {P}ractical {S}tereo {M}atching via {C}ascaded {R}ecurrent {N}etwork with {A}daptive {C}orrelation.
\newblock \emph{CoRR}, abs/2203.11483, 2022.

\bibitem[Liu et~al.(2020)Liu, Tucker, Jampani, Makadia, Snavely, and Kanazawa]{liu2021infinite}
Andrew Liu, Richard Tucker, Varun Jampani, Ameesh Makadia, Noah Snavely, and Angjoo Kanazawa.
\newblock {I}nfinite {N}ature: {P}erpetual {V}iew {G}eneration of {N}atural {S}cenes from a {S}ingle {I}mage.
\newblock \emph{CoRR}, abs/2012.09855, 2020.

\bibitem[Lombardi et~al.(2019)Lombardi, Simon, Saragih, Schwartz, Lehrmann, and Sheikh]{lombardi2019neural}
Stephen Lombardi, Tomas Simon, Jason~M. Saragih, Gabriel Schwartz, Andreas~M. Lehrmann, and Yaser Sheikh.
\newblock {N}eural {V}olumes: {L}earning {D}ynamic {R}enderable {V}olumes from {I}mages.
\newblock \emph{CoRR}, abs/1906.07751, 2019.

\bibitem[Luo et~al.(2019{\natexlab{a}})Luo, Guan, Ju, Huang, and Luo]{luo2019p}
Keyang Luo, Tao Guan, Lili Ju, Haipeng Huang, and Yawei Luo.
\newblock P-mvsnet: Learning patch-wise matching confidence aggregation for multi-view stereo.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 10452--10461, 2019{\natexlab{a}}.

\bibitem[Luo et~al.(2020)Luo, Guan, Ju, Wang, Chen, and Luo]{luo2020attention}
Keyang Luo, Tao Guan, Lili Ju, Yuesong Wang, Zhuo Chen, and Yawei Luo.
\newblock Attention-aware multi-view stereo.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 1590--1599, 2020.

\bibitem[Luo and Yang(2024)]{luo2024large}
Yawei Luo and Yi Yang.
\newblock Large language model and domain-specific model collaboration for smart education.
\newblock \emph{Frontiers of Information Technology \& Electronic Engineering}, 25\penalty0 (3):\penalty0 333--341, 2024.

\bibitem[Luo et~al.(2019{\natexlab{b}})Luo, Zheng, Guan, Yu, and Yang]{luo2019taking}
Yawei Luo, Liang Zheng, Tao Guan, Junqing Yu, and Yi Yang.
\newblock Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2019{\natexlab{b}}.

\bibitem[Luo et~al.(2021)Luo, Liu, Zheng, Guan, Yu, and Yang]{luo2021category}
Yawei Luo, Ping Liu, Liang Zheng, Tao Guan, Junqing Yu, and Yi Yang.
\newblock Category-level adversarial adaptation for semantic segmentation using purified features.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2021.

\bibitem[Luo et~al.(2024)Luo, Liu, and Yang]{luo2024kill}
Yawei Luo, Ping Liu, and Yi Yang.
\newblock Kill two birds with one stone: Domain generalization for semantic segmentation via network pruning.
\newblock \emph{International Journal of Computer Vision}, 2024.

\bibitem[Ma et~al.(2024)Ma, Luo, and Yang]{ma2024reconstructing}
Shaojie Ma, Yawei Luo, and Yi Yang.
\newblock Reconstructing and simulating dynamic 3d objects with mesh-adsorbed gaussian splatting.
\newblock \emph{arXiv preprint arXiv:2406.01593}, 2024.

\bibitem[Mayer et~al.(2015)Mayer, Ilg, H{\"{a}}usser, Fischer, Cremers, Dosovitskiy, and Brox]{mayer2016large}
Nikolaus Mayer, Eddy Ilg, Philip H{\"{a}}usser, Philipp Fischer, Daniel Cremers, Alexey Dosovitskiy, and Thomas Brox.
\newblock {A} {L}arge {D}ataset to {T}rain {C}onvolutional {N}etworks for {D}isparity, {O}ptical {F}low, and {S}cene {F}low {E}stimation.
\newblock \emph{CoRR}, abs/1512.02134, 2015.

\bibitem[Miao et~al.(2024)Miao, Luo, and Yang]{miao2024pla4d}
Qiaowei Miao, Yawei Luo, and Yi Yang.
\newblock Pla4d: Pixel-level alignments for text-to-4d gaussian splatting.
\newblock \emph{arXiv preprint arXiv:2405.19957}, 2024.

\bibitem[Mildenhall et~al.(2020)Mildenhall, Srinivasan, Tancik, Barron, Ramamoorthi, and Ng]{mildenhall2021nerf}
Ben Mildenhall, Pratul~P. Srinivasan, Matthew Tancik, Jonathan~T. Barron, Ravi Ramamoorthi, and Ren Ng.
\newblock {N}e{R}{F}: {R}epresenting {S}cenes as {N}eural {R}adiance {F}ields for {V}iew {S}ynthesis.
\newblock \emph{CoRR}, abs/2003.08934, 2020.

\bibitem[Min et~al.(2024)Min, Luo, Yang, Wang, and Yang]{min2023entangled}
Zhiyuan Min, Yawei Luo, Wei Yang, Yuesong Wang, and Yi Yang.
\newblock Entangled view-epipolar information aggregation for generalizable neural radiance fields.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 4906--4916, 2024.

\bibitem[M{\"{u}}ller et~al.(2022)M{\"{u}}ller, Evans, Schied, and Keller]{muller2022instant}
Thomas M{\"{u}}ller, Alex Evans, Christoph Schied, and Alexander Keller.
\newblock {I}nstant {N}eural {G}raphics {P}rimitives with a {M}ultiresolution {H}ash {E}ncoding.
\newblock \emph{CoRR}, abs/2201.05989, 2022.

\bibitem[Ramirez et~al.(2022)Ramirez, Tosi, Poggi, Salti, Mattoccia, and Stefano]{ramirez2022open}
Pierluigi~Zama Ramirez, Fabio Tosi, Matteo Poggi, Samuele Salti, Stefano Mattoccia, and Luigi~Di Stefano.
\newblock {O}pen {C}hallenges in {D}eep {S}tereo: the {B}ooster {D}ataset.
\newblock \emph{CoRR}, abs/2206.04671, 2022.

\bibitem[Rombach et~al.(2021)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"{o}}rn Ommer.
\newblock {H}igh-resolution {I}mage {S}ynthesis with {L}atent {D}iffusion {M}odels.
\newblock \emph{CoRR}, abs/2112.10752, 2021.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and Brox]{ronneberger2015u}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{Medical image computing and computer-assisted intervention--MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18}, pages 234--241. Springer, 2015.

\bibitem[Sajjadi et~al.(2022)Sajjadi, Meyer, Pot, Bergmann, Greff, Radwan, Vora, Lu{\v{c}}i{\'c}, Duckworth, Dosovitskiy, et~al.]{sajjadi2022scene}
Mehdi~SM Sajjadi, Henning Meyer, Etienne Pot, Urs Bergmann, Klaus Greff, Noha Radwan, Suhani Vora, Mario Lu{\v{c}}i{\'c}, Daniel Duckworth, Alexey Dosovitskiy, et~al.
\newblock {S}cene representation transformer: {G}eometry-free novel view synthesis through set-latent scene representations.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 6229--6238, 2022.

\bibitem[Scharstein et~al.(2014)Scharstein, Hirschm{\"{u}}ller, Kitajima, Krathwohl, Nesic, Wang, and Westling]{scharstein2014high}
Daniel Scharstein, Heiko Hirschm{\"{u}}ller, York Kitajima, Greg Krathwohl, Nera Nesic, Xi Wang, and Porter Westling.
\newblock {H}igh-resolution {S}tereo {D}atasets with {S}ubpixel-accurate {G}round {T}ruth.
\newblock In \emph{Pattern Recognition - 36th German Conference, {GCPR} 2014, M{\"{u}}nster, Germany, September 2-5, 2014, Proceedings}, pages 31--42. Springer, 2014.

\bibitem[Sch{\"{o}}ps et~al.(2017)Sch{\"{o}}ps, Sch{\"{o}}nberger, Galliani, Sattler, Schindler, Pollefeys, and Geiger]{schops2017multi}
Thomas Sch{\"{o}}ps, Johannes~L. Sch{\"{o}}nberger, Silvano Galliani, Torsten Sattler, Konrad Schindler, Marc Pollefeys, and Andreas Geiger.
\newblock {A} {M}ulti-view {S}tereo {B}enchmark with {H}igh-resolution {I}mages and {M}ulti-camera {V}ideos.
\newblock In \emph{2017 {IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR} 2017, Honolulu, HI, USA, July 21-26, 2017}, pages 2538--2547. {IEEE} Computer Society, 2017.

\bibitem[Sitzmann et~al.(2018)Sitzmann, Thies, Heide, Nie{\ss}ner, Wetzstein, and Zollh{\"{o}}fer]{sitzmann2019deepvoxels}
Vincent Sitzmann, Justus Thies, Felix Heide, Matthias Nie{\ss}ner, Gordon Wetzstein, and Michael Zollh{\"{o}}fer.
\newblock {D}eep{V}oxels: {L}earning {P}ersistent 3{D} {F}eature {E}mbeddings.
\newblock \emph{CoRR}, abs/1812.01024, 2018.

\bibitem[Su et~al.(2021)Su, Lu, Pan, Wen, and Liu]{su2024roformer}
Jianlin Su, Yu Lu, Shengfeng Pan, Bo Wen, and Yunfeng Liu.
\newblock {R}o{F}ormer: {E}nhanced {T}ransformer with {R}otary {P}osition {E}mbedding.
\newblock \emph{CoRR}, abs/2104.09864, 2021.

\bibitem[Suhail et~al.(2021)Suhail, Esteves, Sigal, and Makadia]{suhail2022light}
Mohammed Suhail, Carlos Esteves, Leonid Sigal, and Ameesh Makadia.
\newblock {L}ight {F}ield {N}eural {R}endering.
\newblock \emph{CoRR}, abs/2112.09687, 2021.

\bibitem[Suhail et~al.(2022)Suhail, Esteves, Sigal, and Makadia]{suhail2022generalizable}
Mohammed Suhail, Carlos Esteves, Leonid Sigal, and Ameesh Makadia.
\newblock {G}eneralizable {P}atch-based {N}eural {R}endering.
\newblock \emph{CoRR}, abs/2207.10662, 2022.

\bibitem[Szymanowicz et~al.(2023)Szymanowicz, Rupprecht, and Vedaldi]{szymanowicz2023splatter}
Stanislaw Szymanowicz, Christian Rupprecht, and Andrea Vedaldi.
\newblock Splatter image: Ultra-fast single-view 3d reconstruction.
\newblock \emph{arXiv preprint arXiv:2312.13150}, 2023.

\bibitem[T et~al.(2023)T, Wang, Chen, Chen, Venugopalan, and Wang]{wang2022attention}
Mukund~Varma T, Peihao Wang, Xuxi Chen, Tianlong Chen, Subhashini Venugopalan, and Zhangyang Wang.
\newblock {I}s {A}ttention {A}ll {T}hat {N}e{R}{F} {N}eeds?
\newblock In \emph{The Eleventh International Conference on Learning Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net, 2023.

\bibitem[Tang et~al.(2024)Tang, Chen, Chen, Wang, Zeng, and Liu]{tang2024lgm}
Jiaxiang Tang, Zhaoxi Chen, Xiaokang Chen, Tengfei Wang, Gang Zeng, and Ziwei Liu.
\newblock {LGM:} {L}arge {M}ulti-view {G}aussian {M}odel for {H}igh-resolution 3{D} {C}ontent {C}reation.
\newblock \emph{CoRR}, abs/2402.05054, 2024.

\bibitem[Wang et~al.(2021{\natexlab{a}})Wang, Wang, Wang, Zhan, Wang, and Lu]{wang2021can}
Lijun Wang, Yifan Wang, Linzhao Wang, Yunlong Zhan, Ying Wang, and Huchuan Lu.
\newblock {C}an {S}cale-consistent {M}onocular {D}epth {B}e {L}earned in a {S}elf-supervised {S}cale-invariant {M}anner?
\newblock In \emph{2021 {IEEE/CVF} International Conference on Computer Vision, {ICCV} 2021, Montreal, QC, Canada, October 10-17, 2021}, pages 12707--12716. {IEEE}, 2021{\natexlab{a}}.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Tan, Bi, Xu, Luan, Sunkavalli, Wang, Xu, and Zhang]{wang2023pf}
Peng Wang, Hao Tan, Sai Bi, Yinghao Xu, Fujun Luan, Kalyan Sunkavalli, Wenping Wang, Zexiang Xu, and Kai Zhang.
\newblock Pf-lrm: Pose-free large reconstruction model for joint pose and shape prediction.
\newblock \emph{arXiv preprint arXiv:2311.12024}, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2021{\natexlab{b}})Wang, Wang, Genova, Srinivasan, Zhou, Barron, Martin{-}Brualla, Snavely, and Funkhouser]{wang2021ibrnet}
Qianqian Wang, Zhicheng Wang, Kyle Genova, Pratul~P. Srinivasan, Howard Zhou, Jonathan~T. Barron, Ricardo Martin{-}Brualla, Noah Snavely, and Thomas~A. Funkhouser.
\newblock {I}{B}{R}{N}et: {L}earning {M}ulti-view {I}mage-based {R}endering.
\newblock \emph{CoRR}, abs/2102.13090, 2021{\natexlab{b}}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Leroy, Cabon, Chidlovskii, and Revaud]{dust3r_cvpr24}
Shuzhe Wang, Vincent Leroy, Yohann Cabon, Boris Chidlovskii, and J{\'{e}}r{\^{o}}me Revaud.
\newblock {D}{U}{S}t3{R}: {G}eometric 3{D} {V}ision {M}ade {E}asy.
\newblock \emph{CoRR}, abs/2312.14132, 2023{\natexlab{b}}.

\bibitem[Wang et~al.(2004)Wang, Bovik, Sheikh, and Simoncelli]{wang2004image}
Zhou Wang, Alan~C. Bovik, Hamid~R. Sheikh, and Eero~P. Simoncelli.
\newblock {I}mage quality assessment: from error visibility to structural similarity.
\newblock \emph{{IEEE} Trans. Image Process.}, 13\penalty0 (4):\penalty0 600--612, 2004.

\bibitem[Wei et~al.(2021)Wei, Fan, Xie, Wu, Yuille, and Feichtenhofer]{wei2022masked}
Chen Wei, Haoqi Fan, Saining Xie, Chao{-}Yuan Wu, Alan~L. Yuille, and Christoph Feichtenhofer.
\newblock {M}asked {F}eature {P}rediction for {S}elf-supervised {V}isual {P}re-training.
\newblock \emph{CoRR}, abs/2112.09133, 2021.

\bibitem[Weinzaepfel et~al.(2022)Weinzaepfel, Leroy, Lucas, Br{\'{e}}gier, Cabon, Arora, Antsfeld, Chidlovskii, Csurka, and Revaud]{weinzaepfel2022croco}
Philippe Weinzaepfel, Vincent Leroy, Thomas Lucas, Romain Br{\'{e}}gier, Yohann Cabon, Vaibhav Arora, Leonid Antsfeld, Boris Chidlovskii, Gabriela Csurka, and J{\'{e}}r{\^{o}}me Revaud.
\newblock {C}ro{C}o: {S}elf-supervised {P}re-training for 3{D} {V}ision {T}asks by {C}ross-view {C}ompletion.
\newblock \emph{CoRR}, abs/2210.10716, 2022.

\bibitem[Weinzaepfel et~al.(2023)Weinzaepfel, Lucas, Leroy, Cabon, Arora, Br{\'{e}}gier, Csurka, Antsfeld, Chidlovskii, and Revaud]{weinzaepfel2023croco}
Philippe Weinzaepfel, Thomas Lucas, Vincent Leroy, Yohann Cabon, Vaibhav Arora, Romain Br{\'{e}}gier, Gabriela Csurka, Leonid Antsfeld, Boris Chidlovskii, and J{\'{e}}r{\^{o}}me Revaud.
\newblock {C}ro{C}o v2: {I}mproved {C}ross-view {C}ompletion {P}re-training for {S}tereo {M}atching and {O}ptical {F}low.
\newblock In \emph{{IEEE/CVF} International Conference on Computer Vision, {ICCV} 2023, Paris, France, October 1-6, 2023}, pages 17923--17934. {IEEE}, 2023.

\bibitem[Wewer et~al.(2024)Wewer, Raj, Ilg, Schiele, and Lenssen]{wewer2024latentsplat}
Christopher Wewer, Kevin Raj, Eddy Ilg, Bernt Schiele, and Jan~Eric Lenssen.
\newblock latent{S}plat: {A}utoencoding {V}ariational {G}aussians for {F}ast {G}eneralizable 3{D} {R}econstruction.
\newblock \emph{CoRR}, abs/2403.16292, 2024.

\bibitem[Xu et~al.(2022)Xu, Zhang, Cai, Rezatofighi, Yu, Tao, and Geiger]{xu2023unifying}
Haofei Xu, Jing Zhang, Jianfei Cai, Hamid Rezatofighi, Fisher Yu, Dacheng Tao, and Andreas Geiger.
\newblock {U}nifying {F}low, {S}tereo and {D}epth {E}stimation.
\newblock \emph{CoRR}, abs/2211.05783, 2022.

\bibitem[Yao et~al.(2018)Yao, Luo, Li, Fang, and Quan]{yao2018mvsnet}
Yao Yao, Zixin Luo, Shiwei Li, Tian Fang, and Long Quan.
\newblock {M}{V}{S}{N}et: {D}epth {I}nference for {U}nstructured {M}ulti-view {S}tereo.
\newblock \emph{CoRR}, abs/1804.02505, 2018.

\bibitem[Yu et~al.(2020)Yu, Ye, Tancik, and Kanazawa]{yu2021pixelnerf}
Alex Yu, Vickie Ye, Matthew Tancik, and Angjoo Kanazawa.
\newblock pixel{N}e{R}{F}: {N}eural {R}adiance {F}ields from {O}ne or {F}ew {I}mages.
\newblock \emph{CoRR}, abs/2012.02190, 2020.

\bibitem[Yu et~al.(2021{\natexlab{a}})Yu, Fridovich{-}Keil, Tancik, Chen, Recht, and Kanazawa]{fridovich2022plenoxels}
Alex Yu, Sara Fridovich{-}Keil, Matthew Tancik, Qinhong Chen, Benjamin Recht, and Angjoo Kanazawa.
\newblock {P}lenoxels: {R}adiance {F}ields without {N}eural {N}etworks.
\newblock \emph{CoRR}, abs/2112.05131, 2021{\natexlab{a}}.

\bibitem[Yu et~al.(2021{\natexlab{b}})Yu, Li, Tancik, Li, Ng, and Kanazawa]{yu2021plenoctrees}
Alex Yu, Ruilong Li, Matthew Tancik, Hao Li, Ren Ng, and Angjoo Kanazawa.
\newblock Plenoctrees for real-time rendering of neural radiance fields.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 5752--5761, 2021{\natexlab{b}}.

\bibitem[Zhang et~al.(2020)Zhang, Riegler, Snavely, and Koltun]{zhang2020nerf++}
Kai Zhang, Gernot Riegler, Noah Snavely, and Vladlen Koltun.
\newblock {N}e{R}{F}++: {A}nalyzing and {I}mproving {N}eural {R}adiance {F}ields.
\newblock \emph{CoRR}, abs/2010.07492, 2020.

\bibitem[Zhang et~al.(2024)Zhang, Bi, Tan, Xiangli, Zhao, Sunkavalli, and Xu]{zhang2024gs}
Kai Zhang, Sai Bi, Hao Tan, Yuanbo Xiangli, Nanxuan Zhao, Kalyan Sunkavalli, and Zexiang Xu.
\newblock Gs-lrm: Large reconstruction model for 3d gaussian splatting.
\newblock \emph{arXiv preprint arXiv:2404.19702}, 2024.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and Wang]{zhang2018unreasonable}
Richard Zhang, Phillip Isola, Alexei~A. Efros, Eli Shechtman, and Oliver Wang.
\newblock {T}he {U}nreasonable {E}ffectiveness of {D}eep {F}eatures as a {P}erceptual {M}etric.
\newblock \emph{CoRR}, abs/1801.03924, 2018.

\bibitem[Zhang(1998)]{zhang1998determining}
Zhengyou Zhang.
\newblock {D}etermining the {E}pipolar {G}eometry and its {U}ncertainty: {A} {R}eview.
\newblock \emph{Int. J. Comput. Vis.}, 27\penalty0 (2):\penalty0 161--195, 1998.

\bibitem[Zheng et~al.(2023)Zheng, Zhou, Shao, Liu, Zhang, Nie, and Liu]{zheng2023gps}
Shunyuan Zheng, Boyao Zhou, Ruizhi Shao, Boning Liu, Shengping Zhang, Liqiang Nie, and Yebin Liu.
\newblock {G}{P}{S}-{G}aussian: {G}eneralizable {P}ixel-wise 3{D} {G}aussian {S}platting for {R}eal-time {H}uman {N}ovel {V}iew {S}ynthesis.
\newblock \emph{CoRR}, abs/2312.02155, 2023.

\bibitem[Zhou et~al.(2018)Zhou, Tucker, Flynn, Fyffe, and Snavely]{zhou2018stereo}
Tinghui Zhou, Richard Tucker, John Flynn, Graham Fyffe, and Noah Snavely.
\newblock {S}tereo {M}agnification: {L}earning {V}iew {S}ynthesis using {M}ultiplane {I}mages.
\newblock \emph{CoRR}, abs/1805.09817, 2018.

\bibitem[Zou et~al.(2023)Zou, Yu, Guo, Li, Liang, Cao, and Zhang]{zou2023triplane}
Zi{-}Xin Zou, Zhipeng Yu, Yuan{-}Chen Guo, Yangguang Li, Ding Liang, Yan{-}Pei Cao, and Song{-}Hai Zhang.
\newblock {T}riplane {M}eets {G}aussian {S}platting: {F}ast and {G}eneralizable {S}ingle-view 3{D} {R}econstruction with {T}ransformers.
\newblock \emph{CoRR}, abs/2312.09147, 2023.

\end{thebibliography}
