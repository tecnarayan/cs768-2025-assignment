\begin{thebibliography}{10}

\bibitem[Blevins(2018)]{blevins2018deep}
Terra Blevins, Omer Levy, and Luke Zettlemoyer.
\newblock Deep rnns encode soft hierarchical syntax.
\newblock {\em arXiv preprint arXiv:1805.04218}, 2018.

\bibitem[Carter(2019)]{carter2019activation}
Shan Carter, Zan Armstrong, Ludwig Schubert, Ian Johnson, and Chris Olah.
\newblock Activation atlas.
\newblock {\em Distill}, 2019.
\newblock https://distill.pub/2019/activation-atlas.

\bibitem[Conneau(2018)]{conneau2018you}
Alexis Conneau, German Kruszewski, Guillaume Lample, Lo{\"\i}c Barrault, and
  Marco Baroni.
\newblock What you can cram into a single vector: Probing sentence embeddings
  for linguistic properties.
\newblock {\em arXiv preprint arXiv:1805.01070}, 2018.

\bibitem[De~Marneffe(2006)]{de2006generating}
Marie-Catherine De~Marneffe, Bill MacCartney, Christopher~D Manning, et~al.
\newblock Generating typed dependency parses from phrase structure parses.
\newblock In {\em Lrec}, volume~6, pages 449--454, 2006.

\bibitem[Devlin(2018)]{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Hewitt(2019)]{hewittstructural}
John Hewitt and Christopher~D Manning.
\newblock A structural probe for finding syntax in word representations.
\newblock {\em Association for Computational Linguistics}, 2019.

\bibitem[Kim(2017)]{kim2017interpretability}
Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda
  Viegas, and Rory Sayres.
\newblock Interpretability beyond feature attribution: Quantitative testing
  with concept activation vectors (tcav).
\newblock {\em arXiv preprint arXiv:1711.11279}, 2017.

\bibitem[Krizhevsky(2012)]{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em Advances in neural information processing systems}, pages
  1097--1105, 2012.

\bibitem[Lecun(1995)]{lecun1995convolutional}
Yann LeCun, Yoshua Bengio, et~al.
\newblock Convolutional networks for images, speech, and time series.
\newblock {\em The handbook of brain theory and neural networks},
  3361(10):1995, 1995.

\bibitem[Linzen(2016)]{linzen2016assessing}
Tal Linzen, Emmanuel Dupoux, and Yoav Goldberg.
\newblock Assessing the ability of lstms to learn syntax-sensitive
  dependencies.
\newblock {\em Transactions of the Association for Computational Linguistics},
  4:521--535, 2016.

\bibitem[Liu(2019)]{liu2019linguistic}
Nelson~F Liu, Matt Gardner, Yonatan Belinkov, Matthew Peters, and Noah~A Smith.
\newblock Linguistic knowledge and transferability of contextual
  representations.
\newblock {\em arXiv preprint arXiv:1903.08855}, 2019.

\bibitem[Maehara(2013)]{maehara2013euclidean}
Hiroshi Maehara.
\newblock Euclidean embeddings of finite metric spaces.
\newblock {\em Discrete Mathematics}, 313(23):2848--2856, 2013.

\bibitem[Marcus(1993)]{Marcus:1993:BLA:972470.972475}
Mitchell~P. Marcus, Mary~Ann Marcinkiewicz, and Beatrice Santorini.
\newblock Building a large annotated corpus of english: The penn treebank.
\newblock {\em Comput. Linguist.}, 19(2):313--330, June 1993.

\bibitem[McClosky(2015)]{pyStanfordDeps}
David McClosky.
\newblock Pystanforddependencies.
\newblock \url{https://github.com/dmcc/PyStanfordDependencies}, 2015.

\bibitem[McInnes(2018)]{mcinnes2018umap}
Leland McInnes, John Healy, and James Melville.
\newblock Umap: Uniform manifold approximation and projection for dimension
  reduction.
\newblock {\em arXiv preprint arXiv:1802.03426}, 2018.

\bibitem[Mikolov(2013)]{mikolov2013distributed}
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg~S Corrado, and Jeff Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In {\em Advances in neural information processing systems}, pages
  3111--3119, 2013.


\bibitem[Miller(1993)]{Miller1993ASC}
George~A. Miller, Claudia Leacock, Randee Tengi, and Ross Bunker.
\newblock A semantic concordance.
\newblock In {\em HLT}, 1993.

\bibitem[Nickel(2017)]{nickel2017poincare}
Maximillian Nickel and Douwe Kiela.
\newblock Poincar{\'e} embeddings for learning hierarchical representations.
\newblock In {\em Advances in neural information processing systems}, pages
  6338--6347, 2017.

\bibitem[Pedregosa(2011)]{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock {\em Journal of Machine Learning Research}, 12:2825--2830, 2011.

\bibitem[Peters(2018)]{peters2018deep}
Matthew~E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,
  Kenton Lee, and Luke Zettlemoyer.
\newblock Deep contextualized word representations.
\newblock {\em arXiv preprint arXiv:1802.05365}, 2018.


\bibitem[Raganato(2017)]{raganato-etal-2017-word}
Alessandro Raganato, Jose Camacho-Collados, and Roberto Navigli.
\newblock Word sense disambiguation: A unified evaluation framework and
  empirical comparison.
\newblock In {\em Proceedings of the 15th Conference of the {E}uropean Chapter
  of the Association for Computational Linguistics: Volume 1, Long Papers},
  pages 99--110, Valencia, Spain, April 2017. Association for Computational
  Linguistics.

\bibitem[Schoenberg(1937)]{schoenberg1937certain}
Isaac~J Schoenberg.
\newblock On certain metric spaces arising from euclidean spaces by a change of
  metric and their imbedding in hilbert space.
\newblock {\em Annals of mathematics}, pages 787--793, 1937.

\bibitem[Tenney(2019)]{tenney2019bert}
Ian Tenney, Dipanjan Das, and Ellie Pavlick.
\newblock Bert rediscovers the classical nlp pipeline.
\newblock {\em arXiv preprint arXiv:1905.05950}, 2019.

\bibitem[Tenney(2018)]{tenney2018you}
Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R~Thomas McCoy,
  Najoung Kim, Benjamin Van~Durme, Samuel~R Bowman, Dipanjan Das, et~al.
\newblock What do you learn from context? probing for sentence structure in
  contextualized word representations.
\newblock 2018.

\bibitem[Vaswani(2017)]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em Advances in neural information processing systems}, pages
  5998--6008, 2017.

\bibitem[Vig(2019)]{vig2019visualizing}
Jesse Vig.
\newblock Visualizing attention in transformer-based language models.
\newblock {\em arXiv preprint arXiv:1904.02679}, 2019.

\bibitem[Zeiler(2014)]{zeiler2014visualizing}
Matthew~D Zeiler and Rob Fergus.
\newblock Visualizing and understanding convolutional networks.
\newblock In {\em European conference on computer vision}, pages 818--833.
  Springer, 2014.

\bibitem[Yury(2019)]{cstheory}
Yury.
\newblock Minimizing the maximum dot product among k unit vectors in an
  n-dimensional space.
\newblock \url{https://cstheory.stackexchange.com/q/14748}, 2012.
\newblock Accessed: 2019-05-09.

\end{thebibliography}
