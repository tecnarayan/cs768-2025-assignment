\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Tishby and Zaslavsky(2015)]{tishby2015bottleneck_principle}
Naftali Tishby and Noga Zaslavsky.
\newblock Deep learning and the information bottleneck principle.
\newblock \emph{2015 IEEE Information Theory Workshop (ITW)}, pages 1--5, 2015.

\bibitem[Xu and Raginsky(2017)]{xu2017IT_analysis}
Aolin Xu and Maxim Raginsky.
\newblock Information-theoretic analysis of generalization capability of
  learning algorithms.
\newblock In I.~Guyon, U.~Von Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2017/file/ad71c82b22f4f65b9398f76d8be4c615-Paper.pdf}.

\bibitem[Goldfeld et~al.(2019)Goldfeld, van~den Berg, Greenewald, Melnyk,
  Nguyen, Kingsbury, and Polyanskiy]{goldfeld2019estimating_information_flow}
Ziv Goldfeld, Ewout van~den Berg, Kristjan~H. Greenewald, Igor~V. Melnyk,
  Nam~H. Nguyen, Brian Kingsbury, and Yury Polyanskiy.
\newblock Estimating information flow in deep neural networks.
\newblock In \emph{ICML}, 2019.

\bibitem[Steinke and Zakynthinou(2020)]{abernethy2020reasoning_conditional_MI}
Thomas Steinke and Lydia Zakynthinou.
\newblock {R}easoning {A}bout {G}eneralization via {C}onditional {M}utual
  {I}nformation.
\newblock In Jacob Abernethy and Shivani Agarwal, editors, \emph{Proceedings of
  Thirty Third Conference on Learning Theory}, volume 125 of \emph{Proceedings
  of Machine Learning Research}, pages 3437--3452. PMLR, 09--12 Jul 2020.
\newblock URL \url{https://proceedings.mlr.press/v125/steinke20a.html}.

\bibitem[Amjad et~al.(2022)Amjad, Liu, and
  Geiger]{kairen2018individual_neurons}
Rana~Ali Amjad, Kairen Liu, and Bernhard~C. Geiger.
\newblock Understanding neural networks and individual neuron importance via
  information-ordered cumulative ablation.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  33\penalty0 (12):\penalty0 7842--7852, 2022.
\newblock \doi{10.1109/TNNLS.2021.3088685}.

\bibitem[Chen et~al.(2016)Chen, Duan, Houthooft, Schulman, Sutskever, and
  Abbeel]{chen2016infogan}
Xi~Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter
  Abbeel.
\newblock Infogan: Interpretable representation learning by information
  maximizing generative adversarial nets.
\newblock In Daniel~D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle
  Guyon, and Roman Garnett, editors, \emph{Advances in Neural Information
  Processing Systems 29: Annual Conference on Neural Information Processing
  Systems 2016, December 5-10, 2016, Barcelona, Spain}, pages 2172--2180, 2016.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2016/hash/7c9d0b1f96aebd7b5eca8c3edaa19ebb-Abstract.html}.

\bibitem[Belghazi et~al.(2018)Belghazi, Baratin, Rajeshwar, Ozair, Bengio,
  Courville, and Hjelm]{belghazi2018mine}
Mohamed~Ishmael Belghazi, Aristide Baratin, Sai Rajeshwar, Sherjil Ozair,
  Yoshua Bengio, Aaron Courville, and Devon Hjelm.
\newblock Mutual information neural estimation.
\newblock In Jennifer Dy and Andreas Krause, editors, \emph{Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of
  \emph{Proceedings of Machine Learning Research}, pages 531--540. PMLR, 07
  2018.
\newblock URL \url{https://proceedings.mlr.press/v80/belghazi18a.html}.

\bibitem[Ardizzone et~al.(2020)Ardizzone, Mackowiak, Rother, and
  K\"{o}the]{ardizzone2020training_normflows}
Lynton Ardizzone, Radek Mackowiak, Carsten Rother, and Ullrich K\"{o}the.
\newblock Training normalizing flows with the information bottleneck for
  competitive generative classification.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 7828--7840. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2020/file/593906af0d138e69f49d251d3e7cbed0-Paper.pdf}.

\bibitem[Berrett and Samworth(2017)]{berrett2017independence_testing}
Thomas Berrett and Richard Samworth.
\newblock Nonparametric independence testing via mutual information.
\newblock \emph{Biometrika}, 106, 11 2017.
\newblock \doi{10.1093/biomet/asz024}.

\bibitem[Sen et~al.(2017)Sen, Suresh, Shanmugam, Dimakis, and
  Shakkottai]{sen2017conditional_independence_test}
Rajat Sen, Ananda~Theertha Suresh, Karthikeyan Shanmugam, Alexandros~G Dimakis,
  and Sanjay Shakkottai.
\newblock Model-powered conditional independence test.
\newblock In I.~Guyon, U.~Von Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2017/file/02f039058bd48307e6f653a2005c9dd2-Paper.pdf}.

\bibitem[Duong and
  Nguyen(2023{\natexlab{a}})]{duong2023normflows_for_conditional_independence_testing}
Bao Duong and Thin Nguyen.
\newblock Normalizing flows for conditional independence testing.
\newblock \emph{Knowledge and Information Systems}, 66, 08 2023{\natexlab{a}}.
\newblock \doi{10.1007/s10115-023-01964-w}.

\bibitem[{Goldfeld} et~al.(2020){Goldfeld}, {Greenewald}, {Niles-Weed}, and
  {Polyanskiy}]{goldfeld2020convergence_of_SEM_entropy_estimation}
Z.~{Goldfeld}, K.~{Greenewald}, J.~{Niles-Weed}, and Y.~{Polyanskiy}.
\newblock Convergence of smoothed empirical measures with applications to
  entropy estimation.
\newblock \emph{IEEE Transactions on Information Theory}, 66\penalty0
  (7):\penalty0 4368--4391, 2020.
\newblock \doi{10.1109/TIT.2020.2975480}.

\bibitem[McAllester and Stratos(2020)]{mcallester2020limitations_MI}
David McAllester and Karl Stratos.
\newblock Formal limitations on the measurement of mutual information.
\newblock In Silvia Chiappa and Roberto Calandra, editors, \emph{Proceedings of
  the Twenty Third International Conference on Artificial Intelligence and
  Statistics}, volume 108 of \emph{Proceedings of Machine Learning Research},
  pages 875--884. PMLR, 08 2020.
\newblock URL \url{https://proceedings.mlr.press/v108/mcallester20a.html}.

\bibitem[Czy{\.z} et~al.(2023)Czy{\.z}, Grabowski, Vogt, Beerenwinkel, and
  Marx]{czyz2023beyond_normal}
Pawe{\l} Czy{\.z}, Frederic Grabowski, Julia~E Vogt, Niko Beerenwinkel, and
  Alexander Marx.
\newblock Beyond normal: On the evaluation of mutual information estimators.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing
  Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=25vRtG56YH}.

\bibitem[van~den Oord et~al.(2019)van~den Oord, Li, and
  Vinyals]{oord2019representation_learning_CPC}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding, 2019.

\bibitem[Song and Ermon(2020)]{song2020understanding_limitations}
Jiaming Song and Stefano Ermon.
\newblock xtanding the limitations of variational mutual information
  estimators.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=B1x62TNtDS}.

\bibitem[Rhodes et~al.(2020)Rhodes, Xu, and Gutmann]{rhodes2020telescoping}
Benjamin Rhodes, Kai Xu, and Michael~U. Gutmann.
\newblock Telescoping density-ratio estimation.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 4905--4916. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2020/file/33d3b157ddc0896addfb22fa2a519097-Paper.pdf}.

\bibitem[Ao and Li(2022)]{Ao_Li_2022entropy_estimation_normflows}
Ziqiao Ao and Jinglai Li.
\newblock Entropy estimation via normalizing flow.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  36\penalty0 (9):\penalty0 9990--9998, Jun. 2022.
\newblock \doi{10.1609/aaai.v36i9.21237}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/21237}.

\bibitem[Butakov et~al.(2024)Butakov, Tolmachev, Malanchuk, Neopryatnaya,
  Frolov, and Andreev]{butakov2024lossy_compression}
Ivan Butakov, Alexander Tolmachev, Sofia Malanchuk, Anna Neopryatnaya, Alexey
  Frolov, and Kirill Andreev.
\newblock Information bottleneck analysis of deep neural networks via lossy
  compression.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=huGECz8dPp}.

\bibitem[Franzese et~al.(2024)Franzese, BOUNOUA, and
  Michiardi]{franzese2024minde}
Giulio Franzese, Mustapha BOUNOUA, and Pietro Michiardi.
\newblock {MINDE}: Mutual information neural diffusion estimation.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=0kWd8SJq8d}.

\bibitem[Tabak and Vanden-Eijnden(2010)]{tabak2010PDF_estimators_LL_ascend}
Esteban~G. Tabak and Eric Vanden-Eijnden.
\newblock {Density estimation by dual ascent of the log-likelihood}.
\newblock \emph{Communications in Mathematical Sciences}, 8\penalty0
  (1):\penalty0 217 -- 233, 2010.

\bibitem[Tabak and Turner(2013)]{tabak2013nonparametric_PDF_estimators}
E.~G. Tabak and Cristina~V. Turner.
\newblock A family of nonparametric density estimation algorithms.
\newblock \emph{Communications on Pure and Applied Mathematics}, 66\penalty0
  (2):\penalty0 145--164, 2013.
\newblock \doi{https://doi.org/10.1002/cpa.21423}.
\newblock URL \url{https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.21423}.

\bibitem[Dinh et~al.(2015)Dinh, Krueger, and Bengio]{dinh2015NICE}
Laurent Dinh, David Krueger, and Yoshua Bengio.
\newblock {NICE:} non-linear independent components estimation.
\newblock In Yoshua Bengio and Yann LeCun, editors, \emph{3rd International
  Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May
  7-9, 2015, Workshop Track Proceedings}, 2015.
\newblock URL \url{http://arxiv.org/abs/1410.8516}.

\bibitem[Rezende and Mohamed(2015)]{rezende2015variational_inference_normflows}
Danilo~Jimenez Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In Francis~R. Bach and David~M. Blei, editors, \emph{Proceedings of
  the 32nd International Conference on Machine Learning, {ICML} 2015, Lille,
  France, 6-11 July 2015}, volume~37 of \emph{{JMLR} Workshop and Conference
  Proceedings}, pages 1530--1538. JMLR.org, 2015.
\newblock URL \url{http://proceedings.mlr.press/v37/rezende15.html}.

\bibitem[Duong and Nguyen(2023{\natexlab{b}})]{duong2023dine}
Bao Duong and Thin Nguyen.
\newblock Diffeomorphic information neural estimation.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  37\penalty0 (6):\penalty0 7468--7475, Jun. 2023{\natexlab{b}}.
\newblock \doi{10.1609/aaai.v37i6.25908}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/25908}.

\bibitem[Spivak(1965)]{spivak1965calculus}
M.~Spivak.
\newblock \emph{Calculus On Manifolds: A Modern Approach To Classical Theorems
  Of Advanced Calculus}.
\newblock Avalon Publishing, 1965.
\newblock ISBN 9780805390216.

\bibitem[Berrett et~al.(2019)Berrett, Samworth, and
  Yuan]{berrett2019efficient_knn_entropy_estimation}
Thomas~B. Berrett, Richard~J. Samworth, and Ming Yuan.
\newblock Efficient multivariate entropy estimation via $k$-nearest neighbour
  distances.
\newblock \emph{Ann. Statist.}, 47\penalty0 (1):\penalty0 288--318, 02 2019.
\newblock \doi{10.1214/18-AOS1688}.
\newblock URL \url{https://doi.org/10.1214/18-AOS1688}.

\bibitem[Butakov et~al.(2021)Butakov, Malanchuk, Neopryatnaya, Tolmachev,
  Andreev, Kruglik, Marshakov, and
  Frolov]{butakov2021high_dimensional_entropy_estimation}
I.~D. Butakov, S.~V. Malanchuk, A.~M. Neopryatnaya, A.~D. Tolmachev, K.~V.
  Andreev, S.~A. Kruglik, E.~A. Marshakov, and A.~A. Frolov.
\newblock High-dimensional dataset entropy estimation via lossy compression.
\newblock \emph{Journal of Communications Technology and Electronics},
  66\penalty0 (6):\penalty0 764--768, 7 2021.
\newblock ISSN 1555-6557.
\newblock \doi{10.1134/S1064226921060061}.
\newblock URL \url{https://doi.org/10.1134/S1064226921060061}.

\bibitem[Greenewald et~al.(2023)Greenewald, Kingsbury, and
  Yu]{kristjan2023smoothed_entropy_PCA}
Kristjan~H. Greenewald, Brian Kingsbury, and Yuancheng Yu.
\newblock High-dimensional smoothed entropy estimation via dimensionality
  reduction.
\newblock In \emph{{IEEE} International Symposium on Information Theory, {ISIT}
  2023, Taipei, Taiwan, June 25-30, 2023}, pages 2613--2618. {IEEE}, 2023.
\newblock \doi{10.1109/ISIT54713.2023.10206641}.
\newblock URL \url{https://doi.org/10.1109/ISIT54713.2023.10206641}.

\bibitem[Adilova et~al.(2023)Adilova, Geiger, and
  Fischer]{adilova2023IP_dropout}
Linara Adilova, Bernhard~C. Geiger, and Asja Fischer.
\newblock Information plane analysis for dropout neural networks, 2023.

\bibitem[Kraskov et~al.(2004)Kraskov, St\"ogbauer, and
  Grassberger]{kraskov2004KSG}
Alexander Kraskov, Harald St\"ogbauer, and Peter Grassberger.
\newblock Estimating mutual information.
\newblock \emph{Phys. Rev. E}, 69:\penalty0 066138, Jun 2004.
\newblock \doi{10.1103/PhysRevE.69.066138}.
\newblock URL \url{https://link.aps.org/doi/10.1103/PhysRevE.69.066138}.

\bibitem[Czyż et~al.(2023)Czyż, Grabowski, Vogt, Beerenwinkel, and
  Marx]{czyz2023pointwise_MI}
Paweł Czyż, Frederic Grabowski, Julia~E. Vogt, Niko Beerenwinkel, and
  Alexander Marx.
\newblock The mixtures and the neural critics: On the pointwise mutual
  information profiles of fine distributions, 2023.

\bibitem[Polyanskiy and Wu(2024)]{polyanskiy2024information_theory}
Y.~Polyanskiy and Y.~Wu.
\newblock \emph{Information Theory: From Coding to Learning}.
\newblock Cambridge University Press, 2024.
\newblock ISBN 9781108832908.
\newblock URL \url{https://books.google.ru/books?id=CySo0AEACAAJ}.

\bibitem[Kobyzev et~al.(2021)Kobyzev, Prince, and
  Brubaker]{kobyzev2021normflows_overview}
I.~Kobyzev, S.~D. Prince, and M.~A. Brubaker.
\newblock Normalizing flows: An introduction and review of current methods.
\newblock \emph{IEEE Transactions on Pattern Analysis \& Machine Intelligence},
  43\penalty0 (11):\penalty0 3964--3979, nov 2021.
\newblock ISSN 1939-3539.
\newblock \doi{10.1109/TPAMI.2020.2992934}.

\bibitem[Cover and Thomas(2006)]{cover2006information_theory}
Thomas~M. Cover and Joy~A. Thomas.
\newblock \emph{Elements of Information Theory (Wiley Series in
  Telecommunications and Signal Processing)}.
\newblock Wiley-Interscience, USA, 2006.

\bibitem[Lancaster(1958)]{lancaster1958bivariate_structure}
H.~O. Lancaster.
\newblock The structure of bivariate distributions.
\newblock \emph{The Annals of Mathematical Statistics}, 29\penalty0
  (3):\penalty0 719--736, 1958.
\newblock ISSN 00034851.
\newblock URL \url{http://www.jstor.org/stable/2237259}.

\bibitem[Hannan(1961)]{hannan1961cca}
E.~J. Hannan.
\newblock The general theory of canonical correlation and its relation to
  functional analysis.
\newblock \emph{Journal of the Australian Mathematical Society}, 2\penalty0
  (2):\penalty0 229–242, 1961.
\newblock \doi{10.1017/S1446788700026707}.

\bibitem[Donsker and Varadhan(1983)]{donsker1983dv}
{M. D.} Donsker and {S. R.S.} Varadhan.
\newblock Asymptotic evaluation of certain markov process expectations for
  large time. iv.
\newblock \emph{Communications on Pure and Applied Mathematics}, 36\penalty0
  (2):\penalty0 183--212, March 1983.
\newblock ISSN 0010-3640.
\newblock \doi{10.1002/cpa.3160360204}.

\bibitem[Nguyen et~al.(2007)Nguyen, Wainwright, and Jordan]{nguyen2007nwj}
XuanLong Nguyen, Martin~J Wainwright, and Michael Jordan.
\newblock Estimating divergence functionals and the likelihood ratio by
  penalized convex risk minimization.
\newblock In J.~Platt, D.~Koller, Y.~Singer, and S.~Roweis, editors,
  \emph{Advances in Neural Information Processing Systems}, volume~20. Curran
  Associates, Inc., 2007.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2007/file/72da7fd6d1302c0a159f6436d01e9eb0-Paper.pdf}.

\bibitem[Nishiyama(2019)]{nishiyama2019new_lower_bound_on_kld}
Tomohiro Nishiyama.
\newblock A new lower bound for kullback-leibler divergence based on
  hammersley-chapman-robbins bound, 2019.

\bibitem[Teng and Choromanska(2019)]{teng2019invertible_AE}
Yunfei Teng and Anna Choromanska.
\newblock Invertible autoencoder for domain adaptation.
\newblock \emph{Computation}, 7\penalty0 (2), 2019.
\newblock ISSN 2079-3197.
\newblock \doi{10.3390/computation7020020}.
\newblock URL \url{https://www.mdpi.com/2079-3197/7/2/20}.

\bibitem[Brehmer and Cranmer(2020)]{brehmer2020flows_manifold_learning}
Johann Brehmer and Kyle Cranmer.
\newblock Flows for simultaneous manifold learning and density estimation.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 442--453. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2020/file/051928341be67dcba03f0e04104d9047-Paper.pdf}.

\bibitem[Poole et~al.(2019)Poole, Ozair, Van Den~Oord, Alemi, and
  Tucker]{poole2019on_variational_bounds_MI}
Ben Poole, Sherjil Ozair, Aaron Van Den~Oord, Alex Alemi, and George Tucker.
\newblock On variational bounds of mutual information.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors,
  \emph{Proceedings of the 36th International Conference on Machine Learning},
  volume~97 of \emph{Proceedings of Machine Learning Research}, pages
  5171--5180. PMLR, 06 2019.
\newblock URL \url{https://proceedings.mlr.press/v97/poole19a.html}.

\bibitem[Kozachenko and Leonenko(1987)]{kozachenko1987entropy_of_random_vector}
L.~F. Kozachenko and N.~N. Leonenko.
\newblock Sample estimate of the entropy of a random vector.
\newblock \emph{Problems Inform. Transmission}, 23:\penalty0 95--101, 1987.

\bibitem[Kingma and Dhariwal(2018)]{kingma2018GLOW}
Durk~P Kingma and Prafulla Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, \emph{Advances in Neural Information Processing
  Systems}, volume~31. Curran Associates, Inc., 2018.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2018/file/d139db6a236200b21cc7f752979132d0-Paper.pdf}.

\bibitem[Dinh et~al.(2017)Dinh, Sohl-Dickstein, and Bengio]{dinh2017real_NVP}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real {NVP}.
\newblock In \emph{International Conference on Learning Representations}, 2017.
\newblock URL \url{https://openreview.net/forum?id=HkpbnH9lx}.

\bibitem[Shwartz-Ziv and Tishby(2017)]{shwartz_ziv2017opening_black_box}
Ravid Shwartz-Ziv and Naftali Tishby.
\newblock Opening the black box of deep neural networks via information, 2017.

\bibitem[He et~al.(2023)He, Yu, and Goldfeld]{he2023generalization_bounds}
Haiyun He, Christina Yu, and Ziv Goldfeld.
\newblock Information-theoretic generalization bounds for deep neural networks.
\newblock In \emph{NeurIPS 2023 workshop: Information-Theoretic Principles in
  Cognitive Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=udEjq72DFO}.

\bibitem[Zhang and Chen(2021)]{zhang2021diffusion_normalizing_flows}
Qinsheng Zhang and Yongxin Chen.
\newblock Diffusion normalizing flow.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman
  Vaughan, editors, \emph{Advances in Neural Information Processing Systems},
  volume~34, pages 16280--16291. Curran Associates, Inc., 2021.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2021/file/876f1f9954de0aa402d91bb988d12cd4-Paper.pdf}.

\bibitem[Kingma et~al.(2021)Kingma, Salimans, Poole, and
  Ho]{kingma2021density_estimation_with_diffusion_models}
Diederik~P Kingma, Tim Salimans, Ben Poole, and Jonathan Ho.
\newblock On density estimation with diffusion models.
\newblock In A.~Beygelzimer, Y.~Dauphin, P.~Liang, and J.~Wortman Vaughan,
  editors, \emph{Advances in Neural Information Processing Systems}, 2021.
\newblock URL \url{https://openreview.net/forum?id=2LdBqxc1Yv}.

\bibitem[Cai et~al.(2015)Cai, Liang, and Zhou]{cai2015logdet}
T.~Tony Cai, Tengyuan Liang, and Harrison~H. Zhou.
\newblock Law of log determinant of sample covariance matrix and optimal
  estimation of differential entropy for high-dimensional gaussian
  distributions.
\newblock \emph{Journal of Multivariate Analysis}, 137:\penalty0 161--172,
  2015.
\newblock ISSN 0047-259X.
\newblock \doi{https://doi.org/10.1016/j.jmva.2015.02.003}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S0047259X1500038X}.

\bibitem[Arellano-Valle et~al.(2013)Arellano-Valle, Contreras-Reyes, and
  Genton]{arellano_valle2013MI_for_skew_distributions}
R.~Arellano-Valle, Javier Contreras-Reyes, and Marc Genton.
\newblock Shannon entropy and mutual information for multivariate
  skew-elliptical distributions.
\newblock \emph{Scandinavian Journal of Statistics}, 40:\penalty0 42--62, 03
  2013.
\newblock \doi{10.1111/j.1467-9469.2011.}

\bibitem[Stimper et~al.(2023)Stimper, Liu, Campbell, Berenz, Ryll, Schölkopf,
  and Hernández-Lobato]{stimper2023normflows}
Vincent Stimper, David Liu, Andrew Campbell, Vincent Berenz, Lukas Ryll,
  Bernhard Schölkopf, and José~Miguel Hernández-Lobato.
\newblock normflows: A pytorch package for normalizing flows.
\newblock \emph{Journal of Open Source Software}, 8\penalty0 (86):\penalty0
  5361, 2023.
\newblock \doi{10.21105/joss.05361}.
\newblock URL \url{https://doi.org/10.21105/joss.05361}.

\bibitem[Kingma and Ba(2017)]{kingma2017adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization, 2017.

\end{thebibliography}
