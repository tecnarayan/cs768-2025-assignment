\begin{thebibliography}{65}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amari(1998)]{amari1998natural}
Amari, S.-I.
\newblock Natural gradient works efficiently in learning.
\newblock \emph{Neural computation}, 10\penalty0 (2):\penalty0 251--276, 1998.

\bibitem[Amos et~al.(2018)Amos, Jimenez, Sacks, Boots, and
  Kolter]{amos2018differentiable}
Amos, B., Jimenez, I., Sacks, J., Boots, B., and Kolter, J.~Z.
\newblock Differentiable {MPC} for end-to-end planning and control.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  8299--8310, 2018.

\bibitem[Anthony et~al.(2017)Anthony, Tian, and Barber]{anthony2017thinking}
Anthony, T., Tian, Z., and Barber, D.
\newblock Thinking fast and slow with deep learning and tree search.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  5360--5370, 2017.

\bibitem[Beck \& Teboulle(2003)Beck and Teboulle]{beck2003mirror}
Beck, A. and Teboulle, M.
\newblock Mirror descent and nonlinear projected subgradient methods for convex
  optimization.
\newblock \emph{Operations Research Letters}, 31\penalty0 (3):\penalty0
  167--175, 2003.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{brockman2016openai}
Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang,
  J., and Zaremba, W.
\newblock Open{AI} {G}ym.
\newblock \emph{arXiv preprint arXiv:1606.01540}, 2016.

\bibitem[Chebotar et~al.(2017)Chebotar, Hausman, Zhang, Sukhatme, Schaal, and
  Levine]{chebotar2017combining}
Chebotar, Y., Hausman, K., Zhang, M., Sukhatme, G., Schaal, S., and Levine, S.
\newblock Combining model-based and model-free updates for trajectory-centric
  reinforcement learning.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  703--711, 2017.

\bibitem[Cheng \& Boots(2018)Cheng and Boots]{cheng2018convergence}
Cheng, C.-A. and Boots, B.
\newblock Convergence of value aggregation for imitation learning.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, volume~84, pp.\  1801--1809, 2018.

\bibitem[Cheng et~al.(2018)Cheng, Yan, Wagener, and Boots]{cheng2018fast}
Cheng, C.-A., Yan, X., Wagener, N., and Boots, B.
\newblock Fast policy learning through imitation and reinforcement.
\newblock In \emph{Proceedings of the 34th Conference on Uncertanty in
  Artificial Intelligence}, pp.\  845--855, 2018.

\bibitem[Cheng et~al.(2019)Cheng, Yan, Theodorou, and
  Boots]{cheng2019accelerating}
Cheng, C.-A., Yan, X., Theodorou, E., and Boots, B.
\newblock Accelerating imitation learning with predictive models.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, 2019.

\bibitem[Chiang et~al.(2012)Chiang, Yang, Lee, Mahdavi, Lu, Jin, and
  Zhu]{chiang2012online}
Chiang, C.-K., Yang, T., Lee, C.-J., Mahdavi, M., Lu, C.-J., Jin, R., and Zhu,
  S.
\newblock Online optimization with gradual variations.
\newblock In \emph{Conference on Learning Theory}, pp.\  6--1, 2012.

\bibitem[Daniely et~al.(2015)Daniely, Gonen, and
  Shalev-Shwartz]{daniely2015strongly}
Daniely, A., Gonen, A., and Shalev-Shwartz, S.
\newblock Strongly adaptive online learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1405--1411, 2015.

\bibitem[Deisenroth \& Rasmussen(2011)Deisenroth and
  Rasmussen]{deisenroth2011pilco}
Deisenroth, M. and Rasmussen, C.~E.
\newblock Pilco: A model-based and data-efficient approach to policy search.
\newblock In \emph{International Conference on machine learning}, pp.\
  465--472, 2011.

\bibitem[Diakonikolas \& Orecchia(2017)Diakonikolas and
  Orecchia]{diakonikolas2017accelerated}
Diakonikolas, J. and Orecchia, L.
\newblock Accelerated extra-gradient descent: A novel accelerated first-order
  method.
\newblock \emph{arXiv preprint arXiv:1706.04680}, 2017.

\bibitem[Duan et~al.(2016)Duan, Chen, Houthooft, Schulman, and
  Abbeel]{duan2016benchmarking}
Duan, Y., Chen, X., Houthooft, R., Schulman, J., and Abbeel, P.
\newblock Benchmarking deep reinforcement learning for continuous control.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1329--1338, 2016.

\bibitem[Duchi et~al.(2011)Duchi, Hazan, and Singer]{duchi2011adaptive}
Duchi, J., Hazan, E., and Singer, Y.
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock \emph{Journal of Machine Learning Research}, 12\penalty0
  (Jul):\penalty0 2121--2159, 2011.

\bibitem[Gordon(1999)]{gordon1999regret}
Gordon, G.~J.
\newblock Regret bounds for prediction problems.
\newblock In \emph{Annual Conference on Computational Learning Theory}, pp.\
  29--40. ACM, 1999.

\bibitem[Grathwohl et~al.(2018)Grathwohl, Choi, Wu, Roeder, and
  Duvenaud]{grathwohl2017backpropagation}
Grathwohl, W., Choi, D., Wu, Y., Roeder, G., and Duvenaud, D.
\newblock Backpropagation through the void: Optimizing control variates for
  black-box gradient estimation.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Gupta et~al.(2017)Gupta, Koren, and Singer]{gupta2017unified}
Gupta, V., Koren, T., and Singer, Y.
\newblock A unified approach to adaptive regularization in online and
  stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1706.06569}, 2017.

\bibitem[Hazan et~al.(2007)Hazan, Agarwal, and Kale]{hazan2007logarithmic}
Hazan, E., Agarwal, A., and Kale, S.
\newblock Logarithmic regret algorithms for online convex optimization.
\newblock \emph{Machine Learning}, 69\penalty0 (2-3):\penalty0 169--192, 2007.

\bibitem[Hazan et~al.(2016)]{hazan2016introduction}
Hazan, E. et~al.
\newblock Introduction to online convex optimization.
\newblock \emph{Foundations and Trends{\textregistered} in Optimization},
  2\penalty0 (3-4):\penalty0 157--325, 2016.

\bibitem[Ho-Nguyen \& K{\i}l{\i}n{\c{c}}-Karzan(2018)Ho-Nguyen and
  K{\i}l{\i}n{\c{c}}-Karzan]{ho2017exploiting}
Ho-Nguyen, N. and K{\i}l{\i}n{\c{c}}-Karzan, F.
\newblock Exploiting problem structure in optimization under uncertainty via
  online convex optimization.
\newblock \emph{Mathematical Programming}, pp.\  1--35, 2018.

\bibitem[Jacobson \& Mayne(1970)Jacobson and Mayne]{jacobson1970differential}
Jacobson, D.~H. and Mayne, D.~Q.
\newblock Differential dynamic programming.
\newblock 1970.

\bibitem[Jadbabaie et~al.(2015)Jadbabaie, Rakhlin, Shahrampour, and
  Sridharan]{jadbabaie2015online}
Jadbabaie, A., Rakhlin, A., Shahrampour, S., and Sridharan, K.
\newblock Online optimization: Competing with dynamic comparators.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  398--406,
  2015.

\bibitem[Juditsky et~al.(2011)Juditsky, Nemirovski, and
  Tauvel]{juditsky2011solving}
Juditsky, A., Nemirovski, A., and Tauvel, C.
\newblock Solving variational inequalities with stochastic mirror-prox
  algorithm.
\newblock \emph{Stochastic Systems}, 1\penalty0 (1):\penalty0 17--58, 2011.

\bibitem[Kakade \& Langford(2002)Kakade and Langford]{kakade2002approximately}
Kakade, S. and Langford, J.
\newblock Approximately optimal approximate reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, volume~2,
  pp.\  267--274, 2002.

\bibitem[Kakade(2002)]{kakade2002natural}
Kakade, S.~M.
\newblock A natural policy gradient.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1531--1538, 2002.

\bibitem[Kalai \& Vempala(2005)Kalai and Vempala]{kalai2005efficient}
Kalai, A. and Vempala, S.
\newblock Efficient algorithms for online decision problems.
\newblock \emph{Journal of Computer and System Sciences}, 71\penalty0
  (3):\penalty0 291--307, 2005.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2015.

\bibitem[Konda \& Tsitsiklis(2000)Konda and Tsitsiklis]{konda2000actor}
Konda, V.~R. and Tsitsiklis, J.~N.
\newblock Actor-critic algorithms.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1008--1014, 2000.

\bibitem[Korpelevich(1976)]{korpelevich1976extragradient}
Korpelevich, G.
\newblock The extragradient method for finding saddle points and other
  problems.
\newblock \emph{Matecon}, 12:\penalty0 747--756, 1976.

\bibitem[Lee et~al.(2018)Lee, Grey, Ha, Kunz, Jain, Ye, Srinivasa, Stilman, and
  Liu]{Lee2018}
Lee, J., Grey, M.~X., Ha, S., Kunz, T., Jain, S., Ye, Y., Srinivasa, S.~S.,
  Stilman, M., and Liu, C.~K.
\newblock {DART}: Dynamic animation and robotics toolkit.
\newblock \emph{The Journal of Open Source Software}, 3\penalty0 (22):\penalty0
  500, feb 2018.

\bibitem[Levine \& Koltun(2013)Levine and Koltun]{levine2013guided}
Levine, S. and Koltun, V.
\newblock Guided policy search.
\newblock In \emph{International Conference on Machine Learning}, pp.\  1--9,
  2013.

\bibitem[McMahan(2017)]{mcmahan2017survey}
McMahan, H.~B.
\newblock A survey of algorithms and analysis for adaptive online learning.
\newblock \emph{The Journal of Machine Learning Research}, 18\penalty0
  (1):\penalty0 3117--3166, 2017.

\bibitem[McMahan \& Streeter(2010)McMahan and Streeter]{mcmahan2010adaptive}
McMahan, H.~B. and Streeter, M.
\newblock Adaptive bound optimization for online convex optimization.
\newblock In \emph{{COLT} 2010 - The 23rd Conference on Learning Theory}, 2010.

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{mnih2013playing}
Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra,
  D., and Riedmiller, M.
\newblock Playing atari with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1312.5602}, 2013.

\bibitem[Nemirovski(2004)]{nemirovski2004prox}
Nemirovski, A.
\newblock Prox-method with rate of convergence o (1/t) for variational
  inequalities with lipschitz continuous monotone operators and smooth
  convex-concave saddle point problems.
\newblock \emph{SIAM Journal on Optimization}, 15\penalty0 (1):\penalty0
  229--251, 2004.

\bibitem[Nesterov(2013)]{nesterov2013introductory}
Nesterov, Y.
\newblock \emph{Introductory lectures on convex optimization: A basic course},
  volume~87.
\newblock Springer Science \& Business Media, 2013.

\bibitem[Oh et~al.(2017)Oh, Singh, and Lee]{oh2017value}
Oh, J., Singh, S., and Lee, H.
\newblock Value prediction network.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6120--6130, 2017.

\bibitem[Pan \& Theodorou(2014)Pan and Theodorou]{pan2014probabilistic}
Pan, Y. and Theodorou, E.
\newblock Probabilistic differential dynamic programming.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1907--1915, 2014.

\bibitem[Papini et~al.(2018)Papini, Binaghi, Canonaco, Pirotta, and
  Restelli]{papini2018stochastic}
Papini, M., Binaghi, D., Canonaco, G., Pirotta, M., and Restelli, M.
\newblock Stochastic variance-reduced policy gradient.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, pp.\  4023--4032, 2018.

\bibitem[Pascanu et~al.(2017)Pascanu, Li, Vinyals, Heess, Buesing,
  Racani{\`e}re, Reichert, Weber, Wierstra, and Battaglia]{pascanu2017learning}
Pascanu, R., Li, Y., Vinyals, O., Heess, N., Buesing, L., Racani{\`e}re, S.,
  Reichert, D., Weber, T., Wierstra, D., and Battaglia, P.
\newblock Learning model-based planning from scratch.
\newblock \emph{arXiv preprint arXiv:1707.06170}, 2017.

\bibitem[Peters \& Schaal(2008)Peters and Schaal]{peters2008natural}
Peters, J. and Schaal, S.
\newblock Natural actor-critic.
\newblock \emph{Neurocomputing}, 71\penalty0 (7-9):\penalty0 1180--1190, 2008.

\bibitem[Peters et~al.(2010)Peters, M{\"u}lling, and Altun]{peters2010relative}
Peters, J., M{\"u}lling, K., and Altun, Y.
\newblock Relative entropy policy search.
\newblock In \emph{AAAI}, pp.\  1607--1612. Atlanta, 2010.

\bibitem[Rakhlin \& Sridharan(2013{\natexlab{a}})Rakhlin and
  Sridharan]{rakhlin2013online}
Rakhlin, A. and Sridharan, K.
\newblock Online learning with predictable sequences.
\newblock In \emph{{COLT} 2013 - The 26th Annual Conference on Learning
  Theory}, pp.\  993--1019, 2013{\natexlab{a}}.

\bibitem[Rakhlin \& Sridharan(2013{\natexlab{b}})Rakhlin and
  Sridharan]{rakhlin2013optimization}
Rakhlin, S. and Sridharan, K.
\newblock Optimization, learning, and games with predictable sequences.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3066--3074, 2013{\natexlab{b}}.

\bibitem[Reddi et~al.(2018)Reddi, Kale, and Kumar]{reddi2018convergence}
Reddi, S.~J., Kale, S., and Kumar, S.
\newblock On the convergence of adam and beyond.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Ross \& Bagnell(2014)Ross and Bagnell]{ross2014reinforcement}
Ross, S. and Bagnell, J.~A.
\newblock Reinforcement and imitation learning via interactive no-regret
  learning.
\newblock \emph{arXiv preprint arXiv:1406.5979}, 2014.

\bibitem[Ross et~al.(2011)Ross, Gordon, and Bagnell]{ross2011reduction}
Ross, S., Gordon, G., and Bagnell, D.
\newblock A reduction of imitation learning and structured prediction to
  no-regret online learning.
\newblock In \emph{International conference on artificial intelligence and
  statistics}, pp.\  627--635, 2011.

\bibitem[Schulman et~al.(2015)Schulman, Levine, Abbeel, Jordan, and
  Moritz]{schulman2015trust}
Schulman, J., Levine, S., Abbeel, P., Jordan, M., and Moritz, P.
\newblock Trust region policy optimization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1889--1897, 2015.

\bibitem[Schulman et~al.(2016)Schulman, Moritz, Levine, Jordan, and
  Abbeel]{schulman2015high}
Schulman, J., Moritz, P., Levine, S., Jordan, M., and Abbeel, P.
\newblock High-dimensional continuous control using generalized advantage
  estimation.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2016.

\bibitem[Silver et~al.(2014)Silver, Lever, Heess, Degris, Wierstra, and
  Riedmiller]{silver2014deterministic}
Silver, D., Lever, G., Heess, N., Degris, T., Wierstra, D., and Riedmiller, M.
\newblock Deterministic policy gradient algorithms.
\newblock In \emph{Proceedings of the 31th International Conference on Machine
  Learning}, pp.\  387--395, 2014.

\bibitem[Silver et~al.(2017)Silver, van Hasselt, Hessel, Schaul, Guez, Harley,
  Dulac-Arnold, Reichert, Rabinowitz, Barreto, et~al.]{silver2016predictron}
Silver, D., van Hasselt, H., Hessel, M., Schaul, T., Guez, A., Harley, T.,
  Dulac-Arnold, G., Reichert, D., Rabinowitz, N., Barreto, A., et~al.
\newblock The predictron: End-to-end learning and planning.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, 2017.

\bibitem[Silver et~al.(2018)Silver, Hubert, Schrittwieser, Antonoglou, Lai,
  Guez, Lanctot, Sifre, Kumaran, Graepel, Lillicrap, Simonyan, and
  Hassabis]{silver2017mastering}
Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A.,
  Lanctot, M., Sifre, L., Kumaran, D., Graepel, T., Lillicrap, T., Simonyan,
  K., and Hassabis, D.
\newblock A general reinforcement learning algorithm that masters chess, shogi,
  and go through self-play.
\newblock \emph{Science}, 362\penalty0 (6419):\penalty0 1140--1144, 2018.
\newblock ISSN 0036-8075.

\bibitem[Srinivas et~al.(2018)Srinivas, Jabri, Abbeel, Levine, and
  Finn]{srinivas2018universal}
Srinivas, A., Jabri, A., Abbeel, P., Levine, S., and Finn, C.
\newblock Universal planning networks: Learning generalizable representations
  for visuomotor control.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, 2018.

\bibitem[Sun et~al.(2017)Sun, Venkatraman, Gordon, Boots, and
  Bagnell]{sun2017deeply}
Sun, W., Venkatraman, A., Gordon, G.~J., Boots, B., and Bagnell, J.~A.
\newblock Deeply aggrevated: Differentiable imitation learning for sequential
  prediction.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, pp.\  3309--3318, 2017.

\bibitem[Sun et~al.(2018)Sun, Gordon, Boots, and Bagnell]{wen2018dual}
Sun, W., Gordon, G.~J., Boots, B., and Bagnell, J.~A.
\newblock Dual policy iteration.
\newblock In \emph{Advances in Neural Information Processing Systems 31}, pp.\
  7059--7069, 2018.

\bibitem[Sutton(1991)]{sutton1991dyna}
Sutton, R.~S.
\newblock Dyna, an integrated architecture for learning, planning, and
  reacting.
\newblock \emph{ACM SIGART Bulletin}, 2\penalty0 (4):\penalty0 160--163, 1991.

\bibitem[Sutton \& Barto(1998)Sutton and Barto]{sutton1998introduction}
Sutton, R.~S. and Barto, A.~G.
\newblock \emph{Introduction to reinforcement learning}, volume 135.
\newblock MIT press Cambridge, 1998.

\bibitem[Sutton et~al.(2000)Sutton, McAllester, Singh, and
  Mansour]{sutton2000policy}
Sutton, R.~S., McAllester, D.~A., Singh, S.~P., and Mansour, Y.
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1057--1063, 2000.

\bibitem[Sutton et~al.(2012)Sutton, Szepesv{\'a}ri, Geramifard, and
  Bowling]{sutton2012dyna}
Sutton, R.~S., Szepesv{\'a}ri, C., Geramifard, A., and Bowling, M.~P.
\newblock Dyna-style planning with linear function approximation and
  prioritized sweeping.
\newblock \emph{arXiv preprint arXiv:1206.3285}, 2012.

\bibitem[Tan et~al.(2018)Tan, Zhang, Coumans, Iscen, Bai, Hafner, Bohez, and
  Vanhoucke]{tan2018sim}
Tan, J., Zhang, T., Coumans, E., Iscen, A., Bai, Y., Hafner, D., Bohez, S., and
  Vanhoucke, V.
\newblock Sim-to-real: Learning agile locomotion for quadruped robots.
\newblock In \emph{Robotics: Science and Systems XIV}, 2018.

\bibitem[Tieleman \& Hinton(2012)Tieleman and Hinton]{tieleman2012lecture}
Tieleman, T. and Hinton, G.
\newblock Lecture 6.5-rmsprop: Divide the gradient by a running average of its
  recent magnitude.
\newblock \emph{COURSERA: Neural networks for machine learning}, 4\penalty0
  (2):\penalty0 26--31, 2012.

\bibitem[Todorov \& Li(2005)Todorov and Li]{todorov2005generalized}
Todorov, E. and Li, W.
\newblock A generalized iterative {LQG} method for locally-optimal feedback
  control of constrained nonlinear systems.
\newblock In \emph{American Control Conference}, pp.\  300--306. IEEE, 2005.

\bibitem[Zeiler(2012)]{zeiler2012adadelta}
Zeiler, M.~D.
\newblock Adadelta: an adaptive learning rate method.
\newblock \emph{arXiv preprint arXiv:1212.5701}, 2012.

\bibitem[Zinkevich(2003)]{zinkevich2003online}
Zinkevich, M.
\newblock Online convex programming and generalized infinitesimal gradient
  ascent.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  928--936, 2003.

\end{thebibliography}
