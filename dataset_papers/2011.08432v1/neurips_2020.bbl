\begin{thebibliography}{10}

\bibitem{Rakshit17}
Rakshit Allamraju and Girish Chowdhary.
\newblock Communication efficient decentralized gaussian process fusion for
  multi-uas path planning.
\newblock In {\em American Control Conference}, pages 4442--4447, 05 2017.

\bibitem{Ansell06}
T.~J. {Ansell et al.}
\newblock Daily mean sea level pressure reconstructions for the {European-North
  Atlantic} region for the period $1850$-$2003$.
\newblock {\em J. Climate}, 19(12):2717--2742, 2006.

\bibitem{Musco17}
H.~Avron, M.~Kapralov, C.~Musco, C.~Musco, A.~Velingker, and A.~Zandieh.
\newblock Random fourier features for kernel ridge regression: Approximation
  bounds and statistical guarantees.
\newblock In {\em Proc. ICML}, pages 253--262, 2017.

\bibitem{gas-data}
Javier Burgues.
\newblock {Gas Sensor Array Temperature Modulation Dataset}, howpublished=
  {\url{https://archive.ics.uci.edu/ml/machine-learning-databases/00487/}}.

\bibitem{burgues2018estimation}
Javier Burgu{\'e}s, Juan~Manuel Jim{\'e}nez-Soto, and Santiago Marco.
\newblock Estimation of the limit of detection in semiconductor gas sensors
  through linearized calibration models.
\newblock {\em Analytica chimica acta}, 1013:13--25, 2018.

\bibitem{burgues2018multivariate}
Javier Burgu{\'e}s and Santiago Marco.
\newblock Multivariate estimation of the limit of detection by orthogonal
  partial least squares in temperature-modulated mox sensors.
\newblock {\em Analytica chimica acta}, 1019:49--64, 2018.

\bibitem{LowAAMAS13}
N.~Cao, K.~H. Low, and J.~M. Dolan.
\newblock Multi-robot informative path planning for active sensing of
  environmental phenomena: A tale of two algorithms.
\newblock In {\em Proc. {AAMAS}}, pages 7--14, 2013.

\bibitem{LowUAI13}
J.~Chen, N.~Cao, K.~H. Low, R.~Ouyang, C.~K.-Y. Tan, and P.~Jaillet.
\newblock Parallel {Gaussian} process regression with low-rank covariance
  matrix approximations.
\newblock In {\em Proc. UAI}, pages 152--161, 2013.

\bibitem{LowUAI12}
J.~Chen, K.~H. Low, C.~K.-Y. Tan, A.~Oran, P.~Jaillet, J.~M. Dolan, and G.~S.
  Sukhatme.
\newblock Decentralized data fusion and active sensing with mobile sensors for
  modeling and predicting spatiotemporal traffic phenomena.
\newblock In {\em Proc. UAI}, pages 163--173, 2012.

\bibitem{LowRSS13}
Jie Chen, Kian~Hsiang Low, and Colin Tan.
\newblock Gaussian process-based decentralized data fusion and active sensing
  for mobility-on-demand system.
\newblock {\em Robotics: Science and System}, 06 2013.

\bibitem{Chernoff52}
H.~Chernoff.
\newblock A measure of asymptotic efficiency for tests of hypothesis based on
  the sum of observations.
\newblock {\em Annals of Mathematical Statistics}, 23:493--509, 1952.

\bibitem{LowSPIE09}
J.~M. Dolan, G.~Podnar, S.~Stancliff, K.~H. Low, A.~Elfes, J.~Higinbotham,
  J.~C. Hosler, T.~A. Moisan, and J.~Moisan.
\newblock Cooperative aquatic sensing using the telesupervised adaptive ocean
  sensor fleet.
\newblock In {\em Proc. {SPIE} Conference on Remote Sensing of the Ocean, Sea
  Ice, and Large Water Regions}, volume 7473, 2009.

\bibitem{Yarin14}
Y.~Gal, M.~{van der Wilk}, and C.~Rasmussen.
\newblock Distributed variational inference in sparse {G}aussian process
  regression and latent variable models.
\newblock In {\em Proc. NIPS}, 2014.

\bibitem{Gal15}
Yarin Gal and Richard Turner.
\newblock Improving the gaussian process sparse spectrum approximation by
  representing uncertainty in frequency inputs.
\newblock 2015.

\bibitem{Hensman13}
J.~Hensman, N.~Fusi, and N.~D. Lawrence.
\newblock Gaussian processes for big data.
\newblock In {\em Proc. UAI}, pages 282--290, 2013.

\bibitem{MinhICML2020}
M.~Hoang and C.~Kingsford.
\newblock Optimizing dynamic structures with bayesian generative search.
\newblock In {\em Internation Conference on Machine Learning}, 2020.

\bibitem{NghiaAAAI17}
Q.~M. Hoang, T.~N. Hoang, and K.~H. Low.
\newblock A generalized stochastic variational {B}ayesian hyperparameter
  learning framework for sparse spectrum {G}aussian process regression.
\newblock In {\em Proc. {AAAI}}, pages 2007--2014, 2017.

\bibitem{NghiaICML19a}
Q.~M. Hoang, T.~N. Hoang, K.~H. Low, and C.~Kingsford.
\newblock Collective model fusion for multiple black-box experts.
\newblock In {\em Proc. ICML}, 2019.

\bibitem{NghiaICML15}
T.~N. Hoang, Q.~M. Hoang, and K.~H. Low.
\newblock A unifying framework of anytime sparse {Gaussian} process regression
  models with stochastic variational inference for big data.
\newblock In {\em Proc. {ICML}}, pages 569--578, 2015.

\bibitem{NghiaICML16}
T.~N. Hoang, Q.~M. Hoang, and K.~H. Low.
\newblock A distributed variational inference framework for unifying parallel
  sparse {G}aussian process regression models.
\newblock In {\em Proc. {ICML}}, pages 382--391, 2016.

\bibitem{NghiaAAAI19}
T.~N. Hoang, Q.~M. Hoang, K.~H. Low, and J.~P. How.
\newblock Collective online learning of {G}aussian processes in massive
  multi-agent systems.
\newblock In {\em Proc. {AAAI}}, 2019.

\bibitem{NghiaAAAI18}
T.~N. Hoang, Q.~M. Hoang, O.~Ruofei, and K.~H. Low.
\newblock Decentralized high-dimensional bayesian optimization with factor
  graphs.
\newblock In {\em Proc. AAAI}, 2018.

\bibitem{NghiaICML14}
T.~N. Hoang, K.~H. Low, P.~Jaillet, and M.~Kankanhalli.
\newblock Nonmyopic $\epsilon$-{B}ayes-optimal active learning of {G}aussian
  processes.
\newblock In {\em Proc. ICML}, pages 739--747, 2014.

\bibitem{NghiaECMLKDD14}
T.~N. Hoang, K.~H. Low, P.~Jaillet, and M.~S. Kankanhalli.
\newblock Active learning is planning: Non-myopic $\epsilon$-{B}ayes-optimal
  active learning of {G}aussian processes.
\newblock In {\em Proc. {ECML-PKDD Nectar Track}}, pages 494--498, 2014.

\bibitem{Hoeffding63}
W.~Hoeffding.
\newblock Probability inequalities for the sum of bounded random variables.
\newblock {\em Journal of the American Statistical Association}, 58:13--30,
  1963.

\bibitem{Kingma13}
D.~Kingma and M.~Welling.
\newblock Auto-{E}ncoding {V}ariational {B}ayes.
\newblock In {\em Proc. {ICLR}}, 2013.

\bibitem{Andreas07}
A.~Krause and C.~Guestrin.
\newblock Nonmyopic active learning of {Gaussian} processes: An
  exploration{-}exploitation approach.
\newblock In {\em Proc. ICML}, pages 449--456, 2007.

\bibitem{Miguel10}
M.~{L\'{a}zaro}-Gredilla, J.~{Qui\~{n}onero}-Candela, C.~E. Rasmussen, and
  A.~R. Figueiras-Vidal.
\newblock Sparse spectrum {G}aussian process regression.
\newblock {\em Journal of Machine Learning Research}, pages 1865--1881, 2010.

\bibitem{LowAAAI15}
K.~H. Low, J.~Yu, J.~Chen, and P.~Jaillet.
\newblock Parallel {Gaussian} process regression for big data: Low-rank
  representation meets {M}arkov approximation.
\newblock In {\em Proc. {AAAI}}, pages 2821--2827, 2015.

\bibitem{Yee19}
Emile Mathieu, Tom Rainforth, Siddharth Narayanaswamy, and Yee~Whye Teh.
\newblock Disentangling disentanglement in variational autoencoders.
\newblock In {\em ICML}, 2019.

\bibitem{Mohri18}
Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar.
\newblock {\em Foundations of Machine Learning}.
\newblock MIT press, 2018.

\bibitem{Musco16}
C.~Musco and C.~Musco.
\newblock Recursive sampling for the nystrom method.
\newblock In {\em Proc. NIPS}, 2016.

\bibitem{Candela05}
J.~{Qui\~{n}onero}-Candela and C.~E. Rasmussen.
\newblock A unifying view of sparse approximate {Gaussian} process regression.
\newblock {\em Journal of Machine Learning Research}, 6:1939--1959, 2005.

\bibitem{Candela07}
J.~{Qui\~{n}onero}-Candela, C.~E. Rasmussen, and C.~K.~I. Williams.
\newblock Approximation methods for gaussian process regression.
\newblock {\em Large-Scale Kernel Machines}, pages 203--223, 2007.

\bibitem{Rahimi07}
A.~Rahimi and B.~Recht.
\newblock Random features for large-scale kernel machines.
\newblock In {\em Proc. NIPS}, 2007.

\bibitem{Rasmussen06}
C.~E. Rasmussen and C.~K.~I. Williams.
\newblock {\em Gaussian Processes for Machine Learning}.
\newblock MIT Press, 2006.

\bibitem{Seeger03}
M.~Seeger, C.~K.~I. Williams, and N.~D. Lawrence.
\newblock Fast forward selection to speed up sparse {Gaussian} process
  regression.
\newblock In {\em Proc. AISTATS}, 2003.

\bibitem{Snoek12}
J.~Snoek, L.~Hugo, and R.~P. Adams.
\newblock Practical {B}ayesian optimization of machine learning algorithms.
\newblock In {\em Proc. {NIPS}}, pages 2960--2968, 2012.

\bibitem{Srinivas10}
N.~Srinivas, A.~Krause, S.~Kakade, and M.~Seeger.
\newblock {G}aussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock In {\em Proc. {ICML}}, pages 1015--1022, 2010.

\bibitem{Titsias09}
M.~K. Titsias.
\newblock Variational learning of inducing variables in sparse {G}aussian
  processes.
\newblock In {\em Proc. {AISTATS}}, 2009.

\bibitem{Maaten08}
L.~J.~P. van~der Maaten and G.~E. Hinton.
\newblock Visualizing high-dimensional data using t-sne.
\newblock {\em Journal of Machine Learning Research}, 9:2579--2605, 2008.

\bibitem{abalone}
Sam Waugh.
\newblock {Abalone Dataset}, howpublished=
  {\url{https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/}}.

\bibitem{LowAAAI14}
N.~Xu, K.~H. Low, J.~Chen, K.~K. Lim, and E.~B. {\"{O}zg\"{u}l}.
\newblock {GP-Localize}: Persistent mobile robot localization using online
  sparse {Gaussian} process observation model.
\newblock In {\em Proc. {AAAI}}, pages 2585--2592, 2014.

\bibitem{Yehong16}
Y.~Zhang, T.~N. Hoang, K.~H. Low, and M.~Kankanhalli.
\newblock Near-optimal active learning of multi-output {G}aussian processes.
\newblock In {\em Proc. {AAAI}}, pages 2351--2357, 2016.

\bibitem{Yehong17}
Y.~Zhang, T.~N. Hoang, K.~H. Low, and M.~Kankanhalli.
\newblock Information-based multi-fidelity bayesian optimization.
\newblock In {\em NIPS Workshop BayesOpt}, 2017.

\end{thebibliography}
