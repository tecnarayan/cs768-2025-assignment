\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Dasgupta(2006)]{Sanjoy}
Sanjoy Dasgupta.
\newblock Coarse sample complexity bounds for active learning.
\newblock In \emph{Advances in neural information processing systems}, pages
  235--242, 2006.

\bibitem[Balcan(2013)]{Balcan}
Long~P. Balcan, M.
\newblock Active and passive learning of linear separators under log-concave
  distributions.
\newblock In \emph{Proceedings of the 26th Conference on Learning Theory},
  2013.

\bibitem[Balcan and Zhang(2017)]{s-concave}
Maria-Florina~F Balcan and Hongyang Zhang.
\newblock Sample and computationally efficient learning algorithms under
  s-concave distributions.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4796--4805, 2017.

\bibitem[El-Yaniv and Wiener(2012)]{El-Yaniv}
Ran El-Yaniv and Yair Wiener.
\newblock Active learning via perfect selective classification.
\newblock \emph{Journal of Machine Learning Research}, 13\penalty0
  (Feb):\penalty0 255--279, 2012.

\bibitem[Kane(2017)]{KLMZ}
Lovett S. Moran S. Zhang~J Kane, D.
\newblock Active classification with comparison queries.
\newblock In \emph{IEEE 58th Annual Symposium on Foundations of Computer
  Science}, 2017.

\bibitem[Satzger et~al.(2006)Satzger, Endres, and Kiessling]{rec}
Benjamin Satzger, Markus Endres, and Werner Kiessling.
\newblock A preference-based recommender system.
\newblock In \emph{Proceedings of the 7th International Conference on
  E-Commerce and Web Technologies}, EC-Web'06, pages 31--40, Berlin,
  Heidelberg, 2006. Springer-Verlag.
\newblock ISBN 3-540-37743-3, 978-3-540-37743-6.

\bibitem[Xu et~al.(2017)Xu, Zhang, Miller, Singh, and Dubrawski]{xu2017noise}
Yichong Xu, Hongyang Zhang, Kyle Miller, Aarti Singh, and Artur Dubrawski.
\newblock Noise-tolerant interactive learning using pairwise comparisons.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2431--2440, 2017.

\bibitem[Rivest(1998)]{Rivest}
Sloan~R. Rivest, R.
\newblock Learning complicated concepts reliably and usefully.
\newblock In \emph{Proceedings of the First Workshop on Computational Learning
  Theory}, pages 61--71, 1998.

\bibitem[Chow(1957)]{Chow}
Chi-Keung Chow.
\newblock An optimum character recognition system using decision functions.
\newblock \emph{IRE Transactions on Electronic Computers}, \penalty0
  (4):\penalty0 247--254, 1957.

\bibitem[Kivinen(2014)]{kivinen2014reliable}
Jyrki Kivinen.
\newblock Reliable and useful learning.
\newblock In \emph{Proceedings of the second annual workshop on Computational
  learning theory}, pages 365--380, 2014.

\bibitem[Kivinen(1995)]{Kivinen}
J.~Kivinen.
\newblock Learning reliably and with one-sided error.
\newblock \emph{Mathematical Systems Theory}, 28\penalty0 (2):\penalty0
  141--172, 1995.

\bibitem[Kivinen(1990)]{Kivinen2}
J.~Kivinen.
\newblock Reliable and useful learning with uniform probability distributions.
\newblock In \emph{Proceedings of the First International Workshop on
  Algorithmic Learning Theory}, 1990.

\bibitem[Hopkins et~al.(2020{\natexlab{a}})Hopkins, Kane, Lovett, and
  Mahajan]{hopkins2020noise}
Max Hopkins, Daniel Kane, Shachar Lovett, and Gaurav Mahajan.
\newblock Noise-tolerant, reliable active classification with comparison
  queries.
\newblock \emph{arXiv preprint arXiv:2001.05497}, 2020{\natexlab{a}}.

\bibitem[Valiant(1984)]{Valiant}
L.~Valiant.
\newblock A theory of the learnable.
\newblock \emph{Communications of the ACM}, 27\penalty0 (11):\penalty0
  1134--1142, 1984.

\bibitem[Vapnik and Chervonenkis(1974)]{vapnik1974theory}
Vladimir Vapnik and Alexey Chervonenkis.
\newblock Theory of pattern recognition, 1974.

\bibitem[Vapnik~V.(1971)]{VC}
Chervonenkis~A. Vapnik~V.
\newblock On the uniform convergence of relative frequencies of events to their
  probabilities.
\newblock \emph{Theory of Probability and its Applications}, 16\penalty0
  (2):\penalty0 264--280, 1971.

\bibitem[Blumer et~al.(1989)Blumer, Ehrenfeucht, Haussler, and Warmuth]{Blumer}
Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred~K Warmuth.
\newblock Learnability and the vapnik-chervonenkis dimension.
\newblock \emph{Journal of the ACM (JACM)}, 36\penalty0 (4):\penalty0 929--965,
  1989.

\bibitem[Hanneke(2016)]{hanneke2016optimal}
Steve Hanneke.
\newblock The optimal sample complexity of pac learning.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 1319--1333, 2016.

\bibitem[McCallum(1998)]{pool}
Nigam~K. McCallum, A.
\newblock Employing em and pool-based active learning for text classification.
\newblock In \emph{Proceedings of the Fifteenth International Conference on
  Machine Learning}, 1998.

\bibitem[Angluin(1988)]{angluin1988queries}
Dana Angluin.
\newblock Queries and concept learning.
\newblock \emph{Machine learning}, 2\penalty0 (4):\penalty0 319--342, 1988.

\bibitem[Long(1995)]{Long}
P.~Long.
\newblock On the sample complexity of pac learning halfspaces against the
  uniform distribution.
\newblock \emph{IEEE Transactions on Neural Networks}, 6\penalty0 (6):\penalty0
  1556--1559, 1995.

\bibitem[Long(2003)]{Long2}
P.~Long.
\newblock An upper bound on the sample complexity of pac learning halfspaces
  with respect to the uniform distribution.
\newblock \emph{Information Processing Letters}, 2003.

\bibitem[Hanneke(2014)]{Hanneke}
S.~Hanneke.
\newblock Theory of disagreement-based active learning.
\newblock \emph{Foundations and Trends in Machine Learning}, 7\penalty0
  (2-3):\penalty0 131--309, 2014.

\bibitem[Kane(2018{\natexlab{a}})]{K-sum}
Lovett S. Moran~S. Kane, D.
\newblock Near-optimal linear decision trees for k-sum and related problems.
\newblock In \emph{IEEE 50th Annual Symposium on Theory of Computation},
  2018{\natexlab{a}}.

\bibitem[Hopkins et~al.(2020{\natexlab{b}})Hopkins, Kane, Lovett, and
  Mahajan]{hopkins2020point}
Max Hopkins, Daniel~M Kane, Shachar Lovett, and Gaurav Mahajan.
\newblock Point location and active learning: Learning halfspaces almost
  optimally.
\newblock \emph{arXiv preprint arXiv:2004.11380}, 2020{\natexlab{b}}.

\bibitem[Kane(2018{\natexlab{b}})]{KLM}
Lovett S. Moran~S. Kane, D.
\newblock Generalized comparison trees for point-location problems.
\newblock In \emph{Proceedings of the 45th International Colloquium on
  Automata, Languages and Programming}, 2018{\natexlab{b}}.

\bibitem[Kulkarni et~al.(1993)Kulkarni, Mitter, and Tsitsiklis]{lowerbound}
Sanjeev~R Kulkarni, Sanjoy~K Mitter, and John~N Tsitsiklis.
\newblock Active learning using arbitrary binary valued queries.
\newblock \emph{Machine Learning}, 11\penalty0 (1):\penalty0 23--35, 1993.

\bibitem[Dudley et~al.(2006)Dudley, Kunita, and Ledrappier]{dudley2006ecole}
Richard~M Dudley, Hiroshi Kunita, and Fran{\c{c}}ois Ledrappier.
\newblock \emph{Ecole d'Ete de Probabilites de Saint-Flour XII, 1982}, volume
  1097.
\newblock Springer, 2006.

\bibitem[Yao(1977)]{yao1977probabilistic}
Andrew Chi-Chin Yao.
\newblock Probabilistic computations: Toward a unified measure of complexity.
\newblock In \emph{18th Annual Symposium on Foundations of Computer Science
  (sfcs 1977)}, pages 222--227. IEEE, 1977.

\bibitem[Lovasz(2007)]{log-concave}
Vempala~S. Lovasz, L.
\newblock The geometry of logconcave functions and sampling algorithms.
\newblock \emph{Random Structures and Algorithms}, 2007.

\bibitem[Klivans et~al.(2009)Klivans, Long, and Tang]{Klivans}
Adam~R Klivans, Philip~M Long, and Alex~K Tang.
\newblock Baum’s algorithm learns intersections of halfspaces with respect to
  log-concave distributions.
\newblock In \emph{Approximation, Randomization, and Combinatorial
  Optimization. Algorithms and Techniques}, pages 588--600. Springer, 2009.

\bibitem[Awasthi et~al.(2014)Awasthi, Balcan, and Long]{awasthi2014power}
Pranjal Awasthi, Maria~Florina Balcan, and Philip~M Long.
\newblock The power of localization for efficiently learning linear separators
  with noise.
\newblock In \emph{Proceedings of the forty-sixth annual ACM symposium on
  Theory of computing}, pages 449--458, 2014.

\bibitem[Barany(1994)]{ball}
I.~Barany.
\newblock Random points and lattice points in convex bodies.
\newblock \emph{The Bulletin}, 45\penalty0 (3):\penalty0 339--365, 1994.

\bibitem[Barany(1988)]{ball-MQS}
Furedi~Z. Barany, I.
\newblock Approximation of the sphere by polytopes having few vertices.
\newblock \emph{Proceedings of the American Mathematical Society}, 102\penalty0
  (3):\penalty0 651--659, 1988.

\bibitem[Wieacker(1978)]{Wie}
JA~Wieacker.
\newblock Einige probleme der polyedrischen approximation.
\newblock \emph{Freiburg im Breisgau: Diplomarbeit}, 1978.

\bibitem[B{\'a}r{\'a}ny et~al.(1999)]{label-aid}
Imre B{\'a}r{\'a}ny et~al.
\newblock Sylvester’s question: The probability that $ n $ points are in
  convex position.
\newblock \emph{The annals of probability}, 27\penalty0 (4):\penalty0
  2020--2034, 1999.

\bibitem[Xing et~al.(2003)Xing, Jordan, Russell, and Ng]{Xing}
Eric~P Xing, Michael~I Jordan, Stuart~J Russell, and Andrew~Y Ng.
\newblock Distance metric learning with application to clustering with
  side-information.
\newblock In \emph{Advances in neural information processing systems}, pages
  521--528, 2003.

\bibitem[Schultz and Joachims(2004)]{schultz}
Matthew Schultz and Thorsten Joachims.
\newblock Learning a distance metric from relative comparisons.
\newblock In \emph{Advances in neural information processing systems}, pages
  41--48, 2004.

\bibitem[Agarwal et~al.(2007)Agarwal, Wills, Cayton, Lanckriet, Kriegman, and
  Belongie]{agarwal}
Sameer Agarwal, Josh Wills, Lawrence Cayton, Gert Lanckriet, David Kriegman,
  and Serge Belongie.
\newblock Generalized non-metric multidimensional scaling.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 11--18, 2007.

\bibitem[McFee and Lanckriet(2010)]{mcfee}
Brian McFee and Gert Lanckriet.
\newblock Learning similarity in heterogeneous data.
\newblock In \emph{Proceedings of the international conference on Multimedia
  information retrieval}, pages 243--244. ACM, 2010.

\bibitem[Huang et~al.(2011)Huang, Ying, and Campbell]{huang}
Kaizhu Huang, Yiming Ying, and Colin Campbell.
\newblock Generalized sparse metric learning with relative comparisons.
\newblock \emph{Knowledge and Information Systems}, 28\penalty0 (1):\penalty0
  25--45, 2011.

\bibitem[Tamuz et~al.(2011)Tamuz, Liu, Belongie, Shamir, and Kalai]{tamuz}
Omer Tamuz, Ce~Liu, Serge Belongie, Ohad Shamir, and Adam~Tauman Kalai.
\newblock Adaptively learning the crowd kernel.
\newblock \emph{arXiv preprint arXiv:1105.1033}, 2011.

\bibitem[Qian et~al.(2013)Qian, Wang, Wang, Li, Ye, and Davidson]{qian}
Buyue Qian, Xiang Wang, Fei Wang, Hongfei Li, Jieping Ye, and Ian Davidson.
\newblock Active learning from relative queries.
\newblock In \emph{Twenty-Third International Joint Conference on Artificial
  Intelligence}, 2013.

\bibitem[Awasthi et~al.(2015)Awasthi, Balcan, Haghtalab, and
  Urner]{awasthi2015efficient}
Pranjal Awasthi, Maria-Florina Balcan, Nika Haghtalab, and Ruth Urner.
\newblock Efficient learning of linear separators under bounded noise.
\newblock In \emph{Conference on Learning Theory}, pages 167--190, 2015.

\bibitem[Wang and Singh(2016)]{wang}
Yining Wang and Aarti Singh.
\newblock Noise-adaptive margin-based active learning and lower bounds under
  tsybakov noise condition.
\newblock In \emph{Thirtieth AAAI Conference on Artificial Intelligence}, 2016.

\bibitem[Ramdas and Singh(2013)]{ramdas2013optimal}
Aaditya Ramdas and Aarti Singh.
\newblock Optimal rates for stochastic convex optimization under tsybakov noise
  condition.
\newblock In \emph{International Conference on Machine Learning}, pages
  365--373, 2013.

\bibitem[Xiang(2011)]{xiang2011classification}
DaoHong Xiang.
\newblock Classification with gaussians and convex loss ii: improving error
  bounds by noise conditions.
\newblock \emph{Science China Mathematics}, 54\penalty0 (1):\penalty0 165--171,
  2011.

\bibitem[Awasthi et~al.(2016)Awasthi, Balcan, Haghtalab, and
  Zhang]{awasthi2016learning}
Pranjal Awasthi, Maria-Florina Balcan, Nika Haghtalab, and Hongyang Zhang.
\newblock Learning and 1-bit compressed sensing under asymmetric noise.
\newblock In \emph{Conference on Learning Theory}, pages 152--192, 2016.

\bibitem[Massart et~al.(2006)Massart, N{\'e}d{\'e}lec, et~al.]{massart2006risk}
Pascal Massart, {\'E}lodie N{\'e}d{\'e}lec, et~al.
\newblock Risk bounds for statistical learning.
\newblock \emph{The Annals of Statistics}, 34\penalty0 (5):\penalty0
  2326--2366, 2006.

\bibitem[Tsybakov et~al.(2004)]{tsybakov}
Alexander~B Tsybakov et~al.
\newblock Optimal aggregation of classifiers in statistical learning.
\newblock \emph{The Annals of Statistics}, 32\penalty0 (1):\penalty0 135--166,
  2004.

\bibitem[Castro and Nowak()]{castro2006upper}
Rui~M Castro and Robert~D Nowak.
\newblock Upper and lower error bounds for active learning.

\bibitem[Oliveira and Santhanam(2017)]{circuit}
Igor~Carboni Oliveira and Rahul Santhanam.
\newblock Conspiracies between learning algorithms, circuit lower bounds and
  pseudorandomness.
\newblock 2017.

\end{thebibliography}
