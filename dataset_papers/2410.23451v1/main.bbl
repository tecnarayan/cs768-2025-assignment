\begin{thebibliography}{21}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Banach(1922)]{banach}
Stefan Banach.
\newblock {Sur les op\'erations dans les ensembles abstratits et leur applications aux \'equations int\'egrales}.
\newblock \emph{Fundamenat Mathematicae}, 1\penalty0 (3):\penalty0 133 -- 181, 1922.

\bibitem[Bansal et~al.(2022)Bansal, Schwarzschild, Borgnia, Emam, Huang, Goldblum, and Goldstein]{bansal2022endtoend}
Arpit Bansal, Avi Schwarzschild, Eitan Borgnia, Zeyad Emam, Furong Huang, Micah Goldblum, and Tom Goldstein.
\newblock End-to-end algorithm synthesis with recurrent networks: Extrapolation without overthinking.
\newblock In S.~Koyejo, S.~Mohamed, A.~Agarwal, D.~Belgrave, K.~Cho, and A.~Oh, editors, \emph{Advances in Neural Information Processing Systems}, volume~35, pages 20232--20242. Curran Associates, Inc., 2022.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2022/file/7f70331dbe58ad59d83941dfa7d975aa-Paper-Conference.pdf}.

\bibitem[Ciesielski(2007)]{10.15352/bjma/1240321550}
Krzysztof Ciesielski.
\newblock {On Stefan Banach and some of his results}.
\newblock \emph{Banach Journal of Mathematical Analysis}, 1\penalty0 (1):\penalty0 1 -- 10, 2007.
\newblock \doi{10.15352/bjma/1240321550}.
\newblock URL \url{https://doi.org/10.15352/bjma/1240321550}.

\bibitem[Clevert et~al.(2016)Clevert, Unterthiner, and Hochreiter]{clevert2016elu}
Djork-Arné Clevert, Thomas Unterthiner, and Sepp Hochreiter.
\newblock {Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)}, 2016.
\newblock URL \url{https://arxiv.org/abs/1511.07289}.

\bibitem[Graves(2016)]{DBLP:journals/corr/Graves16}
Alex Graves.
\newblock Adaptive computation time for recurrent neural networks.
\newblock \emph{CoRR}, abs/1603.08983, 2016.
\newblock URL \url{http://arxiv.org/abs/1603.08983}.

\bibitem[Graves et~al.(2014)Graves, Wayne, and Danihelka]{graves2014turing}
Alex Graves, Greg Wayne, and Ivo Danihelka.
\newblock Neural turing machines.
\newblock \emph{CoRR}, abs/1410.5401, 2014.
\newblock URL \url{http://arxiv.org/abs/1410.5401}.

\bibitem[Graves et~al.(2016)Graves, Wayne, Reynolds, Harley, Danihelka, Grabska-Barwi{\'{n}}ska, Colmenarejo, Grefenstette, Ramalho, Agapiou, Badia, Hermann, Zwols, Ostrovski, Cain, King, Summerfield, Blunsom, Kavukcuoglu, and Hassabis]{graves2016neural}
Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-Barwi{\'{n}}ska, Sergio~G{\'o}mez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, Adri{\`a}~Puigdom{\`e}nech Badia, Karl~Moritz Hermann, Yori Zwols, Georg Ostrovski, Adam Cain, Helen King, Christopher Summerfield, Phil Blunsom, Koray Kavukcuoglu, and Demis Hassabis.
\newblock Hybrid computing using a neural network with dynamic external memory.
\newblock \emph{Nature}, 538\penalty0 (7626):\penalty0 471--476, Oct 2016.
\newblock ISSN 1476-4687.
\newblock \doi{10.1038/nature20101}.
\newblock URL \url{https://doi.org/10.1038/nature20101}.

\bibitem[Hendrycks and Gimpel(2016)]{hendrycks2016gelu}
Dan Hendrycks and Kevin Gimpel.
\newblock Bridging nonlinearities and stochastic regularizers with gaussian error linear units.
\newblock \emph{CoRR}, abs/1606.08415, 2016.
\newblock URL \url{http://arxiv.org/abs/1606.08415}.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{NEURIPS2020_4c5bcfec}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin, editors, \emph{Advances in Neural Information Processing Systems}, volume~33, pages 6840--6851. Curran Associates, Inc., 2020.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf}.

\bibitem[Ioffe and Szegedy(2015)]{sergey2015batchnorm}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: accelerating deep network training by reducing internal covariate shift.
\newblock In \emph{Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37}, ICML'15, page 448–456. JMLR.org, 2015.

\bibitem[Jastrzebski et~al.(2018)Jastrzebski, Arpit, Ballas, Verma, Che, and Bengio]{jastrzebski2018residual}
Stanisław Jastrzebski, Devansh Arpit, Nicolas Ballas, Vikas Verma, Tong Che, and Yoshua Bengio.
\newblock Residual connections encourage iterative inference.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=SJa9iHgAZ}.

\bibitem[Kingma and Ba(2015)]{kingma2015adam}
Diederik Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, San Diega, CA, USA, 2015.

\bibitem[Lu et~al.(2020)Lu, Shin, Su, and Karniadakis]{lu2020dying}
Lu~Lu, Yeonjong Shin, Yanhui Su, and George~Em Karniadakis.
\newblock {Dying ReLU and Initialization: Theory and Numerical Examples}.
\newblock \emph{Communications in Computational Physics}, 28\penalty0 (5):\penalty0 1671–1706, June 2020.
\newblock ISSN 1991-7120.
\newblock \doi{10.4208/cicp.oa-2020-0165}.
\newblock URL \url{http://dx.doi.org/10.4208/cicp.OA-2020-0165}.

\bibitem[Mena et~al.(2018)Mena, Belanger, Linderman, and Snoek]{mena2018gumbel}
Gonzalo Mena, David Belanger, Scott Linderman, and Jasper Snoek.
\newblock {Learning Latent Permutations with Gumbel-Sinkhorn Networks}.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=Byt3oJ-0W}.

\bibitem[Miyato et~al.(2018)Miyato, Kataoka, Koyama, and Yoshida]{miyato2018spectral}
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida.
\newblock {Spectral Normalization for Generative Adversarial Networks}.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=B1QRgziT-}.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan, Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison, Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{paszke2019torch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf}.

\bibitem[Schwarzschild et~al.(2021{\natexlab{a}})Schwarzschild, Borgnia, Gupta, Bansal, Emam, Huang, Goldblum, and Goldstein]{schwarzschild2021dataset}
Avi Schwarzschild, Eitan Borgnia, Arjun Gupta, Arpit Bansal, Zeyad Emam, Furong Huang, Micah Goldblum, and Tom Goldstein.
\newblock {Datasets for Studying Generalization from Easy to Hard Examples}.
\newblock \emph{CoRR}, abs/2108.06011, 2021{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2108.06011}.

\bibitem[Schwarzschild et~al.(2021{\natexlab{b}})Schwarzschild, Borgnia, Gupta, Huang, Vishkin, Goldblum, and Goldstein]{schwarzschild2021algorithm}
Avi Schwarzschild, Eitan Borgnia, Arjun Gupta, Furong Huang, Uzi Vishkin, Micah Goldblum, and Tom Goldstein.
\newblock Can you learn an algorithm? generalizing from easy to hard problems with recurrent networks.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman Vaughan, editors, \emph{Advances in Neural Information Processing Systems}, volume~34, pages 6695--6706. Curran Associates, Inc., 2021{\natexlab{b}}.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2021/file/3501672ebc68a5524629080e3ef60aef-Paper.pdf}.

\bibitem[Trottier et~al.(2016)Trottier, Gigu{\`{e}}re, and Chaib{-}draa]{trottier2016pelu}
Ludovic Trottier, Philippe Gigu{\`{e}}re, and Brahim Chaib{-}draa.
\newblock {Parametric Exponential Linear Unit for Deep Convolutional Neural Networks}.
\newblock \emph{CoRR}, abs/1605.09332, 2016.
\newblock URL \url{http://arxiv.org/abs/1605.09332}.

\bibitem[Yoshida and Miyato(2017)]{yoshida2017spectral}
Yuichi Yoshida and Takeru Miyato.
\newblock {Spectral Norm Regularization for Improving the Generalizability of Deep Learning}, 2017.
\newblock URL \url{https://arxiv.org/abs/1705.10941}.

\bibitem[Zhang et~al.(2019)Zhang, Hare, and Prugel-Bennett]{NEURIPS2019_6e79ed05}
Yan Zhang, Jonathon Hare, and Adam Prugel-Bennett.
\newblock Deep set prediction networks.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2019/file/6e79ed05baec2754e25b4eac73a332d2-Paper.pdf}.

\end{thebibliography}
