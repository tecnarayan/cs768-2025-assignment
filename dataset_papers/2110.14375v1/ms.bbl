\begin{thebibliography}{60}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Antol et~al.(2015)Antol, Agrawal, Lu, Mitchell, Batra, Zitnick, and
  Parikh]{VQA}
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra,
  C.~Lawrence Zitnick, and Devi Parikh.
\newblock {VQA}: {V}isual {Q}uestion {A}nswering.
\newblock In \emph{ICCV}, 2015.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{imgnet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, K.~Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{CVPR}, 2009.

\bibitem[Tsung-Yi et~al.(2014)Tsung-Yi, Michael, Serge, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{coco}
Lin Tsung-Yi, Maire Michael, Belongie Serge, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C.~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{ECCV}, 2014.

\bibitem[Nair and Hinton(2010)]{rlu}
Vinod Nair and Geoffrey~E. Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In \emph{ICML}, 2010.

\bibitem[Ioffe and Szegedy(2015)]{batchnorm}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{ICML}, 2015.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, 2016.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{NIPS}, 2017.

\bibitem[Liu and Ziebart(2014)]{classifierRobust}
Anqi Liu and Brian Ziebart.
\newblock Robust classification under sample selection bias.
\newblock In \emph{NIPS}, 2014.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{dropout}
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
  Salakhutdinov.
\newblock Dropout: A simple way to prevent neural networks from overfitting.
\newblock \emph{JMLR}, 2014.

\bibitem[Stock and Cisse(2018)]{adversBias}
Pierre Stock and Moustapha Cisse.
\newblock Convnets and imagenet beyond accuracy: Understanding mistakes and
  uncovering biases.
\newblock In \emph{ECCV}, 2018.

\bibitem[Schwartz et~al.(2019{\natexlab{a}})Schwartz, Schwing, and
  Hazan]{simple-avsd}
Idan Schwartz, Alexander~G. Schwing, and Tamir Hazan.
\newblock A simple baseline for audio-visual scene-aware dialog.
\newblock In \emph{CVPR}, 2019{\natexlab{a}}.

\bibitem[Lecun et~al.(1998)Lecun, Bottou, Bengio, and Haffner]{mnist}
Yann Lecun, LÃ©on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock In \emph{Proceedings of the IEEE}, 1998.

\bibitem[Nene et~al.(1996)Nene, Nayar, and Murase]{coil20}
Sameer~A. Nene, Shree~K. Nayar, and Hiroshi Murase.
\newblock Columbia object image library (coil-20).
\newblock Technical report, Columbia, 1996.

\bibitem[Tjong Kim~Sang and De~Meulder(2003)]{conll2003}
Erik~F. Tjong Kim~Sang and Fien De~Meulder.
\newblock Introduction to the {C}o{NLL}-2003 shared task: Language-independent
  named entity recognition.
\newblock In \emph{NAACL}, 2003.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and Hinton]{alexnet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{NIPS}, 2012.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{inception}
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott~E. Reed,
  Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
\newblock Going deeper with convolutions.
\newblock In \emph{CVPR}, 2015.

\bibitem[Geva et~al.(2019)Geva, Goldberg, and Berant]{Geva2019AreWM}
Mor Geva, Y.~Goldberg, and Jonathan Berant.
\newblock Are we modeling the task or the annotator? an investigation of
  annotator bias in natural language understanding datasets.
\newblock In \emph{EMNLP}, 2019.

\bibitem[Jabri et~al.(2016)Jabri, Joulin, and van~der Maaten]{vqaBias}
Allan Jabri, Armand Joulin, and Laurens van~der Maaten.
\newblock Revisiting visual question answering baselines.
\newblock In \emph{ECCV}, 2016.

\bibitem[Rosenberg et~al.(2021)Rosenberg, Gat, Feder, and Reichart]{acl_rosen}
Daniel Rosenberg, Itai Gat, Amir Feder, and Roi Reichart.
\newblock Are {VQA} systems rad? measuring robustness to augmented data with
  focused interventions.
\newblock In \emph{ACL}, 2021.

\bibitem[Goyal et~al.(2017)Goyal, Khot, Summers{-}Stay, Batra, and
  Parikh]{vqa2}
Yash Goyal, Tejas Khot, Douglas Summers{-}Stay, Dhruv Batra, and Devi Parikh.
\newblock Making the {V} in {VQA} matter: Elevating the role of image
  understanding in {V}isual {Q}uestion {A}nswering.
\newblock In \emph{CVPR}, 2017.

\bibitem[Agrawal et~al.(2018)Agrawal, Batra, Parikh, and Kembhavi]{vqa-cp}
Aishwarya Agrawal, Dhruv Batra, Devi Parikh, and Aniruddha Kembhavi.
\newblock Don't just assume; look and answer: Overcoming priors for visual
  question answering.
\newblock In \emph{CVPR}, 2018.

\bibitem[Alamri et~al.(2019)Alamri, Cartillier, Das, Wang, Cherian, Essa,
  Batra, Marks, Hori, Anderson, Lee, and Parikh]{avsd}
Huda Alamri, Vincent Cartillier, Abhishek Das, Jue Wang, Anoop Cherian, Irfan
  Essa, Dhruv Batra, Tim~K. Marks, Chiori Hori, Peter Anderson, Stefan Lee, and
  Devi Parikh.
\newblock Audio-visual scene-aware dialog.
\newblock In \emph{CVPR}, 2019.

\bibitem[Bowman et~al.(2015)Bowman, Angeli, Potts, and Manning]{snli:emnlp2015}
Samuel~R. Bowman, Gabor Angeli, Christopher Potts, and Christopher~D. Manning.
\newblock A large annotated corpus for learning natural language inference.
\newblock In \emph{EMNLP}, 2015.

\bibitem[Gururangan et~al.(2018)Gururangan, Swayamdipta, Levy, Schwartz,
  Bowman, and Smith]{snliBias}
Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel Bowman,
  and Noah~A. Smith.
\newblock Annotation artifacts in natural language inference data.
\newblock In \emph{NAACL (Short Papers)}, 2018.

\bibitem[Mostafazadeh et~al.(2016)Mostafazadeh, Chambers, He, Parikh, Batra,
  Vanderwende, Kohli, and Allen]{ClozeStory}
Nasrin Mostafazadeh, Nathanael Chambers, Xiaodong He, Devi Parikh, Dhruv Batra,
  Lucy Vanderwende, Pushmeet Kohli, and James Allen.
\newblock A corpus and cloze evaluation for deeper understanding of commonsense
  stories.
\newblock In \emph{NAACL}, 2016.

\bibitem[Schwartz et~al.(2017)Schwartz, Sap, Konstas, Zilles, Choi, and
  Smith]{clozeBias}
Roy Schwartz, Maarten Sap, Ioannis Konstas, Leila Zilles, Yejin Choi, and
  Noah~A. Smith.
\newblock The effect of different writing tasks on linguistic style: A case
  study of the {ROC} story cloze task.
\newblock In \emph{CoNLL}, 2017.

\bibitem[Zadeh et~al.(2019)Zadeh, Chan, Liang, Tong, and
  Morency]{zadeh2019social}
Amir Zadeh, Michael Chan, Paul~Pu Liang, Edmund Tong, and Louis-Philippe
  Morency.
\newblock Social-iq: A question answering benchmark for artificial social
  intelligence.
\newblock In \emph{CVPR}, 2019.

\bibitem[Alvi et~al.(2018)Alvi, Zisserman, and Nell{\aa}ker]{blindEye}
Mohsan~S. Alvi, Andrew Zisserman, and Christoffer Nell{\aa}ker.
\newblock Turning a blind eye: Explicit removal of biases and variation from
  deep neural network embeddings.
\newblock In \emph{ECCV (Workshop)}, 2018.

\bibitem[Bordia and Bowman(2019)]{genderBias}
Shikha Bordia and Samuel~R. Bowman.
\newblock Identifying and reducing gender bias in word-level language models.
\newblock In \emph{NAACL (Workshop)}, 2019.

\bibitem[Davidson et~al.(2019)Davidson, Bhattacharya, and Weber]{raceBias}
Thomas Davidson, Debasmita Bhattacharya, and Ingmar Weber.
\newblock Racial bias in hate speech and abusive language detection datasets.
\newblock In \emph{ACL}, 2019.

\bibitem[Hendricks et~al.(2018)Hendricks, Burns, Saenko, Darrell, and
  Rohrbach]{WomenSnowboard}
Lisa~Anne Hendricks, Kaylee Burns, Kate Saenko, Trevor Darrell, and Anna
  Rohrbach.
\newblock Women also snowboard: Overcoming bias in captioning models.
\newblock In \emph{ECCV}, 2018.

\bibitem[Jacques et~al.(2019)Jacques, Ozcinar, Marjanovic, Bar{\'o},
  Anbarjafari, and Escalera]{AgeBiasV}
Julio Cezar~Silveira Jacques, Cagri Ozcinar, Marina Marjanovic, Xavier
  Bar{\'o}, Gholamreza Anbarjafari, and Sergio Escalera.
\newblock On the effect of age perception biases for real age regression.
\newblock \emph{FG 2019}, 2019.

\bibitem[K{\"a}rkk{\"a}inen and Joo(2019)]{FairFace}
Kimmo K{\"a}rkk{\"a}inen and Jungseock Joo.
\newblock Fairface: Face attribute dataset for balanced race, gender, and age,
  2019.
\newblock URL \url{https://arxiv.org/pdf/1908.04913.pdf}.

\bibitem[Kim et~al.(2018{\natexlab{a}})Kim, Kim, Kim, Kim, and
  Kim]{learningNotToLearn}
Byungju Kim, Hyunwoo Kim, Kyungsu Kim, Sungjin Kim, and Junmo Kim.
\newblock Learning not to learn: Training deep neural networks with biased
  data.
\newblock In \emph{CVPR}, 2018{\natexlab{a}}.

\bibitem[Wang et~al.(2019)Wang, Zhao, Yatskar, Chang, and
  Ordonez]{genderBiasVision}
Tianlu Wang, Jieyu Zhao, Mark Yatskar, Kai-Wei Chang, and Vicente Ordonez.
\newblock Balanced datasets are not enough: Estimating and mitigating gender
  bias in deep image representations.
\newblock In \emph{ICCV}, 2019.

\bibitem[Zhao et~al.(2018)Zhao, Wang, Yatskar, Ordonez, and
  Chang]{zhao-etal-2018-gender}
Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang.
\newblock Gender bias in coreference resolution: Evaluation and debiasing
  methods.
\newblock In \emph{NAACL}, 2018.

\bibitem[Zmigrod et~al.(2019)Zmigrod, Mielke, Wallach, and
  Cotterell]{zmigrod-etal-2019-counterfactual}
Ran Zmigrod, Sabrina~J. Mielke, Hanna Wallach, and Ryan Cotterell.
\newblock Counterfactual data augmentation for mitigating gender stereotypes in
  languages with rich morphology.
\newblock In \emph{ACL}, 2019.

\bibitem[Zhao et~al.(2017)Zhao, Wang, Yatskar, Ordonez, and Chang]{MenShopping}
Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang.
\newblock Men also like shopping: Reducing gender bias amplification using
  corpus-level constraints.
\newblock In \emph{EMNLP}, 2017.

\bibitem[Cadene et~al.(2019)Cadene, Dancette, Cord, Parikh, et~al.]{rubi}
Remi Cadene, Corentin Dancette, Matthieu Cord, Devi Parikh, et~al.
\newblock Rubi: Reducing unimodal biases for visual question answering.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Clark et~al.(2019)Clark, Yatskar, and Zettlemoyer]{ensemble}
Christopher Clark, Mark Yatskar, and Luke Zettlemoyer.
\newblock Don{'}t take the easy way out: Ensemble based methods for avoiding
  known dataset biases.
\newblock In \emph{EMNLP}, 2019.

\bibitem[Gat et~al.(2020)Gat, Schwartz, Schwing, and Hazan]{removing}
Itai Gat, Idan Schwartz, Alexander Schwing, and Tamir Hazan.
\newblock Removing bias in multi-modal classifiers: Regularization by
  maximizing functional entropies.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Ramakrishnan et~al.(2018)Ramakrishnan, Agrawal, and Lee]{overcoming}
Sainandan Ramakrishnan, Aishwarya Agrawal, and Stefan Lee.
\newblock Overcoming language priors in visual question answering with
  adversarial regularization.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Hinton(2002)]{poe}
Geoffrey~E Hinton.
\newblock Training products of experts by minimizing contrastive divergence.
\newblock \emph{Neural computation}, 2002.

\bibitem[Ribeiro et~al.(2016)Ribeiro, Singh, and Guestrin]{lime}
Marco~Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.
\newblock Why should {I} trust you?: Explaining the predictions of any
  classifier.
\newblock In \emph{SIGKDD}, 2016.

\bibitem[Shrikumar et~al.(2017)Shrikumar, Greenside, and Kundaje]{deeplift}
Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje.
\newblock Learning important features through propagating activation
  differences.
\newblock In \emph{ICML}, 2017.

\bibitem[Lundberg and Lee(2017)]{shap}
Scott~M Lundberg and Su-In Lee.
\newblock A unified approach to interpreting model predictions.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Hessel and Lee(2020)]{hessel2020emap}
Jack Hessel and Lillian Lee.
\newblock Does my multimodal model learn cross-modal interactions? it's harder
  to tell than you might think!
\newblock In \emph{EMNLP}, 2020.

\bibitem[Anderson et~al.(2018)Anderson, He, Buehler, Teney, Johnson, Gould, and
  Zhang]{butd}
Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen
  Gould, and Lei Zhang.
\newblock Bottom-up and top-down attention for image captioning and visual
  question answering.
\newblock In \emph{CVPR}, 2018.

\bibitem[Krishna et~al.(2017)Krishna, Zhu, Groth, Johnson, Hata, Kravitz, Chen,
  Kalantidis, Li, Shamma, Bernstein, and Fei-Fei]{krishnavisualgenome}
Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua
  Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David~A Shamma,
  Michael Bernstein, and Li~Fei-Fei.
\newblock Visual genome: Connecting language and vision using crowdsourced
  dense image annotations.
\newblock \emph{International journal of computer vision}, 2017.

\bibitem[Kim et~al.(2018{\natexlab{b}})Kim, Jun, and Zhang]{ban}
Jin-Hwa Kim, Jaehyun Jun, and Byoung-Tak Zhang.
\newblock Bilinear attention networks.
\newblock In \emph{NeurIPS}, 2018{\natexlab{b}}.

\bibitem[Tan and Bansal(2019)]{tan2019lxmert}
Hao Tan and Mohit Bansal.
\newblock Lxmert: Learning cross-modality encoder representations from
  transformers.
\newblock \emph{EMNLP}, 2019.

\bibitem[Chen et~al.(2020)Chen, Yan, Xiao, Zhang, Pu, and
  Zhuang]{chen2020counterfactual}
Long Chen, Xin Yan, Jun Xiao, Hanwang Zhang, Shiliang Pu, and Yueting Zhuang.
\newblock Counterfactual samples synthesizing for robust visual question
  answering.
\newblock In \emph{CVPR}, 2020.

\bibitem[Schwartz et~al.(2019{\natexlab{b}})Schwartz, Yu, Hazan, and
  Schwing]{fga}
Idan Schwartz, Seunghak Yu, Tamir Hazan, and Alexander~G. Schwing.
\newblock Factor graph attention.
\newblock In \emph{CVPR}, 2019{\natexlab{b}}.

\bibitem[Pennington et~al.(2014)Pennington, Socher, and Manning]{glove}
Jeffrey Pennington, Richard Socher, and Christopher~D. Manning.
\newblock Glove: Global vectors for word representation.
\newblock In \emph{EMNLP}, 2014.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{NAACL}, 2019.

\bibitem[Loper and Bird(2004)]{nltk}
Edward Loper and Steven Bird.
\newblock Nltk: The natural language toolkit.
\newblock In \emph{ACL}, 2004.

\bibitem[Das et~al.(2017)Das, Kottur, Gupta, Singh, Yadav, Moura, Parikh, and
  Batra]{visdial}
Abhishek Das, Satwik Kottur, Khushi Gupta, Avi Singh, Deshraj Yadav,
  Jos{\'e}~MF Moura, Devi Parikh, and Dhruv Batra.
\newblock Visual dialog.
\newblock In \emph{CVPR}, 2017.

\bibitem[Murahari et~al.(2020)Murahari, Batra, Parikh, and
  Das]{murahari2019large}
Vishvak Murahari, Dhruv Batra, Devi Parikh, and Abhishek Das.
\newblock Large-scale pretraining for visual dialog: A simple state-of-the-art
  baseline.
\newblock \emph{ECCV}, 2020.

\bibitem[Sharma et~al.(2018)Sharma, Ding, Goodman, and
  Soricut]{sharma2018conceptual}
Piyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut.
\newblock Conceptual captions: A cleaned, hypernymed, image alt-text dataset
  for automatic image captioning.
\newblock In \emph{ACL}, 2018.

\bibitem[Di et~al.(2020)Di, Mou, Wang, Gao, Hua, Dou, and Zhu]{ambient}
Hu~Di, Lichao Mou, Qingzhong Wang, Junyu Gao, Yuansheng Hua, Dejing Dou, and
  Xiao Zhu.
\newblock Ambient sound helps: Audiovisual crowd counting in extreme
  conditions.
\newblock In \emph{CVPR}, 2020.

\end{thebibliography}
