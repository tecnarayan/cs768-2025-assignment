\begin{thebibliography}{10}

\bibitem{graves2013generating}
Alex Graves.
\newblock Generating sequences with recurrent neural networks.
\newblock {\em arXiv preprint arXiv:1308.0850}, 2013.

\bibitem{uria2016neural}
Benigno Uria, Marc-Alexandre C{\^o}t{\'e}, Karol Gregor, Iain Murray, and Hugo
  Larochelle.
\newblock Neural autoregressive distribution estimation.
\newblock {\em The Journal of Machine Learning Research}, 17(1):7184--7220,
  2016.

\bibitem{flunkert2017deepar}
Valentin Flunkert, David Salinas, and Jan Gasthaus.
\newblock Deepar: Probabilistic forecasting with autoregressive recurrent
  networks.
\newblock {\em arXiv preprint arXiv:1704.04110}, 2017.

\bibitem{chen2017pixelsnail}
Xi~Chen, Nikhil Mishra, Mostafa Rohaninejad, and Pieter Abbeel.
\newblock Pixelsnail: An improved autoregressive generative model.
\newblock {\em arXiv preprint arXiv:1712.09763}, 2017.

\bibitem{parmar2018image}
Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, {\L}ukasz Kaiser, Noam Shazeer,
  and Alexander Ku.
\newblock Image transformer.
\newblock {\em arXiv preprint arXiv:1802.05751}, 2018.

\bibitem{dai2019transformer}
Zihang Dai, Zhilin Yang, Yiming Yang, William~W Cohen, Jaime Carbonell, Quoc~V
  Le, and Ruslan Salakhutdinov.
\newblock Transformer-xl: Attentive language models beyond a fixed-length
  context.
\newblock {\em arXiv preprint arXiv:1901.02860}, 2019.

\bibitem{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock {\em arXiv preprint arXiv:1401.4082}, 2014.

\bibitem{bayer2014learning}
Justin Bayer and Christian Osendorfer.
\newblock Learning stochastic recurrent networks.
\newblock {\em arXiv preprint arXiv:1411.7610}, 2014.

\bibitem{chung2015recurrent}
Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron~C Courville,
  and Yoshua Bengio.
\newblock A recurrent latent variable model for sequential data.
\newblock In {\em Advances in neural information processing systems}, pages
  2980--2988, 2015.

\bibitem{fraccaro2016sequential}
Marco Fraccaro, S{\o}ren~Kaae S{\o}nderby, Ulrich Paquet, and Ole Winther.
\newblock Sequential neural models with stochastic layers.
\newblock In {\em Advances in neural information processing systems}, pages
  2199--2207, 2016.

\bibitem{goyal2017z}
Anirudh Goyal Alias~Parth Goyal, Alessandro Sordoni, Marc-Alexandre
  C{\^o}t{\'e}, Nan~Rosemary Ke, and Yoshua Bengio.
\newblock Z-forcing: Training stochastic recurrent networks.
\newblock In {\em Advances in neural information processing systems}, pages
  6713--6723, 2017.

\bibitem{lai2018stochastic}
Guokun Lai, Bohan Li, Guoqing Zheng, and Yiming Yang.
\newblock Stochastic wavenet: A generative latent variable model for sequential
  data.
\newblock {\em arXiv preprint arXiv:1806.06116}, 2018.

\bibitem{aksan2019stcn}
Emre Aksan and Otmar Hilliges.
\newblock Stcn: Stochastic temporal convolutional networks.
\newblock {\em arXiv preprint arXiv:1902.06568}, 2019.

\bibitem{oord2016pixel}
Aaron van~den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu.
\newblock Pixel recurrent neural networks.
\newblock {\em arXiv preprint arXiv:1601.06759}, 2016.

\bibitem{van2016conditional}
Aaron van~den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex
  Graves, et~al.
\newblock Conditional image generation with pixelcnn decoders.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4790--4798, 2016.

\bibitem{salimans2017pixelcnn++}
Tim Salimans, Andrej Karpathy, Xi~Chen, and Diederik~P Kingma.
\newblock Pixelcnn++: Improving the pixelcnn with discretized logistic mixture
  likelihood and other modifications.
\newblock {\em arXiv preprint arXiv:1701.05517}, 2017.

\bibitem{gregor2015draw}
Karol Gregor, Ivo Danihelka, Alex Graves, Danilo~Jimenez Rezende, and Daan
  Wierstra.
\newblock Draw: A recurrent neural network for image generation.
\newblock {\em arXiv preprint arXiv:1502.04623}, 2015.

\bibitem{gregor2016towards}
Karol Gregor, Frederic Besse, Danilo~Jimenez Rezende, Ivo Danihelka, and Daan
  Wierstra.
\newblock Towards conceptual compression.
\newblock In {\em Advances In Neural Information Processing Systems}, pages
  3549--3557, 2016.

\bibitem{rezende2015variational}
Danilo~Jimenez Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock {\em arXiv preprint arXiv:1505.05770}, 2015.

\bibitem{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real nvp.
\newblock {\em arXiv preprint arXiv:1605.08803}, 2016.

\bibitem{kingma2016improved}
Durk~P Kingma, Tim Salimans, Rafal Jozefowicz, Xi~Chen, Ilya Sutskever, and Max
  Welling.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock In {\em Advances in neural information processing systems}, pages
  4743--4751, 2016.

\bibitem{boulanger2012modeling}
Nicolas Boulanger-Lewandowski, Yoshua Bengio, and Pascal Vincent.
\newblock Modeling temporal dependencies in high-dimensional sequences:
  Application to polyphonic music generation and transcription.
\newblock {\em arXiv preprint arXiv:1206.6392}, 2012.

\bibitem{germain2015made}
Mathieu Germain, Karol Gregor, Iain Murray, and Hugo Larochelle.
\newblock Made: Masked autoencoder for distribution estimation.
\newblock In {\em International Conference on Machine Learning}, pages
  881--889, 2015.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{loshchilov2016sgdr}
Ilya Loshchilov and Frank Hutter.
\newblock Sgdr: Stochastic gradient descent with warm restarts.
\newblock {\em arXiv preprint arXiv:1608.03983}, 2016.

\bibitem{roweis1999unifying}
Sam Roweis and Zoubin Ghahramani.
\newblock A unifying review of linear gaussian models.
\newblock {\em Neural computation}, 11(2):305--345, 1999.

\bibitem{rabiner1986introduction}
Lawrence~R Rabiner and Biing-Hwang Juang.
\newblock An introduction to hidden markov models.
\newblock {\em ieee assp magazine}, 3(1):4--16, 1986.

\bibitem{kalman1960new}
Rudolph~Emil Kalman.
\newblock A new approach to linear filtering and prediction problems.
\newblock {\em Journal of basic Engineering}, 82(1):35--45, 1960.

\bibitem{sutskever2009recurrent}
Ilya Sutskever, Geoffrey~E Hinton, and Graham~W Taylor.
\newblock The recurrent temporal restricted boltzmann machine.
\newblock In {\em Advances in neural information processing systems}, pages
  1601--1608, 2009.

\bibitem{gan2015deep}
Zhe Gan, Chunyuan Li, Ricardo Henao, David~E Carlson, and Lawrence Carin.
\newblock Deep temporal sigmoid belief networks for sequence modeling.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2467--2475, 2015.

\bibitem{krishnan2015deep}
Rahul~G Krishnan, Uri Shalit, and David Sontag.
\newblock Deep kalman filters.
\newblock {\em arXiv preprint arXiv:1511.05121}, 2015.

\bibitem{krishnan2017structured}
Rahul~G Krishnan, Uri Shalit, and David Sontag.
\newblock Structured inference networks for nonlinear state space models.
\newblock In {\em AAAI}, pages 2101--2109, 2017.

\bibitem{fraccaro2017disentangled}
Marco Fraccaro, Simon Kamronn, Ulrich Paquet, and Ole Winther.
\newblock A disentangled recognition and nonlinear dynamics model for
  unsupervised learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3601--3610, 2017.

\bibitem{johnson2016composing}
Matthew Johnson, David~K Duvenaud, Alex Wiltschko, Ryan~P Adams, and Sandeep~R
  Datta.
\newblock Composing graphical models with neural networks for structured
  representations and fast inference.
\newblock In {\em Advances in neural information processing systems}, pages
  2946--2954, 2016.

\end{thebibliography}
