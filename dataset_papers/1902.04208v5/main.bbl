\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bowman et~al.(2015)Bowman, Vilnis, Vinyals, Dai, Jozefowicz, and
  Bengio]{bowman2015generating}
Samuel~R Bowman, Luke Vilnis, Oriol Vinyals, Andrew~M Dai, Rafal Jozefowicz,
  and Samy Bengio.
\newblock Generating sentences from a continuous space.
\newblock \emph{arXiv preprint arXiv:1511.06349}, 2015.

\bibitem[Brock et~al.(2019)Brock, Donahue, and Simonyan]{brock2018large}
Andrew Brock, Jeff Donahue, and Karen Simonyan.
\newblock Large scale gan training for high fidelity natural image synthesis.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Chen et~al.(2017)Chen, Mishra, Rohaninejad, and
  Abbeel]{chen2017pixelsnail}
Xi~Chen, Nikhil Mishra, Mostafa Rohaninejad, and Pieter Abbeel.
\newblock Pixelsnail: An improved autoregressive generative model.
\newblock \emph{arXiv preprint arXiv:1712.09763}, 2017.

\bibitem[Clevert et~al.(2015)Clevert, Unterthiner, and
  Hochreiter]{clevert2015elu}
Djork-Arn{\'e} Clevert, Thomas Unterthiner, and Sepp Hochreiter.
\newblock Fast and accurate deep network learning by exponential linear units
  (elus).
\newblock \emph{arXiv preprint arXiv:1511.07289}, 2015.

\bibitem[Dinh et~al.(2014)Dinh, Krueger, and Bengio]{dinh2014nice}
Laurent Dinh, David Krueger, and Yoshua Bengio.
\newblock Nice: Non-linear independent components estimation.
\newblock \emph{arXiv preprint arXiv:1410.8516}, 2014.

\bibitem[Dinh et~al.(2016)Dinh, Sohl-Dickstein, and Bengio]{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real nvp.
\newblock \emph{arXiv preprint arXiv:1605.08803}, 2016.

\bibitem[Germain et~al.(2015)Germain, Gregor, Murray, and
  Larochelle]{germain2015made}
Mathieu Germain, Karol Gregor, Iain Murray, and Hugo Larochelle.
\newblock Made: Masked autoencoder for distribution estimation.
\newblock In \emph{International Conference on Machine Learning}, pages
  881--889, 2015.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems
  (NIPS-2014)}, pages 2672--2680, 2014.

\bibitem[Ho et~al.(2019)Ho, Chen, Srinivas, Duan, and Abbeel]{ho2019flow++}
Jonathan Ho, Xi~Chen, Aravind Srinivas, Yan Duan, and Pieter Abbeel.
\newblock Flow++: Improving flow-based generative models with variational
  dequantization and architecture design.
\newblock In \emph{International Conference on Machine Learning}, pages
  2722--2730, 2019.

\bibitem[Hoogeboom et~al.(2019)Hoogeboom, Van Den~Berg, and
  Welling]{hoogeboom2019emerging}
Emiel Hoogeboom, Rianne Van Den~Berg, and Max Welling.
\newblock Emerging convolutions for generative normalizing flows.
\newblock In \emph{International Conference on Machine Learning}, pages
  2771--2780, 2019.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{International Conference on Machine Learning}, pages
  448--456, 2015.

\bibitem[Karras et~al.(2018)Karras, Aila, Laine, and
  Lehtinen]{karras2017progressive}
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
\newblock Progressive growing of gans for improved quality, stability, and
  variation.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma and Welling(2014)]{kingma2014auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock In \emph{Proceedings of the 2th International Conference on Learning
  Representations (ICLR-2014)}, Banff, Canada, April 2014.

\bibitem[Kingma et~al.(2016)Kingma, Salimans, Jozefowicz, Chen, Sutskever, and
  Welling]{kingma2016improved}
Diederik~P Kingma, Tim Salimans, Rafal Jozefowicz, Xi~Chen, Ilya Sutskever, and
  Max Welling.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4743--4751, 2016.

\bibitem[Kingma and Dhariwal(2018)]{kingma2018glow}
Durk~P Kingma and Prafulla Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  10236--10245, 2018.

\bibitem[Krizhevsky and Hinton(2009)]{krizhevsky2009learning}
Alex Krizhevsky and Geoffrey Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, Citeseer, 2009.

\bibitem[Larochelle and Murray(2011)]{larochelle2011neural}
Hugo Larochelle and Iain Murray.
\newblock The neural autoregressive distribution estimator.
\newblock In \emph{Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics (AISTATS-2011}, pages 29--37, 2011.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{liu2015faceattributes}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{Proceedings of International Conference on Computer Vision
  (ICCV)}, pages 3730--3738, 2015.

\bibitem[Ma et~al.(2019)Ma, Zhou, and Hovy]{ma2019mae}
Xuezhe Ma, Chunting Zhou, and Eduard Hovy.
\newblock {MAE}: Mutual posterior-divergence regularization for variational
  autoencoders.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Menick and Kalchbrenner(2019)]{menick2018generating}
Jacob Menick and Nal Kalchbrenner.
\newblock Generating high fidelity images with subscale pixel networks and
  multidimensional upscaling, 2019.

\bibitem[Oord et~al.(2016)Oord, Kalchbrenner, and Kavukcuoglu]{oord2016pixel}
Aaron van~den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu.
\newblock Pixel recurrent neural networks.
\newblock In \emph{Proceedings of International Conference on Machine Learning
  (ICML-2016)}, 2016.

\bibitem[Papamakarios et~al.(2017)Papamakarios, Pavlakou, and
  Murray]{papamakarios2017masked}
George Papamakarios, Theo Pavlakou, and Iain Murray.
\newblock Masked autoregressive flow for density estimation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2338--2347, 2017.

\bibitem[Parmar et~al.(2018)Parmar, Vaswani, Uszkoreit, Kaiser, Shazeer, and
  Ku]{parmar2018image}
Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, {\L}ukasz Kaiser, Noam Shazeer,
  and Alexander Ku.
\newblock Image transformer.
\newblock \emph{arXiv preprint arXiv:1802.05751}, 2018.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in {PyTorch}.
\newblock In \emph{NIPS Autodiff Workshop}, 2017.

\bibitem[Prenger et~al.(2018)Prenger, Valle, and
  Catanzaro]{prenger2018waveglow}
Ryan Prenger, Rafael Valle, and Bryan Catanzaro.
\newblock Waveglow: A flow-based generative network for speech synthesis.
\newblock \emph{arXiv preprint arXiv:1811.00002}, 2018.

\bibitem[Radford et~al.(2015)Radford, Metz, and
  Chintala]{radford2015unsupervised}
Alec Radford, Luke Metz, and Soumith Chintala.
\newblock Unsupervised representation learning with deep convolutional
  generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1511.06434}, 2015.

\bibitem[Reed et~al.(2017)Reed, Oord, Kalchbrenner, Colmenarejo, Wang, Chen,
  Belov, and Freitas]{reed2017parallel}
Scott Reed, A{\"a}ron Oord, Nal Kalchbrenner, Sergio~G{\'o}mez Colmenarejo,
  Ziyu Wang, Yutian Chen, Dan Belov, and Nando Freitas.
\newblock Parallel multiscale autoregressive density estimation.
\newblock In \emph{International Conference on Machine Learning}, pages
  2912--2921, 2017.

\bibitem[Rezende and Mohamed(2015)]{rezende2015variational}
Danilo~Jimenez Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock \emph{arXiv preprint arXiv:1505.05770}, 2015.

\bibitem[Salimans et~al.(2017)Salimans, Karpathy, Chen, Kingma, and
  Bulatov]{salimans2017pixelcnn++}
Tim Salimans, Andrej Karpathy, Xi~Chen, Diederik~P Kingma, and Yaroslav
  Bulatov.
\newblock Pixelcnn++: A pixelcnn implementation with discretized logistic
  mixture likelihood and other modifications.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2017.

\bibitem[Theis et~al.(2016)Theis, van~den Oord, and Bethge]{theis2016note}
L~Theis, A~van~den Oord, and M~Bethge.
\newblock A note on the evaluation of generative models.
\newblock In \emph{International Conference on Learning Representations (ICLR
  2016)}, pages 1--10, 2016.

\bibitem[Uria et~al.(2013)Uria, Murray, and Larochelle]{uria2013rnade}
Benigno Uria, Iain Murray, and Hugo Larochelle.
\newblock Rnade: The real-valued neural autoregressive density-estimator.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2175--2183, 2013.

\bibitem[Van Den~Oord et~al.(2016)Van Den~Oord, Dieleman, Zen, Simonyan,
  Vinyals, Graves, Kalchbrenner, Senior, and Kavukcuoglu]{van2016wavenet}
A{\"a}ron Van Den~Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol
  Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu.
\newblock Wavenet: A generative model for raw audio.
\newblock 2016.

\bibitem[van~den Oord et~al.(2016)van~den Oord, Kalchbrenner, Espeholt,
  Vinyals, Graves, et~al.]{van2016conditional}
Aaron van~den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex
  Graves, et~al.
\newblock Conditional image generation with pixelcnn decoders.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4790--4798, 2016.

\bibitem[Yu et~al.(2015)Yu, Zhang, Song, Seff, and Xiao]{yu15lsun}
Fisher Yu, Yinda Zhang, Shuran Song, Ari Seff, and Jianxiong Xiao.
\newblock Lsun: Construction of a large-scale image dataset using deep learning
  with humans in the loop.
\newblock \emph{arXiv preprint arXiv:1506.03365}, 2015.

\bibitem[Zheng et~al.(2017)Zheng, Yang, and Carbonell]{zheng2017}
Guoqing Zheng, Yiming Yang, and Jaime~G. Carbonell.
\newblock Convolutional normalizing flows.
\newblock \emph{CoRR}, abs/1711.02255, 2017.

\bibitem[Ziegler and Rush(2019)]{ziegler2019latent}
Zachary~M Ziegler and Alexander~M Rush.
\newblock Latent normalizing flows for discrete sequences.
\newblock In \emph{Proceedings of International Conference on Machine Learning
  (ICML-2019)}, 2019.

\end{thebibliography}
