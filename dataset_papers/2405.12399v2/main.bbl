\begin{thebibliography}{}

\bibitem[Agarwal et~al., 2021]{agarwal2021deep}
Agarwal, R., Schwarzer, M., Castro, P.~S., Courville, A.~C., and Bellemare, M. (2021).
\newblock Deep reinforcement learning at the edge of the statistical precipice.
\newblock {\em Advances in Neural Information Processing Systems}, 34:29304--29320.

\bibitem[Ajay et~al., 2022]{ajay2022conditional}
Ajay, A., Du, Y., Gupta, A., Tenenbaum, J., Jaakkola, T., and Agrawal, P. (2022).
\newblock Is conditional generative modeling all you need for decision-making?
\newblock {\em International Conference on Learning Representations}.

\bibitem[Alonso et~al., 2023]{alonso2023diffusion}
Alonso, E., Jelley, A., Kanervisto, A., and Pearce, T. (2023).
\newblock Diffusion world models.
\newblock {\em OpenReview}.

\bibitem[Anderson, 1982]{anderson1982reverse}
Anderson, B.~D. (1982).
\newblock Reverse-time diffusion equation models.
\newblock {\em Stochastic Processes and their Applications}, 12(3):313--326.

\bibitem[Ascher and Petzold, 1998]{ascher1998computer}
Ascher, U.~M. and Petzold, L.~R. (1998).
\newblock {\em Computer methods for ordinary differential equations and differential-algebraic equations}.
\newblock Society for Industrial and Applied Mathematics.

\bibitem[Bamford and Lucas, 2020]{bamford2020neural}
Bamford, C. and Lucas, S.~M. (2020).
\newblock Neural game engine: Accurate learning of generalizable forward models from pixels.
\newblock In {\em 2020 IEEE Conference on Games (CoG)}, pages 81--88. IEEE.

\bibitem[Bar-Tal et~al., 2024]{bar2024lumiere}
Bar-Tal, O., Chefer, H., Tov, O., Herrmann, C., Paiss, R., Zada, S., Ephrat, A., Hur, J., Li, Y., Michaeli, T., et~al. (2024).
\newblock Lumiere: A space-time diffusion model for video generation.
\newblock {\em arXiv preprint arXiv:2401.12945}.

\bibitem[Brooks et~al., 2024]{sora2024}
Brooks, T., Peebles, B., Holmes, C., DePue, W., Guo, Y., Jing, L., Schnurr, D., Taylor, J., Luhman, T., Luhman, E., Ng, C., Wang, R., and Ramesh, A. (2024).
\newblock Video generation models as world simulators.

\bibitem[Bruce et~al., 2024]{bruce2024genie}
Bruce, J., Dennis, M.~D., Edwards, A., Parker-Holder, J., Shi, Y., Hughes, E., Lai, M., Mavalankar, A., Steigerwald, R., Apps, C., et~al. (2024).
\newblock Genie: Generative interactive environments.
\newblock In {\em Forty-first International Conference on Machine Learning}.

\bibitem[Chang et~al., 2023]{muse2023}
Chang, H., Zhang, H., Barber, J., Maschinot, A., Lezama, J., Jiang, L., Yang, M.-H., Murphy, K.~P., Freeman, W.~T., Rubinstein, M., Li, Y., and Krishnan, D. (2023).
\newblock Muse: Text-to-image generation via masked generative transformers.
\newblock In {\em International Conference on Machine Learning}, pages 4055--4075. PMLR.

\bibitem[Chang et~al., 2022]{chang2022maskgit}
Chang, H., Zhang, H., Jiang, L., Liu, C., and Freeman, W.~T. (2022).
\newblock Maskgit: Masked generative image transformer.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 11315--11325.

\bibitem[{\c{C}}i{\c{c}}ek et~al., 2016]{unet3d}
{\c{C}}i{\c{c}}ek, {\"O}., Abdulkadir, A., Lienkamp, S.~S., Brox, T., and Ronneberger, O. (2016).
\newblock 3d u-net: learning dense volumetric segmentation from sparse annotation.
\newblock In {\em Medical Image Computing and Computer-Assisted Intervention--MICCAI 2016: 19th International Conference, Athens, Greece, October 17-21, 2016, Proceedings, Part II 19}, pages 424--432. Springer.

\bibitem[Degrave et~al., 2022]{degrave2022magnetic}
Degrave, J., Felici, F., Buchli, J., Neunert, M., Tracey, B., Carpanese, F., Ewalds, T., Hafner, R., Abdolmaleki, A., de~Las~Casas, D., et~al. (2022).
\newblock Magnetic control of tokamak plasmas through deep reinforcement learning.
\newblock {\em Nature}, 602:414--419.

\bibitem[Devlin et~al., 2018]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2018).
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}.

\bibitem[Dhariwal and Nichol, 2021]{dhariwal2021diffbeatsgans}
Dhariwal, P. and Nichol, A. (2021).
\newblock Diffusion models beat gans on image synthesis.
\newblock {\em Advances in Neural Information Processing Systems}, 34:8780--8794.

\bibitem[Ding et~al., 2024]{ding2024diffusion}
Ding, Z., Zhang, A., Tian, Y., and Zheng, Q. (2024).
\newblock Diffusion world model.
\newblock {\em arXiv preprint arXiv:2402.03570}.

\bibitem[Elfwing et~al., 2018]{elfwing2018sigmoid}
Elfwing, S., Uchibe, E., and Doya, K. (2018).
\newblock Sigmoid-weighted linear units for neural network function approximation in reinforcement learning.
\newblock {\em Neural networks}, 107:3--11.

\bibitem[Esser et~al., 2021]{esser2021taming}
Esser, P., Rombach, R., and Ommer, B. (2021).
\newblock Taming transformers for high-resolution image synthesis.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 12873--12883.

\bibitem[Gers et~al., 2000]{Gers2000}
Gers, F.~A., Schmidhuber, J., and Cummins, F. (2000).
\newblock Learning to forget: Continual prediction with {LSTM}.
\newblock {\em Neural Computation}, 12(10):2451--2471.

\bibitem[Goodfellow et~al., 2014]{goodfellow2014GAN}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2014).
\newblock Generative adversarial nets.
\newblock {\em Advances in Neural Information Processing Systems}, 27.

\bibitem[Ha and Schmidhuber, 2018]{ha2018world}
Ha, D. and Schmidhuber, J. (2018).
\newblock Recurrent world models facilitate policy evolution.
\newblock {\em Advances in Neural Information Processing Systems}, 31:2451--2463.

\bibitem[Hafner et~al., 2020]{hafner2020dream}
Hafner, D., Lillicrap, T., Ba, J., and Norouzi, M. (2020).
\newblock Dream to control: Learning behaviors by latent imagination.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Hafner et~al., 2021]{hafner2021mastering}
Hafner, D., Lillicrap, T.~P., Norouzi, M., and Ba, J. (2021).
\newblock Mastering atari with discrete world models.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Hafner et~al., 2023]{hafner2023dreamerv3}
Hafner, D., Pasukonis, J., Ba, J., and Lillicrap, T. (2023).
\newblock Mastering diverse domains through world models.
\newblock {\em arXiv preprint arXiv:2301.04104}.

\bibitem[He et~al., 2015]{He2015}
He, K., Zhang, X., Ren, S., and Sun, J. (2015).
\newblock Deep residual learning for image recognition.
\newblock {\em arXiv preprint arXiv:1512.03385}.

\bibitem[Heusel et~al., 2017]{heusel2017gans}
Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochreiter, S. (2017).
\newblock Gans trained by a two time-scale update rule converge to a local nash equilibrium.
\newblock {\em Advances in Neural Information Processing Systems}, 30.

\bibitem[Ho et~al., 2020]{ho2020DDPM}
Ho, J., Jain, A., and Abbeel, P. (2020).
\newblock Denoising diffusion probabilistic models.
\newblock {\em Advances in Neural Information Processing Systems}, 33:6840--6851.

\bibitem[Ho et~al., 2022]{ho2022video}
Ho, J., Salimans, T., Gritsenko, A., Chan, W., Norouzi, M., and Fleet, D.~J. (2022).
\newblock Video diffusion models.
\newblock {\em URL https://arxiv. org/abs/2204.03458}.

\bibitem[Hochreiter and Schmidhuber, 1997]{lstm}
Hochreiter, S. and Schmidhuber, J. (1997).
\newblock Long short-term memory.
\newblock {\em Neural Computation}, 9(8):1735--1780.

\bibitem[Hu et~al., 2023]{hu2023gaia}
Hu, A., Russell, L., Yeo, H., Murez, Z., Fedoseev, G., Kendall, A., Shotton, J., and Corrado, G. (2023).
\newblock Gaia-1: A generative world model for autonomous driving.
\newblock {\em arXiv preprint arXiv:2309.17080}.

\bibitem[Hyv{\"a}rinen, 2005]{hyvarinen2005estimation}
Hyv{\"a}rinen, A. (2005).
\newblock Estimation of non-normalized statistical models by score matching.
\newblock {\em Journal of Machine Learning Research}, 6:695--709.

\bibitem[Jackson et~al., 2024]{jackson2024policyguided}
Jackson, M.~T., Matthews, M.~T., Lu, C., Ellis, B., Whiteson, S., and Foerster, J. (2024).
\newblock Policy-guided diffusion.
\newblock {\em arXiv preprint arXiv:2404.06356}.

\bibitem[Janner et~al., 2022]{janner2022planning}
Janner, M., Du, Y., Tenenbaum, J., and Levine, S. (2022).
\newblock Planning with diffusion for flexible behavior synthesis.
\newblock In {\em International Conference on Machine Learning}, pages 9902--9915. PMLR.

\bibitem[Kaiser et~al., 2019]{kaiser2019atari100k}
Kaiser, L., Babaeizadeh, M., Milos, P., Osinski, B., Campbell, R.~H., Czechowski, K., Erhan, D., Finn, C., Kozakowski, P., Levine, S., et~al. (2019).
\newblock Model-based reinforcement learning for atari.
\newblock {\em arXiv preprint arXiv:1903.00374}.

\bibitem[Kaiser and Sutskever, 2015]{kaiser2015neural}
Kaiser, {\L}. and Sutskever, I. (2015).
\newblock Neural gpus learn algorithms.
\newblock {\em arXiv preprint arXiv:1511.08228}.

\bibitem[Kapturowski et~al., 2018]{r2d2}
Kapturowski, S., Ostrovski, G., Quan, J., Munos, R., and Dabney, W. (2018).
\newblock Recurrent experience replay in distributed reinforcement learning.
\newblock {\em International Conference on Learning Representations}.

\bibitem[Karras et~al., 2022]{karras2022elucidating}
Karras, T., Aittala, M., Aila, T., and Laine, S. (2022).
\newblock Elucidating the design space of diffusion-based generative models.
\newblock {\em Advances in Neural Information Processing Systems}, 35:26565--26577.

\bibitem[Kim et~al., 2020]{gameGAN2020}
Kim, S.~W., Zhou, Y., Philion, J., Torralba, A., and Fidler, S. (2020).
\newblock Learning to simulate dynamic environments with gamegan.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 1231--1240.

\bibitem[LeCun, 2022]{lecun2022path}
LeCun, Y. (2022).
\newblock A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27.
\newblock {\em OpenReview}.

\bibitem[LeCun et~al., 1989]{cnn_lecun}
LeCun, Y., Boser, B., Denker, J.~S., Henderson, D., Howard, R.~E., Hubbard, W., and Jackel, L.~D. (1989).
\newblock Backpropagation applied to handwritten zip code recognition.
\newblock {\em Neural computation}, 1(4):541--551.

\bibitem[Liang et~al., 2023]{liang2023adaptdiffuser}
Liang, Z., Mu, Y., Ding, M., Ni, F., Tomizuka, M., and Luo, P. (2023).
\newblock Adaptdiffuser: Diffusion models as adaptive self-evolving planners.
\newblock {\em International Conference on Machine Learning}.

\bibitem[Lu et~al., 2023]{lu2023synthetic}
Lu, C., Ball, P.~J., and Parker-Holder, J. (2023).
\newblock Synthetic experience replay.
\newblock {\em arXiv preprint arXiv:2303.06614}.

\bibitem[Luo et~al., 2023]{luo2023dhf}
Luo, G., Dunlap, L., Park, D.~H., Holynski, A., and Darrell, T. (2023).
\newblock Diffusion hyperfeatures: Searching through time and space for semantic correspondence.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Micheli et~al., 2023]{iris2023}
Micheli, V., Alonso, E., and Fleuret, F. (2023).
\newblock Transformers are sample-efficient world models.
\newblock {\em International Conference on Learning Representations}.

\bibitem[Mnih et~al., 2016]{a3c}
Mnih, V., Badia, A.~P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., Silver, D., and Kavukcuoglu, K. (2016).
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In Balcan, M.~F. and Weinberger, K.~Q., editors, {\em Proceedings of The 33rd International Conference on Machine Learning}, volume~48 of {\em Proceedings of Machine Learning Research}, pages 1928--1937, New York, New York, USA.

\bibitem[Mnih et~al., 2015]{mnih2015dqn}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare, M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al. (2015).
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518(7540):529--533.

\bibitem[Nichol and Dhariwal, 2021]{ddpm++}
Nichol, A.~Q. and Dhariwal, P. (2021).
\newblock Improved denoising diffusion probabilistic models.
\newblock {\em International Conference on Machine Learning}.

\bibitem[Nuti et~al., 2023]{nuti2023extracting}
Nuti, F., Franzmeyer, T., and Henriques, J.~F. (2023).
\newblock Extracting reward functions from diffusion models.
\newblock {\em arXiv preprint arXiv:2306.01804}.

\bibitem[Ouyang et~al., 2022]{ouyang2022training}
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et~al. (2022).
\newblock Training language models to follow instructions with human feedback.
\newblock {\em Advances in Neural Information Processing Systems}, 35:27730--27744.

\bibitem[Pearce et~al., 2023]{pearce2023imitating}
Pearce, T., Rashid, T., Kanervisto, A., Bignell, D., Sun, M., Georgescu, R., Macua, S.~V., Tan, S.~Z., Momennejad, I., Hofmann, K., and Devlin, S. (2023).
\newblock Imitating human behaviour with diffusion models.
\newblock {\em The Eleventh International Conference on Learning Representations}.

\bibitem[Pearce and Zhu, 2022]{pearce2022counter}
Pearce, T. and Zhu, J. (2022).
\newblock Counter-strike deathmatch with large-scale behavioural cloning.
\newblock In {\em 2022 IEEE Conference on Games (CoG)}, pages 104--111. IEEE.

\bibitem[Peebles and Xie, 2023]{dit2023}
Peebles, W. and Xie, S. (2023).
\newblock Scalable diffusion models with transformers.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pages 4195--4205.

\bibitem[Podell et~al., 2023]{podell2023sdxl}
Podell, D., English, Z., Lacey, K., Blattmann, A., Dockhorn, T., M{\"u}ller, J., Penna, J., and Rombach, R. (2023).
\newblock Sdxl: Improving latent diffusion models for high-resolution image synthesis.
\newblock {\em arXiv preprint arXiv:2307.01952}.

\bibitem[Radford et~al., 2019]{radford2019language}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I. (2019).
\newblock Language models are unsupervised multitask learners.

\bibitem[Ramesh et~al., 2022]{ramesh2022hierarchical}
Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M. (2022).
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock {\em arXiv preprint arXiv:2204.06125}, 1(2):3.

\bibitem[Ramesh et~al., 2021]{ramesh2021zero}
Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., and Sutskever, I. (2021).
\newblock Zero-shot text-to-image generation.
\newblock {\em International Conference on Machine Learning}.

\bibitem[Robine et~al., 2023]{robine2023transformer}
Robine, J., H{\"o}ftmann, M., Uelwer, T., and Harmeling, S. (2023).
\newblock Transformer-based world models are happy with 100k interactions.
\newblock {\em International Conference on Learning Representations}.

\bibitem[Rombach et~al., 2022]{ldm_stable_diffusion}
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B. (2022).
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 10684--10695.

\bibitem[Ronneberger et~al., 2015]{ronneberger2015unet}
Ronneberger, O., Fischer, P., and Brox, T. (2015).
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In {\em Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18}, pages 234--241. Springer.

\bibitem[Saharia et~al., 2022a]{saharia2022imagen}
Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E.~L., Ghasemipour, K., Gontijo~Lopes, R., Karagol~Ayan, B., Salimans, T., et~al. (2022a).
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock {\em Advances in Neural Information Processing Systems}, 35:36479--36494.

\bibitem[Saharia et~al., 2022b]{saharia2022image}
Saharia, C., Ho, J., Chan, W., Salimans, T., Fleet, D.~J., and Norouzi, M. (2022b).
\newblock Image super-resolution via iterative refinement.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence}.

\bibitem[Santana and Hotz, 2016]{santana2016learning}
Santana, E. and Hotz, G. (2016).
\newblock Learning a driving simulator.
\newblock {\em arXiv preprint arXiv:1608.01230}.

\bibitem[Schrittwieser et~al., 2020]{muzero2020}
Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L., Schmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., et~al. (2020).
\newblock Mastering atari, go, chess and shogi by planning with a learned model.
\newblock {\em Nature}, 588(7839):604--609.

\bibitem[Schwarzer et~al., 2023]{schwarzer2023bigger}
Schwarzer, M., Ceron, J. S.~O., Courville, A., Bellemare, M.~G., Agarwal, R., and Castro, P.~S. (2023).
\newblock Bigger, better, faster: Human-level atari with human-level efficiency.
\newblock {\em International Conference on Machine Learning}.

\bibitem[Silver et~al., 2016]{alphago}
Silver, D., Huang, A., Maddison, C.~J., Guez, A., Sifre, L., Van Den~Driessche, G., Schrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M., et~al. (2016).
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em Nature}, 529:484--489.

\bibitem[Singer et~al., 2023]{singer2023make}
Singer, U., Polyak, A., Hayes, T., Yin, X., An, J., Zhang, S., Hu, Q., Yang, H., Ashual, O., Gafni, O., et~al. (2023).
\newblock Make-a-video: Text-to-video generation without text-video data.
\newblock {\em International Conference on Learning Representations}.

\bibitem[Skorokhodov et~al., 2022]{skorokhodov2022stylegan}
Skorokhodov, I., Tulyakov, S., and Elhoseiny, M. (2022).
\newblock Stylegan-v: A continuous video generator with the price, image quality and perks of stylegan2.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 3626--3636.

\bibitem[Sohl-Dickstein et~al., 2015]{sohl2015difforigin}
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S. (2015).
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock {\em International Conference on Machine Learning}.

\bibitem[Song et~al., 2020]{song_sde}
Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole, B. (2020).
\newblock Score-based generative modeling through stochastic differential equations.
\newblock {\em International Conference on Learning Representations}.

\bibitem[Sutton, 1991]{sutton1991dyna}
Sutton, R.~S. (1991).
\newblock Dyna, an integrated architecture for learning, planning, and reacting.
\newblock {\em ACM Sigart Bulletin}, 2(4):160--163.

\bibitem[Sutton and Barto, 2018]{sutton2018reinforcement}
Sutton, R.~S. and Barto, A.~G. (2018).
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press.

\bibitem[Unterthiner et~al., 2018]{unterthiner2018towards}
Unterthiner, T., Van~Steenkiste, S., Kurach, K., Marinier, R., Michalski, M., and Gelly, S. (2018).
\newblock Towards accurate generative models of video: A new metric \& challenges.
\newblock {\em arXiv preprint arXiv:1812.01717}.

\bibitem[Valevski et~al., 2024]{valevski2024diffusionmodelsrealtimegame}
Valevski, D., Leviathan, Y., Arar, M., and Fruchter, S. (2024).
\newblock Diffusion models are real-time game engines.

\bibitem[Van Den~Oord et~al., 2017]{vqvae}
Van Den~Oord, A., Vinyals, O., et~al. (2017).
\newblock Neural discrete representation learning.
\newblock {\em Advances in Neural Information Processing Systems}, 30.

\bibitem[Vaswani et~al., 2017]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N., Kaiser, {\L}., and Polosukhin, I. (2017).
\newblock Attention is all you need.
\newblock {\em Advances in Neural Information Processing Systems}, 30.

\bibitem[Villegas et~al., 2023]{phenaki}
Villegas, R., Babaeizadeh, M., Kindermans, P.-J., Moraldo, H., Zhang, H., Saffar, M.~T., Castro, S., Kunze, J., and Erhan, D. (2023).
\newblock Phenaki: Variable length video generation from open domain textual descriptions.
\newblock {\em International Conference on Learning Representations}.

\bibitem[Vincent, 2011]{vincent2011connection}
Vincent, P. (2011).
\newblock A connection between score matching and denoising autoencoders.
\newblock {\em Neural computation}, 23(7):1661--1674.

\bibitem[Vincent et~al., 2008]{vincent2008extracting}
Vincent, P., Larochelle, H., Bengio, Y., and Manzagol, P.-A. (2008).
\newblock Extracting and composing robust features with denoising autoencoders.
\newblock In {\em International Conference on Machine learning}.

\bibitem[Wang et~al., 2022]{wang2022diffusion}
Wang, Z., Hunt, J.~J., and Zhou, M. (2022).
\newblock Diffusion policies as an expressive policy class for offline reinforcement learning.
\newblock {\em International Conference on Learning Representations}.

\bibitem[Wang et~al., 2016]{dueling_networks}
Wang, Z., Schaul, T., Hessel, M., Hasselt, H., Lanctot, M., and Freitas, N. (2016).
\newblock Dueling network architectures for deep reinforcement learning.
\newblock {\em International Conference on Machine Learning}.

\bibitem[Wu et~al., 2021]{wu2021godiva}
Wu, C., Huang, L., Zhang, Q., Li, B., Ji, L., Yang, F., Sapiro, G., and Duan, N. (2021).
\newblock Godiva: Generating open-domain videos from natural descriptions.
\newblock {\em arXiv preprint arXiv:2104.14806}.

\bibitem[Wu et~al., 2023]{wu2023daydreamer}
Wu, P., Escontrela, A., Hafner, D., Abbeel, P., and Goldberg, K. (2023).
\newblock Daydreamer: World models for physical robot learning.
\newblock In {\em Conference on Robot Learning}, pages 2226--2240. PMLR.

\bibitem[Wu and He, 2018]{groupnorm}
Wu, Y. and He, K. (2018).
\newblock Group normalization.
\newblock In {\em Proceedings of the European Conference on Computer Vision (ECCV)}.

\bibitem[Xu et~al., 2023]{xu2023open}
Xu, J., Liu, S., Vahdat, A., Byeon, W., Wang, X., and De~Mello, S. (2023).
\newblock Open-vocabulary panoptic segmentation with text-to-image diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 2955--2966.

\bibitem[Yan et~al., 2023]{yan2023teco}
Yan, W., Hafner, D., James, S., and Abbeel, P. (2023).
\newblock Temporally consistent transformers for video generation.
\newblock {\em International Conference on Machine Learning}.

\bibitem[Yan et~al., 2021]{yan2021videogpt}
Yan, W., Zhang, Y., Abbeel, P., and Srinivas, A. (2021).
\newblock Videogpt: Video generation using vq-vae and transformers.
\newblock {\em arXiv preprint arXiv:2104.10157}.

\bibitem[Ye et~al., 2021]{ye2021efficientzero}
Ye, W., Liu, S., Kurutach, T., Abbeel, P., and Gao, Y. (2021).
\newblock Mastering atari games with limited data.
\newblock {\em Advances in Neural Information Processing Systems}, 34.

\bibitem[Zhang et~al., 2018]{zhang2018lpips}
Zhang, R., Isola, P., Efros, A.~A., Shechtman, E., and Wang, O. (2018).
\newblock The unreasonable effectiveness of deep features as a perceptual metric.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 586--595.

\bibitem[Zhang et~al., 2023]{zhang2023storm}
Zhang, W., Wang, G., Sun, J., Yuan, Y., and Huang, G. (2023).
\newblock Storm: Efficient stochastic transformer based world models for reinforcement learning.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing Systems}.

\bibitem[Zheng et~al., 2020]{adagn}
Zheng, H., Fu, J., Zeng, Y., Luo, J., and Zha, Z.-J. (2020).
\newblock Learning semantic-aware normalization for generative adversarial networks.
\newblock In {\em Advances in Neural Information Processing Systems}.

\end{thebibliography}
