\begin{thebibliography}{}

\bibitem[Achlioptas and McSherry, 2005]{achlioptas2005spectral}
Achlioptas, D. and McSherry, F. (2005).
\newblock On spectral learning of mixtures of distributions.
\newblock In {\em International Conference on Computational Learning Theory},
  pages 458--469. Springer.

\bibitem[Agarwal et~al., 2019]{agarwal2019optimality}
Agarwal, A., Kakade, S.~M., Lee, J.~D., and Mahajan, G. (2019).
\newblock Optimality and approximation with policy gradient methods in {M}arkov
  decision processes.
\newblock {\em arXiv preprint arXiv:1908.00261}.

\bibitem[Agrawal and Jia, 2017]{agrawal2017optimistic}
Agrawal, S. and Jia, R. (2017).
\newblock Optimistic posterior sampling for reinforcement learning: Worst-case
  regret bounds.
\newblock In {\em Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pages 1184--1194. Curran Associates Inc.

\bibitem[Antos et~al., 2008]{antos2008learning}
Antos, A., Szepesv{\'a}ri, C., and Munos, R. (2008).
\newblock Learning near-optimal policies with {B}ellman-residual minimization
  based fitted policy iteration and a single sample path.
\newblock {\em Machine Learning}, 71(1):89--129.

\bibitem[Arora and Kannan, 2001]{sanjeev2001learning}
Arora, S. and Kannan, R. (2001).
\newblock Learning mixtures of arbitrary {G}aussians.
\newblock In {\em Proceedings of the thirty-third annual ACM symposium on
  Theory of computing}, pages 247--257.

\bibitem[Azar et~al., 2017]{azar2017minimax}
Azar, M.~G., Osband, I., and Munos, R. (2017).
\newblock Minimax regret bounds for reinforcement learning.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 263--272. JMLR. org.

\bibitem[{Azizzadenesheli} et~al., 2018]{azizzadenesheli2018efficient}
{Azizzadenesheli}, K., {Brunskill}, E., and {Anandkumar}, A. (2018).
\newblock Efficient exploration through {B}ayesian deep {Q}-networks.
\newblock In {\em 2018 Information Theory and Applications Workshop (ITA)},
  pages 1--9.

\bibitem[Bagnell et~al., 2004]{bagnell2004policy}
Bagnell, J.~A., Kakade, S.~M., Schneider, J.~G., and Ng, A.~Y. (2004).
\newblock Policy search by dynamic programming.
\newblock In {\em Advances in neural information processing systems}, pages
  831--838.

\bibitem[Bellemare et~al., 2016]{bellemare2016unifying}
Bellemare, M., Srinivasan, S., Ostrovski, G., Schaul, T., Saxton, D., and
  Munos, R. (2016).
\newblock Unifying count-based exploration and intrinsic motivation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1471--1479.

\bibitem[Bontemps and Toussile, 2013]{bontemps2013clustering}
Bontemps, D. and Toussile, W. (2013).
\newblock Clustering and variable selection for categorical multivariate data.
\newblock {\em Electronic Journal of Statistics}, 7:2344--2371.

\bibitem[Bouguila and Fan, 2020]{bouguila2020mixture}
Bouguila, N. and Fan, W. (2020).
\newblock {\em Mixture models and applications}.
\newblock Springer.

\bibitem[Charikar, 2002]{charikar2002similarity}
Charikar, M.~S. (2002).
\newblock Similarity estimation techniques from rounding algorithms.
\newblock In {\em Proceedings of the thiry-fourth annual ACM symposium on
  Theory of computing}, pages 380--388.

\bibitem[Chen and Jiang, 2019]{chen2019information}
Chen, J. and Jiang, N. (2019).
\newblock Information-theoretic considerations in batch reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  1042--1051.

\bibitem[Dahl, 2006]{dahl2006model}
Dahl, D.~B. (2006).
\newblock Model-based clustering for expression data via a {D}irichlet process
  mixture model.
\newblock {\em Bayesian inference for gene expression and proteomics},
  4:201--218.

\bibitem[Dann et~al., 2018]{dann2018oracle}
Dann, C., Jiang, N., Krishnamurthy, A., Agarwal, A., Langford, J., and
  Schapire, R.~E. (2018).
\newblock On oracle-efficient {PAC} {RL} with rich observations.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1422--1432.

\bibitem[Dann et~al., 2017]{dann2017unifying}
Dann, C., Lattimore, T., and Brunskill, E. (2017).
\newblock Unifying {PAC} and regret: Uniform {PAC} bounds for episodic
  reinforcement learning.
\newblock In {\em Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, NIPS'17, pages 5717--5727, USA. Curran
  Associates Inc.

\bibitem[Dasgupta and Schulman, 2000]{dasgupta2000two}
Dasgupta, S. and Schulman, L.~J. (2000).
\newblock A two-round variant of {EM} for {G}aussian mixtures.
\newblock In {\em Proceedings of the Sixteenth conference on Uncertainty in
  artificial intelligence}, pages 152--159.

\bibitem[Du et~al., 2019a]{du2019provably}
Du, S., Krishnamurthy, A., Jiang, N., Agarwal, A., Dudik, M., and Langford, J.
  (2019a).
\newblock Provably efficient {RL} with rich observations via latent state
  decoding.
\newblock In {\em International Conference on Machine Learning}, pages
  1665--1674.

\bibitem[Du et~al., 2020a]{Du2020Is}
Du, S.~S., Kakade, S.~M., Wang, R., and Yang, L.~F. (2020a).
\newblock Is a good representation sufficient for sample efficient
  reinforcement learning?
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Du et~al., 2020b]{du2020agnostic}
Du, S.~S., Lee, J.~D., Mahajan, G., and Wang, R. (2020b).
\newblock Agnostic {Q}-learning with function approximation in deterministic
  systems: Tight bounds on approximation error and sample complexity.
\newblock {\em arXiv preprint arXiv:2002.07125}.

\bibitem[Du et~al., 2019b]{du2019provablyQ}
Du, S.~S., Luo, Y., Wang, R., and Zhang, H. (2019b).
\newblock Provably efficient {Q}-learning with function approximation via
  distribution shift error checking oracle.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  8058--8068.

\bibitem[Elhamifar and Vidal, 2013]{elhamifar2013sparse}
Elhamifar, E. and Vidal, R. (2013).
\newblock Sparse subspace clustering: Algorithm, theory, and applications.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  35(11):2765--2781.

\bibitem[Fortunato et~al., 2018]{fortunato2018noisy}
Fortunato, M., Azar, M.~G., Piot, B., Menick, J., Hessel, M., Osband, I.,
  Graves, A., Mnih, V., Munos, R., Hassabis, D., Pietquin, O., Blundell, C.,
  and Legg, S. (2018).
\newblock Noisy networks for exploration.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Geist et~al., 2019]{geist2019theory}
Geist, M., Scherrer, B., and Pietquin, O. (2019).
\newblock A theory of regularized {M}arkov decision processes.
\newblock In {\em International Conference on Machine Learning}, pages
  2160--2169.

\bibitem[Jaksch et~al., 2010]{jaksch2010near}
Jaksch, T., Ortner, R., and Auer, P. (2010).
\newblock Near-optimal regret bounds for reinforcement learning.
\newblock {\em Journal of Machine Learning Research}, 11(Apr):1563--1600.

\bibitem[Jiang et~al., 2017]{jiang2017contextual}
Jiang, N., Krishnamurthy, A., Agarwal, A., Langford, J., and Schapire, R.~E.
  (2017).
\newblock Contextual decision processes with low {B}ellman rank are
  {PAC}-learnable.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 1704--1713. JMLR. org.

\bibitem[Jin et~al., 2018]{jin2018q}
Jin, C., Allen-Zhu, Z., Bubeck, S., and Jordan, M.~I. (2018).
\newblock Is {Q}-learning provably efficient?
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4863--4873.

\bibitem[Jin et~al., 2019]{jin2019provably}
Jin, C., Yang, Z., Wang, Z., and Jordan, M.~I. (2019).
\newblock Provably efficient reinforcement learning with linear function
  approximation.
\newblock {\em arXiv preprint arXiv:1907.05388}.

\bibitem[Juan and Vidal, 2002]{juan2002use}
Juan, A. and Vidal, E. (2002).
\newblock On the use of {B}ernoulli mixture models for text classification.
\newblock {\em Pattern Recognition}, 35(12):2705--2710.

\bibitem[Juan and Vidal, 2004]{juan2004bernoulli}
Juan, A. and Vidal, E. (2004).
\newblock {B}ernoulli mixture models for binary images.
\newblock In {\em Proceedings of the 17th International Conference on Pattern
  Recognition, 2004. ICPR 2004.}, volume~3, pages 367--370. IEEE.

\bibitem[Kakade and Langford, 2002]{kakade2002approximately}
Kakade, S. and Langford, J. (2002).
\newblock Approximately optimal approximate reinforcement learning.
\newblock In {\em ICML}, volume~2, pages 267--274.

\bibitem[Kakade et~al., 2018]{kakade2018variance}
Kakade, S., Wang, M., and Yang, L.~F. (2018).
\newblock Variance reduction methods for sublinear reinforcement learning.
\newblock {\em arXiv preprint arXiv:1802.09184}.

\bibitem[Kearns and Singh, 2002]{kearns2002near}
Kearns, M. and Singh, S. (2002).
\newblock Near-optimal reinforcement learning in polynomial time.
\newblock {\em Machine learning}, 49(2-3):209--232.

\bibitem[Krishnamurthy et~al., 2016]{krishnamurthy2016pac}
Krishnamurthy, A., Agarwal, A., and Langford, J. (2016).
\newblock {PAC} reinforcement learning with rich observations.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1840--1848.

\bibitem[Li and Zha, 2006]{li2006two}
Li, J. and Zha, H. (2006).
\newblock Two-way {P}oisson mixture models for simultaneous document
  classification and word clustering.
\newblock {\em Computational Statistics \& Data Analysis}, 50(1):163--180.

\bibitem[Li et~al., 2011]{li2011knows}
Li, L., Littman, M.~L., Walsh, T.~J., and Strehl, A.~L. (2011).
\newblock Knows what it knows: A framework for self-aware learning.
\newblock {\em Machine learning}, 82(3):399--443.

\bibitem[Lipton et~al., 2018]{lipton2018bbq}
Lipton, Z.~C., Li, X., Gao, J., Li, L., Ahmed, F., and Deng, L. (2018).
\newblock {BBQ}-networks: Efficient exploration in deep reinforcement learning
  for task-oriented dialogue systems.
\newblock In {\em AAAI}.

\bibitem[McLachlan and Basford, 1988]{mclachlan1988mixture}
McLachlan, G.~J. and Basford, K.~E. (1988).
\newblock {\em Mixture models: Inference and applications to clustering},
  volume~38.
\newblock M. Dekker New York.

\bibitem[McLachlan and Peel, 2004]{mclachlan2004finite}
McLachlan, G.~J. and Peel, D. (2004).
\newblock {\em Finite mixture models}.
\newblock John Wiley \& Sons.

\bibitem[Munos, 2005]{munos2005error}
Munos, R. (2005).
\newblock Error bounds for approximate value iteration.
\newblock In {\em Proceedings of the National Conference on Artificial
  Intelligence}, volume~20, page 1006. Menlo Park, CA; Cambridge, MA; London;
  AAAI Press; MIT Press; 1999.

\bibitem[Najafi et~al., 2020]{najafi2020reliable}
Najafi, A., Motahari, S.~A., and Rabiee, H.~R. (2020).
\newblock Reliable clustering of {B}ernoulli mixture models.
\newblock {\em Bernoulli}, 26(2):1535--1559.

\bibitem[{Ni} et~al., 2019]{8919864}
{Ni}, C., {Yang}, L.~F., and {Wang}, M. (2019).
\newblock Learning to control in metric space with optimal regret.
\newblock In {\em 2019 57th Annual Allerton Conference on Communication,
  Control, and Computing (Allerton)}, pages 726--733.

\bibitem[Osband et~al., 2016]{osband2016generalization}
Osband, I., Van~Roy, B., and Wen, Z. (2016).
\newblock Generalization and exploration via randomized value functions.
\newblock In {\em Proceedings of the 33rd International Conference on
  International Conference on Machine Learning - Volume 48}, ICML'16, pages
  2377--2386. JMLR.org.

\bibitem[Pathak et~al., 2017]{pathak2017curiosity}
Pathak, D., Agrawal, P., Efros, A.~A., and Darrell, T. (2017).
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In {\em International Conference on Machine Learning (ICML)}, volume
  2017.

\bibitem[Pazis and Parr, 2013]{pazis2013pac}
Pazis, J. and Parr, R. (2013).
\newblock {PAC} optimal exploration in continuous space {M}arkov decision
  processes.
\newblock In {\em Proceedings of the Twenty-Seventh AAAI Conference on
  Artificial Intelligence}, AAAI'13, pages 774--781. AAAI Press.

\bibitem[Regev and Vijayaraghavan, 2017]{regev2017learning}
Regev, O. and Vijayaraghavan, A. (2017).
\newblock On learning mixtures of well-separated {G}aussians.
\newblock In {\em 2017 IEEE 58th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 85--96. IEEE.

\bibitem[Scherrer and Geist, 2014]{scherrer2014local}
Scherrer, B. and Geist, M. (2014).
\newblock Local policy search in a convex space and conservative policy
  iteration as boosted policy search.
\newblock In {\em Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 35--50. Springer.

\bibitem[Simchowitz and Jamieson, 2019]{simchowitz2019non}
Simchowitz, M. and Jamieson, K.~G. (2019).
\newblock Non-asymptotic gap-dependent regret bounds for tabular {MDP}s.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1151--1160.

\bibitem[Soltanolkotabi et~al., 2014]{soltanolkotabi2014robust}
Soltanolkotabi, M., Elhamifar, E., Candes, E.~J., et~al. (2014).
\newblock Robust subspace clustering.
\newblock {\em The Annals of Statistics}, 42(2):669--699.

\bibitem[Song and Sun, 2019]{song2019efficient}
Song, Z. and Sun, W. (2019).
\newblock Efficient model-free reinforcement learning in metric spaces.
\newblock {\em arXiv preprint arXiv:1905.00475}.

\bibitem[Strehl et~al., 2006]{strehl2006pac}
Strehl, A.~L., Li, L., Wiewiora, E., Langford, J., and Littman, M.~L. (2006).
\newblock {PAC} model-free reinforcement learning.
\newblock In {\em Proceedings of the 23rd international conference on Machine
  learning}, pages 881--888. ACM.

\bibitem[Sun et~al., 2019]{sun2019model}
Sun, W., Jiang, N., Krishnamurthy, A., Agarwal, A., and Langford, J. (2019).
\newblock Model-based {RL} in contextual decision processes: {PAC} bounds and
  exponential improvements over model-free approaches.
\newblock In {\em Conference on Learning Theory}, pages 2898--2933.

\bibitem[Tang et~al., 2017]{tang2017exploration}
Tang, H., Houthooft, R., Foote, D., Stooke, A., Chen, O.~X., Duan, Y.,
  Schulman, J., DeTurck, F., and Abbeel, P. (2017).
\newblock \# {E}xploration: A study of count-based exploration for deep
  reinforcement learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2753--2762.

\bibitem[Vempala and Wang, 2004]{vempala2004spectral}
Vempala, S. and Wang, G. (2004).
\newblock A spectral algorithm for learning mixture models.
\newblock {\em Journal of Computer and System Sciences}, 68(4):841--860.

\bibitem[Vidal, 2011]{vidal2011subspace}
Vidal, R. (2011).
\newblock Subspace clustering.
\newblock {\em IEEE Signal Processing Magazine}, 28(2):52--68.

\bibitem[Wallace et~al., 2015]{wallace2015application}
Wallace, T., Sekmen, A., and Wang, X. (2015).
\newblock Application of subspace clustering in {DNA} sequence analysis.
\newblock {\em Journal of Computational Biology}, 22(10):940--952.

\bibitem[Wang et~al., 2013]{wang2013provable}
Wang, Y.-X., Xu, H., and Leng, C. (2013).
\newblock Provable subspace clustering: When {LRR} meets {SSC}.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  64--72.

\bibitem[Wen and Van~Roy, 2013]{wen2013efficient}
Wen, Z. and Van~Roy, B. (2013).
\newblock Efficient exploration and value function generalization in
  deterministic systems.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3021--3029.

\bibitem[Yang and Wang, 2019]{yang2019sample}
Yang, L.~F. and Wang, M. (2019).
\newblock Sample-optimal parametric {Q}-learning using linearly additive
  features.
\newblock In {\em International Conference on Machine Learning}, pages
  6995--7004.

\bibitem[Yang et~al., 2019]{yang2019theoretical}
Yang, Z., Xie, Y., and Wang, Z. (2019).
\newblock A theoretical analysis of deep {Q}-learning.
\newblock {\em arXiv preprint arXiv:1901.00137}.

\bibitem[Zanette and Brunskill, 2019]{zanette2019tighter}
Zanette, A. and Brunskill, E. (2019).
\newblock Tighter problem-dependent regret bounds in reinforcement learning
  without domain knowledge using value function bounds.
\newblock In {\em International Conference on Machine Learning}, pages
  7304--7312.

\end{thebibliography}
