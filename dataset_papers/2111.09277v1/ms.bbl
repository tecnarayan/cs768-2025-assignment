\begin{thebibliography}{70}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alfarra et~al.(2020)Alfarra, Bibi, Torr, and Ghanem]{alfarra2020data}
Motasem Alfarra, Adel Bibi, Philip H.~S. Torr, and Bernard Ghanem.
\newblock Data dependent randomized smoothing, 2020.

\bibitem[Amodei et~al.(2016)Amodei, Olah, Steinhardt, Christiano, Schulman, and
  Man{\'e}]{amodei2016concrete}
Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and
  Dan Man{\'e}.
\newblock Concrete problems in {AI} safety.
\newblock \emph{arXiv preprint arXiv:1606.06565}, 2016.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and Wagner]{pmlr-v80-athalye18a}
Anish Athalye, Nicholas Carlini, and David Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, volume~80 of \emph{Proceedings of Machine Learning Research},
  pages 274--283, Stockholmsm√§ssan, Stockholm Sweden, 10--15 Jul 2018. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v80/athalye18a.html}.

\bibitem[Balunovic and Vechev(2020)]{Balunovic2020Adversarial}
Mislav Balunovic and Martin Vechev.
\newblock Adversarial training and provable defenses: Bridging the gap.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=SJxSDxrKDr}.

\bibitem[Bhattad et~al.(2020)Bhattad, Chong, Liang, Li, and
  Forsyth]{bhattad2020Unrestricted}
Anand Bhattad, Min~Jin Chong, Kaizhao Liang, Bo~Li, and D.~A. Forsyth.
\newblock Unrestricted adversarial examples via semantic manipulation.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=Sye_OgHFwH}.

\bibitem[Carlini and Wagner(2017{\natexlab{a}})]{carlini2017adversarial}
Nicholas Carlini and David Wagner.
\newblock Adversarial examples are not easily detected: Bypassing ten detection
  methods.
\newblock In \emph{Proceedings of the 10th ACM Workshop on Artificial
  Intelligence and Security}, pages 3--14, 2017{\natexlab{a}}.

\bibitem[Carlini and Wagner(2017{\natexlab{b}})]{carlini2017towards}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{IEEE Symposium on Security and Privacy}, pages 39--57. IEEE,
  2017{\natexlab{b}}.

\bibitem[Carlini et~al.(2019)Carlini, Athalye, Papernot, Brendel, Rauber,
  Tsipras, Goodfellow, and Madry]{carlini2019evaluating}
Nicholas Carlini, Anish Athalye, Nicolas Papernot, Wieland Brendel, Jonas
  Rauber, Dimitris Tsipras, Ian Goodfellow, and Aleksander Madry.
\newblock On evaluating adversarial robustness.
\newblock \emph{arXiv preprint arXiv:1902.06705}, 2019.

\bibitem[Caruana et~al.(2015)Caruana, Lou, Gehrke, Koch, Sturm, and
  Elhadad]{caruana2015intelligible}
Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, and Noemie
  Elhadad.
\newblock Intelligible models for healthcare: Predicting pneumonia risk and
  hospital 30-day readmission.
\newblock In \emph{Proceedings of the 21th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pages 1721--1730, 2015.

\bibitem[Chen et~al.(2021)Chen, Kong, Yu, Luque, Goldstein, and
  Huang]{chen2021instars}
Chen Chen, Kezhi Kong, Peihong Yu, Juan Luque, Tom Goldstein, and Furong Huang.
\newblock {Insta-RS}: Instance-wise randomized smoothing for improved
  robustness and accuracy, 2021.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{pmlr-v97-cohen19c}
Jeremy Cohen, Elan Rosenfeld, and Zico Kolter.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors,
  \emph{Proceedings of the 36th International Conference on Machine Learning},
  volume~97 of \emph{Proceedings of Machine Learning Research}, pages
  1310--1320, Long Beach, California, USA, 09--15 Jun 2019. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v97/cohen19c.html}.

\bibitem[Croce and Hein(2020)]{Croce2020Provable}
Francesco Croce and Matthias Hein.
\newblock Provable robustness against all adversarial $l_p$-perturbations for
  $p\geq 1$.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=rklk_ySYPB}.

\bibitem[Croce et~al.(2019)Croce, Andriushchenko, and Hein]{pmlr-v89-croce19a}
Francesco Croce, Maksym Andriushchenko, and Matthias Hein.
\newblock Provable robustness of {ReLU} networks via maximization of linear
  regions.
\newblock In Kamalika Chaudhuri and Masashi Sugiyama, editors,
  \emph{Proceedings of Machine Learning Research}, volume~89 of
  \emph{Proceedings of Machine Learning Research}, pages 2057--2066. PMLR,
  16--18 Apr 2019.
\newblock URL \url{http://proceedings.mlr.press/v89/croce19a.html}.

\bibitem[Dvijotham et~al.(2020)Dvijotham, Hayes, Balle, Kolter, Qin, Gyorgy,
  Xiao, Gowal, and Kohli]{dvijotham2020a}
Krishnamurthy~(Dj) Dvijotham, Jamie Hayes, Borja Balle, Zico Kolter, Chongli
  Qin, Andras Gyorgy, Kai Xiao, Sven Gowal, and Pushmeet Kohli.
\newblock A framework for robustness certification of smoothed classifiers
  using f-divergences.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=SJlKrkSFPH}.

\bibitem[Engstrom et~al.(2019)Engstrom, Ilyas, Santurkar, Tsipras, Tran, and
  Madry]{engstrom2019adversarial}
Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Brandon
  Tran, and Aleksander Madry.
\newblock Adversarial robustness as a prior for learned representations.
\newblock \emph{arXiv preprint arXiv:1906.00945}, 2019.

\bibitem[Gehr et~al.(2018)Gehr, Mirman, Drachsler-Cohen, Tsankov, Chaudhuri,
  and Vechev]{gehr2018ai2}
Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat
  Chaudhuri, and Martin Vechev.
\newblock Ai2: Safety and robustness certification of neural networks with
  abstract interpretation.
\newblock In \emph{2018 IEEE Symposium on Security and Privacy}, pages 3--18.
  IEEE, 2018.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Gowal et~al.(2019)Gowal, Dvijotham, Stanforth, Bunel, Qin, Uesato,
  Arandjelovic, Mann, and Kohli]{gowal2019scalable}
Sven Gowal, Krishnamurthy~Dj Dvijotham, Robert Stanforth, Rudy Bunel, Chongli
  Qin, Jonathan Uesato, Relja Arandjelovic, Timothy Mann, and Pushmeet Kohli.
\newblock Scalable verified training for provably robust image classification.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 4842--4851, 2019.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{pmlr-v70-guo17a}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q. Weinberger.
\newblock On calibration of modern neural networks.
\newblock In Doina Precup and Yee~Whye Teh, editors, \emph{Proceedings of the
  34th International Conference on Machine Learning}, volume~70 of
  \emph{Proceedings of Machine Learning Research}, pages 1321--1330,
  International Convention Centre, Sydney, Australia, 06--11 Aug 2017. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v70/guo17a.html}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 770--778, 2016.

\bibitem[Hendrycks and Gimpel(2017)]{hendrycks2016baseline}
Dan Hendrycks and Kevin Gimpel.
\newblock A baseline for detecting misclassified and out-of-distribution
  examples in neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2017.
\newblock URL \url{https://openreview.net/forum?id=Hkg4TI9xl}.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Mazeika, Kadavath, and
  Song]{hendrycks2019self}
Dan Hendrycks, Mantas Mazeika, Saurav Kadavath, and Dawn Song.
\newblock Using self-supervised learning can improve model robustness and
  uncertainty.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32. Curran Associates, Inc., 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/file/a2b15837edac15df90721968986f7f8e-Paper.pdf}.

\bibitem[Jeong and Shin(2020)]{jeong2020consistency}
Jongheon Jeong and Jinwoo Shin.
\newblock Consistency regularization for certified robustness of smoothed
  classifiers.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Jiang et~al.(2018)Jiang, Kim, Guan, and Gupta]{NEURIPS2018_7180cffd}
Heinrich Jiang, Been Kim, Melody Guan, and Maya Gupta.
\newblock To trust or not to trust a classifier.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, \emph{Advances in Neural Information Processing
  Systems}, volume~31, pages 5541--5552. Curran Associates, Inc., 2018.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2018/file/7180cffd6a8e829dacfc2a31b3f72ece-Paper.pdf}.

\bibitem[Kang et~al.(2020)Kang, Sun, Hendrycks, Brown, and
  Steinhardt]{kang2020testing}
Daniel Kang, Yi~Sun, Dan Hendrycks, Tom Brown, and Jacob Steinhardt.
\newblock Testing robustness against unforeseen adversaries, 2020.

\bibitem[Kaur et~al.(2019)Kaur, Cohen, and Lipton]{kaur2019perceptually}
Simran Kaur, Jeremy Cohen, and Zachary~C Lipton.
\newblock Are perceptually-aligned gradients a general property of robust
  classifiers?
\newblock \emph{arXiv preprint arXiv:1910.08640}, 2019.

\bibitem[Kim et~al.(2020)Kim, Choo, and Song]{pmlr-v119-kim20b}
Jang-Hyun Kim, Wonho Choo, and Hyun~Oh Song.
\newblock Puzzle {Mix}: Exploiting saliency and local statistics for optimal
  mixup.
\newblock In Hal~Daum√© III and Aarti Singh, editors, \emph{Proceedings of the
  37th International Conference on Machine Learning}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 5275--5285. PMLR,
  13--18 Jul 2020.
\newblock URL \url{http://proceedings.mlr.press/v119/kim20b.html}.

\bibitem[Kim et~al.(2021)Kim, Choo, Jeong, and Song]{kim2021comixup}
JangHyun Kim, Wonho Choo, Hosan Jeong, and Hyun~Oh Song.
\newblock {Co-Mixup}: Saliency guided joint mixup with supermodular diversity.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=gvxJzw8kW4b}.

\bibitem[Krizhevsky(2009)]{dataset/cifar}
Alex Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, Department of Computer Science, University of
  Toronto, 2009.

\bibitem[Kumar et~al.(2019)Kumar, Liang, and Ma]{NEURIPS2019_f8c0c968}
Ananya Kumar, Percy~S Liang, and Tengyu Ma.
\newblock Verified uncertainty calibration.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, pages 3792--3803. Curran Associates, Inc., 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/file/f8c0c968632845cd133308b1a494967f-Paper.pdf}.

\bibitem[Lamb et~al.(2019)Lamb, Verma, Kannala, and
  Bengio]{lamb2019interpolated}
Alex Lamb, Vikas Verma, Juho Kannala, and Yoshua Bengio.
\newblock Interpolated adversarial training: Achieving robust neural networks
  without sacrificing too much accuracy.
\newblock In \emph{Proceedings of the 12th ACM Workshop on Artificial
  Intelligence and Security}, pages 95--103, 2019.

\bibitem[{Le{C}un} et~al.(1998){Le{C}un}, {Bottou}, {Bengio}, and
  {Haffner}]{dataset/mnist}
Y.~{Le{C}un}, L.~{Bottou}, Y.~{Bengio}, and P.~{Haffner}.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, Nov 1998.
\newblock ISSN 1558-2256.
\newblock \doi{10.1109/5.726791}.

\bibitem[Lecuyer et~al.(2019)Lecuyer, Atlidakis, Geambasu, Hsu, and
  Jana]{lecuyer2019certified}
Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman
  Jana.
\newblock Certified robustness to adversarial examples with differential
  privacy.
\newblock In \emph{2019 IEEE Symposium on Security and Privacy (SP)}, pages
  656--672. IEEE, 2019.

\bibitem[Lee et~al.(2019)Lee, Yuan, Chang, and Jaakkola]{lee2019tight}
Guang-He Lee, Yang Yuan, Shiyu Chang, and Tommi Jaakkola.
\newblock Tight certificates of adversarial robustness for randomly smoothed
  classifiers.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, pages 4910--4921. Curran Associates, Inc., 2019.

\bibitem[Lee et~al.(2017)Lee, Hwang, Park, and Shin]{pmlr-v70-lee17b}
Kimin Lee, Changho Hwang, KyoungSoo Park, and Jinwoo Shin.
\newblock Confident multiple choice learning.
\newblock In Doina Precup and Yee~Whye Teh, editors, \emph{Proceedings of the
  34th International Conference on Machine Learning}, volume~70 of
  \emph{Proceedings of Machine Learning Research}, pages 2014--2023,
  International Convention Centre, Sydney, Australia, 06--11 Aug 2017. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v70/lee17b.html}.

\bibitem[Lee et~al.(2018)Lee, Lee, Lee, and Shin]{lee2018training}
Kimin Lee, Honglak Lee, Kibok Lee, and Jinwoo Shin.
\newblock Training confidence-calibrated classifiers for detecting
  out-of-distribution samples.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=ryiAv2xAZ}.

\bibitem[Lee et~al.(2020)Lee, Lee, and Yoon]{lee2020adversarial}
Saehyung Lee, Hyungyu Lee, and Sungroh Yoon.
\newblock Adversarial vertex mixup: Toward better adversarially robust
  generalization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 272--281, 2020.

\bibitem[Li et~al.(2019)Li, Chen, Wang, and Carin]{li2019stab}
Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin.
\newblock Certified adversarial robustness with additive noise.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pages
  9464--9474. Curran Associates, Inc., 2019.

\bibitem[Li et~al.(2020)Li, Qi, Xie, and Li]{li2020sokcertified}
Linyi Li, Xiangyu Qi, Tao Xie, and Bo~Li.
\newblock {SoK}: Certified robustness for deep neural networks.
\newblock \emph{arXiv preprint arXiv:2009.04131}, 2020.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=rJzIBfZAb}.

\bibitem[Meinke and Hein(2020)]{Meinke2020Towards}
Alexander Meinke and Matthias Hein.
\newblock Towards neural networks that provably know when they don't know.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=ByxGkySKwH}.

\bibitem[Mirman et~al.(2018)Mirman, Gehr, and Vechev]{pmlr-v80-mirman18b}
Matthew Mirman, Timon Gehr, and Martin Vechev.
\newblock Differentiable abstract interpretation for provably robust neural
  networks.
\newblock In Jennifer Dy and Andreas Krause, editors, \emph{Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of
  \emph{Proceedings of Machine Learning Research}, pages 3578--3586,
  Stockholmsm√§ssan, Stockholm Sweden, 10--15 Jul 2018. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v80/mirman18b.html}.

\bibitem[Mohapatra et~al.(2020)Mohapatra, Ko, Weng, Chen, Liu, and
  Daniel]{mohapatra2020higher}
Jeet Mohapatra, Ching-Yun Ko, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, and Luca
  Daniel.
\newblock Higher-order certification for randomized smoothing.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Moosavi-Dezfooli et~al.(2016)Moosavi-Dezfooli, Fawzi, and
  Frossard]{moosavi2016deepfool}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard.
\newblock Deep{F}ool: a simple and accurate method to fool deep neural
  networks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2574--2582, 2016.

\bibitem[Pereyra et~al.(2017)Pereyra, Tucker, Chorowski, Kaiser, and
  Hinton]{pereyra2017regularizing}
Gabriel Pereyra, George Tucker, Jan Chorowski, {\L}ukasz Kaiser, and Geoffrey
  Hinton.
\newblock Regularizing neural networks by penalizing confident output
  distributions.
\newblock \emph{arXiv preprint arXiv:1701.06548}, 2017.

\bibitem[Qin et~al.(2019)Qin, Carlini, Cottrell, Goodfellow, and
  Raffel]{qin2019speech}
Yao Qin, Nicholas Carlini, Garrison Cottrell, Ian Goodfellow, and Colin Raffel.
\newblock Imperceptible, robust, and targeted adversarial examples for
  automatic speech recognition.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, volume~97 of \emph{Proceedings of Machine Learning Research},
  pages 5231--5240, Long Beach, California, USA, 09--15 Jun 2019. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v97/qin19a.html}.

\bibitem[Rice et~al.(2020)Rice, Wong, and Kolter]{pmlr-v119-rice20a}
Leslie Rice, Eric Wong, and Zico Kolter.
\newblock Overfitting in adversarially robust deep learning.
\newblock In Hal~Daum√© III and Aarti Singh, editors, \emph{Proceedings of the
  37th International Conference on Machine Learning}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 8093--8104. PMLR,
  13--18 Jul 2020.
\newblock URL \url{http://proceedings.mlr.press/v119/rice20a.html}.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{dataset/ilsvrc}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein,
  Alexander~C. Berg, and Li~Fei-Fei.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock \emph{International Journal of Computer Vision}, 115\penalty0
  (3):\penalty0 211--252, 2015.
\newblock \doi{10.1007/s11263-015-0816-y}.

\bibitem[Salman et~al.(2019)Salman, Li, Razenshteyn, Zhang, Zhang, Bubeck, and
  Yang]{nips_salman19}
Hadi Salman, Jerry Li, Ilya Razenshteyn, Pengchuan Zhang, Huan Zhang, Sebastien
  Bubeck, and Greg Yang.
\newblock Provably robust deep learning via adversarially trained smoothed
  classifiers.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pages
  11289--11300. Curran Associates, Inc., 2019.

\bibitem[Santurkar et~al.(2019)Santurkar, Ilyas, Tsipras, Engstrom, Tran, and
  Madry]{santurkar2019cvrobust}
Shibani Santurkar, Andrew Ilyas, Dimitris Tsipras, Logan Engstrom, Brandon
  Tran, and Aleksander Madry.
\newblock Image synthesis with a single (robust) classifier.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, pages 1262--1273. Curran Associates, Inc., 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/file/6f2268bd1d3d3ebaabb04d6b5d099425-Paper.pdf}.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  Madry]{schmidt2018adversarially}
Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, and
  Aleksander Madry.
\newblock Adversarially robust generalization requires more data.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Stutz et~al.(2020)Stutz, Hein, and Schiele]{pmlr-v119-stutz20a}
David Stutz, Matthias Hein, and Bernt Schiele.
\newblock Confidence-calibrated adversarial training: Generalizing to unseen
  attacks.
\newblock In Hal~Daum√© III and Aarti Singh, editors, \emph{Proceedings of the
  37th International Conference on Machine Learning}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 9155--9166. PMLR,
  13--18 Jul 2020.
\newblock URL \url{http://proceedings.mlr.press/v119/stutz20a.html}.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Tack et~al.(2020)Tack, Mo, Jeong, and Shin]{tack2020csi}
Jihoon Tack, Sangwoo Mo, Jongheon Jeong, and Jinwoo Shin.
\newblock {CSI}: Novelty detection via contrastive learning on distributionally
  shifted instances.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 11839--11852. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/file/8965f76632d7672e7d3cf29c87ecaa0c-Paper.pdf}.

\bibitem[Tramer et~al.(2020)Tramer, Carlini, Brendel, and
  Madry]{tramer2020adaptive}
Florian Tramer, Nicholas Carlini, Wieland Brendel, and Aleksander Madry.
\newblock On adaptive attacks to adversarial example defenses.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, 2020.

\bibitem[Tsipras et~al.(2019)Tsipras, Santurkar, Engstrom, Turner, and
  Madry]{tsipras2018robustness}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
  Aleksander Madry.
\newblock Robustness may be at odds with accuracy.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=SyxAb30cY7}.

\bibitem[Verma et~al.(2019)Verma, Lamb, Beckham, Najafi, Mitliagkas, Lopez-Paz,
  and Bengio]{pmlr-v97-verma19a}
Vikas Verma, Alex Lamb, Christopher Beckham, Amir Najafi, Ioannis Mitliagkas,
  David Lopez-Paz, and Yoshua Bengio.
\newblock Manifold mixup: Better representations by interpolating hidden
  states.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors,
  \emph{Proceedings of the 36th International Conference on Machine Learning},
  volume~97 of \emph{Proceedings of Machine Learning Research}, pages
  6438--6447. PMLR, 09--15 Jun 2019.
\newblock URL \url{http://proceedings.mlr.press/v97/verma19a.html}.

\bibitem[Wang et~al.(2021)Wang, Zhai, He, Wang, and
  Jian]{wang2021pretraintofinetune}
Lei Wang, Runtian Zhai, Di~He, Liwei Wang, and Li~Jian.
\newblock Pretrain-to-finetune adversarial training via sample-wise randomized
  smoothing, 2021.
\newblock URL \url{https://openreview.net/forum?id=Te1aZ2myPIu}.

\bibitem[Wong and Kolter(2018)]{pmlr-v80-wong18a}
Eric Wong and Zico Kolter.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In Jennifer Dy and Andreas Krause, editors, \emph{Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of
  \emph{Proceedings of Machine Learning Research}, pages 5286--5295,
  Stockholmsm√§ssan, Stockholm Sweden, 10--15 Jul 2018. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v80/wong18a.html}.

\bibitem[Xiao et~al.(2018)Xiao, Zhu, Li, He, Liu, and Song]{xiao2018spatially}
Chaowei Xiao, Jun-Yan Zhu, Bo~Li, Warren He, Mingyan Liu, and Dawn Song.
\newblock Spatially transformed adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=HyydRMZC-}.

\bibitem[Xiao et~al.(2019)Xiao, Tjeng, Shafiullah, and Madry]{xiao2018training}
Kai~Y. Xiao, Vincent Tjeng, Nur Muhammad~(Mahi) Shafiullah, and Aleksander
  Madry.
\newblock Training for faster adversarial robustness verification via inducing
  {ReLU} stability.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=BJfIVjAcKm}.

\bibitem[Yang et~al.(2020)Yang, Duan, Hu, Salman, Razenshteyn, and
  Li]{pmlr-v119-yang20c}
Greg Yang, Tony Duan, J.~Edward Hu, Hadi Salman, Ilya Razenshteyn, and Jerry
  Li.
\newblock Randomized smoothing of all shapes and sizes.
\newblock In Hal~Daum√© III and Aarti Singh, editors, \emph{Proceedings of the
  37th International Conference on Machine Learning}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 10693--10705. PMLR,
  13--18 Jul 2020.
\newblock URL \url{http://proceedings.mlr.press/v119/yang20c.html}.

\bibitem[Yun et~al.(2019)Yun, Han, Oh, Chun, Choe, and Yoo]{yun2019cutmix}
Sangdoo Yun, Dongyoon Han, Seong~Joon Oh, Sanghyuk Chun, Junsuk Choe, and
  Youngjoon Yoo.
\newblock {CutMix}: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 6023--6032, 2019.

\bibitem[Yurtsever et~al.(2020)Yurtsever, Lambert, Carballo, and
  Takeda]{yurtsever2020survey}
Ekim Yurtsever, Jacob Lambert, Alexander Carballo, and Kazuya Takeda.
\newblock A survey of autonomous driving: Common practices and emerging
  technologies.
\newblock \emph{IEEE Access}, 8:\penalty0 58443--58469, 2020.

\bibitem[Zhai et~al.(2020)Zhai, Dan, He, Zhang, Gong, Ravikumar, Hsieh, and
  Wang]{Zhai2020MACER}
Runtian Zhai, Chen Dan, Di~He, Huan Zhang, Boqing Gong, Pradeep Ravikumar,
  Cho-Jui Hsieh, and Liwei Wang.
\newblock {MACER}: Attack-free and scalable robust training via maximizing
  certified radius.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=rJx1Na4Fwr}.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, Ghaoui, and
  Jordan]{pmlr-v97-zhang19p}
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent~El Ghaoui, and
  Michael Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, volume~97 of \emph{Proceedings of Machine Learning Research},
  pages 7472--7482, Long Beach, California, USA, 09--15 Jun 2019. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v97/zhang19p.html}.

\bibitem[Zhang et~al.(2018)Zhang, Cisse, Dauphin, and
  Lopez-Paz]{zhang2018mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N. Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=r1Ddp1-Rb}.

\bibitem[Zhang et~al.(2020{\natexlab{a}})Zhang, Chen, Xiao, Gowal, Stanforth,
  Li, Boning, and Hsieh]{zhang2020towards}
Huan Zhang, Hongge Chen, Chaowei Xiao, Sven Gowal, Robert Stanforth, Bo~Li,
  Duane Boning, and Cho-Jui Hsieh.
\newblock Towards stable and efficient training of verifiably robust neural
  networks.
\newblock In \emph{International Conference on Learning Representations},
  2020{\natexlab{a}}.
\newblock URL \url{https://openreview.net/forum?id=Skxuk1rFwB}.

\bibitem[Zhang et~al.(2020{\natexlab{b}})Zhang, Xu, Han, Niu, Cui, Sugiyama,
  and Kankanhalli]{pmlr-v119-zhang20z}
Jingfeng Zhang, Xilie Xu, Bo~Han, Gang Niu, Lizhen Cui, Masashi Sugiyama, and
  Mohan Kankanhalli.
\newblock Attacks which do not kill training make adversarial learning
  stronger.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, volume 119 of \emph{Proceedings of Machine Learning Research},
  pages 11278--11287. PMLR, 13--18 Jul 2020{\natexlab{b}}.
\newblock URL \url{http://proceedings.mlr.press/v119/zhang20z.html}.

\bibitem[Zhang et~al.(2021)Zhang, Deng, Kawaguchi, Ghorbani, and
  Zou]{zhang2021how}
Linjun Zhang, Zhun Deng, Kenji Kawaguchi, Amirata Ghorbani, and James Zou.
\newblock How does mixup help with robustness and generalization?
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=8yKEo06dKNo}.

\end{thebibliography}
