@article{rakelly2019efficient,
  title   = {Efficient off-policy meta-reinforcement learning via probabilistic context variables},
  author  = {Rakelly, Kate and Zhou, Aurick and Quillen, Deirdre and Finn, Chelsea and Levine, Sergey},
  journal = {arXiv preprint arXiv:1903.08254},
  year    = {2019}
}

@article{zhang2022off,
  title={Off-Policy Fitted Q-Evaluation with Differentiable Function Approximators: Z-Estimation and Inference Theory},
  author={Zhang, Ruiqi and Zhang, Xuezhou and Ni, Chengzhuo and Wang, Mengdi},
  journal={International Conference on Machine Learning},
  year={2022}
}

@inproceedings{yin2020asymptotically,
  title={Asymptotically efficient off-policy evaluation for tabular reinforcement learning},
  author={Yin, Ming and Wang, Yu-Xiang},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3948--3958},
  year={2020},
  organization={PMLR}
}


@inproceedings{duan2020minimax,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020},
  organization={PMLR}
}

@article{li2006towards,
  title={Towards a Unified Theory of State Abstraction for MDPs.},
  author={Li, Lihong and Walsh, Thomas J and Littman, Michael L},
  journal={ISAIM},
  volume={4},
  number={5},
  pages={9},
  year={2006}
}

@inproceedings{jin2021pessimism,
  title={Is pessimism provably efficient for offline rl?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={5084--5096},
  year={2021},
  organization={PMLR}
}

@article{yin2022near,
  title={Near-optimal offline reinforcement learning with linear representation: Leveraging variance information with pessimism},
  author={Yin, Ming and Duan, Yaqi and Wang, Mengdi and Wang, Yu-Xiang},
  journal={International Conference on Learning Representations},
  year={2022}
}

@book{kakade2003sample,
  title={On the sample complexity of reinforcement learning},
  author={Kakade, Sham Machandranath},
  year={2003},
  publisher={University of London, University College London (United Kingdom)}
}

@article{zou2019finite,
  title={Finite-sample analysis for sarsa with linear function approximation},
  author={Zou, Shaofeng and Xu, Tengyu and Liang, Yingbin},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={In Proc. 19th International Conference on Machine Learning},
  year={2002},
  organization={Citeseer}
}

@inproceedings{chen2019information,
  title={Information-theoretic considerations in batch reinforcement learning},
  author={Chen, Jinglin and Jiang, Nan},
  booktitle={International Conference on Machine Learning},
  pages={1042--1051},
  year={2019},
  organization={PMLR}
}

@article{perkins2002convergent,
  title={A convergent form of approximate policy iteration},
  author={Perkins, Theodore and Precup, Doina},
  journal={Advances in neural information processing systems},
  volume={15},
  year={2002}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{reynolds2009gaussian,
  title={Gaussian mixture models.},
  author={Reynolds, Douglas A},
  journal={Encyclopedia of biometrics},
  volume={741},
  number={659-663},
  year={2009},
  publisher={Berlin, Springer}
}

@article{kumar2019stabilizing,
  title   = {Stabilizing off-policy q-learning via bootstrapping error reduction},
  author  = {Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {32},
  year    = {2019}
}
@article{peng2019advantage,
  title   = {Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
  author  = {Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal = {arXiv preprint arXiv:1910.00177},
  year    = {2019}
}
@inproceedings{fujimoto2019off,
  title     = {Off-Policy Deep Reinforcement Learning without Exploration},
  author    = {Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle = {International Conference on Machine Learning},
  pages     = {2052--2062},
  year      = {2019}
}
@inproceedings{fujimoto2021minimalist,
  title     = {A Minimalist Approach to Offline Reinforcement Learning},
  author    = {Scott Fujimoto and Shixiang Shane Gu},
  booktitle = {Thirty-Fifth Conference on Neural Information Processing Systems},
  year      = {2021}
}
@misc{oac,
  title         = {Better Exploration with Optimistic Actor-Critic},
  author        = {Kamil Ciosek and Quan Vuong and Robert Loftin and Katja Hofmann},
  year          = {2019},
  eprint        = {1910.12807},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML}
}
@inproceedings{AgostiniGaussianMixture,
  author    = {Agostini, Alejandro and Celaya, Enric},
  booktitle = {The 2010 International Joint Conference on Neural Networks (IJCNN)},
  title     = {Reinforcement Learning with a Gaussian mixture model},
  year      = {2010},
  volume    = {},
  number    = {},
  pages     = {1-8},
  doi       = {10.1109/IJCNN.2010.5596306}
}


@article{brandfonbrener2021offline,
  title   = {Offline RL Without Off-Policy Evaluation},
  author  = {Brandfonbrener, David and Whitney, William F and Ranganath, Rajesh and Bruna, Joan},
  journal = {arXiv preprint arXiv:2106.08909},
  year    = {2021}
}
@inproceedings{goo2022you,
  title        = {You Only Evaluate Once: a Simple Baseline Algorithm for Offline RL},
  author       = {Goo, Wonjoon and Niekum, Scott},
  booktitle    = {Conference on Robot Learning},
  pages        = {1543--1553},
  year         = {2022},
  organization = {PMLR}
}

@article{levine2020offline,
  title   = {Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author  = {Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal = {arXiv preprint arXiv:2005.01643},
  year    = {2020}
}
@inproceedings{wang2021instabilities,
  title        = {Instabilities of offline rl with pre-trained neural representation},
  author       = {Wang, Ruosong and Wu, Yifan and Salakhutdinov, Ruslan and Kakade, Sham},
  booktitle    = {International Conference on Machine Learning},
  pages        = {10948--10960},
  year         = {2021},
  organization = {PMLR}
}
@article{siegel2020keep,
  title   = {Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning},
  author  = {Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Riedmiller, Martin},
  journal = {arXiv preprint arXiv:2002.08396},
  year    = {2020}
}

@inproceedings{zintgraf2020varibad,
  title     = {VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning},
  author    = {Zintgraf, Luisa and Shiarlis, Kyriacos and Igl, Maximilian and Schulze, Sebastian and Gal, Yarin and Hofmann, Katja and Whiteson, Shimon},
  booktitle = {International Conference on Learning Representation (ICLR)},
  year      = {2020}
}

@article{agarwal2019optimistic,
  title   = {An Optimistic Perspective on Offline Reinforcement Learning},
  author  = {Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  journal = {arXiv preprint arXiv:1907.04543},
  year    = {2019}
}

@inproceedings{todorov2012mujoco,
  title        = {Mujoco: A physics engine for model-based control},
  author       = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle    = {2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages        = {5026--5033},
  year         = {2012},
  organization = {IEEE}
}

@article{haarnoja2018soft,
  title   = {Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author  = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal = {arXiv preprint arXiv:1801.01290},
  year    = {2018}
}

@article{hermans2017defense,
  title   = {In defense of the triplet loss for person re-identification},
  author  = {Hermans, Alexander and Beyer, Lucas and Leibe, Bastian},
  journal = {arXiv preprint arXiv:1703.07737},
  year    = {2017}
}

@inproceedings{chua2018deep,
  title     = {Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author    = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {4754--4765},
  year      = {2018}
}

@article{kingma2013auto,
  title   = {Auto-encoding variational bayes},
  author  = {Kingma, Diederik P and Welling, Max},
  journal = {arXiv preprint arXiv:1312.6114},
  year    = {2013}
}

@inproceedings{van2016deep,
  title     = {Deep reinforcement learning with double q-learning},
  author    = {Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle = {Thirtieth AAAI conference on artificial intelligence},
  year      = {2016}
}

@article{cabi2020ScalingDR,
  title   = {Scaling data-driven robotics with reward sketching and batch reinforcement learning.},
  author  = {Serkan Cabi and Sergio G{\'o}mez Colmenarejo and Alexander Novikov and Ksenia Konyushkova and Scott Reed and Rae Jeong and Konrad Zolna and Yusuf Aytar and David Budden and Mel Vecer{\'i}k and Oleg Sushkov and David J. P. Barker and Jonathan Scholz and Misha Denil and Nando de Freitas and Ziyu Wang},
  journal = {arXiv: Robotics},
  year    = {2020}
}

@inproceedings{IL_Pieter,
  author    = {Abbeel, Pieter and Ng, Andrew Y.},
  title     = {Apprenticeship Learning via Inverse Reinforcement Learning},
  booktitle = {Proceedings of the Twenty-first International Conference on Machine Learning},
  series    = {ICML '04},
  year      = {2004},
  isbn      = {1-58113-838-5},
  location  = {Banff, Alberta, Canada},
  pages     = {1--},
  url       = {http://doi.acm.org/10.1145/1015330.1015430},
  doi       = {10.1145/1015330.1015430},
  acmid     = {1015430},
  publisher = {ACM},
  address   = {New York, NY, USA}
} 

@article{GAIL,
  author        = {Jonathan Ho and
                   Stefano Ermon},
  title         = {Generative Adversarial Imitation Learning},
  journal       = {CoRR},
  volume        = {abs/1606.03476},
  year          = {2016},
  url           = {http://arxiv.org/abs/1606.03476},
  archiveprefix = {arXiv},
  eprint        = {1606.03476},
  timestamp     = {Mon, 13 Aug 2018 16:47:10 +0200},
  biburl        = {https://dblp.org/rec/bib/journals/corr/HoE16},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{LearnToReinforceLearnWang2016,
  author        = {Jane X. Wang and
                   Zeb Kurth{-}Nelson and
                   Dhruva Tirumala and
                   Hubert Soyer and
                   Joel Z. Leibo and
                   R{\'{e}}mi Munos and
                   Charles Blundell and
                   Dharshan Kumaran and
                   Matthew Botvinick},
  title         = {Learning to reinforcement learn},
  journal       = {CoRR},
  volume        = {abs/1611.05763},
  year          = {2016},
  url           = {http://arxiv.org/abs/1611.05763},
  archiveprefix = {arXiv},
  eprint        = {1611.05763},
  timestamp     = {Mon, 13 Aug 2018 16:47:12 +0200},
  biburl        = {https://dblp.org/rec/bib/journals/corr/WangKTSLMBKB16},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{MAMLFinn2017,
  author        = {Chelsea Finn and
                   Pieter Abbeel and
                   Sergey Levine},
  title         = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  journal       = {CoRR},
  volume        = {abs/1703.03400},
  year          = {2017},
  url           = {http://arxiv.org/abs/1703.03400},
  archiveprefix = {arXiv},
  eprint        = {1703.03400},
  timestamp     = {Mon, 13 Aug 2018 16:47:43 +0200},
  biburl        = {https://dblp.org/rec/bib/journals/corr/FinnAL17},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{CAVIA,
  title     = {Fast Context Adaptation via Meta-Learning},
  author    = {Zintgraf, Luisa and Shiarli, Kyriacos and Kurin, Vitaly and Hofmann, Katja and Whiteson, Shimon},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages     = {7693--7702},
  year      = {2019},
  editor    = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume    = {97},
  series    = {Proceedings of Machine Learning Research},
  address   = {Long Beach, California, USA},
  month     = {09--15 Jun},
  publisher = {PMLR}
}

@incollection{HiddenParamTaylor2017,
  title     = {Robust and Efficient Transfer Learning with Hidden Parameter Markov Decision Processes},
  author    = {Killian, Taylor W and Daulton, Samuel and Konidaris, George and Doshi-Velez, Finale},
  booktitle = {Advances in Neural Information Processing Systems 30},
  editor    = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages     = {6250--6261},
  year      = {2017},
  publisher = {Curran Associates, Inc.},
  url       = {http://papers.nips.cc/paper/7205-robust-and-efficient-transfer-learning-with-hidden-parameter-markov-decision-processes.pdf}
}

@article{benchmarkingWang2019,
  author  = {Tingwu Wang and
             Xuchan Bao and
             Ignasi Clavera and
             Jerrick Hoang and
             Yeming Wen and
             Eric Langlois and
             Shunshi Zhang and
             Guodong Zhang and
             Pieter Abbeel and
             Jimmy Ba},
  title   = {Benchmarking Model-Based Reinforcement Learning},
  journal = {CoRR},
  volume  = {abs/1907.02057},
  year    = {2019},
  url     = {http://arxiv.org/abs/1907.02057}
}

@article{ActorMimicParisotto2015,
  title   = {Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning},
  author  = {Emilio Parisotto and Jimmy Ba and Ruslan Salakhutdinov},
  journal = {CoRR},
  year    = {2015},
  volume  = {abs/1511.06342}
}

@article{caruana1997multitask,
  title     = {Multitask learning},
  author    = {Caruana, Rich},
  journal   = {Machine learning},
  volume    = {28},
  number    = {1},
  pages     = {41--75},
  year      = {1997},
  publisher = {Springer}
}

@article{yang2020multi,
  title   = {Multi-Task Reinforcement Learning with Soft Modularization},
  author  = {Yang, Ruihan and Xu, Huazhe and Wu, Yi and Wang, Xiaolong},
  journal = {arXiv preprint arXiv:2003.13661},
  year    = {2020}
}

@article{espeholt2018impala,
  title   = {Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author  = {Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  journal = {arXiv preprint arXiv:1802.01561},
  year    = {2018}
}

@article{yumulti,
  title  = {Multi-Task Reinforcement Learning without Interference},
  author = {Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  url    = {https://optrl2019.github.io/assets/accepted_papers/16.pdf}
}

@article{rusu2015policy,
  title   = {Policy distillation},
  author  = {Rusu, Andrei A and Colmenarejo, Sergio Gomez and Gulcehre, Caglar and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
  journal = {arXiv preprint arXiv:1511.06295},
  year    = {2015}
}

@article{levine2016end,
  title     = {End-to-end training of deep visuomotor policies},
  author    = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal   = {The Journal of Machine Learning Research},
  volume    = {17},
  number    = {1},
  pages     = {1334--1373},
  year      = {2016},
  publisher = {JMLR. org}
}

@inproceedings{teh2017distral,
  title     = {Distral: Robust multitask reinforcement learning},
  author    = {Teh, Yee and Bapst, Victor and Czarnecki, Wojciech M and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {4496--4506},
  year      = {2017}
}

@article{ghosh2017divide,
  title   = {Divide-and-conquer reinforcement learning},
  author  = {Ghosh, Dibya and Singh, Avi and Rajeswaran, Aravind and Kumar, Vikash and Levine, Sergey},
  journal = {arXiv preprint arXiv:1711.09874},
  year    = {2017}
}

@article{czarnecki2019distilling,
  title   = {Distilling policy distillation},
  author  = {Czarnecki, Wojciech Marian and Pascanu, Razvan and Osindero, Simon and Jayakumar, Siddhant M and Swirszcz, Grzegorz and Jaderberg, Max},
  journal = {arXiv preprint arXiv:1902.02186},
  year    = {2019}
}

@article{fakoor2019meta,
  title   = {Meta-Q-Learning},
  author  = {Fakoor, Rasool and Chaudhari, Pratik and Soatto, Stefano and Smola, Alexander J},
  journal = {arXiv preprint arXiv:1910.00125},
  year    = {2019}
}

@article{humplik2019meta,
  title   = {Meta reinforcement learning as task inference},
  author  = {Humplik, Jan and Galashov, Alexandre and Hasenclever, Leonard and Ortega, Pedro A and Teh, Yee Whye and Heess, Nicolas},
  journal = {arXiv preprint arXiv:1905.06424},
  year    = {2019}
}

@article{lan2019meta,
  title   = {Meta reinforcement learning with task embedding and shared policy},
  author  = {Lan, Lin and Li, Zhenguo and Guan, Xiaohong and Wang, Pinghui},
  journal = {arXiv preprint arXiv:1905.06527},
  year    = {2019}
}

@article{saemundsson2018meta,
  title   = {Meta reinforcement learning with latent variable gaussian processes},
  author  = {S{\ae}mundsson, Steind{\'o}r and Hofmann, Katja and Deisenroth, Marc Peter},
  journal = {arXiv preprint arXiv:1803.07551},
  year    = {2018}
}

@article{duan2016rl,
  title   = {RL{\textdollar}{\^{}}2{\textdollar}: Fast reinforcement learning via slow reinforcement learning},
  author  = {Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter},
  journal = {arXiv preprint arXiv:1611.02779},
  year    = {2016}
}

@article{chu2017cyclegan,
  title   = {Cyclegan, a master of steganography},
  author  = {Chu, Casey and Zhmoginov, Andrey and Sandler, Mark},
  journal = {arXiv preprint arXiv:1712.02950},
  year    = {2017}
}

@article{chen2019bail,
  title   = {BAIL: Best-Action Imitation Learning for Batch Deep Reinforcement Learning},
  author  = {Chen, Xinyue and Zhou, Zijian and Wang, Zheng and Wang, Che and Wu, Yanqiu and Deng, Qing and Ross, Keith},
  journal = {arXiv preprint arXiv:1910.12179},
  year    = {2019}
}

@article{finn2017maml,
  author        = {Chelsea Finn and
                   Pieter Abbeel and
                   Sergey Levine},
  title         = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  journal       = {CoRR},
  volume        = {abs/1703.03400},
  year          = {2017},
  url           = {http://arxiv.org/abs/1703.03400},
  archiveprefix = {arXiv},
  eprint        = {1703.03400},
  timestamp     = {Mon, 13 Aug 2018 16:47:43 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/FinnAL17.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{nichol2018Reptile,
  author        = {Alex Nichol and
                   Joshua Achiam and
                   John Schulman},
  title         = {On First-Order Meta-Learning Algorithms},
  journal       = {CoRR},
  volume        = {abs/1803.02999},
  year          = {2018},
  url           = {http://arxiv.org/abs/1803.02999},
  archiveprefix = {arXiv},
  eprint        = {1803.02999},
  timestamp     = {Mon, 13 Aug 2018 16:48:00 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1803-02999.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{houthooft2018evolvedpg,
  author        = {Rein Houthooft and
                   Richard Y. Chen and
                   Phillip Isola and
                   Bradly C. Stadie and
                   Filip Wolski and
                   Jonathan Ho and
                   Pieter Abbeel},
  title         = {Evolved Policy Gradients},
  journal       = {CoRR},
  volume        = {abs/1802.04821},
  year          = {2018},
  url           = {http://arxiv.org/abs/1802.04821},
  archiveprefix = {arXiv},
  eprint        = {1802.04821},
  timestamp     = {Mon, 13 Aug 2018 16:49:14 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1802-04821.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@book{pearl_2009,
  place     = {Cambridge},
  title     = {Causality},
  doi       = {10.1017/CBO9780511803161},
  publisher = {Cambridge University Press},
  author    = {Pearl, Judea},
  year      = {2009}
}

@book{Peters2017,
  author    = {Peters, J. and Janzing, D. and Sch\"olkopf, B.},
  title     = {Elements of Causal Inference: Foundations and Learning Algorithms},
  address   = {Cambridge, MA, USA},
  publisher = {MIT Press},
  year      = {2017}
}

@inproceedings{hessel2019multi,
  title     = {Multi-task deep reinforcement learning with popart},
  author    = {Hessel, Matteo and Soyer, Hubert and Espeholt, Lasse and Czarnecki, Wojciech and Schmitt, Simon and van Hasselt, Hado},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {33},
  pages     = {3796--3803},
  year      = {2019}
}

@inproceedings{impala2018,
  title     = {IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures},
  author    = {Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  booktitle = {Proceedings of the International Conference on Machine Learning (ICML)},
  year      = {2018}
}

@inproceedings{de2019causal,
  title     = {Causal confusion in imitation learning},
  author    = {de Haan, Pim and Jayaraman, Dinesh and Levine, Sergey},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {11693--11704},
  year      = {2019}
}

@article{xu2019can,
  title   = {What Can Neural Networks Reason About?},
  author  = {Xu, Keyulu and Li, Jingling and Zhang, Mozhi and Du, Simon S and Kawarabayashi, Ken-ichi and Jegelka, Stefanie},
  journal = {arXiv preprint arXiv:1905.13211},
  year    = {2019}
}

@article{pearl2010introduction,
  title     = {An introduction to causal inference},
  author    = {Pearl, Judea},
  journal   = {The international journal of biostatistics},
  volume    = {6},
  number    = {2},
  year      = {2010},
  publisher = {De Gruyter}
}

@article{pearl2009causal,
  title     = {Causal inference in statistics: An overview},
  author    = {Pearl, Judea and others},
  journal   = {Statistics surveys},
  volume    = {3},
  pages     = {96--146},
  year      = {2009},
  publisher = {The author, under a Creative Commons Attribution License}
}

@article{scarselli2008graph,
  title     = {The graph neural network model},
  author    = {Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  journal   = {IEEE Transactions on Neural Networks},
  volume    = {20},
  number    = {1},
  pages     = {61--80},
  year      = {2008},
  publisher = {IEEE}
}

@article{wu2020comprehensive,
  title     = {A comprehensive survey on graph neural networks},
  author    = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Philip, S Yu},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  year      = {2020},
  publisher = {IEEE}
}

@article{zhou2018graph,
  title   = {Graph neural networks: A review of methods and applications},
  author  = {Zhou, Jie and Cui, Ganqu and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
  journal = {arXiv preprint arXiv:1812.08434},
  year    = {2018}
}

@inproceedings{d2019sharing,
  title     = {Sharing Knowledge in Multi-Task Deep Reinforcement Learning},
  author    = {D'Eramo, Carlo and Tateo, Davide and Bonarini, Andrea and Restelli, Marcello and Peters, Jan},
  booktitle = {International Conference on Learning Representations},
  year      = {2019}
}

@misc{xie2019selftraining,
  title         = {Self-training with Noisy Student improves ImageNet classification},
  author        = {Qizhe Xie and Minh-Thang Luong and Eduard Hovy and Quoc V. Le},
  year          = {2019},
  eprint        = {1911.04252},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{mobahi2020selfdistillation,
  title         = {Self-Distillation Amplifies Regularization in Hilbert Space},
  author        = {Hossein Mobahi and Mehrdad Farajtabar and Peter L. Bartlett},
  year          = {2020},
  eprint        = {2002.05715},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{sharma2020emergent,
  title         = {Emergent Real-World Robotic Skills via Unsupervised Off-Policy Reinforcement Learning},
  author        = {Archit Sharma and Michael Ahn and Sergey Levine and Vikash Kumar and Karol Hausman and Shixiang Gu},
  year          = {2020},
  eprint        = {2004.12974},
  archiveprefix = {arXiv},
  primaryclass  = {cs.RO}
}

@article{peng2019MCP,
  author        = {Xue Bin Peng and
                   Michael Chang and
                   Grace Zhang and
                   Pieter Abbeel and
                   Sergey Levine},
  title         = {{MCP:} Learning Composable Hierarchical Control with Multiplicative
                   Compositional Policies},
  journal       = {CoRR},
  volume        = {abs/1905.09808},
  year          = {2019},
  url           = {http://arxiv.org/abs/1905.09808},
  archiveprefix = {arXiv},
  eprint        = {1905.09808},
  timestamp     = {Wed, 29 May 2019 11:27:50 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1905-09808.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}


@article{TD3,
  author        = {Scott Fujimoto and
                   Herke van Hoof and
                   David Meger},
  title         = {Addressing Function Approximation Error in Actor-Critic Methods},
  journal       = {CoRR},
  volume        = {abs/1802.09477},
  year          = {2018},
  url           = {http://arxiv.org/abs/1802.09477},
  archiveprefix = {arXiv},
  eprint        = {1802.09477},
  timestamp     = {Sat, 28 Sep 2019 00:58:01 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1802-09477.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{choi2019meta,
  title   = {Meta-amortized variational inference and learning},
  author  = {Choi, Kristy and Wu, Mike and Goodman, Noah and Ermon, Stefano},
  journal = {arXiv preprint arXiv:1902.01950},
  year    = {2019}
}

@inproceedings{geiger2012we,
  title        = {Are we ready for autonomous driving? the kitti vision benchmark suite},
  author       = {Geiger, Andreas and Lenz, Philip and Urtasun, Raquel},
  booktitle    = {2012 IEEE Conference on Computer Vision and Pattern Recognition},
  pages        = {3354--3361},
  year         = {2012},
  organization = {IEEE}
}

@article{SpinningUp2018,
  author = {Achiam, Joshua},
  title  = {{Spinning Up in Deep Reinforcement Learning}},
  year   = {2018}
}

@inproceedings{Bengio2020A,
  title     = {A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms},
  author    = {Yoshua Bengio and Tristan Deleu and Nasim Rahaman and Nan Rosemary Ke and Sebastien Lachapelle and Olexa Bilaniuk and Anirudh Goyal and Christopher Pal},
  booktitle = {International Conference on Learning Representations},
  year      = {2020},
  url       = {https://openreview.net/forum?id=ryxWIgBFPS}
}


@article{metagenrl,
  title   = {Improving generalization in meta reinforcement learning using learned objectives},
  author  = {Kirsch, Louis and van Steenkiste, Sjoerd and Schmidhuber, J{\"u}rgen},
  journal = {arXiv preprint arXiv:1910.04098},
  year    = {2019}
}

@article{ddpg,
  title   = {Continuous control with deep reinforcement learning},
  author  = {Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal = {arXiv preprint arXiv:1509.02971},
  year    = {2015}
}

@article{fu2020d4rl,
  title   = {D4rl: Datasets for deep data-driven reinforcement learning},
  author  = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal = {arXiv preprint arXiv:2004.07219},
  year    = {2020}
}

@article{kumar2020conservative,
  title   = {Conservative Q-Learning for Offline Reinforcement Learning},
  author  = {Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal = {arXiv preprint arXiv:2006.04779},
  year    = {2020}
}

@article{roth2020revisiting,
  title   = {Revisiting training strategies and generalization performance in deep metric learning},
  author  = {Roth, Karsten and Milbich, Timo and Sinha, Samarth and Gupta, Prateek and Ommer, Bjoern and Cohen, Joseph Paul},
  journal = {arXiv preprint arXiv:2002.08473},
  year    = {2020}
}

@article{nair2020accelerating,
  title   = {Accelerating Online Reinforcement Learning with Offline Datasets},
  author  = {Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
  journal = {arXiv preprint arXiv:2006.09359},
  year    = {2020}
}

@article{SPU,
  author        = {Quan Ho Vuong and
                   Yiming Zhang and
                   Keith W. Ross},
  title         = {Supervised Policy Update},
  journal       = {CoRR},
  volume        = {abs/1805.11706},
  year          = {2018},
  url           = {http://arxiv.org/abs/1805.11706},
  archiveprefix = {arXiv},
  eprint        = {1805.11706},
  timestamp     = {Thu, 06 Aug 2020 15:57:05 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1805-11706.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{PPO,
  author        = {John Schulman and
                   Filip Wolski and
                   Prafulla Dhariwal and
                   Alec Radford and
                   Oleg Klimov},
  title         = {Proximal Policy Optimization Algorithms},
  journal       = {CoRR},
  volume        = {abs/1707.06347},
  year          = {2017},
  url           = {http://arxiv.org/abs/1707.06347},
  archiveprefix = {arXiv},
  eprint        = {1707.06347},
  timestamp     = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{SAC,
  author        = {Tuomas Haarnoja and
                   Aurick Zhou and
                   Pieter Abbeel and
                   Sergey Levine},
  title         = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
                   with a Stochastic Actor},
  journal       = {CoRR},
  volume        = {abs/1801.01290},
  year          = {2018},
  url           = {http://arxiv.org/abs/1801.01290},
  archiveprefix = {arXiv},
  eprint        = {1801.01290},
  timestamp     = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1801-01290.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@article{TRPO,
  author        = {John Schulman and
                   Sergey Levine and
                   Philipp Moritz and
                   Michael I. Jordan and
                   Pieter Abbeel},
  title         = {Trust Region Policy Optimization},
  journal       = {CoRR},
  volume        = {abs/1502.05477},
  year          = {2015},
  url           = {http://arxiv.org/abs/1502.05477},
  archiveprefix = {arXiv},
  eprint        = {1502.05477},
  timestamp     = {Mon, 13 Aug 2018 16:48:08 +0200},
  biburl        = {https://dblp.org/rec/journals/corr/SchulmanLMJA15.bib},
  bibsource     = {dblp computer science bibliography, https://dblp.org}
}

@misc{SOP,
  title         = {Striving for Simplicity and Performance in Off-Policy DRL: Output Normalization and Non-Uniform Sampling},
  author        = {Che Wang and Yanqiu Wu and Quan Vuong and Keith Ross},
  year          = {2020},
  eprint        = {1910.02208},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@article{kostrikov2021iql,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@inproceedings{kostrikov2021offline,
  title={Offline reinforcement learning with fisher divergence critic regularization},
  author={Kostrikov, Ilya and Fergus, Rob and Tompson, Jonathan and Nachum, Ofir},
  booktitle={International Conference on Machine Learning},
  pages={5774--5783},
  year={2021},
  organization={PMLR}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{bai2022pessimistic,
  title={Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning},
  author={Bai, Chenjia and Wang, Lingxiao and Yang, Zhuoran and Deng, Zhihong and Garg, Animesh and Liu, Peng and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2202.11566},
  year={2022}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14129--14142},
  year={2020}
}

@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{henderson2018deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  year={2018}
}

@article{kumar2020discor,
  title={Discor: Corrective feedback in reinforcement learning via distribution correction},
  author={Kumar, Aviral and Gupta, Abhishek and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18560--18572},
  year={2020}
}

@article{konda1999actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay and Tsitsiklis, John},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}

@article{fu2021benchmarks,
  title={Benchmarks for deep off-policy evaluation},
  author={Fu, Justin and Norouzi, Mohammad and Nachum, Ofir and Tucker, George and Wang, Ziyu and Novikov, Alexander and Yang, Mengjiao and Zhang, Michael R and Chen, Yutian and Kumar, Aviral and others},
  journal={arXiv preprint arXiv:2103.16596},
  year={2021}
}

@article{paine2020hyperparameter,
  title={Hyperparameter selection for offline reinforcement learning},
  author={Paine, Tom Le and Paduraru, Cosmin and Michi, Andrea and Gulcehre, Caglar and Zolna, Konrad and Novikov, Alexander and Wang, Ziyu and de Freitas, Nando},
  journal={arXiv preprint arXiv:2007.09055},
  year={2020}
}

@article{van2018deep,
  title={Deep reinforcement learning and the deadly triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@book{callahan2010advanced,
  title={Advanced calculus: a geometric view},
  author={Callahan, James J},
  volume={1},
  year={2010},
  publisher={Springer}
}

@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@article{sallab2017deep,
  title={Deep reinforcement learning framework for autonomous driving},
  author={Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}

@article{cabi2019framework,
  title={A framework for data-driven robotics},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and Zolna, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

@book{rummery1994line,
  title={On-line Q-learning using connectionist systems},
  author={Rummery, Gavin A and Niranjan, Mahesan},
  volume={37},
  year={1994},
  publisher={Citeseer}
}

@inproceedings{dabney2018implicit,
  title={Implicit quantile networks for distributional reinforcement learning},
  author={Dabney, Will and Ostrovski, Georg and Silver, David and Munos, R{\'e}mi},
  booktitle={International conference on machine learning},
  pages={1096--1105},
  year={2018},
  organization={PMLR}
}

@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@inproceedings{janner2021sequence,
  title = {Offline Reinforcement Learning as One Big Sequence Modeling Problem},
  author = {Michael Janner and Qiyang Li and Sergey Levine},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2021},
}

@inproceedings{ghasemipour2021emaq,
  title={Emaq: Expected-max q-learning operator for simple yet effective offline and online rl},
  author={Ghasemipour, Seyed Kamyar Seyed and Schuurmans, Dale and Gu, Shixiang Shane},
  booktitle={International Conference on Machine Learning},
  pages={3682--3691},
  year={2021},
  organization={PMLR}
}

@article{jaques2019way,
  title={Way off-policy batch deep reinforcement learning of implicit human preferences in dialog},
  author={Jaques, Natasha and Ghandeharioun, Asma and Shen, Judy Hanwen and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang and Picard, Rosalind},
  journal={arXiv preprint arXiv:1907.00456},
  year={2019}
}

@article{sohn2015learning,
  title={Learning structured output representation using deep conditional generative models},
  author={Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  pages={503--556},
  year={2005},
  publisher={Microtome Publishing}
}

@inproceedings{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang and Voloshin, Cameron and Yue, Yisong},
  booktitle={International Conference on Machine Learning},
  pages={3703--3712},
  year={2019},
  organization={PMLR}
}

@article{fujimoto2022should,
  title={Why Should I Trust You, Bellman? The Bellman Error is a Poor Replacement for Value Error},
  author={Fujimoto, Scott and Meger, David and Precup, Doina and Nachum, Ofir and Gu, Shixiang Shane},
  journal={arXiv preprint arXiv:2201.12417},
  year={2022}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{jin2016local,
  title={Local maxima in the likelihood of gaussian mixture models: Structural results and algorithmic consequences},
  author={Jin, Chi and Zhang, Yuchen and Balakrishnan, Sivaraman and Wainwright, Martin J and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{jordan1994hierarchical,
  title={Hierarchical mixtures of experts and the EM algorithm},
  author={Jordan, Michael I and Jacobs, Robert A},
  journal={Neural computation},
  volume={6},
  number={2},
  pages={181--214},
  year={1994},
  publisher={MIT Press}
}

@article{xu1994alternative,
  title={An alternative model for mixtures of experts},
  author={Xu, Lei and Jordan, Michael and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={7},
  year={1994}
}

@article{bishop2012bayesian,
  title={Bayesian hierarchical mixtures of experts},
  author={Bishop, Christopher M and Svens{\'e}n, Markus},
  journal={arXiv preprint arXiv:1212.2447},
  year={2012}
}

@article{ma2020dsac,
  title={DSAC: Distributional soft actor critic for risk-sensitive reinforcement learning},
  author={Ma, Xiaoteng and Xia, Li and Zhou, Zhengyuan and Yang, Jun and Zhao, Qianchuan},
  journal={arXiv preprint arXiv:2004.14547},
  year={2020}
}

@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc and Munos, R{\'e}mi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}
@article{muller1997integral,
  title={Integral probability metrics and their generating classes of functions},
  author={M{\"u}ller, Alfred},
  journal={Advances in Applied Probability},
  volume={29},
  number={2},
  pages={429--443},
  year={1997},
  publisher={Cambridge University Press}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{agarwal2021deep,
  title={Deep reinforcement learning at the edge of the statistical precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={29304--29320},
  year={2021}
}

@article{rlkit,
  title  = {RLkit: Reinforcement learning framework and algorithms implemented in PyTorch},
  author = {RAIL Berkeley},
  url    = {https://github.com/rail-berkeley/rlkit}
}

@inproceedings{tang2020taylor,
  title={Taylor expansion policy optimization},
  author={Tang, Yunhao and Valko, Michal and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={9397--9406},
  year={2020},
  organization={PMLR}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={International conference on machine learning},
  pages={387--395},
  year={2014},
  organization={PMLR}
}

@article{islam2017reproducibility,
  title={Reproducibility of benchmarked deep reinforcement learning tasks for continuous control},
  author={Islam, Riashat and Henderson, Peter and Gomrokchi, Maziar and Precup, Doina},
  journal={arXiv preprint arXiv:1708.04133},
  year={2017}
}

@article{li2020multi,
  title={Multi-task batch reinforcement learning with metric learning},
  author={Li, Jiachen and Vuong, Quan and Liu, Shuang and Liu, Minghua and Ciosek, Kamil and Christensen, Henrik and Su, Hao},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6197--6210},
  year={2020}
}

@inproceedings{vuong2022dual,
 author = {Vuong, Quan and Kumar, Aviral and Levine, Sergey and Chebotar, Yevgen},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {38937--38949},
 publisher = {Curran Associates, Inc.},
 title = {DASCO: Dual-Generator Adversarial Support Constrained Offline Reinforcement Learning},
 volume = {35},
 year = {2022}
}

@article{metelli2018policy,
  title={Policy optimization via importance sampling},
  author={Metelli, Alberto Maria and Papini, Matteo and Faccio, Francesco and Restelli, Marcello},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{metelli2020importance,
  title={Importance sampling techniques for policy optimization},
  author={Metelli, Alberto Maria and Papini, Matteo and Montali, Nico and Restelli, Marcello},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5552--5626},
  year={2020},
  publisher={JMLRORG}
}

@inproceedings{
wu2022supported,
title={Supported Policy Optimization for Offline Reinforcement Learning},
author={Jialong Wu and Haixu Wu and Zihan Qiu and Jianmin Wang and Mingsheng Long},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=KCXQ5HoM-fy}
}

@inproceedings{
yang2022rorl,
title={{RORL}: Robust Offline Reinforcement Learning via Conservative Smoothing},
author={Rui Yang and Chenjia Bai and Xiaoteng Ma and Zhaoran Wang and Chongjie Zhang and Lei Han},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=_QzJJGH_KE}
}

@inproceedings{
lyu2022mildly,
title={Mildly Conservative Q-Learning for Offline Reinforcement Learning},
author={Jiafei Lyu and Xiaoteng Ma and Xiu Li and Zongqing Lu},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=VYYf6S67pQc}
}