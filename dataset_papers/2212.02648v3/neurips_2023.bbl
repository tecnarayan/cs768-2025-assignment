\begin{thebibliography}{61}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alcorn et~al.(2019)Alcorn, Li, Gong, Wang, Mai, Ku, and
  Nguyen]{adv_pose}
Michael~A. Alcorn, Qi~Li, Zhitao Gong, Chengfei Wang, Long Mai, Wei-Shinn Ku,
  and Anh~M Nguyen.
\newblock Strike (with) a pose: Neural networks are easily fooled by strange
  poses of familiar objects.
\newblock \emph{2019 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 4840--4849, 2019.

\bibitem[Arjovsky et~al.(2020)Arjovsky, Bottou, Gulrajani, and Lopez-Paz]{irm}
Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization, 2020.

\bibitem[Barbu et~al.(2019)Barbu, Mayo, Alverio, Luo, Wang, Gutfreund,
  Tenenbaum, and Katz]{objectnet}
Andrei Barbu, David Mayo, Julian Alverio, William Luo, Christopher Wang, Dan
  Gutfreund, Joshua~B. Tenenbaum, and Boris Katz.
\newblock Objectnet: A large-scale bias-controlled dataset for pushing the
  limits of object recognition models.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Basu et~al.(2021)Basu, Pope, and Feizi]{Basu2021InfluenceFI}
Samyadeep Basu, Philip Pope, and Soheil Feizi.
\newblock Influence functions in deep learning are fragile.
\newblock \emph{ArXiv}, abs/2006.14651, 2021.

\bibitem[Beyer et~al.(2020)Beyer, H'enaff, Kolesnikov, Zhai, and van~den
  Oord]{Beyer2020AreWD}
Lucas Beyer, Olivier~J. H'enaff, Alexander Kolesnikov, Xiaohua Zhai, and
  A{\"a}ron van~den Oord.
\newblock Are we done with imagenet?
\newblock \emph{ArXiv}, abs/2006.07159, 2020.

\bibitem[Buolamwini and Gebru(2018)]{gendershades}
Joy Buolamwini and Timnit Gebru.
\newblock Gender shades: Intersectional accuracy disparities in commercial
  gender classification.
\newblock In \emph{FAT}, 2018.

\bibitem[Caron et~al.(2021)Caron, Touvron, Misra, J\'egou, Mairal, Bojanowski,
  and Joulin]{dino}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\'e J\'egou, Julien Mairal,
  Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In \emph{Proceedings of the International Conference on Computer
  Vision (ICCV)}, 2021.

\bibitem[Chen et~al.(2019)Chen, Li, Barnett, Su, and
  Rudin]{this_looks_like_that}
Chaofan Chen, Oscar Li, Alina~Jade Barnett, Jonathan Su, and Cynthia Rudin.
\newblock This looks like that: deep learning for interpretable image
  recognition.
\newblock \emph{ArXiv}, abs/1806.10574, 2019.

\bibitem[Chen* et~al.(2021)Chen*, Xie*, and He]{moco}
Xinlei Chen*, Saining Xie*, and Kaiming He.
\newblock An empirical study of training self-supervised vision transformers.
\newblock \emph{arXiv preprint arXiv:2104.02057}, 2021.

\bibitem[Chouldechova(2017)]{recidivism}
Alexandra Chouldechova.
\newblock Fair prediction with disparate impact: A study of bias in recidivism
  prediction instruments.
\newblock \emph{Big data}, 5 2:\penalty0 153--163, 2017.

\bibitem[Crabbe et~al.(2021)Crabbe, Qian, Imrie, and van~der
  Schaar]{Crabbe2021ExplainingLR}
Jonathan Crabbe, Zhaozhi Qian, Fergus Imrie, and Mihaela van~der Schaar.
\newblock Explaining latent representations with a corpus of examples.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[DeGrave et~al.(2021)DeGrave, Janizek, and Lee]{deGrave2021aa}
Alex~J. DeGrave, Joseph~D. Janizek, and Su-In Lee.
\newblock Ai for radiographic covid-19 detection selects shortcuts over signal.
\newblock \emph{Nature Machine Intelligence}, 3\penalty0 (7):\penalty0
  610--619, 2021.

\bibitem[Djolonga et~al.(2021)Djolonga, Yung, Tschannen, Romijnders, Beyer,
  Kolesnikov, Puigcerver, Minderer, D'Amour, Moldovan, Gelly, Houlsby, Zhai,
  and Lucic]{si_score}
Josip Djolonga, Jessica Yung, Michael Tschannen, Rob Romijnders, Lucas Beyer,
  Alexander Kolesnikov, Joan Puigcerver, Matthias Minderer, Alexander D'Amour,
  Dan~I. Moldovan, Sylvan Gelly, Neil Houlsby, Xiaohua Zhai, and Mario Lucic.
\newblock On robustness and transferability of convolutional neural networks.
\newblock \emph{2021 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 16453--16463, 2021.

\bibitem[Fel et~al.(2022)Fel, Felipe, Linsley, and Serre]{fel2022aligning}
Thomas Fel, Ivan Felipe, Drew Linsley, and Thomas Serre.
\newblock Harmonizing the object recognition strategies of deep neural networks
  with humans.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2022.

\bibitem[Ghandeharioun et~al.(2022)Ghandeharioun, Kim, Li, Jou, Eoff, and
  Picard]{dissect}
Asma Ghandeharioun, Been Kim, Chun-Liang Li, Brendan Jou, Brian Eoff, and
  Rosalind~W. Picard.
\newblock Dissect: Disentangled simultaneous explanations via concept
  traversals.
\newblock \emph{ArXiv}, abs/2105.15164, 2022.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Basart, Mu, Kadavath, Wang, Dorundo,
  Desai, Zhu, Parajuli, Guo, Song, Steinhardt, and Gilmer]{imagenetR}
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan
  Dorundo, Rahul Desai, Tyler~Lixuan Zhu, Samyak Parajuli, Mike Guo,
  Dawn~Xiaodong Song, Jacob Steinhardt, and Justin Gilmer.
\newblock The many faces of robustness: A critical analysis of
  out-of-distribution generalization.
\newblock \emph{2021 IEEE/CVF International Conference on Computer Vision
  (ICCV)}, pages 8320--8329, 2021.

\bibitem[Hernandez et~al.(2022)Hernandez, Schwettmann, Bau, Bagashvili,
  Torralba, and Andreas]{milan}
Evan Hernandez, Sarah Schwettmann, David Bau, Teona Bagashvili, Antonio
  Torralba, and Jacob Andreas.
\newblock Natural language descriptions of deep visual features.
\newblock \emph{ArXiv}, abs/2201.11114, 2022.

\bibitem[Hu et~al.(2018)Hu, Niu, Sato, and Sugiyama]{dro_like}
Weihua Hu, Gang Niu, Issei Sato, and Masashi Sugiyama.
\newblock Does distributionally robust supervised learning give robust
  classifiers?
\newblock In \emph{ICML}, 2018.

\bibitem[Ilyas et~al.(2022)Ilyas, Park, Engstrom, Leclerc, and
  Madry]{data_models}
Andrew Ilyas, Sung~Min Park, Logan Engstrom, Guillaume Leclerc, and Aleksander
  Madry.
\newblock Datamodels: Predicting predictions from training data.
\newblock \emph{ArXiv}, abs/2202.00622, 2022.

\bibitem[Kirichenko et~al.(2022)Kirichenko, Izmailov, and Wilson]{dfr}
P.~Kirichenko, Pavel Izmailov, and Andrew~Gordon Wilson.
\newblock Last layer re-training is sufficient for robustness to spurious
  correlations.
\newblock \emph{ArXiv}, abs/2204.02937, 2022.

\bibitem[Kirillov et~al.(2023)Kirillov, Mintun, Ravi, Mao, Rolland, Gustafson,
  Xiao, Whitehead, Berg, Lo, Doll{\'a}r, and Girshick]{sam}
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura
  Gustafson, Tete Xiao, Spencer Whitehead, Alexander~C. Berg, Wan-Yen Lo, Piotr
  Doll{\'a}r, and Ross Girshick.
\newblock Segment anything.
\newblock \emph{arXiv:2304.02643}, 2023.

\bibitem[Koh and Liang(2017)]{influence_fns}
Pang~Wei Koh and Percy Liang.
\newblock Understanding black-box predictions via influence functions.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning - Volume 70}, ICML'17, page 1885–1894. JMLR.org, 2017.

\bibitem[Koh et~al.(2021)Koh, Sagawa, Marklund, Xie, Zhang, Balsubramani, Hu,
  Yasunaga, Phillips, Beery, Leskovec, Kundaje, Pierson, Levine, Finn, and
  Liang]{wilds}
Pang~Wei Koh, Shiori Sagawa, Henrik Marklund, Sang~Michael Xie, Marvin Zhang,
  Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard~L. Phillips, Sara
  Beery, Jure Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea
  Finn, and Percy Liang.
\newblock Wilds: A benchmark of in-the-wild distribution shifts.
\newblock In \emph{ICML}, 2021.

\bibitem[Liu et~al.(2021)Liu, Haghgoo, Chen, Raghunathan, Koh, Sagawa, Liang,
  and Finn]{jtt}
Evan~Zheran Liu, Behzad Haghgoo, Annie~S. Chen, Aditi Raghunathan, Pang~Wei
  Koh, Shiori Sagawa, Percy Liang, and Chelsea Finn.
\newblock Just train twice: Improving group robustness without training group
  information.
\newblock In \emph{ICML}, 2021.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{celebA}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{Proceedings of International Conference on Computer Vision
  (ICCV)}, December 2015.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and Vladu]{pgd}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Miller et~al.(2021)Miller, Taori, Raghunathan, Sagawa, Koh, Shankar,
  Liang, Carmon, and Schmidt]{Miller2021AccuracyOT}
John Miller, Rohan Taori, Aditi Raghunathan, Shiori Sagawa, Pang~Wei Koh,
  Vaishaal Shankar, Percy Liang, Yair Carmon, and Ludwig Schmidt.
\newblock Accuracy on the line: on the strong correlation between
  out-of-distribution and in-distribution generalization.
\newblock \emph{ArXiv}, abs/2107.04649, 2021.

\bibitem[Moayeri et~al.(2022{\natexlab{a}})Moayeri, Banihashem, and
  Feizi]{tradeoffs}
Mazda Moayeri, Kiarash Banihashem, and Soheil Feizi.
\newblock Explicit tradeoffs between adversarial and natural distributional
  robustness, 2022{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2209.07592}.

\bibitem[Moayeri et~al.(2022{\natexlab{b}})Moayeri, Pope, Balaji, and
  Feizi]{mazda_rfs}
Mazda Moayeri, Phillip~E. Pope, Yogesh Balaji, and Soheil Feizi.
\newblock A comprehensive study of image classification model sensitivity to
  foregrounds, backgrounds, and visual attributes.
\newblock \emph{2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 19065--19075, 2022{\natexlab{b}}.

\bibitem[Moayeri et~al.(2022{\natexlab{c}})Moayeri, Singla, and
  Feizi]{moayeri2022hard}
Mazda Moayeri, Sahil Singla, and Soheil Feizi.
\newblock Hard imagenet: Segmentations for objects with strong spurious cues.
\newblock In \emph{Thirty-sixth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track}, 2022{\natexlab{c}}.
\newblock URL \url{https://openreview.net/forum?id=76w7bsdViZf}.

\bibitem[Moayeri et~al.(2023)Moayeri, Rezaei, Sanjabi, and Feizi]{text2concept}
Mazda Moayeri, Keivan Rezaei, Maziar Sanjabi, and Soheil Feizi.
\newblock Text-to-concept (and back) via cross-model alignment.
\newblock In \emph{International Conference on Machine Learning}, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:258615488}.

\bibitem[Nam et~al.(2020)Nam, Cha, Ahn, Lee, and Shin]{Nam2020LearningFF}
Jun~Hyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin.
\newblock Learning from failure: Training debiased classifier from biased
  classifier.
\newblock \emph{ArXiv}, abs/2007.02561, 2020.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:220363797}.

\bibitem[Nam et~al.(2022)Nam, Kim, Lee, and Shin]{ssa}
Jun~Hyun Nam, Jaehyung Kim, Jaeho Lee, and Jinwoo Shin.
\newblock Spread spurious attribute: Improving worst-group accuracy with
  spurious attribute estimation.
\newblock \emph{ArXiv}, abs/2204.02070, 2022.

\bibitem[Naseer et~al.(2021)Naseer, Ranasinghe, Khan, Hayat, Khan, and
  Yang]{intriguing_vits}
Muzammal Naseer, Kanchana Ranasinghe, Salman~Hameed Khan, Munawar Hayat,
  Fahad~Shahbaz Khan, and Ming-Hsuan Yang.
\newblock Intriguing properties of vision transformers.
\newblock In \emph{Neural Information Processing Systems}, 2021.

\bibitem[Olah et~al.(2017)Olah, Mordvintsev, and Schubert]{olah}
Chris Olah, Alexander Mordvintsev, and Ludwig Schubert.
\newblock Feature visualization.
\newblock \emph{Distill}, 2017.
\newblock \doi{10.23915/distill.00007}.
\newblock https://distill.pub/2017/feature-visualization.

\bibitem[Qin et~al.(2021)Qin, Zhang, Chen, Lakshminarayanan, Beutel, and
  Wang]{Qin2021UnderstandingAI}
Yao Qin, Chiyuan Zhang, Ting Chen, Balaji Lakshminarayanan, Alex Beutel, and
  Xuezhi Wang.
\newblock Understanding and improving robustness of vision transformers through
  patch-based negative augmentation.
\newblock \emph{ArXiv}, abs/2110.07858, 2021.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock \emph{arXiv preprint arXiv:2103.00020}, 2021.

\bibitem[Robey et~al.(2021)Robey, Pappas, and Hassani]{hassani}
Alexander Robey, George~J. Pappas, and Hamed Hassani.
\newblock Model-based domain generalization.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Rosenfeld et~al.(2018)Rosenfeld, Zemel, and Tsotsos]{elephant}
Amir Rosenfeld, Richard~S. Zemel, and John~K. Tsotsos.
\newblock The elephant in the room.
\newblock \emph{ArXiv}, abs/1808.03305, 2018.

\bibitem[Sagawa et~al.(2019)Sagawa, Koh, Hashimoto, and Liang]{dro_like2}
Shiori Sagawa, Pang~Wei Koh, Tatsunori~B. Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks for group shifts: On the
  importance of regularization for worst-case generalization.
\newblock \emph{ArXiv}, abs/1911.08731, 2019.

\bibitem[Sagawa* et~al.(2020{\natexlab{a}})Sagawa*, Koh*, Hashimoto, and
  Liang]{dro}
Shiori Sagawa*, Pang~Wei Koh*, Tatsunori~B. Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks.
\newblock In \emph{International Conference on Learning Representations},
  2020{\natexlab{a}}.
\newblock URL \url{https://openreview.net/forum?id=ryxGuJrFvS}.

\bibitem[Sagawa* et~al.(2020{\natexlab{b}})Sagawa*, Koh*, Hashimoto, and
  Liang]{waterbirds}
Shiori Sagawa*, Pang~Wei Koh*, Tatsunori~B. Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks.
\newblock In \emph{International Conference on Learning Representations},
  2020{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=ryxGuJrFvS}.

\bibitem[Salman et~al.(2020)Salman, Ilyas, Engstrom, Kapoor, and
  Madry]{robust_models_transfer}
Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, and Aleksander Madry.
\newblock Do adversarially robust imagenet models transfer better?
\newblock In \emph{ArXiv preprint arXiv:2007.08489}, 2020.

\bibitem[Santurkar et~al.(2019)Santurkar, Tsipras, Tran, Ilyas, Engstrom, and
  Madry]{percep_aligned_gradients}
Shibani Santurkar, Dimitris Tsipras, Brandon Tran, Andrew Ilyas, Logan
  Engstrom, and Aleksander Madry.
\newblock Image synthesis with a single (robust) classifier, 2019.

\bibitem[Shetty et~al.(2019)Shetty, Schiele, and Fritz]{sidewalk}
Rakshith Shetty, Bernt Schiele, and Mario Fritz.
\newblock Not using the car to see the sidewalk — quantifying and controlling
  the effects of context in classification and segmentation.
\newblock \emph{2019 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 8210--8218, 2019.

\bibitem[Singla and Feizi(2022)]{salientimagenet2021}
Sahil Singla and Soheil Feizi.
\newblock Salient imagenet: How to discover spurious features in deep learning?
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=XVPqLyNxSyh}.

\bibitem[Singla et~al.(2021)Singla, Nushi, Shah, Kamar, and Horvitz]{barlow}
Sahil Singla, Besmira Nushi, S.~Shah, Ece Kamar, and Eric Horvitz.
\newblock Understanding failures of deep networks via robust feature
  extraction.
\newblock \emph{2021 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 12848--12857, 2021.

\bibitem[Sohoni et~al.(2020)Sohoni, Dunnmon, Angus, Gu, and R{\'e}]{george}
Nimit~Sharad Sohoni, Jared~A. Dunnmon, Geoffrey Angus, Albert Gu, and
  Christopher R{\'e}.
\newblock No subclass left behind: Fine-grained robustness in coarse-grained
  classification problems.
\newblock \emph{ArXiv}, abs/2011.12945, 2020.

\bibitem[Wang et~al.(2019)Wang, Ge, Lipton, and Xing]{sketch}
Haohan Wang, Songwei Ge, Zachary Lipton, and Eric~P Xing.
\newblock Learning robust global representations by penalizing local predictive
  power.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  10506--10518, 2019.

\bibitem[Wei et~al.(2022)Wei, Tay, Bommasani, Raffel, Zoph, Borgeaud, Yogatama,
  Bosma, Zhou, Metzler, hsin Chi, Hashimoto, Vinyals, Liang, Dean, and
  Fedus]{Wei2022EmergentAO}
Jason Wei, Yi~Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian
  Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed~Huai
  hsin Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and
  William Fedus.
\newblock Emergent abilities of large language models.
\newblock \emph{ArXiv}, abs/2206.07682, 2022.

\bibitem[Wightman(2019)]{timm}
Ross Wightman.
\newblock Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem[Wong et~al.(2021)Wong, Santurkar, and Madry]{wong}
Eric Wong, Shibani Santurkar, and Aleksander Madry.
\newblock Leveraging sparse linear layers for debuggable deep networks.
\newblock \emph{ArXiv}, abs/2105.04857, 2021.

\bibitem[Wortsman et~al.(2022)Wortsman, Ilharco, Kim, Li, Kornblith, Roelofs,
  Lopes, Hajishirzi, Farhadi, Namkoong, and Schmidt]{wise_ft}
Mitchell Wortsman, Gabriel Ilharco, Jong~Wook Kim, Mike Li, Simon Kornblith,
  Rebecca Roelofs, Raphael~Gontijo Lopes, Hannaneh Hajishirzi, Ali Farhadi,
  Hongseok Namkoong, and Ludwig Schmidt.
\newblock Robust fine-tuning of zero-shot models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 7959--7971, June 2022.

\bibitem[Xiao et~al.(2021)Xiao, Engstrom, Ilyas, and Madry]{noise_or_signal}
Kai~Yuanqing Xiao, Logan Engstrom, Andrew Ilyas, and Aleksander Madry.
\newblock Noise or signal: The role of image backgrounds in object recognition.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=gl3D-xY7wLq}.

\bibitem[Ye et~al.(2021)Ye, Li, Hong, Bai, Chen, Zhou, and Li]{ood_bench}
Nanyang Ye, Kaican Li, Lanqing Hong, Haoyue Bai, Yiting Chen, Fengwei Zhou, and
  Zhenguo Li.
\newblock Ood-bench: Benchmarking and understanding out-of-distribution
  generalization datasets and algorithms.
\newblock \emph{ArXiv}, abs/2106.03721, 2021.

\bibitem[Yun et~al.(2021)Yun, Oh, Heo, Han, Choe, and
  Chun]{Yun2021RelabelingIF}
Sangdoo Yun, Seong~Joon Oh, Byeongho Heo, Dongyoon Han, Junsuk Choe, and
  Sanghyuk Chun.
\newblock Re-labeling imagenet: from single to multi-labels, from global to
  localized labels.
\newblock \emph{2021 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 2340--2350, 2021.

\bibitem[Zech et~al.(2018)Zech, Badgeley, Liu, Costa, Titano, and
  Oermann]{Zech2018VariableGP}
John~R. Zech, Marcus~A. Badgeley, Manway Liu, Anthony~Beardsworth Costa,
  Joseph~J. Titano, and Eric~Karl Oermann.
\newblock Variable generalization performance of a deep learning model to
  detect pneumonia in chest radiographs: A cross-sectional study.
\newblock \emph{PLoS Medicine}, 15, 2018.

\bibitem[Zhang et~al.(2021)Zhang, Menon, Veit, Bhojanapalli, Kumar, and
  Sra]{dro_like3}
J.~Zhang, Aditya~Krishna Menon, Andreas Veit, Srinadh Bhojanapalli, Sanjiv
  Kumar, and Suvrit Sra.
\newblock Coping with label shift via distributionally robust optimisation.
\newblock \emph{ArXiv}, abs/2010.12230, 2021.

\bibitem[Zhang et~al.(2022)Zhang, Sohoni, Zhang, Finn, and
  R'e]{correct_n_contrast}
Michael Zhang, Nimit~Sharad Sohoni, Hongyang~R. Zhang, Chelsea Finn, and
  Christopher R'e.
\newblock Correct-n-contrast: A contrastive approach for improving robustness
  to spurious correlations.
\newblock In \emph{ICML}, 2022.

\bibitem[Zhang et~al.(2017)Zhang, Song, and Qi]{utkface}
Zhifei Zhang, Yang Song, and Hairong Qi.
\newblock Age progression/regression by conditional adversarial autoencoder.
\newblock In \emph{2017 {IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2017, Honolulu, HI, USA, July 21-26, 2017}, pages
  4352--4360. {IEEE} Computer Society, 2017.
\newblock \doi{10.1109/CVPR.2017.463}.
\newblock URL \url{https://doi.org/10.1109/CVPR.2017.463}.

\bibitem[Zhou et~al.(2016)Zhou, Khosla, A., Oliva, and Torralba]{cam}
B.~Zhou, A.~Khosla, Lapedriza. A., A.~Oliva, and A.~Torralba.
\newblock {Learning Deep Features for Discriminative Localization.}
\newblock In \emph{The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2016.

\end{thebibliography}
