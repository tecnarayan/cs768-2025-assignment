\begin{thebibliography}{45}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Awad et~al.(2021)Awad, Mallik, and Hutter]{Awad2021}
Noor~H. Awad, Neeratyoy Mallik, and Frank Hutter.
\newblock {DEHB:} evolutionary hyberband for scalable, robust and efficient
  hyperparameter optimization.
\newblock In \emph{Proceedings of the Thirtieth International Joint Conference
  on Artificial Intelligence, {IJCAI} 2021, Virtual Event / Montreal, Canada,
  19-27 August 2021}, pages 2147--2153, 2021.
\newblock \doi{10.24963/ijcai.2021/296}.
\newblock URL \url{https://doi.org/10.24963/ijcai.2021/296}.

\bibitem[Baker et~al.(2018)Baker, Gupta, Raskar, and Naik]{Baker2018}
Bowen Baker, Otkrist Gupta, Ramesh Raskar, and Nikhil Naik.
\newblock Accelerating neural architecture search using performance prediction.
\newblock In \emph{6th International Conference on Learning Representations,
  {ICLR} 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Workshop Track
  Proceedings}, 2018.
\newblock URL \url{https://openreview.net/forum?id=HJqk3N1vG}.

\bibitem[Bergstra et~al.(2011)Bergstra, Bardenet, Bengio, and
  K{\'{e}}gl]{Bergstra2011}
James Bergstra, R{\'{e}}mi Bardenet, Yoshua Bengio, and Bal{\'{a}}zs
  K{\'{e}}gl.
\newblock Algorithms for hyper-parameter optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 24: 25th
  Annual Conference on Neural Information Processing Systems 2011. Proceedings
  of a meeting held 12-14 December 2011, Granada, Spain}, pages 2546--2554,
  2011.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2011/hash/86e8f7ab32cfd12577bc2619bc635690-Abstract.html}.

\bibitem[Bertrand et~al.(2017)Bertrand, Ardon, Perrot, and Bloch]{Bertrand2017}
Hadrien Bertrand, Roberto Ardon, Matthieu Perrot, and Isabelle Bloch.
\newblock Hyperparameter optimization of deep neural networks: Combining
  hyperband with bayesian model selection.
\newblock In \emph{Conf{\'e}rence sur lâ€™Apprentissage Automatique}, 2017.

\bibitem[Chen et~al.(2017)Chen, Hoffman, Colmenarejo, Denil, Lillicrap,
  Botvinick, and de~Freitas]{Chen2017}
Yutian Chen, Matthew~W. Hoffman, Sergio~Gomez Colmenarejo, Misha Denil,
  Timothy~P. Lillicrap, Matthew Botvinick, and Nando de~Freitas.
\newblock Learning to learn without gradient descent by gradient descent.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning, {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017}, pages
  748--756, 2017.
\newblock URL \url{http://proceedings.mlr.press/v70/chen17e.html}.

\bibitem[Demsar(2006)]{Demsar2006}
Janez Demsar.
\newblock Statistical comparisons of classifiers over multiple data sets.
\newblock \emph{J. Mach. Learn. Res.}, 7:\penalty0 1--30, 2006.
\newblock URL \url{http://jmlr.org/papers/v7/demsar06a.html}.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{Devlin2019}
Jacob Devlin, Ming{-}Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT:} pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{Proceedings of the 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, {NAACL-HLT} 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume
  1 (Long and Short Papers)}, pages 4171--4186, 2019.
\newblock \doi{10.18653/v1/n19-1423}.
\newblock URL \url{https://doi.org/10.18653/v1/n19-1423}.

\bibitem[Domhan et~al.(2015)Domhan, Springenberg, and Hutter]{Domhan2015}
Tobias Domhan, Jost~Tobias Springenberg, and Frank Hutter.
\newblock Speeding up automatic hyperparameter optimization of deep neural
  networks by extrapolation of learning curves.
\newblock In Qiang Yang and Michael~J. Wooldridge, editors, \emph{Proceedings
  of the Twenty-Fourth International Joint Conference on Artificial
  Intelligence, {IJCAI} 2015, Buenos Aires, Argentina, July 25-31, 2015}, pages
  3460--3468. {AAAI} Press, 2015.
\newblock URL \url{http://ijcai.org/Abstract/15/487}.

\bibitem[Dong and Yang(2020)]{Dong2020}
Xuanyi Dong and Yi~Yang.
\newblock Nas-bench-201: Extending the scope of reproducible neural
  architecture search.
\newblock In \emph{8th International Conference on Learning Representations,
  {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}, 2020.
\newblock URL \url{https://openreview.net/forum?id=HJxyZkBKDr}.

\bibitem[Falkner et~al.(2018)Falkner, Klein, and Hutter]{Falkner2018}
Stefan Falkner, Aaron Klein, and Frank Hutter.
\newblock {BOHB:} robust and efficient hyperparameter optimization at scale.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning, {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15,
  2018}, pages 1436--1445, 2018.
\newblock URL \url{http://proceedings.mlr.press/v80/falkner18a.html}.

\bibitem[Franceschi et~al.(2017)Franceschi, Donini, Frasconi, and
  Pontil]{Franceschi2017}
Luca Franceschi, Michele Donini, Paolo Frasconi, and Massimiliano Pontil.
\newblock Forward and reverse gradient-based hyperparameter optimization.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning, {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017}, pages
  1165--1173, 2017.
\newblock URL \url{http://proceedings.mlr.press/v70/franceschi17a.html}.

\bibitem[Gardner et~al.(2018)Gardner, Pleiss, Weinberger, Bindel, and
  Wilson]{Gardner2018}
Jacob~R. Gardner, Geoff Pleiss, Kilian~Q. Weinberger, David Bindel, and
  Andrew~Gordon Wilson.
\newblock Gpytorch: Blackbox matrix-matrix gaussian process inference with
  {GPU} acceleration.
\newblock In \emph{Advances in Neural Information Processing Systems 31: Annual
  Conference on Neural Information Processing Systems 2018, NeurIPS 2018,
  December 3-8, 2018, Montr{\'{e}}al, Canada}, pages 7587--7597, 2018.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2018/hash/27e8e17134dd7083b050476733207ea1-Abstract.html}.

\bibitem[Gargiani et~al.(2019)Gargiani, Klein, Falkner, and
  Hutter]{Gargiani2019}
Matilde Gargiani, Aaron Klein, Stefan Falkner, and Frank Hutter.
\newblock Probabilistic rollouts for learning curve extrapolation across
  hyperparameter settings.
\newblock \emph{CoRR}, abs/1910.04522, 2019.
\newblock URL \url{http://arxiv.org/abs/1910.04522}.

\bibitem[Jamieson and Talwalkar(2016)]{Jamieson2016}
Kevin~G. Jamieson and Ameet Talwalkar.
\newblock Non-stochastic best arm identification and hyperparameter
  optimization.
\newblock In \emph{Proceedings of the 19th International Conference on
  Artificial Intelligence and Statistics, {AISTATS} 2016, Cadiz, Spain, May
  9-11, 2016}, pages 240--248, 2016.
\newblock URL \url{http://proceedings.mlr.press/v51/jamieson16.html}.

\bibitem[Jones et~al.(1998)Jones, Schonlau, and Welch]{Jones1998_Efficient}
Donald~R. Jones, Matthias Schonlau, and William~J. Welch.
\newblock Efficient global optimization of expensive black-box functions.
\newblock \emph{J. Global Optimization}, 13\penalty0 (4):\penalty0 455--492,
  1998.
\newblock \doi{10.1023/A:1008306431147}.
\newblock URL \url{https://doi.org/10.1023/A:1008306431147}.

\bibitem[Kandasamy et~al.(2016)Kandasamy, Dasarathy, Oliva, Schneider, and
  P{\'{o}}czos]{Kandasamy2016}
Kirthevasan Kandasamy, Gautam Dasarathy, Junier~B. Oliva, Jeff~G. Schneider,
  and Barnab{\'{a}}s P{\'{o}}czos.
\newblock Gaussian process bandit optimisation with multi-fidelity evaluations.
\newblock In \emph{Advances in Neural Information Processing Systems 29: Annual
  Conference on Neural Information Processing Systems 2016, December 5-10,
  2016, Barcelona, Spain}, pages 992--1000, 2016.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2016/hash/605ff764c617d3cd28dbbdd72be8f9a2-Abstract.html}.

\bibitem[Kandasamy et~al.(2017)Kandasamy, Dasarathy, Schneider, and
  P{\'{o}}czos]{Kandasamy2017}
Kirthevasan Kandasamy, Gautam Dasarathy, Jeff~G. Schneider, and Barnab{\'{a}}s
  P{\'{o}}czos.
\newblock Multi-fidelity bayesian optimisation with continuous approximations.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning, {ICML} 2017, Sydney, NSW, Australia, 6-11 August 2017}, pages
  1799--1808, 2017.
\newblock URL \url{http://proceedings.mlr.press/v70/kandasamy17a.html}.

\bibitem[Kandasamy et~al.(2018)Kandasamy, Neiswanger, Schneider, P{\'{o}}czos,
  and Xing]{Kandasamy2018}
Kirthevasan Kandasamy, Willie Neiswanger, Jeff Schneider, Barnab{\'{a}}s
  P{\'{o}}czos, and Eric~P. Xing.
\newblock Neural architecture search with bayesian optimisation and optimal
  transport.
\newblock In \emph{Advances in Neural Information Processing Systems 31: Annual
  Conference on Neural Information Processing Systems 2018, NeurIPS 2018,
  December 3-8, 2018, Montr{\'{e}}al, Canada}, pages 2020--2029, 2018.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2018/hash/f33ba15effa5c10e873bf3842afb46a6-Abstract.html}.

\bibitem[Kandasamy et~al.(2020)Kandasamy, Vysyaraju, Neiswanger, Paria,
  Collins, Schneider, P{\'{o}}czos, and Xing]{Kandasamy2020}
Kirthevasan Kandasamy, Karun~Raju Vysyaraju, Willie Neiswanger, Biswajit Paria,
  Christopher~R. Collins, Jeff Schneider, Barnab{\'{a}}s P{\'{o}}czos, and
  Eric~P. Xing.
\newblock Tuning hyperparameters without grad students: Scalable and robust
  bayesian optimisation with dragonfly.
\newblock \emph{J. Mach. Learn. Res.}, 21:\penalty0 81:1--81:27, 2020.
\newblock URL \url{http://jmlr.org/papers/v21/18-223.html}.

\bibitem[Kingma and Ba(2015)]{Kingma2015}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In \emph{3rd International Conference on Learning Representations,
  {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track
  Proceedings}, 2015.
\newblock URL \url{http://arxiv.org/abs/1412.6980}.

\bibitem[Klein et~al.(2017{\natexlab{a}})Klein, Falkner, Bartels, Hennig, and
  Hutter]{Klein2017}
Aaron Klein, Stefan Falkner, Simon Bartels, Philipp Hennig, and Frank Hutter.
\newblock Fast bayesian optimization of machine learning hyperparameters on
  large datasets.
\newblock In \emph{Proceedings of the 20th International Conference on
  Artificial Intelligence and Statistics, {AISTATS} 2017, 20-22 April 2017,
  Fort Lauderdale, FL, {USA}}, pages 528--536, 2017{\natexlab{a}}.
\newblock URL \url{http://proceedings.mlr.press/v54/klein17a.html}.

\bibitem[Klein et~al.(2017{\natexlab{b}})Klein, Falkner, Springenberg, and
  Hutter]{Klein2017a}
Aaron Klein, Stefan Falkner, Jost~Tobias Springenberg, and Frank Hutter.
\newblock Learning curve prediction with bayesian neural networks.
\newblock In \emph{5th International Conference on Learning Representations,
  {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track
  Proceedings}, 2017{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=S11KBYclx}.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Jamieson, Rostamizadeh, Gonina,
  Ben{-}tzur, Hardt, Recht, and Talwalkar]{Li2020a}
Liam Li, Kevin~G. Jamieson, Afshin Rostamizadeh, Ekaterina Gonina, Jonathan
  Ben{-}tzur, Moritz Hardt, Benjamin Recht, and Ameet Talwalkar.
\newblock A system for massively parallel hyperparameter tuning.
\newblock In Inderjit~S. Dhillon, Dimitris~S. Papailiopoulos, and Vivienne Sze,
  editors, \emph{Proceedings of Machine Learning and Systems 2020, MLSys 2020,
  Austin, TX, USA, March 2-4, 2020}. mlsys.org, 2020{\natexlab{a}}.
\newblock URL \url{https://proceedings.mlsys.org/book/303.pdf}.

\bibitem[Li et~al.(2017)Li, Jamieson, DeSalvo, Rostamizadeh, and
  Talwalkar]{Li2017}
Lisha Li, Kevin~G. Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and Ameet
  Talwalkar.
\newblock Hyperband: {A} novel bandit-based approach to hyperparameter
  optimization.
\newblock \emph{J. Mach. Learn. Res.}, 18:\penalty0 185:1--185:52, 2017.
\newblock URL \url{http://jmlr.org/papers/v18/16-558.html}.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Xing, Kirby, and Zhe]{Li2020}
Shibo Li, Wei Xing, Robert~M. Kirby, and Shandian Zhe.
\newblock Multi-fidelity bayesian optimization via deep neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020,
  December 6-12, 2020, virtual}, 2020{\natexlab{b}}.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/hash/60e1deb043af37db5ea4ce9ae8d2c9ea-Abstract.html}.

\bibitem[Lorraine et~al.(2020)Lorraine, Vicol, and Duvenaud]{Lorraine2020}
Jonathan Lorraine, Paul Vicol, and David Duvenaud.
\newblock Optimizing millions of hyperparameters by implicit differentiation.
\newblock In \emph{The 23rd International Conference on Artificial Intelligence
  and Statistics, {AISTATS} 2020, 26-28 August 2020, Online [Palermo, Sicily,
  Italy]}, pages 1540--1552, 2020.
\newblock URL \url{http://proceedings.mlr.press/v108/lorraine20a.html}.

\bibitem[Maclaurin et~al.(2015)Maclaurin, Duvenaud, and Adams]{Maclaurin2015}
Dougal Maclaurin, David Duvenaud, and Ryan~P. Adams.
\newblock Gradient-based hyperparameter optimization through reversible
  learning.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning, {ICML} 2015, Lille, France, 6-11 July 2015}, pages 2113--2122,
  2015.
\newblock URL \url{http://proceedings.mlr.press/v37/maclaurin15.html}.

\bibitem[Mendes et~al.(2020)Mendes, Casimiro, Romano, and Garlan]{Mendes2020}
Pedro Mendes, Maria Casimiro, Paolo Romano, and David Garlan.
\newblock Trimtuner: Efficient optimization of machine learning jobs in the
  cloud via sub-sampling.
\newblock In \emph{28th International Symposium on Modeling, Analysis, and
  Simulation of Computer and Telecommunication Systems, {MASCOTS} 2020, Nice,
  France, November 17-19, 2020}, pages 1--8. {IEEE}, 2020.
\newblock \doi{10.1109/MASCOTS50786.2020.9285971}.
\newblock URL \url{https://doi.org/10.1109/MASCOTS50786.2020.9285971}.

\bibitem[Mendes et~al.(2021)Mendes, Casimiro, and Romano]{Mendes2021}
Pedro Mendes, Maria Casimiro, and Paolo Romano.
\newblock Hyperjump: Accelerating hyperband via risk modelling.
\newblock \emph{CoRR}, abs/2108.02479, 2021.
\newblock URL \url{https://arxiv.org/abs/2108.02479}.

\bibitem[Metz et~al.(2020)Metz, Maheswaranathan, Sun, Freeman, Poole, and
  Sohl{-}Dickstein]{Metz2020}
Luke Metz, Niru Maheswaranathan, Ruoxi Sun, C.~Daniel Freeman, Ben Poole, and
  Jascha Sohl{-}Dickstein.
\newblock Using a thousand optimization tasks to learn hyperparameter search
  strategies.
\newblock \emph{CoRR}, abs/2002.11887, 2020.
\newblock URL \url{https://arxiv.org/abs/2002.11887}.

\bibitem[Parker{-}Holder et~al.(2020)Parker{-}Holder, Nguyen, and
  Roberts]{Parker-Holder2020}
Jack Parker{-}Holder, Vu~Nguyen, and Stephen~J. Roberts.
\newblock Provably efficient online hyperparameter optimization with
  population-based bandits.
\newblock In \emph{Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020,
  December 6-12, 2020, virtual}, 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/hash/c7af0926b294e47e52e46cfebe173f20-Abstract.html}.

\bibitem[Perrone et~al.(2018)Perrone, Jenatton, Seeger, and
  Archambeau]{Perrone2018}
Valerio Perrone, Rodolphe Jenatton, Matthias~W. Seeger, and C{\'{e}}dric
  Archambeau.
\newblock Scalable hyperparameter transfer learning.
\newblock In \emph{Advances in Neural Information Processing Systems 31: Annual
  Conference on Neural Information Processing Systems 2018, NeurIPS 2018,
  December 3-8, 2018, Montr{\'{e}}al, Canada}, pages 6846--6856, 2018.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2018/hash/14c879f3f5d8ed93a09f6090d77c2cc3-Abstract.html}.

\bibitem[Poloczek et~al.(2017)Poloczek, Wang, and Frazier]{Poloczek2017}
Matthias Poloczek, Jialei Wang, and Peter~I. Frazier.
\newblock Multi-information source optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 30: Annual
  Conference on Neural Information Processing Systems 2017, December 4-9, 2017,
  Long Beach, CA, {USA}}, pages 4288--4298, 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2017/hash/df1f1d20ee86704251795841e6a9405a-Abstract.html}.

\bibitem[Rai et~al.(2016)Rai, Desai, and Goyal]{Rai2016}
Akshara Rai, Ruta Desai, and Siddharth Goyal.
\newblock Bayesian optimization with a neural network kernel, 2016.
\newblock URL \url{http://www.cs.cmu.edu/~rutad/files/BO_NN.pdf}.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{Snoek2012}
Jasper Snoek, Hugo Larochelle, and Ryan~P. Adams.
\newblock Practical bayesian optimization of machine learning algorithms.
\newblock In \emph{Advances in Neural Information Processing Systems 25: 26th
  Annual Conference on Neural Information Processing Systems 2012. Proceedings
  of a meeting held December 3-6, 2012, Lake Tahoe, Nevada, United States},
  pages 2960--2968, 2012.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2012/hash/05311655a15b75fab86956663e1819cd-Abstract.html}.

\bibitem[Srinivas et~al.(2010)Srinivas, Krause, Kakade, and
  Seeger]{Srinivas2010}
Niranjan Srinivas, Andreas Krause, Sham~M. Kakade, and Matthias~W. Seeger.
\newblock Gaussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock In \emph{Proceedings of the 27th International Conference on Machine
  Learning (ICML-10), June 21-24, 2010, Haifa, Israel}, pages 1015--1022, 2010.
\newblock URL \url{https://icml.cc/Conferences/2010/papers/422.pdf}.

\bibitem[Swersky et~al.(2013)Swersky, Snoek, and Adams]{Swersky2013}
Kevin Swersky, Jasper Snoek, and Ryan~Prescott Adams.
\newblock Multi-task bayesian optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 26: 27th
  Annual Conference on Neural Information Processing Systems 2013. Proceedings
  of a meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States},
  pages 2004--2012, 2013.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2013/hash/f33ba15effa5c10e873bf3842afb46a6-Abstract.html}.

\bibitem[Swersky et~al.(2014)Swersky, Snoek, and Adams]{Swersky2014}
Kevin Swersky, Jasper Snoek, and Ryan~Prescott Adams.
\newblock Freeze-thaw bayesian optimization.
\newblock \emph{CoRR}, abs/1406.3896, 2014.
\newblock URL \url{http://arxiv.org/abs/1406.3896}.

\bibitem[Takeno et~al.(2020)Takeno, Fukuoka, Tsukada, Koyama, Shiga, Takeuchi,
  and Karasuyama]{Takeno2020}
Shion Takeno, Hitoshi Fukuoka, Yuhki Tsukada, Toshiyuki Koyama, Motoki Shiga,
  Ichiro Takeuchi, and Masayuki Karasuyama.
\newblock Multi-fidelity bayesian optimization with max-value entropy search
  and its parallelization.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning, {ICML} 2020, 13-18 July 2020, Virtual Event}, pages 9334--9345,
  2020.
\newblock URL \url{http://proceedings.mlr.press/v119/takeno20a.html}.

\bibitem[Wang et~al.(2018)Wang, Xu, and Wang]{Wang2018}
Jiazhuo Wang, Jason Xu, and Xuejun Wang.
\newblock Combination of hyperband and bayesian optimization for hyperparameter
  optimization in deep learning.
\newblock \emph{CoRR}, abs/1801.01596, 2018.
\newblock URL \url{http://arxiv.org/abs/1801.01596}.

\bibitem[Wilson et~al.(2016)Wilson, Hu, Salakhutdinov, and Xing]{Wilson2016}
Andrew~Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric~P. Xing.
\newblock Deep kernel learning.
\newblock In \emph{Proceedings of the 19th International Conference on
  Artificial Intelligence and Statistics, {AISTATS} 2016, Cadiz, Spain, May
  9-11, 2016}, pages 370--378, 2016.
\newblock URL \url{http://proceedings.mlr.press/v51/wilson16.html}.

\bibitem[Wistuba(2017)]{Wistuba2017}
Martin Wistuba.
\newblock Bayesian optimization combined with incremental evaluation for neural
  network architecture optimization.
\newblock In \emph{AutoML@PKDD/ECML}, 2017.

\bibitem[Wistuba and Grabocka(2021)]{Wistuba2021}
Martin Wistuba and Josif Grabocka.
\newblock Few-shot bayesian optimization with deep kernel surrogates.
\newblock In \emph{9th International Conference on Learning Representations,
  {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021}, 2021.
\newblock URL \url{https://openreview.net/forum?id=bJxgv5C3sYc}.

\bibitem[Wistuba and Pedapati(2020)]{Wistuba2020}
Martin Wistuba and Tejaswini Pedapati.
\newblock Learning to rank learning curves.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning, {ICML} 2020, 13-18 July 2020, Virtual Event}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 10303--10312. {PMLR},
  2020.
\newblock URL \url{http://proceedings.mlr.press/v119/wistuba20a.html}.

\bibitem[Zimmer et~al.(2021)Zimmer, Lindauer, and Hutter]{Zimmer2021}
Lucas Zimmer, Marius Lindauer, and Frank Hutter.
\newblock Auto-pytorch: Multi-fidelity metalearning for efficient and robust
  autodl.
\newblock \emph{{IEEE} Trans. Pattern Anal. Mach. Intell.}, 43\penalty0
  (9):\penalty0 3079--3090, 2021.
\newblock \doi{10.1109/TPAMI.2021.3067763}.
\newblock URL \url{https://doi.org/10.1109/TPAMI.2021.3067763}.

\end{thebibliography}
