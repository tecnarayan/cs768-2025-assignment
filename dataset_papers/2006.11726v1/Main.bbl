\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bach(2015)]{bach2015submodular}
Francis~R. Bach.
\newblock {Submodular Functions: from Discrete to Continous Domains}.
\newblock \emph{CoRR}, abs/1511.00394, 2015.

\bibitem[Balkanski et~al.(2016)Balkanski, Mirzasoleiman, and
  Singer]{balkanski2016learning}
Eric Balkanski, Baharan Mirzasoleiman, and Yaron Singer.
\newblock {Learning Sparse Combinatorial Representations via Two-stage
  Submodular Maximization}.
\newblock In \emph{Proceedings of The 33rd International Conference on Machine
  Learning}, pages 2207--2216, 2016.

\bibitem[Balkanski et~al.(2019)Balkanski, Rubinstein, and
  Singer]{balkanski2019optimal}
Eric Balkanski, Aviad Rubinstein, and Yaron Singer.
\newblock An optimal approximation for submodular maximization under a matroid
  constraint in the adaptive complexity model.
\newblock In \emph{Proceedings of the 51st Annual ACM SIGACT Symposium on
  Theory of Computing}, 2019.

\bibitem[Bian et~al.(2017{\natexlab{a}})Bian, Levy, Krause, and
  Buhmann]{NIPS2017_6652}
An~Bian, Kfir~Yehuda Levy, Andreas Krause, and Joachim~M. Buhmann.
\newblock Non-monotone continuous dr-submodular maximization: Structure and
  algorithms.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 486--496, 2017{\natexlab{a}}.

\bibitem[Bian et~al.(2017{\natexlab{b}})Bian, Mirzasoleiman, Buhmann, and
  Krause]{bian2016guaranteed}
Andrew~An Bian, Baharan Mirzasoleiman, Joachim~M. Buhmann, and Andreas Krause.
\newblock {Guaranteed Non-convex Optimization: Submodular Maximization over
  Continuous Domains}.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics ({AISTATS})}, 2017{\natexlab{b}}.

\bibitem[Buchbinder and Feldman(2019)]{buchbinder2019constrained}
Niv Buchbinder and Moran Feldman.
\newblock Constrained submodular maximization via a non-symmetric technique.
\newblock \emph{Math. Oper. Res.}, 44\penalty0 (3):\penalty0 988--1005, 2019.

\bibitem[Calinescu et~al.(2011{\natexlab{a}})Calinescu, Chekuri, Pal, and
  Vondrak]{calinescu11maximizing}
Gruia Calinescu, Chandra Chekuri, Martin Pal, and Jan Vondrak.
\newblock Maximizing a submodular set function subject to a matroid constraint.
\newblock \emph{SIAM Journal on Computing}, 2011{\natexlab{a}}.

\bibitem[Calinescu et~al.(2011{\natexlab{b}})Calinescu, Chekuri, P{\'a}l, and
  Vondr{\'a}k]{calinescu2011maximizing}
Gruia Calinescu, Chandra Chekuri, Martin P{\'a}l, and Jan Vondr{\'a}k.
\newblock Maximizing a monotone submodular function subject to a matroid
  constraint.
\newblock \emph{SIAM Journal on Computing}, 40\penalty0 (6):\penalty0
  1740--1766, 2011{\natexlab{b}}.

\bibitem[Celis et~al.(2016)Celis, Deshpande, Kathuria, and
  Vishnoi]{celis2016fair}
L.~Elisa Celis, Amit Deshpande, Tarun Kathuria, and Nisheeth~K. Vishnoi.
\newblock {How to be Fair and Diverse?}
\newblock \emph{CoRR}, abs/1610.07183, 2016.

\bibitem[Chekuri and Quanrud(2019)]{chekuri2019parallelizing}
Chandra Chekuri and Kent Quanrud.
\newblock Parallelizing greedy for submodular set function maximization in
  matroids and beyond.
\newblock In \emph{Proceedings of the 51st Annual ACM SIGACT Symposium on
  Theory of Computing}, 2019.

\bibitem[Chekuri et~al.(2014)Chekuri, Vondr{\'a}k, and
  Zenklusen]{chekuri2014submodular}
Chandra~Sekhar Chekuri, Jan Vondr{\'a}k, and Rico Zenklusen.
\newblock Submodular function maximization via the multilinear relaxation and
  contention resolution schemes.
\newblock \emph{SIAM Journal on Computing}, 2014.

\bibitem[Chen et~al.(2018{\natexlab{a}})Chen, Harshaw, Hassani, and
  Karbasi]{chen2018projection}
Lin Chen, Christopher Harshaw, Hamed Hassani, and Amin Karbasi.
\newblock Projection-free online optimization with stochastic gradient: From
  convexity to submodularity.
\newblock In \emph{International Conference on Machine Learning},
  2018{\natexlab{a}}.

\bibitem[Chen et~al.(2018{\natexlab{b}})Chen, Hassani, and
  Karbasi]{chen2018online}
Lin Chen, Hamed Hassani, and Amin Karbasi.
\newblock {Online Continuous Submodular Maximization}.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics ({AISTATS})}, pages 1896--1905, 2018{\natexlab{b}}.

\bibitem[Chen et~al.(2019)Chen, Feldman, and Karbasi]{chen2019unconstrained}
Lin Chen, Moran Feldman, and Amin Karbasi.
\newblock Unconstrained submodular maximization with constant adaptive
  complexity.
\newblock In \emph{Proceedings of the 51st Annual ACM SIGACT Symposium on
  Theory of Computing}, pages 102--113, 2019.

\bibitem[Cohen and Katzir(2008)]{cohen2008generalized}
Reuven Cohen and Liran Katzir.
\newblock The generalized maximum coverage problem.
\newblock \emph{Inf. Process. Lett.}, 108\penalty0 (1):\penalty0 15--22, 2008.
\newblock \doi{10.1016/j.ipl.2008.03.017}.
\newblock URL \url{https://doi.org/10.1016/j.ipl.2008.03.017}.

\bibitem[Das and Kempe(2011)]{das2011submodular}
Abhimanyu Das and David Kempe.
\newblock {Submodular meets Spectral: Greedy Algorithms for Subset Selection,
  Sparse Approximation and Dictionary Selection}.
\newblock In \emph{{International Conference on Machine Learning}}, pages
  1057--1064, 2011.

\bibitem[Devanur and Jain(2012)]{devanur2012online}
Nikhil~R Devanur and Kamal Jain.
\newblock Online matching with concave returns.
\newblock In \emph{Proceedings of the forty-fourth annual ACM symposium on
  Theory of computing}, pages 137--144. ACM, 2012.

\bibitem[Elenberg et~al.(2017)Elenberg, Dimakis, Feldman, and
  Karbasi]{elenbergDFK17}
Ethan~R. Elenberg, Alexandros~G. Dimakis, Moran Feldman, and Amin Karbasi.
\newblock {Streaming Weak Submodularity: Interpreting Neural Networks on the
  Fly}.
\newblock In \emph{{Advances in Neural Information Processing Systems}}, 2017.

\bibitem[Ene et~al.(2019)Ene, Nguyen, and Vladu]{ene2019submodular}
Alina Ene, Huy~L Nguyen, and Adrian Vladu.
\newblock Submodular maximization with matroid and packing constraints in
  parallel.
\newblock In \emph{Proceedings of the 51st Annual ACM SIGACT Symposium on
  Theory of Computing}, 2019.

\bibitem[Fallat et~al.(2017)Fallat, Lauritzen, Sadeghi, Uhler, Wermuth, and
  Zwiernik]{fallat2017total}
Shaun Fallat, Steffen Lauritzen, Kayvan Sadeghi, Caroline Uhler, Nanny Wermuth,
  and Piotr Zwiernik.
\newblock {Total positivity in Markov structures}.
\newblock \emph{The Annals of Statistics}, 45\penalty0 (3):\penalty0
  1152--1184, 2017.

\bibitem[Feldman et~al.(2011)Feldman, Naor, and Schwartz]{feldman2011unified}
Moran Feldman, Joseph Naor, and Roy Schwartz.
\newblock A unified continuous greedy algorithm for submodular maximization.
\newblock In \emph{Foundations of Computer Science (FOCS)}, pages 570--579.
  IEEE, 2011.

\bibitem[Fujishige(1991)]{fujishige91old}
Satoru Fujishige.
\newblock \emph{Submodular functions and optimization}, volume~58.
\newblock Annals of Discrete. Mathematics, North Holland, Amsterdam, 2nd
  edition, 1991.
\newblock ISBN 0-444-88556-0.

\bibitem[Gillenwater et~al.(2012)Gillenwater, Kulesza, and
  Taskar]{gillenwater2012near}
Jennifer Gillenwater, Alex Kulesza, and Ben Taskar.
\newblock Near-optimal map inference for determinantal point processes.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2735--2743, 2012.

\bibitem[Golovin and Krause(2011)]{golovin11}
Daniel Golovin and Andreas Krause.
\newblock Adaptive submodularity: Theory and applications in active learning
  and stochastic optimization.
\newblock \emph{Journal of Artificial Intelligence Research}, 42:\penalty0
  427--486, 2011.

\bibitem[Golovin et~al.(2014)Golovin, Krause, and Streeter]{golovin2014online}
Daniel Golovin, Andreas Krause, and Matthew~J. Streeter.
\newblock {Online Submodular Maximization under a Matroid Constraint with
  Application to Learning Assignments}.
\newblock \emph{CoRR}, abs/1407.1082, 2014.

\bibitem[Guillory and Bilmes(2010)]{guillory10interactive}
Andrew Guillory and Jeff Bilmes.
\newblock {Interactive Submodular Set Cover}.
\newblock In \emph{International Conference on Machine Learning}, pages
  415--422. Omnipress, 2010.

\bibitem[Harshaw et~al.(2019)Harshaw, Feldman, Ward, and
  Karbasi]{harshaw2019submodular}
Chris Harshaw, Moran Feldman, Justin Ward, and Amin Karbasi.
\newblock Submodular maximization beyond non-negativity: Guarantees, fast
  algorithms, and applications.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Hassani et~al.(2019)Hassani, Karbasi, Mokhtari, and
  Shen]{hassani2019stochastic}
Hamed Hassani, Amin Karbasi, Aryan Mokhtari, and Zebang Shen.
\newblock Stochastic conditional gradient++: (non-)convex minimization and
  continuous submodular maximization, 2019.

\bibitem[Hassani et~al.(2017)Hassani, Soltanolkotabi, and
  Karbasi]{hassanigradient2017}
S.~Hamed Hassani, Mahdi Soltanolkotabi, and Amin Karbasi.
\newblock {Gradient Methods for Submodular Maximization}.
\newblock In \emph{{Advances in Neural Information Processing Systems}}, pages
  5843--5853, 2017.

\bibitem[Karbasi et~al.(2019)Karbasi, Hassani, Mokhtari, and
  Shen]{NIPS2019hassani}
Amin Karbasi, Hamed Hassani, Aryan Mokhtari, and Zebang Shen.
\newblock Stochastic continuous greedy ++: When upper and lower bounds match.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 13066--13076, 2019.

\bibitem[Karlin and Rinott(1980)]{karlin1980classes}
Samuel Karlin and Yosef Rinott.
\newblock Classes of orderings of measures and related correlation
  inequalities. i. multivariate totally positive distributions.
\newblock \emph{Journal of Multivariate Analysis}, 10\penalty0 (4):\penalty0
  467--498, 1980.

\bibitem[Kazemi et~al.(2018)Kazemi, Zadimoghaddam, and
  Karbasi]{kazemi2018scalable}
Ehsan Kazemi, Morteza Zadimoghaddam, and Amin Karbasi.
\newblock Scalable deletion-robust submodular maximization: Data summarization
  with privacy and fairness constraints.
\newblock In \emph{International conference on machine learning}, pages
  2544--2553, 2018.

\bibitem[Kempe et~al.(2003)Kempe, Kleinberg, and Tardos]{kempe03}
David Kempe, Jon Kleinberg, and \'{E}va Tardos.
\newblock Maximizing the spread of influence through a social network.
\newblock In \emph{Proceedings of the ninth ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pages 137--146. ACM, 2003.

\bibitem[Lei et~al.(2018)Lei, Wu, Chen, Dimakis, Dhillon, and
  Witbrock]{lei2018discrete}
Qi~Lei, Lingfei Wu, Pin-Yu Chen, Alexandros~G Dimakis, Inderjit~S Dhillon, and
  Michael Witbrock.
\newblock Discrete adversarial attacks and submodular optimization with
  applications to text classification.
\newblock \emph{arXiv preprint arXiv:1812.00151}, 2018.

\bibitem[Lin and Bilmes(2012)]{lin2012learning}
Hui Lin and Jeff~A. Bilmes.
\newblock {Learning Mixtures of Submodular Shells with Application to Document
  Summarization}.
\newblock In \emph{Proceedings of the Twenty-Eighth Conference on Uncertainty
  in Artificial Intelligence}, pages 479--490, 2012.

\bibitem[Mehta et~al.(2007)Mehta, Saberi, Vazirani, and
  Vazirani]{mehta2007adwords}
Aranyak Mehta, Amin Saberi, Umesh Vazirani, and Vijay Vazirani.
\newblock Adwords and generalized online matching.
\newblock \emph{Journal of the ACM (JACM)}, 2007.

\bibitem[Mirzasoleiman et~al.(2013)Mirzasoleiman, Karbasi, Sarkar, and
  Krause]{mirzasoleiman2013distributed}
Baharan Mirzasoleiman, Amin Karbasi, Rik Sarkar, and Andreas Krause.
\newblock {Distributed Submodular Maximization: Identifying Representative
  Elements in Massive Data}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2049--2057, 2013.

\bibitem[Mitrovic et~al.(2019)Mitrovic, Kazemi, Feldman, Krause, and
  Karbasi]{mitrovic2019adaptive}
Marko Mitrovic, Ehsan Kazemi, Moran Feldman, Andreas Krause, and Amin Karbasi.
\newblock Adaptive sequence submodularity.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5353--5364, 2019.

\bibitem[Mokhtari et~al.(2018{\natexlab{a}})Mokhtari, Hassani, and
  Karbasi]{mokhtari2018conditional}
Aryan Mokhtari, Hamed Hassani, and Amin Karbasi.
\newblock Conditional gradient method for stochastic submodular maximization:
  Closing the gap.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 1886--1895, 2018{\natexlab{a}}.

\bibitem[Mokhtari et~al.(2018{\natexlab{b}})Mokhtari, Hassani, and
  Karbasi]{mokhtari2018decentralized}
Aryan Mokhtari, Hamed Hassani, and Amin Karbasi.
\newblock Decentralized submodular maximization: Bridging discrete and
  continuous settings.
\newblock In \emph{International Conference on Machine Learning},
  2018{\natexlab{b}}.

\bibitem[Mokhtari et~al.(2018{\natexlab{c}})Mokhtari, Hassani, and
  Karbasi]{mokhtari2018stochastic}
Aryan Mokhtari, Hamed Hassani, and Amin Karbasi.
\newblock Stochastic conditional gradient methods: From convex minimization to
  submodular maximization.
\newblock \emph{arXiv preprint arXiv:1804.09554}, 2018{\natexlab{c}}.

\bibitem[Niazadeh et~al.(2018)Niazadeh, Roughgarden, and
  Wang]{niazadeh2018optimal}
Rad Niazadeh, Tim Roughgarden, and Joshua~R. Wang.
\newblock Optimal algorithms for continuous non-monotone submodular and
  {DR}-submodular maximization.
\newblock In \emph{Advances in Neural Information Processing Systems 31}, pages
  9617--9627, 2018.

\bibitem[Nutov(2020)]{perosnal2020nutov}
Zeev Nutov, 2020.
\newblock Personal communication.

\bibitem[Oh~Song et~al.(2017)Oh~Song, Jegelka, Rathod, and Murphy]{oh2017deep}
Hyun Oh~Song, Stefanie Jegelka, Vivek Rathod, and Kevin Murphy.
\newblock Deep metric learning via facility location.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 5382--5390, 2017.

\bibitem[Salehi et~al.(2017)Salehi, Karbasi, Scheinost, and
  Constable]{salehi2017submodular}
Mehraveh Salehi, Amin Karbasi, Dustin Scheinost, and R~Todd Constable.
\newblock A submodular approach to create individualized parcellations of the
  human brain.
\newblock In \emph{International Conference on Medical Image Computing and
  Computer-Assisted Intervention}, pages 478--485. Springer, 2017.

\bibitem[Singla et~al.(2014)Singla, Bogunovic, Bart{\'o}k, Karbasi, and
  Krause]{singla2014near}
Adish Singla, Ilija Bogunovic, G{\'a}bor Bart{\'o}k, Amin Karbasi, and Andreas
  Krause.
\newblock Near-optimally teaching the crowd to classify.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Soma and Yoshida(2015)]{soma2015generalization}
Tasuku Soma and Yuichi Yoshida.
\newblock A generalization of submodular cover via the diminishing return
  property on the integer lattice.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  847--855, 2015.

\bibitem[Staib and Jegelka(2017)]{staib2017robust}
Matthew Staib and Stefanie Jegelka.
\newblock {Robust Budget Allocation via Continuous Submodular Functions}.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, pages 3230--3240, 2017.

\bibitem[Tschiatschek et~al.(2017)Tschiatschek, Singla, and
  Krause]{tschiatschek2017selecting}
Sebastian Tschiatschek, Adish Singla, and Andreas Krause.
\newblock Selecting sequences of items via submodular maximization.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, pages
  2667--2673, 2017.

\bibitem[Wolsey(1982{\natexlab{a}})]{wolsey1982analysis}
Laurence~A Wolsey.
\newblock An analysis of the greedy algorithm for the submodular set covering
  problem.
\newblock \emph{Combinatorica}, 1982{\natexlab{a}}.

\bibitem[Wolsey(1982{\natexlab{b}})]{wolsey82}
Laurence~A. Wolsey.
\newblock An analysis of the greedy algorithm for the submodular set covering
  problem.
\newblock \emph{Combinatorica}, 1982{\natexlab{b}}.

\bibitem[Xie et~al.(2019)Xie, Zhang, Shen, Mi, and Qian]{xie2019decentralized}
Jiahao Xie, Chao Zhang, Zebang Shen, Chao Mi, and Hui Qian.
\newblock Decentralized gradient tracking for continuous dr-submodular
  maximization.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2019.

\bibitem[Zhang et~al.(2019)Zhang, Chen, Hassani, and Karbasi]{zhang2019online}
Mingrui Zhang, Lin Chen, Hamed Hassani, and Amin Karbasi.
\newblock Online continuous submodular maximization: From full-information to
  bandit feedback.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Zhang et~al.(2020)Zhang, Shen, Mokhtari, Hassani, and
  Karbasi]{zhang2019sample}
Mingrui Zhang, Zebang Shen, Aryan Mokhtari, Hamed Hassani, and Amin Karbasi.
\newblock One sample stochastic frank-wolfe.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2020.

\end{thebibliography}
