\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, and Fischer]{ucb1}
P.~Auer, N.~Cesa-Bianchi, and P.~Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock \emph{Machine learning}, 47\penalty0 (2):\penalty0 235--256, 2002.

\bibitem[Binois and Wycoff(2022)]{telosurvey}
M.~Binois and N.~Wycoff.
\newblock A survey on high-dimensional {G}aussian process modeling with
  application to {B}ayesian optimization.
\newblock \emph{{ACM} Transactions on Evolutionary Learning and Optimization},
  2\penalty0 (2):\penalty0 1--26, 2022.

\bibitem[Binois et~al.(2015)Binois, Ginsbourger, and Roustant]{rembophi}
M.~Binois, D.~Ginsbourger, and O.~Roustant.
\newblock A warped kernel improving robustness in {B}ayesian optimization via
  random embeddings.
\newblock In \emph{Proceedings of the 9th International Conference on Learning
  and Intelligent Optimization (LION'15)}, pages 281--286, Lille, France, 2015.

\bibitem[Binois et~al.(2020)Binois, Ginsbourger, and Roustant]{rembogamma}
M.~Binois, D.~Ginsbourger, and O.~Roustant.
\newblock On the choice of the low-dimensional domain for global optimization
  via random embeddings.
\newblock \emph{Journal of Global Optimization}, 76\penalty0 (1):\penalty0
  69--90, 2020.

\bibitem[Browne et~al.(2012)Browne, Powley, Whitehouse, Lucas, Cowling,
  Rohlfshagen, Tavener, Liebana, Samothrakis, and Colton]{mctssurvey}
C.~Browne, E.~J. Powley, D.~Whitehouse, S.~M.~M. Lucas, P.~I. Cowling,
  P.~Rohlfshagen, S.~Tavener, D.~P. Liebana, S.~Samothrakis, and S.~Colton.
\newblock A survey of {M}onte {C}arlo tree search methods.
\newblock \emph{IEEE Transactions on Computational Intelligence and AI in
  Games}, 4\penalty0 (1):\penalty0 1--43, 2012.

\bibitem[Calandra et~al.(2015)Calandra, Seyfarth, Peters, and Deisenroth]{borl}
R.~Calandra, A.~Seyfarth, J.~Peters, and M.~P. Deisenroth.
\newblock Bayesian optimization for learning gaits under uncertainty.
\newblock \emph{Annals of Mathematics and Artificial Intelligence}, 76\penalty0
  (1):\penalty0 5--23, 2015.

\bibitem[Dong and Yang(2020)]{Dong2020NAS-Bench-201}
X.~Dong and Y.~Yang.
\newblock {NAS}-{B}ench-201: {E}xtending the scope of reproducible neural
  architecture search.
\newblock In \emph{Proceedings of the 8th International Conference on Learning
  Representations (ICLR'20)}, Addis Ababa, Ethiopia, 2020.

\bibitem[Duan et~al.(2021)Duan, Chen, Xu, Chen, Liang, Zhang, and Li]{transnas}
Y.~Duan, X.~Chen, H.~Xu, Z.~Chen, X.~Liang, T.~Zhang, and Z.~Li.
\newblock {T}rans{NAS}-{B}ench-101: {I}mproving transferability and
  generalizability of cross-task neural architecture search.
\newblock \emph{CoRR abs/2105.11871}, 2021.

\bibitem[Eriksson and Jankowiak(2021)]{saas}
D.~Eriksson and M.~Jankowiak.
\newblock High-dimensional {B}ayesian optimization with sparse axis-aligned
  subspaces.
\newblock In \emph{Proceedings of the 37th Conference on Uncertainty in
  Artificial Intelligence (UAI'21)}, pages 493--503, Virtual, 2021.

\bibitem[Eriksson et~al.(2019)Eriksson, Pearce, Gardner, Turner, and
  Poloczek]{turbo}
D.~Eriksson, M.~Pearce, J.~R. Gardner, R.~D. Turner, and M.~Poloczek.
\newblock Scalable global optimization via local {B}ayesian optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 32
  (NeurIPS'19)}, pages 5497--5508, Vancouver, Canada, 2019.

\bibitem[Frazier(2018)]{bosurvey2}
P.~I. Frazier.
\newblock A tutorial on {B}ayesian optimization.
\newblock \emph{CoRR abs/1807.02811}, 2018.

\bibitem[G{\'o}mez-Bombarelli et~al.(2018)G{\'o}mez-Bombarelli, Duvenaud,
  Hern{\'a}ndez-Lobato, Aguilera-Iparraguirre, Hirzel, Adams, and
  Aspuru-Guzik]{vae1}
R.~G{\'o}mez-Bombarelli, D.~K. Duvenaud, J.~M. Hern{\'a}ndez-Lobato,
  J.~Aguilera-Iparraguirre, T.D. Hirzel, R.~P. Adams, and A.~Aspuru-Guzik.
\newblock Automatic chemical design using a data-driven continuous
  representation of molecules.
\newblock \emph{ACS Central Science}, 4\penalty0 (2):\penalty0 268 -- 276,
  2018.

\bibitem[Han et~al.(2021)Han, Arora, and Scarlett]{addtreestructure}
E.~Han, I.~Arora, and J.~Scarlett.
\newblock High-dimensional {B}ayesian optimization via tree-structured additive
  models.
\newblock In \emph{Proceedings of the 35th Association for the Advancement of
  Artificial Intelligence (AAAI'21)}, pages 7630--7638, Virtual, 2021.

\bibitem[Hansen(2016)]{cmaes}
N.~Hansen.
\newblock The {CMA} evolution strategy: {A} tutorial.
\newblock \emph{CoRR abs/1604.00772}, 2016.

\bibitem[Hoang et~al.(2018)Hoang, Hoang, Ouyang, and Low]{factorgraph}
T.~N. Hoang, Q.~M. Hoang, R.~Ouyang, and K.~H. Low.
\newblock Decentralized high-dimensional {B}ayesian optimization with factor
  graphs.
\newblock In \emph{Proceedings of the 32nd Association for the Advancement of
  Artificial Intelligence (AAAI'18)}, pages 3231--3239, New Orleans, LA, 2018.

\bibitem[Jones et~al.(1998)Jones, Schonlau, and Welch]{ei2}
D.~R. Jones, M.~Schonlau, and W.~J. Welch.
\newblock Efficient global optimization of expensive black-box functions.
\newblock \emph{Journal of Global Optimization}, 13\penalty0 (4):\penalty0
  455--492, 1998.

\bibitem[Kandasamy et~al.(2015)Kandasamy, Schneider, and P{\'o}czos]{addgpucb}
K.~Kandasamy, J.~G. Schneider, and B.~P{\'o}czos.
\newblock High dimensional {B}ayesian optimisation and bandits via additive
  models.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning (ICML'15)}, pages 295--304, Lille, France, 2015.

\bibitem[Kingma and Welling(2014)]{Kingma2014AutoEncodingVB}
D.~P. Kingma and M.~Welling.
\newblock Auto-encoding variational {B}ayes.
\newblock \emph{CoRR abs/1312.6114}, 2014.

\bibitem[Kushner(1964)]{Krushner64PI}
H.~J. Kushner.
\newblock A new method of locating the maximum point of an arbitrary multipeak
  curve in the presence of noise.
\newblock \emph{Journal of Basic Engineering}, 86\penalty0 (1):\penalty0
  97--106, 1964.

\bibitem[Letham et~al.(2020)Letham, Calandra, Rai, and Bakshy]{alebo}
B.~Letham, R.~Calandra, A.~Rai, and E.~Bakshy.
\newblock Re-examining linear embeddings for high-dimensional {B}ayesian
  optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 33
  (NeurIPS'20)}, pages 1546--1558, Vancouver, Canada, 2020.

\bibitem[Li et~al.(2017)Li, Gupta, Rana, Nguyen, Venkatesh, and
  Shilton]{dropout}
C.~Li, S.~Gupta, S.~Rana, V.~Nguyen, S.~Venkatesh, and A.~Shilton.
\newblock High dimensional {B}ayesian optimization using dropout.
\newblock In \emph{Proceedings of the 26th International Joint Conference on
  Artificial Intelligence (IJCAI'17)}, pages 2096--2102, Melbourne, Australia,
  2017.

\bibitem[Lu et~al.(2018)Lu, Gonz{\'a}lez, Dai, and Lawrence]{vae2}
X.~Lu, J.~I. Gonz{\'a}lez, Z.~Dai, and N.~D. Lawrence.
\newblock Structured variationally auto-encoded optimization.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning (ICML'18)}, pages 3306--3314, Stockholm, Sweden, 2018.

\bibitem[Malu et~al.(2021)Malu, Dasarathy, and Spanias]{bosurvey3}
M.~Malu, G.~Dasarathy, and A.~Spanias.
\newblock {B}ayesian optimization in high-dimensional spaces: {A} brief survey.
\newblock In \emph{Proceedings of the 12th International Conference on
  Information, Intelligence, Systems \& Applications (IISA'21)}, pages 1--8,
  Virtual, 2021.

\bibitem[McKay et~al.(1979)McKay, Beckman, and Conover]{lhs}
M.~D. McKay, R.~J. Beckman, and W.~J. Conover.
\newblock A comparison of three methods for selecting values of input variables
  in the analysis of output from a computer code.
\newblock \emph{Technometrics}, 21\penalty0 (2):\penalty0 239--245, 1979.

\bibitem[Mehrotra et~al.(2021)Mehrotra, Ramos, Bhattacharya, Dudziak, Vipperla,
  Chau, Abdelfattah, Ishtiaq, and Lane]{mehrotra2021nasbenchasr}
A.~Mehrotra, A.~G. C.~P. Ramos, S.~Bhattacharya, {\L}.~Dudziak, R.~Vipperla,
  T.~Chau, M.~S. Abdelfattah, S.~Ishtiaq, and N.~D. Lane.
\newblock {NAS}-{B}ench-{ASR}: {R}eproducible neural architecture search for
  speech recognition.
\newblock In \emph{Proceedings of the 9th International Conference on Learning
  Representations (ICLR'21)}, Virtual, 2021.

\bibitem[Mutn{\'y} and Krause(2018)]{addoverlapping2}
M.~Mutn{\'y} and A.~Krause.
\newblock Efficient high dimensional {B}ayesian optimization with additivity
  and quadrature {F}ourier features.
\newblock In \emph{Advances in Neural Information Processing Systems 31
  (NeurIPS'18)}, pages 9005--9016, Montreal, Canada, 2018.

\bibitem[Nayebi et~al.(2019)Nayebi, Munteanu, and Poloczek]{hesbo}
A.~Nayebi, A.~Munteanu, and M.~Poloczek.
\newblock A framework for {B}ayesian optimization in embedded subspaces.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  LearninG (ICML'19)}, pages 4752--4761, Long Beach, CA, 2019.

\bibitem[Nocedal and Wright(2006)]{NoceWrig06}
J.~Nocedal and S.~J. Wright.
\newblock \emph{{N}umerical {O}ptimization}.
\newblock Springer, New York, NY, second edition edition, 2006.

\bibitem[Qian et~al.(2020)Qian, Xiong, and Xue]{bopp}
C.~Qian, H.~Xiong, and K.~Xue.
\newblock Bayesian optimization using pseudo-points.
\newblock In \emph{Proceedings of the 29th International Joint Conference on
  Artificial Intelligence (IJCAI'20)}, pages 3044--3050, Yokohama, Japan, 2020.

\bibitem[Rasmussen and Williams(2006)]{gp}
C.~E. Rasmussen and C.~K.~I. Williams.
\newblock \emph{{G}aussian {P}rocesses for {M}achine {L}earning}.
\newblock The MIT Press, Cambridge, MA, 2006.

\bibitem[Rolland et~al.(2018)Rolland, Scarlett, Bogunovic, and
  Cevher]{addoverlapping1}
P.~Rolland, J.~Scarlett, I.~Bogunovic, and V.~Cevher.
\newblock High-dimensional {B}ayesian optimization via additive models with
  overlapping groups.
\newblock In \emph{Proceedings of the 21st International Conference on
  Artificial Intelligence and Statistics (AISTATS'18)}, pages 298--307, Playa
  Blanca, Spain, 2018.

\bibitem[Shahriari et~al.(2015)Shahriari, Swersky, Wang, Adams, and
  De~Freitas]{bosurvey1}
B.~Shahriari, K.~Swersky, Z.~Wang, R.~P. Adams, and N.~De~Freitas.
\newblock Taking the human out of the loop: {A} review of {B}ayesian
  optimization.
\newblock \emph{Proceedings of the IEEE}, 104\penalty0 (1):\penalty0 148--175,
  2015.

\bibitem[Shen and Kingsford(2021)]{vsbo}
Y.~Shen and C.~Kingsford.
\newblock Computationally efficient high-dimensional {B}ayesian optimization
  via variable selection.
\newblock \emph{CoRR abs/2109.09264}, 2021.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, van~den
  Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot, Dieleman,
  Grewe, Nham, Kalchbrenner, Sutskever, Lillicrap, Leach, Kavukcuoglu, Graepel,
  and Hassabis]{mctsgo}
D.~Silver, A.~Huang, C.~J. Maddison, A.~Guez, L.~Sifre, G.~van~den Driessche,
  J.~Schrittwieser, I.~Antonoglou, V.~Panneershelvam, M.~Lanctot, S.~Dieleman,
  D.~Grewe, J.~Nham, N.~Kalchbrenner, I.~Sutskever, T.~P. Lillicrap, M.~Leach,
  K.~Kavukcuoglu, T.~Graepel, and D.~Hassabis.
\newblock Mastering the game of {G}o with deep neural networks and tree search.
\newblock \emph{Nature}, 529\penalty0 (7587):\penalty0 484--489, 2016.

\bibitem[Silver et~al.(2017)Silver, Schrittwieser, Simonyan, Antonoglou, Huang,
  Guez, Hubert, baker, Lai, Bolton, Chen, Lillicrap, Hui, Sifre, van~den
  Driessche, Graepel, and Hassabis]{mctsgo1}
D.~Silver, J.~Schrittwieser, K.~Simonyan, I.~Antonoglou, A.~Huang, A.~Guez,
  T.~Hubert, L.~baker, M.~Lai, A.~Bolton, Y.~Chen, T.~P. Lillicrap, F.~Hui,
  L.~Sifre, G.~van~den Driessche, T.~Graepel, and D.~Hassabis.
\newblock Mastering the game of {G}o without human knowledge.
\newblock \emph{Nature}, 550\penalty0 (7676):\penalty0 354--359, 2017.

\bibitem[Snoek et~al.(2015)Snoek, Rippel, Swersky, Kiros, Satish, Sundaram,
  Patwary, Prabhat, and Adams]{dngo}
J.~Snoek, O.~Rippel, K.~Swersky, R.~Kiros, N.~Satish, N.~Sundaram, M.~M.~A.
  Patwary, Prabhat, and R.~P. Adams.
\newblock Scalable {B}ayesian optimization using deep neural networks.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning (ICML'15)}, pages 2171--2180, Lille, France, 2015.

\bibitem[Spagnol et~al.(2019)Spagnol, Riche, and Veiga]{hsicbo}
A.~Spagnol, R.~L. Riche, and S.~D. Veiga.
\newblock Bayesian optimization in effective dimensions via kernel-based
  sensitivity indices.
\newblock In \emph{Proceedings of the 13th International Conference on
  Applications of Statistics and Probability in Civil Engineering (ICASP'13)},
  Seoul, Korea, 2019.

\bibitem[Srinivas et~al.(2012)Srinivas, Krause, Kakade, and Seeger]{gpucb}
N.~Srinivas, A.~Krause, S.~M. Kakade, and M.~W. Seeger.
\newblock Information-theoretic regret bounds for {G}aussian process
  optimization in the bandit setting.
\newblock \emph{IEEE Transactions on Information Theory}, 58\penalty0
  (5):\penalty0 3250--3265, 2012.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{mujoco}
E.~Todorov, E.~Erez, and Y.~Tassa.
\newblock Mu{J}o{C}o: {A} physics engine for model-based control.
\newblock \emph{IEEE/RSJ International Conference on Intelligent Robots and
  Systems}, pages 5026--5033, 2012.

\bibitem[Wang et~al.(2020)Wang, Fonseca, and Tian]{lamcts}
L.~Wang, R.~Fonseca, and Y.~Tian.
\newblock Learning search space partition for black-box optimization using
  {M}onte {C}arlo tree search.
\newblock In \emph{Advances in Neural Information Processing Systems 33
  (NeurIPS'20)}, pages 19511--19522, Vancouver, Canada, 2020.

\bibitem[Wang et~al.(2021)Wang, Xie, Li, Fonseca, and Tian]{lanas}
L.~Wang, S.~Xie, T.~Li, R.~Fonseca, and Y.~Tian.
\newblock Sample-efficient neural architecture search by learning actions for
  {M}onte {C}arlo tree search.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2021.

\bibitem[Wang et~al.(2016)Wang, Hutter, Zoghi, Matheson, and de~Feitas]{rembo}
Z.~Wang, F.~Hutter, M.~Zoghi, D.~Matheson, and N.~de~Feitas.
\newblock Bayesian optimization in a billion dimensions via random embeddings.
\newblock \emph{Journal of Artificial Intelligence Research}, 55\penalty0
  (1):\penalty0 361--387, 2016.

\bibitem[Wang et~al.(2018)Wang, Gehring, Kohli, and Jegelka]{ebo}
Z.~Wang, C.~Gehring, P.~Kohli, and S.~Jegelka.
\newblock Batched large-scale {B}ayesian optimization in high-dimensional
  spaces.
\newblock In \emph{Proceedings of the 21st International Conference on
  Artificial Intelligence and Statistics (AISTATS'18)}, pages 745--754, Playa
  Blanca, Spain, 2018.

\bibitem[Wilson et~al.(2017)Wilson, Moriconi, Hutter, and Deisenroth]{qei}
J.~T. Wilson, R.~Moriconi, F.~Hutter, and M.~P. Deisenroth.
\newblock The reparameterization trick for acquisition functions.
\newblock \emph{CoRR abs/1712.00424}, 2017.

\bibitem[Ying et~al.(2019)Ying, Klein, Christiansen, Real, Murphy, and
  Hutter]{nas101}
C.~Ying, A.~Klein, E.~Christiansen, E.~Real, K.~Murphy, and F.~Hutter.
\newblock {NAS}-bench-101: {T}owards reproducible neural architecture search.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning (ICML'19)}, pages 7105--7114, Long Beach, CA, 2019.

\bibitem[Zela et~al.(2020)Zela, Siems, and Hutter]{Zela2020NAS-Bench-1Shot1}
A.~Zela, J.~Siems, and F.~Hutter.
\newblock {NAS}-{B}ench-1{S}hot1: {B}enchmarking and dissecting one-shot neural
  architecture search.
\newblock In \emph{Proceedings of the 8th International Conference on Learning
  Representations (ICLR'20)}, Addis Ababa, Ethiopia, 2020.

\end{thebibliography}
