\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{CKMY20}

\bibitem[AL88]{AL88}
D.~Angluin and P.~Laird.
\newblock Learning from noisy examples.
\newblock {\em Mach. Learn.}, 2(4):343--370, 1988.

\bibitem[ALNS20]{AggarwalLNS20}
D.~Aggarwal, J.~Li, P.~Q. Nguyen, and N.~Stephens{-}Davidowitz.
\newblock Slide reduction, revisited - filling the gaps in {SVP} approximation.
\newblock In {\em Advances in Cryptology - {CRYPTO} 2020 - 40th Annual
  International Cryptology Conference, {CRYPTO} 2020}, volume 12171 of {\em
  Lecture Notes in Computer Science}, pages 274--295. Springer, 2020.

\bibitem[BFKV96]{BlumFKV96}
A.~Blum, A.~M. Frieze, R.~Kannan, and S.~Vempala.
\newblock A polynomial-time algorithm for learning noisy linear threshold
  functions.
\newblock In {\em 37th Annual Symposium on Foundations of Computer Science,
  {FOCS} '96}, pages 330--338, 1996.

\bibitem[BK09]{beigman2009learning}
E.~Beigman and B.~B. Klebanov.
\newblock Learning with annotation noise.
\newblock In {\em Proceedings of the Joint Conference of the 47th Annual
  Meeting of the ACL and the 4th International Joint Conference on Natural
  Language Processing of the AFNLP}, pages 280--287, 2009.

\bibitem[Blu03]{Blum03}
A.~Blum.
\newblock Machine learning: My favorite results, directions, and open problems.
\newblock In {\em 44th Symposium on Foundations of Computer Science {(FOCS}
  2003)}, pages 11--14, 2003.

\bibitem[BRST21]{Bruna0ST21}
J.~Bruna, O.~Regev, M.~J. Song, and Y.~Tang.
\newblock Continuous {LWE}.
\newblock In {\em {STOC} '21: 53rd Annual {ACM} {SIGACT} Symposium on Theory of
  Computing}, pages 694--707. {ACM}, 2021.

\bibitem[CKMY20]{CKMY20}
S.~Chen, F.~Koehler, A.~Moitra, and M.~Yau.
\newblock Classification under misspecification: Halfspaces, generalized linear
  models, and connections to evolvability.
\newblock {\em CoRR}, abs/2006.04787, 2020.
\newblock Appeared in NeurIPS'20.

\bibitem[Coh97]{Cohen:97}
E.~Cohen.
\newblock Learning noisy perceptrons by a perceptron in polynomial time.
\newblock In {\em Proceedings of the Thirty-Eighth Symposium on Foundations of
  Computer Science}, pages 514--521, 1997.

\bibitem[Dan16]{Daniely16}
A.~Daniely.
\newblock Complexity theoretic limitations on learning halfspaces.
\newblock In {\em Proceedings of the 48th Annual Symposium on Theory of
  Computing, {STOC} 2016}, pages 105--117, 2016.

\bibitem[DGT19]{DGT19}
I.~Diakonikolas, T.~Gouleakis, and C.~Tzamos.
\newblock Distribution-independent {PAC} learning of halfspaces with massart
  noise.
\newblock In Hanna~M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence
  d'Alch{\'{e}}{-}Buc, Emily~B. Fox, and Roman Garnett, editors, {\em Advances
  in Neural Information Processing Systems 32: Annual Conference on Neural
  Information Processing Systems 2019, NeurIPS 2019}, pages 4751--4762, 2019.

\bibitem[DIK{\etalchar{+}}21]{DiakonikolasIKL21}
I.~Diakonikolas, R.~Impagliazzo, D.~M. Kane, R.~Lei, J.~Sorrell, and C.~Tzamos.
\newblock Boosting in the presence of massart noise.
\newblock In {\em Conference on Learning Theory, {COLT} 2021}, volume 134 of
  {\em Proceedings of Machine Learning Research}, pages 1585--1644. {PMLR},
  2021.

\bibitem[DK22]{diakonikolas2021near}
I.~Diakonikolas and D.~M. Kane.
\newblock Near-optimal statistical query hardness of learning halfspaces with
  massart noise.
\newblock In {\em Conference on Learning Theory, {COLT} 2022}, volume 178 of
  {\em Proceedings of Machine Learning Research}, pages 4258--4282. {PMLR},
  2022.
\newblock Full version available at https://arxiv.org/abs/2012.09720.

\bibitem[DKT21]{DKT21}
I.~Diakonikolas, D.~Kane, and C.~Tzamos.
\newblock Forster decomposition and learning halfspaces with noise.
\newblock In {\em Advances in Neural Information Processing Systems 34: Annual
  Conference on Neural Information Processing Systems 2021, NeurIPS 2021},
  pages 7732--7744, 2021.

\bibitem[FGKP06]{FGK+:06short}
V.~Feldman, P.~Gopalan, S.~Khot, and A.~Ponnuswami.
\newblock New results for learning noisy parities and halfspaces.
\newblock In {\em Proc. FOCS}, pages 563--576, 2006.

\bibitem[GR06]{GR:06}
V.~Guruswami and P.~Raghavendra.
\newblock {Hardness of learning halfspaces with noise}.
\newblock In {\em FOCS 2006}, pages 543--552. IEEE Computer Society, 2006.

\bibitem[GVV22]{vinod2022}
A.~Gupte, N.~Vafa, and V.~Vaikuntanathan.
\newblock Continuous lwe is as hard as lwe \& applications to learning gaussian
  mixtures.
\newblock {\em arXiv preprint arXiv:2204.02550}, 2022.

\bibitem[Hau92]{Haussler:92}
D.~Haussler.
\newblock {Decision theoretic generalizations of the PAC model for neural net
  and other learning applications}.
\newblock {\em Information and Computation}, 100:78--150, 1992.

\bibitem[Kea98]{Kearns:98}
M.~J. Kearns.
\newblock Efficient noise-tolerant learning from statistical queries.
\newblock {\em Journal of the ACM}, 45(6):983--1006, 1998.

\bibitem[KSS94]{KSS:94}
M.~Kearns, R.~Schapire, and L.~Sellie.
\newblock {Toward Efficient Agnostic Learning}.
\newblock {\em Machine Learning}, 17(2/3):115--141, 1994.

\bibitem[LP11]{lindner2011better}
R.~Lindner and C.~Peikert.
\newblock Better key sizes (and attacks) for lwe-based encryption.
\newblock In {\em Cryptographersâ€™ Track at the RSA Conference}, pages
  319--339. Springer, 2011.

\bibitem[MG02]{micciancio2002complexity}
D.~Micciancio and S.~Goldwasser.
\newblock {\em Complexity of lattice problems: a cryptographic perspective},
  volume 671.
\newblock Springer Science \& Business Media, 2002.

\bibitem[Mic18a]{Mic18}
D.~Micciancio.
\newblock On the hardness of learning with errors with binary secrets.
\newblock {\em Theory Comput.}, 14(1):1--17, 2018.

\bibitem[Mic18b]{micciancio2018hardness}
D.~Micciancio.
\newblock On the hardness of learning with errors with binary secrets.
\newblock {\em Theory of Computing}, 14(1):1--17, 2018.

\bibitem[MN06]{Massart2006}
P.~Massart and E.~Nedelec.
\newblock Risk bounds for statistical learning.
\newblock {\em Ann. Statist.}, 34(5):2326--2366, 10 2006.

\bibitem[MP68]{MinskyPapert:68}
M.~Minsky and S.~Papert.
\newblock {\em {P}erceptrons: an introduction to computational geometry}.
\newblock MIT Press, Cambridge, MA, 1968.

\bibitem[MR07]{micciancio2007worst}
D.~Micciancio and O.~Regev.
\newblock Worst-case to average-case reductions based on gaussian measures.
\newblock {\em SIAM Journal on Computing}, 37(1):267--302, 2007.

\bibitem[Nov62]{Novikoff:62}
A.~Novikoff.
\newblock On convergence proofs on perceptrons.
\newblock In {\em Proceedings of the Symposium on Mathematical Theory of
  Automata}, volume XII, pages 615--622, 1962.

\bibitem[NT22]{nassert22}
R.~Nasser and S.~Tiegel.
\newblock Optimal {SQ} lower bounds for learning halfspaces with massart noise.
\newblock In {\em Conference on Learning Theory, {COLT} 2022}, volume 178 of
  {\em Proceedings of Machine Learning Research}, pages 1047--1074. {PMLR},
  2022.

\bibitem[Pei09]{Peikert09}
C.~Peikert.
\newblock Public-key cryptosystems from the worst-case shortest vector problem:
  extended abstract.
\newblock In {\em Proceedings of the 41st Annual {ACM} Symposium on Theory of
  Computing, {STOC} 2009, 2009}, pages 333--342. {ACM}, 2009.

\bibitem[Reg09]{regev2009lattices}
O.~Regev.
\newblock On lattices, learning with errors, random linear codes, and
  cryptography.
\newblock {\em Journal of the ACM (JACM)}, 56(6):1--40, 2009.

\bibitem[Ros58]{Rosenblatt:58}
F.~Rosenblatt.
\newblock The {P}erceptron: a probabilistic model for information storage and
  organization in the brain.
\newblock {\em Psychological Review}, 65:386--407, 1958.

\bibitem[RS94]{RivestSloan:94}
R.~Rivest and R.~Sloan.
\newblock A formal model of hierarchical concept learning.
\newblock {\em Information and Computation}, 114(1):88--114, 1994.

\bibitem[Slo88]{Sloan88}
R.~H. Sloan.
\newblock Types of noise in data for concept learning.
\newblock In {\em Proceedings of the First Annual Workshop on Computational
  Learning Theory}, COLT '88, pages 91--96, San Francisco, CA, USA, 1988.
  Morgan Kaufmann Publishers Inc.

\bibitem[Slo96]{Sloan96}
R.~H. Sloan.
\newblock {\em Pac Learning, Noise, and Geometry}, pages 21--41.
\newblock Birkh{\"a}user Boston, Boston, MA, 1996.

\bibitem[Tie22]{Tieg22}
S.~Tiegel.
\newblock Hardness of agnostically learning halfspaces from worst-case lattice
  problems.
\newblock Personal communication, July 2022.

\bibitem[Val84]{val84}
L.~G. Valiant.
\newblock A theory of the learnable.
\newblock In {\em STOC}, pages 436--445. acm, 1984.

\bibitem[Vap82]{Vapnik82}
V.~Vapnik.
\newblock {\em Estimation of Dependences Based on Empirical Data: Springer
  Series in Statistics}.
\newblock Springer-Verlag, Berlin, Heidelberg, 1982.

\end{thebibliography}
