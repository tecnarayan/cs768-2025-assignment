\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alquier et~al.(2019)Alquier, Cottet, and
  Lecu{\'e}]{alquier2019estimation}
Pierre Alquier, Vincent Cottet, and Guillaume Lecu{\'e}.
\newblock Estimation bounds and sharp oracle inequalities of regularized
  procedures with lipschitz loss functions.
\newblock \emph{The Annals of Statistics}, 47\penalty0 (4):\penalty0
  2117--2144, 2019.

\bibitem[Bellec(2018{\natexlab{a}})]{bellec2018nb_lsb}
Pierre~C Bellec.
\newblock The noise barrier and the large signal bias of the lasso and other
  convex estimators.
\newblock \emph{arXiv:1804.01230}, 2018{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/pdf/1804.01230.pdf}.

\bibitem[Bellec(2018{\natexlab{b}})]{bellec2018sharp}
Pierre~C Bellec.
\newblock Sharp oracle inequalities for least squares estimators in shape
  restricted regression.
\newblock \emph{The Annals of Statistics}, 46\penalty0 (2):\penalty0 745--780,
  2018{\natexlab{b}}.

\bibitem[Bellec and Zhang(2019)]{bellec_zhang2019debiasing_adjust}
Pierre~C Bellec and Cun-Hui Zhang.
\newblock De-biasing the lasso with degrees-of-freedom adjustment.
\newblock \emph{arXiv:1902.08885}, 2019.
\newblock URL \url{https://arxiv.org/pdf/1902.08885.pdf}.

\bibitem[Bellec et~al.(2017)Bellec, Lecu{\'e}, and Tsybakov]{bellec2017towards}
Pierre~C Bellec, Guillaume Lecu{\'e}, and Alexandre~B Tsybakov.
\newblock Towards the study of least squares estimators with convex penalty.
\newblock In \emph{Seminaire et Congres, to appear}, number~39. Societe
  mathematique de France, 2017.
\newblock URL \url{https://arxiv.org/pdf/1701.09120.pdf}.

\bibitem[Bellec et~al.(2018{\natexlab{a}})Bellec, Dalalyan, Grappin, and
  Paris]{bellec2018prediction}
Pierre~C Bellec, Arnak~S Dalalyan, Edwin Grappin, and Quentin Paris.
\newblock On the prediction loss of the lasso in the partially labeled setting.
\newblock \emph{Electronic Journal of Statistics}, 12\penalty0 (2):\penalty0
  3443--3472, 2018{\natexlab{a}}.

\bibitem[Bellec et~al.(2018{\natexlab{b}})Bellec, Lecu\'e, and
  Tsybakov]{bellec2016slope}
Pierre~C. Bellec, Guillaume Lecu\'e, and Alexandre~B. Tsybakov.
\newblock Slope meets lasso: Improved oracle bounds and optimality.
\newblock \emph{Ann. Statist.}, 46\penalty0 (6B):\penalty0 3603--3642,
  2018{\natexlab{b}}.
\newblock ISSN 0090-5364.
\newblock \doi{10.1214/17-AOS1670}.
\newblock URL \url{https://arxiv.org/pdf/1605.08651.pdf}.

\bibitem[Belloni and Chernozhukov(2013)]{belloni2013least}
Alexandre Belloni and Victor Chernozhukov.
\newblock Least squares after model selection in high-dimensional sparse
  models.
\newblock \emph{Bernoulli}, 19\penalty0 (2):\penalty0 521--547, 2013.

\bibitem[Belloni et~al.(2014)Belloni, Chernozhukov, and
  Wang]{belloni2014pivotal}
Alexandre Belloni, Victor Chernozhukov, and Lie Wang.
\newblock Pivotal estimation via square-root lasso in nonparametric regression.
\newblock \emph{Ann. Statist.}, 42\penalty0 (2):\penalty0 757--788, 04 2014.
\newblock URL \url{http://dx.doi.org/10.1214/14-AOS1204}.

\bibitem[Belloni et~al.(2016)Belloni, Chernozhukov, and Wei]{belloni2016post}
Alexandre Belloni, Victor Chernozhukov, and Ying Wei.
\newblock Post-selection inference for generalized linear models with many
  controls.
\newblock \emph{Journal of Business \& Economic Statistics}, 34\penalty0
  (4):\penalty0 606--619, 2016.

\bibitem[Bickel et~al.(2009)Bickel, Ritov, and
  Tsybakov]{bickel2009simultaneous}
Peter~J. Bickel, Ya'acov Ritov, and Alexandre~B. Tsybakov.
\newblock Simultaneous analysis of lasso and dantzig selector.
\newblock \emph{Ann. Statist.}, 37\penalty0 (4):\penalty0 1705--1732, 08 2009.
\newblock \doi{10.1214/08-AOS620}.
\newblock URL \url{http://dx.doi.org/10.1214/08-AOS620}.

\bibitem[Boucheron et~al.(2013)Boucheron, Lugosi, and
  Massart]{boucheron2013concentration}
St{\'e}phane Boucheron, G{\'a}bor Lugosi, and Pascal Massart.
\newblock \emph{Concentration inequalities: A nonasymptotic theory of
  independence}.
\newblock Oxford University Press, 2013.

\bibitem[Cai and Zhou(2009)]{cai2009data}
T~Tony Cai and Harrison~H Zhou.
\newblock A data-driven block thresholding approach to wavelet estimation.
\newblock \emph{The Annals of Statistics}, 37\penalty0 (2):\penalty0 569--595,
  2009.

\bibitem[Candes(2006)]{candes2006modern}
Emmanuel~J Candes.
\newblock Modern statistical estimation via oracle inequalities.
\newblock \emph{Acta numerica}, 15:\penalty0 257--325, 2006.

\bibitem[Dedieu(2018)]{dedieu2018error}
Antoine Dedieu.
\newblock Error bounds for sparse classifiers in high-dimensions.
\newblock \emph{arXiv preprint arXiv:1810.03081}, 2018.

\bibitem[Dirksen(2015)]{dirksen2015tail}
Sjoerd Dirksen.
\newblock Tail bounds via generic chaining.
\newblock \emph{Electronic Journal of Probability}, 20, 2015.

\bibitem[Hastie et~al.(2015)Hastie, Tibshirani, and
  Wainwright]{hastie2015statistical}
Trevor Hastie, Robert Tibshirani, and Martin Wainwright.
\newblock \emph{Statistical learning with sparsity: the lasso and
  generalizations}.
\newblock CRC press, 2015.

\bibitem[Hsu et~al.(2012)Hsu, Kakade, and Zhang]{hsu2012tail}
Daniel Hsu, Sham Kakade, and Tong Zhang.
\newblock A tail inequality for quadratic forms of subgaussian random vectors.
\newblock \emph{Electron. Commun. Probab.}, 17:\penalty0 no. 52, 1--6, 2012.
\newblock \doi{10.1214/ECP.v17-2079}.
\newblock URL \url{http://ecp.ejpecp.org/article/view/2079}.

\bibitem[Ichimura(1993)]{ichimura1993semiparametric}
Hidehiko Ichimura.
\newblock Semiparametric least squares (sls) and weighted sls estimation of
  single-index models.
\newblock \emph{Journal of Econometrics}, 58\penalty0 (1-2):\penalty0 71--120,
  1993.

\bibitem[Javanmard and Montanari(2014{\natexlab{a}})]{JavanmardM14a}
Adel Javanmard and Andrea Montanari.
\newblock Confidence intervals and hypothesis testing for high-dimensional
  regression.
\newblock \emph{The Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 2869--2909, 2014{\natexlab{a}}.

\bibitem[Javanmard and Montanari(2014{\natexlab{b}})]{JavanmardM14b}
Adel Javanmard and Andrea Montanari.
\newblock Hypothesis testing in high-dimensional regression under the gaussian
  random design model: Asymptotic theory.
\newblock \emph{IEEE Transactions on Information Theory}, 60\penalty0
  (10):\penalty0 6522--6554, 2014{\natexlab{b}}.

\bibitem[Javanmard and Montanari(2015)]{javanmard2015biasing}
Adel Javanmard and Andrea Montanari.
\newblock De-biasing the lasso: Optimal sample size for gaussian designs.
\newblock \emph{Annals of Statistics, to appear}, 2015.

\bibitem[Knight and Fu(2000)]{knight2000asymptotics}
Keith Knight and Wenjiang Fu.
\newblock Asymptotics for lasso-type estimators.
\newblock \emph{Annals of statistics}, pages 1356--1378, 2000.

\bibitem[Koltchinskii(2009)]{koltchinskii2009sparsity}
Vladimir Koltchinskii.
\newblock Sparsity in penalized empirical risk minimization.
\newblock In \emph{Annales de l'Institut Henri Poincar{\'e}, Probabilit{\'e}s
  et Statistiques}, volume~45, pages 7--57. Institut Henri Poincar{\'e}, 2009.

\bibitem[{Kuchibhotla}(2018)]{2018arXiv180905172K}
A.~K. {Kuchibhotla}.
\newblock {Deterministic Inequalities for Smooth M-estimators}.
\newblock \emph{ArXiv e-prints:1809.05172}, September 2018.

\bibitem[Lecué and Mendelson(2018)]{lecue2015regularization_small_ball_I}
Guillaume Lecué and Shahar Mendelson.
\newblock Regularization and the small-ball method i: Sparse recovery.
\newblock \emph{Ann. Statist.}, 46\penalty0 (2):\penalty0 611--641, 04 2018.
\newblock \doi{10.1214/17-AOS1562}.
\newblock URL \url{https://doi.org/10.1214/17-AOS1562}.

\bibitem[Lee et~al.(2014)Lee, Sun, and Saunders]{lee2014proximal}
Jason~D Lee, Yuekai Sun, and Michael~A Saunders.
\newblock Proximal newton-type methods for minimizing composite functions.
\newblock \emph{SIAM Journal on Optimization}, 24\penalty0 (3):\penalty0
  1420--1443, 2014.

\bibitem[Liaw et~al.(2017)Liaw, Mehrabian, Plan, and
  Vershynin]{plan_vershynin_liaw2017simple}
Christopher Liaw, Abbas Mehrabian, Yaniv Plan, and Roman Vershynin.
\newblock A simple tool for bounding the deviation of random matrices on
  geometric sets.
\newblock In \emph{Geometric aspects of functional analysis}, pages 277--299.
  Springer, 2017.

\bibitem[Liu and Zhang(2009)]{liu2009estimation}
Han Liu and Jian Zhang.
\newblock Estimation consistency of the group lasso and its applications.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 376--383,
  2009.

\bibitem[Loh(2017)]{loh2017statistical}
Po-Ling Loh.
\newblock Statistical consistency and asymptotic normality for high-dimensional
  robust $ m $-estimators.
\newblock \emph{The Annals of Statistics}, 45\penalty0 (2):\penalty0 866--896,
  2017.

\bibitem[Lounici et~al.(2011)Lounici, Pontil, van~de Geer, and
  Tsybakov]{lounici2011oracle}
Karim Lounici, Massimiliano Pontil, Sara van~de Geer, and Alexandre~B.
  Tsybakov.
\newblock Oracle inequalities and optimal inference under group sparsity.
\newblock \emph{Ann. Statist.}, 39\penalty0 (4):\penalty0 2164--2204, 08 2011.
\newblock \doi{10.1214/11-AOS896}.
\newblock URL \url{http://dx.doi.org/10.1214/11-AOS896}.

\bibitem[Mendelson(2010)]{mendelson2010empirical}
Shahar Mendelson.
\newblock Empirical processes with a bounded $\psi_1$ diameter.
\newblock \emph{Geometric and Functional Analysis}, 20\penalty0 (4):\penalty0
  988--1027, 2010.

\bibitem[Mendelson(2016)]{mendelson2016upper}
Shahar Mendelson.
\newblock {Upper bounds on product and multiplier empirical processes}.
\newblock \emph{Stochastic Processes and their Applications}, 126\penalty0
  (12):\penalty0 3652--3680, 2016.
\newblock \doi{10.1016/j.spa.2016.04.028}.
\newblock URL
  \url{https://ideas.repec.org/a/eee/spapps/v126y2016i12p3652-3680.html}.

\bibitem[Mitra and Zhang(2016)]{mitra2016benefit}
Ritwik Mitra and Cun-Hui Zhang.
\newblock The benefit of group sparsity in group inference with de-biased
  scaled group lasso.
\newblock \emph{Electronic Journal of Statistics}, 10\penalty0 (2):\penalty0
  1829--1873, 2016.

\bibitem[Negahban et~al.(2009)Negahban, Yu, Wainwright, and
  Ravikumar]{negahban2009unified}
Sahand Negahban, Bin Yu, Martin~J Wainwright, and Pradeep~K Ravikumar.
\newblock A unified framework for high-dimensional analysis of $ m $-estimators
  with decomposable regularizers.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1348--1356, 2009.

\bibitem[Rigollet and Tsybakov(2011)]{rigollet2011exponential}
Philippe Rigollet and Alexandre Tsybakov.
\newblock Exponential screening and optimal rates of sparse estimation.
\newblock \emph{The Annals of Statistics}, 39\penalty0 (2):\penalty0 731--771,
  2011.

\bibitem[Sun and Zhang(2013)]{sun2013sparse}
Tingni Sun and Cun-Hui Zhang.
\newblock Sparse matrix inversion with scaled lasso.
\newblock \emph{Journal of Machine Learning Research}, 14\penalty0
  (1):\penalty0 3385--3418, 2013.

\bibitem[Tibshirani(1996)]{tibshirani1996regression}
Robert Tibshirani.
\newblock Regression shrinkage and selection via the lasso.
\newblock \emph{Journal of the Royal Statistical Society. Series B
  (Methodological)}, pages 267--288, 1996.

\bibitem[van~de Geer(2014)]{van2014weakly}
Sara van~de Geer.
\newblock Weakly decomposable regularization penalties and structured sparsity.
\newblock \emph{Scandinavian Journal of Statistics}, 41\penalty0 (1):\penalty0
  72--86, 2014.

\bibitem[Van~de Geer et~al.(2014)Van~de Geer, B{\"u}hlmann, Ritov, and
  Dezeure]{GeerBR14}
Sara Van~de Geer, Peter B{\"u}hlmann, Ya'acov Ritov, and Ruben Dezeure.
\newblock On asymptotically optimal confidence regions and tests for
  high-dimensional models.
\newblock \emph{The Annals of Statistics}, 42\penalty0 (3):\penalty0
  1166--1202, 2014.

\bibitem[van~der Vaart(2002)]{van2002part}
Aad van~der Vaart.
\newblock Part iii: Semiparameric statistics.
\newblock \emph{Lectures on Probability Theory and Statistics}, pages 331--457,
  2002.

\bibitem[Van~der Vaart(2000)]{van2000asymptotic}
Aad~W Van~der Vaart.
\newblock \emph{Asymptotic statistics}, volume~3.
\newblock Cambridge university press, 2000.

\bibitem[Vershynin(2018)]{vershynin2018high}
Roman Vershynin.
\newblock \emph{High-dimensional probability: An introduction with applications
  in data science}, volume~47.
\newblock Cambridge University Press, 2018.

\bibitem[Zhang(2010)]{zhang2010nearly}
Cun-Hui Zhang.
\newblock Nearly unbiased variable selection under minimax concave penalty.
\newblock \emph{The Annals of statistics}, pages 894--942, 2010.

\bibitem[Zhang(2011)]{zhang2011statistical}
Cun-Hui Zhang.
\newblock Statistical inference for high-dimensional data.
\newblock \emph{Mathematisches Forschungsinstitut Oberwolfach: Very High
  Dimensional Semiparametric Models, Report}, \penalty0 (48):\penalty0 28--31,
  2011.

\bibitem[Zhang and Zhang(2014)]{ZhangSteph14}
Cun-Hui Zhang and Stephanie~S Zhang.
\newblock Confidence intervals for low dimensional parameters in high
  dimensional linear models.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 76\penalty0 (1):\penalty0 217--242, 2014.

\bibitem[Zhang and Zhang(2012)]{zhang2012}
Cun-Hui Zhang and Tong Zhang.
\newblock A general theory of concave regularization for high-dimensional
  sparse estimation problems.
\newblock \emph{Statist. Sci.}, 27\penalty0 (4):\penalty0 576--593, 11 2012.
\newblock \doi{10.1214/12-STS399}.
\newblock URL \url{https://doi.org/10.1214/12-STS399}.

\end{thebibliography}
