\begin{thebibliography}{33}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Cesa-Bianchi \& Lugosi(2006)Cesa-Bianchi and Lugosi]{CLBook}
Cesa-Bianchi, N. and Lugosi, G.
\newblock \emph{Prediction, Learning, and Games}.
\newblock Cambridge University Press, 2006.

\bibitem[Cutkosky(2019)]{DBLP:conf/colt/Cutkosky19a}
Cutkosky, A.
\newblock Combining online learning guarantees.
\newblock In \emph{COLT}, pp.\  895--913, 2019.

\bibitem[Cutkosky \& Orabona(2018)Cutkosky and Orabona]{cutkosky2018black}
Cutkosky, A. and Orabona, F.
\newblock Black-box reductions for parameter-free online learning in {B}anach
  spaces.
\newblock In \emph{COLT}, pp.\  1493--1529, 2018.

\bibitem[Cutkosky \& Sarlos(2019)Cutkosky and Sarlos]{cutkosky2019matrix}
Cutkosky, A. and Sarlos, T.
\newblock Matrix-free preconditioning in online learning.
\newblock In \emph{ICML}, pp.\  1455--1464, 2019.

\bibitem[Dekel et~al.(2017)Dekel, Flajolet, Haghtalab, and
  Jaillet]{DBLP:conf/nips/DekelFHJ17}
Dekel, O., Flajolet, A., Haghtalab, N., and Jaillet, P.
\newblock Online learning with a hint.
\newblock In \emph{NIPS}, pp.\  5299--5308, 2017.

\bibitem[Foster et~al.(2017)Foster, Kale, Mohri, and
  Sridharan]{foster2017parameter}
Foster, D.~J., Kale, S., Mohri, M., and Sridharan, K.
\newblock Parameter-free online learning via model selection.
\newblock In \emph{NIPS}, pp.\  6020--6030, 2017.

\bibitem[Foster et~al.(2018)Foster, Rakhlin, and Sridharan]{foster2018online}
Foster, D.~J., Rakhlin, A., and Sridharan, K.
\newblock Online learning: Sufficient statistics and the {B}urkholder method.
\newblock In \emph{COLT}, pp.\  3028--3064, 2018.

\bibitem[Hazan(2016)]{HazanBook}
Hazan, E.
\newblock Introduction to online convex optimization.
\newblock \emph{Foundations and TrendsÂ® in Optimization}, 2\penalty0
  (3-4):\penalty0 157--325, 2016.

\bibitem[Hazan \& Kale(2010)Hazan and Kale]{hazan2010extracting}
Hazan, E. and Kale, S.
\newblock Extracting certainty from uncertainty: Regret bounded by variation in
  costs.
\newblock \emph{Machine Learning}, 80\penalty0 (2-3):\penalty0 165--188, 2010.

\bibitem[Hazan \& Megiddo(2007)Hazan and Megiddo]{DBLP:conf/colt/HazanM07}
Hazan, E. and Megiddo, N.
\newblock Online learning with prior knowledge.
\newblock In \emph{COLT}, pp.\  499--513, 2007.

\bibitem[Hazan et~al.(2007)Hazan, Agarwal, and Kale]{hazan2007logarithmic}
Hazan, E., Agarwal, A., and Kale, S.
\newblock Logarithmic regret algorithms for online convex optimization.
\newblock \emph{Machine Learning}, 69\penalty0 (2-3):\penalty0 169--192, 2007.

\bibitem[Hazan et~al.(2008)Hazan, Rakhlin, and Bartlett]{hazan2008adaptive}
Hazan, E., Rakhlin, A., and Bartlett, P.~L.
\newblock Adaptive online gradient descent.
\newblock In \emph{NIPS}, pp.\  65--72, 2008.

\bibitem[Jun \& Orabona(2019)Jun and Orabona]{jun2019parameter}
Jun, K.-S. and Orabona, F.
\newblock Parameter-free online convex optimization with sub-exponential noise.
\newblock In \emph{COLT}, pp.\  1802--1823, 2019.

\bibitem[Kalai \& Vempala(2005)Kalai and Vempala]{KV05}
Kalai, A. and Vempala, S.
\newblock Efficient algorithms for online decision problems.
\newblock \emph{JCSS}, 71(3):\penalty0 291--307, 2005.

\bibitem[Kempka et~al.(2019)Kempka, Kotlowski, and Warmuth]{kempka2019adaptive}
Kempka, M., Kotlowski, W., and Warmuth, M.~K.
\newblock Adaptive scale-invariant online algorithms for learning linear
  models.
\newblock In \emph{ICML}, pp.\  3321--3330, 2019.

\bibitem[Kumar et~al.(2018)Kumar, Purohit, and Svitkina]{KPS18}
Kumar, R., Purohit, M., and Svitkina, Z.
\newblock Improving online algorithms using {ML} predictions.
\newblock In \emph{NeurIPS}, pp.\  9661--9670, 2018.

\bibitem[Kumar et~al.(2019)Kumar, Purohit, Schild, Svitkina, and Vee]{KPSSV19}
Kumar, R., Purohit, M., Schild, A., Svitkina, Z., and Vee, E.
\newblock Semi-online bipartite matching.
\newblock In \emph{ITCS}, pp.\  50:1--50:20, 2019.

\bibitem[Kumar et~al.(2020)Kumar, Purohit, Svitkina, and Vee]{interleaved}
Kumar, R., Purohit, M., Svitkina, Z., and Vee, E.
\newblock Interleaved caching with access graphs.
\newblock In \emph{SODA}, pp.\  1846--1858, 2020.

\bibitem[Lattanzi et~al.(2020)Lattanzi, Lavastida, Moseley, and
  Vassilvitskii]{sergei2}
Lattanzi, S., Lavastida, T., Moseley, B., and Vassilvitskii, S.
\newblock Online scheduling via learned weights.
\newblock In \emph{SODA}, pp.\  1859--1877, 2020.

\bibitem[Li \& Orabona(2019)Li and Orabona]{li2019convergence}
Li, X. and Orabona, F.
\newblock On the convergence of stochastic gradient descent with adaptive
  stepsizes.
\newblock In \emph{AISTATS}, pp.\  983--992, 2019.

\bibitem[Lykouris \& Vassilvitskii(2018)Lykouris and Vassilvitskii]{sergei1}
Lykouris, T. and Vassilvitskii, S.
\newblock Competitive caching with machine learned advice.
\newblock In \emph{ICML}, pp.\  3302--3311, 2018.

\bibitem[McMahan(2017)]{mcmahan2017survey}
McMahan, H.~B.
\newblock A survey of algorithms and analysis for adaptive online learning.
\newblock \emph{JMLR}, 18\penalty0 (1):\penalty0 3117--3166, 2017.

\bibitem[McMahan \& Orabona(2014)McMahan and Orabona]{mcmahan2014unconstrained}
McMahan, H.~B. and Orabona, F.
\newblock Unconstrained online linear learning in {H}ilbert spaces: Minimax
  algorithms and normal approximations.
\newblock In \emph{COLT}, pp.\  1020--1039, 2014.

\bibitem[Mohri \& Yang(2016)Mohri and Yang]{mohri2016accelerating}
Mohri, M. and Yang, S.
\newblock Accelerating online convex optimization via adaptive prediction.
\newblock In \emph{AISTATS}, pp.\  848--856, 2016.

\bibitem[Motwani \& Raghavan(1995)Motwani and Raghavan]{MotwaniRaghavan}
Motwani, R. and Raghavan, P.
\newblock \emph{Randomized Algorithms}.
\newblock Cambridge University Press, 1995.

\bibitem[Orabona \& P{\'a}l(2016)Orabona and P{\'a}l]{orabona2016coin}
Orabona, F. and P{\'a}l, D.
\newblock Coin betting and parameter-free online learning.
\newblock In \emph{NIPS}, pp.\  577--585. 2016.

\bibitem[Pisier(2016)]{pisier2011martingales}
Pisier, G.
\newblock \emph{Martingales in {B}anach Spaces}.
\newblock Cambridge University Press, 2016.

\bibitem[Rakhlin \& Sridharan(2013)Rakhlin and Sridharan]{rakhlin2013online}
Rakhlin, A. and Sridharan, K.
\newblock Online learning with predictable sequences.
\newblock In \emph{COLT}, pp.\  993--1019, 2013.

\bibitem[Rohatgi(2020)]{rohatgi}
Rohatgi, D.
\newblock Near-optimal bounds for online caching with machine learned advice.
\newblock In \emph{SODA}, pp.\  1834--1845, 2020.

\bibitem[Shalev-Shwartz(2011)]{ShaiShalevBook}
Shalev-Shwartz, S.
\newblock Online learning and online convex optimization.
\newblock \emph{Foundation and Trends in Machine Learning}, 4\penalty0
  (2):\penalty0 107--194, 2011.

\bibitem[Steinhardt \& Liang(2014)Steinhardt and
  Liang]{steinhardt2014adaptivity}
Steinhardt, J. and Liang, P.
\newblock Adaptivity and optimism: An improved exponentiated gradient
  algorithm.
\newblock In \emph{ICML}, pp.\  1593--1601, 2014.

\bibitem[van~der Hoeven(2019)]{van2019user}
van~der Hoeven, D.
\newblock User-specified local differential privacy in unconstrained adaptive
  online learning.
\newblock In \emph{NeurIPS}, pp.\  14080--14089, 2019.

\bibitem[Zinkevich(2003)]{zinkevich2003online}
Zinkevich, M.
\newblock Online convex programming and generalized infinitesimal gradient
  ascent.
\newblock In \emph{ICML}, pp.\  928--936, 2003.

\end{thebibliography}
