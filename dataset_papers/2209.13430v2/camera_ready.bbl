\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bossard et~al.(2014)Bossard, Guillaumin, and Gool]{bossard2014food}
L.~Bossard, M.~Guillaumin, and L.~V. Gool.
\newblock Food-101--mining discriminative components with random forests.
\newblock In \emph{European conference on computer vision}, pages 446--461.
  Springer, 2014.

\bibitem[Changpinyo et~al.(2021)Changpinyo, Sharma, Ding, and
  Soricut]{changpinyo2021conceptual}
S.~Changpinyo, P.~Sharma, N.~Ding, and R.~Soricut.
\newblock Conceptual 12m: Pushing web-scale image-text pre-training to
  recognize long-tail visual concepts.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 3558--3568, 2021.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
T.~Chen, S.~Kornblith, M.~Norouzi, and G.~Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International conference on machine learning}, pages
  1597--1607. PMLR, 2020.

\bibitem[Chen and He(2021)]{chen2021exploring}
X.~Chen and K.~He.
\newblock Exploring simple siamese representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 15750--15758, 2021.

\bibitem[Chen et~al.(2015)Chen, Fang, Lin, Vedantam, Gupta, Doll{\'a}r, and
  Zitnick]{chen2015microsoft}
X.~Chen, H.~Fang, T.-Y. Lin, R.~Vedantam, S.~Gupta, P.~Doll{\'a}r, and C.~L.
  Zitnick.
\newblock Microsoft coco captions: Data collection and evaluation server.
\newblock \emph{arXiv preprint arXiv:1504.00325}, 2015.

\bibitem[Cimpoi et~al.(2014)Cimpoi, Maji, Kokkinos, Mohamed, and
  Vedaldi]{cimpoi2014describing}
M.~Cimpoi, S.~Maji, I.~Kokkinos, S.~Mohamed, and A.~Vedaldi.
\newblock Describing textures in the wild.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 3606--3613, 2014.

\bibitem[Cubuk et~al.(2020)Cubuk, Zoph, Shlens, and Le]{cubuk2020randaugment}
E.~D. Cubuk, B.~Zoph, J.~Shlens, and Q.~V. Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition Workshops}, pages 702--703, 2020.

\bibitem[Cui et~al.(2022)Cui, Zhao, Liang, Li, and Shao]{cui2022democratizing}
Y.~Cui, L.~Zhao, F.~Liang, Y.~Li, and J.~Shao.
\newblock Democratizing contrastive language-image pre-training: A clip
  benchmark of data, model, and supervision.
\newblock \emph{arXiv preprint arXiv:2203.05796}, 2022.

\bibitem[Doersch and Zisserman(2017)]{doersch2017multi}
C.~Doersch and A.~Zisserman.
\newblock Multi-task self-supervised visual learning.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pages 2051--2060, 2017.

\bibitem[Doersch et~al.(2015)Doersch, Gupta, and
  Efros]{doersch2015unsupervised}
C.~Doersch, A.~Gupta, and A.~A. Efros.
\newblock Unsupervised visual representation learning by context prediction.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 1422--1430, 2015.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{dosovitskiy2021an}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, J.~Uszkoreit,
  and N.~Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Fei-Fei et~al.(2004)Fei-Fei, Fergus, and Perona]{fei2004learning}
L.~Fei-Fei, R.~Fergus, and P.~Perona.
\newblock Learning generative visual models from few training examples: An
  incremental bayesian approach tested on 101 object categories.
\newblock In \emph{2004 conference on computer vision and pattern recognition
  workshop}, pages 178--178. IEEE, 2004.

\bibitem[Gidaris et~al.(2018)Gidaris, Singh, and
  Komodakis]{gidaris2018unsupervised}
S.~Gidaris, P.~Singh, and N.~Komodakis.
\newblock Unsupervised representation learning by predicting image rotations.
\newblock \emph{arXiv preprint arXiv:1803.07728}, 2018.

\bibitem[Hendrycks et~al.(2021{\natexlab{a}})Hendrycks, Basart, Mu, Kadavath,
  Wang, Dorundo, Desai, Zhu, Parajuli, Guo, et~al.]{hendrycks2021many}
D.~Hendrycks, S.~Basart, N.~Mu, S.~Kadavath, F.~Wang, E.~Dorundo, R.~Desai,
  T.~Zhu, S.~Parajuli, M.~Guo, et~al.
\newblock The many faces of robustness: A critical analysis of
  out-of-distribution generalization.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 8340--8349, 2021{\natexlab{a}}.

\bibitem[Hendrycks et~al.(2021{\natexlab{b}})Hendrycks, Zhao, Basart,
  Steinhardt, and Song]{hendrycks2021natural}
D.~Hendrycks, K.~Zhao, S.~Basart, J.~Steinhardt, and D.~Song.
\newblock Natural adversarial examples.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 15262--15271, 2021{\natexlab{b}}.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and
  Duerig]{jia2021scaling}
C.~Jia, Y.~Yang, Y.~Xia, Y.-T. Chen, Z.~Parekh, H.~Pham, Q.~Le, Y.-H. Sung,
  Z.~Li, and T.~Duerig.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock In \emph{International Conference on Machine Learning}, pages
  4904--4916. PMLR, 2021.

\bibitem[Khosla et~al.(2020)Khosla, Teterwak, Wang, Sarna, Tian, Isola,
  Maschinot, Liu, and Krishnan]{khosla2020supervised}
P.~Khosla, P.~Teterwak, C.~Wang, A.~Sarna, Y.~Tian, P.~Isola, A.~Maschinot,
  C.~Liu, and D.~Krishnan.
\newblock Supervised contrastive learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 18661--18673, 2020.

\bibitem[Kim and Ye(2021)]{kim2021diffusionclip}
G.~Kim and J.~C. Ye.
\newblock Diffusionclip: Text-guided image manipulation using diffusion models.
\newblock \emph{arXiv preprint arXiv:2110.02711}, 2021.

\bibitem[Krause et~al.(2013)Krause, Stark, Deng, and Fei-Fei]{krause20133d}
J.~Krause, M.~Stark, J.~Deng, and L.~Fei-Fei.
\newblock 3d object representations for fine-grained categorization.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision workshops}, pages 554--561, 2013.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
A.~Krizhevsky, G.~Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Li et~al.(2022)Li, Liang, Zhao, Cui, Ouyang, Shao, Yu, and
  Yan]{li2022supervision}
Y.~Li, F.~Liang, L.~Zhao, Y.~Cui, W.~Ouyang, J.~Shao, F.~Yu, and J.~Yan.
\newblock Supervision exists everywhere: A data efficient contrastive
  language-image pre-training paradigm.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Maji et~al.(2013)Maji, Rahtu, Kannala, Blaschko, and
  Vedaldi]{maji2013fine}
S.~Maji, E.~Rahtu, J.~Kannala, M.~Blaschko, and A.~Vedaldi.
\newblock Fine-grained visual classification of aircraft.
\newblock \emph{arXiv preprint arXiv:1306.5151}, 2013.

\bibitem[Miech et~al.(2020)Miech, Alayrac, Smaira, Laptev, Sivic, and
  Zisserman]{miech2020end}
A.~Miech, J.-B. Alayrac, L.~Smaira, I.~Laptev, J.~Sivic, and A.~Zisserman.
\newblock End-to-end learning of visual representations from uncurated
  instructional videos.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 9879--9889, 2020.

\bibitem[Mu et~al.(2021)Mu, Kirillov, Wagner, and Xie]{mu2021slip}
N.~Mu, A.~Kirillov, D.~Wagner, and S.~Xie.
\newblock Slip: Self-supervision meets language-image pre-training.
\newblock \emph{arXiv preprint arXiv:2112.12750}, 2021.

\bibitem[Nilsback and Zisserman(2008)]{nilsback2008automated}
M.-E. Nilsback and A.~Zisserman.
\newblock Automated flower classification over a large number of classes.
\newblock In \emph{2008 Sixth Indian Conference on Computer Vision, Graphics \&
  Image Processing}, pages 722--729. IEEE, 2008.

\bibitem[Noroozi and Favaro(2016)]{noroozi2016unsupervised}
M.~Noroozi and P.~Favaro.
\newblock Unsupervised learning of visual representations by solving jigsaw
  puzzles.
\newblock In \emph{European conference on computer vision}, pages 69--84.
  Springer, 2016.

\bibitem[Noroozi et~al.(2017)Noroozi, Pirsiavash, and
  Favaro]{noroozi2017representation}
M.~Noroozi, H.~Pirsiavash, and P.~Favaro.
\newblock Representation learning by learning to count.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pages 5898--5906, 2017.

\bibitem[Parkhi et~al.(2012)Parkhi, Vedaldi, Zisserman, and
  Jawahar]{parkhi2012cats}
O.~M. Parkhi, A.~Vedaldi, A.~Zisserman, and C.~Jawahar.
\newblock Cats and dogs.
\newblock In \emph{2012 IEEE conference on computer vision and pattern
  recognition}, pages 3498--3505. IEEE, 2012.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen,
  Z.~Lin, N.~Gimelshein, L.~Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Pathak et~al.(2016)Pathak, Krahenbuhl, Donahue, Darrell, and
  Efros]{pathak2016context}
D.~Pathak, P.~Krahenbuhl, J.~Donahue, T.~Darrell, and A.~A. Efros.
\newblock Context encoders: Feature learning by inpainting.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2536--2544, 2016.

\bibitem[Plummer et~al.(2015)Plummer, Wang, Cervantes, Caicedo, Hockenmaier,
  and Lazebnik]{plummer2015flickr30k}
B.~A. Plummer, L.~Wang, C.~M. Cervantes, J.~C. Caicedo, J.~Hockenmaier, and
  S.~Lazebnik.
\newblock Flickr30k entities: Collecting region-to-phrase correspondences for
  richer image-to-sentence models.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 2641--2649, 2015.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark, et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International Conference on Machine Learning}, pages
  8748--8763. PMLR, 2021.

\bibitem[Ramesh et~al.(2021)Ramesh, Pavlov, Goh, Gray, Voss, Radford, Chen, and
  Sutskever]{ramesh2021zero}
A.~Ramesh, M.~Pavlov, G.~Goh, S.~Gray, C.~Voss, A.~Radford, M.~Chen, and
  I.~Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock In \emph{International Conference on Machine Learning}, pages
  8821--8831. PMLR, 2021.

\bibitem[Recht et~al.(2019)Recht, Roelofs, Schmidt, and
  Shankar]{recht2019imagenet}
B.~Recht, R.~Roelofs, L.~Schmidt, and V.~Shankar.
\newblock Do imagenet classifiers generalize to imagenet?
\newblock In \emph{International Conference on Machine Learning}, pages
  5389--5400. PMLR, 2019.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang,
  A.~Karpathy, A.~Khosla, M.~Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International journal of computer vision}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[Schroff et~al.(2015)Schroff, Kalenichenko, and
  Philbin]{schroff2015facenet}
F.~Schroff, D.~Kalenichenko, and J.~Philbin.
\newblock Facenet: A unified embedding for face recognition and clustering.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 815--823, 2015.

\bibitem[Sharma et~al.(2018)Sharma, Ding, Goodman, and
  Soricut]{sharma2018conceptual}
P.~Sharma, N.~Ding, S.~Goodman, and R.~Soricut.
\newblock Conceptual captions: A cleaned, hypernymed, image alt-text dataset
  for automatic image captioning.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 2556--2565,
  2018.

\bibitem[Sohn(2016)]{sohn2016improved}
K.~Sohn.
\newblock Improved deep metric learning with multi-class n-pair loss objective.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{szegedy2015going}
C.~Szegedy, W.~Liu, Y.~Jia, P.~Sermanet, S.~Reed, D.~Anguelov, D.~Erhan,
  V.~Vanhoucke, and A.~Rabinovich.
\newblock Going deeper with convolutions.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1--9, 2015.

\bibitem[Thomee et~al.(2016)Thomee, Shamma, Friedland, Elizalde, Ni, Poland,
  Borth, and Li]{thomee2016yfcc100m}
B.~Thomee, D.~A. Shamma, G.~Friedland, B.~Elizalde, K.~Ni, D.~Poland, D.~Borth,
  and L.-J. Li.
\newblock Yfcc100m: The new data in multimedia research.
\newblock \emph{Communications of the ACM}, 59\penalty0 (2):\penalty0 64--73,
  2016.

\bibitem[Van~den Oord et~al.(2018)Van~den Oord, Li, and
  Vinyals]{van2018representation}
A.~Van~den Oord, Y.~Li, and O.~Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv e-prints}, pages arXiv--1807, 2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  {\L}.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Wang et~al.(2019)Wang, Ge, Lipton, and Xing]{wang2019learning}
H.~Wang, S.~Ge, Z.~Lipton, and E.~P. Xing.
\newblock Learning robust global representations by penalizing local predictive
  power.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Wei and Zou(2019)]{wei2019eda}
J.~Wei and K.~Zou.
\newblock Eda: Easy data augmentation techniques for boosting performance on
  text classification tasks.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 6382--6388, 2019.

\bibitem[Xiao et~al.(2016)Xiao, Ehinger, Hays, Torralba, and
  Oliva]{xiao2016sun}
J.~Xiao, K.~A. Ehinger, J.~Hays, A.~Torralba, and A.~Oliva.
\newblock Sun database: Exploring a large collection of scene categories.
\newblock \emph{International Journal of Computer Vision}, 119\penalty0
  (1):\penalty0 3--22, 2016.

\bibitem[Zhang et~al.(2016)Zhang, Isola, and Efros]{zhang2016colorful}
R.~Zhang, P.~Isola, and A.~A. Efros.
\newblock Colorful image colorization.
\newblock In \emph{European conference on computer vision}, pages 649--666.
  Springer, 2016.

\bibitem[Zhang et~al.(2017)Zhang, Isola, and Efros]{zhang2017split}
R.~Zhang, P.~Isola, and A.~A. Efros.
\newblock Split-brain autoencoders: Unsupervised learning by cross-channel
  prediction.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 1058--1067, 2017.

\end{thebibliography}
