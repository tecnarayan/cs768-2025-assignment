\begin{thebibliography}{72}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anil et~al.(2019)Anil, Lucas, and Grosse]{Anil_SortingOut_2019}
Anil, C., Lucas, J., and Grosse, R.
\newblock Sorting out {Lipschitz} function approximation.
\newblock In Chaudhuri, K. and Salakhutdinov, R. (eds.), \emph{Proceedings of
  the 36th international conference on machine learning}, volume~97 of
  \emph{Proceedings of machine learning research}, pp.\  291--301, Long Beach,
  CA, USA, June 2019. PMLR.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{Arjovsky_WassersteinGenerative_2017}
Arjovsky, M., Chintala, S., and Bottou, L.
\newblock Wasserstein generative adversarial networks.
\newblock In Precup, D. and Teh, Y.~W. (eds.), \emph{Proceedings of the 34th
  international conference on machine learning}, volume~70 of \emph{Proceedings
  of machine learning research}, pp.\  214--223, Sydney, Australia, August
  2017. PMLR.

\bibitem[Askari et~al.(2019)Askari, d'Aspremont, and
  El~Ghaoui]{Askari_NaiveFeature_2019}
Askari, A., d'Aspremont, A., and El~Ghaoui, L.
\newblock Naive feature selection: sparsity in naive bayes.
\newblock \emph{arXiv:1905.09884 [cs, stat]}, May 2019.
\newblock arXiv: 1905.09884.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and Wagner]{AthCarWag18}
Athalye, A., Carlini, N., and Wagner, D.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2018.

\bibitem[Aubin \& Ekeland(1976)Aubin and Ekeland]{Aubin_EstimatesDuality_1976}
Aubin, J.-P. and Ekeland, I.
\newblock Estimates of the duality gap in nonconvex optimization.
\newblock \emph{Mathematics of Operations Research}, 1\penalty0 (3):\penalty0
  225--245, 1976.
\newblock ISSN 0364765X, 15265471.
\newblock \doi{10.1287/moor.1.3.225}.

\bibitem[Barron(1994)]{Barron94}
Barron, A.~R.
\newblock Approximation and estimation bounds for artificial neural networks.
\newblock \emph{Machine Learning}, 14:\penalty0 115--133, 1994.

\bibitem[Benoist \& Hiriart-Urruty(1996)Benoist and
  Hiriart-Urruty]{Benoist_WhatSubdifferential_1996}
Benoist, J. and Hiriart-Urruty, J.-B.
\newblock What is the subdifferential of the closed convex hull of a function?
\newblock \emph{SIAM Journal on Mathematical Analysis}, 27\penalty0
  (6):\penalty0 1661--1679, November 1996.
\newblock ISSN 0036-1410, 1095-7154.
\newblock \doi{10.1137/S0036141094265936}.

\bibitem[Berger(1993)]{Berger_StatisticalDecision_1993}
Berger, J.~O.
\newblock \emph{Statistical decision theory and {Bayesian} analysis}.
\newblock Springer series in statistics. Springer-Verlag, New York, NY, USA, 2
  edition, 1993.
\newblock ISBN 0-387-96098-8.
\newblock tex.mrclass: 62-02 (62A15 62Cxx) tex.mrnumber: 1234489.

\bibitem[Bietti \& Mairal(2019)Bietti and Mairal]{BieMai19}
Bietti, A. and Mairal, J.
\newblock Group invariance, stability to deformations, and complexity of deep
  convolutional representations.
\newblock \emph{Journal of Machine Learning Research}, 20\penalty0
  (25):\penalty0 1--49, 2019.

\bibitem[Bietti et~al.(2019)Bietti, Mialon, Chen, and Mairal]{BieMaiCheetal19}
Bietti, A., Mialon, G., Chen, D., and Mairal, J.
\newblock A kernel perspective for regularizing deep neural networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2019.

\bibitem[Blanchet \& Murthy(2019)Blanchet and
  Murthy]{Blanchet_QuantifyingDistributional_2019}
Blanchet, J. and Murthy, K.
\newblock Quantifying distributional model risk via optimal transport.
\newblock \emph{Mathematics of Operations Research}, 44\penalty0 (2):\penalty0
  565--600, May 2019.
\newblock ISSN 0364-765X, 1526-5471.
\newblock \doi{10.1287/moor.2018.0936}.

\bibitem[Blanchet et~al.(2019)Blanchet, Kang, and
  Murthy]{Blanchet_RobustWasserstein_2019}
Blanchet, J., Kang, Y., and Murthy, K.
\newblock Robust {Wasserstein} profile inference and applications to machine
  learning.
\newblock \emph{Journal of Applied Probability}, 56\penalty0 (3):\penalty0
  830--857, 2019.
\newblock ISSN 0021-9002.
\newblock \doi{10.1017/jpr.2019.49}.

\bibitem[Carlini \& Wagner(2017)Carlini and
  Wagner]{Carlini_EvaluatingRobustness_2017}
Carlini, N. and Wagner, D.
\newblock Towards {Evaluating} the {Robustness} of {Neural} {Networks}.
\newblock In \emph{{IEEE} {Symposium} on {Security} and {Privacy}}, pp.\
  39--57, San Jose, CA, USA, May 2017. IEEE.
\newblock ISBN 978-1-5090-5533-3.
\newblock \doi{10.1109/sp.2017.49}.

\bibitem[Cisse et~al.(2017)Cisse, Bojanowski, Grave, Dauphin, and
  Usunier]{Cisse_ParsevalNetworks_2017}
Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., and Usunier, N.
\newblock Parseval networks: {Improving} robustness to adversarial examples.
\newblock In Precup, D. and Teh, Y.~W. (eds.), \emph{Proceedings of the 34th
  international conference on machine learning}, volume~70, pp.\  854--863,
  Sydney, Australia, August 2017. Proceedings of machine learning research.

\bibitem[Crammer \& Singer(2001)Crammer and Singer]{crammer2001algorithmic}
Crammer, K. and Singer, Y.
\newblock On the algorithmic implementation of multiclass kernel-based vector
  machines.
\newblock \emph{Journal of machine learning research}, 2\penalty0
  (Dec):\penalty0 265--292, 2001.

\bibitem[Cranko et~al.(2019)Cranko, Menon, Nock, Ong, Shi, and
  Walder]{Cranko_MongeBlunts_2019}
Cranko, Z., Menon, A., Nock, R., Ong, C.~S., Shi, Z., and Walder, C.
\newblock Monge blunts {Bayes}: hardness results for adversarial training.
\newblock In Chaudhuri, K. and Salakhutdinov, R. (eds.), \emph{Proceedings of
  the 36th international conference on machine learning}, volume~97, pp.\
  1406--1415, Long Beach, CA, USA, June 2019. Proceedings of machine learning
  research.

\bibitem[Drineas \& Mahoney(2005)Drineas and Mahoney]{DriMah05}
Drineas, P. and Mahoney, M.
\newblock On the nystr{\:o}m method for approximating a gram matrix for
  improved kernel-based learning.
\newblock \emph{JMLR}, 6:\penalty0 2153--2175, 2005.

\bibitem[E~Fasshauer(2011)]{Fasshauer11}
E~Fasshauer, G.
\newblock Positive definite kernels: Past, present and future.
\newblock \emph{Dolomite Res. Notes Approx.}, 4, 01 2011.

\bibitem[Farnia et~al.(2019)Farnia, Zhang, and
  Tse]{Farnia_GeneralizableAdversarial_2019}
Farnia, F., Zhang, J., and Tse, D.
\newblock Generalizable adversarial training via spectral normalization.
\newblock In \emph{International conference on learning representations}, New
  Orleans, LA, United States, May 2019.

\bibitem[Fasshauer \& McCourt(2012)Fasshauer and McCourt]{FasMcC12}
Fasshauer, G. and McCourt, M.
\newblock Stable evaluation of {G}aussian radial basis function interpolants.
\newblock \emph{SIAM Journal on Scientific Computing}, 34\penalty0
  (2):\penalty0 A737--A762, 2012.

\bibitem[Gao \& Kleywegt(2016)Gao and
  Kleywegt]{Gao_DistributionallyRobust_2016}
Gao, R. and Kleywegt, A.~J.
\newblock Distributionally robust stochastic optimization with wasserstein
  distance.
\newblock \emph{arXiv:1604.02199 [math]}, July 2016.
\newblock arXiv: 1604.02199.

\bibitem[Giner(2009)]{Giner_NecessarySufficient_2009}
Giner, E.
\newblock Necessary and sufficient conditions for the interchange between
  infimum and the symbol of integration.
\newblock \emph{Set-Valued and Variational Analysis}, 17\penalty0 (4):\penalty0
  321--357, 2009.
\newblock ISSN 1877-0533.
\newblock \doi{10.1007/s11228-009-0119-y}.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{Goodfellow_ExplainingHarnessing_2015}
Goodfellow, I., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{International Conference on Learning Representations}, 2015.

\bibitem[Gouk et~al.(2018)Gouk, Frank, Pfahringer, and
  Cree]{Gouk_RegularisationNeural_2018}
Gouk, H., Frank, E., Pfahringer, B., and Cree, M.~J.
\newblock Regularisation of neural networks by enforcing lipschitz continuity.
\newblock \emph{arXiv:1804.04368 [cs, stat]}, September 2018.
\newblock arXiv: 1804.04368.

\bibitem[Gouk et~al.(2019)Gouk, Pfahringer, Frank, and
  Cree]{Gouk_MaxGainRegularisation_2019}
Gouk, H., Pfahringer, B., Frank, E., and Cree, M.~J.
\newblock {MaxGain}: regularisation of neural networks by constraining
  activation magnitudes.
\newblock In \emph{Machine {Learning} and {Knowledge} {Discovery} in
  {Databases}}, pp.\  541--556, Cham, Switzerland, 2019. Springer International
  Publishing.
\newblock ISBN 978-3-030-10925-7.

\bibitem[Grünwald \& Dawid(2004)Grünwald and Dawid]{Grunwald_GameTheory_2004}
Grünwald, P.~D. and Dawid, A.~P.
\newblock Game theory, maximum entropy, minimum discrepancy and robust
  {Bayesian} decision theory.
\newblock \emph{The Annals of Statistics}, 32\penalty0 (4):\penalty0
  1367--1433, August 2004.
\newblock ISSN 0090-5364.
\newblock \doi{10.1214/009053604000000553}.

\bibitem[Hiriart-Urruty(1986)]{Hiriart-Urruty_GeneralFormula_1986}
Hiriart-Urruty, J.-B.
\newblock A general formula on the conjugate of the difference of functions.
\newblock \emph{Canadian Mathematical Bulletin}, 29\penalty0 (4):\penalty0
  482--485, December 1986.
\newblock ISSN 0008-4395, 1496-4287.
\newblock \doi{10.4153/cmb-1986-076-7}.

\bibitem[Hiriart-Urruty(1989)]{Hiriart-Urruty_ConvexOptimization_1989}
Hiriart-Urruty, J.-B.
\newblock From convex optimization to nonconvex optimization. necessary and
  sufficient conditions for global optimality.
\newblock In Clarke, F.~H., Dem’yanov, V.~F., and Giannessi, F. (eds.),
  \emph{Nonsmooth {Optimization} and {Related} {Topics}}, pp.\  219--239.
  Springer, Boston, MA, USA, 1989.
\newblock ISBN 978-1-4757-6019-4.
\newblock \doi{10.1007/978-1-4757-6019-4_13}.

\bibitem[Hiriart-Urruty \& Lemaréchal(2010)Hiriart-Urruty and
  Lemaréchal]{Hiriart-Urruty_ConvexAnalysis_2010}
Hiriart-Urruty, J.-B. and Lemaréchal, C.
\newblock \emph{Convex analysis and minimization algorithms {II}}.
\newblock Springer-Verlag, Berlin, Germany, 2010.
\newblock ISBN 978-3-642-08162-0.
\newblock OCLC: 864385173.

\bibitem[Kerdreux et~al.(2019)Kerdreux, Colin, and
  d'Aspremont]{Kerdreux_ApproximateShapleyFolkman_2019}
Kerdreux, T., Colin, I., and d'Aspremont, A.
\newblock An approximate {Shapley}-{Folkman} theorem.
\newblock \emph{arXiv:1712.08559 [math]}, July 2019.
\newblock arXiv: 1712.08559.

\bibitem[K{\"o}nig(1986)]{Konig86}
K{\"o}nig, H.
\newblock \emph{Eigenvalue Distribution of Compact Operators}.
\newblock Birkh{\"a}user, Basel, 1986.

\bibitem[Kurakin et~al.(2017)Kurakin, Goodfellow, and
  Bengio]{Kurakin_AdversarialExamples_2017}
Kurakin, A., Goodfellow, I., and Bengio, S.
\newblock Adversarial examples in the physical world.
\newblock Technical report, 2017.

\bibitem[Lafferty \& Lebanon(2005)Lafferty and Lebanon]{LafLeb05}
Lafferty, J. and Lebanon, G.
\newblock Diffusion kernels on statistical manifolds.
\newblock \emph{Journal of Machine Learning Research}, 6:\penalty0 129--163, 01
  2005.

\bibitem[Lemaréchal \& Renaud(2001)Lemaréchal and
  Renaud]{Lemarechal_GeometricStudy_2001}
Lemaréchal, C. and Renaud, A.
\newblock A geometric study of duality gaps, with applications.
\newblock \emph{Mathematical Programming}, 90\penalty0 (3):\penalty0 399--427,
  May 2001.
\newblock ISSN 0025-5610.
\newblock \doi{10.1007/pl00011429}.

\bibitem[Lin et~al.(2017)Lin, Guo, and Zhou]{LinGuoZho17}
Lin, S.-B., Guo, X., and Zhou, D.-X.
\newblock Distributed learning with regularized least squares.
\newblock \emph{Journal of Machine Learning Research}, 18\penalty0
  (92):\penalty0 1--31, 2017.

\bibitem[LNets()]{LNetscode}
LNets.
\newblock \url{https://github.com/cemanil/LNets}.

\bibitem[MacKay(1998)]{MacKay98}
MacKay, D.~J.~C.
\newblock Introduction to {Gaussian} processes.
\newblock In Bishop, C.~M. (ed.), \emph{Neural Networks and Machine Learning},
  pp.\  133--165. Springer, Berlin, 1998.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{Madry_DeepLearning_2018}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International {Conference} on {Learning} {Representations}},
  2018.

\bibitem[McShane(1934)]{McShane_ExtensionRange_1934}
McShane, E.~J.
\newblock Extension of range of functions.
\newblock \emph{Bulletin of the American Mathematical Society}, 40\penalty0
  (12):\penalty0 837--842, 1934.
\newblock \doi{10.1090/s0002-9904-1934-05978-0}.
\newblock tex.fjournal: Bulletin of the American Mathematical Society.

\bibitem[Micchelli et~al.(2006)Micchelli, Xu, and Zhang]{MicXuZha06}
Micchelli, C.~A., Xu, Y., and Zhang, H.
\newblock Universal kernels.
\newblock \emph{Journal of Machine Learning Research}, 7:\penalty0 2651--2667,
  2006.

\bibitem[Minh(2010)]{Minh10}
Minh, H.~Q.
\newblock Some properties of {G}aussian reproducing kernel {H}ilbert spaces and
  their implications for function approximation and learning theory.
\newblock \emph{Constructive Approximation}, 32\penalty0 (2):\penalty0
  307--338, 2010.

\bibitem[Minh et~al.(2006)Minh, Niyogi, and Yao]{MinNiyYao06}
Minh, H.~Q., Niyogi, P., and Yao, Y.
\newblock Mercer's theorem, feature maps, and smoothing.
\newblock In Lugosi, G. and Simon, H.~U. (eds.), \emph{Conference on
  Computational Learning Theory (COLT)}, pp.\  154--168, 2006.

\bibitem[Miyato et~al.(2018)Miyato, Kataoka, Koyama, and
  Yoshida]{Miyato_SpectralNormalization_2018}
Miyato, T., Kataoka, T., Koyama, M., and Yoshida, Y.
\newblock Spectral normalization for generative adversarial networks.
\newblock In \emph{International conference on learning representations}, 2018.

\bibitem[Moosavi~Dezfooli et~al.(2017)Moosavi~Dezfooli, Fawzi, Fawzi, and
  Frossard]{MoosaviDezfooli_UniversalAdversarial_2017}
Moosavi~Dezfooli, S.~M., Fawzi, A., Fawzi, O., and Frossard, P.
\newblock Universal adversarial perturbations.
\newblock In \emph{Proceedings of 2017 {IEEE} {Conference} on {Computer}
  {Vision} and {Pattern} {Recognition} ({CVPR})}, pp.\ ~9, Honolulu, HI, USA,,
  2017. IEEE.
\newblock ISBN 978-1-5386-0457-1.
\newblock \doi{10.1109/Cvpr.2017.17}.
\newblock tex.address: New York tex.publisher: Ieee.

\bibitem[Pratelli(2007)]{Pratelli_EqualityMonge_2007}
Pratelli, A.
\newblock On the equality between {Monge}'s infimum and {Kantorovich}'s minimum
  in optimal mass transportation.
\newblock \emph{Annales de l'Institut Henri Poincare (B) Probability and
  Statistics}, 43\penalty0 (1):\penalty0 1--13, January 2007.
\newblock ISSN 02460203.
\newblock \doi{10.1016/j.anihpb.2005.12.001}.

\bibitem[Rasmussen \& Williams(2006)Rasmussen and Williams]{RasWil06}
Rasmussen, C.~E. and Williams, C. K.~I.
\newblock \emph{Gaussian Processes for Machine Learning}.
\newblock MIT Press, Cambridge, MA, 2006.

\bibitem[Scaman \& Virmaux(2018)Scaman and
  Virmaux]{Scaman_LipschitzRegularity_2018}
Scaman, K. and Virmaux, A.
\newblock Lipschitz regularity of deep neural networks: analysis and efficient
  estimation.
\newblock In \emph{Proceedings of the 32nd international conference on neural
  information processing systems}, pp.\  3839--3848, Montréal, Canada, 2018.
  Curran Associates Inc.

\bibitem[Schneider(1953)]{Schneider53}
Schneider, H.
\newblock An inequality for latent roots applied to determinants with dominant
  principal diagonal.
\newblock \emph{Journal of the London Mathematical Society}, s1-28\penalty0
  (1):\penalty0 8--20, 1953.

\bibitem[Shafieezadeh-Abadeh et~al.(2019)Shafieezadeh-Abadeh, Kuhn, and
  Esfahani]{Shafieezadeh-Abadeh_RegularizationMass_2019}
Shafieezadeh-Abadeh, S., Kuhn, D., and Esfahani, P.~M.
\newblock Regularization via mass transportation.
\newblock \emph{Journal of Machine Learning Research}, 20\penalty0
  (103):\penalty0 1--68, 2019.

\bibitem[Shaham et~al.(2018)Shaham, Yamada, and
  Negahban]{Shaham_UnderstandingAdversarial_2018}
Shaham, U., Yamada, Y., and Negahban, S.
\newblock Understanding adversarial training: {Increasing} local stability of
  supervised models through robust optimization.
\newblock \emph{Neurocomputing}, 307:\penalty0 195--204, September 2018.
\newblock ISSN 09252312.
\newblock \doi{10.1016/j.neucom.2018.04.027}.

\bibitem[Shalev-Shwartz et~al.(2011)Shalev-Shwartz, Shamir, and
  Sridharan]{ShaShaSri11}
Shalev-Shwartz, S., Shamir, O., and Sridharan, K.
\newblock Learning kernel-based halfspaces with the 0-1 loss.
\newblock \emph{SIAM Journal on Computing}, 40\penalty0 (6):\penalty0
  1623--1646, 2011.

\bibitem[Shi \& Wang(1965)Shi and Wang]{ShiWan65}
Shi, Z.-C. and Wang, B.-Y.
\newblock Bounds for the determinant, characteristic roots and condition number
  of certain types of matrices.
\newblock \emph{Acta Math. Sinica}, 15\penalty0 (3):\penalty0 326--341, 1965.

\bibitem[Sinha et~al.(2018)Sinha, Namkoong, and
  Duchi]{Sinha_CertifiableDistributional_2018}
Sinha, A., Namkoong, H., and Duchi, J.
\newblock Certifiable distributional robustness with principled adversarial
  training.
\newblock In \emph{International conference on learning representations}, 2018.

\bibitem[Staib \& Jegelka(2017)Staib and
  Jegelka]{Staib_DistributionallyRobust_2017}
Staib, M. and Jegelka, S.
\newblock Distributionally robust deep learning as a generalization of
  adversarial training.
\newblock In \emph{31st {Conference} on {Neural} {Information} {Processing}
  {Systems}}, Long Beach, CA, USA, 2017.

\bibitem[Steinwart \& Christmann(2008)Steinwart and
  Christmann]{steinwart2008support}
Steinwart, I. and Christmann, A.
\newblock \emph{Support vector machines}.
\newblock Springer Science \& Business Media, 2008.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{Szegedy_IntriguingProperties_2014}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock \emph{International conference on learning representations}, 2014.

\bibitem[Toland(1979)]{Toland_DualityPrinciple_1979}
Toland, J.~F.
\newblock A duality principle for non-convex optimisation and the calculus of
  variations.
\newblock \emph{Archive for Rational Mechanics and Analysis}, 71\penalty0
  (1):\penalty0 41--61, May 1979.
\newblock ISSN 0003-9527, 1432-0673.
\newblock \doi{10.1007/bf00250669}.

\bibitem[Tropp(2015)]{Tropp15}
Tropp, J.~A.
\newblock An introduction to matrix concentration inequalities.
\newblock \emph{Foundations and Trends in Machine Learning}, 8\penalty0
  (1-2):\penalty0 1--230, 2015.

\bibitem[Tsuzuku et~al.(2018)Tsuzuku, Sato, and
  Sugiyama]{Tsuzuku_LipschitzmarginTraining_2018}
Tsuzuku, Y., Sato, I., and Sugiyama, M.
\newblock Lipschitz-margin training: scalable certification of perturbation
  invariance for deep neural networks.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in neural
  information processing systems 31}, pp.\  6541--6550. Curran Associates,
  Inc., 2018.

\bibitem[Udell \& Boyd(2016)Udell and Boyd]{Udell_BoundingDuality_2016}
Udell, M. and Boyd, S.
\newblock Bounding duality gap for separable problems with linear constraints.
\newblock \emph{Computational Optimization and Applications}, 64\penalty0
  (2):\penalty0 355--378, June 2016.
\newblock ISSN 1573-2894.
\newblock \doi{10.1007/s10589-015-9819-4}.

\bibitem[Vapnik(2000)]{Vapnik_NatureStatistical_2000}
Vapnik, V.~N.
\newblock \emph{The nature of statistical learning theory}.
\newblock Springer, New York, NY, USA, 2000.
\newblock ISBN 978-1-4757-3264-1 978-1-4419-3160-3.
\newblock OCLC: 864225872.

\bibitem[Vidakovic(2000)]{Vidakovic_GMinimaxParadigm_2000}
Vidakovic, B.
\newblock Γ-{Minimax}: a paradigm for conservative robust bayesians.
\newblock In Bickel, P., Diggle, P., Fienberg, S., Krickeberg, K., Olkin, I.,
  Wermuth, N., Zeger, S., Insua, D.~R., and Ruggeri, F. (eds.), \emph{Robust
  {Bayesian} {Analysis}}, volume 152, pp.\  241--259. Springer, New York, NY,
  USA, 2000.
\newblock ISBN 978-0-387-98866-5 978-1-4612-1306-2.
\newblock \doi{10.1007/978-1-4612-1306-2_13}.

\bibitem[Villani(2009)]{Villani_OptimalTransport_2009}
Villani, C.
\newblock \emph{Optimal transport: old and new}.
\newblock Number 338 in Grundlehren der mathematischen {Wissenschaften}.
  Springer-Verlag, Berlin, Germany, 2009.
\newblock ISBN 978-3-540-71049-3.
\newblock OCLC: ocn244421231.

\bibitem[Whitney(1934)]{Whitney_AnalyticExtensions_1934}
Whitney, H.
\newblock Analytic extensions of differentiable functions defined in closed
  sets.
\newblock \emph{Transactions of the American Mathematical Society}, 36\penalty0
  (1):\penalty0 63--89, 1934.
\newblock \doi{10.1090/s0002-9947-1934-1501735-3}.

\bibitem[Williams \& Seeger(2000)Williams and Seeger]{WilSee00b}
Williams, C. K.~I. and Seeger, M.
\newblock Using the {Nystr\"{o}m} method to speed up kernel machines.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2000.

\bibitem[Williamson et~al.(2001)Williamson, Smola, and
  {Sch\"olkopf}]{WilSmoSch01}
Williamson, R.~C., Smola, A.~J., and {Sch\"olkopf}, B.
\newblock Generalization bounds for regularization networks and support vector
  machines via entropy numbers of compact operators.
\newblock \emph{IEEE Transactions on Information Theory}, 47\penalty0
  (6):\penalty0 2516--2532, 2001.

\bibitem[Yoshida \& Miyato(2017)Yoshida and Miyato]{Yoshida_SpectralNorm_2017}
Yoshida, Y. and Miyato, T.
\newblock Spectral norm regularization for improving the generalizability of
  deep learning.
\newblock \emph{arXiv:1705.10941 [cs, stat]}, May 2017.
\newblock arXiv: 1705.10941.

\bibitem[Zhang et~al.(2016)Zhang, Lee, and Jordan]{ZhaLeeJor16}
Zhang, Y., Lee, J.~D., and Jordan, M.~I.
\newblock $\ell_1$-regularized neural networks are improperly learnable in
  polynomial time.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2016.

\bibitem[Zhang et~al.(2017)Zhang, Liang, and Wainwright]{ZhaLiaWai17}
Zhang, Y., Liang, P., and Wainwright, M.
\newblock Convexified convolutional neural networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2017.

\bibitem[Zhou(2002)]{Zhou02}
Zhou, D.-X.
\newblock The covering number in learning theory.
\newblock \emph{Journal of Complexity}, 18\penalty0 (3):\penalty0 739--767,
  2002.

\bibitem[Zhu et~al.(1998)Zhu, Williams, Rohwer, and Morciniec]{ZhuWilRohMor98}
Zhu, H., Williams, C.~K., Rohwer, R.~J., and Morciniec, M.
\newblock Gaussian regression and optimal finite dimensional linear models.
\newblock In Bishop, C.~M. (ed.), \emph{Neural Networks and Machine Learning}.
  Springer-Verlag, Berlin, 1998.

\bibitem[Zălinescu(2002)]{Zalinescu_ConvexAnalysis_2002}
Zălinescu, C.
\newblock \emph{Convex analysis in general vector spaces}.
\newblock World Scientific, River Edge, NJ, USA, 2002.
\newblock ISBN 978-981-238-067-8.
\newblock OCLC: 845511462.

\end{thebibliography}
