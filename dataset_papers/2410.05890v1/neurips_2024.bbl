\begin{thebibliography}{10}

\bibitem{sachs2005causal}
Karen Sachs, Omar Perez, Dana Pe'er, Douglas~A Lauffenburger, and Garry~P
  Nolan.
\newblock Causal protein-signaling networks derived from multiparameter
  single-cell data.
\newblock {\em Science}, 308(5721):523--529, 2005.

\bibitem{robins2000marginal}
James~M Robins, Miguel~Angel Hernan, and Babette Brumback.
\newblock Marginal structural models and causal inference in epidemiology.
\newblock {\em Epidemiology}, pages 550--560, 2000.

\bibitem{sanford2012bayesian}
Andrew~D Sanford and Imad~A Moosa.
\newblock A bayesian network structure for operational risk modelling in
  structured finance operations.
\newblock {\em Journal of the Operational Research Society}, 63:431--444, 2012.

\bibitem{ke2019SDI}
Nan~Rosemary Ke, Olexa Bilaniuk, Anirudh Goyal, Stefan Bauer, Hugo Larochelle,
  Bernhard Sch{\"o}lkopf, Michael~C Mozer, Chris Pal, and Yoshua Bengio.
\newblock Learning neural causal models from unknown interventions.
\newblock {\em arXiv preprint arXiv:1910.01075}, 2019.

\bibitem{ke2020CRN}
Nan~Rosemary Ke, Jane Wang, Jovana Mitrovic, Martin Szummer, Danilo~J Rezende,
  et~al.
\newblock Amortized learning of neural causal representations.
\newblock In {\em ICLR Causal Learning for Decision Making Workshop}, 2020.

\bibitem{yang2021CausalVAE}
Mengyue Yang, Furui Liu, Zhitang Chen, Xinwei Shen, Jianye Hao, and Jun Wang.
\newblock Causalvae: Disentangled representation learning via neural structural
  causal models.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 9593--9602, 2021.

\bibitem{shimizu2006NonGaussian}
Shohei Shimizu, Patrik~O Hoyer, Aapo Hyv{\"a}rinen, Antti Kerminen, and Michael
  Jordan.
\newblock A linear non-gaussian acyclic model for causal discovery.
\newblock {\em Journal of Machine Learning Research}, 7(10), 2006.

\bibitem{peters2014EqualVariances}
Jonas Peters and Peter B{\"u}hlmann.
\newblock Identifiability of gaussian structural equation models with equal
  error variances.
\newblock {\em Biometrika}, 101(1):219--228, 2014.

\bibitem{peters2014ANM}
Jonas Peters, Joris~M Mooij, Dominik Janzing, and Bernhard Sch{\"o}lkopf.
\newblock Causal discovery with continuous additive noise models.
\newblock 2014.

\bibitem{ng2020GOLEM}
Ignavier Ng, AmirEmad Ghassami, and Kun Zhang.
\newblock On the role of sparsity and dag constraints for learning linear dags.
\newblock {\em Advances in Neural Information Processing Systems},
  33:17943--17954, 2020.

\bibitem{rolland2022score}
Paul Rolland, Volkan Cevher, Matth{\"a}us Kleindessner, Chris Russell, Dominik
  Janzing, Bernhard Sch{\"o}lkopf, and Francesco Locatello.
\newblock Score matching enables causal discovery of nonlinear additive noise
  models.
\newblock In {\em International Conference on Machine Learning}, pages
  18741--18753. PMLR, 2022.

\bibitem{teyssier2012ordering}
Marc Teyssier and Daphne Koller.
\newblock Ordering-based search: A simple and effective algorithm for learning
  bayesian networks.
\newblock {\em arXiv preprint arXiv:1207.1429}, 2012.

\bibitem{ghoshal2018LISTEN}
Asish Ghoshal and Jean Honorio.
\newblock Learning linear structural equation models in polynomial time and
  sample complexity.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1466--1475. PMLR, 2018.

\bibitem{guo2020causal_effect}
Ruocheng Guo, Lu~Cheng, Jundong Li, P~Richard Hahn, and Huan Liu.
\newblock A survey of learning causality with data: Problems and methods.
\newblock {\em ACM Computing Surveys (CSUR)}, 53(4):1--37, 2020.

\bibitem{zheng2018NOTEARS}
Xun Zheng, Bryon Aragam, Pradeep~K Ravikumar, and Eric~P Xing.
\newblock Dags with no tears: Continuous optimization for structure learning.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{yu2019DAG_GNN}
Yue Yu, Jie Chen, Tian Gao, and Mo~Yu.
\newblock Dag-gnn: Dag structure learning with graph neural networks.
\newblock In {\em International Conference on Machine Learning}, pages
  7154--7163. PMLR, 2019.

\bibitem{ng2019GAE}
Ignavier Ng, Shengyu Zhu, Zhitang Chen, and Zhuangyan Fang.
\newblock A graph autoencoder approach to causal structure learning.
\newblock {\em arXiv preprint arXiv:1911.07420}, 2019.

\bibitem{zheng2020NOTEARS_MLP}
Xun Zheng, Chen Dan, Bryon Aragam, Pradeep Ravikumar, and Eric Xing.
\newblock Learning sparse nonparametric dags.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 3414--3425. PMLR, 2020.

\bibitem{bello2022dagma}
Kevin Bello, Bryon Aragam, and Pradeep Ravikumar.
\newblock Dagma: Learning dags via m-matrices and a log-determinant acyclicity
  characterization.
\newblock {\em Advances in Neural Information Processing Systems},
  35:8226--8239, 2022.

\bibitem{deng2023topo}
Chang Deng, Kevin Bello, Bryon Aragam, and Pradeep~Kumar Ravikumar.
\newblock Optimizing notears objectives via topological swaps.
\newblock In {\em International Conference on Machine Learning}, pages
  7563--7595. PMLR, 2023.

\bibitem{buhlmann2014cam}
Peter B{\"u}hlmann, Jonas Peters, and Jan Ernest.
\newblock Cam: Causal additive models, high-dimensional order search and
  penalized regression.
\newblock {\em The Annals of Statistics}, 42(6):2526--2556, 2014.

\bibitem{loh2014linear}
Po-Ling Loh and Peter B{\"u}hlmann.
\newblock High-dimensional learning of linear causal networks via inverse
  covariance estimation.
\newblock {\em The Journal of Machine Learning Research}, 15(1):3065--3105,
  2014.

\bibitem{sanchez2023diffusion}
Pedro Sanchez, Xiao Liu, Alison~Q O'Neil, and Sotirios~A Tsaftaris.
\newblock Diffusion models for causal discovery via topological ordering.
\newblock In {\em International Conference on Learning Representations}, 2023.

\bibitem{charpentier2022VIDPDAG}
Bertrand Charpentier, Simon Kibler, and Stephan G{\"u}nnemann.
\newblock Differentiable dag sampling.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{zantedeschi2023DAGuerreotype}
Valentina Zantedeschi, Luca Franceschi, Jean Kaddour, Matt~J Kusner, and Vlad
  Niculae.
\newblock Dag learning on the permutahedron.
\newblock In {\em International Conference on Learning Representations}, 2023.

\bibitem{li2018stein}
Yingzhen Li and Richard~E Turner.
\newblock Gradient estimators for implicit models.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{kahn1962topological}
Arthur~B Kahn.
\newblock Topological sorting of large networks.
\newblock {\em Communications of the ACM}, 5(11):558--562, 1962.

\bibitem{lachapelle2020gradient}
S{\'e}bastien Lachapelle, Philippe Brouillard, Tristan Deleu, and Simon
  Lacoste-Julien.
\newblock Gradient-based neural dag learning.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{peters2015SID}
Jonas Peters and Peter B{\"u}hlmann.
\newblock Structural intervention distance for evaluating causal graphs.
\newblock {\em Neural computation}, 27(3):771--799, 2015.

\bibitem{erdHos1960ER}
Paul Erd{\H{o}}s, Alfr{\'e}d R{\'e}nyi, et~al.
\newblock On the evolution of random graphs.
\newblock {\em Publ. math. inst. hung. acad. sci}, 5(1):17--60, 1960.

\bibitem{barabasi1999SF}
Albert-L{\'a}szl{\'o} Barab{\'a}si and R{\'e}ka Albert.
\newblock Emergence of scaling in random networks.
\newblock {\em science}, 286(5439):509--512, 1999.

\bibitem{van2006syntren}
Tim Van~den Bulcke, Koenraad Van~Leemput, Bart Naudts, Piet van Remortel,
  Hongwu Ma, Alain Verschoren, Bart De~Moor, and Kathleen Marchal.
\newblock Syntren: a generator of synthetic gene expression data for design and
  analysis of structure learning algorithms.
\newblock {\em BMC bioinformatics}, 7:1--12, 2006.

\bibitem{reisach2021beware}
Alexander Reisach, Christof Seiler, and Sebastian Weichwald.
\newblock Beware of the simulated dag! causal discovery benchmarks may be easy
  to game.
\newblock {\em Advances in Neural Information Processing Systems},
  34:27772--27784, 2021.

\bibitem{kyono2020castle}
Trent Kyono, Yao Zhang, and Mihaela van~der Schaar.
\newblock Castle: Regularization via auxiliary causal graph discovery.
\newblock {\em Advances in Neural Information Processing Systems},
  33:1501--1512, 2020.

\end{thebibliography}
