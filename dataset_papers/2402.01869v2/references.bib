
@misc{gpt-j-6b,
  author = {Wang, Ben and Komatsuzaki, Aran},
  title = {{GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model}},
  howpublished = {\url{https://github.com/kingoflolz/mesh-transformer-jax}},
  year = 2021,
  month = May
}

@article{li2023loogle,
  title={LooGLE: Can Long-Context Language Models Understand Long Contexts?},
  author={Li, Jiaqi and Wang, Mengmeng and Zheng, Zilong and Zhang, Muhan},
  journal={arXiv preprint arXiv:2311.04939},
  year={2023},
  month = Nov,
}

@InProceedings{xiao2021next,
    author    = {Xiao, Junbin and Shang, Xindi and Yao, Angela and Chua, Tat-Seng},
    title     = {NExT-QA: Next Phase of Question-Answering to Explaining Temporal Actions},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {9777-9786}
}

@inproceedings{transformer,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017},
month = Dec,
address = {Long Beach, CA}
}


@article{wu2023fast,
      title={Fast Distributed Inference Serving for Large Language Models}, 
      author={Bingyang Wu and Yinmin Zhong and Zili Zhang and Gang Huang and Xuanzhe Liu and Xin Jin},
      year={2023},
month = May,
journal = {arXiv preprint arXiv:2305.05920},
      eprint={2305.05920},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{zheng2023efficiently,
      title={Efficiently Programming Large Language Models using SGLang}, 
      author={Lianmin Zheng and Liangsheng Yin and Zhiqiang Xie and Jeff Huang and Chuyue Sun and Cody Hao Yu and Shiyi Cao and Christos Kozyrakis and Ion Stoica and Joseph E. Gonzalez and Clark Barrett and Ying Sheng},
      year={2023},
month = Dec,
journal = {arXiv preprint arXiv:2312.07104},
      eprint={2312.07104},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{Hu2024InferenceWI,
  title={Inference without Interference: Disaggregate LLM Inference for Mixed Downstream Workloads},
  author={Cunchen Hu and Heyang Huang and Liangliang Xu and Xusheng Chen and Jiang Xu and Shuang Chen and Hao Feng and Chenxi Wang and Sa Wang and Yungang Bao and Ninghui Sun and Yizhou Shan},
  journal={arXiv preprint arXiv:2401.11181},
  year={2024},
month = Jan,
  howpublished={\url{https://api.semanticscholar.org/CorpusID:267068930}}
}

@inproceedings{ainslie-etal-2023-gqa,
    title = "{GQA}: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints",
    author = "Ainslie, Joshua  and
      Lee-Thorp, James  and
      de Jong, Michiel  and
      Zemlyanskiy, Yury  and
      Lebron, Federico  and
      Sanghai, Sumit",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP 2023)",
    month = dec,
    year = "2023",
    address = "Singapore",
}

@misc{yen2024longcontext,
      title={Long-Context Language Modeling with Parallel Context Encoding}, 
      author={Howard Yen and Tianyu Gao and Danqi Chen},
      year={2024},
      eprint={2402.16617},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{gim2024prompt,
      title={Prompt Cache: Modular Attention Reuse for Low-Latency Inference}, 
      author={In Gim and Guojun Chen and Seung-seob Lee and Nikhil Sarda and Anurag Khandelwal and Lin Zhong},
      year={2024},
      month = May,
      address = {Santa Clara, CA},
Booktitle = {Proceedings of the 7th MLSys Conference}
      
}

@inproceedings{zhong2024distserve,
      title={DistLLM: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving}, 
      author={Yinmin Zhong and Shengyu Liu and Junda Chen and Jianbo Hu and Yibo Zhu and Xuanzhe Liu and Xin Jin and Hao Zhang},
      year={2024},
month = Jul,
address = {Santa Clara, CA},
Booktitle = {Proceedings of the 18th USENIX Symposium on Operating Systems Design and Implementation (OSDI '24)}
}



@inproceedings{
zhang2023automatic,
title={Automatic Chain of Thought Prompting in Large Language Models},
author={Zhuosheng Zhang and Aston Zhang and Mu Li and Alex Smola},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
month = May,
address = {Kigali, Rwanda}
}

@inproceedings{Arpan2020clock,
author = {Gujarati, Arpan and Karimi, Reza and Alzayat, Safya and Hao, Wei and Kaufmann, Antoine and Vigfusson, Ymir and Mace, Jonathan},
title = {Serving DNNs like clockwork: performance predictability from the bottom up},
year = {2020},
booktitle = {Proceedings of the 14th USENIX Conference on Operating Systems Design and Implementation},
pages={443--462}
}

@inproceedings{10.5555/3488766.3488791,
author = {Gujarati, Arpan and Karimi, Reza and Alzayat, Safya and Hao, Wei and Kaufmann, Antoine and Vigfusson, Ymir and Mace, Jonathan},
title = {Serving DNNs like clockwork: performance predictability from the bottom up},
year = {2020},
isbn = {978-1-939133-19-9},
publisher = {USENIX Association},
address = {USA},
abstract = {Machine learning inference is becoming a core building block for interactive web applications. As a result, the underlying model serving systems on which these applications depend must consistently meet low latency targets. Existing model serving architectures use well-known reactive techniques to alleviate common-case sources of latency, but cannot effectively curtail tail latency caused by unpredictable execution times. Yet the underlying execution times are not fundamentally unpredictable--on the contrary we observe that inference using Deep Neural Network (DNN) models has deterministic performance.Here, starting with the predictable execution times of individual DNN inferences, we adopt a principled design methodology to successively build a fully distributed model serving system that achieves predictable end-to-end performance. We evaluate our implementation, Clockwork, using production trace workloads, and show that Clockwork can support thousands of models while simultaneously meeting 100 ms latency targets for 99.9999\% of requests. We further demonstrate that Clockwork exploits predictable execution times to achieve tight request-level service-level objectives (SLOs) as well as a high degree of request-level performance isolation.},
booktitle = {Proceedings of the 14th USENIX Conference on Operating Systems Design and Implementation},
articleno = {25},
numpages = {20},
series = {OSDI'20}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2023},
month=Mar,
}


@misc{sora,
    author = {OpenAI},
    title = {Video generation models as world simulators},
    year = {2024},
    howpublished={\url{https://openai.com/index/video-generation-models-as-world-simulators}}
}

@inproceedings{yu2023self,
  title   = {Self-Chained Image-Language Model for Video Localization and Question Answering},
  author  = {Yu, Shoubin and Cho, Jaemin and Yadav, Prateek and Bansal, Mohit},
  booktitle = {Thirty-seventh Conference on Neural Information Processing Systems},
  year    = {2023},
month = Dec,
address = {New Orleans, Louisiana},
}

@misc{tensorRTllm,
    title = {NVIDIA TensorRT-LLM Supercharges Large Language Model Inference on NVIDIA H100 GPUs},
    author = {Vaidya, Neal and Comly, Nick and DeLaere, Joe and Patel, Ankit and Oh, Fred},
    year = {2023},
    howpublished = {\url{https://developer.nvidia.com/blog/nvidia-tensorrt-llm-supercharges-large-language-model-inference-on-nvidia-h100-gpus/}} 
}

@inproceedings{miao2023specinfer,
author = {Miao, Xupeng and Oliaro, Gabriele and Zhang, Zhihao and Cheng, Xinhao and Wang, Zeyu and Zhang, Zhengxin and Wong, Rae Ying Yee and Zhu, Alan and Yang, Lijie and Shi, Xiaoxiang and Shi, Chunan and Chen, Zhuoming and Arfeen, Daiyaan and Abhyankar, Reyna and Jia, Zhihao},
title = {SpecInfer: Accelerating Large Language Model Serving with Tree-based Speculative Inference and Verification},
year = {2024},
location = {La Jolla, CA, USA},
month = Apr,
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems}
}

@misc{azureTrace,
    title = {Azure LLM inference trace 2023} ,
    year = {2023},
    howpublished = {\url{https://github.com/Azure/AzurePublicDataset/blob/master/AzureLLMInferenceDataset2023.md}}
}

@article{jacobs2023deepspeed,
      title={DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models}, 
      author={Sam Ade Jacobs and Masahiro Tanaka and Chengming Zhang and Minjia Zhang and Shuaiwen Leon Song and Samyam Rajbhandari and Yuxiong He},
      year={2023},
      month = Oct,
      journal = {arXiv preprint arXiv:2309.14509},
      eprint={2309.14509},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{liu2023ring,
      title={Ring Attention with Blockwise Transformers for Near-Infinite Context}, 
      author={Hao Liu and Matei Zaharia and Pieter Abbeel},
      year={2023},
month = Nov,
journal = {arXiv preprint arXiv:2310.01889},
      eprint={2310.01889},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{munkhdalai2024leave,
      title={Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention}, 
      author={Tsendsuren Munkhdalai and Manaal Faruqui and Siddharth Gopal},
      year={2024},
month = Apr,
journal = {arXiv preprint arXiv:2404.07143},
      eprint={2404.07143},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{esser2020taming,
      title={Taming Transformers for High-Resolution Image Synthesis}, 
      author={Patrick Esser and Robin Rombach and Björn Ommer},
      year={2020},
      address = {Los Alamitos, CA},
      month = Jun,
      booktitle = {2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
}

@software{Chase_LangChain_2022,
author = {Chase, Harrison},
month = oct,
title = {{LangChain}},
howpublished = {\url{https://github.com/langchain-ai/langchain}},
year = {2022}
}

@online{openai-chatgpt-whisper-apis,
  author = {Greg Brockman and Atty Eleti and Elie Georges and Joanne Jang and Logan Kilpatrick and Rachel Lim and Luke Miller and Michelle Pokrass},
  title = {Introducing ChatGPT and Whisper APIs},
  publisher = {OpenAI Blog},
  year = {2023},
  month = {March 1},
  howpublished = {\url{https://openai.com/blog/introducing-chatgpt-and-whisper-apis}},
  organization={IEEE},
}

@article{shoeybi2020megatronlm,
      title={Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism}, 
      author={Mohammad Shoeybi and Mostofa Patwary and Raul Puri and Patrick LeGresley and Jared Casper and Bryan Catanzaro},
      year={2019},
      journal={arXiv preprint arXiv:1909.08053},
      eprint={1909.08053},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{patil2023gorilla,
    title={Gorilla: Large Language Model Connected with Massive APIs},
    author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},
    journal={arXiv preprint arXiv:2305.15334},
    year={2023},
}

@online{greyling-chatgpt-api,
  author = {Cobus Greyling},
  title = {When Using the ChatGPT API, Users Will Have to Manage the Context},
  year = {2023},
  month = {March 6},
  howpublished = {\url{https://cobusgreyling.medium.com/when-using-the-chatgpt-api-users-will-have-to-manage-the-context-ba5869238913}},
}


@online{wolfram-chatgpt,
  author = {Stephen Wolfram},
  title = {ChatGPT Gets Its `Wolfram Superpowers'!},
  year = {2023},
  month = Mar,
  howpublished = {\url{{https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/}}}
}


@article{nllbteam2022language,
      title={No Language Left Behind: Scaling Human-Centered Machine Translation}, 
      author={Marta R. Costa-jussà and James Cross and Onur Çelebi and Maha Elbayad and Kenneth Heafield and Kevin Heffernan and Elahe Kalbassi and Janice Lam and Daniel Licht and Jean Maillard and Anna Sun and Skyler Wang and Guillaume Wenzek and Al Youngblood and Bapi Akula and Loic Barrault and Gabriel Mejia Gonzalez and Prangthip Hansanti and John Hoffman and Semarley Jarrett and Kaushik Ram Sadagopan and Dirk Rowe and Shannon Spruit and Chau Tran and Pierre Andrews and Necip Fazil Ayan and Shruti Bhosale and Sergey Edunov and Angela Fan and Cynthia Gao and Vedanuj Goswami and Francisco Guzmán and Philipp Koehn and Alexandre Mourachko and Christophe Ropers and Safiyyah Saleem and Holger Schwenk and Jeff Wang},
      journal={arXiv preprint arXiv:2207.04672},
      year={2022},
      month=Jul,
      howpublished={\url{https://arxiv.org/abs/2207.04672}}
}


@inproceedings{yao2023tree,
 author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
 booktitle = {Thirty-seventh Conference on Neural Information Processing Systems},
 editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
 title = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/271db9922b8d1f4dd7aaef84ed5ac703-Paper-Conference.pdf},
 volume = {36},
 year = {2023},
month = Dec,
address = {New Orleans, Louisiana}
}

@article{zhang2022opt,
      title={OPT: Open Pre-trained Transformer Language Models}, 
      author={Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
      year={2022},
month = Jun,
journal = {arXiv preprint arXiv:2205.01068},
      eprint={2205.01068},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{openai2023gpt4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@book{baeza1999modern,
  author = {Baeza-Yates, Ricardo and Ribeiro-Neto, Berthier and others},
  title = {Modern Information Retrieval},
  volume = {463},
  publisher = {ACM Press},
  year = {1999},
  address = {New York}
}

@online{opentable-chatgpt,
  author = {OpenTable},
  title = {NEW: ChatGPT restaurant recs, powered by OpenTable},
  year = {2023},
  month = {March 23},
  howpublished = {\url{https://www.opentable.com/blog/chatgpt/}},
}


@misc{izacard2022atlas,
      title={Atlas: Few-shot Learning with Retrieval Augmented Language Models}, 
      author={Gautier Izacard and Patrick Lewis and Maria Lomeli and Lucas Hosseini and Fabio Petroni and Timo Schick and Jane Dwivedi-Yu and Armand Joulin and Sebastian Riedel and Edouard Grave},
      year={2022},
      eprint={2208.03299},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{chatgpt-plugin,
author={{OpenAI}},
title={{ChatGPT plugins}},
howpublished={\url{https://openai.com/blog/chatgpt-plugins}},
month=mar,
year={2023},
}

@inproceedings{crankshaw2017clipper,
  title={Clipper: A $\{$Low-Latency$\}$ online prediction serving system},
  author={Crankshaw, Daniel and Wang, Xin and Zhou, Guilio and Franklin, Michael J and Gonzalez, Joseph E and Stoica, Ion},
  booktitle={14th USENIX Symposium on Networked Systems Design and Implementation (NSDI 17)},
  pages={613--627},
  year={2017}
}

@article{tfserving,
  title={Tensorflow-serving: Flexible, high-performance ml serving},
  author={Olston, Christopher and Fiedel, Noah and Gorovoy, Kiril and Harmsen, Jeremiah and Lao, Li and Li, Fangwei and Rajashekhar, Vinu and Ramesh, Sukriti and Soyke, Jordan},
  journal={arXiv preprint arXiv:1712.06139},
  year={2017}
}

@inproceedings{vLLM,
  title={Efficient memory management for large language model serving with pagedattention},
  author={Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion},
  booktitle={Proceedings of the 29th Symposium on Operating Systems Principles},
  year={2023},
address = {Koblenz, Germany},
  month=Oct,
}

@inproceedings {Orca,
author = {Gyeong-In Yu and Joo Seong Jeong and Geon-Woo Kim and Soojeong Kim and Byung-Gon Chun},
title = "{Orca: A Distributed Serving System for {Transformer-Based} Generative Models}",
booktitle = {16th USENIX Symposium on Operating Systems Design and Implementation (OSDI '22)},
year = {2022},
address = {Carlsbad, CA},
month = jul
}

@article{chunk_prefill_sarathi,
  title={SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills},
  author={Agrawal, Amey and Panwar, Ashish and Mohan, Jayashree and Kwatra, Nipun and Gulavani, Bhargav S and Ramjee, Ramachandran},
  journal={arXiv preprint arXiv:2308.16369},
  year={2023},
  month=Aug
}


@article{agrawal2024taming,
  title={Taming Throughput-Latency Tradeoff in LLM Inference with Sarathi-Serve},
  author={Agrawal, Amey and Kedia, Nitin and Panwar, Ashish and Mohan, Jayashree and Kwatra, Nipun and Gulavani, Bhargav S and Tumanov, Alexey and Ramjee, Ramachandran},
  journal={Proceedings of 18th USENIX Symposium on Operating Systems Design and Implementation, 2024, Santa Clara},
  year={2024}
}

@inproceedings{patel2024splitwise,
author = {Patel, Pratyush and Choukse, Esha and Zhang, Chaojie and Shah, Aashaka and Goiri, 
 {\'I}{\~n}igo and Maleki, Saeed and Bianchini, Ricardo},
title = {Splitwise: Efficient generative LLM inference using phase splitting},
booktitle = {The 53th International Symposium on Computer Architecture (ISCA 2024)},
year = {2024},
month = {June},
address = {Buenos Aires, Argentina},
}

@inproceedings{
khattab2024dspy,
title={{DSP}y: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines},
author={Omar Khattab and Arnav Singhvi and Paridhi Maheshwari and Zhiyuan Zhang and Keshav Santhanam and Sri Vardhamanan A and Saiful Haq and Ashutosh Sharma and Thomas T. Joshi and Hanna Moazam and Heather Miller and Matei Zaharia and Christopher Potts},
booktitle={The Twelfth International Conference on Learning Representations (ICLR '24)},
year={2024},
url={https://openreview.net/forum?id=sY5N0zY5Od},
address={Vienna, Austria}
}

@article{chen2019agentgraph,
  author       = {Lu Chen and
                  Zhi Chen and
                  Bowen Tan and
                  Sishan Long and
                  Milica Gasic and
                  Kai Yu},
  title        = {AgentGraph: Towards Universal Dialogue Management with Structured
                  Deep Reinforcement Learning},
  journal      = {arXiv preprint arXiv:1905.11259},
  year         = {2019},
month = May,
}

@inproceedings{
lu2023chameleon,
title={Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models},
author={Pan Lu and Baolin Peng and Hao Cheng and Michel Galley and Kai-Wei Chang and Ying Nian Wu and Song-Chun Zhu and Jianfeng Gao},
year = {2023},
month = Dec,
address = {New Orleans, Louisiana},
booktitle = { Proceedings of the 37th International Conference on Neural Information Processing Systems (NeurIPS '23)},
}

@INPROCEEDINGS {surís2023vipergpt,
author = {D. Suris and S. Menon and C. Vondrick},
booktitle = {2023 IEEE/CVF International Conference on Computer Vision (ICCV '23)},
title = {ViperGPT: Visual Inference via Python Execution for Reasoning},
year = {2023},
pages = {11854-11864},
url = {https://doi.ieeecomputersociety.org/10.1109/ICCV51070.2023.01092},
address = {Los Alamitos, CA, USA},
month = oct,
}

@inproceedings{qian-etal-2023-creator,
    title = "{CREATOR}: Tool Creation for Disentangling Abstract and Concrete Reasoning of Large Language Models",
    author = "Qian, Cheng  and
      Han, Chi  and
      Fung, Yi  and
      Qin, Yujia  and
      Liu, Zhiyuan  and
      Ji, Heng",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: (EMNLP '23)",
    month = dec,
    year = "2023",
    address = "Singapore",
    url = "https://aclanthology.org/2023.findings-emnlp.462",
}


@inproceedings{
shen2023hugginggpt,
title={Hugging{GPT}: Solving {AI} Tasks with Chat{GPT} and its Friends in Hugging Face},
author={Yongliang Shen and Kaitao Song and Xu Tan and Dongsheng Li and Weiming Lu and Yueting Zhuang},
year = {2023},
month = Dec,
address = {New Orleans, Louisiana},
booktitle = { Proceedings of the 37th International Conference on Neural Information Processing Systems (NeurIPS '23)},
}

@article{jiang2023mistral,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      month = Oct,
      journal = {arXiv preprint arXiv:2310.06825},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{llama3,
  author = {Meta},
  title = {Meta Llama 3},
  howpublished = {\url{https://llama.meta.com/llama3/}},
  year = {2024},
}

@article{Wang2023ASO,
  title={A Survey on Large Language Model based Autonomous Agents},
  author={Lei Wang and Chengbang Ma and Xueyang Feng and Zeyu Zhang and Hao-ran Yang and Jingsen Zhang and Zhi-Yang Chen and Jiakai Tang and Xu Chen and Yankai Lin and Wayne Xin Zhao and Zhewei Wei and Ji-rong Wen},
  journal={arXiv preprint arXiv:2308.11432},
  year={2023},
month = Aug,
  url={https://api.semanticscholar.org/CorpusID:261064713}
}

@article{qin2023tool,
      title={Tool Learning with Foundation Models}, 
      author={Yujia Qin and Shengding Hu and Yankai Lin and Weize Chen and Ning Ding and Ganqu Cui and Zheni Zeng and Yufei Huang and Chaojun Xiao and Chi Han and Yi Ren Fung and Yusheng Su and Huadong Wang and Cheng Qian and Runchu Tian and Kunlun Zhu and Shihao Liang and Xingyu Shen and Bokai Xu and Zhen Zhang and Yining Ye and Bowen Li and Ziwei Tang and Jing Yi and Yuzhang Zhu and Zhenning Dai and Lan Yan and Xin Cong and Yaxi Lu and Weilin Zhao and Yuxiang Huang and Junxi Yan and Xu Han and Xian Sun and Dahai Li and Jason Phang and Cheng Yang and Tongshuang Wu and Heng Ji and Zhiyuan Liu and Maosong Sun},
      year={2023},
journal = {arXiv preprint arXiv:2304.08354},
month = Jun,
      eprint={2304.08354},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ng-blog,
  author = {Andrew Ng},
  title = {The Batch Weekly Issues 241},
  howpublished = {\url{https://www.deeplearning.ai/the-batch/issue-241/}},
  year = {2024},
month = Mar,
}


@misc{nvidia2023fastertransformer,
  author = {NVIDIA},
  title = {FasterTransformer},
  howpublished = {\url{https://github.com/NVIDIA/FasterTransformer}},
  year = {2023},
}

@misc{betker2024improving,
  title={Improving Image Generation with Better Captions},
  author={
    James Betker and 
    Gabriel Goh and 
    Li Jing and 
    Tim Brooks and 
    Jianfeng Wang and 
    Linjie Li and 
    Long Ouyang and 
    Juntang Zhuang and 
    Joyce Lee and 
    Yufei Guo and 
    Wesam Manassra and 
    Prafulla Dhariwal and 
    Casey Chu and 
    Yunxin Jiao and 
    Aditya Ramesh
  },
  year={2024},
  institution={OpenAI},
howpublished = {\url{https://cdn.openai.com/papers/dall-e-3.pdf}},
}

@article{srivatsa2024preble,
  title={Preble: Efficient Distributed Prompt Scheduling for LLM Serving},
  author={
    Vikranth Srivatsa and 
    Zijian He and 
    Reyna Abhyankar and 
    Dongming Li and 
    Yiying Zhang
  },
journal = {UCSD CSE Technical Reports},
  year={2024},
month = May,
url = {https://escholarship.org/uc/item/1bm0k1w0},
}

@inproceedings{aminabadi2022deepspeed,
  title={DeepSpeed-inference: enabling efficient inference of transformer models at unprecedented scale},
  author={Aminabadi, Reza Yazdani and Rajbhandari, Samyam and Awan, Ammar Ahmad and Li, Cheng and Li, Du and Zheng, Elton and Ruwase, Olatunji and Smith, Shaden and Zhang, Minjia and Rasley, Jeff and others},
  booktitle={SC22: International Conference for High Performance Computing, Networking, Storage and Analysis},
  year={2022},
  organization={IEEE},
    address = {Dallas, Texas},
  month = Nov
}


@misc{sheng2023flexgen,
      title={FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU}, 
      author={Ying Sheng and Lianmin Zheng and Binhang Yuan and Zhuohan Li and Max Ryabinin and Daniel Y. Fu and Zhiqiang Xie and Beidi Chen and Clark Barrett and Joseph E. Gonzalez and Percy Liang and Christopher Ré and Ion Stoica and Ce Zhang},
      year={2023},
      eprint={2303.06865},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{li2023alpaserve,
author = {Zhuohan Li and Lianmin Zheng and Yinmin Zhong and Vincent Liu and Ying Sheng and Xin Jin and Yanping Huang and Zhifeng Chen and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
title = {{AlpaServe}: Statistical Multiplexing with Model Parallelism for Deep Learning Serving},
booktitle = {17th USENIX Symposium on Operating Systems Design and Implementation (OSDI 23)},
year = {2023},
address = {Boston, MA},
month = jul
}

@article{
mialon2023augmented,
title={Augmented Language Models: a Survey},
author={Gr{\'e}goire Mialon and Roberto Dessi and Maria Lomeli and Christoforos Nalmpantis and Ramakanth Pasunuru and Roberta Raileanu and Baptiste Roziere and Timo Schick and Jane Dwivedi-Yu and Asli Celikyilmaz and Edouard Grave and Yann LeCun and Thomas Scialom},
journal={Transactions on Machine Learning Research (TMLR)},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=jh7wH2AzKK},
note={Survey Certification}
}

@inproceedings{wei2022chain,
author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
title = {Chain-of-thought prompting elicits reasoning in large language models},
year = {2023},
address = {New Orleans, Louisiana},
booktitle = { Proceedings of the 36th International Conference on Neural Information Processing Systems},
}

@inproceedings{
yao2022react,
title={ReAct: Synergizing Reasoning and Acting in Language Models},
author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik R Narasimhan and Yuan Cao},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
month=May,
address={Kigali, Rwanda},
}

@article{parisi2022talm,
  title={Talm: Tool augmented language models},
  author={Parisi, Aaron and Zhao, Yao and Fiedel, Noah},
  journal={arXiv preprint arXiv:2205.12255},
  year={2022},
month=May
}

@inproceedings{hao2023toolkengpt,
 author = {Hao, Shibo and Liu, Tianyang and Wang, Zhen and Hu, Zhiting},
 booktitle = {Advances in Neural Information Processing Systems 36},
 title = {ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings},
 year = {2023},
month = Dec,
address = {New Orleans, Louisiana}
}

@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={37th Conference on Neural Information Processing Systems},
  address={New Orleans, Louisiana},
  year={2023}
}

@article{guo2024stabletoolbench,
      title={StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models},
      author={Guo, Zhicheng and Cheng, Sijie and Wang, Hao and Liang, Shihao and Qin, Yujia and Li, Peng and Liu, Zhiyuan and Sun, Maosong and Liu, Yang},
      journal = {arXiv preprint arXiv:2403.07714},
      year={2024},
      month={Mar},
      eprint={2403.07714},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{li2024agents,
      title={More Agents Is All You Need}, 
      author={Junyou Li and Qin Zhang and Yangbin Yu and Qiang Fu and Deheng Ye},
      year={2024},
month = Feb,
journal = {arXiv preprint arXiv:2402.05120},
      eprint={2402.05120},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{wu2023autogen,
      title={AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation}, 
      author={Qingyun Wu and Gagan Bansal and Jieyu Zhang and Yiran Wu and Beibin Li and Erkang Zhu and Li Jiang and Xiaoyun Zhang and Shaokun Zhang and Jiale Liu and Ahmed Hassan Awadallah and Ryen W White and Doug Burger and Chi Wang},
      year={2023},
month = Oct,
journal = {arXiv preprint arXiv:2308.08155},
      eprint={2308.08155},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{qin2023toolllm,
      title={ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs}, 
      author={Yujia Qin and Shihao Liang and Yining Ye and Kunlun Zhu and Lan Yan and Yaxi Lu and Yankai Lin and Xin Cong and Xiangru Tang and Bill Qian and Sihan Zhao and Runchu Tian and Ruobing Xie and Jie Zhou and Mark Gerstein and Dahai Li and Zhiyuan Liu and Maosong Sun},
      year={2023},
month = Oct,
journal = {arXiv preprint arXiv:2307.16789},
      eprint={2307.16789},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{wang2024mint,
      title={MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback}, 
      author={Xingyao Wang and Zihan Wang and Jiateng Liu and Yangyi Chen and Lifan Yuan and Hao Peng and Heng Ji},
      booktitle = {The Twelfth International Conference on Learning Representations},
      year={2024},
    month = May,
address = {Vienna, Austria},
}

@article{agentHospital,
      title={Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents}, 
      author={Junkai Li and Siyu Wang and Meng Zhang and Weitao Li and Yunghwei Lai and Xinhui Kang and Weizhi Ma and Yang Liu},
      year={2024},
month = May,
journal = {arXiv preprint arXiv:2405.02957},
      eprint={2405.02957},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{yang2018hotpotqa,
  title={HotpotQA: A dataset for diverse, explainable multi-hop question answering},
  author={Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W and Salakhutdinov, Ruslan and Manning, Christopher D},
  journal={arXiv preprint arXiv:1809.09600},
  year={2018}
}

@article{juravsky2024hydragen,
      title={Hydragen: High-Throughput LLM Inference with Shared Prefixes}, 
      author={Jordan Juravsky and Bradley Brown and Ryan Ehrlich and Daniel Y. Fu and Christopher Ré and Azalia Mirhoseini},
      year={2024},
month = May,
journal = {arXiv preprint arXiv:2402.05099},
      eprint={2402.05099},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{hendrycksapps2021,
  title={Measuring Coding Challenge Competence With APPS},
  author={Dan Hendrycks and Steven Basart and Saurav Kadavath and Mantas Mazeika and Akul Arora and Ethan Guo and Collin Burns and Samir Puranik and Horace He and Dawn Song and Jacob Steinhardt},
booktitle    = {Proceedings of the Neural Information Processing Systems Track on
                  Datasets and Benchmarks},
  year={2021},
  month = Dec,
}

@inproceedings{
vicuna_share_gpt,
title={Judging {LLM}-as-a-Judge with {MT}-Bench and Chatbot Arena},
author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
address={New Orleans, Louisiana},
year={2023},
month=Dec
}

@misc{gemini,
    author = {Pichai, Sundar and Hassabis, Demis},
    title = {Introducing Gemini: our largest and most capable AI model},
    year = {2023},
    howpublished = {\url{https://blog.google/technology/ai/google-gemini-ai/}}
}

@article{GAREY1976237,
title = {Some simplified NP-complete graph problems},
journal = {Theoretical Computer Science},
volume = {1},
number = {3},
pages = {237-267},
year = {1976},
issn = {0304-3975},
doi = {https://doi.org/10.1016/0304-3975(76)90059-1},
url = {https://www.sciencedirect.com/science/article/pii/0304397576900591},
author = {M.R. Garey and D.S. Johnson and L. Stockmeyer},
}

@inproceedings{shridhar2020alfworld,
  title ={ALFWorld: Aligning Text and Embodied
           Environments for Interactive Learning},
  author={Mohit Shridhar and Xingdi Yuan and
          Marc-Alexandre C\^ot\'e and Yonatan Bisk and
          Adam Trischler and Matthew Hausknecht},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year = {2021},
address = {Virtual},
}
@misc{tts_sunoai2023bark,
  author = {Suno AI},
  title = {Bark: Text-to-Speech Model},
  howpublished = {\url{https://github.com/suno-ai/bark}},
  year = {2023},
}

@article{stable_diffusion,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
      journal={arXiv preprint arXiv:2112.10752},
      year={2021},
      eprint={2112.10752},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{rapidapi,
  author = {{RapidAPI}},
  title = {{RapidAPI: World’s Largest API Hub

}},
  howpublished = {\url{https://rapidapi.com/}},
  year = {2023},
}
@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}

@misc{chatgpt,
    author = {OpenAI},
    title = {Introducing ChatGPT},
    year = {2022},
    howpublished = {\url{https://openai.com/index/chatgpt}}
}

@inproceedings{Gu_2022,
   title={Vision-and-Language Navigation: A Survey of Tasks, Methods, and Future Directions},
   DOI={10.18653/v1/2022.acl-long.524},
   booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   publisher={Association for Computational Linguistics},
address = {Dublin, Ireland},
   author={Gu, Jing and Stefani, Eliana and Wu, Qi and Thomason, Jesse and Wang, Xin},
   year={2022} }

@inproceedings{huang2022language,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={Proceedings of 39th International Conference on Machine Learning},
  year={2022},
  address={Honolulu, Hawai'i}
}

@article{nijkamp2023codegen2,
      title={CodeGen2: Lessons for Training LLMs on Programming and Natural Languages}, 
      author={Erik Nijkamp and Hiroaki Hayashi and Caiming Xiong and Silvio Savarese and Yingbo Zhou},
      year={2023},
month = Jul,
journal = {arXiv preprint arXiv:2305.02309},
      eprint={2305.02309},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{hu2023look,
      title={Look Before You Leap: Unveiling the Power of GPT-4V in Robotic Vision-Language Planning}, 
      author={Yingdong Hu and Fanqi Lin and Tong Zhang and Li Yi and Yang Gao},
      year={2023},
      month=Nov,
      journal={arXiv preprint arXiv:2311.17842},
      howpublished={\url{https://arxiv.org/abs/2311.17842}}
}

@inproceedings{leviathan2023fast,
  title={Fast inference from transformers via speculative decoding},
  author={Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  booktitle={International Conference on Machine Learning},
  pages={19274--19286},
  year={2023},
  organization={PMLR}
}

@inproceedings{dao2022flashattention,
  title={Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
  author={Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{brysbaert_2019,
  title={How many words do we read per minute? A review and meta-analysis of reading rate},
  author={Brysbaert, Marc},
  journal={Journal of memory and language},
  volume={109},
  pages={104047},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{ma2015haptic,
  title={Haptic keyclick feedback improves typing speed and reduces typing errors on a flat keyboard},
  author={Ma, Zhaoyuan and Edge, Darren and Findlater, Leah and Tan, Hong Z},
  booktitle={2015 IEEE World Haptics Conference (WHC)},
  year={2015},
address={Evanston, Illinois},
  organization={IEEE}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}




@misc{vllm-pr-for-prefix-sharing,
 title={Automatic Prefix Caching},
author={Moore, Sage and Li, Zhouhan},
year={2024},
month={March},
 howpublished={\url{https://github.com/vllm-project/vllm/issues/2614}},
}
