\begin{thebibliography}{85}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Addepalli et~al.(2021)Addepalli, Jain, Sriramanan, Khare, and Radhakrishnan]{addepalli2021towards}
Addepalli, S., Jain, S., Sriramanan, G., Khare, S., and Radhakrishnan, V.~B.
\newblock Towards achieving adversarial robustness beyond perceptual limits.
\newblock In \emph{ICML 2021 Workshop on Adversarial Machine Learning}, 2021.
\newblock URL \url{https://openreview.net/forum?id=SHB_znlW5G7}.

\bibitem[Addepalli et~al.(2022)Addepalli, Jain, Sriramanan, and Venkatesh~Babu]{addepalli2022scaling}
Addepalli, S., Jain, S., Sriramanan, G., and Venkatesh~Babu, R.
\newblock Scaling adversarial training to large perturbation bounds.
\newblock In \emph{European Conference on Computer Vision}, pp.\  301--316. Springer, 2022.

\bibitem[Araujo et~al.(2023)Araujo, Havens, Delattre, Allauzen, and Hu]{araujo2023a}
Araujo, A., Havens, A.~J., Delattre, B., Allauzen, A., and Hu, B.
\newblock A unified algebraic perspective on lipschitz neural networks.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=k71IGLC8cfc}.

\bibitem[Bastani et~al.(2016)Bastani, Ioannou, Lampropoulos, Vytiniotis, Nori, and Criminisi]{bastani2016measuring}
Bastani, O., Ioannou, Y., Lampropoulos, L., Vytiniotis, D., Nori, A., and Criminisi, A.
\newblock Measuring neural net robustness with constraints.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Biggio et~al.(2013)Biggio, Corona, Maiorca, Nelson, {\v{S}}rndi{\'c}, Laskov, Giacinto, and Roli]{biggio2013evasion}
Biggio, B., Corona, I., Maiorca, D., Nelson, B., {\v{S}}rndi{\'c}, N., Laskov, P., Giacinto, G., and Roli, F.
\newblock Evasion attacks against machine learning at test time.
\newblock In \emph{Joint European conference on machine learning and knowledge discovery in databases}, pp.\  387--402. Springer, 2013.

\bibitem[Brix et~al.(2023{\natexlab{a}})Brix, Bak, Liu, and Johnson]{brix2023fourth}
Brix, C., Bak, S., Liu, C., and Johnson, T.~T.
\newblock The fourth international verification of neural networks competition (vnn-comp 2023): Summary and results.
\newblock \emph{arXiv preprint arXiv:2312.16760}, 2023{\natexlab{a}}.

\bibitem[Brix et~al.(2023{\natexlab{b}})Brix, M{\"u}ller, Bak, Johnson, and Liu]{brix2023first}
Brix, C., M{\"u}ller, M.~N., Bak, S., Johnson, T.~T., and Liu, C.
\newblock First three years of the international verification of neural networks competition (vnn-comp).
\newblock \emph{International Journal on Software Tools for Technology Transfer}, 25\penalty0 (3):\penalty0 329--339, 2023{\natexlab{b}}.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{carlini2017adversarial}
Carlini, N. and Wagner, D.
\newblock Adversarial examples are not easily detected: Bypassing ten detection methods.
\newblock In \emph{Proceedings of the 10th ACM workshop on artificial intelligence and security}, pp.\  3--14, 2017.

\bibitem[Carlini \& Wagner(2016)Carlini and Wagner]{carlini2016towards}
Carlini, N. and Wagner, D.~A.
\newblock Towards evaluating the robustness of neural networks.
\newblock \emph{2017 IEEE Symposium on Security and Privacy (SP)}, pp.\  39--57, 2016.

\bibitem[Carlini et~al.(2017)Carlini, Katz, Barrett, and Dill]{carlini2017provably}
Carlini, N., Katz, G., Barrett, C., and Dill, D.~L.
\newblock Provably minimally-distorted adversarial examples.
\newblock \emph{arXiv preprint arXiv:1709.10207}, 2017.

\bibitem[Carmon et~al.(2019)Carmon, Raghunathan, Schmidt, Duchi, and Liang]{carmon2019unlabeled}
Carmon, Y., Raghunathan, A., Schmidt, L., Duchi, J.~C., and Liang, P.~S.
\newblock Unlabeled data improves adversarial robustness.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Chattamvelli(2024)]{chattamvelli2024correlation}
Chattamvelli, R.
\newblock \emph{Correlation in Engineering and the Applied Sciences: Applications in R}.
\newblock Springer Nature, 2024.

\bibitem[Cheng et~al.(2017)Cheng, N{\"u}hrenberg, and Ruess]{cheng2017maximum}
Cheng, C.-H., N{\"u}hrenberg, G., and Ruess, H.
\newblock Maximum resilience of artificial neural networks.
\newblock In \emph{Automated Technology for Verification and Analysis: 15th International Symposium, ATVA 2017, Pune, India, October 3--6, 2017, Proceedings 15}, pp.\  251--268. Springer, 2017.

\bibitem[Cisse et~al.(2017)Cisse, Bojanowski, Grave, Dauphin, and Usunier]{cisse2017parseval}
Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., and Usunier, N.
\newblock Parseval networks: Improving robustness to adversarial examples.
\newblock In \emph{International conference on machine learning}, pp.\  854--863. PMLR, 2017.

\bibitem[Corbi{\`e}re et~al.(2019)Corbi{\`e}re, Thome, Bar-Hen, Cord, and P{\'e}rez]{corbiere2019addressing}
Corbi{\`e}re, C., Thome, N., Bar-Hen, A., Cord, M., and P{\'e}rez, P.
\newblock Addressing failure prediction by learning model confidence.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Croce \& Hein(2020{\natexlab{a}})Croce and Hein]{croce2020minimally}
Croce, F. and Hein, M.
\newblock Minimally distorted adversarial examples with a fast adaptive boundary attack.
\newblock In \emph{International Conference on Machine Learning}, pp.\  2196--2205. PMLR, 2020{\natexlab{a}}.

\bibitem[Croce \& Hein(2020{\natexlab{b}})Croce and Hein]{croce2020reliable}
Croce, F. and Hein, M.
\newblock Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks.
\newblock In \emph{International conference on machine learning}, pp.\  2206--2216. PMLR, 2020{\natexlab{b}}.

\bibitem[Croce et~al.(2021)Croce, Andriushchenko, Sehwag, Debenedetti, Flammarion, Chiang, Mittal, and Hein]{croce2021robustbench}
Croce, F., Andriushchenko, M., Sehwag, V., Debenedetti, E., Flammarion, N., Chiang, M., Mittal, P., and Hein, M.
\newblock Robustbench: a standardized adversarial robustness benchmark.
\newblock In \emph{Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track}, 2021.
\newblock URL \url{https://openreview.net/forum?id=SSKZPJCt7B}.

\bibitem[Cui et~al.(2023)Cui, Tian, Zhong, Qi, Yu, and Zhang]{cui2023decoupled}
Cui, J., Tian, Z., Zhong, Z., Qi, X., Yu, B., and Zhang, H.
\newblock Decoupled kullback-leibler divergence loss.
\newblock \emph{arXiv preprint arXiv:2305.13948}, 2023.

\bibitem[Debenedetti et~al.(2023)Debenedetti, Sehwag, and Mittal]{debenedetti2023light}
Debenedetti, E., Sehwag, V., and Mittal, P.
\newblock A light recipe to train robust vision transformers.
\newblock In \emph{2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)}, pp.\  225--253. IEEE, 2023.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern recognition}, pp.\  248--255. Ieee, 2009.

\bibitem[Ding et~al.(2020)Ding, Sharma, Lui, and Huang]{Ding2020MMA}
Ding, G.~W., Sharma, Y., Lui, K. Y.~C., and Huang, R.
\newblock Mma training: Direct input space margin maximization through adversarial training.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=HkeryxBtPB}.

\bibitem[Dreossi et~al.(2019)Dreossi, Ghosh, Sangiovanni-Vincentelli, and Seshia]{dreossi2019formalization}
Dreossi, T., Ghosh, S., Sangiovanni-Vincentelli, A., and Seshia, S.~A.
\newblock A formalization of robustness for deep neural networks.
\newblock \emph{arXiv preprint arXiv:1903.10033}, 2019.

\bibitem[Elsayed et~al.(2018)Elsayed, Krishnan, Mobahi, Regan, and Bengio]{elsayed2018large}
Elsayed, G., Krishnan, D., Mobahi, H., Regan, K., and Bengio, S.
\newblock Large margin deep networks for classification.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Engstrom et~al.(2019)Engstrom, Ilyas, Salman, Santurkar, and Tsipras]{robustness}
Engstrom, L., Ilyas, A., Salman, H., Santurkar, S., and Tsipras, D.
\newblock Robustness (python library), 2019.
\newblock URL \url{https://github.com/MadryLab/robustness}.

\bibitem[Evtimov et~al.(2017)Evtimov, Eykholt, Fernandes, Kohno, Li, Prakash, Rahmati, and Song]{evtimov2017robust}
Evtimov, I., Eykholt, K., Fernandes, E., Kohno, T., Li, B., Prakash, A., Rahmati, A., and Song, D.
\newblock Robust physical-world attacks on machine learning models.
\newblock \emph{arXiv preprint arXiv:1707.08945}, 2\penalty0 (3):\penalty0 4, 2017.

\bibitem[Fawzi et~al.(2018)Fawzi, Fawzi, and Fawzi]{fawzi2018adversarial}
Fawzi, A., Fawzi, H., and Fawzi, O.
\newblock Adversarial vulnerability for any classifier.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Fischetti \& Jo(2017)Fischetti and Jo]{fischetti2017deep}
Fischetti, M. and Jo, J.
\newblock Deep neural networks as 0-1 mixed integer linear programs: A feasibility study.
\newblock \emph{arXiv preprint arXiv:1712.06174}, 2017.

\bibitem[Geifman \& El-Yaniv(2017)Geifman and El-Yaniv]{geifman2017selective}
Geifman, Y. and El-Yaniv, R.
\newblock Selective classification for deep neural networks.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Gnanasambandam et~al.(2021)Gnanasambandam, Sherman, and Chan]{gnanasambandam2021optical}
Gnanasambandam, A., Sherman, A.~M., and Chan, S.~H.
\newblock Optical adversarial attack.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  92--101, 2021.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In Bengio, Y. and LeCun, Y. (eds.), \emph{3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings}, 2015.
\newblock URL \url{http://arxiv.org/abs/1412.6572}.

\bibitem[Gourdeau et~al.(2021)Gourdeau, Kanade, Kwiatkowska, and Worrell]{gourdeau2021hardness}
Gourdeau, P., Kanade, V., Kwiatkowska, M., and Worrell, J.
\newblock On the hardness of robust classification.
\newblock \emph{The Journal of Machine Learning Research}, 22\penalty0 (1):\penalty0 12521--12549, 2021.

\bibitem[Granese et~al.(2021)Granese, Romanelli, Gorla, Palamidessi, and Piantanida]{granese2021doctor}
Granese, F., Romanelli, M., Gorla, D., Palamidessi, C., and Piantanida, P.
\newblock Doctor: A simple method for detecting misclassification errors.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 5669--5681, 2021.

\bibitem[Han et~al.(2023)Han, Srinivas, and Lakkaraju]{han2023efficient}
Han, T., Srinivas, S., and Lakkaraju, H.
\newblock Efficient estimation of local robustness of machine learning models.
\newblock In \emph{ICML 3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH)}, 2023.
\newblock URL \url{https://openreview.net/forum?id=ZGSfAElJmp}.

\bibitem[He et~al.(2008)He, Wang, Zhong, and Li]{he2008survey}
He, C., Wang, C., Zhong, Y.-X., and Li, R.-F.
\newblock A survey on learning to rank.
\newblock In \emph{2008 International Conference on Machine Learning and Cybernetics}, volume~3, pp.\  1734--1739. Ieee, 2008.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  770--778, 2016.

\bibitem[Hendrycks \& Dietterich(2019)Hendrycks and Dietterich]{hendrycks2018benchmarking}
Hendrycks, D. and Dietterich, T.
\newblock Benchmarking neural network robustness to common corruptions and perturbations.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=HJz6tiCqYm}.

\bibitem[Hendrycks \& Gimpel(2017)Hendrycks and Gimpel]{hendrycks2017a}
Hendrycks, D. and Gimpel, K.
\newblock A baseline for detecting misclassified and out-of-distribution examples in neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2017.
\newblock URL \url{https://openreview.net/forum?id=Hkg4TI9xl}.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Lee, and Mazeika]{hendrycks2019using}
Hendrycks, D., Lee, K., and Mazeika, M.
\newblock Using pre-training can improve model robustness and uncertainty.
\newblock In \emph{International conference on machine learning}, pp.\  2712--2721. PMLR, 2019.

\bibitem[Huang et~al.(2017)Huang, Kwiatkowska, Wang, and Wu]{huang2017safety}
Huang, X., Kwiatkowska, M., Wang, S., and Wu, M.
\newblock Safety verification of deep neural networks.
\newblock In \emph{International conference on computer aided verification}, pp.\  3--29. Springer, 2017.

\bibitem[Jiang et~al.(2018)Jiang, Kim, Guan, and Gupta]{jiang2018trust}
Jiang, H., Kim, B., Guan, M., and Gupta, M.
\newblock To trust or not to trust a classifier.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Jordan \& Dimakis(2020)Jordan and Dimakis]{jordan2020exactly}
Jordan, M. and Dimakis, A.~G.
\newblock Exactly computing the local lipschitz constant of relu networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 7344--7353, 2020.

\bibitem[Kannan et~al.(2018)Kannan, Kurakin, and Goodfellow]{kannan2018adversarial}
Kannan, H., Kurakin, A., and Goodfellow, I.
\newblock Adversarial logit pairing.
\newblock \emph{arXiv preprint arXiv:1803.06373}, 2018.

\bibitem[Katz et~al.(2017)Katz, Barrett, Dill, Julian, and Kochenderfer]{katz2017reluplex}
Katz, G., Barrett, C., Dill, D.~L., Julian, K., and Kochenderfer, M.~J.
\newblock Reluplex: An efficient smt solver for verifying deep neural networks.
\newblock In \emph{Computer Aided Verification: 29th International Conference, CAV 2017, Heidelberg, Germany, July 24-28, 2017, Proceedings, Part I 30}, pp.\  97--117. Springer, 2017.

\bibitem[K{\"o}nig et~al.(2024)K{\"o}nig, Bosman, Hoos, and van Rijn]{konig2024critically}
K{\"o}nig, M., Bosman, A.~W., Hoos, H.~H., and van Rijn, J.~N.
\newblock Critically assessing the state of the art in neural network verification.
\newblock \emph{Journal of Machine Learning Research}, 25\penalty0 (12):\penalty0 1--53, 2024.

\bibitem[Krizhevsky(2009)]{Krizhevsky2009LearningML}
Krizhevsky, A.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical Report TR-2009, University of Toronto, 2009.

\bibitem[Li et~al.(2019)Li, Haque, Anil, Lucas, Grosse, and Jacobsen]{li2019preventing}
Li, Q., Haque, S., Anil, C., Lucas, J., Grosse, R.~B., and Jacobsen, J.-H.
\newblock Preventing gradient attenuation in lipschitz constrained convolutional networks.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Liu et~al.(2021)Liu, Han, Liu, Gong, Niu, Zhou, Sugiyama, et~al.]{liu2021probabilistic}
Liu, F., Han, B., Liu, T., Gong, C., Niu, G., Zhou, M., Sugiyama, M., et~al.
\newblock Probabilistic margins for instance reweighting in adversarial training.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 23258--23269, 2021.

\bibitem[Lomuscio \& Maganti(2017)Lomuscio and Maganti]{lomuscio2017approach}
Lomuscio, A. and Maganti, L.
\newblock An approach to reachability analysis for feed-forward relu neural networks.
\newblock \emph{arXiv preprint arXiv:1706.07351}, 2017.

\bibitem[Luo et~al.(2021)Luo, Wong, Kankanhalli, and Zhao]{luo2021learning}
Luo, Y., Wong, Y., Kankanhalli, M.~S., and Zhao, Q.
\newblock Learning to predict trustworthiness with steep slope loss.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 21533--21544, 2021.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and Vladu]{madry2018towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=rJzIBfZAb}.

\bibitem[Mickisch et~al.(2020)Mickisch, Assion, Gre{\ss}ner, G{\"u}nther, and Motta]{mickisch2020understanding}
Mickisch, D., Assion, F., Gre{\ss}ner, F., G{\"u}nther, W., and Motta, M.
\newblock Understanding the decision boundary of deep neural networks: An empirical study.
\newblock \emph{arXiv preprint arXiv:2002.01810}, 2020.

\bibitem[Moosavi-Dezfooli et~al.(2016)Moosavi-Dezfooli, Fawzi, and Frossard]{moosavi2016deepfool}
Moosavi-Dezfooli, S.-M., Fawzi, A., and Frossard, P.
\newblock Deepfool: a simple and accurate method to fool deep neural networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  2574--2582, 2016.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, Ng, et~al.]{netzer2011reading}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.~Y., et~al.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In \emph{NIPS workshop on deep learning and unsupervised feature learning}, volume 2011, pp.\ ~4. Granada, 2011.

\bibitem[Pang et~al.(2022)Pang, Lin, Yang, Zhu, and Yan]{pang2022robustness}
Pang, T., Lin, M., Yang, X., Zhu, J., and Yan, S.
\newblock Robustness and accuracy could be reconcilable by (proper) definition.
\newblock In \emph{International Conference on Machine Learning}, pp.\  17258--17277. PMLR, 2022.

\bibitem[Papyan et~al.(2020)Papyan, Han, and Donoho]{papyan2020prevalence}
Papyan, V., Han, X., and Donoho, D.~L.
\newblock Prevalence of neural collapse during the terminal phase of deep learning training.
\newblock \emph{Proceedings of the National Academy of Sciences}, 117\penalty0 (40):\penalty0 24652--24663, 2020.

\bibitem[Peng et~al.(2024)Peng, Luo, Zhang, Li, and Fang]{peng2024conjnorm}
Peng, B., Luo, Y., Zhang, Y., Li, Y., and Fang, Z.
\newblock Conjnorm: Tractable density estimation for out-of-distribution detection.
\newblock In \emph{Proceedings of the International Conference on Learning Representations}, 2024.

\bibitem[Rade \& Moosavi-Dezfooli(2021)Rade and Moosavi-Dezfooli]{rade2021helperbased}
Rade, R. and Moosavi-Dezfooli, S.-M.
\newblock Helper-based adversarial training: Reducing excessive margin to achieve a better accuracy vs. robustness trade-off.
\newblock In \emph{ICML 2021 Workshop on Adversarial Machine Learning}, 2021.
\newblock URL \url{https://openreview.net/forum?id=BuD2LmNaU3a}.

\bibitem[Rebuffi et~al.(2021)Rebuffi, Gowal, Calian, Stimberg, Wiles, and Mann]{rebuffi2021fixing}
Rebuffi, S.-A., Gowal, S., Calian, D.~A., Stimberg, F., Wiles, O., and Mann, T.
\newblock Fixing data augmentation to improve adversarial robustness.
\newblock \emph{arXiv preprint arXiv:2103.01946}, 2021.

\bibitem[Rice et~al.(2020)Rice, Wong, and Kolter]{rice2020overfitting}
Rice, L., Wong, E., and Kolter, Z.
\newblock Overfitting in adversarially robust deep learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\  8093--8104. PMLR, 2020.

\bibitem[Salman et~al.(2019)Salman, Yang, Zhang, Hsieh, and Zhang]{salman2019convex}
Salman, H., Yang, G., Zhang, H., Hsieh, C.-J., and Zhang, P.
\newblock A convex relaxation barrier to tight robustness verification of neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 32:\penalty0 9835--9846, 2019.

\bibitem[Sehwag et~al.(2021)Sehwag, Mahloujifar, Handina, Dai, Xiang, Chiang, and Mittal]{sehwag2021robust}
Sehwag, V., Mahloujifar, S., Handina, T., Dai, S., Xiang, C., Chiang, M., and Mittal, P.
\newblock Robust learning meets generative models: Can proxy distributions improve adversarial robustness?
\newblock \emph{arXiv preprint arXiv:2104.09425}, 2021.

\bibitem[Serrurier et~al.(2021)Serrurier, Mamalet, Gonz{\'a}lez-Sanz, Boissin, Loubes, and Del~Barrio]{serrurier2021achieving}
Serrurier, M., Mamalet, F., Gonz{\'a}lez-Sanz, A., Boissin, T., Loubes, J.-M., and Del~Barrio, E.
\newblock Achieving robustness in classification using optimal transport with hinge regularization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  505--514, 2021.

\bibitem[Seshia et~al.(2018)Seshia, Desai, Dreossi, Fremont, Ghosh, Kim, Shivakumar, Vazquez-Chanlatte, and Yue]{seshia2018formal}
Seshia, S.~A., Desai, A., Dreossi, T., Fremont, D.~J., Ghosh, S., Kim, E., Shivakumar, S., Vazquez-Chanlatte, M., and Yue, X.
\newblock Formal specification for deep neural networks.
\newblock In \emph{International Symposium on Automated Technology for Verification and Analysis}, pp.\  20--34. Springer, 2018.

\bibitem[Shi et~al.(2023)Shi, Jin, Kolter, Jana, Hsieh, and Zhang]{shi2023generalnonlinear}
Shi, Z., Jin, Q., Kolter, J.~Z., Jana, S., Hsieh, C.-J., and Zhang, H.
\newblock Formal verification for neural networks with general nonlinearities via branch-and-bound.
\newblock \emph{2nd Workshop on Formal Verification of Machine Learning (WFVML 2023)}, 2023.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan, Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.~J., and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In Bengio, Y. and LeCun, Y. (eds.), \emph{2nd International Conference on Learning Representations, {ICLR} 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings}, 2014.
\newblock URL \url{http://arxiv.org/abs/1312.6199}.

\bibitem[Tjeng et~al.(2019)Tjeng, Xiao, and Tedrake]{tjeng2017evaluating}
Tjeng, V., Xiao, K.~Y., and Tedrake, R.
\newblock Evaluating robustness of neural networks with mixed integer programming.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=HyGIdiRqtm}.

\bibitem[Tramer(2022)]{tramer2022detecting}
Tramer, F.
\newblock Detecting adversarial examples is (nearly) as hard as classifying them.
\newblock In \emph{International Conference on Machine Learning}, pp.\  21692--21702. PMLR, 2022.

\bibitem[Virmaux \& Scaman(2018)Virmaux and Scaman]{virmaux2018lipschitz}
Virmaux, A. and Scaman, K.
\newblock Lipschitz regularity of deep neural networks: analysis and efficient estimation.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Wang et~al.(2020)Wang, Zou, Yi, Bailey, Ma, and Gu]{Wang2020Improving}
Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., and Gu, Q.
\newblock Improving adversarial robustness requires revisiting misclassified examples.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=rklOg6EFwS}.

\bibitem[Wang et~al.(2023)Wang, Pang, Du, Lin, Liu, and Yan]{wang2023better}
Wang, Z., Pang, T., Du, C., Lin, M., Liu, W., and Yan, S.
\newblock Better diffusion models further improve adversarial training.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2023.

\bibitem[Weng(2019)]{provenpresentation}
Weng, T.-W.
\newblock Proven: Verifying robustness of neural networks with a probabilistic approach - powerpoint presentation.
\newblock \url{https://icml.cc/media/Slides/icml/2019/grandball(11-11-00)-11-12-15-4739-proven_verifyi.pdf}, 2019.
\newblock (Accessed on 05/23/2023).

\bibitem[Weng et~al.(2018)Weng, Zhang, Chen, Yi, Su, Gao, Hsieh, and Daniel]{weng2018evaluating}
Weng, T.-W., Zhang, H., Chen, P.-Y., Yi, J., Su, D., Gao, Y., Hsieh, C.-J., and Daniel, L.
\newblock Evaluating the robustness of neural networks: An extreme value theory approach.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=BkUHlMZ0b}.

\bibitem[Wu et~al.(2020)Wu, Xia, and Wang]{wu2020adversarial}
Wu, D., Xia, S.-T., and Wang, Y.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 2958--2969, 2020.

\bibitem[Xu et~al.(2020)Xu, Shi, Zhang, Wang, Chang, Huang, Kailkhura, Lin, and Hsieh]{xu2020automatic}
Xu, K., Shi, Z., Zhang, H., Wang, Y., Chang, K.-W., Huang, M., Kailkhura, B., Lin, X., and Hsieh, C.-J.
\newblock Automatic perturbation analysis for scalable certified robustness and beyond.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Xu et~al.(2021)Xu, Zhang, Wang, Wang, Jana, Lin, and Hsieh]{xu2021fast}
Xu, K., Zhang, H., Wang, S., Wang, Y., Jana, S., Lin, X., and Hsieh, C.-J.
\newblock {Fast and Complete}: Enabling complete neural network verification with rapid and massively parallel incomplete verifiers.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=nVZtXBI6LNn}.

\bibitem[Xu et~al.(2017)Xu, Evans, and Qi]{xu2017feature}
Xu, W., Evans, D., and Qi, Y.
\newblock Feature squeezing: Detecting adversarial examples in deep neural networks.
\newblock \emph{arXiv preprint arXiv:1704.01155}, 2017.

\bibitem[Xu et~al.(2023)Xu, Sun, Goldblum, Goldstein, and Huang]{xu2023exploring}
Xu, Y., Sun, Y., Goldblum, M., Goldstein, T., and Huang, F.
\newblock Exploring and exploiting decision boundary dynamics for adversarial robustness.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=aRTKuscKByJ}.

\bibitem[Yang et~al.(2021)Yang, Zhou, Li, and Liu]{yang2021generalized}
Yang, J., Zhou, K., Li, Y., and Liu, Z.
\newblock Generalized out-of-distribution detection: A survey. arxiv.
\newblock \emph{arXiv preprint arXiv:2110.11334}, 2021.

\bibitem[Zhang et~al.(2018)Zhang, Weng, Chen, Hsieh, and Daniel]{zhang2018efficient}
Zhang, H., Weng, T.-W., Chen, P.-Y., Hsieh, C.-J., and Daniel, L.
\newblock Efficient neural network robustness certification with general activation functions.
\newblock \emph{Advances in Neural Information Processing Systems}, 31:\penalty0 4939--4948, 2018.
\newblock URL \url{https://arxiv.org/pdf/1811.00866.pdf}.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, El~Ghaoui, and Jordan]{zhang2019theoretically}
Zhang, H., Yu, Y., Jiao, J., Xing, E., El~Ghaoui, L., and Jordan, M.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{International conference on machine learning}, pp.\  7472--7482. PMLR, 2019.

\bibitem[Zhang et~al.(2022)Zhang, Wang, Xu, Wang, Jana, Hsieh, and Kolter]{zhang22babattack}
Zhang, H., Wang, S., Xu, K., Wang, Y., Jana, S., Hsieh, C.-J., and Kolter, Z.
\newblock A branch and bound framework for stronger adversarial attacks of {R}e{LU} networks.
\newblock In \emph{Proceedings of the 39th International Conference on Machine Learning}, volume 162, pp.\  26591--26604, 2022.

\bibitem[Zhang et~al.(2020)Zhang, Zhu, Niu, Han, Sugiyama, and Kankanhalli]{zhang2020geometry}
Zhang, J., Zhu, J., Niu, G., Han, B., Sugiyama, M., and Kankanhalli, M.
\newblock Geometry-aware instance-reweighted adversarial training.
\newblock \emph{arXiv preprint arXiv:2010.01736}, 2020.

\bibitem[Zhong et~al.(2021)Zhong, Tian, and Ray]{zhong2021understanding}
Zhong, Z., Tian, Y., and Ray, B.
\newblock Understanding local robustness of deep neural networks under natural variations.
\newblock In \emph{International Conference on Fundamental Approaches to Software Engineering}, pp.\  313--337. Springer, Cham, 2021.

\bibitem[Zhu et~al.(2023)Zhu, Cheng, Zhang, and Liu]{zhu2023openmix}
Zhu, F., Cheng, Z., Zhang, X.-Y., and Liu, C.-L.
\newblock Openmix: Exploring outlier samples for misclassification detection.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  12074--12083, 2023.

\end{thebibliography}
