\begin{thebibliography}{10}

\bibitem{hornik1989multilayer}
Kurt Hornik, Maxwell Stinchcombe, and Halbert White.
\newblock Multilayer feedforward networks are universal approximators.
\newblock {\em Neural networks}, 2(5):359--366, 1989.

\bibitem{sullivan2012overview}
Gary~J Sullivan, Jens-Rainer Ohm, Woo-Jin Han, and Thomas Wiegand.
\newblock Overview of the high efficiency video coding (hevc) standard.
\newblock {\em IEEE Transactions on circuits and systems for video technology},
  22(12):1649--1668, 2012.

\bibitem{lu2019dvc}
Guo Lu, Wanli Ouyang, Dong Xu, Xiaoyun Zhang, Chunlei Cai, and Zhiyong Gao.
\newblock Dvc: An end-to-end deep video compression framework.
\newblock In {\em CVPR}, 2019.

\bibitem{mildenhall2020nerf}
Ben Mildenhall, Pratul~P Srinivasan, Matthew Tancik, Jonathan~T Barron, Ravi
  Ramamoorthi, and Ren Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view
  synthesis.
\newblock In {\em European Conference on Computer Vision}, pages 405--421.
  Springer, 2020.

\bibitem{sitzmann2020implicit}
Vincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, and Gordon
  Wetzstein.
\newblock Implicit neural representations with periodic activation functions.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{tancik2020fourier}
Matthew Tancik, Pratul~P Srinivasan, Ben Mildenhall, Sara Fridovich-Keil,
  Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan~T Barron, and
  Ren Ng.
\newblock Fourier features let networks learn high frequency functions in low
  dimensional domains.
\newblock {\em NeurIPS}, 2020.

\bibitem{mercat2020uvg}
Alexandre Mercat, Marko Viitanen, and Jarno Vanne.
\newblock Uvg dataset: 50/120fps 4k sequences for video codec analysis and
  development.
\newblock In {\em Proceedings of the 11th ACM Multimedia Systems Conference},
  pages 297--302, 2020.

\bibitem{wiegand2003overview}
Thomas Wiegand, Gary~J Sullivan, Gisle Bjontegaard, and Ajay Luthra.
\newblock Overview of the h. 264/avc video coding standard.
\newblock {\em IEEE Transactions on circuits and systems for video technology},
  13(7):560--576, 2003.

\bibitem{genova2019learning}
Kyle Genova, Forrester Cole, Daniel Vlasic, Aaron Sarna, William~T Freeman, and
  Thomas Funkhouser.
\newblock Learning shape templates with structured implicit functions.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 7154--7164, 2019.

\bibitem{genova2019deep}
Kyle Genova, Forrester Cole, Avneesh Sud, Aaron Sarna, and Thomas~A Funkhouser.
\newblock Deep structured implicit functions.
\newblock 2019.

\bibitem{sitzmann2019scene}
Vincent Sitzmann, Michael Zollh{\"o}fer, and Gordon Wetzstein.
\newblock Scene representation networks: Continuous 3d-structure-aware neural
  scene representations.
\newblock {\em arXiv preprint arXiv:1906.01618}, 2019.

\bibitem{jiang2020local}
Chiyu Jiang, Avneesh Sud, Ameesh Makadia, Jingwei Huang, Matthias Nie{\ss}ner,
  Thomas Funkhouser, et~al.
\newblock Local implicit grid representations for 3d scenes.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 6001--6010, 2020.

\bibitem{peng2020convolutional}
Songyou Peng, Michael Niemeyer, Lars Mescheder, Marc Pollefeys, and Andreas
  Geiger.
\newblock Convolutional occupancy networks.
\newblock {\em arXiv preprint arXiv:2003.04618}, 2, 2020.

\bibitem{chabra2020deep}
Rohan Chabra, Jan~E Lenssen, Eddy Ilg, Tanner Schmidt, Julian Straub, Steven
  Lovegrove, and Richard Newcombe.
\newblock Deep local shapes: Learning local sdf priors for detailed 3d
  reconstruction.
\newblock In {\em European Conference on Computer Vision}, pages 608--625.
  Springer, 2020.

\bibitem{niemeyer2020differentiable}
Michael Niemeyer, Lars Mescheder, Michael Oechsle, and Andreas Geiger.
\newblock Differentiable volumetric rendering: Learning implicit 3d
  representations without 3d supervision.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 3504--3515, 2020.

\bibitem{oechsle2019texture}
Michael Oechsle, Lars Mescheder, Michael Niemeyer, Thilo Strauss, and Andreas
  Geiger.
\newblock Texture fields: Learning texture representations in function space.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 4531--4540, 2019.

\bibitem{dupont2021coin}
Emilien Dupont, Adam Goli{\'n}ski, Milad Alizadeh, Yee~Whye Teh, and Arnaud
  Doucet.
\newblock Coin: Compression with implicit neural representations.
\newblock {\em arXiv preprint arXiv:2103.03123}, 2021.

\bibitem{wallace1992jpeg}
Gregory~K Wallace.
\newblock The jpeg still picture compression standard.
\newblock {\em IEEE transactions on consumer electronics}, 38(1):xviii--xxxiv,
  1992.

\bibitem{skodras2001jpeg}
Athanassios Skodras, Charilaos Christopoulos, and Touradj Ebrahimi.
\newblock The jpeg 2000 still image compression standard.
\newblock {\em IEEE Signal processing magazine}, 18(5):36--58, 2001.

\bibitem{le1991mpeg}
Didier Le~Gall.
\newblock Mpeg: A video compression standard for multimedia applications.
\newblock {\em Communications of the ACM}, 34(4):46--58, 1991.

\bibitem{ahmed1974discrete}
Nasir Ahmed, T\_ Natarajan, and Kamisetty~R Rao.
\newblock Discrete cosine transform.
\newblock {\em IEEE transactions on Computers}, 100(1):90--93, 1974.

\bibitem{antonini1992image}
Marc Antonini, Michel Barlaud, Pierre Mathieu, and Ingrid Daubechies.
\newblock Image coding using wavelet transform.
\newblock {\em IEEE Transactions on image processing}, 1(2):205--220, 1992.

\bibitem{cheng2019learning}
Zhengxue Cheng, Heming Sun, Masaru Takeuchi, and Jiro Katto.
\newblock Learning image and video compression through spatial-temporal energy
  compaction.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10071--10080, 2019.

\bibitem{wu2018video}
Chao-Yuan Wu, Nayan Singhal, and Philipp Krahenbuhl.
\newblock Video compression through image interpolation.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 416--431, 2018.

\bibitem{agustsson2020scale}
Eirikur Agustsson, David Minnen, Nick Johnston, Johannes Balle, Sung~Jin Hwang,
  and George Toderici.
\newblock Scale-space flow for end-to-end optimized video compression.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 8503--8512, 2020.

\bibitem{yang2020learning}
Ren Yang, Fabian Mentzer, Luc~Van Gool, and Radu Timofte.
\newblock Learning for video compression with hierarchical quality and
  recurrent enhancement.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 6628--6637, 2020.

\bibitem{vanhoucke2011improving}
Vincent Vanhoucke, Andrew Senior, and Mark~Z Mao.
\newblock Improving the speed of neural networks on cpus.
\newblock 2011.

\bibitem{gupta2015deep}
Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, and Pritish Narayanan.
\newblock Deep learning with limited numerical precision.
\newblock In {\em International conference on machine learning}, pages
  1737--1746. PMLR, 2015.

\bibitem{han2015deep}
Song Han, Huizi Mao, and William~J Dally.
\newblock Deep compression: Compressing deep neural networks with pruning,
  trained quantization and huffman coding.
\newblock {\em arXiv preprint arXiv:1510.00149}, 2015.

\bibitem{wen2016learning}
Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li.
\newblock Learning structured sparsity in deep neural networks.
\newblock {\em arXiv preprint arXiv:1608.03665}, 2016.

\bibitem{jacob2018quantization}
Benoit Jacob, Skirmantas Kligys, Bo~Chen, Menglong Zhu, Matthew Tang, Andrew
  Howard, Hartwig Adam, and Dmitry Kalenichenko.
\newblock Quantization and training of neural networks for efficient
  integer-arithmetic-only inference.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2704--2713, 2018.

\bibitem{krishnamoorthi2018quantizing}
Raghuraman Krishnamoorthi.
\newblock Quantizing deep convolutional networks for efficient inference: A
  whitepaper.
\newblock {\em arXiv preprint arXiv:1806.08342}, 2018.

\bibitem{rigamonti2013learning}
Roberto Rigamonti, Amos Sironi, Vincent Lepetit, and Pascal Fua.
\newblock Learning separable filters.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2754--2761, 2013.

\bibitem{denton2014exploiting}
Emily Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus.
\newblock Exploiting linear structure within convolutional networks for
  efficient evaluation.
\newblock {\em arXiv preprint arXiv:1404.0736}, 2014.

\bibitem{jaderberg2014speeding}
Max Jaderberg, Andrea Vedaldi, and Andrew Zisserman.
\newblock Speeding up convolutional neural networks with low rank expansions.
\newblock {\em arXiv preprint arXiv:1405.3866}, 2014.

\bibitem{cohen2016group}
Taco Cohen and Max Welling.
\newblock Group equivariant convolutional networks.
\newblock In {\em International conference on machine learning}, pages
  2990--2999. PMLR, 2016.

\bibitem{zhai2016doubly}
Shuangfei Zhai, Yu~Cheng, Weining Lu, and Zhongfei Zhang.
\newblock Doubly convolutional neural networks.
\newblock {\em arXiv preprint arXiv:1610.09716}, 2016.

\bibitem{shang2016understanding}
Wenling Shang, Kihyuk Sohn, Diogo Almeida, and Honglak Lee.
\newblock Understanding and improving convolutional neural networks via
  concatenated rectified linear units.
\newblock In {\em international conference on machine learning}, pages
  2217--2225. PMLR, 2016.

\bibitem{dieleman2016exploiting}
Sander Dieleman, Jeffrey De~Fauw, and Koray Kavukcuoglu.
\newblock Exploiting cyclic symmetry in convolutional neural networks.
\newblock In {\em International conference on machine learning}, pages
  1889--1898. PMLR, 2016.

\bibitem{ba2013deep}
Lei~Jimmy Ba and Rich Caruana.
\newblock Do deep nets really need to be deep?
\newblock {\em arXiv preprint arXiv:1312.6184}, 2013.

\bibitem{hinton2015distilling}
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
\newblock Distilling the knowledge in a neural network.
\newblock {\em arXiv preprint arXiv:1503.02531}, 2015.

\bibitem{chen2017learning}
Guobin Chen, Wongun Choi, Xiang Yu, Tony Han, and Manmohan Chandraker.
\newblock Learning efficient object detection models with knowledge
  distillation.
\newblock In {\em Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pages 742--751, 2017.

\bibitem{polino2018model}
Antonio Polino, Razvan Pascanu, and Dan Alistarh.
\newblock Model compression via distillation and quantization.
\newblock {\em arXiv preprint arXiv:1802.05668}, 2018.

\bibitem{rahaman2019spectral}
Nasim Rahaman, Aristide Baratin, Devansh Arpit, Felix Draxler, Min Lin, Fred
  Hamprecht, Yoshua Bengio, and Aaron Courville.
\newblock On the spectral bias of neural networks.
\newblock In {\em International Conference on Machine Learning}, pages
  5301--5310. PMLR, 2019.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em arXiv preprint arXiv:1706.03762}, 2017.

\bibitem{shi2016real}
Wenzhe Shi, Jose Caballero, Ferenc Husz{\'a}r, Johannes Totz, Andrew~P Aitken,
  Rob Bishop, Daniel Rueckert, and Zehan Wang.
\newblock Real-time single image and video super-resolution using an efficient
  sub-pixel convolutional neural network.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1874--1883, 2016.

\bibitem{banner2018scalable}
Ron Banner, Itay Hubara, Elad Hoffer, and Daniel Soudry.
\newblock Scalable methods for 8-bit training of neural networks.
\newblock {\em arXiv preprint arXiv:1805.11046}, 2018.

\bibitem{faghri2020adaptive}
Fartash Faghri, Iman Tabrizian, Ilia Markov, Dan Alistarh, Daniel Roy, and Ali
  Ramezani-Kebrya.
\newblock Adaptive gradient quantization for data-parallel sgd.
\newblock {\em arXiv preprint arXiv:2010.12460}, 2020.

\bibitem{wang2018training}
Naigang Wang, Jungwook Choi, Daniel Brand, Chia-Yu Chen, and Kailash
  Gopalakrishnan.
\newblock Training deep neural networks with 8-bit floating point numbers.
\newblock {\em arXiv preprint arXiv:1812.08011}, 2018.

\bibitem{huffman1952method}
David~A Huffman.
\newblock A method for the construction of minimum-redundancy codes.
\newblock {\em Proceedings of the IRE}, 40(9):1098--1101, 1952.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{loshchilov2016sgdr}
Ilya Loshchilov and Frank Hutter.
\newblock Sgdr: Stochastic gradient descent with warm restarts.
\newblock {\em arXiv preprint arXiv:1608.03983}, 2016.

\bibitem{wang2003multiscale}
Zhou Wang, Eero~P Simoncelli, and Alan~C Bovik.
\newblock Multiscale structural similarity for image quality assessment.
\newblock In {\em The Thrity-Seventh Asilomar Conference on Signals, Systems
  Computers, 2003}, volume~2, pages 1398--1402. Ieee, 2003.

\bibitem{NEURIPS2019_9015}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, {\em Advances in Neural
  Information Processing Systems 32}, pages 8024--8035. Curran Associates,
  Inc., 2019.

\bibitem{wang2016mcl}
Haiqiang Wang, Weihao Gan, Sudeng Hu, Joe~Yuchieh Lin, Lina Jin, Longguang
  Song, Ping Wang, Ioannis Katsavounidis, Anne Aaron, and C-C~Jay Kuo.
\newblock Mcl-jcv: a jnd-based h. 264/avc video quality assessment dataset.
\newblock In {\em 2016 IEEE International Conference on Image Processing
  (ICIP)}, pages 1509--1513. IEEE, 2016.

\bibitem{yang2020hierarchical}
Ruihan Yang, Yibo Yang, Joseph Marino, and Stephan Mandt.
\newblock Hierarchical autoregressive modeling for neural video compression.
\newblock {\em arXiv preprint arXiv:2010.10258}, 2020.

\bibitem{rippel2019learned}
Oren Rippel, Sanjay Nair, Carissa Lew, Steve Branson, Alexander~G Anderson, and
  Lubomir Bourdev.
\newblock Learned video compression.
\newblock In {\em ICCV}, 2019.

\bibitem{liu2020conditional}
Jerry Liu, Shenlong Wang, Wei-Chiu Ma, Meet Shah, Rui Hu, Pranaab Dhawan, and
  Raquel Urtasun.
\newblock Conditional entropy coding for efficient video compression.
\newblock In {\em ECCV}, 2020.

\bibitem{ulyanov2018deep}
Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky.
\newblock Deep image prior.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 9446--9454, 2018.

\bibitem{dumoulin2016guide}
Vincent Dumoulin and Francesco Visin.
\newblock A guide to convolution arithmetic for deep learning.
\newblock {\em arXiv preprint arXiv:1603.07285}, 2016.

\bibitem{hendrycks2016gaussian}
Dan Hendrycks and Kevin Gimpel.
\newblock Gaussian error linear units (gelus).
\newblock {\em arXiv preprint arXiv:1606.08415}, 2016.

\bibitem{tomar2006converting}
Suramya Tomar.
\newblock Converting video formats with ffmpeg.
\newblock {\em Linux Journal}, 2006(146):10, 2006.

\end{thebibliography}
