\begin{thebibliography}{10}

\bibitem{Bo2020AlternatingPS}
Radu~Ioan Boț and Axel B{\"o}hm.
\newblock Alternating proximal-gradient steps for (stochastic) nonconvex-concave minimax problems.
\newblock {\em SIAM J. Optim.}, 33:1884--1913, 2020.

\bibitem{celona2018fine}
Luigi Celona, Simone Bianco, and Raimondo Schettini.
\newblock Fine-grained face annotation using deep multi-task cnn.
\newblock {\em Sensors}, 18(8):2666, 2018.

\bibitem{davis2018stochastic}
Damek Davis and Dmitriy Drusvyatskiy.
\newblock Stochastic model-based minimization of weakly convex functions, 2018.

\bibitem{doi:10.1137/17M1151031}
Damek Davis and Benjamin Grimmer.
\newblock Proximally guided stochastic subgradient method for nonsmooth, nonconvex problems.
\newblock {\em SIAM Journal on Optimization}, 29(3):1908--1930, 2019.

\bibitem{deng2012mnist}
Li~Deng.
\newblock The mnist database of handwritten digit images for machine learning research.
\newblock {\em IEEE Signal Processing Magazine}, 29(6):141--142, 2012.

\bibitem{goodfellow2013challenges}
Ian~J. Goodfellow, Dumitru Erhan, Pierre~Luc Carrier, Aaron Courville, Mehdi Mirza, Ben Hamner, Will Cukierski, Yichuan Tang, David Thaler, Dong-Hyun Lee, Yingbo Zhou, Chetan Ramaiah, Fangxiang Feng, Ruifan Li, Xiaojie Wang, Dimitris Athanasakis, John Shawe-Taylor, Maxim Milakov, John Park, Radu Ionescu, Marius Popescu, Cristian Grozea, James Bergstra, Jingjing Xie, Lukasz Romaszko, Bing Xu, Zhang Chuang, and Yoshua Bengio.
\newblock Challenges in representation learning: A report on three machine learning contests, 2013.

\bibitem{guo2022novel}
Zhishuai Guo, Yi~Xu, Wotao Yin, Rong Jin, and Tianbao Yang.
\newblock A novel convergence analysis for algorithms of the adam family and beyond, 2022.

\bibitem{Grbzbalaban2022ASS}
Mert G{\"u}rb{\"u}zbalaban, A.~Ruszczynski, and Landi Zhu.
\newblock A stochastic subgradient method for distributionally robust non-convex and non-smooth learning.
\newblock {\em Journal of Optimization Theory and Applications}, 194:1014 -- 1041, 2022.

\bibitem{NEURIPS2022_be76ca29}
Quanqi Hu, Yongjian Zhong, and Tianbao Yang.
\newblock Multi-block min-max bilevel optimization with applications in multi-task deep auc maximization.
\newblock In S.~Koyejo, S.~Mohamed, A.~Agarwal, D.~Belgrave, K.~Cho, and A.~Oh, editors, {\em Advances in Neural Information Processing Systems}, volume~35, pages 29552--29565. Curran Associates, Inc., 2022.

\bibitem{Hu2023NonSmoothWF}
Quanqi Hu, Dixian Zhu, and Tianbao Yang.
\newblock Non-smooth weakly-convex finite-sum coupled compositional optimization.
\newblock {\em ArXiv}, abs/2310.03234, 2023.

\bibitem{Huang2020AcceleratedZM}
Feihu Huang, Shangqian Gao, Jian Pei, and Heng Huang.
\newblock Accelerated zeroth-order momentum methods from mini to minimax optimization.
\newblock {\em ArXiv}, abs/2008.08170, 2020.

\bibitem{pmlr-v119-jin20e}
Chi Jin, Praneeth Netrapalli, and Michael Jordan.
\newblock What is local optimality in nonconvex-nonconcave minimax optimization?
\newblock In Hal~Daumé III and Aarti Singh, editors, {\em Proceedings of the 37th International Conference on Machine Learning}, volume 119 of {\em Proceedings of Machine Learning Research}, pages 4880--4889. PMLR, 13--18 Jul 2020.

\bibitem{Kiryo2017PositiveUnlabeledLW}
Ryuichi Kiryo, Gang Niu, Marthinus~Christoffel du~Plessis, and Masashi Sugiyama.
\newblock Positive-unlabeled learning with non-negative risk estimator.
\newblock {\em ArXiv}, abs/1703.00593, 2017.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock {\em Citeseer}, 2009.

\bibitem{doi:10.1137/20M1385706}
Hoai~An Le~Thi, Van~Ngai Huynh, Tao~Pham Dinh, and Hoang~Phuc Hau~Luu.
\newblock Stochastic difference-of-convex-functions algorithms for nonconvex programming.
\newblock {\em SIAM Journal on Optimization}, 32(3):2263--2293, 2022.

\bibitem{LETHI2020220}
Hoai~An {Le Thi}, Hoai~Minh Le, Duy~Nhat Phan, and Bach Tran.
\newblock Stochastic dca for minimizing a large sum of dc functions with application to multi-class logistic regression.
\newblock {\em Neural Networks}, 132:220--231, 2020.

\bibitem{9933731}
Hoai~An Le~Thi, Hoang Phuc~Hau Luu, and Tao~Pham Dinh.
\newblock Online stochastic dca with applications to principal component analysis.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems}, 35(5):7035--7047, 2024.

\bibitem{dcdevelopments}
Hoai~An Le~Thi and Tao Pham~Dinh.
\newblock Dc programming and dca: thirty years of developments.
\newblock {\em Mathematical Programming}, 169, 01 2018.

\bibitem{pmlr-v119-lin20a}
Tianyi Lin, Chi Jin, and Michael Jordan.
\newblock On gradient descent ascent for nonconvex-concave minimax problems.
\newblock In Hal~Daumé III and Aarti Singh, editors, {\em Proceedings of the 37th International Conference on Machine Learning}, volume 119 of {\em Proceedings of Machine Learning Research}, pages 6083--6093. PMLR, 13--18 Jul 2020.

\bibitem{liu2019stochastic}
Mingrui Liu, Zhuoning Yuan, Yiming Ying, and Tianbao Yang.
\newblock Stochastic auc maximization with deep neural networks.
\newblock {\em arXiv preprint arXiv:1908.10831}, 2019.

\bibitem{NEURIPS2020_ecb47fbb}
Luo Luo, Haishan Ye, Zhichao Huang, and Tong Zhang.
\newblock Stochastic recursive gradient descent ascent for stochastic nonconvex-strongly-concave minimax problems.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin, editors, {\em Advances in Neural Information Processing Systems}, volume~33, pages 20566--20577. Curran Associates, Inc., 2020.

\bibitem{madry2019deeplearningmodelsresistant}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks, 2019.

\bibitem{MancinoBall2023VariancereducedAM}
Gabriel Mancino-Ball and Yangyang Xu.
\newblock Variance-reduced accelerated methods for decentralized stochastic double-regularized nonconvex strongly-concave minimax problems.
\newblock {\em ArXiv}, abs/2307.07113, 2023.

\bibitem{Moreau1965}
J.J. Moreau.
\newblock Proximité et dualité dans un espace hilbertien.
\newblock {\em Bulletin de la Société Mathématique de France}, 93:273--299, 1965.

\bibitem{moudafi:hal-03581239}
Abdellatif Moudafi.
\newblock {A Regularization of DC Optimization.}
\newblock {\em {Pure and Applied Functional Analysis}}, 2022.

\bibitem{pmlr-v54-nitanda17a}
Atsushi Nitanda and Taiji Suzuki.
\newblock {Stochastic Difference of Convex Algorithm and its Application to Training Deep Boltzmann Machines}.
\newblock In Aarti Singh and Jerry Zhu, editors, {\em Proceedings of the 20th International Conference on Artificial Intelligence and Statistics}, volume~54 of {\em Proceedings of Machine Learning Research}, pages 470--478. PMLR, 20--22 Apr 2017.

\bibitem{park2022fair}
Sungho Park, Jewook Lee, Pilhyeon Lee, Sunhee Hwang, Dohyung Kim, and Hyeran Byun.
\newblock Fair contrastive learning for facial attribute classification.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 10389--10398, 2022.

\bibitem{rafique2018non}
Hassan Rafique, Mingrui Liu, Qihang Lin, and Tianbao Yang.
\newblock Non-convex min-max optimization: Provable algorithms and applications in machine learning.
\newblock {\em arXiv preprint arXiv:1810.02060}, 2018.

\bibitem{doi:10.1080/10556788.2021.1895152}
Hassan Rafique, Mingrui Liu, Qihang Lin, and Tianbao Yang.
\newblock Weakly-convex–concave min–max optimization: provable algorithms and applications in machine learning.
\newblock {\em Optimization Methods and Software}, 37(3):1087--1121, 2022.

\bibitem{rockafellar2009variational}
R.T. Rockafellar, M.~Wets, and R.J.B. Wets.
\newblock {\em Variational Analysis}.
\newblock Grundlehren der mathematischen Wissenschaften. Springer Berlin Heidelberg, 2009.

\bibitem{sinha2020certifyingdistributionalrobustnessprincipled}
Aman Sinha, Hongseok Namkoong, Riccardo Volpi, and John Duchi.
\newblock Certifying some distributional robustness with principled adversarial training, 2020.

\bibitem{Sun2022AlgorithmsFD}
Kaizhao Sun and Xu~Andy Sun.
\newblock Algorithms for difference-of-convex programs based on difference-of-moreau-envelopes smoothing.
\newblock {\em INFORMS J. Optim.}, 5:321--339, 2022.

\bibitem{Tao1986AlgorithmsFS}
Pham~Dinh Tao and El~Bernoussi Souad.
\newblock Algorithms for solving a class of nonconvex optimization problems. methods of subgradients.
\newblock {\em North-holland Mathematics Studies}, 129:249--271, 1986.

\bibitem{pmlr-v70-thi17a}
Hoai An~Le Thi, Hoai~Minh Le, Duy~Nhat Phan, and Bach Tran.
\newblock Stochastic {DCA} for the large-sum of non-convex functions problem and its application to group variable selection in classification.
\newblock In Doina Precup and Yee~Whye Teh, editors, {\em Proceedings of the 34th International Conference on Machine Learning}, volume~70 of {\em Proceedings of Machine Learning Research}, pages 3394--3403. PMLR, 06--11 Aug 2017.

\bibitem{10.1093/bioinformatics/btac112}
Zhengyang Wang, Meng Liu, Youzhi Luo, Zhao Xu, Yaochen Xie, Limei Wang, Lei Cai, Qi~Qi, Zhuoning Yuan, Tianbao Yang, and Shuiwang Ji.
\newblock {Advanced graph and sequence neural networks for molecular property prediction and drug discovery}.
\newblock {\em Bioinformatics}, 38(9):2579--2586, 02 2022.

\bibitem{Xiao2017FashionMNISTAN}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.
\newblock {\em ArXiv}, abs/1708.07747, 2017.

\bibitem{Xie2017ControllableIT}
Qizhe Xie, Zihang Dai, Yulun Du, Eduard~H. Hovy, and Graham Neubig.
\newblock Controllable invariance through adversarial feature learning.
\newblock In {\em Neural Information Processing Systems}, 2017.

\bibitem{Xu2020EnhancedFA}
Tengyu Xu, Zhe Wang, Yingbin Liang, and H.~Vincent Poor.
\newblock Enhanced first and zeroth order variance reduced algorithms for min-max optimization.
\newblock {\em ArXiv}, abs/2006.09361, 2020.

\bibitem{DBLP:conf/icml/XuQLJY19}
Yi~Xu, Qi~Qi, Qihang Lin, Rong Jin, and Tianbao Yang.
\newblock Stochastic optimization for {DC} functions and non-smooth non-convex regularizers with non-asymptotic convergence.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, {\em Proceedings of the 36th International Conference on Machine Learning, {ICML} 2019, 9-15 June 2019, Long Beach, California, {USA}}, volume~97 of {\em Proceedings of Machine Learning Research}, pages 6942--6951. {PMLR}, 2019.

\bibitem{NEURIPS2020_3f8b2a81}
Yan Yan, Yi~Xu, Qihang Lin, Wei Liu, and Tianbao Yang.
\newblock Optimal epoch stochastic gradient descent ascent methods for min-max optimization.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin, editors, {\em Advances in Neural Information Processing Systems}, volume~33, pages 5789--5800. Curran Associates, Inc., 2020.

\bibitem{yan2020sharp}
Yan Yan, Yi~Xu, Qihang Lin, Wei Liu, and Tianbao Yang.
\newblock Sharp analysis of epoch stochastic gradient descent ascent methods for min-max optimization.
\newblock {\em arXiv preprint arXiv:2002.05309}, 2020.

\bibitem{Yang2022NestYA}
Junchi Yang, Xiang Li, and Niao He.
\newblock Nest your adaptive algorithm for parameter-agnostic nonconvex minimax optimization.
\newblock {\em ArXiv}, abs/2206.00743, 2022.

\bibitem{pmlr-v151-yang22b}
Junchi Yang, Antonio Orvieto, Aurelien Lucchi, and Niao He.
\newblock Faster single-loop algorithms for minimax optimization without strong concavity.
\newblock In Gustau Camps-Valls, Francisco J.~R. Ruiz, and Isabel Valera, editors, {\em Proceedings of The 25th International Conference on Artificial Intelligence and Statistics}, volume 151 of {\em Proceedings of Machine Learning Research}, pages 5485--5517. PMLR, 28--30 Mar 2022.

\bibitem{DBLP:journals/csur/YangY23}
Tianbao Yang and Yiming Ying.
\newblock {AUC} maximization in the era of big data and {AI:} {A} survey.
\newblock {\em {ACM} Comput. Surv.}, 55(8):172:1--172:37, 2023.

\bibitem{yao2022largescale}
Yao Yao, Qihang Lin, and Tianbao Yang.
\newblock Large-scale optimization of partial auc in a range of false positive rates, 2022.

\bibitem{yuan2021largescale}
Zhuoning Yuan, Yan Yan, Milan Sonka, and Tianbao Yang.
\newblock Large-scale robust deep auc maximization: A new surrogate loss and empirical studies on medical image classification, 2021.

\bibitem{NEURIPS2020_52aaa62e}
Jiawei Zhang, Peijun Xiao, Ruoyu Sun, and Zhiquan Luo.
\newblock A single-loop smoothed gradient descent-ascent algorithm for nonconvex-concave min-max problems.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin, editors, {\em Advances in Neural Information Processing Systems}, volume~33, pages 7377--7389. Curran Associates, Inc., 2020.

\bibitem{NEURIPS2022_880d8999}
Xuan Zhang, Necdet~Serhat Aybat, and Mert Gurbuzbalaban.
\newblock Sapd+: An accelerated stochastic method for nonconvex-concave minimax problems.
\newblock In S.~Koyejo, S.~Mohamed, A.~Agarwal, D.~Belgrave, K.~Cho, and A.~Oh, editors, {\em Advances in Neural Information Processing Systems}, volume~35, pages 21668--21681. Curran Associates, Inc., 2022.

\bibitem{Zhang2022SAPDAA}
Xuan Zhang, Necdet~Serhat Aybat, and Mert G{\"u}rb{\"u}zbalaban.
\newblock Sapd+: An accelerated stochastic method for nonconvex-concave minimax problems.
\newblock In {\em Neural Information Processing Systems}, 2022.

\bibitem{zhang2023sapd}
Xuan Zhang, Necdet~Serhat Aybat, and Mert Gurbuzbalaban.
\newblock Sapd+: An accelerated stochastic method for nonconvex-concave minimax problems, 2023.

\bibitem{zhao2022primaldual}
Renbo Zhao.
\newblock A primal-dual smoothing framework for max-structured non-convex optimization, 2022.

\bibitem{pmlr-v162-zhu22g}
Dixian Zhu, Gang Li, Bokun Wang, Xiaodong Wu, and Tianbao Yang.
\newblock When {AUC} meets {DRO}: Optimizing partial {AUC} for deep learning with non-convex convergence guarantee.
\newblock In Kamalika Chaudhuri, Stefanie Jegelka, Le~Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, {\em Proceedings of the 39th International Conference on Machine Learning}, volume 162 of {\em Proceedings of Machine Learning Research}, pages 27548--27573. PMLR, 17--23 Jul 2022.

\end{thebibliography}
