\begin{thebibliography}{10}

\bibitem{kingma2014semi}
Durk~P Kingma, Shakir Mohamed, Danilo Jimenez~Rezende, and Max Welling.
\newblock Semi-supervised learning with deep generative models.
\newblock {\em Advances in neural information processing systems}, 27, 2014.

\bibitem{dinh16_densit_estim_using_real_nvp}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real {NVP}.
\newblock In {\em International Conference on Learning Representations}, 2017.

\bibitem{NEURIPS2018_d139db6a}
Durk~P Kingma and Prafulla Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, {\em Advances in Neural Information Processing
  Systems}, volume~31. Curran Associates, Inc., 2018.

\bibitem{karras2020analyzing}
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and
  Timo Aila.
\newblock Analyzing and improving the image quality of stylegan.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 8110--8119, 2020.

\bibitem{vaswani17_atten_is_all_you_need}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in {N}eural {I}nformation {P}rocessing {S}ystems}, 30,
  2017.

\bibitem{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 4171--4186,
  Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

\bibitem{floridi2020gpt}
Luciano Floridi and Massimo Chiriatti.
\newblock Gpt-3: Its nature, scope, limits, and consequences.
\newblock {\em Minds and Machines}, 30:681--694, 2020.

\bibitem{noe2019boltzmann}
Frank No{\'e}, Simon Olsson, Jonas K{\"o}hler, and Hao Wu.
\newblock Boltzmann generators --- sampling equilibrium states of many-body
  systems with deep learning.
\newblock {\em Science}, 365:eaaw1147, 2019.

\bibitem{jumper2021highly}
John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov,
  Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin
  {\v{Z}}{\'\i}dek, Anna Potapenko, et~al.
\newblock Highly accurate protein structure prediction with alphafold.
\newblock {\em Nature}, 596(7873):583--589, 2021.

\bibitem{watson2022broadly}
Joseph~L. Watson, David Juergens, Nathaniel~R. Bennett, Brian~L. Trippe, Jason
  Yim, Helen~E. Eisenach, Woody Ahern, Andrew~J. Borst, Robert~J. Ragotte,
  Lukas~F. Milles, Basile I.~M. Wicky, Nikita Hanikel, Samuel~J. Pellock,
  Alexis Courbet, William Sheffler, Jue Wang, Preetham Venkatesh, Isaac
  Sappington, Susana~V{\'a}zquez Torres, Anna Lauko, Valentin~De Bortoli, Emile
  Mathieu, Regina Barzilay, Tommi~S. Jaakkola, Frank DiMaio, Minkyung Baek, and
  David Baker.
\newblock Broadly applicable and accurate protein design by integrating
  structure prediction networks and diffusion generative models.
\newblock {\em bioRxiv}, 2022.

\bibitem{tabak2010density}
Esteban~G Tabak, Eric Vanden-Eijnden, et~al.
\newblock Density estimation by dual ascent of the log-likelihood.
\newblock {\em Communications in Mathematical Sciences}, 8(1):217--233, 2010.

\bibitem{tabak2013family}
Esteban~G Tabak and Cristina~V Turner.
\newblock A family of nonparametric density estimation algorithms.
\newblock {\em Communications on Pure and Applied Mathematics}, 66(2):145--164,
  2013.

\bibitem{papamakarios19_normal_flows_probab_model_infer}
George Papamakarios, Eric Nalisnick, Danilo~Jimenez Rezende, Shakir Mohamed,
  and Balaji Lakshminarayanan.
\newblock Normalizing flows for probabilistic modeling and inference.
\newblock {\em CoRR}, 2019.

\bibitem{RezendeEtAl_NormalizingFlows}
Danilo Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In {\em International conference on machine learning}, pages
  1530--1538. PMLR, 2015.

\bibitem{PhysRevLett.125.121601}
Gurtej Kanwar, Michael~S. Albergo, Denis Boyda, Kyle Cranmer, Daniel~C.
  Hackett, S\'ebastien Racani\`ere, Danilo~Jimenez Rezende, and Phiala~E.
  Shanahan.
\newblock Equivariant flow-based sampling for lattice gauge theory.
\newblock {\em Phys. Rev. Lett.}, 125:121601, Sep 2020.

\bibitem{NEURIPS2021_581b41df}
Isay Katsman, Aaron Lou, Derek Lim, Qingxuan Jiang, Ser~Nam Lim, and
  Christopher~M De~Sa.
\newblock Equivariant manifold flows.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman
  Vaughan, editors, {\em Advances in Neural Information Processing Systems},
  volume~34, pages 10600--10612. Curran Associates, Inc., 2021.

\bibitem{kohler2020equivariant}
Jonas K{\"o}hler, Leon Klein, and Frank No{\'e}.
\newblock Equivariant flows: exact likelihood generative learning for symmetric
  densities.
\newblock In {\em International conference on machine learning}, pages
  5361--5370. PMLR, 2020.

\bibitem{satorras2021n}
Victor Garcia~Satorras, Emiel Hoogeboom, Fabian Fuchs, Ingmar Posner, and Max
  Welling.
\newblock E(n) equivariant normalizing flows.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman
  Vaughan, editors, {\em Advances in Neural Information Processing Systems},
  volume~34, pages 4181--4192. Curran Associates, Inc., 2021.

\bibitem{kohler2023rigid}
Jonas K{\"{o}}hler, Michele Invernizzi, Pim de~Haan, and Frank No{\'{e}}.
\newblock Rigid body flows for sampling molecular crystal structures.
\newblock In {\em International Conference on Machine Learning, {ICML} 2023},
  volume 202 of {\em Proceedings of Machine Learning Research}, pages
  17301--17326. {PMLR}, 2023.

\bibitem{kohler2021smooth}
Jonas K\"{o}hler, Andreas Kr\"{a}mer, and Frank Noé.
\newblock Smooth normalizing flows.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.S. Liang, and J.~Wortman
  Vaughan, editors, {\em Advances in Neural Information Processing Systems},
  volume~34, pages 2796--2809. Curran Associates, Inc., 2021.

\bibitem{lipman2022flow}
Yaron Lipman, Ricky T.~Q. Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew
  Le.
\newblock Flow matching for generative modeling.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem{tong2023conditional}
Alexander Tong, Nikolay Malkin, Guillaume Huguet, Yanlei Zhang, Jarrid
  Rector-Brooks, Kilian Fatras, Guy Wolf, and Yoshua Bengio.
\newblock Conditional flow matching: Simulation-free dynamic optimal transport.
\newblock {\em arXiv preprint arXiv:2302.00482}, 2023.

\bibitem{song2023equivariant}
Yuxuan Song, Jingjing Gong, Minkai Xu, Ziyao Cao, Yanyan Lan, Stefano Ermon,
  Hao Zhou, and Wei-Ying Ma.
\newblock Equivariant flow matching with hybrid probability transport for 3d
  molecule generation.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing
  Systems}, 2023.

\bibitem{midgley2023se}
Laurence~Illing Midgley, Vincent Stimper, Javier Antoran, Emile Mathieu,
  Bernhard Sch{\"o}lkopf, and Jos{\'e}~Miguel Hern{\'a}ndez-Lobato.
\newblock {SE}(3) equivariant augmented coupling flows.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing
  Systems}, 2023.

\bibitem{dibak2021temperature}
Manuel Dibak, Leon Klein, Andreas Kr\"amer, and Frank No\'e.
\newblock Temperature steerable flows and {Boltzmann} generators.
\newblock {\em Phys. Rev. Res.}, 4:L042005, Oct 2022.

\bibitem{wirnsberger2020targeted}
Peter Wirnsberger, Andrew~J Ballard, George Papamakarios, Stuart Abercrombie,
  S{\'e}bastien Racani{\`e}re, Alexander Pritzel, Danilo Jimenez~Rezende, and
  Charles Blundell.
\newblock Targeted free energy estimation via learned mappings.
\newblock {\em The Journal of Chemical Physics}, 153(14):144112, 2020.

\bibitem{midgley2022flow}
Laurence~Illing Midgley, Vincent Stimper, Gregor N.~C. Simm, Bernhard
  Sch{\"o}lkopf, and Jos{\'e}~Miguel Hern{\'a}ndez-Lobato.
\newblock Flow annealed importance sampling bootstrap.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem{ding2021deepbar}
Xinqiang Ding and Bin Zhang.
\newblock Deepbar: A fast and exact method for binding free energy computation.
\newblock {\em Journal of Physical Chemistry Letters}, 12:2509--2515, 3 2021.

\bibitem{wu2020snf}
Hao Wu, Jonas K\"{o}hler, and Frank Noe.
\newblock Stochastic normalizing flows.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, {\em Advances in Neural Information Processing Systems}, volume~33,
  pages 5933--5944. Curran Associates, Inc., 2020.

\bibitem{ding2021computing}
Xinqiang Ding and Bin Zhang.
\newblock Computing absolute free energy with deep generative models.
\newblock {\em Biophysical Journal}, 120(3):195a, 2021.

\bibitem{rizzi2023multimap}
Andrea Rizzi, Paolo Carloni, and Michele Parrinello.
\newblock Multimap targeted free energy estimation, 2023.

\bibitem{rizzi2021targeted}
Andrea Rizzi, Paolo Carloni, and Michele Parrinello.
\newblock Targeted free energy perturbation revisited: Accurate free energies
  from mapped reference potentials.
\newblock {\em Journal of Physical Chemistry Letters}, 12:9449--9454, 2021.

\bibitem{invernizzi2022skipping}
Michele Invernizzi, Andreas Kr\"amer, Cecilia Clementi, and Frank No{\'e}.
\newblock Skipping the replica exchange ladder with normalizing flows.
\newblock {\em The Journal of Physical Chemistry Letters}, 13:11643--11649,
  2022.

\bibitem{klein2023timewarp}
Leon Klein, Andrew Y.~K. Foong, Tor~Erlend Fjelde, Bruno~Kacper Mlodozeniec,
  Marc Brockschmidt, Sebastian Nowozin, Frank Noe, and Ryota Tomioka.
\newblock Timewarp: Transferable acceleration of molecular dynamics by learning
  time-coarsened dynamics.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing
  Systems}, 2023.

\bibitem{pmlr-v162-hoogeboom22a}
Emiel Hoogeboom, V\'{\i}ctor~Garcia Satorras, Cl{\'e}ment Vignac, and Max
  Welling.
\newblock Equivariant diffusion for molecule generation in 3{D}.
\newblock In Kamalika Chaudhuri, Stefanie Jegelka, Le~Song, Csaba Szepesvari,
  Gang Niu, and Sivan Sabato, editors, {\em Proceedings of the 39th
  International Conference on Machine Learning}, volume 162 of {\em Proceedings
  of Machine Learning Research}, pages 8867--8887. PMLR, 17--23 Jul 2022.

\bibitem{xu2022geodiff}
Minkai Xu, Lantao Yu, Yang Song, Chence Shi, Stefano Ermon, and Jian Tang.
\newblock Geodiff: A geometric diffusion model for molecular conformation
  generation.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{jing2022torsional}
Bowen Jing, Gabriele Corso, Jeffrey Chang, Regina Barzilay, and Tommi Jaakkola.
\newblock Torsional diffusion for molecular conformer generation.
\newblock In S.~Koyejo, S.~Mohamed, A.~Agarwal, D.~Belgrave, K.~Cho, and A.~Oh,
  editors, {\em Advances in Neural Information Processing Systems}, volume~35,
  pages 24240--24253. Curran Associates, Inc., 2022.

\bibitem{schreiner2023implicit}
Mathias Schreiner, Ole Winther, and Simon Olsson.
\newblock Implicit transfer operator learning: Multiple time-resolution models
  for molecular dynamics.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing
  Systems}, 2023.

\bibitem{finlay2020train}
Chris Finlay, J{\"o}rn-Henrik Jacobsen, Levon Nurbekyan, and Adam Oberman.
\newblock How to train your neural ode: the world of jacobian and kinetic
  regularization.
\newblock In {\em International conference on machine learning}, pages
  3154--3164. PMLR, 2020.

\bibitem{tong2020trajectorynet}
Alexander Tong, Jessie Huang, Guy Wolf, David Van~Dijk, and Smita Krishnaswamy.
\newblock Trajectorynet: A dynamic optimal transport network for modeling
  cellular dynamics.
\newblock In {\em International conference on machine learning}, pages
  9526--9536. PMLR, 2020.

\bibitem{onken2021ot}
Derek Onken, Samy~Wu Fung, Xingjian Li, and Lars Ruthotto.
\newblock Ot-flow: Fast and accurate continuous normalizing flows via optimal
  transport.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 9223--9232, 2021.

\bibitem{albergo2023building}
Michael~Samuel Albergo and Eric Vanden-Eijnden.
\newblock Building normalizing flows with stochastic interpolants.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem{liu2023flow}
Xingchao Liu, Chengyue Gong, and qiang liu.
\newblock Flow straight and fast: Learning to generate and transfer data with
  rectified flow.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem{pooladian2023multisample}
Aram-Alexandre Pooladian, Heli Ben-Hamu, Carles Domingo-Enrich, Brandon Amos,
  Yaron Lipman, and Ricky Chen.
\newblock Multisample flow matching: Straightening flows with minibatch
  couplings.
\newblock {\em arXiv preprint arXiv:2304.14772}, 2023.

\bibitem{alvarez19towards}
David Alvarez-Melis, Stefanie Jegelka, and Tommi~S. Jaakkola.
\newblock Towards optimal transport with global invariances.
\newblock In Kamalika Chaudhuri and Masashi Sugiyama, editors, {\em Proceedings
  of the Twenty-Second International Conference on Artificial Intelligence and
  Statistics}, volume~89 of {\em Proceedings of Machine Learning Research},
  pages 1870--1879. PMLR, 16--18 Apr 2019.

\bibitem{kohler2023flow}
Jonas K{\"o}hler, Yaoyi Chen, Andreas Kr{\"a}mer, Cecilia Clementi, and Frank
  No{\'e}.
\newblock Flow-matching: Efficient coarse-graining of molecular dynamics
  without forces.
\newblock {\em Journal of Chemical Theory and Computation}, 19(3):942--952,
  2023.

\bibitem{papamakarios2021normalizing}
George Papamakarios, Eric~T Nalisnick, Danilo~Jimenez Rezende, Shakir Mohamed,
  and Balaji Lakshminarayanan.
\newblock Normalizing flows for probabilistic modeling and inference.
\newblock {\em J. Mach. Learn. Res.}, 22(57):1--64, 2021.

\bibitem{chen2018neural}
Tian~Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David~K Duvenaud.
\newblock Neural ordinary differential equations.
\newblock In {\em Advances in neural information processing systems}, pages
  6571--6583, 2018.

\bibitem{grathwohl2018ffjord}
Will Grathwohl, Ricky T.~Q. Chen, Jesse Bettencourt, and David Duvenaud.
\newblock Scalable reversible generative models with free-form continuous
  dynamics.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{Rezende2019EquivariantHF}
Danilo~Jimenez Rezende, S{\'e}bastien Racani{\`e}re, Irina Higgins, and Peter
  Toth.
\newblock Equivariant {H}amiltonian flows.
\newblock {\em arXiv preprint arXiv:1909.13739}, 2019.

\bibitem{fatras2021minibatch}
Kilian Fatras, Younes Zine, Szymon Majewski, R{\'e}mi Flamary, R{\'e}mi
  Gribonval, and Nicolas Courty.
\newblock Minibatch optimal transport distances; analysis and applications.
\newblock {\em arXiv preprint arXiv:2101.01792}, 2021.

\bibitem{kuhn1955hungarian}
Harold~W Kuhn.
\newblock The hungarian method for the assignment problem.
\newblock {\em Naval research logistics quarterly}, 2(1-2):83--97, 1955.

\bibitem{kabsch1976solution}
Wolfgang Kabsch.
\newblock A solution for the best rotation to relate two sets of vectors.
\newblock {\em Acta Crystallographica Section A: Crystal Physics, Diffraction,
  Theoretical and General Crystallography}, 32(5):922--923, 1976.

\bibitem{satorras2021graph}
V{\i}ctor~Garcia Satorras, Emiel Hoogeboom, and Max Welling.
\newblock E (n) equivariant graph neural networks.
\newblock In {\em International conference on machine learning}, pages
  9323--9332. PMLR, 2021.

\bibitem{dormand1980family}
John~R Dormand and Peter~J Prince.
\newblock A family of embedded runge-kutta formulae.
\newblock {\em Journal of computational and applied mathematics}, 6(1):19--26,
  1980.

\bibitem{xtb}
Christoph Bannwarth, Sebastian Ehlert, and Stefan Grimme.
\newblock Gfn2-xtb—an accurate and broadly parametrized self-consistent
  tight-binding quantum chemical method with multipole electrostatics and
  density-dependent dispersion contributions.
\newblock {\em Journal of Chemical Theory and Computation}, 15(3):1652--1671,
  2019.
\newblock PMID: 30741547.

\bibitem{kurtzberg1962approximation}
Jerome~M Kurtzberg.
\newblock On approximation methods for the assignment problem.
\newblock {\em Journal of the ACM (JACM)}, 9(4):419--439, 1962.

\bibitem{jing2020learning}
Bowen Jing, Stephan Eismann, Patricia Suriana, Raphael John~Lamarre Townshend,
  and Ron Dror.
\newblock Learning from protein structure with geometric vector perceptrons.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{schutt2021equivariant}
Kristof Sch{\"u}tt, Oliver Unke, and Michael Gastegger.
\newblock Equivariant message passing for the prediction of tensorial
  properties and molecular spectra.
\newblock In {\em International Conference on Machine Learning}, pages
  9377--9388. PMLR, 2021.

\bibitem{liao2023equiformer}
Yi-Lun Liao and Tess Smidt.
\newblock Equiformer: Equivariant graph attention transformer for 3d atomistic
  graphs.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem{gasteiger2021gemnet}
Johannes Gasteiger, Florian Becker, and Stephan G{\"u}nnemann.
\newblock Gemnet: Universal directional graph neural networks for molecules.
\newblock {\em Advances in Neural Information Processing Systems},
  34:6790--6802, 2021.

\bibitem{du2023new}
Weitao Du, Yuanqi Du, Limei Wang, Dieqiao Feng, Guifeng Wang, Shuiwang Ji,
  Carla Gomes, and Zhi-Ming Ma.
\newblock A new perspective on building efficient and expressive 3d equivariant
  graph neural networks.
\newblock {\em arXiv preprint arXiv:2304.04757}, 2023.

\bibitem{zwartsenberg2022conditional}
Berend Zwartsenberg, Adam {\'S}cibior, Matthew Niedoba, Vasileios Lioutas,
  Yunpeng Liu, Justice Sefas, Setareh Dabiri, Jonathan~Wilder Lavington, Trevor
  Campbell, and Frank Wood.
\newblock Conditional permutation invariant flows.
\newblock {\em arXiv preprint arXiv:2206.09021}, 2022.

\bibitem{bilos2021equivariant}
Marin Bilo{\v{s}} and Stephan G{\"u}nnemann.
\newblock Equivariant normalizing flows for point processes and sets, 2021.

\bibitem{li2020exchangeable}
Yang Li, Haidong Yi, Christopher Bender, Siyuan Shan, and Junier~B Oliva.
\newblock Exchangeable neural ode for set modeling.
\newblock {\em Advances in Neural Information Processing Systems},
  33:6936--6946, 2020.

\bibitem{katsman2021equivariant}
Isay Katsman, Aaron Lou, Derek Lim, Qingxuan Jiang, Ser~Nam Lim, and
  Christopher~M De~Sa.
\newblock Equivariant manifold flows.
\newblock {\em Advances in Neural Information Processing Systems},
  34:10600--10612, 2021.

\bibitem{monteiller2019alleviating}
Pierre Monteiller, Sebastian Claici, Edward Chien, Farzaneh Mirzazadeh,
  Justin~M Solomon, and Mikhail Yurochkin.
\newblock Alleviating label switching with optimal transport.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{brenier1991polar}
Yann Brenier.
\newblock Polar factorization and monotone rearrangement of vector-valued
  functions.
\newblock {\em Communications on pure and applied mathematics}, 44(4):375--417,
  1991.

\bibitem{NEURIPS2019_9015}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In {\em Advances in Neural Information Processing Systems 32}, pages
  8024--8035. Curran Associates, Inc., 2019.

\bibitem{politorchdyn}
Michael Poli, Stefano Massaroli, Atsushi Yamashita, Hajime Asama, Jinkyoo Park,
  and Stefano Ermon.
\newblock Torchdyn: Implicit models and neural numerical methods in pytorch.
\newblock In {\em Neural Information Processing Systems, Workshop on Physical
  Reasoning and Inductive Biases for the Real World}, volume~2, 2021.

\bibitem{flamary2021pot}
R{\'e}mi Flamary, Nicolas Courty, Alexandre Gramfort, Mokhtar~Z. Alaya,
  Aur{\'e}lie Boisbunon, Stanislas Chambon, Laetitia Chapel, Adrien Corenflos,
  Kilian Fatras, Nemo Fournier, L{\'e}o Gautheron, Nathalie~T.H. Gayraud,
  Hicham Janati, Alain Rakotomamonjy, Ievgen Redko, Antoine Rolet, Antony
  Schutz, Vivien Seguy, Danica~J. Sutherland, Romain Tavenard, Alexander Tong,
  and Titouan Vayer.
\newblock Pot: Python optimal transport.
\newblock {\em Journal of Machine Learning Research}, 22(78):1--8, 2021.

\bibitem{eastman2017openmm}
Peter Eastman, Jason Swails, John~D Chodera, Robert~T McGibbon, Yutong Zhao,
  Kyle~A Beauchamp, Lee-Ping Wang, Andrew~C Simmonett, Matthew~P Harrigan,
  Chaya~D Stern, et~al.
\newblock Openmm 7: Rapid development of high performance algorithms for
  molecular dynamics.
\newblock {\em PLoS computational biology}, 13(7):e1005659, 2017.

\bibitem{ase-paper}
Ask~Hjorth Larsen, Jens~Jørgen Mortensen, Jakob Blomqvist, Ivano~E Castelli,
  Rune Christensen, Marcin Dułak, Jesper Friis, Michael~N Groves, Bjørk
  Hammer, Cory Hargus, Eric~D Hermes, Paul~C Jennings, Peter~Bjerre Jensen,
  James Kermode, John~R Kitchin, Esben~Leonhard Kolsbjerg, Joseph Kubal,
  Kristen Kaasbjerg, Steen Lysgaard, Jón~Bergmann Maronsson, Tristan Maxson,
  Thomas Olsen, Lars Pastewka, Andrew Peterson, Carsten Rostgaard, Jakob
  Schiøtz, Ole Schütt, Mikkel Strange, Kristian~S Thygesen, Tejs Vegge, Lasse
  Vilhelmsen, Michael Walter, Zhenhua Zeng, and Karsten~W Jacobsen.
\newblock The atomic simulation environment—a python library for working with
  atoms.
\newblock {\em Journal of Physics: Condensed Matter}, 29(27):273002, 2017.

\bibitem{wiegand1968kish}
H~Wiegand.
\newblock Kish, l.: Survey sampling. john wiley \& sons, inc., new york, london
  1965, ix+ 643 s., 31 abb., 56 tab., preis 83 s., 1968.

\end{thebibliography}
