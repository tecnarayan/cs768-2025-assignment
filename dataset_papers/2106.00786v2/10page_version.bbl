\begin{thebibliography}{74}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alvarez-Melis et~al.(2019)Alvarez-Melis, Daum{\'e}~III, Vaughan, and
  Wallach]{alvarez2019weight}
David Alvarez-Melis, Hal Daum{\'e}~III, Jennifer~Wortman Vaughan, and Hanna
  Wallach.
\newblock Weight of evidence as a basis for human-oriented explanations.
\newblock \emph{arXiv preprint arXiv:1910.13503}, 2019.
\newblock URL \url{https://arxiv.org/pdf/1910.13503.pdf}.

\bibitem[Arras et~al.(2019)Arras, Osman, M{\"u}ller, and
  Samek]{arras-etal-2019-evaluating}
Leila Arras, Ahmed Osman, Klaus-Robert M{\"u}ller, and Wojciech Samek.
\newblock Evaluating recurrent neural network explanations.
\newblock In \emph{Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing
  and Interpreting Neural Networks for NLP}, pages 113--126, Florence, Italy,
  August 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/W19-4813}.
\newblock URL \url{https://www.aclweb.org/anthology/W19-4813}.

\bibitem[Bang et~al.(2019)Bang, Xie, Wu, and Xing]{bang_explaining_2019}
Seo-Jin Bang, Pengtao Xie, Wei Wu, and Eric~P. Xing.
\newblock Explaining a black-box using deep variational information bottleneck
  approach.
\newblock \emph{ArXiv}, abs/1902.06918, 2019.
\newblock URL \url{https://arxiv.org/abs/1902.06918}.

\bibitem[Baptista and Poloczek(2018)]{baptista2018bayesian}
Ricardo Baptista and Matthias Poloczek.
\newblock Bayesian optimization of combinatorial structures.
\newblock In \emph{International Conference on Machine Learning}, pages
  462--471. PMLR, 2018.
\newblock URL
  \url{http://proceedings.mlr.press/v80/baptista18a/baptista18a.pdf}.

\bibitem[Bastings et~al.(2019)Bastings, Aziz, and
  Titov]{bastings-2019-interpretable}
Jasmijn Bastings, Wilker Aziz, and Ivan Titov.
\newblock Interpretable neural predictions with differentiable binary
  variables.
\newblock In \emph{ACL 2019}, pages 2963--2977, Florence, Italy, July 2019.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P19-1284}.
\newblock URL \url{https://www.aclweb.org/anthology/P19-1284}.

\bibitem[Belanger et~al.(2017)Belanger, Yang, and
  McCallum]{belanger2017end-to-end}
David Belanger, Bishan Yang, and Andrew McCallum.
\newblock End-to-end learning for structured prediction energy networks.
\newblock In Doina Precup and Yee~Whye Teh, editors, \emph{Proceedings of the
  34th International Conference on Machine Learning, {ICML} 2017, Sydney, NSW,
  Australia, 6-11 August 2017}, volume~70 of \emph{Proceedings of Machine
  Learning Research}, pages 429--439. {PMLR}, 2017.
\newblock URL \url{http://proceedings.mlr.press/v70/belanger17a.html}.

\bibitem[Bowman et~al.(2015)Bowman, Angeli, Potts, and
  Manning]{bowman_large_2015}
Samuel~R. Bowman, Gabor Angeli, Christopher Potts, and Christopher~D. Manning.
\newblock A large annotated corpus for learning natural language inference.
\newblock In \emph{EMNLP 2015}, 2015.
\newblock URL \url{https://arxiv.org/abs/1508.05326}.

\bibitem[Chang et~al.(2019)Chang, Creager, Goldenberg, and
  Duvenaud]{chang2018explaining}
Chun-Hao Chang, Elliot Creager, Anna Goldenberg, and David Duvenaud.
\newblock Explaining image classifiers by counterfactual generation.
\newblock In \emph{ICLR}, 2019.
\newblock URL \url{https://arxiv.org/pdf/1807.08024.pdf}.

\bibitem[Chen and Ji(2020)]{chen-ji-2020-learning}
Hanjie Chen and Yangfeng Ji.
\newblock Learning variational word masks to improve the interpretability of
  neural text classifiers.
\newblock In \emph{EMNLP}, pages 4236--4251, Online, November 2020. Association
  for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.emnlp-main.347}.
\newblock URL \url{https://www.aclweb.org/anthology/2020.emnlp-main.347}.

\bibitem[Claesen and De~Moor(2015)]{claesen2015hyperparameter}
Marc Claesen and Bart De~Moor.
\newblock Hyperparameter search in machine learning.
\newblock \emph{arXiv preprint arXiv:1502.02127}, 2015.
\newblock URL \url{https://arxiv.org/pdf/1502.02127.pdf}.

\bibitem[Clark et~al.(2019)Clark, Lee, Chang, Kwiatkowski, Collins, and
  Toutanova]{clark-etal-2019-boolq}
Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael
  Collins, and Kristina Toutanova.
\newblock {B}ool{Q}: Exploring the surprising difficulty of natural yes/no
  questions.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 2924--2936,
  Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N19-1300}.
\newblock URL \url{https://www.aclweb.org/anthology/N19-1300}.

\bibitem[De~Cao et~al.(2020)De~Cao, Schlichtkrull, Aziz, and
  Titov]{de-cao-etal-2020-decisions}
Nicola De~Cao, Michael~Sejr Schlichtkrull, Wilker Aziz, and Ivan Titov.
\newblock How do decisions emerge across layers in neural models?
  interpretation with differentiable masking.
\newblock In \emph{EMNLP}, pages 3243--3255, Online, November 2020. Association
  for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.emnlp-main.262}.
\newblock URL \url{https://www.aclweb.org/anthology/2020.emnlp-main.262}.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova]{devlin_bert_2019}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{ACL 2019}, 2019.
\newblock URL \url{https://arxiv.org/pdf/1810.04805.pdf}.

\bibitem[DeYoung et~al.(2020)DeYoung, Jain, Rajani, Lehman, Xiong, Socher, and
  Wallace]{deyoung_eraser_2019}
Jay DeYoung, Sarthak Jain, Nazneen~Fatema Rajani, Eric Lehman, Caiming Xiong,
  Richard Socher, and Byron~C. Wallace.
\newblock Eraser: A benchmark to evaluate rationalized nlp models.
\newblock In \emph{ACL 2020}, volume abs/1911.03429, 2020.
\newblock URL \url{https://arxiv.org/pdf/1911.03429.pdf}.

\bibitem[Dodge et~al.(2020)Dodge, Ilharco, Schwartz, Farhadi, Hajishirzi, and
  Smith]{dodge_fine-tuning_2020}
Jesse Dodge, Gabriel Ilharco, Roy Schwartz, Ali Farhadi, Hannaneh Hajishirzi,
  and Noah Smith.
\newblock Fine-{Tuning} {Pretrained} {Language} {Models}: {Weight}
  {Initializations}, {Data} {Orders}, and {Early} {Stopping}.
\newblock \emph{arXiv:2002.06305 [cs]}, February 2020.
\newblock URL \url{http://arxiv.org/abs/2002.06305}.
\newblock arXiv: 2002.06305.

\bibitem[Du and Xu(2021)]{dumodel}
Qingfeng Du and Jincheng Xu.
\newblock Model-agnostic local explanations with genetic algorithms for text
  classification.
\newblock In \emph{The 33rd International Conference on Software Engineering \&
  Knowledge Engineering}, 2021.
\newblock URL \url{https://ksiresearch.org/seke/seke21paper/paper040.pdf}.

\bibitem[Ebrahimi et~al.(2018)Ebrahimi, Rao, Lowd, and
  Dou]{ebrahimi-etal-2018-hotflip}
Javid Ebrahimi, Anyi Rao, Daniel Lowd, and Dejing Dou.
\newblock {H}ot{F}lip: White-box adversarial examples for text classification.
\newblock In \emph{ACL}, pages 31--36, Melbourne, Australia, July 2018.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P18-2006}.
\newblock URL \url{https://www.aclweb.org/anthology/P18-2006}.

\bibitem[Efron and Tibshirani(1994)]{efron1994introduction}
Bradley Efron and Robert~J Tibshirani.
\newblock \emph{An Introduction to the Bootstrap}.
\newblock CRC press, 1994.

\bibitem[Ehsan et~al.(2021)Ehsan, Passi, Liao, Chan, Lee, Muller, Riedl,
  et~al.]{ehsan2021explainable}
Upol Ehsan, Samir Passi, Q~Vera Liao, Larry Chan, I~Lee, Michael Muller, Mark~O
  Riedl, et~al.
\newblock The who in explainable ai: How ai background shapes perceptions of ai
  explanations.
\newblock \emph{arXiv preprint arXiv:2107.13509}, 2021.
\newblock URL \url{https://arxiv.org/pdf/2107.13509.pdf}.

\bibitem[Fong and Vedaldi(2017)]{fong2017interpretable}
Ruth~C Fong and Andrea Vedaldi.
\newblock Interpretable explanations of black boxes by meaningful perturbation.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pages 3429--3437, 2017.
\newblock URL \url{https://arxiv.org/pdf/1704.03296.pdf}.

\bibitem[Hase and Bansal(2020)]{hase_evaluating_2020}
Peter Hase and Mohit Bansal.
\newblock Evaluating explainable ai: Which algorithmic explanations help users
  predict model behavior?
\newblock In \emph{ACL 2020}, 2020.
\newblock URL \url{https://arxiv.org/pdf/2005.01831.pdf}.

\bibitem[Haug et~al.(2021)Haug, Z{\"u}rn, El-Jiz, and
  Kasneci]{haug2021baselines}
Johannes Haug, Stefan Z{\"u}rn, Peter El-Jiz, and Gjergji Kasneci.
\newblock On baselines for local feature attributions.
\newblock In \emph{AAAI}, 2021.
\newblock URL \url{https://arxiv.org/pdf/2101.00905.pdf}.

\bibitem[Hooker et~al.(2019)Hooker, Erhan, Kindermans, and
  Kim]{hooker_benchmark_2019}
Sara Hooker, Dumitru Erhan, Pieter-Jan Kindermans, and Been Kim.
\newblock A benchmark for interpretability methods in deep neural networks.
\newblock In \emph{Proceedings of the 33rd International Conference on Neural
  Information Processing Systems}, 2019.
\newblock URL \url{https://arxiv.org/abs/1806.10758}.

\bibitem[Hsieh et~al.(2020)Hsieh, Yeh, Liu, Ravikumar, Kim, Kumar, and
  Hsieh]{hsieh2020evaluations}
Cheng-Yu Hsieh, Chih-Kuan Yeh, Xuanqing Liu, Pradeep Ravikumar, Seungyeon Kim,
  Sanjiv Kumar, and Cho-Jui Hsieh.
\newblock Evaluations and methods for explanation through robustness analysis.
\newblock \emph{arXiv preprint arXiv:2006.00442}, 2020.
\newblock URL \url{https://arxiv.org/pdf/2006.00442.pdf}.

\bibitem[Jacovi and Goldberg(2021)]{jacovi2021aligning}
Alon Jacovi and Yoav Goldberg.
\newblock Aligning faithful interpretations with their social attribution.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  9:\penalty0 294--310, 2021.
\newblock URL
  \url{https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00367/98620/Aligning}.

\bibitem[Jain and Wallace(2019)]{jain2019attention}
Sarthak Jain and Byron~C Wallace.
\newblock Attention is not explanation.
\newblock In \emph{Proceedings of the 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 3543--3556, 2019.

\bibitem[Jang et~al.(2016)Jang, Gu, and Poole]{jang2016categorical}
Eric Jang, Shixiang Gu, and Ben Poole.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock In \emph{ICLR}, 2016.
\newblock URL \url{https://arxiv.org/pdf/1611.01144.pdf}.

\bibitem[Janzing et~al.(2020)Janzing, Minorics, and
  Bl{\"o}baum]{janzing2020feature}
Dominik Janzing, Lenon Minorics, and Patrick Bl{\"o}baum.
\newblock Feature relevance quantification in explainable ai: A causal problem.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 2907--2916. PMLR, 2020.
\newblock URL \url{https://arxiv.org/pdf/1910.13413.pdf}.

\bibitem[Jethani et~al.(2021)Jethani, Sudarshan, Aphinyanaphongs, and
  Ranganath]{jethani2021have}
Neil Jethani, Mukund Sudarshan, Yindalon Aphinyanaphongs, and Rajesh Ranganath.
\newblock Have we learned to explain?: How interpretability methods can learn
  to encode predictions in their interpretations.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 1459--1467. PMLR, 2021.
\newblock URL \url{https://arxiv.org/pdf/2103.01890.pdf}.

\bibitem[Khashabi et~al.(2018)Khashabi, Chaturvedi, Roth, Upadhyay, and
  Roth]{khashabi-etal-2018-looking}
Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, and Dan
  Roth.
\newblock Looking beyond the surface: A challenge set for reading comprehension
  over multiple sentences.
\newblock In \emph{Proceedings of the 2018 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, pages 252--262, New Orleans,
  Louisiana, June 2018. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N18-1023}.
\newblock URL \url{https://www.aclweb.org/anthology/N18-1023}.

\bibitem[Kim et~al.(2020)Kim, Yi, Kim, and Yoon]{kim-etal-2020-interpretation}
Siwon Kim, Jihun Yi, Eunji Kim, and Sungroh Yoon.
\newblock Interpretation of {NLP} models through input marginalization.
\newblock In \emph{EMNLP}, pages 3154--3167, Online, November 2020. Association
  for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.emnlp-main.255}.
\newblock URL \url{https://www.aclweb.org/anthology/2020.emnlp-main.255}.

\bibitem[Lakkaraju et~al.(2019)Lakkaraju, Kamar, Caruana, and
  Leskovec]{lakkaraju2019faithful}
Himabindu Lakkaraju, Ece Kamar, Rich Caruana, and Jure Leskovec.
\newblock Faithful and customizable explanations of black box models.
\newblock In \emph{Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics,
  and Society}, pages 131--138, 2019.
\newblock URL
  \url{https://papers.nips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf}.

\bibitem[Lehman et~al.(2019)Lehman, DeYoung, Barzilay, and
  Wallace]{lehman-etal-2019-inferring}
Eric Lehman, Jay DeYoung, Regina Barzilay, and Byron~C. Wallace.
\newblock Inferring which medical treatments work from reports of clinical
  trials.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 3705--3717,
  Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N19-1371}.
\newblock URL \url{https://www.aclweb.org/anthology/N19-1371}.

\bibitem[Li et~al.(2015)Li, Chen, Hovy, and Jurafsky]{li2015visualizing}
Jiwei Li, Xinlei Chen, Eduard Hovy, and Dan Jurafsky.
\newblock Visualizing and understanding neural models in nlp.
\newblock \emph{arXiv preprint arXiv:1506.01066}, 2015.
\newblock URL \url{https://arxiv.org/pdf/1506.01066.pdf}.

\bibitem[Li et~al.(2016)Li, Monroe, and Jurafsky]{li2016understanding}
Jiwei Li, Will Monroe, and Dan Jurafsky.
\newblock Understanding neural networks through representation erasure.
\newblock \emph{arXiv preprint arXiv:1612.08220}, 2016.
\newblock URL \url{https://arxiv.org/pdf/1612.08220.pdf}.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis,
  Zettlemoyer, and Stoyanov]{liu_roberta_2019}
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
  Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{ArXiv}, abs/1907.11692, 2019.
\newblock URL \url{https://arxiv.org/pdf/1907.11692.pdf}.

\bibitem[Loshchilov and Hutter(2017)]{loshchilov_decoupled_2017}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization, 2017.
\newblock URL \url{https://arxiv.org/pdf/1711.05101.pdf}.

\bibitem[Lundberg and Lee(2017)]{lundberg_unified_2017}
Scott~M Lundberg and Su-In Lee.
\newblock A {Unified} {Approach} to {Interpreting} {Model} {Predictions}.
\newblock In I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, \emph{Advances in {Neural}
  {Information} {Processing} {Systems} 30}, pages 4765--4774, 2017.
\newblock URL
  \url{http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf}.

\bibitem[Maddison et~al.(2017)Maddison, Mnih, and Teh]{maddison_concrete_2016}
Chris~J. Maddison, Andriy Mnih, and Yee~Whye Teh.
\newblock The concrete distribution: A continuous relaxation of discrete random
  variables.
\newblock In \emph{ICLR 2017}, 2017.
\newblock URL \url{https://arxiv.org/abs/1611.00712}.

\bibitem[Miller(2019)]{miller2019explanation}
Tim Miller.
\newblock Explanation in artificial intelligence: Insights from the social
  sciences.
\newblock \emph{Artif. Intell.}, 267:\penalty0 1--38, 2019.
\newblock \doi{10.1016/j.artint.2018.07.007}.
\newblock URL \url{https://doi.org/10.1016/j.artint.2018.07.007}.

\bibitem[Miyato et~al.(2018)Miyato, Maeda, Koyama, and
  Ishii]{miyato2018virtual}
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii.
\newblock Virtual adversarial training: a regularization method for supervised
  and semi-supervised learning.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 41\penalty0 (8):\penalty0 1979--1993, 2018.
\newblock URL \url{https://arxiv.org/pdf/1704.03976.pdf}.

\bibitem[Moreno-Torres et~al.(2012)Moreno-Torres, Raeder, Alaiz-Rodr{\'\i}guez,
  Chawla, and Herrera]{moreno2012unifying}
Jose~G Moreno-Torres, Troy Raeder, Roc{\'\i}o Alaiz-Rodr{\'\i}guez, Nitesh~V
  Chawla, and Francisco Herrera.
\newblock A unifying view on dataset shift in classification.
\newblock \emph{Pattern recognition}, 45\penalty0 (1):\penalty0 521--530, 2012.
\newblock URL
  \url{https://rtg.cis.upenn.edu/cis700-2019/papers/dataset-shift/dataset-shift-terminology.pdf}.

\bibitem[Mothilal et~al.(2020)Mothilal, Sharma, and
  Tan]{mothilal2020explaining}
Ramaravind~Kommiya Mothilal, Amit Sharma, and Chenhao Tan.
\newblock Explaining machine learning classifiers through diverse
  counterfactual explanations.
\newblock In Mireille Hildebrandt, Carlos Castillo, Elisa Celis, Salvatore
  Ruggieri, Linnet Taylor, and Gabriela Zanfir{-}Fortuna, editors, \emph{FAT*
  '20: Conference on Fairness, Accountability, and Transparency}, pages
  607--617. {ACM}, 2020.
\newblock \doi{10.1145/3351095.3372850}.
\newblock URL \url{https://doi.org/10.1145/3351095.3372850}.

\bibitem[Nguyen(2018)]{nguyen_comparing_2018}
Dong Nguyen.
\newblock Comparing automatic and human evaluation of local explanations for
  text classification.
\newblock In \emph{NAACL-HLT 2018}, 2018.
\newblock URL \url{https://www.aclweb.org/anthology/N18-1097.pdf}.

\bibitem[Paranjape et~al.(2020)Paranjape, Joshi, Thickstun, Hajishirzi, and
  Zettlemoyer]{paranjape-etal-2020-information}
Bhargavi Paranjape, Mandar Joshi, John Thickstun, Hannaneh Hajishirzi, and Luke
  Zettlemoyer.
\newblock An information bottleneck approach for controlling conciseness in
  rationale extraction.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 1938--1952, Online, November
  2020. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.emnlp-main.153}.
\newblock URL \url{https://www.aclweb.org/anthology/2020.emnlp-main.153}.

\bibitem[Pirlot(1996)]{pirlot1996general}
Marc Pirlot.
\newblock General local search methods.
\newblock \emph{European journal of operational research}, 92\penalty0
  (3):\penalty0 493--511, 1996.

\bibitem[Probst et~al.(2019)Probst, Boulesteix, and
  Bischl]{probst2019tunability}
Philipp Probst, Anne-Laure Boulesteix, and Bernd Bischl.
\newblock Tunability: Importance of hyperparameters of machine learning
  algorithms.
\newblock \emph{J. Mach. Learn. Res.}, 20\penalty0 (53):\penalty0 1--32, 2019.
\newblock URL \url{https://arxiv.org/pdf/1802.09596.pdf}.

\bibitem[Qiu et~al.(2021)Qiu, Yang, Cao, Liu, Zheng, Ngai, Hsiao, and
  Chen]{qiu2021resisting}
Luyu Qiu, Yi~Yang, Caleb~Chen Cao, Jing Liu, Yueyuan Zheng, Hilary Hei~Ting
  Ngai, Janet Hsiao, and Lei Chen.
\newblock Resisting out-of-distribution data problem in perturbation of xai.
\newblock \emph{arXiv preprint arXiv:2107.14000}, 2021.

\bibitem[Ribeiro et~al.(2016)Ribeiro, Singh, and Guestrin]{ribeiro_why_2016}
Marco~Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.
\newblock "{W}hy {S}hould {I} {T}rust {Y}ou?": Explaining the predictions of
  any classifier.
\newblock \emph{Proceedings of the 22nd ACM SIGKDD International Conference on
  Knowledge Discovery and Data Mining}, 2016.
\newblock URL \url{https://arxiv.org/pdf/1602.04938.pdf}.

\bibitem[Ribeiro et~al.(2018)Ribeiro, Singh, and
  Guestrin]{ribeiro_anchors_2018}
Marco~Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.
\newblock Anchors: High-precision model-agnostic explanations.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2018.
\newblock URL \url{https://homes.cs.washington.edu/~marcotcr/aaai18.pdf}.

\bibitem[Robnik-Sikonja and Kononenko(2008)]{RobnikSikonja2008ExplainingCF}
M.~Robnik-Sikonja and I.~Kononenko.
\newblock Explaining classifications for individual instances.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering},
  20:\penalty0 589--600, 2008.
\newblock URL
  \url{http://lkm.fri.uni-lj.si/rmarko/papers/RobnikSikonjaKononenko08-TKDE.pdf}.

\bibitem[Sanyal and Ren(2021)]{sanyal2021discretized}
Soumya Sanyal and Xiang Ren.
\newblock Discretized integrated gradients for explaining language models.
\newblock \emph{arXiv preprint arXiv:2108.13654}, 2021.
\newblock URL \url{https://arxiv.org/pdf/2108.13654.pdf}.

\bibitem[Sch{\"a}fer(2013)]{schafer2013particle}
Christian Sch{\"a}fer.
\newblock Particle algorithms for optimization on binary spaces.
\newblock \emph{ACM Transactions on Modeling and Computer Simulation (TOMACS)},
  23\penalty0 (1):\penalty0 1--25, 2013.
\newblock URL \url{https://arxiv.org/pdf/1111.0574.pdf}.

\bibitem[Shrikumar et~al.(2017)Shrikumar, Greenside, and
  Kundaje]{shrikumar2017learning}
Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje.
\newblock Learning important features through propagating activation
  differences.
\newblock In \emph{International Conference on Machine Learning}, pages
  3145--3153, 2017.
\newblock URL \url{https://arxiv.org/pdf/1704.02685.pdf}.

\bibitem[Simonyan et~al.(2013)Simonyan, Vedaldi, and
  Zisserman]{simonyan_2013_deep}
Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock \emph{Workshop at International Conference on Learning
  Representations.}, 2013.
\newblock URL \url{https://arxiv.org/pdf/1312.6034.pdf}.

\bibitem[Smilkov et~al.(2017)Smilkov, Thorat, Kim, Vi{\'e}gas, and
  Wattenberg]{smilkov2017smoothgrad}
Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Vi{\'e}gas, and Martin
  Wattenberg.
\newblock Smoothgrad: removing noise by adding noise.
\newblock \emph{arXiv preprint arXiv:1706.03825}, 2017.
\newblock URL \url{https://arxiv.org/pdf/1706.03825.pdf}.

\bibitem[Socher et~al.(2013{\natexlab{a}})Socher, Perelygin, Wu, Chuang,
  Manning, Ng, and Potts]{socher-etal-2013-recursive}
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher~D. Manning,
  Andrew Ng, and Christopher Potts.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock In \emph{Proceedings of the 2013 Conference on Empirical Methods in
  Natural Language Processing}, pages 1631--1642, Seattle, Washington, USA,
  October 2013{\natexlab{a}}. Association for Computational Linguistics.
\newblock URL \url{https://www.aclweb.org/anthology/D13-1170}.

\bibitem[Socher et~al.(2013{\natexlab{b}})Socher, Perelygin, Wu, Chuang,
  Manning, Ng, and Potts]{socher2013recursive}
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher~D Manning,
  Andrew~Y Ng, and Christopher Potts.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock In \emph{Proceedings of the 2013 conference on empirical methods in
  natural language processing}, pages 1631--1642, 2013{\natexlab{b}}.
\newblock URL \url{https://www.aclweb.org/anthology/D13-1170.pdf}.

\bibitem[Sturmfels et~al.(2020)Sturmfels, Lundberg, and
  Lee]{sturmfels2020visualizing}
Pascal Sturmfels, Scott Lundberg, and Su-In Lee.
\newblock Visualizing the impact of feature attribution baselines.
\newblock \emph{Distill}, 5\penalty0 (1):\penalty0 e22, 2020.
\newblock URL \url{https://distill.pub/2020/attribution-baselines/}.

\bibitem[Sundararajan and Najmi(2020)]{sundararajan2020many}
Mukund Sundararajan and Amir Najmi.
\newblock The many shapley values for model explanation.
\newblock In \emph{International Conference on Machine Learning}, pages
  9269--9278. PMLR, 2020.
\newblock URL \url{https://arxiv.org/pdf/1908.08474.pdf}.

\bibitem[Sundararajan et~al.(2017)Sundararajan, Taly, and
  Yan]{sundararajan_2017_axiomatic}
Mukund Sundararajan, Ankur Taly, and Qiqi Yan.
\newblock Axiomatic attribution for deep networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  3319--3328, 2017.
\newblock URL \url{https://arxiv.org/pdf/1703.01365.pdf}.

\bibitem[Thorne et~al.(2018)Thorne, Vlachos, Christodoulopoulos, and
  Mittal]{thorne-etal-2018-fever}
James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal.
\newblock {FEVER}: a large-scale dataset for fact extraction and
  {VER}ification.
\newblock In \emph{Proceedings of the 2018 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, pages 809--819, New Orleans,
  Louisiana, June 2018. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N18-1074}.
\newblock URL \url{https://www.aclweb.org/anthology/N18-1074}.

\bibitem[Vafa et~al.(2021)Vafa, Deng, Blei, and Rush]{vafa2021rationales}
Keyon Vafa, Yuntian Deng, David~M Blei, and Alexander~M Rush.
\newblock Rationales for sequential predictions.
\newblock In \emph{EMNLP}, 2021.
\newblock URL \url{https://arxiv.org/pdf/2109.06387.pdf}.

\bibitem[Van~Rijn and Hutter(2018)]{van2018hyperparameter}
Jan~N Van~Rijn and Frank Hutter.
\newblock Hyperparameter importance across datasets.
\newblock In \emph{Proceedings of the 24th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pages 2367--2376, 2018.
\newblock URL \url{https://arxiv.org/pdf/1710.04725.pdf}.

\bibitem[Wiegreffe and Pinter(2019)]{wiegreffe2019attention}
Sarah Wiegreffe and Yuval Pinter.
\newblock Attention is not not explanation.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 11--20, 2019.
\newblock URL \url{https://arxiv.org/pdf/1908.04626.pdf}.

\bibitem[Wojtas and Chen(2020)]{maksymilian2020feature}
Maksymilian Wojtas and Ke~Chen.
\newblock Feature importance ranking for deep learning.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 5105--5114. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/file/36ac8e558ac7690b6f44e2cb5ef93322-Paper.pdf}.

\bibitem[Wolf et~al.(2019)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, et~al.]{wolf2019huggingface}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
  Anthony Moi, Pierric Cistac, Tim Rault, R{\'e}mi Louf, Morgan Funtowicz,
  et~al.
\newblock Huggingface's transformers: State-of-the-art natural language
  processing.
\newblock \emph{ArXiv}, pages arXiv--1910, 2019.

\bibitem[Wolf et~al.(2020)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, Davison, Shleifer, von Platen, Ma, Jernite, Plu, Xu,
  Scao, Gugger, Drame, Lhoest, and Rush]{wolf-etal-2020-transformers}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
  Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe
  Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
  Plu, Canwen Xu, Teven~Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
  and Alexander~M. Rush.
\newblock Transformers: State-of-the-art natural language processing.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}, pages 38--45, Online,
  October 2020. Association for Computational Linguistics.
\newblock URL \url{https://www.aclweb.org/anthology/2020.emnlp-demos.6}.

\bibitem[Yi et~al.(2020)Yi, Kim, Kim, and Yoon]{yi2020information}
Jihun Yi, Eunji Kim, Siwon Kim, and Sungroh Yoon.
\newblock Information-theoretic visual explanation for black-box classifiers.
\newblock \emph{arXiv preprint arXiv:2009.11150}, 2020.
\newblock URL \url{https://arxiv.org/pdf/2009.11150.pdf}.

\bibitem[Yin et~al.(2021)Yin, Shi, Hsieh, and Chang]{yin2021faithfulness}
Fan Yin, Zhouxing Shi, Cho-Jui Hsieh, and Kai-Wei Chang.
\newblock On the faithfulness measurements for model interpretations, 2021.
\newblock URL \url{https://arxiv.org/pdf/2104.08782.pdf}.

\bibitem[Zaidan et~al.(2007)Zaidan, Eisner, and Piatko]{zaidan_using_2007}
Omar Zaidan, Jason Eisner, and Christine Piatko.
\newblock Using “{Annotator} {Rationales}” to {Improve} {Machine}
  {Learning} for {Text} {Categorization}.
\newblock In \emph{Human {Language} {Technologies} 2007: {The} {Conference} of
  the {North} {American} {Chapter} of the {Association} for {Computational}
  {Linguistics}; {Proceedings} of the {Main} {Conference}}, pages 260--267,
  Rochester, New York, April 2007. Association for Computational Linguistics.
\newblock URL \url{https://www.aclweb.org/anthology/N07-1033}.

\bibitem[Zhong et~al.(2019)Zhong, Shao, and McKeown]{zhong2019fine}
Ruiqi Zhong, Steven Shao, and Kathleen McKeown.
\newblock Fine-grained sentiment analysis with faithful attention.
\newblock \emph{arXiv preprint arXiv:1908.06870}, 2019.
\newblock URL \url{https://arxiv.org/pdf/1908.06870.pdf}.

\bibitem[Zhou et~al.(2021)Zhou, Booth, Ribeiro, and Shah]{zhou2021feature}
Yilun Zhou, Serena Booth, Marco~Tulio Ribeiro, and Julie Shah.
\newblock Do feature attribution methods correctly attribute features?
\newblock \emph{arXiv preprint arXiv:2104.14403}, 2021.
\newblock URL \url{https://arxiv.org/pdf/2104.14403.pdf}.

\bibitem[Zintgraf et~al.(2017)Zintgraf, Cohen, Adel, and
  Welling]{zintgraf2017visualizing}
Luisa~M Zintgraf, Taco~S Cohen, Tameem Adel, and Max Welling.
\newblock Visualizing deep neural network decisions: Prediction difference
  analysis.
\newblock In \emph{ICLR}, 2017.
\newblock URL \url{https://arxiv.org/pdf/1702.04595.pdf}.

\end{thebibliography}
