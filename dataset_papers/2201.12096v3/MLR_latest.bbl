\begin{thebibliography}{67}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2021)Agarwal, Schwarzer, Castro, Courville, and
  Bellemare]{agarwal2021deep}
Agarwal, R., Schwarzer, M., Castro, P.~S., Courville, A.~C., and Bellemare, M.
\newblock Deep reinforcement learning at the edge of the statistical precipice.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Anand et~al.(2019)Anand, Racah, Ozair, Bengio, C\^{o}t\'{e}, and
  Hjelm]{anand2019stdim}
Anand, A., Racah, E., Ozair, S., Bengio, Y., C\^{o}t\'{e}, M.-A., and Hjelm,
  R.~D.
\newblock Unsupervised state representation learning in atari.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Ba, J.~L., Kiros, J.~R., and Hinton, G.~E.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Bao et~al.(2021)Bao, Dong, Piao, and Wei]{bao2021beit}
Bao, H., Dong, L., Piao, S., and Wei, F.
\newblock Beit: Bert pre-training of image transformers.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Bellemare et~al.(2013)Bellemare, Naddaf, Veness, and
  Bowling]{bellemare2013arcade}
Bellemare, M.~G., Naddaf, Y., Veness, J., and Bowling, M.
\newblock The arcade learning environment: An evaluation platform for general
  agents.
\newblock \emph{Journal of Artificial Intelligence Research}, 47:\penalty0
  253--279, 2013.

\bibitem[Bellemare et~al.(2017)Bellemare, Dabney, and
  Munos]{bellemare2017distributional}
Bellemare, M.~G., Dabney, W., and Munos, R.
\newblock A distributional perspective on reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  449--458. PMLR, 2017.

\bibitem[Bellman(1957)]{bellman1957markovian}
Bellman, R.
\newblock A markovian decision process.
\newblock \emph{Journal of mathematics and mechanics}, 6\penalty0 (5):\penalty0
  679--684, 1957.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{arXiv preprint arXiv:2005.14165}, 2020.

\bibitem[Castro et~al.(2018)Castro, Moitra, Gelada, Kumar, and
  Bellemare]{castro2018dopamine}
Castro, P.~S., Moitra, S., Gelada, C., Kumar, S., and Bellemare, M.~G.
\newblock Dopamine: A research framework for deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1812.06110}, 2018.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Radford, Child, Wu, Jun, Luan,
  and Sutskever]{chen2020generative}
Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., and Sutskever, I.
\newblock Generative pretraining from pixels.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1691--1703. PMLR, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Norouzi, and
  Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1597--1607. PMLR, 2020{\natexlab{b}}.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Dolan \& Mor{\'e}(2002)Dolan and Mor{\'e}]{dolan2002benchmarking}
Dolan, E.~D. and Mor{\'e}, J.~J.
\newblock Benchmarking optimization software with performance profiles.
\newblock \emph{Mathematical programming}, 91\penalty0 (2):\penalty0 201--213,
  2002.

\bibitem[Fortunato et~al.(2017)Fortunato, Azar, Piot, Menick, Osband, Graves,
  Mnih, Munos, Hassabis, Pietquin, et~al.]{fortunato2017noisy}
Fortunato, M., Azar, M.~G., Piot, B., Menick, J., Osband, I., Graves, A., Mnih,
  V., Munos, R., Hassabis, D., Pietquin, O., et~al.
\newblock Noisy networks for exploration.
\newblock \emph{arXiv preprint arXiv:1706.10295}, 2017.

\bibitem[Grill et~al.(2020)Grill, Strub, Altch\'{e}, Tallec, Richemond,
  Buchatskaya, Doersch, Avila~Pires, Guo, Gheshlaghi~Azar, Piot, kavukcuoglu,
  Munos, and Valko]{grill2020byol}
Grill, J.-B., Strub, F., Altch\'{e}, F., Tallec, C., Richemond, P.,
  Buchatskaya, E., Doersch, C., Avila~Pires, B., Guo, Z., Gheshlaghi~Azar, M.,
  Piot, B., kavukcuoglu, k., Munos, R., and Valko, M.
\newblock Bootstrap your own latent - a new approach to self-supervised
  learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Guo et~al.(2020)Guo, Pires, Piot, Grill, Altch{\'e}, Munos, and
  Azar]{guo2020bootstrap}
Guo, Z.~D., Pires, B.~A., Piot, B., Grill, J.-B., Altch{\'e}, F., Munos, R.,
  and Azar, M.~G.
\newblock Bootstrap latent-predictive representations for multitask
  reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3875--3886. PMLR, 2020.

\bibitem[Guo et~al.(2022)Guo, Thakoor, P{\^\i}slar, Pires, Altch{\'e}, Tallec,
  Saade, Calandriello, Grill, Tang, et~al.]{guo2022byol}
Guo, Z.~D., Thakoor, S., P{\^\i}slar, M., Pires, B.~A., Altch{\'e}, F., Tallec,
  C., Saade, A., Calandriello, D., Grill, J.-B., Tang, Y., et~al.
\newblock Byol-explore: Exploration by bootstrapped prediction.
\newblock \emph{arXiv preprint arXiv:2206.08332}, 2022.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Hartikainen, Tucker, Ha, Tan,
  Kumar, Zhu, Gupta, Abbeel, et~al.]{haarnoja2018soft}
Haarnoja, T., Zhou, A., Hartikainen, K., Tucker, G., Ha, S., Tan, J., Kumar,
  V., Zhu, H., Gupta, A., Abbeel, P., et~al.
\newblock Soft actor-critic algorithms and applications.
\newblock \emph{arXiv preprint arXiv:1812.05905}, 2018.

\bibitem[Hafner et~al.(2019)Hafner, Lillicrap, Fischer, Villegas, Ha, Lee, and
  Davidson]{hafner2019learning}
Hafner, D., Lillicrap, T., Fischer, I., Villegas, R., Ha, D., Lee, H., and
  Davidson, J.
\newblock Learning latent dynamics for planning from pixels.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2555--2565. PMLR, 2019.

\bibitem[Hafner et~al.(2020{\natexlab{a}})Hafner, Lillicrap, Ba, and
  Norouzi]{Hafner2020Dream}
Hafner, D., Lillicrap, T., Ba, J., and Norouzi, M.
\newblock Dream to control: Learning behaviors by latent imagination.
\newblock In \emph{International Conference on Learning Representations},
  2020{\natexlab{a}}.

\bibitem[Hafner et~al.(2020{\natexlab{b}})Hafner, Lillicrap, Norouzi, and
  Ba]{hafner2020mastering}
Hafner, D., Lillicrap, T., Norouzi, M., and Ba, J.
\newblock Mastering atari with discrete world models.
\newblock \emph{arXiv preprint arXiv:2010.02193}, 2020{\natexlab{b}}.

\bibitem[Hansen \& Wang(2021)Hansen and Wang]{hansen2021generalization}
Hansen, N. and Wang, X.
\newblock Generalization in reinforcement learning by soft data augmentation.
\newblock In \emph{2021 IEEE International Conference on Robotics and
  Automation (ICRA)}, pp.\  13611--13617. IEEE, 2021.

\bibitem[Hansen et~al.(2019)Hansen, Dabney, Barreto, Van~de Wiele,
  Warde-Farley, and Mnih]{hansen2019fast}
Hansen, S., Dabney, W., Barreto, A., Van~de Wiele, T., Warde-Farley, D., and
  Mnih, V.
\newblock Fast task inference with variational intrinsic successor features.
\newblock \emph{arXiv preprint arXiv:1906.05030}, 2019.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020momentum}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  9729--9738, 2020.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and
  Girshick]{he2022masked}
He, K., Chen, X., Xie, S., Li, Y., Doll{\'a}r, P., and Girshick, R.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  16000--16009, 2022.

\bibitem[Hessel et~al.(2018)Hessel, Modayil, Van~Hasselt, Schaul, Ostrovski,
  Dabney, Horgan, Piot, Azar, and Silver]{hessel2018rainbow}
Hessel, M., Modayil, J., Van~Hasselt, H., Schaul, T., Ostrovski, G., Dabney,
  W., Horgan, D., Piot, B., Azar, M., and Silver, D.
\newblock Rainbow: Combining improvements in deep reinforcement learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem[Jaderberg et~al.(2016)Jaderberg, Mnih, Czarnecki, Schaul, Leibo,
  Silver, and Kavukcuoglu]{jaderberg2016reinforcement}
Jaderberg, M., Mnih, V., Czarnecki, W.~M., Schaul, T., Leibo, J.~Z., Silver,
  D., and Kavukcuoglu, K.
\newblock Reinforcement learning with unsupervised auxiliary tasks.
\newblock \emph{arXiv preprint arXiv:1611.05397}, 2016.

\bibitem[Kaelbling et~al.(1998)Kaelbling, Littman, and
  Cassandra]{kaelbling1998planning}
Kaelbling, L.~P., Littman, M.~L., and Cassandra, A.~R.
\newblock Planning and acting in partially observable stochastic domains.
\newblock \emph{Artificial intelligence}, 101\penalty0 (1-2):\penalty0 99--134,
  1998.

\bibitem[Kielak(2020)]{kielak2020recent}
Kielak, K.
\newblock Do recent advancements in model-based deep reinforcement learning
  really improve data efficiency?
\newblock \emph{arXiv preprint arXiv:2003.10181}, 2020.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Laskin et~al.(2020{\natexlab{a}})Laskin, Lee, Stooke, Pinto, Abbeel,
  and Srinivas]{laskin2020reinforcement}
Laskin, M., Lee, K., Stooke, A., Pinto, L., Abbeel, P., and Srinivas, A.
\newblock Reinforcement learning with augmented data.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2020{\natexlab{a}}.

\bibitem[Laskin et~al.(2020{\natexlab{b}})Laskin, Srinivas, and
  Abbeel]{laskin2020curl}
Laskin, M., Srinivas, A., and Abbeel, P.
\newblock Curl: Contrastive unsupervised representations for reinforcement
  learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5639--5650. PMLR, 2020{\natexlab{b}}.

\bibitem[Lee et~al.(2020{\natexlab{a}})Lee, Nagabandi, Abbeel, and
  Levine]{lee2020slac}
Lee, A.~X., Nagabandi, A., Abbeel, P., and Levine, S.
\newblock Stochastic latent actor-critic: Deep reinforcement learning with a
  latent variable model.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2020{\natexlab{a}}.

\bibitem[Lee et~al.(2020{\natexlab{b}})Lee, Fischer, Liu, Guo, Lee, Canny, and
  Guadarrama]{lee2020predictive}
Lee, K.-H., Fischer, I., Liu, A., Guo, Y., Lee, H., Canny, J., and Guadarrama,
  S.
\newblock Predictive information accelerates learning in {RL}.
\newblock \emph{arXiv preprint arXiv:2007.12401}, 2020{\natexlab{b}}.

\bibitem[Liu et~al.(2021)Liu, Zhang, Zhao, Qin, Zhu, Jian, Yu, and
  Liu]{liu2021returnbased}
Liu, G., Zhang, C., Zhao, L., Qin, T., Zhu, J., Jian, L., Yu, N., and Liu,
  T.-Y.
\newblock Return-based contrastive representation learning for reinforcement
  learning.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Liu \& Abbeel(2021{\natexlab{a}})Liu and Abbeel]{liu2021aps}
Liu, H. and Abbeel, P.
\newblock Aps: Active pretraining with successor features.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  6736--6747. PMLR, 2021{\natexlab{a}}.

\bibitem[Liu \& Abbeel(2021{\natexlab{b}})Liu and Abbeel]{liu2021behavior}
Liu, H. and Abbeel, P.
\newblock Behavior from the void: Unsupervised active pre-training.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 18459--18473, 2021{\natexlab{b}}.

\bibitem[Mazoure et~al.(2020)Mazoure, Tachet~des Combes, DOAN, Bachman, and
  Hjelm]{mazoure2020deep}
Mazoure, B., Tachet~des Combes, R., DOAN, T.~L., Bachman, P., and Hjelm, R.~D.
\newblock Deep reinforcement and infomax learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{mnih2013playing}
Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra,
  D., and Riedmiller, M.
\newblock Playing atari with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1312.5602}, 2013.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Oord, A. v.~d., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Pathak et~al.(2016)Pathak, Krahenbuhl, Donahue, Darrell, and
  Efros]{pathak2016context}
Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., and Efros, A.~A.
\newblock Context encoders: Feature learning by inpainting.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2536--2544, 2016.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, and
  Sutskever]{radford2018improving}
Radford, A., Narasimhan, K., Salimans, T., and Sutskever, I.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever,
  et~al.]{radford2019language}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 1\penalty0 (8):\penalty0 9, 2019.

\bibitem[Schaul et~al.(2015)Schaul, Quan, Antonoglou, and
  Silver]{schaul2015prioritized}
Schaul, T., Quan, J., Antonoglou, I., and Silver, D.
\newblock Prioritized experience replay.
\newblock \emph{arXiv preprint arXiv:1511.05952}, 2015.

\bibitem[Schrittwieser et~al.(2020)Schrittwieser, Antonoglou, Hubert, Simonyan,
  Sifre, Schmitt, Guez, Lockhart, Hassabis, Graepel,
  et~al.]{schrittwieser2020mastering}
Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L.,
  Schmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., et~al.
\newblock Mastering atari, go, chess and shogi by planning with a learned
  model.
\newblock \emph{Nature}, 588\penalty0 (7839):\penalty0 604--609, 2020.

\bibitem[Schwarzer et~al.(2021{\natexlab{a}})Schwarzer, Anand, Goel, Hjelm,
  Courville, and Bachman]{schwarzer2021dataefficient}
Schwarzer, M., Anand, A., Goel, R., Hjelm, R.~D., Courville, A., and Bachman,
  P.
\newblock Data-efficient reinforcement learning with self-predictive
  representations.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{a}}.

\bibitem[Schwarzer et~al.(2021{\natexlab{b}})Schwarzer, Rajkumar, Noukhovitch,
  Anand, Charlin, Hjelm, Bachman, and Courville]{schwarzer2021pretraining}
Schwarzer, M., Rajkumar, N., Noukhovitch, M., Anand, A., Charlin, L., Hjelm,
  R.~D., Bachman, P., and Courville, A.~C.
\newblock Pretraining representations for data-efficient reinforcement
  learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 12686--12699, 2021{\natexlab{b}}.

\bibitem[Shelhamer et~al.(2017)Shelhamer, Mahmoudieh, Argus, and
  Darrell]{Shelhamer2017LossII}
Shelhamer, E., Mahmoudieh, P., Argus, M., and Darrell, T.
\newblock Loss is its own reward: Self-supervision for reinforcement learning.
\newblock \emph{ArXiv}, abs/1612.07307, 2017.

\bibitem[Stooke et~al.(2020)Stooke, Lee, Abbeel, and
  Laskin]{stooke2020decoupling}
Stooke, A., Lee, K., Abbeel, P., and Laskin, M.
\newblock Decoupling representation learning from reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2009.08319}, 2020.

\bibitem[Sutton \& Barto(2018)Sutton and Barto]{sutton2018reinforcement}
Sutton, R.~S. and Barto, A.~G.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Tarvainen \& Valpola(2017)Tarvainen and Valpola]{tarvainen2017mean}
Tarvainen, A. and Valpola, H.
\newblock Mean teachers are better role models: Weight-averaged consistency
  targets improve semi-supervised deep learning results.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Tassa et~al.(2018)Tassa, Doron, Muldal, Erez, Li, Casas, Budden,
  Abdolmaleki, Merel, Lefrancq, et~al.]{tassa2018deepmind}
Tassa, Y., Doron, Y., Muldal, A., Erez, T., Li, Y., Casas, D. d.~L., Budden,
  D., Abdolmaleki, A., Merel, J., Lefrancq, A., et~al.
\newblock Deepmind control suite.
\newblock \emph{arXiv preprint arXiv:1801.00690}, 2018.

\bibitem[Van~Hasselt et~al.(2016)Van~Hasselt, Guez, and Silver]{van2016deep}
Van~Hasselt, H., Guez, A., and Silver, D.
\newblock Deep reinforcement learning with double q-learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~30, 2016.

\bibitem[van Hasselt et~al.(2019)van Hasselt, Hessel, and
  Aslanides]{van2019der}
van Hasselt, H.~P., Hessel, M., and Aslanides, J.
\newblock When to use parametric models in reinforcement learning?
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  5998--6008, 2017.

\bibitem[Wang et~al.(2016)Wang, Schaul, Hessel, Hasselt, Lanctot, and
  Freitas]{wang2016dueling}
Wang, Z., Schaul, T., Hessel, M., Hasselt, H., Lanctot, M., and Freitas, N.
\newblock Dueling network architectures for deep reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1995--2003. PMLR, 2016.

\bibitem[Wei et~al.(2022)Wei, Fan, Xie, Wu, Yuille, and
  Feichtenhofer]{wei2022masked}
Wei, C., Fan, H., Xie, S., Wu, C.-Y., Yuille, A., and Feichtenhofer, C.
\newblock Masked feature prediction for self-supervised visual pre-training.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  14668--14678, 2022.

\bibitem[Xie et~al.(2022)Xie, Zhang, Cao, Lin, Bao, Yao, Dai, and
  Hu]{xie2022simmim}
Xie, Z., Zhang, Z., Cao, Y., Lin, Y., Bao, J., Yao, Z., Dai, Q., and Hu, H.
\newblock Simmim: A simple framework for masked image modeling.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  9653--9663, 2022.

\bibitem[Yarats et~al.(2021{\natexlab{a}})Yarats, Fergus, Lazaric, and
  Pinto]{yarats2021reinforcement}
Yarats, D., Fergus, R., Lazaric, A., and Pinto, L.
\newblock Reinforcement learning with prototypical representations.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  11920--11931. PMLR, 2021{\natexlab{a}}.

\bibitem[Yarats et~al.(2021{\natexlab{b}})Yarats, Kostrikov, and
  Fergus]{yarats2021image}
Yarats, D., Kostrikov, I., and Fergus, R.
\newblock Image augmentation is all you need: Regularizing deep reinforcement
  learning from pixels.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{b}}.

\bibitem[Yarats et~al.(2021{\natexlab{c}})Yarats, Zhang, Kostrikov, Amos,
  Pineau, and Fergus]{yarats2021improving}
Yarats, D., Zhang, A., Kostrikov, I., Amos, B., Pineau, J., and Fergus, R.
\newblock Improving sample efficiency in model-free reinforcement learning from
  images.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pp.\  10674--10681, 2021{\natexlab{c}}.

\bibitem[Ye et~al.(2021)Ye, Liu, Kurutach, Abbeel, and Gao]{ye2021mastering}
Ye, W., Liu, S., Kurutach, T., Abbeel, P., and Gao, Y.
\newblock Mastering atari games with limited data.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Yu et~al.(2021)Yu, Lan, Zeng, Feng, Zhang, and
  Chen]{yu2021playvirtual}
Yu, T., Lan, C., Zeng, W., Feng, M., Zhang, Z., and Chen, Z.
\newblock Playvirtual: Augmenting cycle-consistent virtual trajectories for
  reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Zhang et~al.(2021)Zhang, McAllister, Calandra, Gal, and
  Levine]{zhang2021learning}
Zhang, A., McAllister, R.~T., Calandra, R., Gal, Y., and Levine, S.
\newblock Learning invariant representations for reinforcement learning without
  reconstruction.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Zhu et~al.(2020)Zhu, Xia, Wu, Deng, Zhou, Qin, and Li]{zhu2020masked}
Zhu, J., Xia, Y., Wu, L., Deng, J., Zhou, W., Qin, T., and Li, H.
\newblock Masked contrastive representation learning for reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:2010.07470}, 2020.

\bibitem[Ziebart et~al.(2008)Ziebart, Maas, Bagnell, Dey,
  et~al.]{ziebart2008maximum}
Ziebart, B.~D., Maas, A.~L., Bagnell, J.~A., Dey, A.~K., et~al.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In \emph{AAAI}, volume~8, pp.\  1433--1438. Chicago, IL, USA, 2008.

\bibitem[Łukasz Kaiser et~al.(2020)Łukasz Kaiser, Babaeizadeh, Miłos,
  Osiński, Campbell, Czechowski, Erhan, Finn, Kozakowski, Levine, Mohiuddin,
  Sepassi, Tucker, and Michalewski]{Kaiser2020Model}
Łukasz Kaiser, Babaeizadeh, M., Miłos, P., Osiński, B., Campbell, R.~H.,
  Czechowski, K., Erhan, D., Finn, C., Kozakowski, P., Levine, S., Mohiuddin,
  A., Sepassi, R., Tucker, G., and Michalewski, H.
\newblock Model based reinforcement learning for atari.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\end{thebibliography}
