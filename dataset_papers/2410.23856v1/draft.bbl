\begin{thebibliography}{114}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achiam et~al.(2023)Achiam, Adler, Agarwal, Ahmad, Akkaya, Aleman, Almeida, Altenschmidt, Altman, Anadkat, et~al.]{achiam2023gpt}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[Agrawal et~al.(2023)Agrawal, Mackey, and Kalai]{agrawal2023language}
Ayush Agrawal, Lester Mackey, and Adam~Tauman Kalai.
\newblock Do language models know when they're hallucinating references?
\newblock \emph{arXiv preprint arXiv:2305.18248}, 2023.

\bibitem[Aky{\"u}rek et~al.(2023)Aky{\"u}rek, Aky{\"u}rek, Madaan, Kalyan, Clark, Wijaya, and Tandon]{akyurek2023rl4f}
Afra~Feyza Aky{\"u}rek, Ekin Aky{\"u}rek, Aman Madaan, Ashwin Kalyan, Peter Clark, Derry Wijaya, and Niket Tandon.
\newblock Rl4f: Generating natural language feedback with reinforcement learning for repairing model outputs.
\newblock \emph{arXiv preprint arXiv:2305.08844}, 2023.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Chandler and Sweller(1991)]{chandler1991cognitive}
Paul Chandler and John Sweller.
\newblock Cognitive load theory and the format of instruction.
\newblock \emph{Cognition and instruction}, 1991.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual representations.
\newblock In \emph{ICML}, 2020.

\bibitem[Chen et~al.(2022)Chen, Zhang, Bian, Yang, Ma, Xie, Liu, Han, and Cheng]{chen2022ciga}
Yongqiang Chen, Yonggang Zhang, Yatao Bian, Han Yang, Kaili Ma, Binghui Xie, Tongliang Liu, Bo~Han, and James Cheng.
\newblock Learning causally invariant representations for out-of-distribution generalization on graphs.
\newblock In \emph{NeurIPS}, 2022.

\bibitem[Chen et~al.(2023)Chen, Huang, Zhou, Bian, Han, and Cheng]{chen2023understanding}
Yongqiang Chen, Wei Huang, Kaiwen Zhou, Yatao Bian, Bo~Han, and James Cheng.
\newblock Understanding and improving feature learning for out-of-distribution generalization.
\newblock In \emph{NeurIPS}, 2023.

\bibitem[Chia et~al.(2023)Chia, Chen, Tuan, Poria, and Bing]{chia2023contrastive}
Yew~Ken Chia, Guizhen Chen, Luu~Anh Tuan, Soujanya Poria, and Lidong Bing.
\newblock Contrastive chain-of-thought prompting.
\newblock \emph{arXiv preprint arXiv:2311.09277}, 2023.

\bibitem[Choi et~al.(2018)Choi, He, Iyyer, Yatskar, Yih, Choi, Liang, and Zettlemoyer]{choi2018quac}
Eunsol Choi, He~He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang, and Luke Zettlemoyer.
\newblock Quac: Question answering in context.
\newblock \emph{arXiv preprint arXiv:1808.07036}, 2018.

\bibitem[Chowdhery et~al.(2023)Chowdhery, Narang, Devlin, Bosma, Mishra, Roberts, Barham, Chung, Sutton, Gehrmann, et~al.]{chowdhery2023palm}
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung~Won Chung, Charles Sutton, Sebastian Gehrmann, et~al.
\newblock Palm: Scaling language modeling with pathways.
\newblock \emph{Journal of Machine Learning Research}, 2023.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser, Plappert, Tworek, Hilton, Nakano, et~al.]{cobbe2021training}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et~al.
\newblock Training verifiers to solve math word problems.
\newblock \emph{arXiv preprint arXiv:2110.14168}, 2021.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{cohen2019certified}
Jeremy Cohen, Elan Rosenfeld, and Zico Kolter.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock In \emph{ICML}, 2019.

\bibitem[Del~Vicario et~al.(2017)Del~Vicario, Scala, Caldarelli, Stanley, and Quattrociocchi]{del2017modeling}
Michela Del~Vicario, Antonio Scala, Guido Caldarelli, H~Eugene Stanley, and Walter Quattrociocchi.
\newblock Modeling confirmation bias and polarization.
\newblock \emph{Scientific reports}, 2017.

\bibitem[DeVore and Lorentz(1993)]{devore1993constructive}
Ronald~A DeVore and George~G Lorentz.
\newblock \emph{Constructive approximation}.
\newblock 1993.

\bibitem[Dong et~al.(2022)Dong, Li, Dai, Zheng, Wu, Chang, Sun, Xu, and Sui]{dong2022survey}
Qingxiu Dong, Lei Li, Damai Dai, Ce~Zheng, Zhiyong Wu, Baobao Chang, Xu~Sun, Jingjing Xu, and Zhifang Sui.
\newblock A survey for in-context learning.
\newblock \emph{arXiv preprint arXiv:2301.00234}, 2022.

\bibitem[Floridi and Chiriatti(2020)]{floridi2020gpt}
Luciano Floridi and Massimo Chiriatti.
\newblock Gpt-3: Its nature, scope, limits, and consequences.
\newblock \emph{Minds and Machines}, 2020.

\bibitem[Freeman et~al.(2023)Freeman, Culp, Parisi, Bileschi, Elsayed, Rizkowsky, Simpson, Alemi, Nova, Adlam, et~al.]{freeman2023frontier}
C~Daniel Freeman, Laura Culp, Aaron Parisi, Maxwell~L Bileschi, Gamaleldin~F Elsayed, Alex Rizkowsky, Isabelle Simpson, Alex Alemi, Azade Nova, Ben Adlam, et~al.
\newblock Frontier language models are not robust to adversarial arithmetic, or" what do i need to say so you agree 2+ 2= 5?
\newblock \emph{arXiv preprint arXiv:2311.07587}, 2023.

\bibitem[Gan and Mori(2023)]{gan2023sensitivity}
Chengguang Gan and Tatsunori Mori.
\newblock Sensitivity and robustness of large language models to prompt in japanese.
\newblock \emph{arXiv preprint arXiv:2305.08714}, 2023.

\bibitem[Gebru et~al.(2021)Gebru, Morgenstern, Vecchione, Vaughan, Wallach, Iii, and Crawford]{gebru2021datasheets}
Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer~Wortman Vaughan, Hanna Wallach, Hal~Daum{\'e} Iii, and Kate Crawford.
\newblock Datasheets for datasets.
\newblock \emph{Communications of the ACM}, 2021.

\bibitem[Gero et~al.(2023)Gero, Singh, Cheng, Naumann, Galley, Gao, and Poon]{gero2023self}
Zelalem Gero, Chandan Singh, Hao Cheng, Tristan Naumann, Michel Galley, Jianfeng Gao, and Hoifung Poon.
\newblock Self-verification improves few-shot clinical information extraction.
\newblock \emph{arXiv preprint arXiv:2306.00024}, 2023.

\bibitem[Gong et~al.(2021)Gong, Wang, Liu, Han, You, Yang, and Tao]{gong2021instance}
Chen Gong, Qizhou Wang, Tongliang Liu, Bo~Han, Jane You, Jian Yang, and Dacheng Tao.
\newblock Instance-dependent positive and unlabeled learning with labeling bias estimation.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2021.

\bibitem[Griffiths(2020)]{griffiths2020understanding}
Thomas~L Griffiths.
\newblock Understanding human intelligence through human limitations.
\newblock \emph{Trends in Cognitive Sciences}, 2020.

\bibitem[Han et~al.(2018)Han, Yao, Yu, Niu, Xu, Hu, Tsang, and Sugiyama]{han2018co}
Bo~Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi Sugiyama.
\newblock Co-teaching: Robust training of deep neural networks with extremely noisy labels.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Havrilla and Iyer(2024)]{havrilla2024understanding}
Alex Havrilla and Maia Iyer.
\newblock Understanding the effect of noise in llm training data with algorithmic chains of thought.
\newblock \emph{arXiv preprint arXiv:2402.04004}, 2024.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020momentum}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{CVPR}, 2020.

\bibitem[He et~al.(2024)He, Zeng, Huang, Chen, Xiao, He, Zhou, Liang, and Xiao]{he2024can}
Qianyu He, Jie Zeng, Wenhao Huang, Lina Chen, Jin Xiao, Qianxi He, Xunzhe Zhou, Jiaqing Liang, and Yanghua Xiao.
\newblock Can large language models understand real-world complex instructions?
\newblock In \emph{AAAI}, 2024.

\bibitem[Huang et~al.(2022)Huang, Gu, Hou, Wu, Wang, Yu, and Han]{huang2022selfimprove}
Jiaxin Huang, Shixiang~Shane Gu, Le~Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei Han.
\newblock Large language models can self-improve.
\newblock \emph{arXiv preprint arXiv:2210.11610}, 2022.

\bibitem[Huang et~al.(2024)Huang, Chen, Mishra, Zheng, Yu, Song, and Zhou]{huang2023large}
Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu~Steven Zheng, Adams~Wei Yu, Xinying Song, and Denny Zhou.
\newblock Large language models cannot self-correct reasoning yet.
\newblock In \emph{ICLR}, 2024.

\bibitem[Huang et~al.(2023)Huang, Yu, Ma, Zhong, Feng, Wang, Chen, Peng, Feng, Qin, et~al.]{huang2023survey}
Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et~al.
\newblock A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions.
\newblock \emph{arXiv preprint arXiv:2311.05232}, 2023.

\bibitem[Janis(2008)]{janis2008groupthink}
Irving~L Janis.
\newblock Groupthink.
\newblock \emph{IEEE Engineering Management Review}, 2008.

\bibitem[Jia and Liang(2017)]{jia2017adversarial}
Robin Jia and Percy Liang.
\newblock Adversarial examples for evaluating reading comprehension systems.
\newblock In \emph{EMNLP}, 2017.

\bibitem[Jiang et~al.(2024)Jiang, Sablayrolles, Roux, Mensch, Savary, Bamford, Chaplot, Casas, Hanna, Bressand, et~al.]{jiang2024mixtral}
Albert~Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra~Singh Chaplot, Diego de~las Casas, Emma~Bou Hanna, Florian Bressand, et~al.
\newblock Mixtral of experts.
\newblock \emph{arXiv preprint arXiv:2401.04088}, 2024.

\bibitem[Jiang et~al.(2023)Jiang, Wang, and Wang]{jiang2023selfevolve}
Shuyang Jiang, Yuhao Wang, and Yu~Wang.
\newblock Selfevolve: A code evolution framework via large language models.
\newblock \emph{arXiv preprint arXiv:2306.02907}, 2023.

\bibitem[Khosla et~al.(2020)Khosla, Teterwak, Wang, Sarna, Tian, Isola, Maschinot, Liu, and Krishnan]{khosla2020supervised}
Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce~Liu, and Dilip Krishnan.
\newblock Supervised contrastive learning.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Kim et~al.(2023)Kim, Baldi, and McAleer]{kim2023language}
Geunwoo Kim, Pierre Baldi, and Stephen McAleer.
\newblock Language models can solve computer tasks.
\newblock \emph{arXiv preprint arXiv:2303.17491}, 2023.

\bibitem[Kleijn and van~der Vaart(2012)]{kleijn2012bernstein}
BJK Kleijn and AW~van~der Vaart.
\newblock The bernstein-von-mises theorem under misspecification.
\newblock \emph{Electronic Journal of Statistics}, 2012.

\bibitem[Koh(2022)]{koh2022inversion}
Sin~Yee Koh.
\newblock The inversion of majority/minority at the de/reterritorialised urban higher education enclave: Xiamen university malaysia.
\newblock \emph{Urban Studies}, 2022.

\bibitem[Kojima et~al.(2022)Kojima, Gu, Reid, Matsuo, and Iwasawa]{kojima2022large}
Takeshi Kojima, Shixiang~Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa.
\newblock Large language models are zero-shot reasoners.
\newblock In \emph{NeurIPS}, 2022.

\bibitem[Koo et~al.(2023)Koo, Park, Lee, Seo, Eo, Moon, and Lim]{koo2023uncovering}
Seonmin Koo, Chanjun Park, Seolhwa Lee, Jaehyung Seo, Sugyeong Eo, Hyeonseok Moon, and Heuiseok Lim.
\newblock Uncovering the risks and drawbacks associated with the use of synthetic data for grammatical error correction.
\newblock \emph{IEEE Access}, 2023.

\bibitem[Lake and Baroni(2018)]{lake2018generalization}
Brenden Lake and Marco Baroni.
\newblock Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks.
\newblock In \emph{ICML}, 2018.

\bibitem[Lei et~al.(2023)Lei, Li, Wei, He, Huang, Zhao, and Liu]{lei2023s}
Fangyu Lei, Xiang Li, Yifan Wei, Shizhu He, Yiming Huang, Jun Zhao, and Kang Liu.
\newblock S $\hat{3}$ hqa: A three-stage approach for multi-hop text-table hybrid question answering.
\newblock \emph{arXiv preprint arXiv:2305.11725}, 2023.

\bibitem[Li et~al.(2023{\natexlab{a}})Li, Peng, and Zhang]{li2023self}
Miaoran Li, Baolin Peng, and Zhu Zhang.
\newblock Self-checker: Plug-and-play modules for fact-checking with large language models.
\newblock \emph{arXiv preprint arXiv:2305.14623}, 2023{\natexlab{a}}.

\bibitem[Li et~al.(2023{\natexlab{b}})Li, Zhou, Zhu, Yao, Liu, and Han]{li2023deepinception}
Xuan Li, Zhanke Zhou, Jianing Zhu, Jiangchao Yao, Tongliang Liu, and Bo~Han.
\newblock Deepinception: Hypnotize large language model to be jailbreaker.
\newblock \emph{arXiv preprint arXiv:2311.03191}, 2023{\natexlab{b}}.

\bibitem[Li et~al.(2023{\natexlab{c}})Li, Zhang, and Sun]{li2023metaagents}
Yuan Li, Yixuan Zhang, and Lichao Sun.
\newblock Metaagents: Simulating interactions of human behaviors for llm-based task-oriented coordination via collaborative generative agents.
\newblock \emph{arXiv preprint arXiv:2310.06500}, 2023{\natexlab{c}}.

\bibitem[Liang et~al.(2023)Liang, Liu, Zhou, Tu, Wen, Yang, Dong, and Liu]{liang2023knowledge}
Ke~Liang, Yue Liu, Sihang Zhou, Wenxuan Tu, Yi~Wen, Xihong Yang, Xiangjun Dong, and Xinwang Liu.
\newblock Knowledge graph contrastive learning based on relation-symmetrical structure.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering}, 2023.

\bibitem[Liang et~al.(2024)Liang, Meng, Liu, Liu, Tu, Wang, Zhou, Liu, Sun, and He]{liang2024survey}
Ke~Liang, Lingyuan Meng, Meng Liu, Yue Liu, Wenxuan Tu, Siwei Wang, Sihang Zhou, Xinwang Liu, Fuchun Sun, and Kunlun He.
\newblock A survey of knowledge graph reasoning on graph types: Static, dynamic, and multi-modal.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2024.

\bibitem[Liu et~al.(2023)Liu, Wu, Michael, Suhr, West, Koller, Swayamdipta, Smith, and Choi]{liu2023we}
Alisa Liu, Zhaofeng Wu, Julian Michael, Alane Suhr, Peter West, Alexander Koller, Swabha Swayamdipta, Noah~A Smith, and Yejin Choi.
\newblock We're afraid language models aren't modeling ambiguity.
\newblock \emph{arXiv preprint arXiv:2304.14399}, 2023.

\bibitem[Liu et~al.(2021{\natexlab{a}})Liu, Han, Liu, Gong, Niu, Zhou, Sugiyama, et~al.]{liu2021probabilistic}
Feng Liu, Bo~Han, Tongliang Liu, Chen Gong, Gang Niu, Mingyuan Zhou, Masashi Sugiyama, et~al.
\newblock Probabilistic margins for instance reweighting in adversarial training.
\newblock In \emph{NeurIPS}, 2021{\natexlab{a}}.

\bibitem[Liu et~al.(2021{\natexlab{b}})Liu, Shen, Zhang, Dolan, Carin, and Chen]{liu2021makes}
Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen.
\newblock What makes good in-context examples for gpt-$3 $?
\newblock \emph{arXiv preprint arXiv:2101.06804}, 2021{\natexlab{b}}.

\bibitem[Lu et~al.(2021)Lu, Bartolo, Moore, Riedel, and Stenetorp]{lu2021fantastically}
Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp.
\newblock Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity.
\newblock \emph{arXiv preprint arXiv:2104.08786}, 2021.

\bibitem[Madaan et~al.(2023)Madaan, Tandon, Gupta, Hallinan, Gao, Wiegreffe, Alon, Dziri, Prabhumoye, Yang, et~al.]{madaan2023self}
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et~al.
\newblock Self-refine: Iterative refinement with self-feedback.
\newblock \emph{arXiv preprint arXiv:2303.17651}, 2023.

\bibitem[Mayer(1977)]{mayer1977thinking}
Richard~E Mayer.
\newblock \emph{Thinking and problem solving: An introduction to human cognition and learning.}
\newblock Scott, Foresman, 1977.

\bibitem[Min et~al.(2022)Min, Lyu, Holtzman, Artetxe, Lewis, Hajishirzi, and Zettlemoyer]{min2022rethinking}
Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer.
\newblock Rethinking the role of demonstrations: What makes in-context learning work?
\newblock In \emph{EMNLP}, 2022.

\bibitem[Morewedge and Kahneman(2010)]{morewedge2010associative}
Carey~K Morewedge and Daniel Kahneman.
\newblock Associative processes in intuitive judgment.
\newblock \emph{Trends in cognitive sciences}, 2010.

\bibitem[Norris(2000)]{norris2000emotional}
Paul Norris.
\newblock \emph{Emotional reasoning}.
\newblock University of Massachusetts Amherst, 2000.

\bibitem[Pan et~al.(2023)Pan, Saxon, Xu, Nathani, Wang, and Wang]{pan2023automatically}
Liangming Pan, Michael Saxon, Wenda Xu, Deepak Nathani, Xinyi Wang, and William~Yang Wang.
\newblock Automatically correcting large language models: Surveying the landscape of diverse self-correction strategies.
\newblock \emph{arXiv preprint arXiv:2308.03188}, 2023.

\bibitem[Pandia and Ettinger(2021)]{pandia2021sorting}
Lalchand Pandia and Allyson Ettinger.
\newblock Sorting through the noise: Testing robustness of information processing in pre-trained language models.
\newblock In \emph{EMNLP}, 2021.

\bibitem[Paul et~al.(2023)Paul, Ismayilzada, Peyrard, Borges, Bosselut, West, and Faltings]{paul2023refiner}
Debjit Paul, Mete Ismayilzada, Maxime Peyrard, Beatriz Borges, Antoine Bosselut, Robert West, and Boi Faltings.
\newblock Refiner: Reasoning feedback on intermediate representations.
\newblock \emph{arXiv preprint arXiv:2304.01904}, 2023.

\bibitem[Perez et~al.(2021)Perez, Kiela, and Cho]{perez2021true}
Ethan Perez, Douwe Kiela, and Kyunghyun Cho.
\newblock True few-shot learning with language models.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever, et~al.]{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 2019.

\bibitem[Robey et~al.(2023)Robey, Wong, Hassani, and Pappas]{robey2023smoothllm}
Alexander Robey, Eric Wong, Hamed Hassani, and George~J Pappas.
\newblock Smoothllm: Defending large language models against jailbreaking attacks.
\newblock \emph{arXiv preprint arXiv:2310.03684}, 2023.

\bibitem[Rokicki et~al.(2014)Rokicki, Kociemba, Davidson, and Dethridge]{rokicki2014diameter}
Tomas Rokicki, Herbert Kociemba, Morley Davidson, and John Dethridge.
\newblock The diameter of the rubik's cube group is twenty.
\newblock \emph{SIAM REVIEW}, 2014.

\bibitem[Sambasivan et~al.(2021)Sambasivan, Kapania, Highfill, Akrong, Paritosh, and Aroyo]{sambasivan2021everyone}
Nithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, and Lora~M Aroyo.
\newblock “everyone wants to do the model work, not the data work”: Data cascades in high-stakes ai.
\newblock In \emph{CHI}, 2021.

\bibitem[Saparov and He(2022)]{saparov2022language}
Abulhair Saparov and He~He.
\newblock Language models are greedy reasoners: A systematic formal analysis of chain-of-thought.
\newblock \emph{arXiv preprint arXiv:2210.01240}, 2022.

\bibitem[Schaeffer et~al.(2023)Schaeffer, Miranda, and Koyejo]{schaeffer2023emergent}
Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo.
\newblock Are emergent abilities of large language models a mirage?
\newblock In \emph{NeurIPS}, 2023.

\bibitem[Scheurer et~al.(2023)Scheurer, Campos, Korbak, Chan, Chen, Cho, and Perez]{scheurer2023training}
J{\'e}r{\'e}my Scheurer, Jon~Ander Campos, Tomasz Korbak, Jun~Shern Chan, Angelica Chen, Kyunghyun Cho, and Ethan Perez.
\newblock Training language models with language feedback at scale.
\newblock \emph{arXiv preprint arXiv:2303.16755}, 2023.

\bibitem[Shi et~al.(2023)Shi, Chen, Misra, Scales, Dohan, Chi, Sch{\"a}rli, and Zhou]{shi2023large}
Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed~H Chi, Nathanael Sch{\"a}rli, and Denny Zhou.
\newblock Large language models can be easily distracted by irrelevant context.
\newblock In \emph{ICML}, 2023.

\bibitem[Shinn et~al.(2023)Shinn, Cassano, Gopinath, Narasimhan, and Yao]{shinn2023reflexion}
Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik~R Narasimhan, and Shunyu Yao.
\newblock Reflexion: Language agents with verbal reinforcement learning.
\newblock In \emph{NeurIPS}, 2023.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot, et~al.]{silver2016mastering}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{Nature}, 2016.

\bibitem[Sinha et~al.(2019)Sinha, Sodhani, Dong, Pineau, and Hamilton]{sinha2019clutrr}
Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, and William~L Hamilton.
\newblock Clutrr: A diagnostic benchmark for inductive reasoning from text.
\newblock \emph{arXiv preprint arXiv:1908.06177}, 2019.

\bibitem[Srivastava et~al.(2022)Srivastava, Rastogi, Rao, Shoeb, Abid, Fisch, Brown, Santoro, Gupta, Garriga-Alonso, et~al.]{srivastava2022beyond}
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal~Md Shoeb, Abubakar Abid, Adam Fisch, Adam~R Brown, Adam Santoro, Aditya Gupta, Adri{\`a} Garriga-Alonso, et~al.
\newblock Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.
\newblock \emph{arXiv preprint arXiv:2206.04615}, 2022.

\bibitem[Stacey et~al.(2024)Stacey, Cheng, Torr, Guigue, Driesen, Coca, Gaynor, and Johannsen]{stacey2024lucid}
Joe Stacey, Jianpeng Cheng, John Torr, Tristan Guigue, Joris Driesen, Alexandru Coca, Mark Gaynor, and Anders Johannsen.
\newblock Lucid: Llm-generated utterances for complex and interesting dialogues.
\newblock \emph{arXiv preprint arXiv:2403.00462}, 2024.

\bibitem[Tang et~al.(2023)Tang, Wang, He, Zhang, Pan, Wang, Zeng, Zhao, Shi, He, et~al.]{tang2023fusionai}
Zhenheng Tang, Yuxin Wang, Xin He, Longteng Zhang, Xinglin Pan, Qiang Wang, Rongfei Zeng, Kaiyong Zhao, Shaohuai Shi, Bingsheng He, et~al.
\newblock Fusionai: Decentralized training and deploying llms with massive consumer-level gpus.
\newblock \emph{arXiv preprint arXiv:2309.01172}, 2023.

\bibitem[Tang et~al.(2024)Tang, Kang, Yin, Pan, Wang, He, Wang, Zeng, Zhao, Shi, Zhou, Li, He, and Chu]{tang2024fusionllm}
Zhenheng Tang, Xueze Kang, Yiming Yin, Xinglin Pan, Yuxin Wang, Xin He, Qiang Wang, Rongfei Zeng, Kaiyong Zhao, Shaohuai Shi, Amelie~Chi Zhou, Bo~Li, Bingsheng He, and Xiaowen Chu.
\newblock Fusionllm: A decentralized llm training system on geo-distributed gpus with adaptive compression.
\newblock \emph{arXiv preprint arXiv:2410.12707}, 2024.

\bibitem[Team et~al.(2023)Team, Anil, Borgeaud, Wu, Alayrac, Yu, Soricut, Schalkwyk, Dai, Hauth, et~al.]{team2023gemini}
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew~M Dai, Anja Hauth, et~al.
\newblock Gemini: a family of highly capable multimodal models.
\newblock \emph{arXiv preprint arXiv:2312.11805}, 2023.

\bibitem[Thorstad(2023)]{thorstad2023cognitive}
David Thorstad.
\newblock Cognitive bias in large language models: Cautious optimism meets anti-panglossian meliorism.
\newblock \emph{arXiv preprint arXiv:2311.10932}, 2023.

\bibitem[Tian et~al.(2023)Tian, Zhu, Wang, Li, and Lan]{tian2023r3}
Qingyuan Tian, Hanlun Zhu, Lei Wang, Yang Li, and Yunshi Lan.
\newblock R3 prompting: Review, rephrase and resolve for chain-of-thought reasoning in large language models under noisy context prompting: Review, rephrase and resolve for chain-of-thought reasoning in large language models under noisy context.
\newblock In \emph{EMNLP}, 2023.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, et~al.]{touvron2023llama}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv:2307.09288}, 2023.

\bibitem[Tversky and Kahneman(1974)]{tversky1974judgment}
Amos Tversky and Daniel Kahneman.
\newblock Judgment under uncertainty: Heuristics and biases: Biases in judgments reveal some heuristics of thinking under uncertainty.
\newblock \emph{Science}, 1974.

\bibitem[Tyen et~al.(2023)Tyen, Mansoor, Chen, Mak, and C{\u{a}}rbune]{tyen2023llms}
Gladys Tyen, Hassan Mansoor, Peter Chen, Tony Mak, and Victor C{\u{a}}rbune.
\newblock Llms cannot find reasoning errors, but can correct them!
\newblock \emph{arXiv preprint arXiv:2311.08516}, 2023.

\bibitem[Valmeekam et~al.(2023)Valmeekam, Marquez, Sreedharan, and Kambhampati]{valmeekam2023planning}
Karthik Valmeekam, Matthew Marquez, Sarath Sreedharan, and Subbarao Kambhampati.
\newblock On the planning abilities of large language models-a critical investigation.
\newblock In \emph{NeurIPS}, 2023.

\bibitem[Wang et~al.(2023)Wang, Wei, Schuurmans, Le, Chi, Narang, Chowdhery, and Zhou]{wang2023self}
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed~Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou.
\newblock Self-consistency improves chain of thought reasoning in language models.
\newblock In \emph{ICLR}, 2023.

\bibitem[Wei et~al.(2022{\natexlab{a}})Wei, Tay, Bommasani, Raffel, Zoph, Borgeaud, Yogatama, Bosma, Zhou, Metzler, et~al.]{wei2022emergent}
Jason Wei, Yi~Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et~al.
\newblock Emergent abilities of large language models.
\newblock \emph{arXiv preprint arXiv:2206.07682}, 2022{\natexlab{a}}.

\bibitem[Wei et~al.(2022{\natexlab{b}})Wei, Wang, Schuurmans, Bosma, Xia, Chi, Le, Zhou, et~al.]{wei2022chain}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed~Chi, Quoc~V Le, Denny Zhou, et~al.
\newblock Chain-of-thought prompting elicits reasoning in large language models.
\newblock In \emph{NeurIPS}, 2022{\natexlab{b}}.

\bibitem[Wei et~al.(2023)Wei, Wei, Tay, Tran, Webson, Lu, Chen, Liu, Huang, Zhou, et~al.]{wei2023larger}
Jerry Wei, Jason Wei, Yi~Tay, Dustin Tran, Albert Webson, Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da~Huang, Denny Zhou, et~al.
\newblock Larger language models do in-context learning differently.
\newblock \emph{arXiv preprint arXiv:2303.03846}, 2023.

\bibitem[Wimmer and Shohamy(2012)]{wimmer2012preference}
G~Elliott Wimmer and Daphna Shohamy.
\newblock Preference by association: how memory mechanisms in the hippocampus bias decisions.
\newblock \emph{Science}, 2012.

\bibitem[Wu et~al.(2023)Wu, Qiu, Ross, Aky{\"u}rek, Chen, Wang, Kim, Andreas, and Kim]{wu2023reasoning}
Zhaofeng Wu, Linlu Qiu, Alexis Ross, Ekin Aky{\"u}rek, Boyuan Chen, Bailin Wang, Najoung Kim, Jacob Andreas, and Yoon Kim.
\newblock Reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks.
\newblock \emph{arXiv preprint arXiv:2307.02477}, 2023.

\bibitem[Xi et~al.(2023)Xi, Jin, Zhou, Zheng, Gao, Gui, Zhang, and Huang]{xi2023self}
Zhiheng Xi, Senjie Jin, Yuhao Zhou, Rui Zheng, Songyang Gao, Tao Gui, Qi~Zhang, and Xuanjing Huang.
\newblock Self-polish: Enhance reasoning in large language models via problem refinement.
\newblock \emph{arXiv preprint arXiv:2305.14497}, 2023.

\bibitem[Xie et~al.(2021)Xie, Raghunathan, Liang, and Ma]{xie2021explanation}
Sang~Michael Xie, Aditi Raghunathan, Percy Liang, and Tengyu Ma.
\newblock An explanation of in-context learning as implicit bayesian inference.
\newblock \emph{arXiv preprint arXiv:2111.02080}, 2021.

\bibitem[Yang et~al.(2023)Yang, Wang, Lu, Liu, Le, Zhou, and Chen]{yang2023large}
Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc~V Le, Denny Zhou, and Xinyun Chen.
\newblock Large language models as optimizers.
\newblock \emph{arXiv preprint arXiv:2309.03409}, 2023.

\bibitem[Yao et~al.(2023)Yao, Yu, Zhao, Shafran, Griffiths, Cao, and Narasimhan]{yao2024tree}
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan.
\newblock Tree of thoughts: Deliberate problem solving with large language models.
\newblock In \emph{NeurIPS}, 2023.

\bibitem[Ye et~al.(2023)Ye, Jo, Kim, Kim, Hwang, and Seo]{ye2023selfee}
Seonghyeon Ye, Yongrae Jo, Doyoung Kim, Sungdong Kim, Hyeonbin Hwang, and Minjoon Seo.
\newblock Selfee: Iterative self-revising llm empowered by self-feedback generation.
\newblock \emph{Blog post, May}, 2023.

\bibitem[Ye and Durrett(2022)]{ye2022unreliability}
Xi~Ye and Greg Durrett.
\newblock The unreliability of explanations in few-shot prompting for textual reasoning.
\newblock In \emph{NeurIPS}, 2022.

\bibitem[Yu et~al.(2024)Yu, He, Minervini, and Pan]{yu2024evaluating}
Simon Chi~Lok Yu, Jie He, Pasquale Minervini, and Jeff~Z Pan.
\newblock Evaluating the adversarial robustness of retrieval-based in-context learning for large language models.
\newblock \emph{arXiv preprint arXiv:2405.15984}, 2024.

\bibitem[Yu et~al.(2023)Yu, Zhang, Liang, Jiang, and Sabharwal]{yu2023improving}
Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, and Ashish Sabharwal.
\newblock Improving language models via plug-and-play retrieval feedback.
\newblock \emph{arXiv preprint arXiv:2305.14002}, 2023.

\bibitem[Zelikman et~al.(2022)Zelikman, Wu, Mu, and Goodman]{zelikman2022star}
Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah Goodman.
\newblock Star: Bootstrapping reasoning with reasoning.
\newblock In \emph{NeurIPS}, 2022.

\bibitem[Zeng et~al.(2023)Zeng, Xu, Zheng, and Huang]{zeng2023certified}
Jiehang Zeng, Jianhan Xu, Xiaoqing Zheng, and Xuanjing Huang.
\newblock Certified robustness to text adversarial attacks by randomized [mask].
\newblock \emph{Computational Linguistics}, 2023.

\bibitem[Zhang et~al.(2022)Zhang, Feng, and Tan]{zhang2022active}
Yiming Zhang, Shi Feng, and Chenhao Tan.
\newblock Active example selection for in-context learning.
\newblock \emph{arXiv preprint arXiv:2211.04486}, 2022.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Zhou, Yao, Chu, and Han]{zhang2023adaprop}
Yongqi Zhang, Zhanke Zhou, Quanming Yao, Xiaowen Chu, and Bo~Han.
\newblock Adaprop: Learning adaptive propagation for graph neural network based knowledge graph reasoning.
\newblock In \emph{SIGKDD}, 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Li, Cui, Cai, Liu, Fu, Huang, Zhao, Zhang, Chen, Wang, Luu, Bi, Shi, and Shi]{zhang2023hallucination}
Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu~Zhang, Yulong Chen, Longyue Wang, Anh~Tuan Luu, Wei Bi, Freda Shi, and Shuming Shi.
\newblock Siren's song in the ai ocean: A survey on hallucination in large language models.
\newblock \emph{arXiv preprint arXiv:2309.01219}, 2023{\natexlab{b}}.

\bibitem[Zhang et~al.(2023{\natexlab{c}})Zhang, Zhang, Hou, Fan, Li, Liu, Zhang, and Chang]{zhang2023certified}
Zhen Zhang, Guanhua Zhang, Bairu Hou, Wenqi Fan, Qing Li, Sijia Liu, Yang Zhang, and Shiyu Chang.
\newblock Certified robustness for large language models with self-denoising.
\newblock \emph{arXiv preprint arXiv:2307.07171}, 2023{\natexlab{c}}.

\bibitem[Zhang et~al.(2023{\natexlab{d}})Zhang, Zhang, Li, and Smola]{zhang2023automatic}
Zhuosheng Zhang, Aston Zhang, Mu~Li, and Alex Smola.
\newblock Automatic chain of thought prompting in large language models.
\newblock In \emph{ICLR}, 2023{\natexlab{d}}.

\bibitem[Zhao et~al.(2023{\natexlab{a}})Zhao, Chen, Yang, Liu, Deng, Cai, Wang, Yin, and Du]{zhao2023explainability}
Haiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, and Mengnan Du.
\newblock Explainability for large language models: A survey.
\newblock \emph{ACM Transactions on Intelligent Systems and Technology}, 2023{\natexlab{a}}.

\bibitem[Zhao et~al.(2023{\natexlab{b}})Zhao, Zhou, Li, Tang, Wang, Hou, Min, Zhang, Zhang, Dong, et~al.]{zhao2023survey}
Wayne~Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et~al.
\newblock A survey of large language models.
\newblock \emph{arXiv preprint arXiv:2303.18223}, 2023{\natexlab{b}}.

\bibitem[Zhao et~al.(2021)Zhao, Wallace, Feng, Klein, and Singh]{zhao2021calibrate}
Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh.
\newblock Calibrate before use: Improving few-shot performance of language models.
\newblock In \emph{ICML}, 2021.

\bibitem[Zheng and Saparov(2023)]{zheng2023noisy}
Hongyi Zheng and Abulhair Saparov.
\newblock Noisy exemplars make large language models more robust: A domain-agnostic behavioral analysis.
\newblock In \emph{EMNLP}, 2023.

\bibitem[Zheng et~al.(2023)Zheng, Chiang, Sheng, Zhuang, Wu, Zhuang, Lin, Li, Li, Xing, et~al.]{zheng2024judging}
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi~Lin, Zhuohan Li, Dacheng Li, Eric Xing, et~al.
\newblock Judging llm-as-a-judge with mt-bench and chatbot arena.
\newblock In \emph{NeurIPS}, 2023.

\bibitem[Zhou et~al.(2022{\natexlab{a}})Zhou, Sch{\"a}rli, Hou, Wei, Scales, Wang, Schuurmans, Cui, Bousquet, Le, et~al.]{zhou2022least}
Denny Zhou, Nathanael Sch{\"a}rli, Le~Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et~al.
\newblock Least-to-most prompting enables complex reasoning in large language models.
\newblock \emph{arXiv preprint arXiv:2205.10625}, 2022{\natexlab{a}}.

\bibitem[Zhou et~al.(2022{\natexlab{b}})Zhou, Muresanu, Han, Paster, Pitis, Chan, and Ba]{zhou2022large}
Yongchao Zhou, Andrei~Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba.
\newblock Large language models are human-level prompt engineers.
\newblock \emph{arXiv preprint arXiv:2211.01910}, 2022{\natexlab{b}}.

\bibitem[Zhou et~al.(2023{\natexlab{a}})Zhou, Yao, Liu, Guo, Yao, He, Wang, Zheng, and Han]{zhou2023combating}
Zhanke Zhou, Jiangchao Yao, Jiaxu Liu, Xiawei Guo, Quanming Yao, Li~He, Liang Wang, Bo~Zheng, and Bo~Han.
\newblock Combating bilateral edge noise for robust link prediction.
\newblock In \emph{NeurIPS}, 2023{\natexlab{a}}.

\bibitem[Zhou et~al.(2023{\natexlab{b}})Zhou, Zhou, Li, Yao, Yao, and Han]{zhou2023mcgra}
Zhanke Zhou, Chenyu Zhou, Xuan Li, Jiangchao Yao, Quanming Yao, and Bo~Han.
\newblock On strengthening and defending graph reconstruction attack with markov chain approximation.
\newblock In \emph{ICML}, 2023{\natexlab{b}}.

\bibitem[Zhou et~al.(2024)Zhou, Zhang, Yao, Yao, and Han]{zhou2024less}
Zhanke Zhou, Yongqi Zhang, Jiangchao Yao, Quanming Yao, and Bo~Han.
\newblock Less is more: One-shot subgraph reasoning on large-scale knowledge graphs.
\newblock In \emph{ICLR}, 2024.

\bibitem[Zhu et~al.(2024)Zhu, Moniz, Bhargava, Lu, Piraviperumal, Li, Zhang, Yu, and Tseng]{zhu2024large}
Yilun Zhu, Joel Ruben~Antony Moniz, Shruti Bhargava, Jiarui Lu, Dhivya Piraviperumal, Site Li, Yuan Zhang, Hong Yu, and Bo-Hsiang Tseng.
\newblock Can large language models understand context?
\newblock \emph{arXiv preprint arXiv:2402.00858}, 2024.

\end{thebibliography}
