@article{autonomous_car,
  title={An overview of recent progress in the study of distributed multi-agent coordination},
  author={Cao, Yongcan and Yu, Wenwu and Ren, Wei and Chen, Guanrong},
  journal={IEEE Transactions on Industrial informatics},
  volume={9},
  number={1},
  pages={427--438},
  year={2012},
  publisher={IEEE}
}

@article{MMI,
  title={A maximum mutual information framework for multi-agent reinforcement learning},
  author={Kim, Woojun and Jung, Whiyoung and Cho, Myungsik and Sung, Youngchul},
  journal={arXiv preprint arXiv:2006.02732},
  year={2020}
}

@article{online_game1,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{online_game2,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{robotic1,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@article{robotic2,
  title={Guided deep reinforcement learning for swarm systems},
  author={H{\"u}ttenrauch, Maximilian and {\v{S}}o{\v{s}}i{\'c}, Adrian and Neumann, Gerhard},
  journal={arXiv preprint arXiv:1709.06011},
  year={2017}
}


@incollection{Dec-POMDP,
  title={Decentralized pomdps},
  author={Oliehoek, Frans A},
  booktitle={Reinforcement Learning},
  pages={471--503},
  year={2012},
  publisher={Springer}
}

@inproceedings{IQL,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Tan, Ming},
  booktitle={Proceedings of the tenth international conference on machine learning},
  pages={330--337},
  year={1993}
}

@article{MADDPG,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, Pieter and Mordatch, Igor},
  journal={arXiv preprint arXiv:1706.02275},
  year={2017}
}

@inproceedings{COMA,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{VDN,
  title={Value-decomposition networks for cooperative multi-agent learning},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  journal={arXiv preprint arXiv:1706.05296},
  year={2017}
}

@inproceedings{QMIX,
  title={Qmix: Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning},
  pages={4295--4304},
  year={2018},
  organization={PMLR}
}

@inproceedings{QTRAN,
  title={Qtran: Learning to factorize with transformation for cooperative multi-agent reinforcement learning},
  author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
  booktitle={International Conference on Machine Learning},
  pages={5887--5896},
  year={2019},
  organization={PMLR}
}

@book{reward_shaping,
  title={Encyclopedia of machine learning},
  author={Sammut, Claude and Webb, Geoffrey I},
  year={2011},
  publisher={Springer Science \& Business Media}
}

@inproceedings{demonstration_RL,
  title={Guided Reinforcement Learning with Learned Skills},
  author={Pertsch, Karl and Lee, Youngwoon and Wu, Yue and Lim, Joseph J},
  booktitle={Self-Supervision for Reinforcement Learning Workshop-ICLR 2021},
  year={2021}
}

@article{diayn,
  title={Diversity is all you need: Learning skills without a reward function},
  author={Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.06070},
  year={2018}
}

@inproceedings{curious,
  title={CURIOUS: intrinsically motivated modular multi-goal reinforcement learning},
  author={Colas, C{\'e}dric and Fournier, Pierre and Chetouani, Mohamed and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  booktitle={International conference on machine learning},
  pages={1331--1340},
  year={2019},
  organization={PMLR}
}

@inproceedings{curiosity,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={International conference on machine learning},
  pages={2778--2787},
  year={2017},
  organization={PMLR}
}

@article{RND,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@article{remax,
  title={REMAX: Relational Representation for Multi-Agent Exploration},
  author={Ryu, Heechang and Shin, Hayong and Park, Jinkyoo},
  journal={arXiv preprint arXiv:2008.05214},
  year={2020}
}

@article{hdmarl,
  title={Hierarchical deep multiagent reinforcement learning with temporal abstraction},
  author={Tang, Hongyao and Hao, Jianye and Lv, Tangjie and Chen, Yingfeng and Zhang, Zongzhang and Jia, Hangtian and Ren, Chunxu and Zheng, Yan and Meng, Zhaopeng and Fan, Changjie and others},
  journal={arXiv preprint arXiv:1809.09332},
  year={2018}
}

@inproceedings{DQFD,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-second AAAI conference on artificial intelligence},
  year={2018}
}

@article{DDPGFD,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@article{HER,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1707.01495},
  year={2017}
}

@article{hdqn,
  title={Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation},
  author={Kulkarni, Tejas D and Narasimhan, Karthik and Saeedi, Ardavan and Tenenbaum, Josh},
  journal={Advances in neural information processing systems},
  volume={29},
  pages={3675--3683},
  year={2016}
}

@article{generate_subgoal,
  title={Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement Learning},
  author={Zhang, Tianren and Guo, Shangqi and Tan, Tian and Hu, Xiaolin and Chen, Feng},
  journal={arXiv preprint arXiv:2006.11485},
  year={2020}
}

@inproceedings{imagined_subgoal,
  title={Goal-conditioned reinforcement learning with imagined subgoals},
  author={Chane-Sane, Elliot and Schmid, Cordelia and Laptev, Ivan},
  booktitle={International Conference on Machine Learning},
  pages={1430--1440},
  year={2021},
  organization={PMLR}
}
@article{intrinsic_motivation,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  journal={Advances in neural information processing systems},
  volume={29},
  pages={1471--1479},
  year={2016}
}

@article{unreliable_intrinsic,
  title={Exploration with unreliable intrinsic reward in multi-agent reinforcement learning},
  author={B{\"o}hmer, Wendelin and Rashid, Tabish and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1906.02138},
  year={2019}
}

@inproceedings{cmae,
  title={Cooperative exploration for multi-agent deep reinforcement learning},
  author={Liu, Iou-Jen and Jain, Unnat and Yeh, Raymond A and Schwing, Alexander},
  booktitle={International Conference on Machine Learning},
  pages={6826--6836},
  year={2021},
  organization={PMLR}
}

@article{seac,
  title={Shared experience actor-critic for multi-agent reinforcement learning},
  author={Christianos, Filippos and Sch{\"a}fer, Lukas and Albrecht, Stefano V},
  journal={arXiv preprint arXiv:2006.07169},
  year={2020}
}

@article{hdmarl,
  title={Hierarchical deep multiagent reinforcement learning with temporal abstraction},
  author={Tang, Hongyao and Hao, Jianye and Lv, Tangjie and Chen, Yingfeng and Zhang, Zongzhang and Jia, Hangtian and Ren, Chunxu and Zheng, Yan and Meng, Zhaopeng and Fan, Changjie and others},
  journal={arXiv preprint arXiv:1809.09332},
  year={2018}
}

@article{LIIR,
  title={Liir: Learning individual intrinsic reward in multi-agent reinforcement learning},
  author={Du, Yali and Han, Lei and Fang, Meng and Liu, Ji and Dai, Tianhong and Tao, Dacheng},
  year={2019}
}

@article{GIIR,
  title={Generating individual intrinsic reward for cooperative multiagent reinforcement learning},
  author={Wu, Haolin and Li, Hui and Zhang, Jianwei and Wang, Zhuang and Zhang, Jianeng},
  journal={International Journal of Advanced Robotic Systems},
  volume={18},
  number={5},
  pages={17298814211044946},
  year={2021},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{mapping_state,
  title={Mapping state space using landmarks for universal goal reaching},
  author={Huang, Zhiao and Liu, Fangchen and Su, Hao},
  journal={arXiv preprint arXiv:1908.05451},
  year={2019}
}

@article{adjacency,
  title={Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement Learning},
  author={Zhang, Tianren and Guo, Shangqi and Tan, Tian and Hu, Xiaolin and Chen, Feng},
  journal={arXiv preprint arXiv:2006.11485},
  year={2020}
}

@article{laplacian,
  title={The laplacian in rl: Learning representations with efficient approximations},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1810.04586},
  year={2018}
}

@article{ARC,
  title={Learning actionable representations with goal-conditioned policies},
  author={Ghosh, Dibya and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:1811.07819},
  year={2018}
}

@article{policy_distillation,
  title={Policy distillation},
  author={Rusu, Andrei A and Colmenarejo, Sergio Gomez and Gulcehre, Caglar and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
  journal={arXiv preprint arXiv:1511.06295},
  year={2015}
}

@article{roma,
  title={Roma: Multi-agent reinforcement learning with emergent roles},
  author={Wang, Tonghan and Dong, Heng and Lesser, Victor and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2003.08039},
  year={2020}
}
@article{rode,
  title={Rode: Learning roles to decompose multi-agent tasks},
  author={Wang, Tonghan and Gupta, Tarun and Mahajan, Anuj and Peng, Bei and Whiteson, Shimon and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2010.01523},
  year={2020}
}

@article{hsd,
  title={Hierarchical cooperative multi-agent reinforcement learning with skill discovery},
  author={Yang, Jiachen and Borovikov, Igor and Zha, Hongyuan},
  journal={arXiv preprint arXiv:1912.03558},
  year={2019}
}

@article{maven,
  title={Maven: Multi-agent variational exploration},
  author={Mahajan, Anuj and Rashid, Tabish and Samvelyan, Mikayel and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1910.07483},
  year={2019}
}

@article{icql,
  title={Exploration with unreliable intrinsic reward in multi-agent reinforcement learning},
  author={B{\"o}hmer, Wendelin and Rashid, Tabish and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1906.02138},
  year={2019}
}

@article{dqn,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}
@inproceedings{MARL-IS,
  title={Communication in Multi-Agent Reinforcement Learning: Intention Sharing},
  author={Kim, Woojun and Park, Jongeui and Sung, Youngchul},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@book{Amaribook,
  title={Information geometry and its applications},
  author={Amari, Shun-ichi},
  volume={194},
  year={2016},
  publisher={Springer}
}
@inproceedings{drqn,
  title={Deep recurrent q-learning for partially observable mdps},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={2015 aaai fall symposium series},
  year={2015}
}
@article{gru,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.3555},
  year={2014}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%
@article{SpinningUp2018,
    author = {Achiam, Joshua},
    title = {{Spinning Up in Deep Reinforcement Learning}},
    year = {2018}
}

@article{2018Iqbal,
  title={Actor-attention-critic for multi-agent reinforcement learning},
  author={Iqbal, Shariq and Sha, Fei},
  journal={arXiv preprint arXiv:1810.02912},
  year={2018}
}

@inproceedings{2015mohamed,
  title={Variational information maximisation for intrinsically motivated reinforcement learning},
  author={Mohamed, Shakir and Rezende, Danilo J},
  booktitle={Proceedings of the 28th International Conference on Neural Information Processing Systems-Volume 2},
  pages={2125--2133},
  year={2015}
}

@inproceedings{maac,
  title={Actor-attention-critic for multi-agent reinforcement learning},
  author={Iqbal, Shariq and Sha, Fei},
  booktitle={International Conference on Machine Learning},
  pages={2961--2970},
  year={2019},
  organization={PMLR}
}


@book{Cover:book,
   title={Elements of Information Theory },
   author={Cover, T. M. and Thomas, J. A.},
   year={2006},
   publisher={Wiley}
}

@incollection{1994Littman,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={Machine learning proceedings 1994},
  pages={157--163},
  year={1994},
  publisher={Elsevier}
}



@inproceedings{2018zheng,
  title={Structured Exploration via Hierarchical Variational Policy Networks},
  author={Stephan Zheng and Yisong Yue},
  year={2018}
}

@inproceedings{2019Li,
  title={Efficient ridesharing order dispatching with mean field multi-agent reinforcement learning},
  author={Li, Minne and Qin, Zhiwei and Jiao, Yan and Yang, Yaodong and Wang, Jun and Wang, Chenxi and Wu, Guobin and Ye, Jieping},
  booktitle={The World Wide Web Conference},
  pages={983--994},
  year={2019}
}


@article{2019Jaques,
  title={Social influence as intrinsic motivation for multi-agent deep reinforcement learning},
  author={Jaques, Natasha and Lazaridou, Angeliki and Hughes, Edward and Gulcehre, Caglar and Ortega, Pedro A and Strouse, DJ and Leibo, Joel Z and De Freitas, Nando},
  journal={arXiv preprint arXiv:1810.08647},
  year={2018}
}

@article{2019Wang,
  title={Influence-based multi-agent exploration},
  author={Wang, Tonghan and Wang, Jianhao and Wu, Yi and Zhang, Chongjie},
  journal={arXiv preprint arXiv:1910.05512},
  year={2019}
}

@inproceedings{2019Mahajan2019,
  title={MAVEN: Multi-Agent Variational Exploration},
  author={Mahajan, Anuj and Rashid, Tabish and Samvelyan, Mikayel and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7611--7622},
  year={2019}
}

@article{2018Fujimoto,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Van Hoof, Herke and Meger, David},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}


@inproceedings{2018Strouse,
  title={Learning to share and hide intentions using information regularization},
  author={Strouse, DJ and Kleiman-Weiner, Max and Tenenbaum, Josh and Botvinick, Matt and Schwab, David J},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10249--10259},
  year={2018}
}


@article{2020Liu,
  title={Multi-Agent Interactions Modeling with Correlated Policies},
  author={Liu, Minghuan and Zhou, Ming and Zhang, Weinan and Zhuang, Yuzheng and Wang, Jun and Liu, Wulong and Yu, Yong},
  journal={arXiv preprint arXiv:2001.03415},
  year={2020}
}


@inproceedings{2019de,
  title={Multi-Agent Common Knowledge Reinforcement Learning},
  author={de Witt, Christian Schroeder and Foerster, Jakob and Farquhar, Gregory and Torr, Philip and B{\"o}hmer, Wendelin and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9924--9935},
  year={2019}
}


@article{2019Oroojlooyjadid,
  title={A review of cooperative multi-agent deep reinforcement learning},
  author={OroojlooyJadid, Afshin and Hajinezhad, Davood},
  journal={arXiv preprint arXiv:1908.03963},
  year={2019}
}


@article{2019Andriotis,
  title={Managing engineering systems with large state and action spaces through deep reinforcement learning},
  author={Andriotis, CP and Papakonstantinou, KG},
  journal={Reliability Engineering \& System Safety},
  volume={191},
  pages={106483},
  year={2019},
  publisher={Elsevier}
}

@article{2019son,
  title={Qtran: Learning to factorize with transformation for cooperative multi-agent reinforcement learning},
  author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
  journal={arXiv preprint arXiv:1905.05408},
  year={2019}
}

@article{2017sunehag,
  title={Value-decomposition networks for cooperative multi-agent learning},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  journal={arXiv preprint arXiv:1706.05296},
  year={2017}
}


@article{2018rashid,
  title={QMIX: monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1803.11485},
  year={2018}
}

@inproceedings{2016foerester,
  title={Learning to communicate with deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Assael, Ioannis Alexandros and De Freitas, Nando and Whiteson, Shimon},
  booktitle={Advances in neural information processing systems},
  pages={2137--2145},
  year={2016}
}


@inproceedings{2004Szer,
  title={Improving coordination with communication in multi-agent reinforcement learning},
  author={Szer, Daniel and Charpillet, Francois},
  booktitle={16th IEEE International Conference on Tools with Artificial Intelligence},
  pages={436--440},
  year={2004},
  organization={IEEE}
}


@article{2019Pesce,
  title={Improving Coordination in Small-Scale Multi-Agent Deep Reinforcement Learning through Memory-driven Communication},
  author={Pesce, Emanuele and Montana, Giovanni},
  journal={arXiv preprint arXiv:1901.03887},
  year={2019}
}

@inproceedings{2019Kim,
  title={Message-dropout: An efficient training method for multi-agent deep reinforcement learning},
  author={Kim, Woojun and Cho, Myungsik and Sung, Youngchul},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={6079--6086},
  year={2019}
}


@inproceedings{2013zhang,
  title={Coordinating multi-agent reinforcement learning with limited communication},
  author={Zhang, Chongjie and Lesser, Victor},
  booktitle={Proceedings of the 2013 international conference on Autonomous agents and multi-agent systems},
  pages={1101--1108},
  year={2013}
}

@book{1999vpe1,
  title={Real analysis: modern techniques and their applications},
  author={Folland, Gerald B},
  volume={40},
  year={1999},
  publisher={John Wiley \& Sons}
}

@article{2018vpe2,
  title={Fixed Point Theory in Metric Spaces},
  author={Agarwal, Praveen and Jleli, Mohamed and Samet, Bessem},
  journal={Recent Advances and Applications},
  year={2018},
  publisher={Springer}
}


@article{2019Wen,
  title={Probabilistic recursive reasoning for multi-agent reinforcement learning},
  author={Wen, Ying and Yang, Yaodong and Luo, Rui and Wang, Jun and Pan, Wei},
  journal={arXiv preprint arXiv:1901.09207},
  year={2019}
}


@inproceedings{2018Foerster,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob N and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  booktitle={Thirty-second AAAI conference on artificial intelligence},
  year={2018}
}


@inproceedings{MeanfieldMARL,
  title={Efficient ridesharing order dispatching with mean field multi-agent reinforcement learning},
  author={Li, Minne and Qin, Zhiwei and Jiao, Yan and Yang, Yaodong and Wang, Jun and Wang, Chenxi and Wu, Guobin and Ye, Jieping},
  booktitle={The World Wide Web Conference},
  pages={983--994},
  year={2019}
}

@inproceedings{1993Tan,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Tan, Ming},
  booktitle={Proceedings of the tenth international conference on machine learning},
  pages={330--337},
  year={1993}
}


@article{2016vanderpol,
  title={Coordinated deep reinforcement learners for traffic light control},
  author={Van der Pol, Elise and Oliehoek, Frans A},
  journal={Proceedings of Learning, Inference and Control of Multi-Agent Systems (at NIPS 2016)},
  year={2016}
}


@article{2018Haarnoja,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@inproceedings{2018Gupta,
  title={Cooperative multi-agent control using deep reinforcement learning},
  author={Gupta, Jayesh K and Egorov, Maxim and Kochenderfer, Mykel},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems},
  pages={66--83},
  year={2017},
  organization={Springer}
}

@inproceedings{2017Lowe,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, OpenAI Pieter and Mordatch, Igor},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6379--6390},
  year={2017}
}

@article{2015Mnih,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{2015Lillicrap,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{2016Shalev,
  title={Safe, multi-agent, reinforcement learning for autonomous driving},
  author={Shalev-Shwartz, Shai and Shammah, Shaked and Shashua, Amnon},
  journal={arXiv preprint arXiv:1610.03295},
  year={2016}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author =     "T. M. Mitchell",
  title =     "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year =     "1980",
  address =    "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}


@Book{MachineLearningI,
  editor =     "R. S. Michalski and J. G. Carbonell and T.
        M. Mitchell",
  title =     "Machine Learning: An Artificial Intelligence
        Approach, Vol. I",
  publisher =     "Tioga",
  year =     "1983",
  address =    "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2020}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author =     "A. L. Samuel",
  title =     "Some Studies in Machine Learning Using the Game of
        Checkers",
  journal =    "IBM Journal of Research and Development",
  year =    "1959",
  volume =    "3",
  number =    "3",
  pages =    "211--229"
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}
