\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{Anderson2018BottomUpAT}
Peter Anderson, X. He, Chris Buehler, Damien Teney, Mark Johnson, Stephen
  Gould, and Lei Zhang.
\newblock Bottom-up and top-down attention for image captioning and visual
  question answering.
\newblock In {\em CVPR}, 2018.

\bibitem{baevski2020wav2vec}
Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, and Michael Auli.
\newblock wav2vec 2.0: A framework for self-supervised learning of speech
  representations.
\newblock In {\em NeurIPS}, 2020.

\bibitem{beltagy2020longformer}
Iz Beltagy, Matthew~E Peters, and Arman Cohan.
\newblock Longformer: The long-document transformer.
\newblock {\em arXiv}, 2020.

\bibitem{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
  Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
  Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
  Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
  and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock In {\em NeurIPS}, 2020.

\bibitem{carion2020end}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em ECCV}, 2020.

\bibitem{caron2021emerging}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv{\'e} J{\'e}gou, Julien Mairal,
  Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock {\em arXiv}, 2021.

\bibitem{chen2021empirical}
Xinlei Chen, Saining Xie, and Kaiming He.
\newblock An empirical study of training self-supervised visual transformers.
\newblock {\em arXiv}, 2021.

\bibitem{chollet2017xception}
Fran{\c{c}}ois Chollet.
\newblock Xception: Deep learning with depthwise separable convolutions.
\newblock In {\em CVPR}, 2017.

\bibitem{choromanski2020rethinking}
Krzysztof Choromanski, Valerii Likhosherstov, David Dohan, Xingyou Song,
  Andreea Gane, Tamas Sarlos, Peter Hawkins, Jared Davis, Afroz Mohiuddin,
  Lukasz Kaiser, et~al.
\newblock Rethinking attention with performers.
\newblock In {\em ICLR}, 2021.

\bibitem{daras2020smyrf}
Giannis Daras, Nikita Kitaev, Augustus Odena, and Alexandros~G Dimakis.
\newblock Smyrf: Efficient attention using asymmetric clustering.
\newblock In {\em NeurIPS}, 2020.

\bibitem{d2021convit}
St{\'e}phane d'Ascoli, Hugo Touvron, Matthew Leavitt, Ari Morcos, Giulio
  Biroli, and Levent Sagun.
\newblock Convit: Improving vision transformers with soft convolutional
  inductive biases.
\newblock {\em arXiv}, 2021.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em CVPR}, 2009.

\bibitem{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em NAACL}, 2019.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em ICLR}, 2021.

\bibitem{esser2020taming}
Patrick Esser, Robin Rombach, and Bj{\"o}rn Ommer.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In {\em CVPR}, 2021.

\bibitem{fu2019dual}
Jun Fu, Jing Liu, Haijie Tian, Yong Li, Yongjun Bao, Zhiwei Fang, and Hanqing
  Lu.
\newblock Dual attention network for scene segmentation.
\newblock In {\em CVPR}, 2019.

\bibitem{gao2019dynamic}
Peng Gao, Zhengkai Jiang, Haoxuan You, Pan Lu, Steven~CH Hoi, Xiaogang Wang,
  and Hongsheng Li.
\newblock Dynamic fusion with intra-and inter-modality attention flow for
  visual question answering.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 6639--6648, 2019.

\bibitem{gao2019multi}
Peng Gao, Haoxuan You, Zhanpeng Zhang, Xiaogang Wang, and Hongsheng Li.
\newblock Multi-modality latent interaction network for visual question
  answering.
\newblock In {\em ICCV}, 2019.

\bibitem{gao2021fast}
Peng Gao, Minghang Zheng, Xiaogang Wang, Jifeng Dai, and Hongsheng Li.
\newblock Fast convergence of detr with spatially modulated co-attention.
\newblock {\em arXiv}, 2021.

\bibitem{geng2020dynamic}
Shijie Geng, Peng Gao, Moitreya Chatterjee, Chiori Hori, Jonathan~Le Roux,
  Yongfeng Zhang, Hongsheng Li, and Anoop Cherian.
\newblock Dynamic graph representation learning for video dialog via
  multi-modal shuffled transformers.
\newblock {\em arXiv preprint arXiv:2007.03848}, 2020.

\bibitem{geng2020character}
Shijie Geng, Ji Zhang, Zuohui Fu, Peng Gao, Hang Zhang, and Gerard de Melo.
\newblock Character matters: Video story understanding with character-aware
  relations.
\newblock {\em arXiv preprint arXiv:2005.08646}, 2020.

\bibitem{he2017mask}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Mask r-cnn.
\newblock In {\em ICCV}, 2017.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{Heo2021RethinkingSD}
Byeongho Heo, Sangdoo Yun, Dongyoon Han, Sanghyuk Chun, Junsuk Choe, and
  Seong~Joon Oh.
\newblock Rethinking spatial dimensions of vision transformers.
\newblock {\em arXiv}, 2021.

\bibitem{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural computation}, 9(8), 1997.

\bibitem{howard2017mobilenets}
Andrew~G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang,
  Tobias Weyand, Marco Andreetto, and Hartwig Adam.
\newblock Mobilenets: Efficient convolutional neural networks for mobile vision
  applications.
\newblock {\em arXiv}, 2017.

\bibitem{hu2018relation}
Han Hu, Jiayuan Gu, Zheng Zhang, Jifeng Dai, and Yichen Wei.
\newblock Relation networks for object detection.
\newblock In {\em CVPR}, 2018.

\bibitem{hu2018squeeze}
Jie Hu, Li Shen, and Gang Sun.
\newblock Squeeze-and-excitation networks.
\newblock In {\em CVPR}, 2018.

\bibitem{huang2019ccnet}
Zilong Huang, Xinggang Wang, Lichao Huang, Chang Huang, Yunchao Wei, and Wenyu
  Liu.
\newblock Ccnet: Criss-cross attention for semantic segmentation.
\newblock In {\em ICCV}, 2019.

\bibitem{kaiser2017depthwise}
Lukasz Kaiser, Aidan~N Gomez, and Francois Chollet.
\newblock Depthwise separable convolutions for neural machine translation.
\newblock {\em arXiv}, 2017.

\bibitem{katharopoulos2020transformers}
Angelos Katharopoulos, Apoorv Vyas, Nikolaos Pappas, and Fran{\c{c}}ois
  Fleuret.
\newblock Transformers are rnns: Fast autoregressive transformers with linear
  attention.
\newblock In {\em ICML}, 2020.

\bibitem{kitaev2020reformer}
Nikita Kitaev, {\L}ukasz Kaiser, and Anselm Levskaya.
\newblock Reformer: The efficient transformer.
\newblock In {\em ICLR}, 2020.

\bibitem{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock {\em NeurIPS}, 2012.

\bibitem{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE}, 86(11), 1998.

\bibitem{li2021involution}
Duo Li, Jie Hu, Changhu Wang, Xiangtai Li, Qi She, Lei Zhu, Tong Zhang, and
  Qifeng Chen.
\newblock Involution: Inverting the inherence of convolution for visual
  recognition.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12321--12330, 2021.

\bibitem{Li2021LocalViTBL}
Yawei Li, Kai Zhang, Jiezhang Cao, R. Timofte, and L. Gool.
\newblock Localvit: Bringing locality to vision transformers.
\newblock {\em arXiv}, 2021.

\bibitem{lin2017focal}
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
\newblock Focal loss for dense object detection.
\newblock In {\em ICCV}, 2017.

\bibitem{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em ECCV}, 2014.

\bibitem{liu2021multimodal}
Yicheng Liu, Jinghuai Zhang, Liangji Fang, Qinhong Jiang, and Bolei Zhou.
\newblock Multimodal motion prediction with stacked transformers.
\newblock In {\em CVPR}, 2021.

\bibitem{liu2021swin}
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock {\em arXiv}, 2021.

\bibitem{oord2017neural}
Aaron van~den Oord, Oriol Vinyals, and Koray Kavukcuoglu.
\newblock Neural discrete representation learning.
\newblock In {\em NeurIPS}, 2017.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  Gretchen Krueger, and Ilya Sutskever.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock {\em arXiv}, 2021.

\bibitem{radford2015unsupervised}
Alec Radford, Luke Metz, and Soumith Chintala.
\newblock Unsupervised representation learning with deep convolutional
  generative adversarial networks.
\newblock {\em arXiv}, 2015.

\bibitem{radosavovic2020designing}
Ilija Radosavovic, Raj~Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr
  Doll{\'a}r.
\newblock Designing network design spaces.
\newblock In {\em CVPR}, 2020.

\bibitem{rajpurkar2016squad}
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang.
\newblock Squad: 100,000+ questions for machine comprehension of text.
\newblock {\em arXiv}, 2016.

\bibitem{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In {\em ICLR}, 2015.

\bibitem{srinivas2021bottleneck}
Aravind Srinivas, Tsung-Yi Lin, Niki Parmar, Jonathon Shlens, Pieter Abbeel,
  and Ashish Vaswani.
\newblock Bottleneck transformers for visual recognition.
\newblock {\em arXiv}, 2021.

\bibitem{szegedy2015going}
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
  Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
\newblock Going deeper with convolutions.
\newblock In {\em CVPR}, 2015.

\bibitem{tan2019efficientnet}
Mingxing Tan and Quoc Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In {\em ICML}, 2019.

\bibitem{Tan2021EfficientNetV2SM}
Mingxing Tan and Quoc~V. Le.
\newblock Efficientnetv2: Smaller models and faster training.
\newblock {\em arXiv}, 2021.

\bibitem{tay2021synthesizer}
Yi Tay, Dara Bahri, Donald Metzler, Da-Cheng Juan, Zhe Zhao, and Che Zheng.
\newblock Synthesizer: Rethinking self-attention for transformer models.
\newblock In {\em International Conference on Machine Learning}, pages
  10183--10192. PMLR, 2021.

\bibitem{tolstikhin2021mlpmixer}
Ilya Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai,
  Thomas Unterthiner, Jessica Yung, Daniel Keysers, Jakob Uszkoreit, Mario
  Lucic, and Alexey Dosovitskiy.
\newblock Mlp-mixer: An all-mlp architecture for vision.
\newblock {\em arXiv}, 2021.

\bibitem{touvron2021resmlp}
Hugo Touvron, Piotr Bojanowski, Mathilde Caron, Matthieu Cord, Alaaeldin
  El-Nouby, Edouard Grave, Armand Joulin, Gabriel Synnaeve, Jakob Verbeek, and
  Herv{\'e} J{\'e}gou.
\newblock Resmlp: Feedforward networks for image classification with
  data-efficient training.
\newblock {\em arXiv}, 2021.

\bibitem{touvron2020training}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv{\'e} J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock {\em arXiv}, 2020.

\bibitem{Vaswani2021ScalingLS}
Ashish Vaswani, Prajit Ramachandran, A. Srinivas, Niki Parmar, Blake~A.
  Hechtman, and Jonathon Shlens.
\newblock Scaling local self-attention for parameter efficient visual
  backbones.
\newblock {\em arXiv}, 2021.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, 2017.

\bibitem{vyas2020fast}
Apoorv Vyas, Angelos Katharopoulos, and Fran{\c{c}}ois Fleuret.
\newblock Fast transformers with clustered attention.
\newblock In {\em NeurIPS}, 2020.

\bibitem{wang2018glue}
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel~R
  Bowman.
\newblock Glue: A multi-task benchmark and analysis platform for natural
  language understanding.
\newblock {\em arXiv}, 2018.

\bibitem{wang2020linformer}
Sinong Wang, Belinda Li, Madian Khabsa, Han Fang, and Hao Ma.
\newblock Linformer: Self-attention with linear complexity.
\newblock {\em arXiv}, 2020.

\bibitem{wang2021pyramid}
Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong
  Lu, Ping Luo, and Ling Shao.
\newblock Pyramid vision transformer: A versatile backbone for dense prediction
  without convolutions.
\newblock {\em arXiv}, 2021.

\bibitem{wang2018non}
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.
\newblock Non-local neural networks.
\newblock In {\em CVPR}, 2018.

\bibitem{wu2019pay}
Felix Wu, Angela Fan, Alexei Baevski, Yann~N Dauphin, and Michael Auli.
\newblock Pay less attention with lightweight and dynamic convolutions.
\newblock In {\em ICLR}, 2019.

\bibitem{xie2017aggregated}
Saining Xie, Ross Girshick, Piotr Doll{\'a}r, Zhuowen Tu, and Kaiming He.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In {\em CVPR}, 2017.

\bibitem{Xu2021CoScaleCI}
Weijian Xu, Yifan Xu, Tyler Chang, and Zhuowen Tu.
\newblock Co-scale conv-attentional image transformers.
\newblock {\em arXiv}, 2021.

\bibitem{yang2020transpose}
Sen Yang, Zhibin Quan, Mu Nie, and Wankou Yang.
\newblock Transpose: Towards explainable human pose estimation by transformer.
\newblock {\em arXiv}, 2020.

\bibitem{yuan2021incorporating}
Kun Yuan, Shaopeng Guo, Ziwei Liu, Aojun Zhou, Fengwei Yu, and Wei Wu.
\newblock Incorporating convolution designs into visual transformers.
\newblock {\em arXiv}, 2021.

\bibitem{yuan2019object}
Yuhui Yuan, Xilin Chen, and Jingdong Wang.
\newblock Object-contextual representations for semantic segmentation.
\newblock In {\em ECCV}, 2020.

\bibitem{zaheer2020big}
Manzil Zaheer, Guru Guruganesh, Avinava Dubey, Joshua Ainslie, Chris Alberti,
  Santiago Ontanon, Philip Pham, Anirudh Ravula, Qifan Wang, Li Yang, et~al.
\newblock Big bird: Transformers for longer sequences.
\newblock In {\em NeurIPS}, 2020.

\bibitem{Zhang2021MultiScaleVL}
Pengchuan Zhang, Xiyang Dai, Jianwei Yang, Bin Xiao, Lu Yuan, Lei Zhang, and
  Jianfeng Gao.
\newblock Multi-scale vision longformer: A new vision transformer for
  high-resolution image encoding.
\newblock {\em arXiv}, 2021.

\bibitem{zhang2021rest}
Qinglong Zhang and Yubin Yang.
\newblock Rest: An efficient transformer for visual recognition.
\newblock {\em arXiv preprint arXiv:2105.13677}, 2021.

\bibitem{zhao2019muse}
Guangxiang Zhao, Xu Sun, Jingjing Xu, Zhiyuan Zhang, and Liangchen Luo.
\newblock Muse: Parallel multi-scale attention for sequence to sequence
  learning.
\newblock {\em arXiv preprint arXiv:1911.09483}, 2019.

\bibitem{zhao2021proto}
Zelin Zhao, Karan Samel, Binghong Chen, and Le Song.
\newblock Proto: Program-guided transformer for program-guided tasks.
\newblock {\em arXiv preprint arXiv:2110.00804}, 2021.

\bibitem{zheng2020end}
Minghang Zheng, Peng Gao, Xiaogang Wang, Hongsheng Li, and Hao Dong.
\newblock End-to-end object detection with adaptive clustering transformer.
\newblock {\em arXiv}, 2020.

\bibitem{zheng2020rethinking}
Sixiao Zheng, Jiachen Lu, Hengshuang Zhao, Xiatian Zhu, Zekun Luo, Yabiao Wang,
  Yanwei Fu, Jianfeng Feng, Tao Xiang, Philip H.~S. Torr, and Li Zhang.
\newblock Rethinking semantic segmentation from a sequence-to-sequence
  perspective with transformers.
\newblock In {\em CVPR}, 2021.

\bibitem{zhu2020deformable}
Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai.
\newblock Deformable detr: Deformable transformers for end-to-end object
  detection.
\newblock In {\em ICLR}, 2021.

\bibitem{zhu2019asymmetric}
Zhen Zhu, Mengde Xu, Song Bai, Tengteng Huang, and Xiang Bai.
\newblock Asymmetric non-local neural networks for semantic segmentation.
\newblock In {\em ICCV}, 2019.

\end{thebibliography}
