\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[gra(2021)]{graham2021levit}
{LeViT}: a vision transformer in convnet's clothing for faster inference.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 12259--12269, 2021.

\bibitem[Antoniou et~al.(2017)Antoniou, Storkey, and Edwards]{antoniou2017data}
A.~Antoniou, A.~Storkey, and H.~Edwards.
\newblock Data augmentation generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1711.04340}, 2017.

\bibitem[Bloem-Reddy and Teh(2020)]{bloem2020probabilistic}
B.~Bloem-Reddy and Y.~W. Teh.
\newblock Probabilistic symmetries and invariant neural networks.
\newblock \emph{J. Mach. Learn. Res.}, 21:\penalty0 90--1, 2020.

\bibitem[Caron et~al.(2021)Caron, Touvron, Misra, J\'egou, Mairal, Bojanowski,
  and Joulin]{caron2021emerging}
M.~Caron, H.~Touvron, I.~Misra, H.~J\'egou, J.~Mairal, P.~Bojanowski, and
  A.~Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In \emph{Proceedings of the International Conference on Computer
  Vision (ICCV)}, 2021.

\bibitem[Chen et~al.(2019)Chen, Dobriban, and Lee]{chen2019invariance}
S.~Chen, E.~Dobriban, and J.~H. Lee.
\newblock Invariance reduces variance: Understanding data augmentation in deep
  learning and beyond.
\newblock 2019.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Dobriban, and Lee]{chen2020group}
S.~Chen, E.~Dobriban, and J.~Lee.
\newblock A group-theoretic framework for data augmentation.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 21321--21333, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Norouzi, and
  Hinton]{chen2020simple}
T.~Chen, S.~Kornblith, M.~Norouzi, and G.~Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International conference on machine learning}, pages
  1597--1607. PMLR, 2020{\natexlab{b}}.

\bibitem[Cobb et~al.(2020)Cobb, Wallis, Mavor-Parker, Marignier, Price,
  d'Avezac, and McEwen]{cobb2020efficient}
O.~J. Cobb, C.~G. Wallis, A.~N. Mavor-Parker, A.~Marignier, M.~A. Price,
  M.~d'Avezac, and J.~D. McEwen.
\newblock Efficient generalized spherical {CNN}s.
\newblock \emph{arXiv preprint arXiv:2010.11661}, 2020.

\bibitem[Cohen and Welling(2016{\natexlab{a}})]{cohen2016group}
T.~Cohen and M.~Welling.
\newblock Group equivariant convolutional networks.
\newblock In \emph{International conference on machine learning}, pages
  2990--2999. PMLR, 2016{\natexlab{a}}.

\bibitem[Cohen and Welling(2016{\natexlab{b}})]{cohen2016steerable}
T.~S. Cohen and M.~Welling.
\newblock Steerable {CNN}s.
\newblock \emph{arXiv preprint arXiv:1612.08498}, 2016{\natexlab{b}}.

\bibitem[Cohen et~al.(2018)Cohen, Geiger, K{\"o}hler, and
  Welling]{cohen2018spherical}
T.~S. Cohen, M.~Geiger, J.~K{\"o}hler, and M.~Welling.
\newblock Spherical {CNN}s.
\newblock \emph{arXiv preprint arXiv:1801.10130}, 2018.

\bibitem[Cubuk et~al.(2018)Cubuk, Zoph, Mane, Vasudevan, and
  Le]{cubuk2018autoaugment}
E.~D. Cubuk, B.~Zoph, D.~Mane, V.~Vasudevan, and Q.~V. Le.
\newblock Autoaugment: Learning augmentation policies from data.
\newblock \emph{arXiv preprint arXiv:1805.09501}, 2018.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{imagenet_cvpr09}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock {ImageNet: A Large-Scale Hierarchical Image Database}.
\newblock In \emph{CVPR09}, 2009.

\bibitem[Deng(2012)]{deng2012mnist}
L.~Deng.
\newblock The {MNIST} database of handwritten digit images for machine learning
  research.
\newblock \emph{IEEE Signal Processing Magazine}, 29\penalty0 (6):\penalty0
  141--142, 2012.

\bibitem[Dummit and Foote(2004)]{dummit2004abstract}
D.~S. Dummit and R.~M. Foote.
\newblock \emph{Abstract algebra}, volume~3.
\newblock Wiley Hoboken, 2004.

\bibitem[Esteves et~al.(2018)Esteves, Allen-Blanchette, Makadia, and
  Daniilidis]{esteves2018learning}
C.~Esteves, C.~Allen-Blanchette, A.~Makadia, and K.~Daniilidis.
\newblock Learning {SO}(3) equivariant representations with spherical {{CNN}}s.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 52--68, 2018.

\bibitem[Folland(1999)]{folland1999real}
G.~B. Folland.
\newblock \emph{Real analysis: modern techniques and their applications},
  volume~40.
\newblock John Wiley \& Sons, 1999.

\bibitem[Fuchs et~al.(2020)Fuchs, Worrall, Fischer, and Welling]{fuchs2020se}
F.~Fuchs, D.~Worrall, V.~Fischer, and M.~Welling.
\newblock {SE}(3)-transformers: {3D} roto-translation equivariant attention
  networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 1970--1981, 2020.

\bibitem[Hauberg et~al.(2016)Hauberg, Freifeld, Larsen, Fisher, and
  Hansen]{hauberg2016dreaming}
S.~Hauberg, O.~Freifeld, A.~B.~L. Larsen, J.~Fisher, and L.~Hansen.
\newblock Dreaming more data: Class-dependent distributions over
  diffeomorphisms for learned data augmentation.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 342--350.
  PMLR, 2016.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and
  Weinberger]{huang2017densely}
G.~Huang, Z.~Liu, L.~Van Der~Maaten, and K.~Q. Weinberger.
\newblock Densely connected convolutional networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4700--4708, 2017.

\bibitem[Hutchinson et~al.(2021)Hutchinson, Le~Lan, Zaidi, Dupont, Teh, and
  Kim]{hutchinson2021lietransformer}
M.~J. Hutchinson, C.~Le~Lan, S.~Zaidi, E.~Dupont, Y.~W. Teh, and H.~Kim.
\newblock Lietransformer: Equivariant self-attention for {Lie} groups.
\newblock In \emph{International Conference on Machine Learning}, pages
  4533--4543. PMLR, 2021.

\bibitem[Jacobsen et~al.(2018)Jacobsen, Behrmann, Zemel, and
  Bethge]{jacobsen2018excessive}
J.-H. Jacobsen, J.~Behrmann, R.~Zemel, and M.~Bethge.
\newblock Excessive invariance causes adversarial vulnerability.
\newblock \emph{arXiv preprint arXiv:1811.00401}, 2018.

\bibitem[Kamath et~al.(2019)Kamath, Deshpande, and
  Subrahmanyam]{kamath2019invariance}
S.~Kamath, A.~Deshpande, and K.~Subrahmanyam.
\newblock Invariance vs robustness of neural networks.
\newblock 2019.

\bibitem[Kaur et~al.(2022)Kaur, Jha, Roy, Park, Dobriban, Sokolsky, and
  Lee]{kaur2022idecode}
R.~Kaur, S.~Jha, A.~Roy, S.~Park, E.~Dobriban, O.~Sokolsky, and I.~Lee.
\newblock idecode: In-distribution equivariance for conformal
  out-of-distribution detection, 2022.

\bibitem[Kolesnikov et~al.(2020)Kolesnikov, Beyer, Zhai, Puigcerver, Yung,
  Gelly, and Houlsby]{kolesnikov2020big}
A.~Kolesnikov, L.~Beyer, X.~Zhai, J.~Puigcerver, J.~Yung, S.~Gelly, and
  N.~Houlsby.
\newblock Big transfer ({BiT}): General visual representation learning.
\newblock In \emph{European conference on computer vision}, pages 491--507.
  Springer, 2020.

\bibitem[Kondor and Trivedi(2018)]{kondor2018generalization}
R.~Kondor and S.~Trivedi.
\newblock On the generalization of equivariance and convolution in neural
  networks to the action of compact groups.
\newblock In \emph{International Conference on Machine Learning}, pages
  2747--2755. PMLR, 2018.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
A.~Krizhevsky, G.~Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{10.5555/2999134.2999257}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Proceedings of the 25th International Conference on Neural
  Information Processing Systems - Volume 1}, NIPS'12, page 1097â€“1105, Red
  Hook, NY, USA, 2012. Curran Associates Inc.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and Tenenbaum]{lake2015human}
B.~M. Lake, R.~Salakhutdinov, and J.~B. Tenenbaum.
\newblock Human-level concept learning through probabilistic program induction.
\newblock \emph{Science}, 350\penalty0 (6266):\penalty0 1332--1338, 2015.

\bibitem[Lam et~al.(2018)Lam, Kuzma, McGee, Dooley, Laielli, Klaric, Bulatov,
  and McCord]{lam2018xview}
D.~Lam, R.~Kuzma, K.~McGee, S.~Dooley, M.~Laielli, M.~Klaric, Y.~Bulatov, and
  B.~McCord.
\newblock {xView}: Objects in context in overhead imagery.
\newblock \emph{arXiv preprint arXiv:1802.07856}, 2018.

\bibitem[LeCun et~al.(1999)LeCun, Haffner, Bottou, and Bengio]{lecun1999object}
Y.~LeCun, P.~Haffner, L.~Bottou, and Y.~Bengio.
\newblock Object recognition with gradient-based learning.
\newblock In \emph{Shape, contour and grouping in computer vision}, pages
  319--345. Springer, 1999.

\bibitem[Lee et~al.(2019)Lee, Lee, Kim, Kosiorek, Choi, and
  Teh]{pmlr-v97-lee19d}
J.~Lee, Y.~Lee, J.~Kim, A.~Kosiorek, S.~Choi, and Y.~W. Teh.
\newblock Set transformer: A framework for attention-based
  permutation-invariant neural networks.
\newblock In K.~Chaudhuri and R.~Salakhutdinov, editors, \emph{Proceedings of
  the 36th International Conference on Machine Learning}, volume~97 of
  \emph{Proceedings of Machine Learning Research}, pages 3744--3753. PMLR,
  09--15 Jun 2019.
\newblock URL \url{https://proceedings.mlr.press/v97/lee19d.html}.

\bibitem[Lyle et~al.(2020)Lyle, van~der Wilk, Kwiatkowska, Gal, and
  Bloem-Reddy]{lyle2020benefits}
C.~Lyle, M.~van~der Wilk, M.~Kwiatkowska, Y.~Gal, and B.~Bloem-Reddy.
\newblock On the benefits of invariance in neural networks.
\newblock \emph{arXiv preprint arXiv:2005.00178}, 2020.

\bibitem[Marcel and Rodriguez(2010)]{marcel2010torchvision}
S.~Marcel and Y.~Rodriguez.
\newblock Torchvision the machine-vision package of torch.
\newblock In \emph{Proceedings of the 18th ACM international conference on
  Multimedia}, pages 1485--1488, 2010.

\bibitem[Marcos et~al.(2017)Marcos, Volpi, Komodakis, and
  Tuia]{marcos2017rotation}
D.~Marcos, M.~Volpi, N.~Komodakis, and D.~Tuia.
\newblock Rotation equivariant vector field networks.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pages 5048--5057, 2017.

\bibitem[Ratner et~al.(2017)Ratner, Ehrenberg, Hussain, Dunnmon, and
  R{\'e}]{ratner2017learning}
A.~J. Ratner, H.~Ehrenberg, Z.~Hussain, J.~Dunnmon, and C.~R{\'e}.
\newblock Learning to compose domain-specific transformations for data
  augmentation.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Sifre and Mallat(2012)]{sifre2012combined}
L.~Sifre and S.~Mallat.
\newblock Combined scattering for rotation invariant texture analysis.
\newblock In \emph{ESANN}, volume~44, pages 68--81. Citeseer, 2012.

\bibitem[Sifre and Mallat(2013)]{sifre2013rotation}
L.~Sifre and S.~Mallat.
\newblock Rotation, scaling and deformation invariant scattering for texture
  discrimination.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1233--1240, 2013.

\bibitem[Singla et~al.(2021)Singla, Ge, Ronen, and Jacobs]{singla2021shift}
V.~Singla, S.~Ge, B.~Ronen, and D.~Jacobs.
\newblock Shift invariance can reduce adversarial robustness.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Sixt et~al.(2018)Sixt, Wild, and Landgraf]{sixt2018rendergan}
L.~Sixt, B.~Wild, and T.~Landgraf.
\newblock Rendergan: Generating realistic labeled data.
\newblock \emph{Frontiers in Robotics and AI}, 5:\penalty0 66, 2018.

\bibitem[Snell et~al.(2017)Snell, Swersky, and Zemel]{snell2017prototypical}
J.~Snell, K.~Swersky, and R.~Zemel.
\newblock Prototypical networks for few-shot learning.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Sosnovik et~al.(2019)Sosnovik, Szmaja, and
  Smeulders]{sosnovik2019scale}
I.~Sosnovik, M.~Szmaja, and A.~Smeulders.
\newblock Scale-equivariant steerable networks.
\newblock \emph{arXiv preprint arXiv:1910.11093}, 2019.

\bibitem[Spijkervet(2020)]{Spijkervet}
J.~Spijkervet.
\newblock Simclr.
\newblock \url{https://github.com/Spijkervet/SimCLR}, 2020.

\bibitem[Weiler and Cesa(2019)]{weiler2019general}
M.~Weiler and G.~Cesa.
\newblock General {E}(2)-equivariant steerable {CNN}s.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 14334--14345, 2019.

\bibitem[Weiler et~al.()Weiler, Geiger, Welling, Boomsma, and Cohen]{weiler3d}
M.~Weiler, M.~Geiger, M.~Welling, W.~Boomsma, and T.~Cohen.
\newblock {3D} steerable {CNN}s: Learning rotationally equivariant features in
  volumetric data.

\bibitem[Weiler et~al.(2018)Weiler, Hamprecht, and Storath]{weiler2018learning}
M.~Weiler, F.~A. Hamprecht, and M.~Storath.
\newblock Learning steerable filters for rotation equivariant {CNN}s.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 849--858, 2018.

\bibitem[Wightman(2019)]{rw2019timm}
R.~Wightman.
\newblock Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem[Worrall and Welling(2019)]{worrall2019deep}
D.~Worrall and M.~Welling.
\newblock Deep scale-spaces: Equivariance over scale.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Worrall et~al.(2017)Worrall, Garbin, Turmukhambetov, and
  Brostow]{worrall2017harmonic}
D.~E. Worrall, S.~J. Garbin, D.~Turmukhambetov, and G.~J. Brostow.
\newblock Harmonic networks: Deep translation and rotation equivariance.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 5028--5037, 2017.

\bibitem[Xiao et~al.(2020)Xiao, Engstrom, Ilyas, and Madry]{xiao2020noise}
K.~Xiao, L.~Engstrom, A.~Ilyas, and A.~Madry.
\newblock Noise or signal: The role of image backgrounds in object recognition.
\newblock \emph{arXiv preprint arXiv:2006.09994}, 2020.

\bibitem[Zhang(2019)]{zhang2019making}
R.~Zhang.
\newblock Making convolutional networks shift-invariant again.
\newblock In \emph{International conference on machine learning}, pages
  7324--7334. PMLR, 2019.

\end{thebibliography}
