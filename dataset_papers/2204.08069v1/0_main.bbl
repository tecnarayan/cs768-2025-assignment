\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Al-Shedivat et~al.(2020)Al-Shedivat, Gillenwater, Xing, and
  Rostamizadeh]{al2020federated}
Al-Shedivat, M., Gillenwater, J., Xing, E., and Rostamizadeh, A.
\newblock Federated learning via posterior averaging: A new perspective and
  practical algorithms.
\newblock \emph{arXiv preprint arXiv:2010.05273}, 2020.

\bibitem[Al-Shedivat et~al.(2021)Al-Shedivat, Li, Xing, and
  Talwalkar]{al2021data}
Al-Shedivat, M., Li, L., Xing, E., and Talwalkar, A.
\newblock On data efficiency of meta-learning.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  1369--1377. PMLR, 2021.

\bibitem[Alistarh et~al.(2017)Alistarh, Grubic, Li, Tomioka, and
  Vojnovic]{alistarh2017qsgd}
Alistarh, D., Grubic, D., Li, J., Tomioka, R., and Vojnovic, M.
\newblock Qsgd: Communication-efficient sgd via gradient quantization and
  encoding.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1709--1720, 2017.

\bibitem[Bonawitz et~al.(2019)Bonawitz, Eichner, Grieskamp, Huba, Ingerman,
  Ivanov, Kiddon, Kone{\v{c}}n{\`y}, Mazzocchi, McMahan,
  et~al.]{bonawitz2019towards}
Bonawitz, K., Eichner, H., Grieskamp, W., Huba, D., Ingerman, A., Ivanov, V.,
  Kiddon, C., Kone{\v{c}}n{\`y}, J., Mazzocchi, S., McMahan, H.~B., et~al.
\newblock Towards federated learning at scale: System design.
\newblock \emph{arXiv preprint arXiv:1902.01046}, 2019.

\bibitem[Canh T.~Dinh(2020)]{pfedme_repo}
Canh T.~Dinh, Nguyen H.~Tran, T. D.~N.
\newblock Personalized federated learning with moreau envelopes (neurips 2020).
\newblock \url{https://github.com/CharlieDinh/pFedMe}, Jan 2020.

\bibitem[Chen \& Chao(2020)Chen and Chao]{chen2020fedbe}
Chen, H.-Y. and Chao, W.-L.
\newblock Fedbe: Making bayesian model ensemble applicable to federated
  learning.
\newblock \emph{arXiv preprint arXiv:2009.01974}, 2020.

\bibitem[Diao et~al.(2020)Diao, Ding, and Tarokh]{DingHeteroFL}
Diao, E., Ding, J., and Tarokh, V.
\newblock Hetero{FL}: Computation and communication efficient federated
  learning for heterogeneous clients.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2020.

\bibitem[Diao et~al.(2021{\natexlab{a}})Diao, Ding, and Tarokh]{DingGAL}
Diao, E., Ding, J., and Tarokh, V.
\newblock Gradient assisted learning.
\newblock \emph{arXiv preprint arXiv:2106.01425}, 2021{\natexlab{a}}.

\bibitem[Diao et~al.(2021{\natexlab{b}})Diao, Ding, and Tarokh]{SemiFL}
Diao, E., Ding, J., and Tarokh, V.
\newblock {SemiFL}: Communication efficient semi-supervised federated learning
  with unlabeled clients.
\newblock \emph{arXiv preprint arXiv:2106.01432}, 2021{\natexlab{b}}.

\bibitem[Diao et~al.(2021{\natexlab{c}})Diao, Tarokh, and
  Ding]{diao2021privacy}
Diao, E., Tarokh, V., and Ding, J.
\newblock Privacy-preserving multi-target multi-domain recommender systems with
  assisted autoencoders.
\newblock \emph{arXiv preprint arXiv:2110.13340}, 2021{\natexlab{c}}.

\bibitem[Ding et~al.(2022)Ding, Tramel, Sahu, Wu, Avestimehr, and
  Zhang]{ding2022federated}
Ding, J., Tramel, E., Sahu, A.~K., Wu, S., Avestimehr, S., and Zhang, T.
\newblock Federated learning challenges and opportunities: An outlook.
\newblock \emph{International Conference on Acoustics, Speech, and Signal
  Processing (ICASSP)}, 2022.

\bibitem[Dinh et~al.(2020)Dinh, Tran, and Nguyen]{pfedme}
Dinh, C.~T., Tran, N.~H., and Nguyen, T.~D.
\newblock Personalized federated learning with moreau envelopes.
\newblock \emph{arXiv preprint arXiv:2006.08848}, 2020.

\bibitem[Fallah et~al.(2020{\natexlab{a}})Fallah, Mokhtari, and
  Ozdaglar]{fallah2020personalized}
Fallah, A., Mokhtari, A., and Ozdaglar, A.
\newblock Personalized federated learning: A meta-learning approach.
\newblock \emph{arXiv preprint arXiv:2002.07948}, 2020{\natexlab{a}}.

\bibitem[Fallah et~al.(2020{\natexlab{b}})Fallah, Mokhtari, and
  Ozdaglar]{perfedavg}
Fallah, A., Mokhtari, A., and Ozdaglar, A.
\newblock Personalized federated learning: A meta-learning approach.
\newblock \emph{arXiv preprint arXiv:2002.07948}, 2020{\natexlab{b}}.

\bibitem[Go et~al.(2009)Go, Bhayani, and Huang]{go2009twitter}
Go, A., Bhayani, R., and Huang, L.
\newblock Twitter sentiment classification using distant supervision.
\newblock \emph{CS224N project report, Stanford}, 1\penalty0 (12):\penalty0
  2009, 2009.

\bibitem[Hanzely et~al.(2020)Hanzely, Hanzely, Horv{\'a}th, and
  Richt{\'a}rik]{hanzely2020lower}
Hanzely, F., Hanzely, S., Horv{\'a}th, S., and Richt{\'a}rik, P.
\newblock Lower bounds and optimal algorithms for personalized federated
  learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 2304--2315, 2020.

\bibitem[Huang et~al.(2021)Huang, Chu, Zhou, Wang, Liu, Pei, and
  Zhang]{huang2021personalized}
Huang, Y., Chu, L., Zhou, Z., Wang, L., Liu, J., Pei, J., and Zhang, Y.
\newblock Personalized cross-silo federated learning on non-iid data.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pp.\  7865--7873, 2021.

\bibitem[Ivkin et~al.(2019)Ivkin, Rothchild, Ullah, Stoica, Arora,
  et~al.]{ivkin2019communication}
Ivkin, N., Rothchild, D., Ullah, E., Stoica, I., Arora, R., et~al.
\newblock Communication-efficient distributed sgd with sketching.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  13144--13154, 2019.

\bibitem[Jiang et~al.(2019)Jiang, Kone{\v{c}}n{\`y}, Rush, and
  Kannan]{jiang2019improving}
Jiang, Y., Kone{\v{c}}n{\`y}, J., Rush, K., and Kannan, S.
\newblock Improving federated learning personalization via model agnostic meta
  learning.
\newblock \emph{arXiv preprint arXiv:1909.12488}, 2019.

\bibitem[Khodak et~al.(2019)Khodak, Balcan, and Talwalkar]{khodak2019adaptive}
Khodak, M., Balcan, M.-F.~F., and Talwalkar, A.~S.
\newblock Adaptive gradient-based meta-learning methods.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  5917--5928, 2019.

\bibitem[Khodak et~al.(2021)Khodak, Tu, Li, Li, Balcan, Smith, and
  Talwalkar]{khodak2021federated}
Khodak, M., Tu, R., Li, T., Li, L., Balcan, M.-F.~F., Smith, V., and Talwalkar,
  A.
\newblock Federated hyperparameter tuning: Challenges, baselines, and
  connections to weight-sharing.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Konevcny et~al.(2016)Konevcny, McMahan, Yu, Richt{\'a}rik, Suresh, and
  Bacon]{konevcny2016federated}
Konevcny, J., McMahan, H.~B., Yu, F.~X., Richt{\'a}rik, P., Suresh, A.~T., and
  Bacon, D.
\newblock Federated learning: Strategies for improving communication
  efficiency.
\newblock \emph{arXiv preprint arXiv:1610.05492}, 2016.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Sun, Wang, Duan, Li, Chen, and
  Li]{li2020lotteryfl}
Li, A., Sun, J., Wang, B., Duan, L., Li, S., Chen, Y., and Li, H.
\newblock Lotteryfl: Personalized and communication-efficient federated
  learning with lottery ticket hypothesis on non-iid datasets.
\newblock \emph{arXiv preprint arXiv:2008.03371}, 2020{\natexlab{a}}.

\bibitem[Li \& Wang(2019)Li and Wang]{li2019fedmd}
Li, D. and Wang, J.
\newblock Fedmd: Heterogenous federated learning via model distillation.
\newblock \emph{arXiv preprint arXiv:1910.03581}, 2019.

\bibitem[Li(2020)]{fedprox}
Li, T.
\newblock Github repo of paper federated optimization in heterogeneous
  networks.
\newblock \url{https://github.com/litian96/FedProx}, July 2020.

\bibitem[Li et~al.(2019)Li, Sanjabi, Beirami, and Smith]{li2019fair}
Li, T., Sanjabi, M., Beirami, A., and Smith, V.
\newblock Fair resource allocation in federated learning.
\newblock \emph{arXiv preprint arXiv:1905.10497}, 2019.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Sahu, Talwalkar, and
  Smith]{li2020federated}
Li, T., Sahu, A.~K., Talwalkar, A., and Smith, V.
\newblock Federated learning: Challenges, methods, and future directions.
\newblock \emph{IEEE Signal Processing Magazine}, 37\penalty0 (3):\penalty0
  50--60, 2020{\natexlab{b}}.

\bibitem[Li et~al.(2020{\natexlab{c}})Li, Sahu, Zaheer, Sanjabi, Talwalkar, and
  Smith]{li2018federated}
Li, T., Sahu, A.~K., Zaheer, M., Sanjabi, M., Talwalkar, A., and Smith, V.
\newblock Federated optimization in heterogeneous networks.
\newblock In \emph{Proceedings of Machine Learning and Systems}, volume~2, pp.\
   429--450, 2020{\natexlab{c}}.

\bibitem[Li et~al.(2021)Li, Hu, Beirami, and Smith]{li2021ditto}
Li, T., Hu, S., Beirami, A., and Smith, V.
\newblock Ditto: Fair and robust federated learning through personalization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  6357--6368. PMLR, 2021.

\bibitem[Lim et~al.(2020)Lim, Luong, Hoang, Jiao, Liang, Yang, Niyato, and
  Miao]{lim2020federated}
Lim, W. Y.~B., Luong, N.~C., Hoang, D.~T., Jiao, Y., Liang, Y.-C., Yang, Q.,
  Niyato, D., and Miao, C.
\newblock Federated learning in mobile edge networks: A comprehensive survey.
\newblock \emph{IEEE Communications Surveys \& Tutorials}, 2020.

\bibitem[Mansour et~al.(2020)Mansour, Mohri, Ro, and Suresh]{mansour2020three}
Mansour, Y., Mohri, M., Ro, J., and Suresh, A.~T.
\newblock Three approaches for personalization with applications to federated
  learning.
\newblock \emph{arXiv preprint arXiv:2002.10619}, 2020.

\bibitem[Marfoq et~al.(2021)Marfoq, Neglia, Bellet, Kameni, and
  Vidal]{marfoq2021federated}
Marfoq, O., Neglia, G., Bellet, A., Kameni, L., and Vidal, R.
\newblock Federated multi-task learning under a mixture of distributions.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[McMahan et~al.(2017)McMahan, Moore, Ramage, Hampson, and
  y~Arcas]{mcmahan2017communication}
McMahan, B., Moore, E., Ramage, D., Hampson, S., and y~Arcas, B.~A.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In \emph{Proc. AISTATS}, pp.\  1273--1282. PMLR, 2017.

\bibitem[Nishio \& Yonetani(2019)Nishio and Yonetani]{nishio2019client}
Nishio, T. and Yonetani, R.
\newblock Client selection for federated learning with heterogeneous resources
  in mobile edge.
\newblock In \emph{ICC 2019-2019 IEEE International Conference on
  Communications (ICC)}, pp.\  1--7. IEEE, 2019.

\bibitem[Pennington et~al.(2014)Pennington, Socher, and
  Manning]{pennington2014glove}
Pennington, J., Socher, R., and Manning, C.~D.
\newblock Glove: Global vectors for word representation.
\newblock In \emph{Proceedings of the 2014 conference on empirical methods in
  natural language processing (EMNLP)}, pp.\  1532--1543, 2014.

\bibitem[Purington et~al.(2017)Purington, Taft, Sannon, Bazarova, and
  Taylor]{purington2017alexa}
Purington, A., Taft, J.~G., Sannon, S., Bazarova, N.~N., and Taylor, S.~H.
\newblock "alexa is my new bff" social roles, user satisfaction, and
  personification of the amazon echo.
\newblock In \emph{Proceedings of the 2017 CHI conference extended abstracts on
  human factors in computing systems}, pp.\  2853--2859, 2017.

\bibitem[PyTorch(2022)]{pytorch_cf10}
PyTorch.
\newblock Training a classifier.
\newblock
  \url{https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html},
  April 2022.

\bibitem[Reddi et~al.(2020)Reddi, Charles, Zaheer, Garrett, Rush,
  Kone{\v{c}}n{\`y}, Kumar, and McMahan]{reddi2020adaptive}
Reddi, S., Charles, Z., Zaheer, M., Garrett, Z., Rush, K., Kone{\v{c}}n{\`y},
  J., Kumar, S., and McMahan, H.~B.
\newblock Adaptive federated optimization.
\newblock \emph{arXiv preprint arXiv:2003.00295}, 2020.

\bibitem[Shamsian et~al.(2021)Shamsian, Navon, Fetaya, and
  Chechik]{shamsian2021personalized}
Shamsian, A., Navon, A., Fetaya, E., and Chechik, G.
\newblock Personalized federated learning using hypernetworks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  9489--9502. PMLR, 2021.

\bibitem[Smith et~al.(2017)Smith, Chiang, Sanjabi, and
  Talwalkar]{smith2017federated}
Smith, V., Chiang, C.-K., Sanjabi, M., and Talwalkar, A.~S.
\newblock Federated multi-task learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4424--4434, 2017.

\bibitem[Van~der Vaart(2000)]{van2000asymptotic}
Van~der Vaart, A.~W.
\newblock \emph{Asymptotic statistics}, volume~3.
\newblock Cambridge university press, 2000.

\bibitem[Vanhaesebrouck et~al.(2017)Vanhaesebrouck, Bellet, and
  Tommasi]{vanhaesebrouck2017decentralized}
Vanhaesebrouck, P., Bellet, A., and Tommasi, M.
\newblock Decentralized collaborative learning of personalized models over
  networks.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  509--517.
  PMLR, 2017.

\bibitem[Wang et~al.(2019)Wang, Mathews, Kiddon, Eichner, Beaufays, and
  Ramage]{wang2019federated}
Wang, K., Mathews, R., Kiddon, C., Eichner, H., Beaufays, F., and Ramage, D.
\newblock Federated evaluation of on-device personalization.
\newblock \emph{arXiv preprint arXiv:1910.10252}, 2019.

\bibitem[Wang et~al.(2021)Wang, Xiang, Gao, and Ding]{DingIL}
Wang, X., Xiang, Y., Gao, J., and Ding, J.
\newblock Information laundering for model privacy.
\newblock \emph{Proc. ICLR}, 2021.

\bibitem[Xian et~al.(2020)Xian, Wang, Ding, and Ghanadan]{DingAssist}
Xian, X., Wang, X., Ding, J., and Ghanadan, R.
\newblock Assisted learning: a framework for multi-organization learning.
\newblock \emph{Proc. NeurIPS 2020}, 2020.

\bibitem[Zhang et~al.(2021)Zhang, Ding, and Yang]{DingBAGofT}
Zhang, J., Ding, J., and Yang, Y.
\newblock A binary regression adaptive goodness-of-fit test.
\newblock \emph{Journal of the American Statistical Association}, 2021.

\bibitem[Zhang et~al.(2020)Zhang, Sapra, Fidler, Yeung, and
  Alvarez]{zhang2020personalized}
Zhang, M., Sapra, K., Fidler, S., Yeung, S., and Alvarez, J.~M.
\newblock Personalized federated learning with first order model optimization.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\end{thebibliography}
