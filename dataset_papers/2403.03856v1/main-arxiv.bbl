\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{ABDCBH97}

\bibitem[ABDCBH97]{alon1997scale}
Noga Alon, Shai Ben-David, Nicolo Cesa-Bianchi, and David Haussler.
\newblock Scale-sensitive dimensions, uniform convergence, and learnability.
\newblock {\em Journal of the ACM (JACM)}, 44(4):615--631, 1997.

\bibitem[ABG{\etalchar{+}}22]{arora2022differentially}
Raman Arora, Raef Bassily, Crist{\'o}bal Guzm{\'a}n, Michael Menart, and Enayat
  Ullah.
\newblock Differentially private generalized linear models revisited.
\newblock {\em Advances in Neural Information Processing Systems},
  35:22505--22517, 2022.

\bibitem[ABM19]{ABM19}
Noga Alon, Raef Bassily, and Shay Moran.
\newblock Limits of private learning with access to public data.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, {\em Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.

\bibitem[AGM{\etalchar{+}}22]{amid2022-public-mirror}
Ehsan Amid, Arun Ganesh, Rajiv Mathews, Swaroop Ramaswamy, Shuang Song, Thomas
  Steinke, Thomas Steinke, Vinith~M Suriyakumar, Om~Thakkar, and Abhradeep
  Thakurta.
\newblock Public data-assisted mirror descent for private model training.
\newblock In Kamalika Chaudhuri, Stefanie Jegelka, Le~Song, Csaba Szepesvari,
  Gang Niu, and Sivan Sabato, editors, {\em Proceedings of the 39th
  International Conference on Machine Learning}, volume 162 of {\em Proceedings
  of Machine Learning Research}, pages 517--535. PMLR, 17--23 Jul 2022.

\bibitem[BCM{\etalchar{+}}20]{bassily20-private-query-w-public}
Raef Bassily, Albert Cheu, Shay Moran, Aleksandar Nikolov, Jonathan Ullman, and
  Steven Wu.
\newblock Private query release assisted by public data.
\newblock In Hal~Daumé III and Aarti Singh, editors, {\em Proceedings of the
  37th International Conference on Machine Learning}, volume 119 of {\em
  Proceedings of Machine Learning Research}, pages 695--703. PMLR, 13--18 Jul
  2020.

\bibitem[BDBC{\etalchar{+}}23]{ben-david2023private}
Shai Ben-David, Alex Bie, Clement~Louis Canonne, Gautam Kamath, and Vikrant
  Singhal.
\newblock Private distribution learning with public data: The view from sample
  compression.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing
  Systems}, 2023.

\bibitem[BEHW89]{blumer1989learnability}
Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred~K Warmuth.
\newblock Learnability and the vapnik-chervonenkis dimension.
\newblock {\em Journal of the ACM (JACM)}, 36(4):929--965, 1989.

\bibitem[BFT17]{bartlett2017spectrally}
Peter~L Bartlett, Dylan~J Foster, and Matus~J Telgarsky.
\newblock Spectrally-normalized margin bounds for neural networks.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem[BFTGT19]{bassily2019private}
Raef Bassily, Vitaly Feldman, Kunal Talwar, and Abhradeep Guha~Thakurta.
\newblock Private stochastic convex optimization with optimal rates.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[BGM21]{bassily2021differentially}
Raef Bassily, Crist{\'o}bal~A Guzm{\'a}n, and Michael Menart.
\newblock Differentially private stochastic optimization: New results in convex
  and non-convex settings.
\newblock In A.~Beygelzimer, Y.~Dauphin, P.~Liang, and J.~Wortman Vaughan,
  editors, {\em Advances in Neural Information Processing Systems}, 2021.

\bibitem[BKS22]{bie2022private}
Alex Bie, Gautam Kamath, and Vikrant Singhal.
\newblock Private estimation with public data.
\newblock In Alice~H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho,
  editors, {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem[BLW94]{bartlett1994fat}
Peter~L Bartlett, Philip~M Long, and Robert~C Williamson.
\newblock Fat-shattering and the learnability of real-valued functions.
\newblock In {\em Proceedings of the seventh annual conference on Computational
  learning theory}, pages 299--310, 1994.

\bibitem[BNS13]{BNS13}
Amos Beimel, Kobbi Nissim, and Uri Stemmer.
\newblock Private learning and sanitization: Pure vs. approximate differential
  privacy.
\newblock In Prasad Raghavendra, Sofya Raskhodnikova, Klaus Jansen, and
  Jos{\'e} D.~P. Rolim, editors, {\em Approximation, Randomization, and
  Combinatorial Optimization. Algorithms and Techniques}, pages 363--378,
  Berlin, Heidelberg, 2013. Springer Berlin Heidelberg.

\bibitem[BST14]{bassily2014private}
Raef Bassily, Adam Smith, and Abhradeep Thakurta.
\newblock Private empirical risk minimization: Efficient algorithms and tight
  error bounds.
\newblock In {\em 2014 IEEE 55th Annual Symposium on Foundations of Computer
  Science}, pages 464--473. IEEE, 2014.

\bibitem[BTGT18]{BTT18}
Raef Bassily, Om~Thakkar, and Abhradeep Guha~Thakurta.
\newblock Model-agnostic private learning.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, {\em Advances in Neural Information Processing
  Systems}, volume~31. Curran Associates, Inc., 2018.

\bibitem[BUV14]{BUV14}
Mark Bun, Jonathan Ullman, and Salil Vadhan.
\newblock Fingerprinting codes and the price of approximate differential
  privacy.
\newblock In {\em Proceedings of the Forty-Sixth Annual ACM Symposium on Theory
  of Computing}, STOC '14, page 1–10, New York, NY, USA, 2014. Association
  for Computing Machinery.

\bibitem[BWZK22]{Bu2022}
Zhiqi Bu, Yu-Xiang Wang, Sheng Zha, and George Karypis.
\newblock Differentially private bias-term only fine-tuning of foundation
  models.
\newblock In {\em NeurIPS 2022 Workshop on Trustworthy and Socially Responsible
  Machine Learning (TSRML)}, 2022.

\bibitem[CH11]{chaudhuri11a}
Kamalika Chaudhuri and Daniel Hsu.
\newblock Sample complexity bounds for differentially private learning.
\newblock In Sham~M. Kakade and Ulrike von Luxburg, editors, {\em Proceedings
  of the 24th Annual Conference on Learning Theory}, volume~19 of {\em
  Proceedings of Machine Learning Research}, pages 155--186, Budapest, Hungary,
  09--11 Jun 2011. PMLR.

\bibitem[CWZ21]{CWZ21}
T.~Tony Cai, Yichen Wang, and Linjun Zhang.
\newblock {The cost of privacy: Optimal rates of convergence for parameter
  estimation with differential privacy}.
\newblock {\em The Annals of Statistics}, 49(5):2825 -- 2850, 2021.

\bibitem[DMNS06]{dwork2006calibrating}
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.
\newblock Calibrating noise to sensitivity in private data analysis.
\newblock In {\em Theory of cryptography conference}, pages 265--284. Springer,
  2006.

\bibitem[DSS{\etalchar{+}}15]{DSSUV15}
Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan.
\newblock Robust traceability from trace amounts.
\newblock In {\em 2015 IEEE 56th Annual Symposium on Foundations of Computer
  Science}, pages 650--669, 2015.

\bibitem[Duc23]{Duchi-information-theory-statistics}
John Duchi.
\newblock Lecture notes on statistics and information theory, May 2023.

\bibitem[FGV17]{feldman2017statistical}
Vitaly Feldman, Cristobal Guzman, and Santosh Vempala.
\newblock Statistical query algorithms for mean vector estimation and
  stochastic convex optimization.
\newblock In {\em Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on
  Discrete Algorithms}, pages 1265--1277. SIAM, 2017.

\bibitem[FS17]{FS17}
Vitaly Feldman and Thomas Steinke.
\newblock Generalization for adaptively-chosen estimators via stable median.
\newblock In Satyen Kale and Ohad Shamir, editors, {\em Proceedings of the 2017
  Conference on Learning Theory}, volume~65 of {\em Proceedings of Machine
  Learning Research}, pages 728--757. PMLR, 07--10 Jul 2017.

\bibitem[GHN{\etalchar{+}}23]{Ganesh2023WhyIP}
Arun Ganesh, Mahdi Haghifam, Milad Nasr, Sewoong Oh, Thomas Steinke,
  Om~Thakkar, Abhradeep Thakurta, and Lun Wang.
\newblock Why is public pretraining necessary for private model training?
\newblock In {\em International Conference on Machine Learning}, 2023.

\bibitem[GLL22]{gopi2022private}
Sivakanth Gopi, Yin~Tat Lee, and Daogao Liu.
\newblock Private convex optimization via exponential mechanism.
\newblock In {\em Conference on Learning Theory}, pages 1948--1989. PMLR, 2022.

\bibitem[GRS18]{golowich2018size}
Noah Golowich, Alexander Rakhlin, and Ohad Shamir.
\newblock Size-independent sample complexity of neural networks.
\newblock In {\em Conference On Learning Theory}, pages 297--299. PMLR, 2018.

\bibitem[GTU23]{ganesh2023universality}
Arun Ganesh, Abhradeep Thakurta, and Jalaj Upadhyay.
\newblock Universality of langevin diffusion for private optimization, with
  applications to sampling from rashomon sets.
\newblock In {\em The Thirty Sixth Annual Conference on Learning Theory}, pages
  1730--1773. PMLR, 2023.

\bibitem[KDRT21]{kairouz2021}
Peter Kairouz, Monica~Ribero Diaz, Keith Rush, and Abhradeep Thakurta.
\newblock (nearly) dimension independent private erm with adagrad rates\\{via}
  publicly estimated subspaces.
\newblock In Mikhail Belkin and Samory Kpotufe, editors, {\em Proceedings of
  Thirty Fourth Conference on Learning Theory}, volume 134 of {\em Proceedings
  of Machine Learning Research}, pages 2717--2746. PMLR, 15--19 Aug 2021.

\bibitem[KST08]{kakade2008complexity}
Sham~M Kakade, Karthik Sridharan, and Ambuj Tewari.
\newblock On the complexity of linear prediction: Risk bounds, margin bounds,
  and regularization.
\newblock {\em Advances in neural information processing systems}, 21, 2008.

\bibitem[KU20]{kamath2020primer}
Gautam Kamath and Jonathan Ullman.
\newblock A primer on private statistics.
\newblock {\em arXiv preprint arXiv:2005.00010}, 2020.

\bibitem[LLHR23]{lowy2023optimal}
Andrew Lowy, Zeman Li, Tianjian Huang, and Meisam Razaviyayn.
\newblock Optimal differentially private learning with public data.
\newblock {\em arXiv preprint arXiv:2306.15056}, 2023.

\bibitem[LW19]{li2019fedmd}
Daliang Li and Junpu Wang.
\newblock Fedmd: Heterogenous federated learning via model distillation, 2019.

\bibitem[MT07]{mcsherry2007mechanism}
Frank McSherry and Kunal Talwar.
\newblock Mechanism design via differential privacy.
\newblock In {\em 48th Annual IEEE Symposium on Foundations of Computer Science
  (FOCS'07)}, pages 94--103. IEEE, 2007.

\bibitem[NMT{\etalchar{+}}23]{nasr2023-effective-public}
Milad Nasr, Saeed Mahloujifar, Xinyu Tang, Prateek Mittal, and Amir Houmansadr.
\newblock Effectively using public data in privacy preserving machine learning.
\newblock In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt,
  Sivan Sabato, and Jonathan Scarlett, editors, {\em Proceedings of the 40th
  International Conference on Machine Learning}, volume 202 of {\em Proceedings
  of Machine Learning Research}, pages 25718--25732. PMLR, 23--29 Jul 2023.

\bibitem[PAE{\etalchar{+}}17]{papernot2017semisupervised}
Nicolas Papernot, Martin Abadi, Ulfar Erlingsson, Ian Goodfellow, and Kunal
  Talwar.
\newblock Semi-supervised knowledge transfer for deep learning from private
  training data.
\newblock In {\em International Conference on Learning Representations}, 2017.

\bibitem[PSM{\etalchar{+}}18]{papernot2018-scalable}
Nicolas Papernot, Shuang Song, Ilya Mironov, Ananth Raghunathan, Kunal Talwar,
  and {\'{U}}lfar Erlingsson.
\newblock Scalable private learning with {PATE}.
\newblock In {\em 6th International Conference on Learning Representations,
  {ICLR} 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track
  Proceedings}. OpenReview.net, 2018.

\bibitem[PVX{\etalchar{+}}23]{dp-ml-survey}
Natalia Ponomareva, Sergei Vassilvitskii, Zheng Xu, Brendan McMahan, Alexey
  Kurakin, and Chiyaun Zhang.
\newblock How to dp-fy ml: A practical tutorial to machine learning with
  differential privacy.
\newblock In {\em Proceedings of the 29th ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining}, KDD '23, page 5823–5824, New York, NY, USA,
  2023. Association for Computing Machinery.

\bibitem[RS12]{rakhlin2012statistical}
Alexander Rakhlin and Karthik Sridharan.
\newblock Statistical learning theory and sequential prediction.
\newblock {\em Lecture Notes in University of Pennsyvania}, 44, 2012.

\bibitem[SCZ{\etalchar{+}}20]{sui-etal-2020-feded}
Dianbo Sui, Yubo Chen, Jun Zhao, Yantao Jia, Yuantao Xie, and Weijian Sun.
\newblock {F}ed{ED}: Federated learning via ensemble distillation for medical
  relation extraction.
\newblock In Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu, editors, {\em
  Proceedings of the 2020 Conference on Empirical Methods in Natural Language
  Processing (EMNLP)}, pages 2118--2128, Online, November 2020. Association for
  Computational Linguistics.

\bibitem[Sel23]{sellke2023size}
Mark Sellke.
\newblock On size-independent sample complexity of relu networks.
\newblock {\em arXiv preprint arXiv:2306.01992}, 2023.

\bibitem[SSBD14]{shalev2014understanding}
Shai Shalev-Shwartz and Shai Ben-David.
\newblock {\em Understanding machine learning: From theory to algorithms}.
\newblock Cambridge university press, 2014.

\bibitem[SST10]{srebro2010optimistic}
Nathan Srebro, Karthik Sridharan, and Ambuj Tewari.
\newblock Optimistic rates for learning with a smooth loss.
\newblock {\em arXiv preprint arXiv:1009.3896}, 2010.

\bibitem[SSTT21]{song2021evading}
Shuang Song, Thomas Steinke, Om~Thakkar, and Abhradeep Thakurta.
\newblock Evading the curse of dimensionality in unconstrained private glms.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 2638--2646. PMLR, 2021.

\bibitem[SU15]{steinke2015between}
Thomas Steinke and Jonathan Ullman.
\newblock Between pure and approximate differential privacy.
\newblock {\em Journal of Privacy and Confidentiality}, 7, 01 2015.

\bibitem[VC71]{vapnik1971uniform}
N.~Vapnik and A.~Ya. Chervonenkis.
\newblock On the uniform convergence of relative frequencies of events to their
  probabilities.
\newblock {\em Theory of Probability \& Its Applications}, 16(2):264, 1971.

\bibitem[Ver18]{vershynin2018high}
Roman Vershynin.
\newblock {\em High-dimensional probability: An introduction with applications
  in data science}, volume~47.
\newblock Cambridge university press, 2018.

\bibitem[YNB{\etalchar{+}}22]{yu2022differentially}
Da~Yu, Saurabh Naik, Arturs Backurs, Sivakanth Gopi, Huseyin~A Inan, Gautam
  Kamath, Janardhan Kulkarni, Yin~Tat Lee, Andre Manoel, Lukas Wutschitz,
  Sergey Yekhanin, and Huishuai Zhang.
\newblock Differentially private fine-tuning of language models.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem[YZCL21]{Da-dont-overbill}
Da~Yu, Huishuai Zhang, Wei Chen, and Tie-Yan Liu.
\newblock Do not let privacy overbill utility: Gradient embedding perturbation
  for private learning.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem[ZWB21]{zhou2021bypassing}
Yingxue Zhou, Steven Wu, and Arindam Banerjee.
\newblock Bypassing the ambient dimension: Private sgd with gradient subspace
  identification.
\newblock In {\em International Conference on Learning Representations}, 2021.

\end{thebibliography}
