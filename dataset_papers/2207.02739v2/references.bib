%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Saumitra Mishra at 2020-08-25 23:02:49 +0100 


%% Saved with string encoding Unicode (UTF-8) 
@article{sharma2019certifai,
  title={Certifai: Counterfactual explanations for robustness, transparency, interpretability, and fairness of artificial intelligence models},
  author={Sharma, Shubham and Henderson, Jette and Ghosh, Joydeep},
  journal={arXiv preprint arXiv:1905.07857},
  year={2019}
}



@article{spooner2021counterfactual,
  title={Counterfactual Explanations for Arbitrary Regression Models},
  author={Spooner, Thomas and Dervovic, Danial and Long, Jason and Shepard, Jon and Chen, Jiahao and Magazzeni, Daniele},
  journal={arXiv preprint arXiv:2106.15212},
  year={2021}
}

@article{ley2022global,
  title={Global Counterfactual Explanations: Investigations, Implementations and Improvements},
  author={Ley, Dan and Mishra, Saumitra and Magazzeni, Daniele},
  journal={arXiv preprint arXiv:2204.06917},
  year={2022}
}

@inproceedings{raghunathan2018certified,
  title={Certified Defenses against Adversarial Examples},
  author={Raghunathan, Aditi and Steinhardt, Jacob and Liang, Percy},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{cohen2019certified,
  title={Certified adversarial robustness via randomized smoothing},
  author={Cohen, Jeremy and Rosenfeld, Elan and Kolter, Zico},
  booktitle={International Conference on Machine Learning},
  pages={1310--1320},
  year={2019},
  organization={PMLR}
}

@article{alvarez2018robustness,
  title={On the robustness of interpretability methods},
  author={Alvarez-Melis, David and Jaakkola, Tommi S},
  journal={arXiv preprint arXiv:1806.08049},
  year={2018}
}

@inproceedings{breunig2000lof,
  title={LOF: identifying density-based local outliers},
  author={Breunig, Markus M and Kriegel, Hans-Peter and Ng, Raymond T and Sander, J{\"o}rg},
  booktitle={Proceedings of the 2000 ACM SIGMOD international conference on Management of data},
  pages={93--104},
  year={2000}
}


@inproceedings{barocas2020hidden,
  title={The hidden assumptions behind counterfactual explanations and principal reasons},
  author={Barocas, Solon and Selbst, Andrew D and Raghavan, Manish},
  booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages={80--89},
  year={2020}
}

@inproceedings{hancox2020robustness,
  title={Robustness in machine learning explanations: does it matter?},
  author={Hancox-Li, Leif},
  booktitle={Proceedings of the 2020 conference on fairness, accountability, and transparency},
  pages={640--647},
  year={2020}
}

@article{chen2015xgboost,
  title={Xgboost: extreme gradient boosting},
  author={Chen, Tianqi and He, Tong and Benesty, Michael and Khotilovich, Vadim and Tang, Yuan and Cho, Hyunsu and others},
  journal={R package version 0.4-2},
  volume={1},
  number={4},
  pages={1--4},
  year={2015}
}


@misc{Fico_web_2018,
    Author = {FICO},
	Month = {April-October},
	Note = {Accessed January 27, 2022},
	Title = {{Explainable Machine Learning Challenge}},
	Url = {https://community.fico.com/s/explainable-machine-learning-challenge},
	Year = {2018},
}


@misc{Angwin_web_2016,
	Author = {Julia Angwin and Jeff Larson and Surya Mattu and Lauren Kirchner},
	Date-Added = {2019-10-08 20:49:50 +0100},
	Date-Modified = {2020-01-04 16:03:47 +0000},
	Month = {May},
	Note = {Accessed January 27, 2022},
	Title = {{Machine Bias}},
	Url = {https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing},
	Year = {2016},
	Bdsk-Url-1 = {https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing}}


@article{Mishra_arXiv_2021,
  author    = {Saumitra Mishra and Sanghamitra Dutta and Jason Long and Daniele Magazzeni},
  title     = {{A Survey on the Robustness of Feature Importance and Counterfactual
               Explanations}},
  journal   = {arXiv e-prints},
  volume    = {arXiv:2111.00358},
  year      = {2021},
}

%% Some references added by SD

@article{lucic2019focus,
  title={FOCUS: Flexible optimizable counterfactual explanations for tree ensembles},
  author={Lucic, Ana and Oosterhuis, Harrie and Haned, Hinda and de Rijke, Maarten},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2022}
}

@article{albini2021counterfactual,
  title={Counterfactual Shapley Additive Explanations},
  author={Albini, Emanuele and Long, Jason and Dervovic, Danial and Magazzeni, Daniele},
  journal={ACM Conference on Fairness, Accountability, and Transparency},
  year={2022}
}


@inproceedings{tolomei2017interpretable,
  title={Interpretable predictions of tree-based ensembles via actionable feature tweaking},
  author={Tolomei, Gabriele and Silvestri, Fabrizio and Haines, Andrew and Lalmas, Mounia},
  booktitle={Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={465--474},
  year={2017}
}

@misc{scikit-lof,
title = "LOF Implementation",
author = "scikit-learn",
url= "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html"}

@misc{UCI,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }



@article{verma2020counterfactual,
  title={Counterfactual explanations for machine learning: A review},
  author={Verma, Sahil and Dickerson, John and Hines, Keegan},
  journal={arXiv preprint arXiv:2010.10596},
  year={2020}
}

@article{wachter2017counterfactual,
  title={Counterfactual explanations without opening the black box: Automated decisions and the GDPR},
  author={Wachter, Sandra and Mittelstadt, Brent and Russell, Chris},
  journal={Harv. JL \& Tech.},
  volume={31},
  pages={841},
  year={2017},
  publisher={HeinOnline}
}

@inproceedings{marx2020predictive,
  title={Predictive multiplicity in classification},
  author={Marx, Charles and Calmon, Flavio and Ustun, Berk},
  booktitle={International Conference on Machine Learning},
  pages={6765--6774},
  year={2020},
  organization={PMLR}
}


@inproceedings{kanamori2020dace,
  title={DACE: Distribution-Aware Counterfactual Explanation by Mixed-Integer Linear Optimization.},
  author={Kanamori, Kentaro and Takagi, Takuya and Kobayashi, Ken and Arimura, Hiroki},
  booktitle={IJCAI},
  pages={2855--2862},
  year={2020}
}

@article{black2021consistent,
  title={Consistent counterfactuals for deep models},
  author={Black, Emily and Wang, Zifan and Fredrikson, Matt and Datta, Anupam},
  journal={arXiv preprint arXiv:2110.03109},
  year={2021}
}

@article{upadhyay2021towards,
  title={Towards robust and reliable algorithmic recourse},
  author={Upadhyay, Sohini and Joshi, Shalmali and Lakkaraju, Himabindu},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@article{rawal2020can,
  title={Can {I} Still Trust You?: Understanding the Impact of Distribution Shifts on Algorithmic Recourses},
  author={Rawal, Kaivalya and Kamar, Ece and Lakkaraju, Himabindu},
  journal={arXiv preprint arXiv:2012.11788},
  year={2020}
}

@article{slack2021counterfactual,
  title={Counterfactual Explanations Can Be Manipulated},
  author={Slack, Dylan and Hilgard, Sophie and Lakkaraju, Himabindu and Singh, Sameer},
  journal={arXiv preprint arXiv:2106.02666},
  year={2021}
}

@article{multiobjective,
  title={Multi-Objective Counterfactual Explanations},
  author={Dandl, Susanne and Molnar, Christoph and Binder, Martin and Bischl, Bernd},
  journal={International Conference on Parallel Problem Solving from Nature},
  year={2020}
}

@article{konig2021causal,
  title={A Causal Perspective on Meaningful and Robust Algorithmic Recourse},
  author={K{\"o}nig, Gunnar and Freiesleben, Timo and Grosse-Wentrup, Moritz},
  journal={arXiv preprint arXiv:2107.07853},
  year={2021}
}
@inproceedings{pawelczyk2020counterfactual,
  title={On counterfactual explanations under predictive multiplicity},
  author={Pawelczyk, Martin and Broelemann, Klaus and Kasneci, Gjergji},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  pages={809--818},
  year={2020},
  organization={PMLR}
}



@inproceedings{pawelczyk2020learning,
  title={Learning model-agnostic counterfactual explanations for tabular data},
  author={Pawelczyk, Martin and Broelemann, Klaus and Kasneci, Gjergji},
  booktitle={Proceedings of The Web Conference 2020},
  pages={3126--3132},
  year={2020}
}

@inproceedings{poyiadzi2020face,
  title={FACE: Feasible and actionable counterfactual explanations},
  author={Poyiadzi, Rafael and Sokol, Kacper and Santos-Rodriguez, Raul and De Bie, Tijl and Flach, Peter},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  pages={344--350},
  year={2020}
}
%% SD End

@article{Bracke_boe_2019,
  author    = {Philippe Bracke and
               Anupam Datta and
               Carsten Jung and
               Shayak Sen},
  title     = {Machine learning explainability in finance:
an application to default risk analysis},
  journal   = {Bank of England Working Paper},
  year      = {2019},
  url       = {https://www.bankofengland.co.uk/-/media/boe/files/working-paper/2019/machine-learning-explainability-in-finance-an-application-to-default-risk-analysis.pdf},
}


@article{Karimi_arXiv_2020,
  author    = {Amir{-}Hossein Karimi and
               Gilles Barthe and
               Bernhard Sch{\"{o}}lkopf and
               Isabel Valera},
  title     = {A survey of algorithmic recourse: definitions, formulations, solutions,
               and prospects},
  journal   = {CoRR},
  volume    = {abs/2010.04050},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.04050},
  eprinttype = {arXiv},
  eprint    = {2010.04050},
  timestamp = {Tue, 13 Oct 2020 15:25:23 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-04050.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Pawelczyk_arXiv_2021,
  author    = {Martin Pawelczyk and
               Sascha Bielawski and
               Johannes van den Heuvel and
               Tobias Richter and
               Gjergji Kasneci},
  title     = {{CARLA:} {A} Python Library to Benchmark Algorithmic Recourse and
               Counterfactual Explanation Algorithms},
  journal   = {CoRR},
  volume    = {abs/2108.00783},
  year      = {2021},
  url       = {https://arxiv.org/abs/2108.00783},
  eprinttype = {arXiv},
  eprint    = {2108.00783},
  timestamp = {Thu, 05 Aug 2021 14:27:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2108-00783.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Dombrowski_pr_2022,
  author    = {Ann{-}Kathrin Dombrowski and
               Christopher J. Anders and
               Klaus{-}Robert M{\"{u}}ller and
               Pan Kessel},
  title     = {Towards robust explanations for deep neural networks},
  journal   = {Pattern Recognition},
  volume    = {121},
  pages     = {108194},
  year      = {2022},
  url       = {https://doi.org/10.1016/j.patcog.2021.108194},
  doi       = {10.1016/j.patcog.2021.108194},
  timestamp = {Thu, 30 Sep 2021 09:12:06 +0200},
  biburl    = {https://dblp.org/rec/journals/pr/DombrowskiAMK22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@conference{Jacovi_acl_2020,
	Author = {Alon Jacovi and Yoav Goldberg},
	Booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL)},
	Date-Added = {2020-08-25 23:00:46 +0100},
	Date-Modified = {2020-08-25 23:02:49 +0100},
	Month = {July 5--10},
	Organization = {Online},
	Pages = {4198--4205},
	Title = {{Towards Faithfully Interpretable {NLP} Systems: How Should We Define and Evaluate Faithfulness?}},
	Year = {2020}}

@conference{Hancox-Li_fat_2020,
	Author = {Leif Hancox{-}Li},
	Booktitle = {Proceedings of the 3rd ACM Conference on Fairness, Accountability, and Transparency (FAT*)},
	Date-Added = {2020-08-25 22:58:31 +0100},
	Date-Modified = {2020-08-25 23:00:07 +0100},
	Month = {January 27--30},
	Organization = {Barcelona, Spain},
	Pages = {640--647},
	Title = {{Robustness in Machine Learning Explanations: Does It Matter?}},
	Year = {2020}}

@conference{Bansal_cvpr_2020,
	Author = {Naman Bansal and Chirag Agarwal and Anh Nguyen},
	Booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	Date-Added = {2020-08-25 22:40:54 +0100},
	Date-Modified = {2020-08-25 22:42:25 +0100},
	Month = {June 13--19},
	Organization = {Seattle, USA},
	Pages = {8670--8680},
	Title = {{{SAM:} The Sensitivity of Attribution Methods to Hyperparameters}},
	Year = {2020}}

@article{Warnecke_arXiv_2020,
	Author = {Alexander Warnecke and Daniel Arp and Christian Wressnegger and Konrad Rieck},
	Date-Added = {2020-08-20 02:35:52 +0100},
	Date-Modified = {2020-08-20 02:38:51 +0100},
	Journal = {arXiv e-prints},
	Title = {{Evaluating Explanation Methods for Deep Learning in Security}},
	Volume = {arXiv: 1906.02108},
	Year = {2020}}

@inproceedings{Bhatt_ijcai_2020,
	Author = {Umang Bhatt and Adrian Weller and Jos{\'{e}} M. F. Moura},
	Booktitle = {Proceedings of the 29th International Joint Conference on Artificial Intelligence (IJCAI)},
	Date-Added = {2020-08-20 02:17:11 +0100},
	Date-Modified = {2020-08-20 02:19:35 +0100},
	Month = {July},
	Organization = {Yokohama, Japan},
	Pages = {3016--3022},
	Title = {{Evaluating and Aggregating Feature-based Model Explanations}},
	Year = {2020}}

@article{Yang_arXiv_2019,
	Author = {Mengjiao Yang and Been Kim},
	Date-Added = {2020-08-20 02:13:48 +0100},
	Date-Modified = {2020-08-20 02:15:20 +0100},
	Journal = {arXiv e-prints},
	Title = {{Benchmarking Attribution Methods with Relative Feature Importance}},
	Volume = {arXiv:1907.09701},
	Year = {2019}}

@inproceedings{Lakkaraju_icml_2020,
	Author = {Himabindu Lakkaraju and Nino Arsov and Osbert Bastani},
	Booktitle = {Proceedings of the 37th International Conference on Machine Learning (ICML)},
	Date-Added = {2020-08-20 01:56:33 +0100},
	Date-Modified = {2020-08-20 01:58:03 +0100},
	Organization = {Vienna, Austria},
	Title = {{Robust and Stable Black Box Explanations}},
	Year = {2020}}

@article{Zhang_arXiv_2019,
	Author = {Yujia Zhang and Kuangyan Song and Yiming Sun and Sarah Tan and Madeilene Udell},
	Date-Added = {2020-08-20 01:52:16 +0100},
	Date-Modified = {2020-08-20 01:54:22 +0100},
	Journal = {arXiv e-prints},
	Title = {{Why should you trust my interpretation? Understanding uncertainty in {LIME} predictions}},
	Volume = {arXiv: 1904.12991},
	Year = {2019}}

@article{Melis_arXiv_2018,
	Author = {David Alvarez{-}Melis and Tommi S. Jaakkola},
	Date-Added = {2020-08-20 01:49:46 +0100},
	Date-Modified = {2020-08-20 01:50:36 +0100},
	Journal = {arXiv e-prints},
	Title = {{On the Robustness of Interpretability Methods}},
	Volume = {arXiv: 1806.08049},
	Year = {2018}}

@article{Anders_arXiv_2020,
	Author = {Christopher J. Anders and Plamen Pasliev and Ann{-}Kathrin Dombrowski and Klaus{-}Robert M{\"{u}}ller and Pan Kessel},
	Date-Added = {2020-08-20 01:45:27 +0100},
	Date-Modified = {2020-08-20 01:46:45 +0100},
	Journal = {arXiv e-prints},
	Title = {{Fairwashing Explanations with Off-Manifold Detergent}},
	Volume = {arXiv:2007.09969},
	Year = {2020}}

@inproceedings{Dimanov_aaai_ws_2020,
	Author = {Botty Dimanov and Umang Bhatt and Mateja Jamnik and Adrian Weller},
	Booktitle = {{Proceedings of the Workshop on Artificial Intelligence Safety 2020 co-located with the 34th {AAAI} Conference on Artificial Intelligence 2020 (AAAI)}},
	Date-Added = {2020-08-20 01:42:13 +0100},
	Date-Modified = {2020-08-20 01:44:42 +0100},
	Month = {February 7},
	Number = {63--73},
	Organization = {New York, USA},
	Title = {{You Shouldn't Trust Me: Learning Models Which Conceal Unfairness From Multiple Explanation Methods}},
	Year = {2020}}

@inproceedings{Heo_neurips_2019,
	Author = {Juyeon Heo and Sunghwan Joo and Taesup Moon},
	Booktitle = {Proceedings of the 32nd Conference on Neural Information Processing Systems (NeurIPS)},
	Date-Added = {2020-08-20 01:40:24 +0100},
	Date-Modified = {2020-08-20 01:41:43 +0100},
	Month = {December 8--14},
	Number = {2921--2932},
	Organization = {Vancouver, Canada},
	Title = {{Fooling Neural Network Interpretations via Adversarial Model Manipulation}},
	Year = {2019}}

@inproceedings{Slack_aies_2020,
	Author = {Dylan Slack and Sophie Hilgard and Emily Jia and Sameer Singh and Himabindu Lakkaraju},
	Booktitle = {Proceedings of the {AAAI/ACM} Conference on AI, Ethics, and Society (AIES)},
	Date-Added = {2020-08-20 01:16:04 +0100},
	Date-Modified = {2020-08-20 01:18:06 +0100},
	Month = {February 7--8},
	Number = {180--186},
	Organization = {New York, USA},
	Title = {{Fooling {LIME} and {SHAP:} Adversarial Attacks on Post hoc Explanation Methods}},
	Year = {2020}}

@inproceedings{Lakkaraju_aies_2020,
	Author = {Himabindu Lakkaraju and Osbert Bastani},
	Booktitle = {Proceedings of the {AAAI/ACM} Conference on AI, Ethics, and Society (AIES)},
	Date-Added = {2020-08-20 01:13:52 +0100},
	Date-Modified = {2020-08-20 01:18:12 +0100},
	Month = {February 7--8},
	Number = {79--85},
	Organization = {New York, USA},
	Title = {{"How do {I} fool you?": Manipulating User Trust via Misleading BlackBox Explanations}},
	Year = {2020}}

@inproceedings{Dombrowski_neurips_2019,
	Author = {Ann{-}Kathrin Dombrowski and Maximilian Alber and Christopher J. Anders and Marcel Ackermann and Klaus{-}Robert M{\"{u}}ller and Pan Kessel},
	Booktitle = {Proceedings of the 32nd Conference on Neural Information Processing Systems (NeurIPS)},
	Date-Added = {2020-08-20 01:05:58 +0100},
	Date-Modified = {2020-08-20 01:17:57 +0100},
	Month = {December 8--14},
	Organization = {Vancouver, Canada},
	Pages = {13567--13578},
	Title = {{Explanations can be manipulated and geometry is to blame}},
	Year = {2019}}

@inproceedings{Ghorbani_aaai_2019,
	Author = {Amirata Ghorbani and Abubakar Abid and James Y. Zou},
	Booktitle = {Proceedings of the 33rd AAAI Conference on Artificial Intelligence},
	Date-Added = {2020-08-20 00:59:38 +0100},
	Date-Modified = {2020-08-20 01:18:36 +0100},
	Month = {January 27-- February 1},
	Number = {3681--3688},
	Organization = {Honolulu, Hawaii, USA},
	Title = {{Interpretation of Neural Networks Is Fragile}},
	Year = {2019}}



