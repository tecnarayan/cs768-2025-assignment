\begin{thebibliography}{40}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Awasthi et~al.(2014)Awasthi, Balcan, and Long]{awasthi:14}
P.~Awasthi, M.~F. Balcan, and P.~M. Long.
\newblock The power of localization for efficiently learning linear separators
  with noise.
\newblock In \emph{Proceedings of the 46th Annual {ACM} Symposium on Theory of
  Computing}, pages 449--458, 2014.

\bibitem[Balcan et~al.(2022)Balcan, Blum, Hanneke, and
  Sharma]{balcan2022robustly}
Maria-Florina Balcan, Avrim Blum, Steve Hanneke, and Dravyansh Sharma.
\newblock Robustly-reliable learners under poisoning attacks.
\newblock \emph{arXiv preprint arXiv:2203.04160}, 2022.

\bibitem[Barreno et~al.(2006)Barreno, Nelson, Sears, Joseph, and
  Tygar]{barreno2006can}
Marco Barreno, Blaine Nelson, Russell Sears, Anthony~D Joseph, and J~Doug
  Tygar.
\newblock Can machine learning be secure?
\newblock In \emph{Proceedings of the 2006 ACM Symposium on Information,
  computer and communications security}, pages 16--25. ACM, 2006.

\bibitem[Blum et~al.(2021)Blum, Hanneke, Qian, and Shao]{blum2021robust}
Avrim Blum, Steve Hanneke, Jian Qian, and Han Shao.
\newblock obust learning under clean-label attack.
\newblock In \emph{Conference on Learning Theory}, 2021.

\bibitem[Bousquet and Elisseeff(2002)]{bousquet2002stability}
Olivier Bousquet and Andr{\'e} Elisseeff.
\newblock Stability and generalization.
\newblock \emph{The Journal of Machine Learning Research}, 2:\penalty0
  499--526, 2002.

\bibitem[Bousquet et~al.(2020)Bousquet, Hanneke, Moran, and
  Zhivotovskiy]{bousquet2020proper}
Olivier Bousquet, Steve Hanneke, Shay Moran, and Nikita Zhivotovskiy.
\newblock Proper learning, helly number, and an optimal svm bound.
\newblock In \emph{Conference on Learning Theory}, pages 582--609. PMLR, 2020.

\bibitem[Braverman et~al.(2019)Braverman, Kol, Moran, and
  Saxena]{braverman2019convex}
Mark Braverman, Gillat Kol, Shay Moran, and Raghuvansh~R Saxena.
\newblock Convex set disjointness, distributed learning of halfspaces, and lp
  feasibility.
\newblock \emph{arXiv preprint arXiv:1909.03547}, 2019.

\bibitem[Bshouty et~al.(2002)Bshouty, Eiron, and Kushilevitz]{bshouty2002pac}
Nader~H Bshouty, Nadav Eiron, and Eyal Kushilevitz.
\newblock Pac learning with nasty noise.
\newblock \emph{Theoretical Computer Science}, 288\penalty0 (2):\penalty0
  255--275, 2002.

\bibitem[Chakraborty et~al.(2018)Chakraborty, Alam, Dey, Chattopadhyay, and
  Mukhopadhyay]{chakraborty2018adversarial}
Anirban Chakraborty, Manaar Alam, Vishal Dey, Anupam Chattopadhyay, and Debdeep
  Mukhopadhyay.
\newblock Adversarial attacks and defences: A survey.
\newblock \emph{arXiv preprint arXiv:1810.00069}, 2018.

\bibitem[Chen et~al.(2020)Chen, Li, Wu, Sheng, and Li]{chen2020framework}
Ruoxin Chen, Jie Li, Chentao Wu, Bin Sheng, and Ping Li.
\newblock A framework of randomized selection based certified defenses against
  data poisoning attacks, 2020.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{cohen2019certified}
Jeremy Cohen, Elan Rosenfeld, and Zico Kolter.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock In \emph{International Conference on Machine Learning}, pages
  1310--1320. PMLR, 2019.

\bibitem[Diakonikolas et~al.(2018)Diakonikolas, Kane, and
  Stewart]{diakonikolas:18}
I.~Diakonikolas, D.~M. Kane, and A.~Stewart.
\newblock Learning geometric concepts with nasty noise.
\newblock In \emph{Proceedings of the 50th Annual {ACM SIGACT} Symposium on
  Theory of Computing}, pages 1061--1073, 2018.

\bibitem[Diakonikolas et~al.(2016)Diakonikolas, Kamath, Kane, Li, Moitra, and
  Stewart]{diakonikolas2016robust}
Ilias Diakonikolas, Gautam Kamath, Daniel~M Kane, Jerry Li, Ankur Moitra, and
  Alistair Stewart.
\newblock Robust estimators in high dimensions without the computational
  intractability.
\newblock In \emph{Foundations of Computer Science (FOCS), 2016 IEEE 57th
  Annual Symposium on}, pages 655--664. IEEE, 2016.

\bibitem[Etesami et~al.(2020)Etesami, Mahloujifar, and
  Mahmoody]{etesami2020computational}
Omid Etesami, Saeed Mahloujifar, and Mohammad Mahmoody.
\newblock Computational concentration of measure: Optimal bounds, reductions,
  and more.
\newblock In \emph{Proceedings of the Fourteenth Annual ACM-SIAM Symposium on
  Discrete Algorithms}, pages 345--363. SIAM, 2020.

\bibitem[Farhadkhani et~al.(2022)Farhadkhani, Guerraoui, Hoang, and
  Villemaud]{farhadkhani2022equivalence}
Sadegh Farhadkhani, Rachid Guerraoui, L\^{e}-Nguy\^{e}n Hoang, and Oscar
  Villemaud.
\newblock An equivalence between data poisoning and byzantine gradient attacks.
\newblock In \emph{International Conference on Machine Learning}, pages
  6284--6323. PMLR, 2022.

\bibitem[Gao et~al.(2021)Gao, Karbasi, and Mahmoody]{gao2021learning}
Ji~Gao, Amin Karbasi, and Mohammad Mahmoody.
\newblock Learning and certification under instance-targeted poisoning.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 2135--2145.
  PMLR, 2021.

\bibitem[Gu et~al.(2017)Gu, Dolan-Gavitt, and Garg]{gu2017badnets}
Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg.
\newblock Badnets: Identifying vulnerabilities in the machine learning model
  supply chain.
\newblock \emph{arXiv preprint arXiv:1708.06733}, 2017.

\bibitem[Haussler et~al.(1994)Haussler, Littlestone, and
  Warmuth]{haussler1994predicting}
David Haussler, Nick Littlestone, and Manfred~K Warmuth.
\newblock Predicting $\{$0, 1$\}$-functions on randomly drawn points.
\newblock \emph{Information and Computation}, 115\penalty0 (2):\penalty0
  248--292, 1994.

\bibitem[Jagielski et~al.(2021)Jagielski, Severi, Pousette~Harger, and
  Oprea]{jagielski2021subpopulation}
Matthew Jagielski, Giorgio Severi, Niklas Pousette~Harger, and Alina Oprea.
\newblock Subpopulation data poisoning attacks.
\newblock In \emph{Proceedings of the 2021 ACM SIGSAC Conference on Computer
  and Communications Security}, pages 3104--3122, 2021.

\bibitem[Ji et~al.(2017)Ji, Zhang, and Wang]{ji2017backdoor}
Yujie Ji, Xinyang Zhang, and Ting Wang.
\newblock Backdoor attacks against learning systems.
\newblock In \emph{2017 IEEE Conference on Communications and Network Security
  (CNS)}, pages 1--9. IEEE, 2017.

\bibitem[Jia et~al.(2020)Jia, Cao, and Gong]{jia2020intrinsic}
Jinyuan Jia, Xiaoyu Cao, and Neil~Zhenqiang Gong.
\newblock Intrinsic certified robustness of bagging against data poisoning
  attacks.
\newblock \emph{arXiv preprint arXiv:2008.04495}, 2020.

\bibitem[Kalai et~al.(2008)Kalai, Klivans, Mansour, and Servedio]{kalai:08}
A.~T. Kalai, A.~R. Klivans, Y.~Mansour, and R.~A. Servedio.
\newblock Agnostically learning halfspaces.
\newblock \emph{{SIAM} Journal on Computing}, 37\penalty0 (6):\penalty0
  1777--1805, 2008.

\bibitem[Kane et~al.(2019)Kane, Livni, Moran, and
  Yehudayoff]{kane2019communication}
Daniel Kane, Roi Livni, Shay Moran, and Amir Yehudayoff.
\newblock On communication complexity of classification problems.
\newblock In \emph{Conference on Learning Theory}, pages 1903--1943. PMLR,
  2019.

\bibitem[Kearns and Li(1993)]{kearns1993learning}
Michael Kearns and Ming Li.
\newblock Learning in the presence of malicious errors.
\newblock \emph{SIAM Journal on Computing}, 22\penalty0 (4):\penalty0 807--837,
  1993.

\bibitem[Klivans et~al.(2009)Klivans, Long, and Servedio]{klivans:09}
A.~R. Klivans, P.~M. Long, and R.~A. Servedio.
\newblock Learning halfspaces with malicious noise.
\newblock \emph{Journal of Machine Learning Research}, 10\penalty0 (12), 2009.

\bibitem[Lai et~al.(2016)Lai, Rao, and Vempala]{lai2016agnostic}
Kevin~A Lai, Anup~B Rao, and Santosh Vempala.
\newblock Agnostic estimation of mean and covariance.
\newblock In \emph{Foundations of Computer Science (FOCS), 2016 IEEE 57th
  Annual Symposium on}, pages 665--674. IEEE, 2016.

\bibitem[Levine and Feizi(2020)]{levine2020deep}
Alexander Levine and Soheil Feizi.
\newblock Deep partition aggregation: Provable defenses against general
  poisoning attacks.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Long(1999)]{long1999complexity}
Philip~M Long.
\newblock The complexity of learning according to two models of a drifting
  environment.
\newblock \emph{Machine Learning}, 37\penalty0 (3):\penalty0 337--354, 1999.

\bibitem[Mahloujifar and Mahmoody(2017)]{mahloujifar2017blockwise}
Saeed Mahloujifar and Mohammad Mahmoody.
\newblock Blockwise p-tampering attacks on cryptographic primitives,
  extractors, and learners.
\newblock In \emph{Theory of Cryptography Conference}, pages 245--279.
  Springer, 2017.

\bibitem[Rakhlin et~al.(2005)Rakhlin, Mukherjee, and
  Poggio]{rakhlin2005stability}
Alexander Rakhlin, Sayan Mukherjee, and Tomaso Poggio.
\newblock Stability results in learning theory.
\newblock \emph{Analysis and Applications}, 3\penalty0 (04):\penalty0 397--417,
  2005.

\bibitem[Rosenfeld et~al.(2020)Rosenfeld, Winston, Ravikumar, and
  Kolter]{rosenfeld2020certified}
Elan Rosenfeld, Ezra Winston, Pradeep Ravikumar, and Zico Kolter.
\newblock Certified robustness to label-flipping attacks via randomized
  smoothing.
\newblock In \emph{International Conference on Machine Learning}, pages
  8230--8241. PMLR, 2020.

\bibitem[Shafahi et~al.(2018)Shafahi, Huang, Najibi, Suciu, Studer, Dumitras,
  and Goldstein]{shafahi2018poison}
Ali Shafahi, W~Ronny Huang, Mahyar Najibi, Octavian Suciu, Christoph Studer,
  Tudor Dumitras, and Tom Goldstein.
\newblock Poison frogs! targeted clean-label poisoning attacks on neural
  networks.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Shalev-Shwartz and Ben-David(2014)]{shalev2014understanding}
Shai Shalev-Shwartz and Shai Ben-David.
\newblock \emph{Understanding machine learning: From theory to algorithms}.
\newblock Cambridge university press, 2014.

\bibitem[Sloan(1995)]{Sloan::Noise:four-types}
Robert~H. Sloan.
\newblock {Four Types of Noise in Data for {PAC} Learning}.
\newblock \emph{Information Processing Letters}, 54\penalty0 (3):\penalty0
  157--162, 1995.

\bibitem[Steinhardt et~al.(2017)Steinhardt, Koh, and
  Liang]{steinhardt2017certified}
Jacob Steinhardt, Pang~Wei Koh, and Percy Liang.
\newblock Certified defenses for data poisoning attacks.
\newblock In \emph{Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pages 3520--3532, 2017.

\bibitem[Suya et~al.(2021)Suya, Mahloujifar, Suri, Evans, and
  Tian]{suya2021model}
Fnu Suya, Saeed Mahloujifar, Anshuman Suri, David Evans, and Yuan Tian.
\newblock Model-targeted poisoning attacks with provable convergence.
\newblock In \emph{International Conference on Machine Learning}, pages
  10000--10010. PMLR, 2021.

\bibitem[Talagrand(1995)]{talagrand1995concentration}
Michel Talagrand.
\newblock Concentration of measure and isoperimetric inequalities in product
  spaces.
\newblock \emph{Publications Math{\'e}matiques de l'Institut des Hautes Etudes
  Scientifiques}, 81\penalty0 (1):\penalty0 73--205, 1995.

\bibitem[Valiant(1985)]{valiant1985learning}
Leslie~G Valiant.
\newblock Learning disjunction of conjunctions.
\newblock In \emph{IJCAI}, pages 560--566, 1985.

\bibitem[Vapnik and Chervonenkis(1974)]{vapnik1974theory}
Vladimir Vapnik and Alexey Chervonenkis.
\newblock Theory of pattern recognition.
\newblock 1974.

\bibitem[Weber et~al.(2020)Weber, Xu, Karlas, Zhang, and Li]{weber2020rab}
Maurice Weber, Xiaojun Xu, Bojan Karlas, Ce~Zhang, and Bo~Li.
\newblock Rab: Provable robustness against backdoor attacks.
\newblock \emph{arXiv preprint arXiv:2003.08904}, 2020.

\end{thebibliography}
