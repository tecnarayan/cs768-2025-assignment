\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{bengio2013estimating}
Y.~Bengio, N.~L{\'e}onard, and A.~Courville.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock {\em arXiv preprint arXiv:1308.3432}, 2013.

\bibitem{berner2019dota}
C.~Berner, G.~Brockman, B.~Chan, V.~Cheung, P.~D{\k{e}}biak, C.~Dennison,
  D.~Farhi, Q.~Fischer, S.~Hashme, C.~Hesse, et~al.
\newblock Dota 2 with large scale deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1912.06680}, 2019.

\bibitem{bogin2018emergence}
B.~Bogin, M.~Geva, and J.~Berant.
\newblock Emergence of communication in an interactive world with consistent
  speakers.
\newblock {\em arXiv preprint arXiv:1809.00549}, 2018.

\bibitem{brockman2016openai}
G.~Brockman, V.~Cheung, L.~Pettersson, J.~Schneider, J.~Schulman, J.~Tang, and
  W.~Zaremba.
\newblock Openai gym.
\newblock {\em arXiv preprint arXiv:1606.01540}, 2016.

\bibitem{cao2018emergent}
K.~Cao, A.~Lazaridou, M.~Lanctot, J.~Z. Leibo, K.~Tuyls, and S.~Clark.
\newblock Emergent communication through negotiation.
\newblock {\em arXiv preprint arXiv:1804.03980}, 2018.

\bibitem{gym_minigrid}
M.~Chevalier-Boisvert, L.~Willems, and S.~Pal.
\newblock Minimalistic gridworld environment for openai gym.
\newblock \url{https://github.com/maximecb/gym-minigrid}, 2018.

\bibitem{choi2018compositional}
E.~Choi, A.~Lazaridou, and N.~de~Freitas.
\newblock Compositional obverter communication learning from raw visual input.
\newblock {\em arXiv preprint arXiv:1804.02341}, 2018.

\bibitem{chung2014empirical}
J.~Chung, C.~Gulcehre, K.~Cho, and Y.~Bengio.
\newblock Empirical evaluation of gated recurrent neural networks on sequence
  modeling.
\newblock {\em arXiv preprint arXiv:1412.3555}, 2014.

\bibitem{dafoe2020open}
A.~Dafoe, E.~Hughes, Y.~Bachrach, T.~Collins, K.~R. McKee, J.~Z. Leibo,
  K.~Larson, and T.~Graepel.
\newblock Open problems in cooperative ai.
\newblock {\em arXiv preprint arXiv:2012.08630}, 2020.

\bibitem{das2019tarmac}
A.~Das, T.~Gervet, J.~Romoff, D.~Batra, D.~Parikh, M.~Rabbat, and J.~Pineau.
\newblock Tarmac: Targeted multi-agent communication.
\newblock In {\em International Conference on Machine Learning}, pages
  1538--1546. PMLR, 2019.

\bibitem{eccles2019biases}
T.~Eccles, Y.~Bachrach, G.~Lever, A.~Lazaridou, and T.~Graepel.
\newblock Biases for emergent communication in multi-agent reinforcement
  learning.
\newblock {\em arXiv preprint arXiv:1912.05676}, 2019.

\bibitem{ester1996density}
M.~Ester, H.-P. Kriegel, J.~Sander, X.~Xu, et~al.
\newblock A density-based algorithm for discovering clusters in large spatial
  databases with noise.
\newblock In {\em Kdd}, volume~96, pages 226--231, 1996.

\bibitem{evtimova2017emergent}
K.~Evtimova, A.~Drozdov, D.~Kiela, and K.~Cho.
\newblock Emergent communication in a multi-modal, multi-step referential game.
\newblock {\em arXiv preprint arXiv:1705.10369}, 2017.

\bibitem{farrell1987cheap}
J.~Farrell.
\newblock Cheap talk, coordination, and entry.
\newblock {\em The RAND Journal of Economics}, pages 34--39, 1987.

\bibitem{foerster2018counterfactual}
J.~Foerster, G.~Farquhar, T.~Afouras, N.~Nardelli, and S.~Whiteson.
\newblock Counterfactual multi-agent policy gradients.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem{foerster2019bayesian}
J.~Foerster, F.~Song, E.~Hughes, N.~Burch, I.~Dunning, S.~Whiteson,
  M.~Botvinick, and M.~Bowling.
\newblock Bayesian action decoder for deep multi-agent reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  1942--1951. PMLR, 2019.

\bibitem{foerster2016riddles}
J.~N. Foerster, Y.~M. Assael, N.~de~Freitas, and S.~Whiteson.
\newblock Learning to communicate to solve riddles with deep distributed
  recurrent q-networks.
\newblock {\em arXiv preprint arXiv:1602.02672}, 2016.

\bibitem{foerster2016learning}
J.~N. Foerster, Y.~M. Assael, N.~De~Freitas, and S.~Whiteson.
\newblock Learning to communicate with deep multi-agent reinforcement learning.
\newblock {\em arXiv preprint arXiv:1605.06676}, 2016.

\bibitem{graesser2019emergent}
L.~Graesser, K.~Cho, and D.~Kiela.
\newblock Emergent linguistic phenomena in multi-agent communication games.
\newblock {\em arXiv preprint arXiv:1901.08706}, 2019.

\bibitem{harnad1990symbol}
S.~Harnad.
\newblock The symbol grounding problem.
\newblock {\em Physica D: Nonlinear Phenomena}, 42(1-3):335--346, 1990.

\bibitem{hurford1989biological}
J.~R. Hurford.
\newblock Biological evolution of the saussurean sign as a component of the
  language acquisition device.
\newblock {\em Lingua}, 77(2):187--222, 1989.

\bibitem{jaques2019social}
N.~Jaques, A.~Lazaridou, E.~Hughes, C.~Gulcehre, P.~Ortega, D.~Strouse, J.~Z.
  Leibo, and N.~De~Freitas.
\newblock Social influence as intrinsic motivation for multi-agent deep
  reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  3040--3049. PMLR, 2019.

\bibitem{kingma2014adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{konda2000actor}
V.~R. Konda and J.~N. Tsitsiklis.
\newblock Actor-critic algorithms.
\newblock In {\em Advances in neural information processing systems}, pages
  1008--1014. Citeseer, 2000.

\bibitem{krizhevsky2009learning}
A.~Krizhevsky, G.~Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock (0), 2009.

\bibitem{lazaridou2018emergence}
A.~Lazaridou, K.~M. Hermann, K.~Tuyls, and S.~Clark.
\newblock Emergence of linguistic communication from referential games with
  symbolic and pixel input.
\newblock {\em arXiv preprint arXiv:1804.03984}, 2018.

\bibitem{lewis2008convention}
D.~Lewis.
\newblock {\em Convention: A philosophical study}.
\newblock John Wiley \& Sons, 2008.

\bibitem{littman1994markov}
M.~L. Littman.
\newblock Markov games as a framework for multi-agent reinforcement learning.
\newblock In {\em Machine learning proceedings 1994}, pages 157--163. Elsevier,
  1994.

\bibitem{lowe2019pitfalls}
R.~Lowe, J.~Foerster, Y.-L. Boureau, J.~Pineau, and Y.~Dauphin.
\newblock On the pitfalls of measuring emergent communication.
\newblock {\em arXiv preprint arXiv:1903.05168}, 2019.

\bibitem{lowe2017multi}
R.~Lowe, Y.~Wu, A.~Tamar, J.~Harb, P.~Abbeel, and I.~Mordatch.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock {\em arXiv preprint arXiv:1706.02275}, 2017.

\bibitem{macwhinney2013emergence}
B.~MacWhinney.
\newblock {\em The emergence of language from embodiment}.
\newblock Psychology Press, 2013.

\bibitem{mnih2016asynchronous}
V.~Mnih, A.~P. Badia, M.~Mirza, A.~Graves, T.~Lillicrap, T.~Harley, D.~Silver,
  and K.~Kavukcuoglu.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In {\em International conference on machine learning}, pages
  1928--1937. PMLR, 2016.

\bibitem{mnih2013playing}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~Graves, I.~Antonoglou, D.~Wierstra, and
  M.~Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1312.5602}, 2013.

\bibitem{mordatch2018emergence}
I.~Mordatch and P.~Abbeel.
\newblock Emergence of grounded compositional language in multi-agent
  populations.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem{marlgrid}
K.~Ndousse.
\newblock marlgrid.
\newblock \url{https://github.com/kandouss/marlgrid}, 2020.

\bibitem{noukhovitch2021emergent}
M.~Noukhovitch, T.~LaCroix, A.~Lazaridou, and A.~Courville.
\newblock Emergent communication under competition.
\newblock {\em arXiv preprint arXiv:2101.10276}, 2021.

\bibitem{nowak1999evolution}
M.~A. Nowak and D.~C. Krakauer.
\newblock The evolution of language.
\newblock {\em Proceedings of the National Academy of Sciences},
  96(14):8028--8033, 1999.

\bibitem{roy2002learning}
D.~K. Roy and A.~P. Pentland.
\newblock Learning words from sights and sounds: A computational model.
\newblock {\em Cognitive science}, 26(1):113--146, 2002.

\bibitem{schulman2015high}
J.~Schulman, P.~Moritz, S.~Levine, M.~Jordan, and P.~Abbeel.
\newblock High-dimensional continuous control using generalized advantage
  estimation.
\newblock {\em arXiv preprint arXiv:1506.02438}, 2015.

\bibitem{shapley1953stochastic}
L.~S. Shapley.
\newblock Stochastic games.
\newblock {\em Proceedings of the national academy of sciences},
  39(10):1095--1100, 1953.

\bibitem{steels1997synthetic}
L.~Steels.
\newblock The synthetic modeling of language origins.
\newblock {\em Evolution of communication}, 1(1):1--34, 1997.

\bibitem{steels2000aibo}
L.~Steels and F.~Kaplan.
\newblock Aiboâ€™s first words: The social learning of language and meaning.
\newblock {\em Evolution of communication}, 4(1):3--32, 2000.

\bibitem{sukhbaatar2016learning}
S.~Sukhbaatar, A.~Szlam, and R.~Fergus.
\newblock Learning multiagent communication with backpropagation.
\newblock {\em arXiv preprint arXiv:1605.07736}, 2016.

\bibitem{tomasello2010origins}
M.~Tomasello.
\newblock {\em Origins of human communication}.
\newblock MIT press, 2010.

\bibitem{udagawa2019natural}
T.~Udagawa and A.~Aizawa.
\newblock A natural language corpus of common grounding under continuous and
  partially-observable context.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 7120--7127, 2019.

\bibitem{van2008visualizing}
L.~Van~der Maaten and G.~Hinton.
\newblock Visualizing data using t-sne.
\newblock {\em Journal of machine learning research}, 9(11), 2008.

\bibitem{xie2020learning}
A.~Xie, D.~P. Losey, R.~Tolsma, C.~Finn, and D.~Sadigh.
\newblock Learning latent representations to influence multi-agent interaction.
\newblock {\em arXiv preprint arXiv:2011.06619}, 2020.

\bibitem{zintgraf2021deep}
L.~Zintgraf, S.~Devlin, K.~Ciosek, S.~Whiteson, and K.~Hofmann.
\newblock Deep interactive bayesian reinforcement learning via meta-learning.
\newblock {\em arXiv preprint arXiv:2101.03864}, 2021.

\end{thebibliography}
