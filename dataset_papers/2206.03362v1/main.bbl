\begin{thebibliography}{70}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abernethy et~al.(2021)Abernethy, Awasthi, and
  Kale]{abernethy2021multiclass}
Abernethy, J., Awasthi, P., and Kale, S.
\newblock A multiclass boosting framework for achieving fast and provable
  adversarial robustness.
\newblock \emph{arXiv preprint arXiv:2103.01276}, 2021.

\bibitem[Andriushchenko et~al.(2020)Andriushchenko, Croce, Flammarion, and
  Hein]{Andriushchenko2020SquareAA}
Andriushchenko, M., Croce, F., Flammarion, N., and Hein, M.
\newblock Square attack: a query-efficient black-box adversarial attack via
  random search.
\newblock \emph{ArXiv}, abs/1912.00049, 2020.

\bibitem[Athalye et~al.(2018{\natexlab{a}})Athalye, Carlini, and
  Wagner]{athalye2018obfuscated}
Athalye, A., Carlini, N., and Wagner, D.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{International conference on machine learning}, pp.\
  274--283. PMLR, 2018{\natexlab{a}}.

\bibitem[Athalye et~al.(2018{\natexlab{b}})Athalye, Carlini, and
  Wagner]{Athalye2018ObfuscatedGG}
Athalye, A., Carlini, N., and Wagner, D.~A.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{ICML}, 2018{\natexlab{b}}.

\bibitem[Audibert(2009)]{audibert2009fast}
Audibert, J.-Y.
\newblock Fast learning rates in statistical inference through aggregation.
\newblock \emph{The Annals of Statistics}, 37\penalty0 (4):\penalty0
  1591--1646, 2009.

\bibitem[Bartlett et~al.(1998)Bartlett, Freund, Lee, and
  Schapire]{bartlett1998boosting}
Bartlett, P., Freund, Y., Lee, W.~S., and Schapire, R.~E.
\newblock Boosting the margin: A new explanation for the effectiveness of
  voting methods.
\newblock \emph{The annals of statistics}, 26\penalty0 (5):\penalty0
  1651--1686, 1998.

\bibitem[Bartlett(1998)]{bartlett1998sample}
Bartlett, P.~L.
\newblock The sample complexity of pattern classification with neural networks:
  the size of the weights is more important than the size of the network.
\newblock \emph{IEEE transactions on Information Theory}, 44\penalty0
  (2):\penalty0 525--536, 1998.

\bibitem[Blum et~al.(2020)Blum, Dick, Manoj, and Zhang]{blum2020random}
Blum, A., Dick, T., Manoj, N., and Zhang, H.
\newblock Random smoothing might be unable to certify $\ell_\infty$ robustness
  for high-dimensional images.
\newblock \emph{Journal of Machine Learning Research}, 21:\penalty0 1--21,
  2020.

\bibitem[Breiman(1999)]{breiman1999prediction}
Breiman, L.
\newblock Prediction games and arcing algorithms.
\newblock \emph{Neural computation}, 11\penalty0 (7):\penalty0 1493--1517,
  1999.

\bibitem[Bubeck et~al.(2019)Bubeck, Lee, Price, and
  Razenshteyn]{bubeck2019adversarial}
Bubeck, S., Lee, Y.~T., Price, E., and Razenshteyn, I.
\newblock Adversarial examples from computational constraints.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  831--840. PMLR, 2019.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{Carlini2017TowardsET}
Carlini, N. and Wagner, D.~A.
\newblock Towards evaluating the robustness of neural networks.
\newblock \emph{2017 IEEE Symposium on Security and Privacy (SP)}, pp.\
  39--57, 2017.

\bibitem[Carmon et~al.(2019)Carmon, Raghunathan, Schmidt, Liang, and
  Duchi]{Carmon2019UnlabeledDI}
Carmon, Y., Raghunathan, A., Schmidt, L., Liang, P., and Duchi, J.~C.
\newblock Unlabeled data improves adversarial robustness.
\newblock \emph{ArXiv}, abs/1905.13736, 2019.

\bibitem[Catoni(2004)]{catoni2004statistical}
Catoni, O.
\newblock \emph{Statistical learning theory and stochastic optimization: Ecole
  d'Et{\'e} de Probabilit{\'e}s de Saint-Flour, XXXI-2001}, volume 1851.
\newblock Springer Science \& Business Media, 2004.

\bibitem[Cesa-Bianchi \& Lugosi(2006)Cesa-Bianchi and
  Lugosi]{cesa2006prediction}
Cesa-Bianchi, N. and Lugosi, G.
\newblock \emph{Prediction, learning, and games}.
\newblock Cambridge university press, 2006.

\bibitem[Chen \& Guestrin(2016)Chen and Guestrin]{chen2016xgboost}
Chen, T. and Guestrin, C.
\newblock Xgboost: A scalable tree boosting system.
\newblock In \emph{Proceedings of the 22nd acm sigkdd international conference
  on knowledge discovery and data mining}, pp.\  785--794, 2016.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{cohen2019certified}
Cohen, J., Rosenfeld, E., and Kolter, Z.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1310--1320. PMLR, 2019.

\bibitem[Croce \& Hein(2020{\natexlab{a}})Croce and Hein]{Croce2020MinimallyDA}
Croce, F. and Hein, M.
\newblock Minimally distorted adversarial examples with a fast adaptive
  boundary attack.
\newblock In \emph{ICML}, 2020{\natexlab{a}}.

\bibitem[Croce \& Hein(2020{\natexlab{b}})Croce and Hein]{Croce2020ReliableEO}
Croce, F. and Hein, M.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock \emph{ArXiv}, abs/2003.01690, 2020{\natexlab{b}}.

\bibitem[Fan(1953)]{fan1953minimax}
Fan, K.
\newblock Minimax theorems.
\newblock \emph{Proceedings of the National Academy of Sciences of the United
  States of America}, 39\penalty0 (1):\penalty0 42, 1953.

\bibitem[Fawzi et~al.(2018)Fawzi, Fawzi, and Frossard]{fawzi2018analysis}
Fawzi, A., Fawzi, O., and Frossard, P.
\newblock Analysis of classifiers’ robustness to adversarial perturbations.
\newblock \emph{Machine Learning}, 107\penalty0 (3):\penalty0 481--508, 2018.

\bibitem[Freund \& Schapire(1995)Freund and Schapire]{freund1995desicion}
Freund, Y. and Schapire, R.~E.
\newblock A desicion-theoretic generalization of on-line learning and an
  application to boosting.
\newblock In \emph{European conference on computational learning theory}, pp.\
  23--37. Springer, 1995.

\bibitem[Freund et~al.(1996)Freund, Schapire, et~al.]{freund1996experiments}
Freund, Y., Schapire, R.~E., et~al.
\newblock Experiments with a new boosting algorithm.
\newblock In \emph{icml}, volume~96, pp.\  148--156. Citeseer, 1996.

\bibitem[Friedman(2001)]{friedman2001greedy}
Friedman, J.~H.
\newblock Greedy function approximation: a gradient boosting machine.
\newblock \emph{Annals of statistics}, pp.\  1189--1232, 2001.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Hazan(2016)]{hazan2016introduction}
Hazan, E.
\newblock Introduction to online convex optimization.
\newblock \emph{Foundations and Trends in Optimization}, 2\penalty0
  (3-4):\penalty0 157--325, 2016.

\bibitem[Huang et~al.(2017)Huang, Ash, Langford, and
  Schapire]{huang2017learning}
Huang, F., Ash, J., Langford, J., and Schapire, R.
\newblock Learning deep resnet blocks sequentially using boosting theory.
\newblock \emph{arXiv preprint arXiv:1706.04964}, 2017.

\bibitem[Ilyas et~al.(2019)Ilyas, Santurkar, Tsipras, Engstrom, Tran, and
  Madry]{ilyas2019adversarial}
Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., and Madry, A.
\newblock Adversarial examples are not bugs, they are features.
\newblock \emph{arXiv preprint arXiv:1905.02175}, 2019.

\bibitem[Kalai \& Vempala(2005)Kalai and Vempala]{kalai2005efficient}
Kalai, A. and Vempala, S.
\newblock Efficient algorithms for online decision problems.
\newblock \emph{Journal of Computer and System Sciences}, 71\penalty0
  (3):\penalty0 291--307, 2005.

\bibitem[Kariyappa \& Qureshi(2019)Kariyappa and
  Qureshi]{kariyappa2019improving}
Kariyappa, S. and Qureshi, M.~K.
\newblock Improving adversarial robustness of ensembles with diversity
  training.
\newblock \emph{arXiv preprint arXiv:1901.09981}, 2019.

\bibitem[Khim \& Loh(2018)Khim and Loh]{khim2018adversarial}
Khim, J. and Loh, P.-L.
\newblock Adversarial risk bounds via function transformation.
\newblock \emph{arXiv preprint arXiv:1810.09519}, 2018.

\bibitem[Krichene et~al.(2015)Krichene, Balandat, Tomlin, and
  Bayen]{krichene2015hedge}
Krichene, W., Balandat, M., Tomlin, C., and Bayen, A.
\newblock The hedge algorithm on a continuum.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  824--832, 2015.

\bibitem[Maddison et~al.(2014)Maddison, Tarlow, and
  Minka]{maddison2014sampling}
Maddison, C.~J., Tarlow, D., and Minka, T.
\newblock A* sampling.
\newblock \emph{arXiv preprint arXiv:1411.0030}, 2014.

\bibitem[Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \emph{arXiv preprint arXiv:1706.06083}, 2017.

\bibitem[Malmberg \& H{\"o}ssjer(2012)Malmberg and
  H{\"o}ssjer]{malmberg2012argmax}
Malmberg, H. and H{\"o}ssjer, O.
\newblock Argmax over continuous indices of random variables--an approach using
  random fields.
\newblock Technical report, Technical report, Division of Mathematical
  Statistics, Department of~…, 2012.

\bibitem[Mason et~al.(2000{\natexlab{a}})Mason, Bartlett, and
  Baxter]{mason2000improved}
Mason, L., Bartlett, P.~L., and Baxter, J.
\newblock Improved generalization through explicit optimization of margins.
\newblock \emph{Machine Learning}, 38\penalty0 (3):\penalty0 243--255,
  2000{\natexlab{a}}.

\bibitem[Mason et~al.(2000{\natexlab{b}})Mason, Baxter, Bartlett, and
  Frean]{mason2000boosting}
Mason, L., Baxter, J., Bartlett, P.~L., and Frean, M.~R.
\newblock Boosting algorithms as gradient descent.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  512--518, 2000{\natexlab{b}}.

\bibitem[McMahan(2017)]{mcmahan2017survey}
McMahan, H.~B.
\newblock A survey of algorithms and analysis for adaptive online learning.
\newblock \emph{The Journal of Machine Learning Research}, 18\penalty0
  (1):\penalty0 3117--3166, 2017.

\bibitem[Meng et~al.(2020)Meng, Su, O'Kane, and Jamshidi]{meng2020athena}
Meng, Y., Su, J., O'Kane, J., and Jamshidi, P.
\newblock Athena: A framework based on diverse weak defenses for building
  adversarial defense.
\newblock \emph{arXiv preprint arXiv:2001.00308}, 2020.

\bibitem[Mukherjee \& Schapire(2013)Mukherjee and
  Schapire]{mukherjee2013theory}
Mukherjee, I. and Schapire, R.~E.
\newblock A theory of multiclass boosting.
\newblock \emph{Journal of Machine Learning Research}, 14\penalty0
  (Feb):\penalty0 437--497, 2013.

\bibitem[Nitanda \& Suzuki(2018)Nitanda and Suzuki]{nitanda2018functional}
Nitanda, A. and Suzuki, T.
\newblock Functional gradient boosting based on residual network perception.
\newblock \emph{arXiv preprint arXiv:1802.09031}, 2018.

\bibitem[Pang et~al.(2019)Pang, Xu, Du, Chen, and Zhu]{pang2019improving}
Pang, T., Xu, K., Du, C., Chen, N., and Zhu, J.
\newblock Improving adversarial robustness via promoting ensemble diversity.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4970--4979. PMLR, 2019.

\bibitem[Pang et~al.(2021)Pang, Yang, Dong, Su, and Zhu]{Pang2021BagOT}
Pang, T., Yang, X., Dong, Y., Su, H., and Zhu, J.
\newblock Bag of tricks for adversarial training.
\newblock \emph{ArXiv}, abs/2010.00467, 2021.

\bibitem[Pinot et~al.(2020)Pinot, Ettedgui, Rizk, Chevaleyre, and
  Atif]{Pinot2020RandomizationMH}
Pinot, R., Ettedgui, R., Rizk, G., Chevaleyre, Y., and Atif, J.
\newblock Randomization matters. how to defend against strong adversarial
  attacks.
\newblock In \emph{ICML}, 2020.

\bibitem[Raghunathan et~al.(2018)Raghunathan, Steinhardt, and
  Liang]{raghunathan2018certified}
Raghunathan, A., Steinhardt, J., and Liang, P.
\newblock Certified defenses against adversarial examples.
\newblock \emph{arXiv preprint arXiv:1801.09344}, 2018.

\bibitem[R{\"a}tsch et~al.(2005)R{\"a}tsch, Warmuth, and
  Shawe-Taylor]{ratsch2005efficient}
R{\"a}tsch, G., Warmuth, M.~K., and Shawe-Taylor, J.
\newblock Efficient margin maximizing with boosting.
\newblock \emph{Journal of Machine Learning Research}, 6\penalty0 (12), 2005.

\bibitem[Rice et~al.(2020)Rice, Wong, and Kolter]{Rice2020OverfittingIA}
Rice, L., Wong, E., and Kolter, J.~Z.
\newblock Overfitting in adversarially robust deep learning.
\newblock In \emph{ICML}, 2020.

\bibitem[Salman et~al.(2019)Salman, Yang, Li, Zhang, Zhang, Razenshteyn, and
  Bubeck]{salman2019provably}
Salman, H., Yang, G., Li, J., Zhang, P., Zhang, H., Razenshteyn, I., and
  Bubeck, S.
\newblock Provably robust deep learning via adversarially trained smoothed
  classifiers.
\newblock In \emph{Proceedings of the 33rd International Conference on Neural
  Information Processing Systems}, pp.\  11292--11303, 2019.

\bibitem[Schapire \& Singer(1999)Schapire and Singer]{schapire1999improved}
Schapire, R.~E. and Singer, Y.
\newblock Improved boosting algorithms using confidence-rated predictions.
\newblock \emph{Machine learning}, 37\penalty0 (3):\penalty0 297--336, 1999.

\bibitem[Sen et~al.(2020)Sen, Ravindran, and Raghunathan]{sen2019empir}
Sen, S., Ravindran, B., and Raghunathan, A.
\newblock {EMPIR:} ensembles of mixed precision deep networks for increased
  robustness against adversarial attacks.
\newblock In \emph{8th International Conference on Learning Representations,
  {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}. OpenReview.net, 2020.
\newblock URL \url{https://openreview.net/forum?id=HJem3yHKwH}.

\bibitem[Shi et~al.(2020)Shi, Zhang, Dai, Zhu, Mu, and
  Wang]{Shi2020InformativeDF}
Shi, B., Zhang, D., Dai, Q., Zhu, Z., Mu, Y., and Wang, J.
\newblock Informative dropout for robust representation learning: A shape-bias
  perspective.
\newblock \emph{ArXiv}, abs/2008.04254, 2020.

\bibitem[Sion(1958)]{sion1958general}
Sion, M.
\newblock On general minimax theorems.
\newblock \emph{Pacific Journal of mathematics}, 8\penalty0 (1):\penalty0
  171--176, 1958.

\bibitem[Soudry et~al.(2018)Soudry, Hoffer, Nacson, Gunasekar, and
  Srebro]{soudry2018implicit}
Soudry, D., Hoffer, E., Nacson, M.~S., Gunasekar, S., and Srebro, N.
\newblock The implicit bias of gradient descent on separable data.
\newblock \emph{The Journal of Machine Learning Research}, 19\penalty0
  (1):\penalty0 2822--2878, 2018.

\bibitem[Suggala et~al.(2020)Suggala, Liu, and
  Ravikumar]{suggala2020generalized}
Suggala, A., Liu, B., and Ravikumar, P.
\newblock Generalized boosting.
\newblock \emph{Advances in neural information processing systems}, 2020.

\bibitem[Suggala \& Netrapalli(2020)Suggala and Netrapalli]{suggala2020online}
Suggala, A.~S. and Netrapalli, P.
\newblock Online non-convex learning: Following the perturbed leader is
  optimal.
\newblock In \emph{Algorithmic Learning Theory}, pp.\  845--861. PMLR, 2020.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{Szegedy2014IntriguingPO}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow,
  I.~J., and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock \emph{CoRR}, abs/1312.6199, 2014.

\bibitem[Telgarsky(2011)]{telgarsky2011fast}
Telgarsky, M.
\newblock The fast convergence of boosting.
\newblock In \emph{NIPS}, pp.\  1593--1601, 2011.

\bibitem[Tramer et~al.(2020)Tramer, Carlini, Brendel, and
  Madry]{tramer2020adaptive}
Tramer, F., Carlini, N., Brendel, W., and Madry, A.
\newblock On adaptive attacks to adversarial example defenses.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Verma \& Swami(2019)Verma and Swami]{verma2019error}
Verma, G. and Swami, A.
\newblock Error correcting output codes improve probability estimation and
  adversarial robustness of deep neural networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 8646--8656, 2019.

\bibitem[Wang et~al.(2019{\natexlab{a}})Wang, Ma, Bailey, Yi, Zhou, and
  Gu]{Wang2019OnTC}
Wang, Y., Ma, X., Bailey, J., Yi, J., Zhou, B., and Gu, Q.
\newblock On the convergence and robustness of adversarial training.
\newblock \emph{ArXiv}, abs/2112.08304, 2019{\natexlab{a}}.

\bibitem[Wang et~al.(2019{\natexlab{b}})Wang, Zou, Yi, Bailey, Ma, and
  Gu]{wang2019improving}
Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., and Gu, Q.
\newblock Improving adversarial robustness requires revisiting misclassified
  examples.
\newblock In \emph{International Conference on Learning Representations},
  2019{\natexlab{b}}.

\bibitem[Wong \& Kolter(2018)Wong and Kolter]{wong2018provable}
Wong, E. and Kolter, Z.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5286--5295. PMLR, 2018.

\bibitem[Wu et~al.(2020)Wu, Xia, and Wang]{Wu2020AdversarialWP}
Wu, D., Xia, S., and Wang, Y.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock \emph{arXiv: Learning}, 2020.

\bibitem[Yang et~al.(2021)Yang, Li, Xu, Kailkhura, Xie, and
  Li]{yang2021certified}
Yang, Z., Li, L., Xu, X., Kailkhura, B., Xie, T., and Li, B.
\newblock On the certified robustness for ensemble models and beyond.
\newblock \emph{arXiv preprint arXiv:2107.10873}, 2021.

\bibitem[Yin et~al.(2019)Yin, Kannan, and Bartlett]{yin2019rademacher}
Yin, D., Kannan, R., and Bartlett, P.
\newblock Rademacher complexity for adversarially robust generalization.
\newblock In \emph{International conference on machine learning}, pp.\
  7085--7094. PMLR, 2019.

\bibitem[Zhang et~al.(2019{\natexlab{a}})Zhang, Zhang, Lu, Zhu, and
  Dong]{Zhang2019YouOP}
Zhang, D., Zhang, T., Lu, Y., Zhu, Z., and Dong, B.
\newblock You only propagate once: Accelerating adversarial training via
  maximal principle.
\newblock \emph{ArXiv}, abs/1905.00877, 2019{\natexlab{a}}.

\bibitem[Zhang et~al.(2020{\natexlab{a}})Zhang, Ye, Gong, Zhu, and
  Liu]{Zhang2020BlackBoxCW}
Zhang, D., Ye, M., Gong, C., Zhu, Z., and Liu, Q.
\newblock Black-box certification with randomized smoothing: A functional
  optimization based framework.
\newblock \emph{ArXiv}, abs/2002.09169, 2020{\natexlab{a}}.

\bibitem[Zhang et~al.(2019{\natexlab{b}})Zhang, Yu, Jiao, Xing, El~Ghaoui, and
  Jordan]{zhang2019theoretically}
Zhang, H., Yu, Y., Jiao, J., Xing, E., El~Ghaoui, L., and Jordan, M.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7472--7482. PMLR, 2019{\natexlab{b}}.

\bibitem[Zhang et~al.(2020{\natexlab{b}})Zhang, Xu, Han, Niu, zhen Cui,
  Sugiyama, and Kankanhalli]{Zhang2020AttacksWD}
Zhang, J., Xu, X., Han, B., Niu, G., zhen Cui, L., Sugiyama, M., and
  Kankanhalli, M.~S.
\newblock Attacks which do not kill training make adversarial learning
  stronger.
\newblock In \emph{ICML}, 2020{\natexlab{b}}.

\bibitem[Zhang et~al.(2020{\natexlab{c}})Zhang, Zhu, Niu, Han, Sugiyama, and
  Kankanhalli]{Zhang2020GEOMETRYAWAREIA}
Zhang, J., Zhu, J., Niu, G., Han, B., Sugiyama, M., and Kankanhalli, M.~S.
\newblock Geometry-aware instance-reweighted adver-.
\newblock 2020{\natexlab{c}}.

\end{thebibliography}
