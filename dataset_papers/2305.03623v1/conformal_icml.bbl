\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Awad et~al.(2021)Awad, Mallik, and Hutter]{awad-ijcai21}
Awad, N., Mallik, N., and Hutter, F.
\newblock Dehb: Evolutionary hyberband for scalable, robust and efficient
  hyperparameter optimization.
\newblock In \emph{Proceedings of the Thirtieth International Joint Conference
  on Artificial Intelligence (IJCAI'21)}, 2021.

\bibitem[Bassett \& Koenker(1982)Bassett and Koenker]{1982}
Bassett, G. and Koenker, R.
\newblock An empirical quantile function for linear models with iid errors.
\newblock \emph{Journal of the American Statistical Association}, 77\penalty0
  (378):\penalty0 407–415, Jun 1982.
\newblock ISSN 1537-274X.
\newblock \doi{10.1080/01621459.1982.10477826}.
\newblock URL \url{http://dx.doi.org/10.1080/01621459.1982.10477826}.

\bibitem[Bergstra \& Bengio(2012)Bergstra and Bengio]{bergstra-jmlr12a}
Bergstra, J. and Bengio, Y.
\newblock Random search for hyper-parameter optimization.
\newblock \emph{Journal of Machine Learning Research}, 2012.

\bibitem[Bergstra et~al.()Bergstra, Bardenet, Bengio, and Kegl]{Bergstra:11}
Bergstra, J., Bardenet, R., Bengio, Y., and Kegl, B.
\newblock Algorithms for hyperparameter optimization.
\newblock pp.\  2546--2554.

\bibitem[Bergstra et~al.(2011)Bergstra, Bardenet, Bengio, and
  K{\'e}gl]{bergstra-nips11a}
Bergstra, J., Bardenet, R., Bengio, Y., and K{\'e}gl, B.
\newblock Algorithms for hyper-parameter optimization.
\newblock In \emph{Proceedings of the 24th International Conference on Advances
  in Neural Information Processing Systems (NIPS'11)}, 2011.

\bibitem[Chen \& Guestrin(2016)Chen and Guestrin]{chen2016xgboost}
Chen, T. and Guestrin, C.
\newblock Xgboost: A scalable tree boosting system.
\newblock In \emph{Proceedings of the 22nd acm sigkdd international conference
  on knowledge discovery and data mining}, pp.\  785--794, 2016.

\bibitem[Cowen-Rivers et~al.(2020)Cowen-Rivers, Lyu, Tutunov, Wang, Grosnit,
  Griffiths, Maraval, Jianye, Wang, Peters, and Ammar]{cowen2020hebo}
Cowen-Rivers, A.~I., Lyu, W., Tutunov, R., Wang, Z., Grosnit, A., Griffiths,
  R.~R., Maraval, A.~M., Jianye, H., Wang, J., Peters, J., and Ammar, H.~B.
\newblock Hebo pushing the limits of sample-efficient hyperparameter
  optimisation, 2020.
\newblock URL \url{https://arxiv.org/abs/2012.03826}.

\bibitem[Dem{\v{s}}ar(2006)]{demsar06a}
Dem{\v{s}}ar, J.
\newblock Statistical comparisons of classifiers over multiple data sets.
\newblock \emph{Journal of Machine Learning Research}, 7\penalty0 (1):\penalty0
  1--30, 2006.
\newblock URL \url{http://jmlr.org/papers/v7/demsar06a.html}.

\bibitem[Domhan et~al.(2015)Domhan, Springenberg, and Hutter]{domhan:15}
Domhan, T., Springenberg, J.~T., and Hutter, F.
\newblock Speeding up automatic hyperparameter optimization of deep neural
  networks by extrapolation of learning curves.
\newblock In \emph{Twenty-fourth international joint conference on artificial
  intelligence}, 2015.

\bibitem[Dong \& Yang(2020)Dong and Yang]{Dong:20}
Dong, X. and Yang, Y.
\newblock {NAS-Bench-201}: Extending the scope of reproducible neural
  architecture search.
\newblock Technical Report arXiv:2001.00326 [cs.CV], 2020.

\bibitem[Doyle(2022)]{doyle-arxiv22}
Doyle, R.
\newblock Model agnostic conformal hyperparameter optimization.
\newblock \emph{arXiv:2207.03017 [cs.LG]}, 2022.

\bibitem[Falkner et~al.(2018)Falkner, Klein, and Hutter]{Falkner:18}
Falkner, S., Klein, A., and Hutter, F.
\newblock {BOHB}: Robust and efficient hyperparameter optimization at scale.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning (ICML 2018)}, pp.\  1436--1445, 2018.

\bibitem[Feurer \& Hutter(2018)Feurer and Hutter]{feurer-automlbook18a}
Feurer, M. and Hutter, F.
\newblock Hyperparameter optimization.
\newblock In \emph{Automatic Machine Learning: Methods, Systems, Challenges}.
  Springer, 2018.

\bibitem[Friedman(2001)]{Friedman2001}
Friedman, J.~H.
\newblock Greedy function approximation: A gradient boosting machine.
\newblock \emph{The Annals of Statistics}, 29\penalty0 (5):\penalty0
  1189--1232, 2001.
\newblock ISSN 00905364.
\newblock URL \url{http://www.jstor.org/stable/2699986}.

\bibitem[Gasthaus et~al.(2019)Gasthaus, Benidis, Wang, Rangapuram, Salinas,
  Flunkert, and Januschowski]{gasthaus19a}
Gasthaus, J., Benidis, K., Wang, Y., Rangapuram, S.~S., Salinas, D., Flunkert,
  V., and Januschowski, T.
\newblock Probabilistic forecasting with spline quantile function rnns.
\newblock In Chaudhuri, K. and Sugiyama, M. (eds.), \emph{Proceedings of the
  Twenty-Second International Conference on Artificial Intelligence and
  Statistics}, volume~89 of \emph{Proceedings of Machine Learning Research},
  pp.\  1901--1910. PMLR, 16--18 Apr 2019.
\newblock URL \url{https://proceedings.mlr.press/v89/gasthaus19a.html}.

\bibitem[Hutter et~al.(2011)Hutter, Hoos, and Leyton-Brown]{hutter-lion11a}
Hutter, F., Hoos, H., and Leyton-Brown, K.
\newblock Sequential model-based optimization for general algorithm
  configuration.
\newblock In \emph{Proceedings of the Fifth International Conference on
  Learning and Intelligent Optimization (LION'11)}, 2011.

\bibitem[Jamieson \& Talwalkar(2016)Jamieson and Talwalkar]{jamieson-aistats16}
Jamieson, K. and Talwalkar, A.
\newblock Non-stochastic best arm identification and hyperparameter
  optimization.
\newblock In \emph{Proceedings of the 17th International Conference on
  Artificial Intelligence and Statistics (AISTATS'16)}, 2016.

\bibitem[Jones et~al.(1998)Jones, Schonlau, and Welch]{jones1998efficient}
Jones, D.~R., Schonlau, M., and Welch, W.~J.
\newblock Efficient global optimization of expensive black-box functions.
\newblock \emph{Journal of Global optimization}, 13\penalty0 (4):\penalty0 455,
  1998.

\bibitem[Karnin et~al.(2013)Karnin, Koren, and Somekh]{karnin13}
Karnin, Z., Koren, T., and Somekh, O.
\newblock Almost optimal exploration in multi-armed bandits.
\newblock In Dasgupta, S. and McAllester, D. (eds.), \emph{Proceedings of the
  30th International Conference on Machine Learning}, volume~28 of
  \emph{Proceedings of Machine Learning Research}, pp.\  1238--1246, Atlanta,
  Georgia, USA, 17--19 Jun 2013. PMLR.
\newblock URL \url{https://proceedings.mlr.press/v28/karnin13.html}.

\bibitem[Klein \& Hutter(2019)Klein and Hutter]{Klein:19a}
Klein, A. and Hutter, F.
\newblock Tabular benchmarks for joint architecture and hyperparameter
  optimization.
\newblock Technical Report arXiv:1905.04970 [cs.LG], 2019.

\bibitem[Klein et~al.(2017)Klein, Falkner, Springenberg, and
  Hutter]{klein-iclr17}
Klein, A., Falkner, S., Springenberg, J.~T., and Hutter, F.
\newblock Learning curve prediction with {Bayesian} neural networks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR'17)}, 2017.

\bibitem[Klein et~al.(2020)Klein, Tiao, Lienart, Archambeau, and
  Seeger]{Klein:mobster}
Klein, A., Tiao, L., Lienart, T., Archambeau, C., and Seeger, M.
\newblock Model-based asynchronous hyperparameter and neural architecture
  search.
\newblock Number 2003.10865 [cs.LG], 2020.

\bibitem[Kuleshov et~al.(2018)Kuleshov, Fenner, and Ermon]{Kuleshov2018}
Kuleshov, V., Fenner, N., and Ermon, S.
\newblock Accurate uncertainties for deep learning using calibrated regression.
\newblock \emph{CoRR}, abs/1807.00263, 2018.
\newblock URL \url{http://arxiv.org/abs/1807.00263}.

\bibitem[Li et~al.(2017)Li, Jamieson, DeSalvo, Rostamizadeh, and
  Talwalkar]{li-iclr17}
Li, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., and Talwalkar, A.
\newblock Hyperband: Bandit-based configuration evaluation for hyperparameter
  optimization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR'17)}, 2017.

\bibitem[Li et~al.(2019)Li, Jamieson, Rostamizadeh, Gonina, Hardt, Recht, and
  Talwalkar]{Li:19}
Li, L., Jamieson, K., Rostamizadeh, A., Gonina, E., Hardt, M., Recht, B., and
  Talwalkar, A.
\newblock Massively parallel hyperparameter tuning.
\newblock Technical Report 1810.05934v4 [cs.LG], 2019.

\bibitem[Li et~al.(2022)Li, Shen, Jiang, Zhang, Li, Liu, Zhang, and
  Cui]{Yang2022}
Li, Y., Shen, Y., Jiang, H., Zhang, W., Li, J., Liu, J., Zhang, C., and Cui, B.
\newblock Hyper-tune: Towards efficient hyper-parameter tuning at scale.
\newblock \emph{Proc. VLDB Endow.}, 15\penalty0 (6):\penalty0 1256–1265, jun
  2022.
\newblock ISSN 2150-8097.
\newblock \doi{10.14778/3514061.3514071}.
\newblock URL \url{https://doi.org/10.14778/3514061.3514071}.

\bibitem[Mohr \& van Rijn(2022)Mohr and van Rijn]{mohr-arxiv22}
Mohr, F. and van Rijn, J.~N.
\newblock Learning curves for decision making in supervised machine learning --
  a survey.
\newblock \emph{arXiv:2201.12150 [cs.LG]}, 2022.

\bibitem[Moriconi et~al.(2020)Moriconi, Kumar, and
  Deisenroth]{moriconi2020high}
Moriconi, R., Kumar, K.~S., and Deisenroth, M.~P.
\newblock High-dimensional bayesian optimization with projections using
  quantile gaussian processes.
\newblock \emph{Optimization Letters}, 14:\penalty0 51--64, 2020.

\bibitem[Pfisterer et~al.(2022)Pfisterer, Schneider, Moosbauer, Binder, and
  Bischl]{pfisterer2022yahpo}
Pfisterer, F., Schneider, L., Moosbauer, J., Binder, M., and Bischl, B.
\newblock Yahpo gym-an efficient multi-objective multi-fidelity benchmark for
  hyperparameter optimization.
\newblock In \emph{First Conference on Automated Machine Learning (Main
  Track)}, 2022.

\bibitem[Picheny et~al.(2013)Picheny, Ginsbourger, Richet, and
  Caplin]{Picheny13}
Picheny, V., Ginsbourger, D., Richet, Y., and Caplin, G.
\newblock Quantile-based optimization of noisy computer experiments with
  tunable precision.
\newblock \emph{Technometrics}, 55\penalty0 (1):\penalty0 2--13, 2013.
\newblock \doi{10.1080/00401706.2012.707580}.
\newblock URL \url{https://doi.org/10.1080/00401706.2012.707580}.

\bibitem[Real et~al.(2019)Real, Aggarwal, Huang, and Le]{real2019}
Real, E., Aggarwal, A., Huang, Y., and Le, Q.~V.
\newblock Regularized evolution for image classifier architecture search, 2019.

\bibitem[Romano et~al.(2019)Romano, Patterson, and Candès]{romano}
Romano, Y., Patterson, E., and Candès, E.~J.
\newblock Conformalized quantile regression.
\newblock 2019.
\newblock \doi{10.48550/ARXIV.1905.03222}.

\bibitem[Salinas et~al.(2020)Salinas, Shen, and Perrone]{salinas20a}
Salinas, D., Shen, H., and Perrone, V.
\newblock A quantile-based approach for hyperparameter transfer learning.
\newblock In III, H.~D. and Singh, A. (eds.), \emph{Proceedings of the 37th
  International Conference on Machine Learning}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pp.\  8438--8448. PMLR,
  13--18 Jul 2020.
\newblock URL \url{https://proceedings.mlr.press/v119/salinas20a.html}.

\bibitem[Salinas et~al.(2022)Salinas, Seeger, Klein, Perrone, Wistuba, and
  Archambeau]{salinas2022syne}
Salinas, D., Seeger, M., Klein, A., Perrone, V., Wistuba, M., and Archambeau,
  C.
\newblock Syne tune: A library for large scale hyperparameter tuning and
  reproducible research.
\newblock In \emph{International Conference on Automated Machine Learning},
  pp.\  16--1. PMLR, 2022.

\bibitem[Shafer \& Vovk(2007)Shafer and Vovk]{Shafer07}
Shafer, G. and Vovk, V.
\newblock A tutorial on conformal prediction.
\newblock \emph{CoRR}, abs/0706.3188, 2007.
\newblock URL \url{http://arxiv.org/abs/0706.3188}.

\bibitem[Shahriari et~al.(2016)Shahriari, Swersky, Wang, Adams, and
  de~Freitas]{shahriari-ieee16a}
Shahriari, B., Swersky, K., Wang, Z., Adams, R., and de~Freitas, N.
\newblock Taking the human out of the loop: {A} review of {B}ayesian
  optimization.
\newblock \emph{Proceedings of the {IEEE}}, 2016.

\bibitem[Siems et~al.(2020)Siems, Zimmer, Zela, Lukasik, Keuper, and
  Hutter]{nas301}
Siems, J., Zimmer, L., Zela, A., Lukasik, J., Keuper, M., and Hutter, F.
\newblock Nas-bench-301 and the case for surrogate benchmarks for neural
  architecture search.
\newblock \emph{CoRR}, abs/2008.09777, 2020.
\newblock URL \url{https://arxiv.org/abs/2008.09777}.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{snoek-nips12a}
Snoek, J., Larochelle, H., and Adams, R.~P.
\newblock Practical {B}ayesian optimization of machine learning algorithms.
\newblock In \emph{Proceedings of the 25th International Conference on Advances
  in Neural Information Processing Systems (NIPS'12)}, 2012.

\bibitem[Snoek et~al.(2015)Snoek, Rippel, Swersky, Kiros, Satish, Sundaram,
  Patwary, Prabhat, and Adams]{snoek-icml15}
Snoek, J., Rippel, O., Swersky, K., Kiros, R., Satish, N., Sundaram, N.,
  Patwary, M., Prabhat, and Adams, R.
\newblock Scalable {B}ayesian optimization using deep neural networks.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning (ICML'15)}, 2015.

\bibitem[Springenberg et~al.(2016)Springenberg, Klein, Falkner, and
  Hutter]{springenberg-nips16}
Springenberg, J.~T., Klein, A., Falkner, S., and Hutter, F.
\newblock Bayesian optimization with robust bayesian neural networks.
\newblock In \emph{Proceedings of the 29th International Conference on Advances
  in Neural Information Processing Systems (NIPS'16)}, 2016.

\bibitem[Srinivas et~al.(2012)Srinivas, Krause, Kakade, and
  Seeger]{Srinivas2012}
Srinivas, N., Krause, A., Kakade, S.~M., and Seeger, M.~W.
\newblock Information-theoretic regret bounds for gaussian process optimization
  in the bandit setting.
\newblock \emph{{IEEE} Transactions on Information Theory}, 58\penalty0
  (5):\penalty0 3250--3265, may 2012.
\newblock \doi{10.1109/tit.2011.2182033}.
\newblock URL \url{https://doi.org/10.1109%2Ftit.2011.2182033}.

\bibitem[Stanton et~al.(2022)Stanton, Maddox, and Wilson]{Stanton22}
Stanton, S., Maddox, W., and Wilson, A.~G.
\newblock Bayesian optimization with conformal coverage guarantees, 2022.
\newblock URL \url{https://arxiv.org/abs/2210.12496}.

\bibitem[Swersky et~al.(2014)Swersky, Snoek, and Adams]{Swersky:14}
Swersky, K., Snoek, J., and Adams, R.~P.
\newblock Freeze-thaw bayesian optimization, 2014.
\newblock URL \url{https://arxiv.org/abs/1406.3896}.

\bibitem[Tiao et~al.(2021)Tiao, Klein, Seeger, Bonilla, Archambeau, and
  Ramos]{tiao2021bore}
Tiao, L.~C., Klein, A., Seeger, M.~W., Bonilla, E.~V., Archambeau, C., and
  Ramos, F.
\newblock {BORE}: {Bayesian} optimization by density-ratio estimation.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  10289--10300. PMLR, 2021.

\bibitem[Wistuba \& Pedapati(2020)Wistuba and Pedapati]{wistuba20a}
Wistuba, M. and Pedapati, T.
\newblock Learning to rank learning curves.
\newblock In III, H.~D. and Singh, A. (eds.), \emph{Proceedings of the 37th
  International Conference on Machine Learning}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pp.\  10303--10312. PMLR,
  13--18 Jul 2020.

\bibitem[Zimmer et~al.(2021)Zimmer, Lindauer, and Hutter]{zimmer2021}
Zimmer, L., Lindauer, M., and Hutter, F.
\newblock Auto-{PyTorch} {Tabular}: {Multi}-{Fidelity} {MetaLearning} for
  {Efficient} and {Robust} {AutoDL}.
\newblock \emph{arXiv:2006.13799 [cs, stat]}, April 2021.
\newblock URL \url{http://arxiv.org/abs/2006.13799}.
\newblock arXiv: 2006.13799.

\end{thebibliography}
