@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2019}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@article{silver2016mastering,
  author = {Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  title = {{Mastering the Game of Go with Deep Neural Networks and Tree Search}},
  journal = {Nature},
  volume = {529},
  number = {7587},
  pages = {484--489},
  year = {2016},
  publisher = {Nature Research}
}

@article{mnih2015human,
  title = {{Human-Level Control Through Deep Reinforcement Learning}},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal = {Nature},
  volume = {518},
  number = {7540},
  pages = {529--533},
  year = {2015},
  publisher = {Nature Research}
}

@inproceedings{chen2019large,
  title={Large-scale interactive recommendation with tree-structured policy gradient},
  author={Chen, Haokun and Dai, Xinyi and Cai, Han and Zhang, Weinan and Wang, Xuejian and Tang, Ruiming and Zhang, Yuzhou and Yu, Yong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI'19)},
  pages={3312--3320},
  year={2019}
}

@inproceedings{pei2019value,
  title={Value-aware Recommendation based on Reinforcement Profit Maximization},
  author={Pei, Changhua and Yang, Xinru and Cui, Qing and Lin, Xiao and Sun, Fei and Jiang, Peng and Ou, Wenwu and Zhang, Yongfeng},
  booktitle={Proceedings of The World Wide Web Conference 2019 (WWW'19)},
  pages={3123--3129},
  year={2019}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={Proceedings of the 2017 IEEE International Conference on Robotics and Automation (ICRA'17)},
  pages={3389--3396},
  year={2017}
}

@inproceedings{haarnoja2018composable,
  title={Composable deep reinforcement learning for robotic manipulation},
  author={Haarnoja, Tuomas and Pong, Vitchyr and Zhou, Aurick and Dalal, Murtaza and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA'18)},
  pages={6244--6251},
  year={2018}
}

@inproceedings{lample2017playing,
  title={Playing FPS games with deep reinforcement learning},
  author={Lample, Guillaume and Chaplot, Devendra Singh},
  booktitle={Proceedings of the 31st AAAI Conference on Artificial Intelligence (AAAI'17)},
  pages={2140--2146},
  year={2017}
}

@inproceedings{song2019playing,
  title={Playing FPS games with environment-aware hierarchical reinforcement learning},
  author={Song, Shihong and Weng, Jiayi and Su, Hang and Yan, Dong and Zou, Haosheng and Zhu, Jun},
  booktitle={Proceedings of the 28th International Joint Conference on Artificial Intelligence (AAAI'19)},
  pages={3475--3482},
  year={2019}
}

@Article{dorigo1994robot,
  title={Robot shaping: Developing autonomous agents through learning},
  author={Dorigo, Marco and Colombetti, Marco},
  journal={Artificial intelligence},
  volume={71},
  number={2},
  pages={321--370},
  year={1994},
  publisher={Elsevier}
}

@inproceedings{randlov1998learning,
  title={Learning to Drive a Bicycle Using Reinforcement Learning and Shaping},
  author={Randl{\o}v, Jette and Alstr{\o}m, Preben},
  booktitle={Proceedings of the 15th International Conference on Machine Learning {(ICML}'98)},
  pages={463--471},
  year={1998}
}

@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={Proceedings of the 16th International Conference on Machine Learning {(ICML}'99)},
  pages={278--287},
  year={1999}
}

@inproceedings{wiewiora2003principled,
  title={Principled methods for advising reinforcement learning agents},
  author={Wiewiora, Eric and Cottrell, Garrison W and Elkan, Charles},
  booktitle={Proceedings of the 20th International Conference on Machine Learning (ICML'03)},
  pages={792--799},
  year={2003}
}

@inproceedings{devlin2012dynamic,
  title={Dynamic potential-based reward shaping},
  author={Devlin, Sam Michael and Kudenko, Daniel},
  booktitle={Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems (AAMAS'12)},
  pages={433--440},
  year={2012}
}

@inproceedings{harutyunyan2015expressing,
  title={Expressing arbitrary reward functions as potential-based advice},
  author={Harutyunyan, Anna and Devlin, Sam and Vrancx, Peter and Nowe, Ann},
  booktitle={Proceedings of the 29th AAAI Conference on Artificial Intelligence (AAAI'15)},
  pages={2652--2658},
  year={2015}
}

@inproceedings{grzes2008learning,
  title={Learning potential for reward shaping in reinforcement learning with tile coding},
  author={Grzes, Marek and Kudenko, Daniel},
  booktitle={Proceedings of the AAMAS 2008 Workshop on Adaptive and Learning Agents and Multi-Agent Systems (ALAMAS-ALAg 2008)},
  pages={17--23},
  year={2008}
}


@inproceedings{sutton2000policy,
  author    = {Richard S. Sutton and
               David A. McAllester and
               Satinder P. Singh and
               Yishay Mansour},
  title     = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
  booktitle = {Proceedings of Advances in Neural Information Processing Systems 12 (NIPS'00)},
  pages     = {1057--1063},
  year      = {1999},
}

@inproceedings{SilverLHDWR14,
  author    = {David Silver and
               Guy Lever and
               Nicolas Heess and
               Thomas Degris and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Deterministic Policy Gradient Algorithms},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning ({ICML}'14)},
  pages     = {387--395},
  year      = {2014}
}


@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={Proceedings of the 33rd International Conference on Machine Learning ({ICML}'16)},
  pages={1928--1937},
  year={2016}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={Proceedings of the 32nd International Conference on Machine Learning ({ICML}'15)},
  pages={1889--1897},
  year={2015}
}

@Article{SchulmanWDRK17,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal={arXiv preprint},
  volume={{arXiv:1707.06347}},
  year      = {2017},
}

@inproceedings{LillicrapHPHETS15,
  author    = {Timothy P. Lillicrap and
               Jonathan J. Hunt and
               Alexander Pritzel and
               Nicolas Heess and
               Tom Erez and
               Yuval Tassa and
               David Silver and
               Daan Wierstra},
  title     = {Continuous control with deep reinforcement learning},
  booktitle = {Proceedings of the 4th International Conference on Learning Representations ({ICLR'16})},
  year      = {2016}
}

@inproceedings{fujimoto2018addressing,
  title={Addressing Function Approximation Error in Actor-Critic Methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={Proceedings of the 35th International Conference on Machine Learning ({ICML}'18)},
  pages={1582--1591},
  year={2018}
}

@inproceedings{HaarnojaZAL18,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning ({ICML}'18)},
  pages     = {1856--1865},
  year      = {2018}
}

@inproceedings{Marthi07,
  author    = {Bhaskara Marthi},
  title     = {Automatic shaping and decomposition of reward functions},
  booktitle = {Proceedings of the 24th International Conference on Machine Learning {(ICML}'07)},
  pages     = {601--608},
  year      = {2007}
}

@Article{Wiewiora03JAIR,
  author    = {Eric Wiewiora},
  title     = {Potential-Based Shaping and Q-Value Initialization are Equivalent},
  journal   = {J. Artif. Intell. Res.},
  volume    = {19},
  pages     = {205--208},
  year      = {2003}
}

@inproceedings{LaudD03,
  author    = {Adam Laud and
               Gerald DeJong},
  title     = {The Influence of Reward on the Speed of Reinforcement Learning: An Analysis of Shaping},
  booktitle = {Proceedings of the 20th International Conference on Machine Learning {(ICML}'03)},
  pages     = {440--447},
  year      = {2003}
}

@inproceedings{MaromR18,
  author    = {Ofir Marom and Benjamin Rosman},
  title     = {Belief Reward Shaping in Reinforcement Learning},
  booktitle = {Proceedings of the 32nd {AAAI} Conference on Artificial Intelligence (AAAI'18)},
  pages     = {3762--3769},
  year      = {2018}
}

@inproceedings{DevlinK11,
  author    = {Sam Devlin and
               Daniel Kudenko},
  title     = {Theoretical considerations of potential-based reward shaping for multi-agent
               systems},
  booktitle = {Proceedings of the 10th International Conference on Autonomous Agents and Multiagent Systems {(AAMAS}'11)},
  pages     = {225--232},
  year      = {2011}
}

@inproceedings{SunCWL18,
  author    = {Fan{-}Yun Sun and
               Yen{-}Yu Chang and
               Yueh{-}Hua Wu and
               Shou{-}De Lin},
  title     = {Designing Non-greedy Reinforcement Learning Agents with Diminishing
               Reward Shaping},
  booktitle = {Proceedings of the 2018 {AAAI/ACM} Conference on AI, Ethics, and Society ({AIES} 2018)},
  pages     = {297--302},
  year      = {2018}
}

@inproceedings{WuL18,
  author    = {Yueh{-}Hua Wu and
               Shou{-}De Lin},
  title     = {A Low-Cost Ethics Shaping Approach for Designing Reinforcement Learning Agents},
  booktitle = {Proceedings of the 32nd {AAAI} Conference on Artificial Intelligence (AAAI'18)},
  pages     = {1687--1694},
  year      = {2018}
}

@Article{HaoshengZouArXiv-1901-09330,
  author    = {Haosheng Zou and
               Tongzheng Ren and
               Dong Yan and
               Hang Su and
               Jun Zhu},
  title     = {Reward Shaping via Meta-Learning},
  journal   = {arXiv preprint},
  volume    = {{arXiv:1901.09330}},
  year      = {2019}
}

@inproceedings{FuZLL19,
  author    = {Zhao{-}Yang Fu and
               De{-}Chuan Zhan and
               Xin{-}Chun Li and
               Yi{-}Xing Lu},
  title     = {Automatic Successive Reinforcement Learning with Multiple Auxiliary Rewards},
  booktitle = {Proceedings of the 28th International Joint Conference on Artificial Intelligence ({IJCAI}'19)},
  pages     = {2336--2342},
  year      = {2019}
}

@inproceedings{SinghBC04,
  author    = {Satinder P. Singh and
               Andrew G. Barto and
               Nuttapong Chentanez},
  title     = {Intrinsically Motivated Reinforcement Learning},
  booktitle = {Advances in Neural Information Processing Systems 17 ({NIPS}'04)},
  pages     = {1281--1288},
  year      = {2004}
}

@inproceedings{SorgSL10,
  author    = {Jonathan Sorg and
               Satinder P. Singh and
               Richard L. Lewis},
  title     = {Reward Design via Online Gradient Ascent},
  booktitle = {Advances in Neural Information Processing Systems 23 ({NIPS'10})},
  pages     = {2190--2198},
  year      = {2010}
}

@inproceedings{ZhengOS18,
  author    = {Zeyu Zheng and
               Junhyuk Oh and
               Satinder Singh},
  title     = {On Learning Intrinsic Rewards for Policy Gradient Methods},
  booktitle = {Advances in Neural Information Processing Systems 31 ({NeurIPS'18})},
  pages     = {4649--4659},
  year      = {2018}
}

@inproceedings{PathakAED17,
  author    = {Deepak Pathak and
               Pulkit Agrawal and
               Alexei A. Efros and
               Trevor Darrell},
  title     = {Curiosity-driven Exploration by Self-supervised Prediction},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning ({ICML}'17)},
  pages     = {2778--2787},
  year      = {2017}
}

@Article{HaifengZhangArXiv-1909-03510,
  author    = {Haifeng Zhang and
               Weizhe Chen and
               Zeren Huang and
               Minne Li and
               Yaodong Yang and
               Weinan Zhang and
               Jun Wang},
  title     = {Bi-level Actor-Critic for Multi-agent Coordination},
  journal   = {arXiv preprint},
  volume    = {{arXiv:1909.03510}},
  year      = {2019}
}

@misc{Halit2017Unpublished,
  title= {Reward Shaping by Demonstration},
  author= {Halit Bener Suay and
            Tim Brys and
            Matthew E. Taylor and
            Sonia Chernova},
  year= {2017}
}

@inproceedings{TesslerMM19,
  author    = {Chen Tessler and
               Daniel J. Mankowitz and
               Shie Mannor},
  title     = {Reward Constrained Policy Optimization},
  booktitle = {Proceedings of the 7th International Conference on Learning Representations ({ICLR}'19)},
  year      = {2019}
}

@misc{OpenAI_dota,
      author = {OpenAI},
      title = {OpenAI Five},
      howpublished = {{\url{https://blog.openai.com/openai-five/}}},
      year = {2018}
}


@inproceedings{zheng2019can,
  author = {Zheng, Zeyu and
            Oh, Junhyuk and
            Hessel, Matteo and
            Xu, Zhongwen and
            Kroiss, Manuel and
            van Hasselt, Hado and
            Silver, David and
            Singh, Satinder},
  title = {What Can Learned Intrinsic Rewards Capture?},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning ({ICML}'20)},
  year = {2019}
}


@Article{jaderberg2019human,
  title={Human-level performance in 3D multiplayer games with population-based reinforcement learning},
  author={Jaderberg, Max and Czarnecki, Wojciech M and Dunning, Iain and Marris, Luke and Lever, Guy and Castaneda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C and Morcos, Ari S and Ruderman, Avraham and others},
  journal={Science},
  volume={364},
  number={6443},
  pages={859--865},
  year={2019},
}


@inproceedings{milli2017should,
  title={Should robots be obedient?},
  author={Milli, Smitha and Hadfield-Menell, Dylan and Dragan, Anca and Russell, Stuart},
  booktitle={Proceedings of the 26th International Joint Conference on Artificial Intelligence},
  pages={4754--4760},
  year={2017}
}
