\begin{thebibliography}{10}

\bibitem{robbins1951stochastic}
H.~Robbins and S.~Monro.
\newblock A stochastic approximation method.
\newblock {\em The Annals of Mathematical Statistics}, 22(3):400--407, Sep.
  1951.

\bibitem{Zhang:2004}
T.~Zhang.
\newblock Solving large scale linear prediction problems using stochastic
  gradient descent algorithms.
\newblock In {\em Twenty-first International Conference on Machine Learning
  (ICML 2004)}, 2004.

\bibitem{bottou2010large}
L.~Bottou.
\newblock {Large-scale machine learning with stochastic gradient descent}.
\newblock In {\em {Proceedings of the 19th Int. Conf. on Computational
  Statistic (COMPSTAT)}}, pages 177--186. Springer, 2010.

\bibitem{hoffman2013stochastic}
M.D. Hoffman, D.M. Blei, C.~Wang, and J.~Paisley.
\newblock Stochastic variational inference.
\newblock {\em Journal of Machine Learning Research}, 14(1):1303--1347, 2013.

\bibitem{hensman2012fast}
J.~Hensman, M.~Rattray, and N.D. Lawrence.
\newblock Fast variational inference in the conjugate exponential family.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS 25)},
  pages 2888--2896, 2012.

\bibitem{StreamingBayes}
T.~Broderick, N.~Boyd, A.~Wibisono, A.C. Wilson, and M.I. Jordan.
\newblock Streaming variational {B}ayes.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS 26)},
  pages 1727--1735, 2013.

\bibitem{george2006adaptive}
A.P. George and W.B. Powell.
\newblock Adaptive stepsizes for recursive estimation with applications in
  approximate dynamic programming.
\newblock {\em Machine Learning}, 65(1):167--198, 2006.

\bibitem{duchi2011adaptive}
J.~Duchi, E.~Hazan, and Y.~Singer.
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock {\em Journal of Machine Learning Research}, 12:2121--2159, 2011.

\bibitem{schraudolph1999local}
N.N. Schraudolph.
\newblock Local gain adaptation in stochastic gradient descent.
\newblock In {\em Ninth International Conference on Artificial Neural Networks
  (ICANN) 99}, volume~2, pages 569--574, 1999.

\bibitem{amari2000adaptive}
S.-I. Amari, H.~Park, and K.~Fukumizu.
\newblock Adaptive method of realizing natural gradient learning for multilayer
  perceptrons.
\newblock {\em Neural Computation}, 12(6):1399--1409, 2000.

\bibitem{roux2010fast}
N.L. Roux and A.W. Fitzgibbon.
\newblock A fast natural {N}ewton method.
\newblock In {\em 27th International Conference on Machine Learning (ICML)},
  pages 623--630, 2010.

\bibitem{ranganath13}
R.~Rajesh, W.~Chong, D.~Blei, and E.~Xing.
\newblock An adaptive learning rate for stochastic variational inference.
\newblock In {\em 30th International Conference on Machine Learning (ICML)},
  pages 298--306, 2013.

\bibitem{StochasticNewton}
P.~Hennig.
\newblock {Fast Probabilistic Optimization from Noisy Gradients}.
\newblock In {\em {30th International Conference on Machine Learning (ICML)}},
  2013.

\bibitem{schaul2013no}
T.~Schaul, S.~Zhang, and Y.~LeCun.
\newblock No more pesky learning rates.
\newblock In {\em 30th International Conference on Machine Learning (ICML-13)},
  pages 343--351, 2013.

\bibitem{fletcher1964function}
R.~Fletcher and C.M. Reeves.
\newblock {Function minimization by conjugate gradients}.
\newblock {\em The Computer Journal}, 7(2):149--154, 1964.

\bibitem{broyden1969new}
C.G. Broyden.
\newblock {A new double-rank minimization algorithm}.
\newblock {\em Notices of the AMS}, 16:670, 1969.

\bibitem{fletcher1970new}
R.~Fletcher.
\newblock {A new approach to variable metric algorithms}.
\newblock {\em The Computer Journal}, 13(3):317, 1970.

\bibitem{goldfarb1970family}
D.~Goldfarb.
\newblock {A family of variable metric updates derived by variational means}.
\newblock {\em Math. Comp.}, 24(109):23--26, 1970.

\bibitem{shanno1970conditioning}
D.F. Shanno.
\newblock {Conditioning of quasi-{N}ewton methods for function minimization}.
\newblock {\em Math. Comp.}, 24(111):647--656, 1970.

\bibitem{nocedal1999numerical}
J.~Nocedal and S.J. Wright.
\newblock {\em {Numerical Optimization}}.
\newblock Springer Verlag, 1999.

\bibitem{wolfe1969convergence}
P.~Wolfe.
\newblock {Convergence conditions for ascent methods}.
\newblock {\em SIAM Review}, pages 226--235, 1969.

\bibitem{armijo1966minimization}
L.~Armijo.
\newblock Minimization of functions having {L}ipschitz continuous first partial
  derivatives.
\newblock {\em Pacific Journal of Mathematics}, 16(1):1--3, 1966.

\bibitem{jones1998efficient}
D.R. Jones, M.~Schonlau, and W.J. Welch.
\newblock {Efficient global optimization of expensive black-box functions}.
\newblock {\em Journal of Global Optimization}, 13(4):455--492, 1998.

\bibitem{RasmussenWilliams}
C.E. Rasmussen and C.K.I. Williams.
\newblock {\em {Gaussian Processes for Machine Learning}}.
\newblock MIT, 2006.

\bibitem{wahba1990spline}
G.~Wahba.
\newblock {\em {Spline models for observational data}}.
\newblock Number~59 in {CBMS-NSF Regional Conferences series in applied
  mathematics}. SIAM, 1990.

\bibitem{sarkka2013bayesian}
S.~S{\"a}rkk{\"a}.
\newblock {\em {Bayesian filtering and smoothing}}.
\newblock Cambridge University Press, 2013.

\bibitem{papoulis91:probab_random}
A.~Papoulis.
\newblock {\em Probability, Random Variables, and Stochastic Processes}.
\newblock McGraw-Hill, New York, 3rd ed. edition, 1991.

\bibitem{adler1981geometry}
R.J. Adler.
\newblock {\em {The Geometry of Random Fields}}.
\newblock Wiley, 1981.

\bibitem{drezner1990computation}
Z.~Drezner and G.O. Wesolowsky.
\newblock On the computation of the bivariate normal integral.
\newblock {\em Journal of Statistical Computation and Simulation},
  35(1-2):101--107, 1990.

\end{thebibliography}
