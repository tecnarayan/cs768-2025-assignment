@article{zhong2024dpo,
  title={Dpo meets ppo: Reinforced token optimization for rlhf},
  author={Zhong, Han and Feng, Guhao and Xiong, Wei and Zhao, Li and He, Di and Bian, Jiang and Wang, Liwei},
  journal={arXiv preprint arXiv:2404.18922
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2024}
}

@article{rafailov2024r,
  title={From $ r $ to {$ Q^* $}: {Y}our {L}anguage {M}odel is {S}ecretly a {Q-F}unction},
  author={Rafailov, Rafael and Hejna, Joey and Park, Ryan and Finn, Chelsea},
  journal={arXiv preprint arXiv:2404.12358
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2024}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@book{ abelson-et-al:scheme,
  author = "Harold Abelson and Gerald~Jay Sussman and Julie Sussman",
  title = "Structure and Interpretation of Computer Programs",
  publisher = "MIT Press",
  address = "Cambridge, Massachusetts",
  year = "1985"
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@inproceedings{ bgf:Lixto,
  author = "Robert Baumgartner and Georg Gottlob and Sergio Flesca",
  title = "Visual Information Extraction with {Lixto}",
  booktitle = "Proceedings of the 27th International Conference on Very Large Databases",
  pages = "119--128",
  publisher = "Morgan Kaufmann",
  address = "Rome, Italy",
  month = "September",
  year = "2001"
}

@article{ brachman-schmolze:kl-one,
  author = "Ronald~J. Brachman and James~G. Schmolze",
  title = "An overview of the {KL-ONE} knowledge representation system",
  journal = "Cognitive Science",
  volume = "9",
  number = "2",
  pages = "171--216",
  month = "April--June",
  year = "1985"
}

@inproceedings{ levesque:belief,
  author = "Hector~J. Levesque",
  title = "A logic of implicit and explicit belief",
  booktitle = "Proceedings of the Fourth National Conference on Artificial Intelligence",
  publisher = "American Association for Artificial Intelligence",
  pages = "198--202",
  address = "Austin, Texas",
  month = "August",
  year = "1984"
}

@article{ nebel:jair-2000,
  author = "Bernhard Nebel",
  title = "On the compilability and expressive power of propositional planning formalisms",
  journal = "Journal of Artificial Intelligence Research",
  volume = "12",
  pages = "271--315",
  year = "2000"
}

 @misc{proceedings,
  author = {{IJCAI Proceedings}},
  title = {{IJCAI} Camera Ready Submission},
  howpublished = {\url{https://proceedings.ijcai.org/info}},
}

@article{chen_fan_girshick_he_2020, title={moco v2}, journal={arXiv: Computer Vision and Pattern Recognition,arXiv: Computer Vision and Pattern Recognition}, author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming}, year={2020}, month={Mar} }

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={15084--15097},
  year={2021}
}

@article{lee2022multi,
  title={Multi-game decision transformers},
  author={Lee, Kuang-Huei and Nachum, Ofir and Yang, Mengjiao Sherry and Lee, Lisa and Freeman, Daniel and Guadarrama, Sergio and Fischer, Ian and Xu, Winnie and Jang, Eric and Michalewski, Henryk and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27921--27936},
  year={2022}
}

@article{reed2022generalist,
  title={A generalist agent},
  author={Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and others},
  journal={arXiv preprint arXiv:2205.06175
        
        
        
        
        
        
        
        },
  year={2022}
}

@article{fedus_zoph_shazeer_2021, title={Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity.}, journal={arXiv: Learning,arXiv: Learning}, author={Fedus, William and Zoph, Barret and Shazeer, Noam}, year={2021}, month={Jan} }

@article{gupta_mendonca_liu_abbeel_levine_2018, title={Meta-Reinforcement Learning of Structured Exploration Strategies}, journal={arXiv: Learning,arXiv: Learning}, author={Gupta, Abhishek and Mendonca, Russell and Liu, YuXuan and Abbeel, Pieter and Levine, Sergey}, year={2018}, month={Feb} }

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9729--9738},
  year={2020}
}

@inproceedings{he_fan_wu_xie_girshick_2020, title={moco}, url={http://dx.doi.org/10.1109/cvpr42600.2020.00975}, DOI={10.1109/cvpr42600.2020.00975}, booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross}, year={2020}, month={Jun} }

@article{janner_li_levine_2021, title={Offline Reinforcement Learning as One Big Sequence Modeling Problem}, journal={Neural Information Processing Systems,Neural Information Processing Systems}, author={Janner, Michael and Li, Qiyang and Levine, Sergey}, year={2021}, month={Dec} }

@article{kirsch_harrison_sohl-dickstein_metz_2022, title={General-Purpose In-Context Learning by Meta-Learning Transformers}, author={Kirsch, Louis and Harrison, James and Sohl-Dickstein, Jascha and Metz, Luke}, year={2022}, month={Dec} }

@article{laskin2022context,
  title={In-context reinforcement learning with algorithm distillation},
  author={Laskin, Michael and Wang, Luyu and Oh, Junhyuk and Parisotto, Emilio and Spencer, Stephen and Steigerwald, Richie and Strouse, DJ and Hansen, Steven and Filos, Angelos and Brooks, Ethan and others},
  journal={arXiv preprint arXiv:2210.14215
        
        
        
        
        
        },
  year={2022}
}

@article{lee_xie_pacchiano_chandak_finn_nachum_brunskill_university_research_deepmind_0, title={Supervised Pretraining Can Learn In-Context Reinforcement Learning}, author={Lee, JonathanN and Xie, Annie and Pacchiano, Aldo and Chandak, Yash and Finn, Chelsea and Nachum, Ofir and Brunskill, Emma and University, Stanford and Research, Microsoft and Deepmind, Google}, year={0} }

@article{li_huang_luo_2021, title={Provably Improved Context-Based Offline Meta-RL with Attention and Contrastive Learning}, journal={arXiv: Learning,arXiv: Learning}, author={Li, Lanqing and Huang, Yuanhao and Luo, Dijun}, year={2021}, month={Feb} }

@article{li_yang_luo_2020, title={Efficient Fully-Offline Meta-Reinforcement Learning via Distance Metric Learning and Behavior Regularization}, journal={Learning,Learning}, author={Li, Lanqing and Yang, Rui and Luo, Dijun}, year={2020}, month={Oct} }

@article{li_ildiz_papailiopoulos_oymak_2023, title={Transformers as Algorithms: Generalization and Stability in In-context Learning}, author={Li, Yingcong and Ildiz, M.Emrullah and Papailiopoulos, Dimitris and Oymak, Samet}, year={2023}, month={Jan} }

@article{lin_liu_sengupta_0, title={Switch Trajectory Transformer with Distributional Value Approximation for Multi-Task Reinforcement Learning}, author={Lin, Qinjie and Liu, Han and Sengupta, Biswa}, year={0} }

@article{lu_schroecker_gu_parisotto_foerster_singh_behbahani_2023, title={Structured State Space Models for In-Context Reinforcement Learning}, author={Lu, Chris and Schroecker, Yannick and Gu, Albert and Parisotto, Emilio and Foerster, Jakob and Singh, Satinder and Behbahani, Feryal}, year={2023}, month={Mar} }

@article{rakelly_zhou_quillen_finn_levine_2019, title={Efficient Off-Policy Meta-Reinforcement Learning via Probabilistic Context Variables}, journal={Cornell University - arXiv,Cornell University - arXiv}, author={Rakelly, Kate and Zhou, Aurick and Quillen, Deirdre and Finn, Chelsea and Levine, Sergey}, year={2019}, month={Mar} }},
  year={2022}
}

@article{sourati_ilievski_sandlin_mermoud_2023, title={Case-Based Reasoning with Language Models for Classification of Logical Fallacies}, author={Sourati, Zhivar and Ilievski, Filip and Sandlin, H\^ong-\^An and Mermoud, Alain}, year={2023}, month={Jan} }

@article{sun_ma_madaan_bonatti_huang_kapoor_2023, title={SMART: Self-supervised Multi-task pretrAining with contRol Transformers}, author={Sun, Yanchao and Ma, Shuang and Madaan, Ratnesh and Bonatti, Rogerio and Huang, Furong and Kapoor, Ashish}, year={2023}, month={Jan} }

@article{wang_zhao_luo_ren_zhang_li_2022, title={Bootstrapped Transformer for Offline Reinforcement Learning}, author={Wang, Kerong and Zhao, Hanye and Luo, Xufang and Ren, Kan and Zhang, Weinan and Li, Dongsheng}, year={2022}, month={Jun} }

@article{yuan_lu_2022, title={Robust Task Representations for Offline Meta-Reinforcement Learning via Contrastive Learning}, author={Yuan, Haoqi and Lu, Zongqing}, year={2022}, month={Jun} }

@article{zhou_cong_yu_0, title={Task Inference for Offline Meta Reinforcement Learning via Latent Shared Knowledge}, author={Zhou, Ying and Cong, Shan and Yu, Chao}, year={0} }

@article{watson1994case,
  title={Case-based reasoning: A review},
  author={Watson, Ian and Marir, Farhi},
  journal={The knowledge engineering review},
  volume={9},
  number={4},
  pages={327--354},
  year={1994},
  publisher={Cambridge University Press}
}

@article{lee2023supervised,
  title={Supervised Pretraining Can Learn In-Context Reinforcement Learning},
  author={Lee, Jonathan N and Xie, Annie and Pacchiano, Aldo and Chandak, Yash and Finn, Chelsea and Nachum, Ofir and Brunskill, Emma},
  journal={arXiv preprint arXiv:2306.14892
        
        
        
        
        
        
        
        },
  year={2023}
}

@inproceedings{xu2022prompting,
  title={Prompting decision transformer for few-shot policy generalization},
  author={Xu, Mengdi and Shen, Yikang and Zhang, Shun and Lu, Yuchen and Zhao, Ding and Tenenbaum, Joshua and Gan, Chuang},
  booktitle={international conference on machine learning},
  pages={24631--24645},
  year={2022},
  organization={PMLR}
}

@article{xu2023hyper,
  title={Hyper-decision transformer for efficient online policy adaptation},
  author={Xu, Mengdi and Lu, Yuchen and Shen, Yikang and Zhang, Shun and Zhao, Ding and Gan, Chuang},
  journal={arXiv preprint arXiv:2304.08487
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2020}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774
        
        },
  year={2023}
}

@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2022}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@misc{stiennon2022learning,
      title={Learning to summarize from human feedback}, 
      author={Nisan Stiennon and Long Ouyang and Jeff Wu and Daniel M. Ziegler and Ryan Lowe and Chelsea Voss and Alec Radford and Dario Amodei and Paul Christiano},
      year={2022},
      eprint={2009.01325},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Koh_2022,
   title={An Empirical Survey on Long Document Summarization: Datasets, Models, and Metrics},
   volume={55},
   ISSN={1557-7341},
   url={http://dx.doi.org/10.1145/3545176},
   DOI={10.1145/3545176},
   number={8},
   journal={ACM Computing Surveys},
   publisher={Association for Computing Machinery (ACM)},
   author={Koh, Huan Yee and Ju, Jiaxin and Liu, Ming and Pan, Shirui},
   year={2022},
   month=dec, pages={1–35} }

@misc{gao2023pal,
      title={PAL: Program-aided Language Models}, 
      author={Luyu Gao and Aman Madaan and Shuyan Zhou and Uri Alon and Pengfei Liu and Yiming Yang and Jamie Callan and Graham Neubig},
      year={2023},
      eprint={2211.10435},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{chen2021evaluating,
      title={Evaluating Large Language Models Trained on Code}, 
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
      year={2021},
      eprint={2107.03374},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{christian2023amazing,
  title={Amazing “jailbreak” bypasses ChatGPT’s ethics safeguards},
  author={Christian, Jon},
  journal={Futurism, February},
  volume={4},
  pages={2023},
  year={2023}
}

@article{hendrycks2023overview,
  title={An Overview of Catastrophic AI Risks},
  author={Hendrycks, Dan and Mazeika, Mantas and Woodside, Thomas},
  journal={arXiv preprint arXiv:2306.12001
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{shevlane2023model,
  title={Model evaluation for extreme risks},
  author={Shevlane, Toby and Farquhar, Sebastian and Garfinkel, Ben and Phuong, Mary and Whittlestone, Jess and Leung, Jade and Kokotajlo, Daniel and Marchal, Nahema and Anderljung, Markus and Kolt, Noam and others},
  journal={arXiv preprint arXiv:2305.15324
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{urbina2022dual,
  title={Dual use of artificial-intelligence-powered drug discovery},
  author={Urbina, Fabio and Lentzos, Filippa and Invernizzi, C{\'e}dric and Ekins, Sean},
  journal={Nature Machine Intelligence},
  volume={4},
  number={3},
  pages={189--191},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}
@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}
@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2022}
}

@inproceedings{biderman2023pythia,
  title={Pythia: A suite for analyzing large language models across training and scaling},
  author={Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin Gregory and Bradley, Herbie and O’Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and others},
  booktitle={International Conference on Machine Learning},
  pages={2397--2430},
  year={2023},
  organization={PMLR}
}

@article{zheng2023judging,
  title={Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={arXiv preprint arXiv:2306.05685
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}
@inproceedings{maas2011learning,
  title={Learning word vectors for sentiment analysis},
  author={Maas, Andrew and Daly, Raymond E and Pham, Peter T and Huang, Dan and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies},
  pages={142--150},
  year={2011}
}

@article{ganguli2022red,
  title={Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned},
  author={Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  journal={arXiv preprint arXiv:2209.07858
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2022}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347
        
        
        
        },
  year={2017}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016},
  organization={PMLR}
}

@article{glaese2022improving,
  title={Improving alignment of dialogue agents via targeted human judgements},
  author={Glaese, Amelia and McAleese, Nat and Trębacz, Maja and Aslanides, John and Firoiu, Vlad and Ewalds, Timo and Rauh, Maribeth and Weidinger, Laura and Chadwick, Martin and Thacker, Phoebe and others},
  journal={arXiv preprint arXiv:2209.14375
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2022}
}

@inproceedings{gao2023scaling,
  title={Scaling laws for reward model overoptimization},
  author={Gao, Leo and Schulman, John and Hilton, Jacob},
  booktitle={International Conference on Machine Learning},
  pages={10835--10866},
  year={2023},
  organization={PMLR}
}


@article{dong2023raft,
  title={Raft: Reward ranked finetuning for generative foundation model alignment},
  author={Dong, Hanze and Xiong, Wei and Goyal, Deepanshu and Pan, Rui and Diao, Shizhe and Zhang, Jipeng and Shum, Kashun and Zhang, Tong},
  journal={arXiv preprint arXiv:2304.06767
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}
@article{song2023preference,
  title={Preference ranking optimization for human alignment},
  author={Song, Feifan and Yu, Bowen and Li, Minghao and Yu, Haiyang and Huang, Fei and Li, Yongbin and Wang, Houfeng},
  journal={arXiv preprint arXiv:2306.17492
        
        
        
        
        
        
        
        },
  year={2023}
}
@article{yuan2023rrhf,
  title={Rrhf: Rank responses to align language models with human feedback without tears},
  author={Yuan, Zheng and Yuan, Hongyi and Tan, Chuanqi and Wang, Wei and Huang, Songfang and Huang, Fei},
  journal={arXiv preprint arXiv:2304.05302
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{rafailov2023direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea},
  journal={arXiv preprint arXiv:2305.18290
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}
@inproceedings{havrilla2023trlx,
  title={trlX: A Framework for Large Scale Reinforcement Learning from Human Feedback},
  author={Havrilla, Alexander and Zhuravinskyi, Maksym and Phung, Duy and Tiwari, Aman and Tow, Jonathan and Biderman, Stella and Anthony, Quentin and Castricato, Louis},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={8578--8595},
  year={2023}
}

@article{li2015diversity,
  title={A diversity-promoting objective function for neural conversation models},
  author={Li, Jiwei and Galley, Michel and Brockett, Chris and Gao, Jianfeng and Dolan, Bill},
  journal={arXiv preprint arXiv:1510.03055
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2015}
}

@inproceedings{zhu2018texygen,
  title={Texygen: A benchmarking platform for text generation models},
  author={Zhu, Yaoming and Lu, Sidi and Zheng, Lei and Guo, Jiaxian and Zhang, Weinan and Wang, Jun and Yu, Yong},
  booktitle={The 41st international ACM SIGIR conference on research \& development in information retrieval},
  pages={1097--1100},
  year={2018}
}
@article{liu2023statistical,
  title={Statistical rejection sampling improves preference optimization},
  author={Liu, Tianqi and Zhao, Yao and Joshi, Rishabh and Khalman, Misha and Saleh, Mohammad and Liu, Peter J and Liu, Jialu},
  journal={arXiv preprint arXiv:2309.06657
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{wiher2022decoding,
  title={On decoding strategies for neural text generators},
  author={Wiher, Gian and Meister, Clara and Cotterell, Ryan},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={997--1012},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{khalifa2020distributional,
  title={A distributional approach to controlled text generation},
  author={Khalifa, Muhammad and Elsahar, Hady and Dymetman, Marc},
  journal={arXiv preprint arXiv:2012.11635
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2020}
}

@article{perez2202red,
  title={Red teaming language models with language models, 2022},
  author={Perez, Ethan and Huang, Saffron and Song, Francis and Cai, Trevor and Ring, Roman and Aslanides, John and Glaese, Amelia and McAleese, Nat and Irving, Geoffrey},
  journal={URL https://arxiv. org/abs/2202.03286},
  year={2022}
}

@article{santurkar2023whose,
  title={Whose opinions do language models reflect?},
  author={Santurkar, Shibani and Durmus, Esin and Ladhak, Faisal and Lee, Cinoo and Liang, Percy and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2303.17548
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{wang2023beyond,
  title={Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints},
  author={Wang, Chaoqi and Jiang, Yibo and Yang, Chenghao and Liu, Han and Chen, Yuxin},
  journal={arXiv preprint arXiv:2309.16240
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{knox2022models,
  title={Models of human preference for learning reward functions},
  author={Knox, W Bradley and Hatgis-Kessell, Stephane and Booth, Serena and Niekum, Scott and Stone, Peter and Allievi, Alessandro},
  journal={arXiv preprint arXiv:2206.02231
        
        
        
        
        
        },
  year={2022}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}

@article{bradley1952rank,
  title={Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author={Bradley, Ralph Allan and Terry, Milton E},
  journal={Biometrika},
  volume={39},
  number={3/4},
  pages={324--345},
  year={1952},
  publisher={JSTOR}
}

@article{knox2023learning,
  title={Learning Optimal Advantage from Preferences and Mistaking it for Reward},
  author={Knox, W Bradley and Hatgis-Kessell, Stephane and Adalgeirsson, Sigurdur Orn and Booth, Serena and Dragan, Anca and Stone, Peter and Niekum, Scott},
  journal={arXiv preprint arXiv:2310.02456
        
        },
  year={2023}
}

@misc{jiang2023mistral,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{workshop2022bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Workshop, BigScience and Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and others},
  journal={arXiv preprint arXiv:2211.05100
        
        
        
        },
  year={2022}
}
@article{taori2023alpaca,
  title={Alpaca: A strong, replicable instruction-following model},
  author={Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  journal={Stanford Center for Research on Foundation Models. https://crfm. stanford. edu/2023/03/13/alpaca. html},
  volume={3},
  number={6},
  pages={7},
  year={2023}
}

@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  year={2023}
}

@misc{vu2023koala,
      title={Koala: An Index for Quantifying Overlaps with Pre-training Corpora}, 
      author={Thuy-Trang Vu and Xuanli He and Gholamreza Haffari and Ehsan Shareghi},
      year={2023},
      eprint={2303.14770},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{weidinger2021ethical,
  title={Ethical and social risks of harm from language models},
  author={Weidinger, Laura and Mellor, John and Rauh, Maribeth and Griffin, Conor and Uesato, Jonathan and Huang, Po-Sen and Cheng, Myra and Glaese, Mia and Balle, Borja and Kasirzadeh, Atoosa and others},
  journal={arXiv preprint arXiv:2112.04359
        
        
        
        
        
        
        
        
        
        },
  year={2021}
}

@misc{rauh2022characteristics,
      title={Characteristics of Harmful Text: Towards Rigorous Benchmarking of Language Models}, 
      author={Maribeth Rauh and John Mellor and Jonathan Uesato and Po-Sen Huang and Johannes Welbl and Laura Weidinger and Sumanth Dathathri and Amelia Glaese and Geoffrey Irving and Iason Gabriel and William Isaac and Lisa Anne Hendricks},
      year={2022},
      eprint={2206.08325},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{ousidhoum2021probing,
  title={Probing toxic content in large pre-trained language models},
  author={Ousidhoum, Nedjma and Zhao, Xinran and Fang, Tianqing and Song, Yangqiu and Yeung, Dit-Yan},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={4262--4274},
  year={2021}
}

@article{huang2023survey,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={arXiv preprint arXiv:2311.05232
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{deshpande2023toxicity,
  title={Toxicity in chatgpt: Analyzing persona-assigned language models},
  author={Deshpande, Ameet and Murahari, Vishvak and Rajpurohit, Tanmay and Kalyan, Ashwin and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2304.05335
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{sheng2021societal,
  title={Societal biases in language generation: Progress and challenges},
  author={Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun},
  journal={arXiv preprint arXiv:2105.04054
        
        
        
        
        
        
        
        },
  year={2021}
}

@article{wu2023fine,
  title={Fine-Grained Human Feedback Gives Better Rewards for Language Model Training},
  author={Wu, Zeqiu and Hu, Yushi and Shi, Weijia and Dziri, Nouha and Suhr, Alane and Ammanabrolu, Prithviraj and Smith, Noah A and Ostendorf, Mari and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2306.01693
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}

@article{tunstall2023zephyr,
  title={Zephyr: Direct distillation of lm alignment},
  author={Tunstall, Lewis and Beeching, Edward and Lambert, Nathan and Rajani, Nazneen and Rasul, Kashif and Belkada, Younes and Huang, Shengyi and von Werra, Leandro and Fourrier, Cl{\'e}mentine and Habib, Nathan and others},
  journal={arXiv preprint arXiv:2310.16944
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        },
  year={2023}
}
