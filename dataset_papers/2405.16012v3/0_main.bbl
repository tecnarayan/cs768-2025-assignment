\begin{thebibliography}{10}

\bibitem{bengio2021flow}
Emmanuel Bengio, Moksh Jain, Maksym Korablyov, Doina Precup, and Yoshua Bengio.
\newblock Flow network based generative models for non-iterative diverse
  candidate generation.
\newblock {\em Advances in Neural Information Processing Systems},
  34:27381--27394, 2021.

\bibitem{jain2023multi}
Moksh Jain, Sharath~Chandra Raparthy, Alex Hern{\'a}ndez-Garc{\i}a, Jarrid
  Rector-Brooks, Yoshua Bengio, Santiago Miret, and Emmanuel Bengio.
\newblock Multi-objective gflownets.
\newblock In {\em International Conference on Machine Learning}, pages
  14631--14653. PMLR, 2023.

\bibitem{cretu2024synflownet}
Miruna Cretu, Charles Harris, Julien Roy, Emmanuel Bengio, and Pietro Li{\`o}.
\newblock Synflownet: Towards molecule design with guaranteed synthesis
  pathways.
\newblock In {\em ICLR 2024 Generative and Experimental Perspectives for
  Biomolecular Design (GEM) Workshop}, 2024.

\bibitem{jain2022biological}
Moksh Jain, Emmanuel Bengio, Alex Hernandez-Garcia, Jarrid Rector-Brooks,
  Bonaventure~FP Dossou, Chanakya~Ajit Ekbote, Jie Fu, Tianyu Zhang, Michael
  Kilgour, Dinghuai Zhang, et~al.
\newblock Biological sequence design with gflownets.
\newblock In {\em International Conference on Machine Learning}, pages
  9786--9801. PMLR, 2022.

\bibitem{zhang2023let}
Dinghuai Zhang, Hanjun Dai, Nikolay Malkin, Aaron~C Courville, Yoshua Bengio,
  and Ling Pan.
\newblock Let the flows tell: Solving graph combinatorial problems with
  gflownets.
\newblock In A.~Oh, T.~Naumann, A.~Globerson, K.~Saenko, M.~Hardt, and
  S.~Levine, editors, {\em Advances in Neural Information Processing Systems},
  volume~36, pages 11952--11969. Curran Associates, Inc., 2023.

\bibitem{hu2023amortizing}
Edward~J Hu, Moksh Jain, Eric Elmoznino, Younesse Kaddar, Guillaume Lajoie,
  Yoshua Bengio, and Nikolay Malkin.
\newblock Amortizing intractable inference in large language models.
\newblock In {\em International Conference on Learning Representations}, 2024.

\bibitem{bengio2021gflownet}
Yoshua Bengio, Salem Lahlou, Tristan Deleu, Edward~J Hu, Mo~Tiwari, and
  Emmanuel Bengio.
\newblock Gflownet foundations.
\newblock {\em Journal of Machine Learning Research}, 24(210):1--55, 2023.

\bibitem{malkin2022trajectory}
Nikolay Malkin, Moksh Jain, Emmanuel Bengio, Chen Sun, and Yoshua Bengio.
\newblock Trajectory balance: Improved credit assignment in gflownets.
\newblock {\em Advances in Neural Information Processing Systems},
  35:5955--5967, 2022.

\bibitem{madan2023learning}
Kanika Madan, Jarrid Rector-Brooks, Maksym Korablyov, Emmanuel Bengio, Moksh
  Jain, Andrei~Cristian Nica, Tom Bosc, Yoshua Bengio, and Nikolay Malkin.
\newblock Learning gflownets from partial episodes for improved convergence and
  stability.
\newblock In {\em International Conference on Machine Learning}, pages
  23467--23483. PMLR, 2023.

\bibitem{pan2023better}
Ling Pan, Nikolay Malkin, Dinghuai Zhang, and Yoshua Bengio.
\newblock Better training of gflownets with local credit and incomplete
  trajectories.
\newblock In {\em International Conference on Machine Learning}, pages
  26878--26890. PMLR, 2023.

\bibitem{jang2023learning}
Hyosoon Jang, Minsu Kim, and Sungsoo Ahn.
\newblock Learning energy decompositions for partial inference of gflownets.
\newblock In {\em International Conference on Learning Representations}, 2024.

\bibitem{pan2023generative}
Ling Pan, Dinghuai Zhang, Aaron Courville, Longbo Huang, and Yoshua Bengio.
\newblock Generative augmented flow networks.
\newblock In {\em International Conference on Learning Representations}, 2023.

\bibitem{towardsunderstandinggflownets}
Max~Walt Shen, Emmanuel Bengio, Ehsan Hajiramezanali, Andreas Loukas, Kyunghyun
  Cho, and Tommaso Biancalani.
\newblock Towards understanding and improving gflownet training.
\newblock In {\em Proceedings of the 40th International Conference on Machine
  Learning}, Proceedings of Machine Learning Research. PMLR, 2023.

\bibitem{kim2023local}
Minsu Kim, Taeyoung Yun, Emmanuel Bengio, Dinghuai Zhang, Yoshua Bengio,
  Sungsoo Ahn, and Jinkyoo Park.
\newblock Local search gflownets.
\newblock In {\em International Conference on Learning Representations}, 2024.

\bibitem{mohammadpour2023maximum}
Sobhan Mohammadpour, Emmanuel Bengio, Emma Frejinger, and Pierre-Luc Bacon.
\newblock Maximum entropy gflownets with soft q-learning.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 2593--2601. PMLR, 2024.

\bibitem{deleu2024discrete}
Tristan Deleu, Padideh Nouri, Nikolay Malkin, Doina Precup, and Yoshua Bengio.
\newblock Discrete probabilistic inference as control in multi-path
  environments.
\newblock {\em arXiv preprint arXiv:2402.10309}, 2024.

\bibitem{tiapkin2024generative}
Daniil Tiapkin, Nikita Morozov, Alexey Naumov, and Dmitry~P Vetrov.
\newblock Generative flow networks as entropy-regularized rl.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 4213--4221. PMLR, 2024.

\bibitem{malkin2022gflownets}
Nikolay Malkin, Salem Lahlou, Tristan Deleu, Xu~Ji, Edward Hu, Katie Everett,
  Dinghuai Zhang, and Yoshua Bengio.
\newblock Gflownets and variational inference.
\newblock In {\em International Conference on Learning Representations}, 2023.

\bibitem{rector2023thompson}
Jarrid Rector-Brooks, Kanika Madan, Moksh Jain, Maksym Korablyov, Cheng-Hao
  Liu, Sarath Chandar, Nikolay Malkin, and Yoshua Bengio.
\newblock Thompson sampling for improved exploration in gflownets.
\newblock In {\em ICML 2023 Structured Probabilistic Inference \& Generative
  Modeling (SPIGM) Workshop}, 2023.

\bibitem{lau2024qgfn}
Elaine Lau, Stephen~Zhewen Lu, Ling Pan, Doina Precup, and Emmanuel Bengio.
\newblock Qgfn: Controllable greediness with action values.
\newblock {\em arXiv preprint arXiv:2402.05234}, 2024.

\bibitem{kim2023learning}
Minsu Kim, Joohwan Ko, Dinghuai Zhang, Ling Pan, Taeyoung Yun, Woochang Kim,
  Jinkyoo Park, and Yoshua Bengio.
\newblock Learning to scale logits for temperature-conditional gflownets.
\newblock {\em arXiv preprint arXiv:2310.02823}, 2023.

\bibitem{chenorder}
Yihang Chen and Lukas Mauch.
\newblock Order-preserving gflownets.
\newblock In {\em The Twelfth International Conference on Learning
  Representations}.

\bibitem{zhu2024sample}
Yiheng Zhu, Jialu Wu, Chaowen Hu, Jiahuan Yan, Tingjun Hou, Jian Wu, et~al.
\newblock Sample-efficient multi-objective molecular optimization with
  gflownets.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2023.

\bibitem{ghari2023generative}
Pouya~M Ghari, Alex Tseng, G{\"o}kcen Eraslan, Romain Lopez, Tommaso
  Biancalani, Gabriele Scalia, and Ehsan Hajiramezanali.
\newblock Generative flow networks assisted biological sequence editing.
\newblock In {\em NeurIPS 2023 Generative AI and Biology (GenBio) Workshop},
  2023.

\bibitem{zhang2022generative}
Dinghuai Zhang, Nikolay Malkin, Zhen Liu, Alexandra Volokhova, Aaron Courville,
  and Yoshua Bengio.
\newblock Generative flow networks for discrete probabilistic modeling.
\newblock In {\em International Conference on Machine Learning}, pages
  26412--26428. PMLR, 2022.

\bibitem{deleu2022bayesian}
Tristan Deleu, Ant{\'o}nio G{\'o}is, Chris Emezue, Mansi Rankawat, Simon
  Lacoste-Julien, Stefan Bauer, and Yoshua Bengio.
\newblock Bayesian structure learning with generative flow networks.
\newblock In {\em Uncertainty in Artificial Intelligence}, pages 518--528.
  PMLR, 2022.

\bibitem{zhang2023robust}
David~W Zhang, Corrado Rainone, Markus Peschl, and Roberto Bondesan.
\newblock Robust scheduling with gflownets.
\newblock In {\em International Conference on Learning Representations}, 2023.

\bibitem{kim2024ant}
Minsu Kim, Sanghyeok Choi, Jiwoo Son, Hyeonah Kim, Jinkyoo Park, and Yoshua
  Bengio.
\newblock Ant colony sampling with gflownets for combinatorial optimization.
\newblock {\em arXiv preprint arXiv:2403.07041}, 2024.

\bibitem{lahlou2023theory}
Salem Lahlou, Tristan Deleu, Pablo Lemos, Dinghuai Zhang, Alexandra Volokhova,
  Alex Hern{\'a}ndez-Garc{\i}a, L{\'e}na~N{\'e}hale Ezzine, Yoshua Bengio, and
  Nikolay Malkin.
\newblock A theory of continuous generative flow networks.
\newblock In {\em International Conference on Machine Learning}, pages
  18269--18300. PMLR, 2023.

\bibitem{zhang2023diffusion}
Dinghuai Zhang, Ricky Tian~Qi Chen, Cheng-Hao Liu, Aaron Courville, and Yoshua
  Bengio.
\newblock Diffusion generative flow samplers: Improving learning signals
  through partial trajectory optimization.
\newblock In {\em International Conference on Learning Representations}, 2024.

\bibitem{sendera2024diffusion}
Marcin Sendera, Minsu Kim, Sarthak Mittal, Pablo Lemos, Luca Scimeca, Jarrid
  Rector-Brooks, Alexandre Adam, Yoshua Bengio, and Nikolay Malkin.
\newblock On diffusion models for amortized inference: Benchmarking and
  improving stochastic control and sampling.
\newblock {\em arXiv preprint arXiv:2402.05098}, 2024.

\bibitem{bajusz2015tanimoto}
D{\'a}vid Bajusz, Anita R{\'a}cz, and K{\'a}roly H{\'e}berger.
\newblock Why is tanimoto index an appropriate choice for fingerprint-based
  similarity calculations?
\newblock {\em Journal of cheminformatics}, 7(1):1--13, 2015.

\bibitem{pmlr-v48-mniha16}
Volodymyr Mnih, Adria~Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy
  Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In Maria~Florina Balcan and Kilian~Q. Weinberger, editors, {\em
  Proceedings of The 33rd International Conference on Machine Learning},
  volume~48 of {\em Proceedings of Machine Learning Research}, pages
  1928--1937, New York, New York, USA, 20--22 Jun 2016. PMLR.

\bibitem{barrera2016survey}
Luis~A Barrera, Anastasia Vedenko, Jesse~V Kurland, Julia~M Rogers, Stephen~S
  Gisselbrecht, Elizabeth~J Rossin, Jaie Woodard, Luca Mariani, Kian~Hong Kock,
  Sachi Inukai, et~al.
\newblock Survey of variation in human transcription factors reveals prevalent
  dna binding changes.
\newblock {\em Science}, 351(6280):1450--1454, 2016.

\bibitem{trabucco2022design}
Brandon Trabucco, Xinyang Geng, Aviral Kumar, and Sergey Levine.
\newblock Design-bench: Benchmarks for data-driven offline model-based
  optimization.
\newblock In {\em International Conference on Machine Learning}, pages
  21658--21676. PMLR, 2022.

\bibitem{sinai2021adalead}
Sam Sinai, Richard Wang, Alexander Whatley, Stewart Slocum, Elina Locane, and
  Eric Kelsic.
\newblock Adalead: A simple and robust adaptive greedy search algorithm for
  sequence design.
\newblock {\em arXiv preprint arXiv:2010.02141}, 2021.

\bibitem{xu2018how}
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka.
\newblock How powerful are graph neural networks?
\newblock In {\em International Conference on Learning Representations}, 2019.

\end{thebibliography}
