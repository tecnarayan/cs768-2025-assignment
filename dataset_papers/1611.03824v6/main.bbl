\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andrychowicz et~al.(2016)Andrychowicz, Denil, Gomez, Hoffman, Pfau,
  Schaul, Shillingford, and de~Freitas]{andrychowicz2016learning}
M.~Andrychowicz, M.~Denil, S.~Gomez, M.~W. Hoffman, D.~Pfau, T.~Schaul,
  B.~Shillingford, and N.~de~Freitas.
\newblock Learning to learn by gradient descent by gradient descent.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Bengio et~al.(1992)Bengio, Bengio, Cloutier, and Gecsei]{Bengio+al-92}
Y.~Bengio, S.~Bengio, J.~Cloutier, and J.~Gecsei.
\newblock On the optimization of a synaptic learning rule.
\newblock In \emph{Conference on Optimality in Biological and Artificial
  Networks}, 1992.

\bibitem[Bergstra et~al.(2011)Bergstra, Bardenet, Bengio, and
  K{\'e}gl]{bergstra2011algorithms}
J.~S. Bergstra, R.~Bardenet, Y.~Bengio, and B.~K{\'e}gl.
\newblock Algorithms for hyper-parameter optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2546--2554, 2011.

\bibitem[Brochu et~al.(2009)Brochu, Cora, and {de Freitas}]{Brochu:2009}
E.~Brochu, V.~M. Cora, and N.~{de Freitas}.
\newblock A tutorial on {B}ayesian optimization of expensive cost functions,
  with application to active user modeling and hierarchical reinforcement
  learning.
\newblock Technical Report UBC TR-2009-23 and arXiv:1012.2599v1, Dept. of
  Computer Science, University of British Columbia, 2009.

\bibitem[Bubeck et~al.(2009)Bubeck, Munos, and Stoltz]{Bubeck:2009}
S.~Bubeck, R.~Munos, and G.~Stoltz.
\newblock Pure exploration in multi-armed bandits problems.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  2009.

\bibitem[Desautels et~al.(2014)Desautels, Krause, and Burdick]{Desautels:2012}
T.~Desautels, A.~Krause, and J.~Burdick.
\newblock Parallelizing exploration-exploitation tradeoffs with {Gaussian}
  process bandit optimization.
\newblock \emph{Journal of Machine Learning Research}, 2014.

\bibitem[Duan et~al.(2016)Duan, Schulman, Chen, Bartlett, Sutskever, and
  Abbeel]{Duan2016}
Y.~Duan, J.~Schulman, X.~Chen, P.~Bartlett, I.~Sutskever, and P.~Abbeel.
\newblock Rl$^2$: Fast reinforcement learning via slow reinforcement learning.
\newblock Technical report, UC Berkeley and OpenAI, 2016.

\bibitem[Eggensperger et~al.(2013)Eggensperger, Feurer, Hutter, Bergstra,
  Snoek, Hoos, and Leyton-Brown]{EggFeuBerSnoHooHutLey13}
K.~Eggensperger, M.~Feurer, F.~Hutter, J.~Bergstra, J.~Snoek, H.~Hoos, and
  K.~Leyton-Brown.
\newblock Towards an empirical foundation for assessing bayesian optimization
  of hyperparameters.
\newblock In \emph{NIPS workshop on Bayesian Optimization in Theory and
  Practice}, 2013.

\bibitem[Gabillon et~al.(2012)Gabillon, Ghavamzadeh, and
  Lazaric]{Gabillon:2012}
V.~Gabillon, M.~Ghavamzadeh, and A.~Lazaric.
\newblock Best arm identification: A unified approach to fixed budget and fixed
  confidence.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3212--3220, 2012.

\bibitem[Graves et~al.(2016)Graves, Wayne, Reynolds, Harley, Danihelka,
  Grabska-Barwi\AA{}ska, Colmenarejo, Grefenstette, Ramalho, Agapiou, Badia,
  Hermann, Zwols, Ostrovski, Cain, King, Summerfield, Blunsom, Kavukcuoglu, and
  Hassabis]{dnc2016}
A.~Graves, G.~Wayne, M.~Reynolds, T.~Harley, I.~Danihelka,
  A.~Grabska-Barwi\AA{}ska, S.~G. Colmenarejo, E.~Grefenstette, T.~Ramalho,
  J.~Agapiou, A.~A.~P. Badia, K.~M. Hermann, Y.~Zwols, G.~Ostrovski, A.~Cain,
  H.~King, C.~Summerfield, P.~Blunsom, K.~Kavukcuoglu, and D.~Hassabis.
\newblock {Hybrid computing using a neural network with dynamic external
  memory}.
\newblock \emph{Nature}, 2016.

\bibitem[Harlow(1949)]{harlow1949formation}
H.~F. Harlow.
\newblock The formation of learning sets.
\newblock \emph{Psychological review}, 56\penalty0 (1):\penalty0 51, 1949.

\bibitem[Hochreiter and Schmidhuber(1997)]{hochreiter:1997}
S.~Hochreiter and J.~Schmidhuber.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Hochreiter et~al.(2001)Hochreiter, Younger, and
  Conwell]{hochreiter:2001}
S.~Hochreiter, A.~S. Younger, and P.~R. Conwell.
\newblock Learning to learn using gradient descent.
\newblock In \emph{International Conference on Artificial Neural Networks},
  pages 87--94. Springer, 2001.

\bibitem[Hoffman et~al.(2009)Hoffman, Kueck, de~Freitas, and
  Doucet]{hoffman:2009b}
M.~W. Hoffman, H.~Kueck, N.~de~Freitas, and A.~Doucet.
\newblock New inference strategies for solving {Markov} decision processes
  using reversible jump {MCMC}.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 223--231,
  2009.

\bibitem[Hutter et~al.(2011{\natexlab{a}})Hutter, Hoos, and
  Leyton-Brown]{Hutter:smac}
F.~Hutter, H.~H. Hoos, and K.~Leyton-Brown.
\newblock Sequential model-based optimization for general algorithm
  configuration.
\newblock In \emph{LION}, pages 507--523, 2011{\natexlab{a}}.

\bibitem[Hutter et~al.(2011{\natexlab{b}})Hutter, Hoos, and
  Leyton-Brown]{hutter2011sequential}
F.~Hutter, H.~H. Hoos, and K.~Leyton-Brown.
\newblock Sequential model-based optimization for general algorithm
  configuration.
\newblock In \emph{International Conference on Learning and Intelligent
  Optimization}, pages 507--523. Springer, 2011{\natexlab{b}}.

\bibitem[Kehoe(1988)]{kehoe1988layered}
E.~J. Kehoe.
\newblock A layered network model of associative learning: learning to learn
  and configuration.
\newblock \emph{Psychological review}, 95\penalty0 (4):\penalty0 411, 1988.

\bibitem[Kohavi et~al.(2009)Kohavi, Longbotham, Sommerfield, and
  Henne]{Kohavi:2009}
R.~Kohavi, R.~Longbotham, D.~Sommerfield, and R.~M. Henne.
\newblock Controlled experiments on the web: survey and practical guide.
\newblock \emph{Data mining and knowledge discovery}, 18\penalty0 (1):\penalty0
  140--181, 2009.

\bibitem[Li and Malik(2017)]{Li2017learning}
S.~Li and J.~Malik.
\newblock Learning to optimize.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Mo{\v c}kus(1982)]{Mockus:1982}
J.~Mo{\v c}kus.
\newblock The {B}ayesian approach to global optimization.
\newblock In \emph{Systems Modeling and Optimization}, volume~38, pages
  473--481. Springer, 1982.

\bibitem[Naik and Mammone(1992)]{naik:1992}
D.~K. Naik and R.~Mammone.
\newblock Meta-neural networks that learn by learning.
\newblock In \emph{International Joint Conference on Neural Networks},
  volume~1, pages 437--442, 1992.

\bibitem[Rasmussen and Williams(2006)]{Rasmussen:2006}
C.~E. Rasmussen and C.~K.~I. Williams.
\newblock \emph{Gaussian Processes for Machine Learning}.
\newblock The MIT Press, 2006.

\bibitem[Ravi and Larochelle(2017)]{Ravi2017optimization}
S.~Ravi and H.~Larochelle.
\newblock Optimization as a model for few-shot learning.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Santoro et~al.(2016)Santoro, Bartunov, Botvinick, Wierstra, and
  Lillicrap]{santoro:2016}
A.~Santoro, S.~Bartunov, M.~Botvinick, D.~Wierstra, and T.~Lillicrap.
\newblock Meta-learning with memory-augmented neural networks.
\newblock In \emph{International Conference on Machine Learning}, 2016.

\bibitem[Schmidhuber(1987)]{schmidhuber:1987}
J.~Schmidhuber.
\newblock \emph{Evolutionary Principles in Self-Referential Learning. On
  Learning how to Learn: The Meta-Meta-Meta...-Hook}.
\newblock PhD thesis, Institut f. Informatik, Tech. Univ. Munich, 1987.

\bibitem[Scott(2010)]{Scott:2010}
S.~L. Scott.
\newblock A modern {B}ayesian look at the multi-armed bandit.
\newblock \emph{Applied Stochastic Models in Business and Industry},
  26\penalty0 (6):\penalty0 639--658, 2010.

\bibitem[Shahriari et~al.(2016)Shahriari, Swersky, Wang, Adams, and
  de~Freitas]{Outoftheloop}
B.~Shahriari, K.~Swersky, Z.~Wang, R.~P. Adams, and N.~de~Freitas.
\newblock Taking the human out of the loop: A review of {Bayesian}
  optimization.
\newblock \emph{Proceedings of the IEEE}, 104\penalty0 (1):\penalty0 148--175,
  2016.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{Snoek:2012}
J.~Snoek, H.~Larochelle, and R.~P. Adams.
\newblock Practical {Bayesian} optimization of machine learning algorithms.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2951--2959, 2012.

\bibitem[Snoek et~al.(2014)Snoek, Swersky, Zemel, and
  Adams]{snoek-warping-2014}
J.~Snoek, K.~Swersky, R.~S. Zemel, and R.~P. Adams.
\newblock Input warping for {B}ayesian optimization of non-stationary
  functions.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Spelke and Kinzler(2007)]{spelke2007core}
E.~S. Spelke and K.~D. Kinzler.
\newblock Core knowledge.
\newblock \emph{Developmental science}, 10\penalty0 (1):\penalty0 89--96, 2007.

\bibitem[Srinivas et~al.(2010)Srinivas, Krause, Kakade, and
  Seeger]{Srinivas:2010}
N.~Srinivas, A.~Krause, S.~M. Kakade, and M.~Seeger.
\newblock Gaussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock In \emph{International Conference on Machine Learning}, pages
  1015--1022, 2010.

\bibitem[Thrun and Pratt(1998)]{thrun:1998}
S.~Thrun and L.~Pratt.
\newblock \emph{Learning to learn}.
\newblock Springer Science \& Business Media, 1998.

\bibitem[Wang et~al.(2016)Wang, Kurth{-}Nelson, Tirumala, Soyer, Leibo, Munos,
  Blundell, Kumaran, and Botvinick]{Wang2016learning}
J.~X. Wang, Z.~Kurth{-}Nelson, D.~Tirumala, H.~Soyer, J.~Z. Leibo, R.~Munos,
  C.~Blundell, D.~Kumaran, and M.~Botvinick.
\newblock Learning to reinforcement learn.
\newblock arXiv Report 1611.05763, 2016.

\bibitem[Wang et~al.(2014)Wang, Shakibi, Jin, and de~Freitas]{Wang:2014aistats}
Z.~Wang, B.~Shakibi, L.~Jin, and N.~de~Freitas.
\newblock Bayesian multi-scale optimistic optimization.
\newblock In \emph{AI and Statistics}, pages 1005--1014, 2014.

\bibitem[Ward(1937)]{ward1937reminiscence}
L.~B. Ward.
\newblock Reminiscence and rote learning.
\newblock \emph{Psychological Monographs}, 49\penalty0 (4), 1937.

\bibitem[Williams(1992)]{williams1992simple}
R.~J. Williams.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 229--256, 1992.

\bibitem[Zoph and Le(2017)]{ZophLe2017}
B.~Zoph and Q.~V. Le.
\newblock Neural architecture search with reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\end{thebibliography}
