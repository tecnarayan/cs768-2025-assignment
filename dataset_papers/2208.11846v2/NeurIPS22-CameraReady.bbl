\begin{thebibliography}{100}

\bibitem{ElAlaoui-ABLpLaplacian2016}
A.~El~Alaoui, X.~Cheng, A.~Ramdas, M.~J. Wainwright, and M.~I. Jordan,
  ``Asymptotic behavior of $\ell_p$-based {Laplacian} regularization in
  semi-supervised learning,'' in {\em Conference on Learning Theory},
  pp.~879--906, 2016.

\bibitem{Adil-NeurIPS2019}
D.~Adil, R.~Peng, and S.~Sachdeva, ``Fast, provably convergent {IRLS} algorithm
  for p-norm linear regression,'' {\em Advances in Neural Information
  Processing Systems}, vol.~32, 2019.

\bibitem{Slepcev-SIAMAnalysis19}
D.~Slepcev and M.~Thorpe, ``Analysis of p-{Laplacian} regularization in
  semisupervised learning,'' {\em SIAM Journal on Mathematical Analysis},
  vol.~51, no.~3, pp.~2085--2120, 2019.

\bibitem{Bubeck-STOC2018}
S.~Bubeck, M.~B. Cohen, Y.~T. Lee, and Y.~Li, ``An homotopy method for $\ell_p$
  regression provably beyond self-concordance and in input-sparsity time,'' in
  {\em ACM Symposium on Theory of Computing}, pp.~1130--1137, 2018.

\bibitem{Adil-SODA2019}
D.~Adil, R.~Kyng, R.~Peng, and S.~Sachdeva, ``Iterative refinement for
  $\ell_p$-norm regression,'' in {\em ACM-SIAM Symposium on Discrete
  Algorithms}, pp.~1405--1424, 2019.

\bibitem{Jambulapati-arXiv2021}
A.~Jambulapati, Y.~P. Liu, and A.~Sidford, ``Improved iteration complexities
  for overconstrained $p$-norm regression,'' tech. rep., arXiv:2111.01848v2
  [cs.DS], 2021.

\bibitem{Boscovich-1757}
R.~J. Boscovich, ``De litteraria expeditione per pontificiam ditionem, et
  synopsis amplioris operis, ac habentur plura ejus ex exemplaria etiam
  sensorum impessa,'' {\em Bononiensi Scientiarum et Artum Instuto Atque
  Academia Commentarii}, vol.~4, pp.~353--396, 1757.

\bibitem{Plackett-Biometrika1972}
R.~L. Plackett, ``{Studies in the History of Probability and Statistics. XXIX:
  The discovery of the method of least squares},'' {\em Biometrika}, vol.~59,
  pp.~239--251, 08 1972.

\bibitem{Wright-2020}
J.~Wright and Y.~Ma, {\em High-Dimensional Data Analysis with Low-Dimensional
  Models: Principles, Computation, and Applications}.
\newblock Cambridge University Press, 2020.

\bibitem{Huber-1964}
P.~J. Huber, ``Robust estimation of a location parameter,'' {\em The Annals of
  Mathematical Statistics}, vol.~35, no.~1, pp.~73--101, 1964.

\bibitem{Candes-FOCS2005}
E.~Candes, M.~Rudelson, T.~Tao, and R.~Vershynin, ``Error correction via linear
  programming,'' in {\em IEEE Symposium on Foundations of Computer Science},
  pp.~668--681, 2005.

\bibitem{Bhatia-NeurIPS2015}
K.~Bhatia, P.~Jain, and P.~Kar, ``Robust regression via hard thresholding,''
  {\em Advances in Neural Information Processing Systems}, vol.~28, 2015.

\bibitem{Bhatia-NeurIPS2017}
K.~Bhatia, P.~Jain, P.~Kamalaruban, and P.~Kar, ``Consistent robust
  regression,'' {\em Advances in Neural Information Processing Systems},
  vol.~30, 2017.

\bibitem{Yang-JMLR2017}
J.~Yang, Y.-L. Chow, C.~R{\'e}, and M.~W. Mahoney, ``Weighted {SGD} for
  $\ell_p$ regression with randomized preconditioning,'' {\em The Journal of
  Machine Learning Research}, vol.~18, no.~1, pp.~7811--7853, 2017.

\bibitem{Durfee-COLT2018}
D.~Durfee, K.~A. Lai, and S.~Sawlani, ``$\ell_1$ regression using lewis weights
  preconditioning and stochastic gradient descent,'' in {\em Conference On
  Learning Theory}, pp.~1626--1656, 2018.

\bibitem{Suggala-COLT2019}
A.~S. Suggala, K.~Bhatia, P.~Ravikumar, and P.~Jain, ``Adaptive hard
  thresholding for near-optimal consistent robust regression,'' in {\em
  Conference on Learning Theory}, pp.~2892--2897, 2019.

\bibitem{Mukhoty-AISTATS2019}
B.~Mukhoty, G.~Gopakumar, P.~Jain, and P.~Kar, ``Globally-convergent
  iteratively reweighted least squares for robust regression problems,'' in
  {\em International Conference on Artificial Intelligence and Statistics},
  pp.~313--322, 2019.

\bibitem{Pesme-NeurIPS2020}
S.~Pesme and N.~Flammarion, ``Online robust regression via sgd on the $\ell_1$
  loss,'' {\em Advances in Neural Information Processing Systems}, vol.~33,
  pp.~2540--2552, 2020.

\bibitem{Chen-COLT2021}
X.~Chen and M.~Derezinski, ``Query complexity of least absolute deviation
  regression via robust uniform convergence,'' in {\em Conference on Learning
  Theory}, pp.~1144--1179, 2021.

\bibitem{Parulekar-arXiv2021}
A.~Parulekar, A.~Parulekar, and E.~Price, ``$\ell_1$ regression with {Lewis}
  weights subsampling,'' tech. rep., arXiv:2105.09433 [cs.LG], 2021.

\bibitem{Candes-TIT2005}
E.~J. Candes and T.~Tao, ``Decoding by linear programming,'' {\em IEEE
  Transactions on Information Theory}, vol.~51, no.~12, pp.~4203--4215, 2005.

\bibitem{Candes-CPAM2006}
E.~J. Candes, J.~K. Romberg, and T.~Tao, ``Stable signal recovery from
  incomplete and inaccurate measurements,'' {\em Communications on Pure and
  Applied Mathematics}, vol.~59, no.~8, pp.~1207--1223, 2006.

\bibitem{Donoho-CPAM2006}
D.~L. Donoho, ``For most large underdetermined systems of linear equations the
  minimal $\ell_1$-norm solution is also the sparsest solution,'' {\em
  Communications on Pure and Applied Mathematics}, vol.~59, no.~6,
  pp.~797--829, 2006.

\bibitem{Cohen-JAMS2009}
A.~Cohen, W.~Dahmen, and R.~DeVore, ``Compressed sensing and best $k$-term
  approximation,'' {\em Journal of the American Mathematical Society}, vol.~22,
  no.~1, pp.~211--231, 2009.

\bibitem{Blumensath-ACHA2009}
T.~Blumensath and M.~E. Davies, ``Iterative hard thresholding for compressed
  sensing,'' {\em Applied and Computational Harmonic Analysis}, vol.~27, no.~3,
  pp.~265--274, 2009.

\bibitem{Daubechies-CPAM2010}
I.~Daubechies, R.~DeVore, M.~Fornasier, and C.~S. G{\"u}nt{\"u}rk,
  ``Iteratively reweighted least squares minimization for sparse recovery,''
  {\em Communications on Pure and Applied Mathematics}, vol.~63, no.~1,
  pp.~1--38, 2010.

\bibitem{Kummerle-NeurIPS2021}
C.~K{\"u}mmerle, C.~Mayrink~Verdun, and D.~St{\"o}ger, ``Iteratively reweighted
  least squares for basis pursuit with global linear convergence rate,'' {\em
  Advances in Neural Information Processing Systems}, 2021.

\bibitem{Foucart-2013}
S.~Foucart and H.~Rauhut, {\em A Mathematical Introduction to Compressive
  Sensing}.
\newblock Springer New York, 2013.

\bibitem{Chartrand-ICASSP2007}
R.~Chartrand, ``Nonconvex compressed sensing and error correction,'' in {\em
  IEEE International Conference on Acoustics, Speech and Signal Processing},
  vol.~3, pp.~III--889, 2007.

\bibitem{Chartrand-SPL2007}
R.~Chartrand, ``Exact reconstruction of sparse signals via nonconvex
  minimization,'' {\em IEEE Signal Processing Letters}, vol.~14, no.~10,
  pp.~707--710, 2007.

\bibitem{Chartrand-2008}
R.~Chartrand and V.~Staneva, ``Restricted isometry properties and nonconvex
  compressive sensing,'' {\em Inverse Problems}, vol.~24, no.~3, p.~035020,
  2008.

\bibitem{Foucart-ACHA2009}
S.~Foucart and M.-J. Lai, ``Sparsest solutions of underdetermined linear
  systems via $\ell_q$-minimization for $0< q \leq 1$,'' {\em Applied and
  Computational Harmonic Analysis}, vol.~26, no.~3, pp.~395--407, 2009.

\bibitem{Wang-TIT2011}
M.~Wang, W.~Xu, and A.~Tang, ``On the performance of sparse recovery via
  $\ell_p$-minimization ($0\leq p \leq 1$),'' {\em IEEE Transactions on
  Information Theory}, vol.~57, no.~11, pp.~7255--7278, 2011.

\bibitem{Sun-ACHA2012}
Q.~Sun, ``Recovery of sparsest signals via $\ell_q$-minimization,'' {\em
  Applied and Computational Harmonic Analysis}, vol.~32, no.~3, pp.~329--341,
  2012.

\bibitem{Ba-TSP2013}
D.~Ba, B.~Babadi, P.~L. Purdon, and E.~N. Brown, ``Convergence and stability of
  iteratively re-weighted least squares algorithms,'' {\em IEEE Transactions on
  Signal Processing}, vol.~62, no.~1, pp.~183--195, 2013.

\bibitem{Zheng-TIT2017}
L.~Zheng, A.~Maleki, H.~Weng, X.~Wang, and T.~Long, ``Does
  $\ell_p$-minimization outperform $\ell_1$-minimization?,'' {\em IEEE
  Transactions on Information Theory}, vol.~63, no.~11, pp.~6896--6935, 2017.

\bibitem{Marjanovic-TSP2012}
G.~Marjanovic and V.~Solo, ``On $\ell_q$ optimization and matrix completion,''
  {\em IEEE Transactions on Signal Processing}, vol.~60, no.~11,
  pp.~5714--5724, 2012.

\bibitem{Mohan-JMLR2012}
K.~Mohan and M.~Fazel, ``Iterative reweighted algorithms for matrix rank
  minimization,'' {\em The Journal of Machine Learning Research}, vol.~13,
  no.~1, pp.~3441--3473, 2012.

\bibitem{Nie-AAAI2012}
F.~Nie, H.~Huang, and C.~Ding, ``Low-rank matrix recovery via efficient
  {Schatten} $p$-norm minimization,'' in {\em AAAI Conference on Artificial
  Intelligence}, 2012.

\bibitem{Kummerle-JMLR2018}
C.~K{\"u}mmerle and J.~Sigl, ``Harmonic mean iteratively reweighted least
  squares for low-rank matrix recovery,'' {\em The Journal of Machine Learning
  Research}, vol.~19, no.~1, pp.~1815--1863, 2018.

\bibitem{Giampouras-NeurIPS2020}
P.~Giampouras, R.~Vidal, A.~Rontogiannis, and B.~Haeffele, ``A novel
  variational form of the {Schatten}-$p$ quasi-norm,'' {\em Advances in Neural
  Information Processing Systems}, vol.~33, pp.~21453--21463, 2020.

\bibitem{Kummerle-ICML2021}
C.~K{\"u}mmerle and C.~Mayrink~Verdun, ``A scalable second order method for
  ill-conditioned matrix completion from few samples,'' in {\em International
  Conference on Machine Learning}, pp.~5872--5883, 2021.

\bibitem{Lerman-FoCM2015}
G.~Lerman, M.~B. McCoy, J.~A. Tropp, and T.~Zhang, ``Robust computation of
  linear models by convex relaxation,'' {\em Foundations of Computational
  Mathematics}, vol.~15, no.~2, pp.~363--410, 2015.

\bibitem{Tsakiris-JMLR2018}
M.~C. Tsakiris and R.~Vidal, ``Dual principal component pursuit,'' {\em Journal
  of Machine Learning Research}, vol.~19, no.~18, pp.~1--50, 2018.

\bibitem{Zhu-NeurIPS2018}
Z.~Zhu, Y.~Wang, D.~Robinson, D.~Naiman, R.~Vidal, and M.~C. Tsakiris, ``Dual
  principal component pursuit: Improved analysis and efficient algorithms,'' in
  {\em Advances in Neural Information Processing Systems}, 2018.

\bibitem{Ding-ICML2019}
T.~Ding, Z.~Zhu, T.~Ding, Y.~Yang, R.~Vidal, M.~C. Tsakiris, and D.~Robinson,
  ``Noisy dual principal component pursuit,'' in {\em International Conference
  on Machine Learning}, pp.~1617--1625, 2019.

\bibitem{Aftab-WCACV2015}
K.~Aftab and R.~Hartley, ``Convergence of iteratively re-weighted least squares
  to robust {M}-estimators,'' in {\em IEEE Winter Conference on Applications of
  Computer Vision}, pp.~480--487, 2015.

\bibitem{Dong-PRL2019}
W.~Dong, X.-j. Wu, and J.~Kittler, ``Sparse subspace clustering via smoothed
  $\ell_p$ minimization,'' {\em Pattern Recognition Letters}, vol.~125,
  pp.~206--211, 2019.

\bibitem{Iwata-ECCV2020}
D.~Iwata, M.~Waechter, W.-Y. Lin, and Y.~Matsushita, ``An analysis of sketched
  {IRLS} for accelerated sparse residual regression,'' in {\em European
  Conference on Computer Vision}, pp.~609--626, 2020.

\bibitem{Ding-CVPR2020}
T.~Ding, Y.~Yang, Z.~Zhu, D.~P. Robinson, R.~Vidal, L.~Kneip, and M.~C.
  Tsakiris, ``Robust homography estimation via dual principal component
  pursuit,'' in {\em IEEE Conference on Computer Vision and Pattern
  Recognition}, pp.~6080--6089, 2020.

\bibitem{Yang-RA-L2020}
H.~Yang, P.~Antonante, V.~Tzoumas, and L.~Carlone, ``Graduated non-convexity
  for robust spatial perception: From non-minimal solvers to global outlier
  rejection,'' {\em IEEE Robotics and Automation Letters}, vol.~5, no.~2,
  pp.~1127--1134, 2020.

\bibitem{Zhao-SIAM-J-O2012}
Y.-B. Zhao and D.~Li, ``Reweighted $\ell_1$-minimization for sparse solutions
  to underdetermined linear systems,'' {\em SIAM Journal on Optimization},
  vol.~22, no.~3, pp.~1065--1088, 2012.

\bibitem{Beck-OptBook2017}
A.~Beck, {\em First-Order Methods in Optimization}.
\newblock Society for Industrial and Applied Mathematics, 2017.

\bibitem{Nesterov-2018}
Y.~Nesterov, {\em Lectures on Convex Optimization}.
\newblock Springer, 2018.

\bibitem{Chen-MP2019}
Y.~Chen, Y.~Chi, J.~Fan, and C.~Ma, ``Gradient descent with random
  initialization: fast global convergence for nonconvex phase retrieval,'' {\em
  Mathematical Programming}, vol.~176, no.~1, pp.~5--37, 2019.

\bibitem{Tan-AA-J-IMA2019}
Y.~S. Tan and R.~Vershynin, ``Phase retrieval via randomized {K}aczmarz:
  Theoretical guarantees,'' {\em Information and Inference: A Journal of the
  IMA}, vol.~8, no.~1, pp.~97--123, 2019.

\bibitem{Unnikrishnan-TIT18}
J.~Unnikrishnan, S.~Haghighatshoar, and M.~Vetterli, ``Unlabeled sensing with
  random linear measurements,'' {\em IEEE Transactions on Information Theory},
  vol.~64, no.~5, pp.~3237--3253, 2018.

\bibitem{Slawski-JoS19}
M.~Slawski and E.~Ben-David, ``Linear regression with sparsely permuted data,''
  {\em Electronic Journal of Statistics}, vol.~13, no.~1, pp.~1--36, 2019.

\bibitem{Tsakiris-TIT2020}
M.~C. {Tsakiris}, L.~{Peng}, A.~{Conca}, L.~{Kneip}, Y.~{Shi}, and H.~{Choi},
  ``An algebraic-geometric approach for linear regression without
  correspondences,'' {\em IEEE Transactions on Information Theory}, vol.~66,
  no.~8, pp.~5130--5144, 2020.

\bibitem{Peng-SPL2020}
L.~{Peng} and M.~C. {Tsakiris}, ``Linear regression without correspondences via
  concave minimization,'' {\em IEEE Signal Processing Letters}, vol.~27,
  pp.~1580--1584, 2020.

\bibitem{Wright-TPAMI2008}
J.~Wright, A.~Y. Yang, A.~Ganesh, S.~S. Sastry, and Y.~Ma, ``Robust face
  recognition via sparse representation,'' {\em IEEE Transactions on Pattern
  Analysis and Machine Intelligence}, vol.~31, no.~2, pp.~210--227, 2008.

\bibitem{Solomon-2011}
C.~Solomon and T.~Breckon, {\em Fundamentals of Digital Image Processing: A
  practical approach with examples in Matlab}.
\newblock John Wiley \& Sons, 2011.

\bibitem{Yao-NeurIPS2021}
Y.~Yao, L.~Peng, and M.~Tsakiris, ``Unlabeled principal component analysis,''
  {\em Advances in Neural Information Processing Systems}, 2021.

\bibitem{Balan-ACHA2006}
R.~Balan, P.~Casazza, and D.~Edidin, ``On signal reconstruction without
  phase,'' {\em Applied and Computational Harmonic Analysis}, vol.~20, no.~3,
  pp.~345 -- 356, 2006.

\bibitem{Strohmer-JFAA2009}
T.~Strohmer and R.~Vershynin, ``A randomized {K}aczmarz algorithm with
  exponential convergence,'' {\em Journal of Fourier Analysis and
  Applications}, vol.~15, no.~2, pp.~262--278, 2009.

\bibitem{Wei-IP2015}
K.~Wei, ``Solving systems of phaseless equations via {K}aczmarz methods: A
  proof of concept study,'' {\em Inverse Problems}, vol.~31, no.~12, p.~125008,
  2015.

\bibitem{Dhifallah-Allerton2017}
O.~Dhifallah, C.~Thrampoulidis, and Y.~M. Lu, ``Phase retrieval via linear
  programming: Fundamental limits and algorithmic improvements,'' in {\em
  Allerton Conference on Communication, Control, and Computing},
  pp.~1071--1077, 2017.

\bibitem{Chen-NIPS2015}
Y.~Chen and E.~Candes, ``Solving random quadratic systems of equations is
  nearly as easy as solving linear systems,'' {\em Advances in Neural
  Information Processing Systems}, vol.~28, 2015.

\bibitem{Zeng-arXiv2017}
W.-J. Zeng and H.-C. So, ``Coordinate descent algorithms for phase retrieval,''
  tech. rep., arXiv:1706.03474 [cs.IT], 2017.

\bibitem{Applegate-NeurIPS2021}
D.~Applegate, M.~D{\'i}az, O.~Hinder, H.~Lu, M.~Lubin, B.~O'Donoghue, and
  W.~Schudy, ``Practical large-scale linear programming using primal-dual
  hybrid gradient,'' {\em Advances in Neural Information Processing Systems},
  vol.~34, 2021.

\bibitem{Gurobi951}
``Gurobi 9.5.1.'' https://www.gurobi.com/, Date Accessed: May 10, 2022.

\bibitem{Beck-OMS2019}
A.~Beck and N.~Guttmann-Beck, ``{FOM} – a {MATLAB} toolbox of first-order
  methods for solving convex optimization problems,'' {\em Optimization Methods
  and Software}, vol.~34, no.~1, pp.~172--193, 2019.

\bibitem{Georghiades-PAMI2001}
A.~S. Georghiades, P.~N. Belhumeur, and D.~J. Kriegman, ``From few to many:
  Illumination cone models for face recognition under variable lighting and
  pose,'' {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  vol.~23, no.~6, pp.~643--660, 2001.

\bibitem{Chen-SIAM-Rev2001}
S.~S. Chen, D.~L. Donoho, and M.~A. Saunders, ``Atomic decomposition by basis
  pursuit,'' {\em SIAM Review}, vol.~43, no.~1, pp.~129--159, 2001.

\bibitem{Lerman-J-IMA2018}
G.~Lerman and T.~Maunu, ``Fast, robust and non-convex subspace recovery,'' {\em
  Information and Inference: A Journal of the IMA}, vol.~7, no.~2,
  pp.~277--336, 2018.

\bibitem{Qu-arXiv2020}
Q.~Qu, Z.~Zhu, X.~Li, M.~C. Tsakiris, J.~Wright, and R.~Vidal, ``Finding the
  sparsest vectors in a subspace: Theory, algorithms, and applications,'' tech.
  rep., arXiv:2001.06970 [cs.LG], 2020.

\bibitem{Chan-SIAM-J-NA1999}
T.~F. Chan and P.~Mulet, ``On the convergence of the lagged diffusivity fixed
  point method in total variation image restoration,'' {\em SIAM Journal on
  Numerical Analysis}, vol.~36, no.~2, pp.~354--367, 1999.

\bibitem{Beck-SIAMOpt2015}
A.~Beck, ``On the convergence of alternating minimization for convex
  programming with applications to iteratively reweighted least squares and
  decomposition schemes,'' {\em SIAM Journal on Optimization}, vol.~25, no.~1,
  pp.~185--209, 2015.

\bibitem{Aravkin-arXiv2019}
A.~Y. Aravkin, J.~V. Burke, and D.~He, ``{IRLS} for sparse recovery revisited:
  Examples of failure and a remedy,'' tech. rep., arXiv:1910.07095 [math.ST],
  2019.

\bibitem{Yang-arXiv2021Lp}
X.~Yang, J.~Wang, and H.~Wang, ``Towards an efficient approach for the
  nonconvex $\ell_p$-ball projection: Algorithm and analysis,'' tech. rep.,
  arXiv:2101.01350v5 [math.OC], 2021.

\bibitem{Tillmann-TIT2013}
A.~M. Tillmann and M.~E. Pfetsch, ``The computational complexity of the
  restricted isometry property, the nullspace property, and related concepts in
  compressed sensing,'' {\em IEEE Transactions on Information Theory}, vol.~60,
  no.~2, pp.~1248--1259, 2013.

\bibitem{Arora-2009}
S.~Arora and B.~Barak, {\em Computational Complexity: A Modern Approach}.
\newblock Cambridge University Press, 2009.

\bibitem{Boyd-book2004}
S.~Boyd, S.~P. Boyd, and L.~Vandenberghe, {\em Convex optimization}.
\newblock Cambridge University Press, 2004.

\bibitem{Allen-JMLR2017}
Z.~Allen-Zhu, ``Katyusha: The first direct acceleration of stochastic gradient
  methods,'' {\em The Journal of Machine Learning Research}, vol.~18, no.~1,
  pp.~8194--8244, 2017.

\bibitem{LecueMendelson-EMS17}
G.~Lecu{\'e} and S.~Mendelson, ``Sparse recovery under weak moment
  assumptions,'' {\em Journal of the European Mathematical Society}, vol.~19,
  no.~3, pp.~881--904, 2017.

\bibitem{DirksenLecueRauhut-IEEEIT2017}
S.~Dirksen, G.~Lecu{\'e}, and H.~Rauhut, ``On the gap between restricted
  isometry properties and sparse recovery conditions,'' {\em IEEE Transactions
  on Information Theory}, vol.~64, no.~8, pp.~5478--5487, 2016.

\bibitem{Tsakiris-ICML2019}
M.~C. Tsakiris and L.~Peng, ``Homomorphic sensing,'' in {\em International
  Conference on Machine Learning}, 2019.

\bibitem{Peng-ICML2021}
L.~Peng, B.~Wang, and M.~Tsakiris, ``Homomorphic sensing: Sparsity and noise,''
  in {\em International Conference on Machine Learning}, pp.~8464--8475, 2021.

\bibitem{Peng-ACHA2021}
L.~Peng and M.~C. Tsakiris, ``Homomorphic sensing of subspace arrangements,''
  {\em Applied and Computational Harmonic Analysis}, vol.~55, pp.~466--485,
  2021.

\bibitem{Grohs-SIAM-Review2020}
P.~Grohs, S.~Koppensteiner, and M.~Rathmair, ``Phase retrieval: Uniqueness and
  stability,'' {\em SIAM Review}, vol.~62, no.~2, pp.~301--350, 2020.

\bibitem{Huang-arXiv2021b}
M.~Huang and Y.~Wang, ``Linear convergence of randomized {K}aczmarz method for
  solving complex-valued phaseless equations,'' tech. rep., arXiv:2109.11811
  [math.NA], 2021.

\bibitem{Chandra-SampTA2019}
R.~Chandra, T.~Goldstein, and C.~Studer, ``{PhasePack}: A phase retrieval
  library,'' in {\em International conference on Sampling Theory and
  Applications}, pp.~1--5, 2019.

\bibitem{Pananjady-TIT18}
A.~Pananjady, M.~J. Wainwright, and T.~A. Courtade, ``Linear regression with
  shuffled data: Statistical and computational limits of permutation
  recovery,'' {\em IEEE Transactions on Information Theory}, vol.~64, no.~5,
  pp.~3286--3300, 2018.

\bibitem{Slawski-JCGS2021}
M.~Slawski, G.~Diao, and E.~Ben-David, ``A pseudo-likelihood approach to linear
  regression with partially shuffled data,'' {\em Journal of Computational and
  Graphical Statistics}, vol.~0, no.~0, pp.~1--31, 2021.

\bibitem{Xie-ICLR2021}
Y.~Xie, Y.~Mao, S.~Zuo, H.~Xu, X.~Ye, T.~Zhao, and H.~Zha, ``A hypergradient
  approach to robust regression without correspondence,'' in {\em International
  Conference on Learning Representations}, 2021.

\bibitem{Li-ICCV2021}
F.~Li, K.~Fujiwara, F.~Okura, and Y.~Matsushita, ``Generalized shuffled linear
  regression,'' in {\em IEEE/CVF International Conference on Computer Vision},
  pp.~6474--6483, 2021.

\bibitem{Hsu-NIPS17}
D.~Hsu, K.~Shi, and X.~Sun, ``Linear regression without correspondence,'' in
  {\em Advances in Neural Information Processing Systems}, 2017.

\bibitem{You-CVPR2016}
C.~You, D.~Robinson, and R.~Vidal, ``Scalable sparse subspace clustering by
  orthogonal matching pursuit,'' in {\em IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.~3918--3927, 2016.

\bibitem{Basri-TPAMI2003}
R.~Basri and D.~W. Jacobs, ``Lambertian reflectance and linear subspaces,''
  {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  vol.~25, no.~2, pp.~218--233, 2003.

\bibitem{Fornasier-COA2016}
M.~Fornasier, S.~Peter, H.~Rauhut, and S.~Worm, ``Conjugate gradient
  acceleration of iteratively re-weighted least squares methods,'' {\em
  Computational Optimization and Applications}, vol.~65, no.~1, pp.~205--259,
  2016.

\bibitem{Gazzola-SIAM-J-MA2020}
S.~Gazzola, C.~Meng, and J.~G. Nagy, ``Krylov methods for low-rank
  regularization,'' {\em SIAM Journal on Matrix Analysis and Applications},
  vol.~41, no.~4, pp.~1477--1504, 2020.

\bibitem{Chatterjee-TPAMI2017}
A.~Chatterjee and V.~M. Govindu, ``Robust relative rotation averaging,'' {\em
  IEEE Transactions on Pattern Analysis and Machine Intelligence}, vol.~40,
  no.~4, pp.~958--972, 2017.

\bibitem{Sidhartha-3DV2021}
C.~Sidhartha and V.~M. Govindu, ``It is all in the weights: Robust rotation
  averaging revisited,'' in {\em International Conference on 3D Vision},
  pp.~1134--1143, 2021.

\bibitem{Peng-CVPR2022}
L.~Peng, M.~C. Tsakiris, and R.~Vidal, ``{ARCS}: Accurate rotation and
  correspondences search,'' in {\em IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pp.~11153--11163, 2022.

\bibitem{Lee-CVPR2022}
S.~H. Lee and J.~Civera, ``{HARA}: A hierarchical approach for robust rotation
  averaging,'' in {\em IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.~15777--15786, 2022.

\bibitem{Peng-ECCV2022}
L.~Peng, M.~Fazlyab, and R.~Vidal, ``Semidefinite relaxations of truncated
  least-squares in robust rotation search: Tight or not,'' in {\em European
  Conference on Computer Vision}, pp.~0--0, Springer, 2022.

\bibitem{Carlone-arXiv2022}
L.~Carlone, ``Estimation contracts for outlier-robust geometric perception,''
  tech. rep., arXiv:2208.10521 [stat.ML], 2022.

\bibitem{Chen-MP2012}
X.~Chen, ``Smoothing methods for nonsmooth, nonconvex minimization,'' {\em
  Mathematical Programming}, vol.~134, no.~1, pp.~71--99, 2012.

\bibitem{Nesterov-FoCM2017}
Y.~Nesterov and V.~Spokoiny, ``Random gradient-free minimization of convex
  functions,'' {\em Foundations of Computational Mathematics}, vol.~17, no.~2,
  pp.~527--566, 2017.

\bibitem{Beck-JOTA2015}
A.~Beck and S.~Sabach, ``Weiszfeld's method: Old and new results,'' {\em
  Journal of Optimization Theory and Applications}, vol.~164, no.~1, pp.~1--40,
  2015.

\bibitem{Lange-MM2016}
K.~Lange, {\em {MM Optimization Algorithms}}.
\newblock Philadelphia, PA: Society for Industrial and Applied Mathematics,
  2016.

\bibitem{SunBabuPalomar-IEEESP2017}
Y.~Sun, P.~Babu, and D.~P. Palomar, ``{M}ajorization-{M}inimization algorithms
  in signal processing, communications, and machine learning,'' {\em {IEEE}
  Transactions on Signal Processing}, vol.~65, no.~3, pp.~794--816, 2017.

\bibitem{FazelHindiBoyd-ACC2003}
M.~{Fazel}, H.~{Hindi}, and S.~P. {Boyd}, ``Log-det heuristic for matrix rank
  minimization with applications to {H}ankel and {E}uclidean distance
  matrices,'' in {\em {Proceedings of the American Control Conference}},
  vol.~3, pp.~2156--2162, 2003.

\bibitem{CandesWakinBoyd-JFA2008}
E.~Cand\`{e}s, M.~B. Wakin, and S.~Boyd, ``Enhancing sparsity by reweighted
  $\ell_1$ minimization,'' {\em The Journal of Fourier Analysis and
  Applications}, vol.~14, pp.~877--905, 2008.

\bibitem{OchsDBP-SIAMIMS2015}
P.~Ochs, A.~Dosovitskiy, T.~Brox, and T.~Pock, ``On iteratively reweighted
  algorithms for nonsmooth nonconvex optimization in computer vision,'' {\em
  SIAM Journal on Imaging Sciences}, vol.~8, no.~1, pp.~331--372, 2015.

\bibitem{Gordon-1988}
Y.~Gordon, ``On {M}ilman's inequality and random subspaces which escape through
  a mesh in $\mathbb{R}^n$,'' in {\em Geometric Aspects of Functional
  Analysis}, pp.~84--106, Springer, 1988.

\bibitem{Rudelson-CPAM2008}
M.~Rudelson and R.~Vershynin, ``On sparse reconstruction from {F}ourier and
  {G}aussian measurements,'' {\em Communications on Pure and Applied
  Mathematics}, vol.~61, no.~8, pp.~1025--1045, 2008.

\end{thebibliography}
