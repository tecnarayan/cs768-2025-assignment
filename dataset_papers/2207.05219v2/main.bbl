\begin{thebibliography}{10}

\bibitem{andrychowicz2020matters}
M.~Andrychowicz, A.~Raichuk, P.~Stanczyk, M.~Orsini, S.~Girgin, R.~Marinier,
  L.~Hussenot, M.~Geist, O.~Pietquin, M.~Michalski, S.~Gelly, and O.~Bachem.
\newblock What matters in on-policy reinforcement learning? {A} large-scale
  empirical study.
\newblock {\em CoRR}, abs/2006.05990, 2020.

\bibitem{arjovsky2019irm}
M.~Arjovsky, L.~Bottou, I.~Gulrajani, and D.~Lopez{-}Paz.
\newblock Invariant risk minimization.
\newblock {\em CoRR}, abs/1907.02893, 2019.

\bibitem{bellman1956problem}
R.~Bellman.
\newblock A problem in the sequential design of experiments.
\newblock {\em Sankhy{\=a}: The Indian Journal of Statistics (1933-1960)},
  16(3/4):221--229, 1956.

\bibitem{bernstein2002complexity}
D.~S. Bernstein, R.~Givan, N.~Immerman, and S.~Zilberstein.
\newblock The complexity of decentralized control of markov decision processes.
\newblock {\em Mathematics of operations research}, 27(4):819--840, 2002.

\bibitem{bickel2009discriminative}
S.~Bickel, M.~Br{\"{u}}ckner, and T.~Scheffer.
\newblock Discriminative learning under covariate shift.
\newblock {\em Journal of Machine Learning Research}, 10:2137--2155, 2009.

\bibitem{amigo}
A.~Campero, R.~Raileanu, H.~Kuttler, J.~B. Tenenbaum, T.~Rockt{\"a}schel, and
  E.~Grefenstette.
\newblock Learning with {AMIG}o: Adversarially motivated intrinsic goals.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{ciosek2017offer}
K.~A. Ciosek and S.~Whiteson.
\newblock {OFFER:} off-environment reinforcement learning.
\newblock In S.~P. Singh and S.~Markovitch, editors, {\em Proceedings of the
  Thirty-First {AAAI} Conference on Artificial Intelligence, February 4-9,
  2017, San Francisco, California, {USA}}, pages 1819--1825. {AAAI} Press,
  2017.

\bibitem{paired}
M.~Dennis, N.~Jaques, E.~Vinitsky, A.~Bayen, S.~Russell, A.~Critch, and
  S.~Levine.
\newblock Emergent complexity and zero-shot transfer via unsupervised
  environment design.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~33, 2020.

\bibitem{der2009aleatory}
A.~Der~Kiureghian and O.~Ditlevsen.
\newblock Aleatory or epistemic? does it matter?
\newblock {\em Structural safety}, 31(2):105--112, 2009.

\bibitem{duff2002optimal}
M.~O. Duff.
\newblock {\em Optimal Learning: Computational procedures for Bayes-adaptive
  Markov decision processes}.
\newblock University of Massachusetts Amherst, 2002.

\bibitem{espeholt18a}
L.~Espeholt, H.~Soyer, R.~Munos, K.~Simonyan, V.~Mnih, T.~Ward, Y.~Doron,
  V.~Firoiu, T.~Harley, I.~Dunning, S.~Legg, and K.~Kavukcuoglu.
\newblock {IMPALA}: Scalable distributed deep-{RL} with importance weighted
  actor-learner architectures.
\newblock In J.~Dy and A.~Krause, editors, {\em Proceedings of the 35th
  International Conference on Machine Learning}, volume~80 of {\em Proceedings
  of Machine Learning Research}, pages 1407--1416. PMLR, 10--15 Jul 2018.

\bibitem{goalgan}
C.~Florensa, D.~Held, X.~Geng, and P.~Abbeel.
\newblock Automatic goal generation for reinforcement learning agents.
\newblock In J.~Dy and A.~Krause, editors, {\em Proceedings of the 35th
  International Conference on Machine Learning}, volume~80 of {\em Proceedings
  of Machine Learning Research}, pages 1515--1528. PMLR, 10--15 Jul 2018.

\bibitem{gelada2019offpolicy}
C.~Gelada and M.~G. Bellemare.
\newblock Off-policy deep reinforcement learning by bootstrapping the covariate
  shift.
\newblock In {\em The Thirty-Third {AAAI} Conference on Artificial
  Intelligence, {AAAI} 2019, The Thirty-First Innovative Applications of
  Artificial Intelligence Conference, {IAAI} 2019, The Ninth {AAAI} Symposium
  on Educational Advances in Artificial Intelligence, {EAAI} 2019, Honolulu,
  Hawaii, USA, January 27 - February 1, 2019}, pages 3647--3655. {AAAI} Press,
  2019.

\bibitem{hallak17a}
A.~Hallak and S.~Mannor.
\newblock Consistent on-line off-policy evaluation.
\newblock In D.~Precup and Y.~W. Teh, editors, {\em Proceedings of the 34th
  International Conference on Machine Learning}, volume~70 of {\em Proceedings
  of Machine Learning Research}, pages 1372--1383. PMLR, 06--11 Aug 2017.

\bibitem{heckman1979sample}
J.~J. Heckman.
\newblock Sample selection bias as a specification error.
\newblock {\em Econometrica: Journal of the econometric society}, pages
  153--161, 1979.

\bibitem{hu2021obl}
H.~Hu, A.~Lerer, B.~Cui, L.~Pineda, N.~Brown, and J.~N. Foerster.
\newblock Off-belief learning.
\newblock In M.~Meila and T.~Zhang, editors, {\em Proceedings of the 38th
  International Conference on Machine Learning, {ICML} 2021, 18-24 July 2021,
  Virtual Event}, volume 139 of {\em Proceedings of Machine Learning Research},
  pages 4369--4379. {PMLR}, 2021.

\bibitem{hu2021otherplay}
H.~Hu, A.~Lerer, A.~Peysakhovich, and J.~Foerster.
\newblock “{O}ther-play” for zero-shot coordination.
\newblock In H.~D. III and A.~Singh, editors, {\em Proceedings of the 37th
  International Conference on Machine Learning}, volume 119 of {\em Proceedings
  of Machine Learning Research}, pages 4399--4410. PMLR, 13--18 Jul 2020.

\bibitem{huang2006correcting}
J.~Huang, A.~Gretton, K.~Borgwardt, B.~Sch{\"o}lkopf, and A.~Smola.
\newblock Correcting sample selection bias by unlabeled data.
\newblock {\em Advances in neural information processing systems}, 19:601--608,
  2006.

\bibitem{evolutionary_dr}
N.~Jakobi.
\newblock Evolutionary robotics and the radical envelope-of-noise hypothesis.
\newblock {\em Adaptive Behavior}, 6(2):325--368, 1997.

\bibitem{robustplr}
M.~Jiang, M.~Dennis, J.~Parker-Holder, J.~Foerster, E.~Grefenstette, and
  T.~Rockt{\"a}schel.
\newblock Replay-guided adversarial environment design.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{plr}
M.~Jiang, E.~Grefenstette, and T.~Rockt{\"{a}}schel.
\newblock Prioritized level replay.
\newblock In {\em Proceedings of the 38th International Conference on Machine
  Learning, {ICML} 2021, 18-24 July 2021, Virtual Event}, volume 139 of {\em
  Proceedings of Machine Learning Research}, pages 4940--4950. {PMLR}, 2021.

\bibitem{justesen2018illuminating}
N.~Justesen, R.~R. Torrado, P.~Bontrager, A.~Khalifa, J.~Togelius, and S.~Risi.
\newblock Procedural level generation improves generality of deep reinforcement
  learning.
\newblock {\em CoRR}, abs/1806.10729, 2018.

\bibitem{nle}
H.~K{\"{u}}ttler, N.~Nardelli, A.~H. Miller, R.~Raileanu, M.~Selvatici,
  E.~Grefenstette, and T.~Rockt{\"{a}}schel.
\newblock {The NetHack Learning Environment}.
\newblock In {\em Proceedings of the Conference on Neural Information
  Processing Systems (NeurIPS)}, 2020.

\bibitem{carracing_ppo}
X.~Ma.
\newblock Car racing with pytorch.
\newblock \url{https://github.com/xtma/pytorch_car_caring}, 2019.

\bibitem{tscl}
T.~Matiisen, A.~Oliver, T.~Cohen, and J.~Schulman.
\newblock Teacher-student curriculum learning.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems}, PP,
  07 2017.

\bibitem{nash1950equilibrium}
J.~F. Nash et~al.
\newblock Equilibrium points in n-person games.
\newblock {\em Proceedings of the national academy of sciences}, 36(1):48--49,
  1950.

\bibitem{openai2021asymmetric}
O.~OpenAI, M.~Plappert, R.~Sampedro, T.~Xu, I.~Akkaya, V.~Kosaraju,
  P.~Welinder, R.~D'Sa, A.~Petron, H.~P. de~Oliveira~Pinto, A.~Paino, H.~Noh,
  L.~Weng, Q.~Yuan, C.~Chu, and W.~Zaremba.
\newblock Asymmetric self-play for automatic goal discovery in robotic
  manipulation, 2021.

\bibitem{osband2013more}
I.~Osband, D.~Russo, and B.~V. Roy.
\newblock (more) efficient reinforcement learning via posterior sampling.
\newblock In C.~J.~C. Burges, L.~Bottou, Z.~Ghahramani, and K.~Q. Weinberger,
  editors, {\em Advances in Neural Information Processing Systems 26: 27th
  Annual Conference on Neural Information Processing Systems 2013. Proceedings
  of a meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States},
  pages 3003--3011, 2013.

\bibitem{peng2017dr}
X.~B. Peng, M.~Andrychowicz, W.~Zaremba, and P.~Abbeel.
\newblock Sim-to-real transfer of robotic control with dynamics randomization.
\newblock {\em CoRR}, abs/1710.06537, 2017.

\bibitem{pinto2017robust}
L.~Pinto, J.~Davidson, R.~Sukthankar, and A.~Gupta.
\newblock Robust adversarial reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  2817--2826. PMLR, 2017.

\bibitem{pomerleau1988alvinn}
D.~Pomerleau.
\newblock {ALVINN:} an autonomous land vehicle in a neural network.
\newblock In D.~S. Touretzky, editor, {\em Advances in Neural Information
  Processing Systems 1, {[NIPS} Conference, Denver, Colorado, USA, 1988]},
  pages 305--313. Morgan Kaufmann, 1988.

\bibitem{portelas2020alpgmm}
R.~Portelas, C.~Colas, K.~Hofmann, and P.-Y. Oudeyer.
\newblock Teacher algorithms for curriculum learning of deep rl in continuously
  parameterized environments.
\newblock In L.~P. Kaelbling, D.~Kragic, and K.~Sugiura, editors, {\em
  Proceedings of the Conference on Robot Learning}, volume 100 of {\em
  Proceedings of Machine Learning Research}, pages 835--853. PMLR, 30 Oct--01
  Nov 2020.

\bibitem{ross2010efficient}
S.~Ross and D.~Bagnell.
\newblock Efficient reductions for imitation learning.
\newblock In Y.~W. Teh and M.~Titterington, editors, {\em Proceedings of the
  Thirteenth International Conference on Artificial Intelligence and
  Statistics}, volume~9 of {\em Proceedings of Machine Learning Research},
  pages 661--668, Chia Laguna Resort, Sardinia, Italy, 13--15 May 2010. PMLR.

\bibitem{rowland20a}
M.~Rowland, W.~Dabney, and R.~Munos.
\newblock Adaptive trade-offs in off-policy learning.
\newblock In S.~Chiappa and R.~Calandra, editors, {\em Proceedings of the
  Twenty Third International Conference on Artificial Intelligence and
  Statistics}, volume 108 of {\em Proceedings of Machine Learning Research},
  pages 34--44. PMLR, 26--28 Aug 2020.

\bibitem{cad2rl}
F.~Sadeghi and S.~Levine.
\newblock {CAD2RL:} real single-image flight without a single real image.
\newblock In N.~M. Amato, S.~S. Srinivasa, N.~Ayanian, and S.~Kuindersma,
  editors, {\em Robotics: Science and Systems XIII, Massachusetts Institute of
  Technology, Cambridge, Massachusetts, USA, July 12-16, 2017}, 2017.

\bibitem{samvelyan2021minihack}
M.~Samvelyan, R.~Kirk, V.~Kurin, J.~Parker-Holder, M.~Jiang, E.~Hambro,
  F.~Petroni, H.~Kuttler, E.~Grefenstette, and T.~Rockt{\"a}schel.
\newblock Minihack the planet: A sandbox for open-ended reinforcement learning
  research.
\newblock In {\em Thirty-fifth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track}, 2021.

\bibitem{savage1951theory}
L.~J. Savage.
\newblock The theory of statistical decision.
\newblock {\em Journal of the American Statistical association},
  46(253):55--67, 1951.

\bibitem{gae}
J.~Schulman, P.~Moritz, S.~Levine, M.~I. Jordan, and P.~Abbeel.
\newblock High-dimensional continuous control using generalized advantage
  estimation.
\newblock In Y.~Bengio and Y.~LeCun, editors, {\em 4th International Conference
  on Learning Representations, {ICLR} 2016, San Juan, Puerto Rico, May 2-4,
  2016, Conference Track Proceedings}, 2016.

\bibitem{schulman2017proximal}
J.~Schulman, F.~Wolski, P.~Dhariwal, A.~Radford, and O.~Klimov.
\newblock Proximal policy optimization algorithms, 2017.

\bibitem{alphago}
D.~Silver, A.~Huang, C.~J. Maddison, A.~Guez, L.~Sifre, G.~van~den Driessche,
  J.~Schrittwieser, I.~Antonoglou, V.~Panneershelvam, M.~Lanctot, S.~Dieleman,
  D.~Grewe, J.~Nham, N.~Kalchbrenner, I.~Sutskever, T.~P. Lillicrap, M.~Leach,
  K.~Kavukcuoglu, T.~Graepel, and D.~Hassabis.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em Nature}, 529(7587):484--489, 2016.

\bibitem{xland}
A.~Stooke, A.~Mahajan, C.~Barros, C.~Deck, J.~Bauer, J.~Sygnowski, M.~Trebacz,
  M.~Jaderberg, M.~Mathieu, N.~McAleese, N.~Bradley{-}Schmieg, N.~Wong,
  N.~Porcel, R.~Raileanu, S.~Hughes{-}Fitt, V.~Dalibard, and W.~M. Czarnecki.
\newblock Open-ended learning leads to generally capable agents.
\newblock {\em CoRR}, abs/2107.12808, 2021.

\bibitem{sukhbaatar2018intrinsic}
S.~Sukhbaatar, Z.~Lin, I.~Kostrikov, G.~Synnaeve, A.~Szlam, and R.~Fergus.
\newblock Intrinsic motivation and automatic curricula via asymmetric
  self-play.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{Sutton1998}
R.~S. Sutton and A.~G. Barto.
\newblock {\em Introduction to Reinforcement Learning}.
\newblock MIT Press, Cambridge, MA, USA, 1st edition, 1998.

\bibitem{sutton2016emphatic}
R.~S. Sutton, A.~R. Mahmood, and M.~White.
\newblock An emphatic approach to the problem of off-policy temporal-difference
  learning.
\newblock {\em Journal of Machine Learning Research}, 17(73):1--29, 2016.

\bibitem{attentionagent}
Y.~Tang, D.~Nguyen, and D.~Ha.
\newblock Neuroevolution of self-interpretable agents.
\newblock In {\em Proceedings of the Genetic and Evolutionary Computation
  Conference}, 2020.

\bibitem{thomasa16}
P.~Thomas and E.~Brunskill.
\newblock Data-efficient off-policy policy evaluation for reinforcement
  learning.
\newblock In M.~F. Balcan and K.~Q. Weinberger, editors, {\em Proceedings of
  The 33rd International Conference on Machine Learning}, volume~48 of {\em
  Proceedings of Machine Learning Research}, pages 2139--2148, New York, New
  York, USA, 20--22 Jun 2016. PMLR.

\bibitem{tobin_dr}
J.~Tobin, R.~Fong, A.~Ray, J.~Schneider, W.~Zaremba, and P.~Abbeel.
\newblock Domain randomization for transferring deep neural networks from
  simulation to the real world.
\newblock In {\em 2017 {IEEE/RSJ} International Conference on Intelligent
  Robots and Systems, {IROS} 2017, Vancouver, BC, Canada, September 24-28,
  2017}, pages 23--30. {IEEE}, 2017.

\bibitem{vapnik1971uniform}
V.~N. Vapnik and A.~Y. Chervonenkis.
\newblock On the uniform convergence of relative frequencies of events to their
  probabilities.
\newblock {\em Theory of Probability and Its Applications}, pages 264--280,
  1971.

\bibitem{alphastar}
O.~Vinyals, I.~Babuschkin, W.~M. Czarnecki, M.~Mathieu, A.~Dudzik, J.~Chung,
  D.~H. Choi, R.~Powell, T.~Ewalds, P.~Georgiev, J.~Oh, D.~Horgan, M.~Kroiss,
  I.~Danihelka, A.~Huang, L.~Sifre, T.~Cai, J.~P. Agapiou, M.~Jaderberg, A.~S.
  Vezhnevets, R.~Leblond, T.~Pohlen, V.~Dalibard, D.~Budden, Y.~Sulsky,
  J.~Molloy, T.~L. Paine, {\c{C}}.~G{\"{u}}l{\c{c}}ehre, Z.~Wang, T.~Pfaff,
  Y.~Wu, R.~Ring, D.~Yogatama, D.~W{\"{u}}nsch, K.~McKinney, O.~Smith,
  T.~Schaul, T.~P. Lillicrap, K.~Kavukcuoglu, D.~Hassabis, C.~Apps, and
  D.~Silver.
\newblock Grandmaster level in starcraft {II} using multi-agent reinforcement
  learning.
\newblock {\em Nature}, 575(7782):350--354, 2019.

\bibitem{poet}
R.~Wang, J.~Lehman, J.~Clune, and K.~O. Stanley.
\newblock Paired open-ended trailblazer {(POET):} endlessly generating
  increasingly complex and diverse learning environments and their solutions.
\newblock {\em CoRR}, abs/1901.01753, 2019.

\bibitem{enhanced_poet}
R.~Wang, J.~Lehman, A.~Rawal, J.~Zhi, Y.~Li, J.~Clune, and K.~Stanley.
\newblock Enhanced {POET}: Open-ended reinforcement learning through unbounded
  invention of learning challenges and their solutions.
\newblock In {\em Proceedings of the 37th International Conference on Machine
  Learning}, pages 9940--9951, 2020.

\bibitem{wu2021whendocurriculawork}
X.~Wu, E.~Dyer, and B.~Neyshabur.
\newblock When do curricula work?
\newblock In {\em 9th International Conference on Learning Representations,
  {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021}. OpenReview.net, 2021.

\bibitem{zhang2019causalreps}
A.~Zhang, Z.~C. Lipton, L.~Pineda, K.~Azizzadenesheli, A.~Anandkumar, L.~Itti,
  J.~Pineau, and T.~Furlanello.
\newblock Learning causal state representations of partially observable
  environments.
\newblock {\em CoRR}, abs/1906.10437, 2019.

\bibitem{zhang2021invariant}
A.~Zhang, R.~T. McAllister, R.~Calandra, Y.~Gal, and S.~Levine.
\newblock Learning invariant representations for reinforcement learning without
  reconstruction.
\newblock In {\em 9th International Conference on Learning Representations,
  {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021}. OpenReview.net, 2021.

\bibitem{rtfm}
V.~Zhong, T.~Rockt{\"{a}}schel, and E.~Grefenstette.
\newblock {RTFM:} generalising to new environment dynamics via reading.
\newblock In {\em 8th International Conference on Learning Representations,
  {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}. OpenReview.net, 2020.

\bibitem{zintgraf2020varibad}
L.~M. Zintgraf, K.~Shiarlis, M.~Igl, S.~Schulze, Y.~Gal, K.~Hofmann, and
  S.~Whiteson.
\newblock Varibad: {A} very good method for bayes-adaptive deep {RL} via
  meta-learning.
\newblock In {\em 8th International Conference on Learning Representations,
  {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}. OpenReview.net, 2020.

\end{thebibliography}
