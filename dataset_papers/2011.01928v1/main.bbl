\begin{thebibliography}{58}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Allen et~al.(2019)Allen, Smith, and Tenenbaum]{allen2019tools}
Allen, K.~R., Smith, K.~A., and Tenenbaum, J.~B.
\newblock The tools challenge: Rapid trial-and-error learning in physical
  problem solving.
\newblock \emph{arXiv preprint arXiv:1907.09620}, 2019.

\bibitem[Andreas et~al.(2017)Andreas, Klein, and Levine]{andreas2017modular}
Andreas, J., Klein, D., and Levine, S.
\newblock Modular multitask reinforcement learning with policy sketches.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  166--175, 2017.

\bibitem[Bakhtin et~al.(2019)Bakhtin, van~der Maaten, Johnson, Gustafson, and
  Girshick]{bakhtin2019phyre}
Bakhtin, A., van~der Maaten, L., Johnson, J., Gustafson, L., and Girshick, R.
\newblock Phyre: A new benchmark for physical reasoning.
\newblock \emph{arXiv:1908.05656}, 2019.

\bibitem[Bengio et~al.(2013)Bengio, Courville, and
  Vincent]{bengio2013representation}
Bengio, Y., Courville, A., and Vincent, P.
\newblock Representation learning: A review and new perspectives.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 35\penalty0 (8):\penalty0 1798--1828, 2013.

\bibitem[Biewald(2020)]{wandb}
Biewald, L.
\newblock Experiment tracking with weights and biases, 2020.
\newblock URL \url{https://www.wandb.com/}.
\newblock Software available from wandb.com.

\bibitem[Blomqvist()]{pymunk}
Blomqvist, V.
\newblock Pymunk.
\newblock URL \url{http://www.pymunk.org/}.
\newblock Accessed 2020-02-18.

\bibitem[Bousquet et~al.(2003)Bousquet, Boucheron, and
  Lugosi]{bousquet2003introduction}
Bousquet, O., Boucheron, S., and Lugosi, G.
\newblock Introduction to statistical learning theory.
\newblock In \emph{Summer School on Machine Learning}, pp.\  169--207.
  Springer, 2003.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{brockman2016openai}
Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang,
  J., and Zaremba, W.
\newblock Openai gym.
\newblock \emph{arXiv preprint arXiv:1606.01540}, 2016.

\bibitem[Chandak et~al.(2019)Chandak, Theocharous, Kostas, Jordan, and
  Thomas]{chandak2019learning}
Chandak, Y., Theocharous, G., Kostas, J., Jordan, S., and Thomas, P.~S.
\newblock Learning action representations for reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1902.00183}, 2019.

\bibitem[Chandak et~al.(2020)Chandak, Theocharous, Nota, and
  Thomas]{Chandak_2020}
Chandak, Y., Theocharous, G., Nota, C., and Thomas, P.
\newblock Lifelong learning with a changing action set.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  34\penalty0 (04):\penalty0 3373â€“3380, Apr 2020.
\newblock ISSN 2159-5399.
\newblock \doi{10.1609/aaai.v34i04.5739}.
\newblock URL \url{http://dx.doi.org/10.1609/aaai.v34i04.5739}.

\bibitem[Chen et~al.(2019)Chen, Chen, Yang, Li, Yin, and Fan]{chen2019learning}
Chen, Y., Chen, Y., Yang, Y., Li, Y., Yin, J., and Fan, C.
\newblock Learning action-transferable policy with action embedding.
\newblock \emph{arXiv preprint arXiv:1909.02291}, 2019.

\bibitem[Chevalier-Boisvert et~al.(2018)Chevalier-Boisvert, Willems, and
  Pal]{gym_minigrid}
Chevalier-Boisvert, M., Willems, L., and Pal, S.
\newblock Minimalistic gridworld environment for openai gym.
\newblock \url{https://github.com/maximecb/gym-minigrid}, 2018.

\bibitem[Chou et~al.(2017)Chou, Maturana, and Scherer]{chou2017improving}
Chou, P.-W., Maturana, D., and Scherer, S.
\newblock Improving stochastic policy gradients in continuous control with deep
  reinforcement learning using the beta distribution.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  834--843, 2017.

\bibitem[Co-Reyes et~al.(2018)Co-Reyes, Liu, Gupta, Eysenbach, Abbeel, and
  Levine]{co2018self}
Co-Reyes, J., Liu, Y., Gupta, A., Eysenbach, B., Abbeel, P., and Levine, S.
\newblock Self-consistent trajectory autoencoder: Hierarchical reinforcement
  learning with trajectory embeddings.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1008--1017, 2018.

\bibitem[Cobbe et~al.(2018)Cobbe, Klimov, Hesse, Kim, and
  Schulman]{cobbe2018quantifying}
Cobbe, K., Klimov, O., Hesse, C., Kim, T., and Schulman, J.
\newblock Quantifying generalization in reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1812.02341}, 2018.

\bibitem[Denton \& Birodkar(2017)Denton and Birodkar]{denton2017unsupervised}
Denton, E.~L. and Birodkar, v.
\newblock Unsupervised learning of disentangled representations from video.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 30}, pp.\  4414--4423. Curran Associates,
  Inc., 2017.
\newblock URL
  \url{http://papers.nips.cc/paper/7028-unsupervised-learning-of-disentangled-representations-from-video.pdf}.

\bibitem[Dulac-Arnold et~al.(2015)Dulac-Arnold, Evans, van Hasselt, Sunehag,
  Lillicrap, Hunt, Mann, Weber, Degris, and Coppin]{dulac2015deep}
Dulac-Arnold, G., Evans, R., van Hasselt, H., Sunehag, P., Lillicrap, T., Hunt,
  J., Mann, T., Weber, T., Degris, T., and Coppin, B.
\newblock Deep reinforcement learning in large discrete action spaces.
\newblock \emph{arXiv preprint arXiv:1512.07679}, 2015.

\bibitem[Ebert et~al.(2017)Ebert, Finn, Lee, and Levine]{ebert2017self}
Ebert, F., Finn, C., Lee, A.~X., and Levine, S.
\newblock Self-supervised visual planning with temporal skip connections.
\newblock In \emph{Conference on Robot Learning}, pp.\  344--356, 2017.

\bibitem[Edwards \& Storkey(2017)Edwards and Storkey]{edwards2016towards}
Edwards, H. and Storkey, A.
\newblock Towards a neural statistician.
\newblock In \emph{International Conference on Learning Representations}, 2017.
\newblock URL \url{https://openreview.net/forum?id=HJDBUF5le}.

\bibitem[Fang et~al.(2018)Fang, Zhu, Garg, Kurenkov, Mehta, Fei-Fei, and
  Savarese]{fang2018learning}
Fang, K., Zhu, Y., Garg, A., Kurenkov, A., Mehta, V., Fei-Fei, L., and
  Savarese, S.
\newblock Learning task-oriented grasping for tool manipulation from simulated
  self-supervision.
\newblock \emph{arXiv preprint arXiv:1806.09266}, 2018.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Finn, C., Abbeel, P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1126--1135, 2017.

\bibitem[Gershman \& Niv(2015)Gershman and Niv]{gershman2015novelty}
Gershman, S.~J. and Niv, Y.
\newblock Novelty and inductive generalization in human reinforcement learning.
\newblock \emph{Topics in cognitive science}, 7\penalty0 (3):\penalty0
  391--415, 2015.

\bibitem[Hausknecht \& Stone(2015)Hausknecht and Stone]{hausknecht2015deep}
Hausknecht, M. and Stone, P.
\newblock Deep reinforcement learning in parameterized action space.
\newblock \emph{arXiv preprint arXiv:1511.04143}, 2015.

\bibitem[Hawkins(2004)]{hawkins2004problem}
Hawkins, D.~M.
\newblock The problem of overfitting.
\newblock \emph{Journal of chemical information and computer sciences},
  44\penalty0 (1):\penalty0 1--12, 2004.

\bibitem[He et~al.(2015)He, Chen, He, Gao, Li, Deng, and Ostendorf]{he2015deep}
He, J., Chen, J., He, X., Gao, J., Li, L., Deng, L., and Ostendorf, M.
\newblock Deep reinforcement learning with a natural language action space.
\newblock \emph{arXiv preprint arXiv:1511.04636}, 2015.

\bibitem[Higgins et~al.(2017{\natexlab{a}})Higgins, Matthey, Pal, Burgess,
  Glorot, Botvinick, Mohamed, and Lerchner]{higgins2017beta}
Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M.,
  Mohamed, S., and Lerchner, A.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock \emph{ICLR}, 2\penalty0 (5):\penalty0 6, 2017{\natexlab{a}}.

\bibitem[Higgins et~al.(2017{\natexlab{b}})Higgins, Pal, Rusu, Matthey,
  Burgess, Pritzel, Botvinick, Blundell, and Lerchner]{higgins2017darla}
Higgins, I., Pal, A., Rusu, A., Matthey, L., Burgess, C., Pritzel, A.,
  Botvinick, M., Blundell, C., and Lerchner, A.
\newblock Darla: Improving zero-shot transfer in reinforcement learning.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  1480--1490. JMLR. org, 2017{\natexlab{b}}.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{ioffe2015batch}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{arXiv preprint arXiv:1502.03167}, 2015.

\bibitem[Kim et~al.(2019)Kim, Kim, Jeong, Levine, and Song]{pmlr-v97-kim19a}
Kim, H., Kim, J., Jeong, Y., Levine, S., and Song, H.~O.
\newblock {EMI}: Exploration with mutual information.
\newblock In Chaudhuri, K. and Salakhutdinov, R. (eds.), \emph{Proceedings of
  the 36th International Conference on Machine Learning}, volume~97 of
  \emph{Proceedings of Machine Learning Research}, pp.\  3360--3369, Long
  Beach, California, USA, 09--15 Jun 2019. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v97/kim19a.html}.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Kostrikov(2018)]{pytorchrl}
Kostrikov, I.
\newblock Pytorch implementations of reinforcement learning algorithms.
\newblock \url{https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail}, 2018.

\bibitem[Laversanne-Finot et~al.(2018)Laversanne-Finot, Pere, and
  Oudeyer]{pmlr-v87-laversanne-finot18a}
Laversanne-Finot, A., Pere, A., and Oudeyer, P.-Y.
\newblock Curiosity driven exploration of learned disentangled goal spaces.
\newblock In Billard, A., Dragan, A., Peters, J., and Morimoto, J. (eds.),
  \emph{Proceedings of The 2nd Conference on Robot Learning}, volume~87 of
  \emph{Proceedings of Machine Learning Research}, pp.\  487--504. PMLR, 29--31
  Oct 2018.
\newblock URL \url{http://proceedings.mlr.press/v87/laversanne-finot18a.html}.

\bibitem[Legg \& Hutter(2007)Legg and Hutter]{legg2007universal}
Legg, S. and Hutter, M.
\newblock Universal intelligence: A definition of machine intelligence.
\newblock \emph{Minds and machines}, 17\penalty0 (4):\penalty0 391--444, 2007.

\bibitem[Liu et~al.(2019)Liu, Jiang, He, Chen, Liu, Gao, and Han]{liu2019radam}
Liu, L., Jiang, H., He, P., Chen, W., Liu, X., Gao, J., and Han, J.
\newblock On the variance of the adaptive learning rate and beyond.
\newblock \emph{arXiv preprint arXiv:1908.03265}, 2019.

\bibitem[Nair et~al.(2018)Nair, Pong, Dalal, Bahl, Lin, and
  Levine]{nair2018visual}
Nair, A.~V., Pong, V., Dalal, M., Bahl, S., Lin, S., and Levine, S.
\newblock Visual reinforcement learning with imagined goals.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  9191--9200, 2018.

\bibitem[Nichol et~al.(2018)Nichol, Pfau, Hesse, Klimov, and
  Schulman]{nichol2018gotta}
Nichol, A., Pfau, V., Hesse, C., Klimov, O., and Schulman, J.
\newblock Gotta learn fast: A new benchmark for generalization in rl.
\newblock \emph{arXiv preprint arXiv:1804.03720}, 2018.

\bibitem[Oh et~al.(2017)Oh, Singh, Lee, and Kohli]{oh2017zero}
Oh, J., Singh, S., Lee, H., and Kohli, P.
\newblock Zero-shot task generalization with multi-task deep reinforcement
  learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2661--2670, 2017.

\bibitem[Packer et~al.(2018)Packer, Gao, Kos, Kr{\"a}henb{\"u}hl, Koltun, and
  Song]{packer2018assessing}
Packer, C., Gao, K., Kos, J., Kr{\"a}henb{\"u}hl, P., Koltun, V., and Song, D.
\newblock Assessing generalization in deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1810.12282}, 2018.

\bibitem[Parisi et~al.(2018)Parisi, Kemker, Part, Kanan, and
  Wermter]{parisi2018continual}
Parisi, G.~I., Kemker, R., Part, J.~L., Kanan, C., and Wermter, S.
\newblock Continual lifelong learning with neural networks: A review.
\newblock \emph{arXiv preprint arXiv:1802.07569}, 2018.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017automatic}
Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z.,
  Desmaison, A., Antiga, L., and Lerer, A.
\newblock Automatic differentiation in {PyTorch}.
\newblock In \emph{NIPS Autodiff Workshop}, 2017.

\bibitem[Pathak et~al.(2019)Pathak, Lu, Darrell, Isola, and
  Efros]{pathak19assemblies}
Pathak, D., Lu, C., Darrell, T., Isola, P., and Efros, A.~A.
\newblock Learning to control self-assembling morphologies: A study of
  generalization via modularity.
\newblock In \emph{arXiv preprint arXiv:1902.05546}, 2019.

\bibitem[Rohde et~al.(2018)Rohde, Bonner, Dunlop, Vasile, and
  Karatzoglou]{rohde2018recogym}
Rohde, D., Bonner, S., Dunlop, T., Vasile, F., and Karatzoglou, A.
\newblock Recogym: A reinforcement learning environment for the problem of
  product recommendation in online advertising.
\newblock \emph{arXiv preprint arXiv:1808.00720}, 2018.

\bibitem[Sanchez-Gonzalez et~al.(2018)Sanchez-Gonzalez, Heess, Springenberg,
  Merel, Riedmiller, Hadsell, and Battaglia]{sanchez-gonzalez2018graph}
Sanchez-Gonzalez, A., Heess, N., Springenberg, J.~T., Merel, J., Riedmiller,
  M., Hadsell, R., and Battaglia, P.
\newblock Graph networks as learnable physics engines for inference and
  control.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{PPO}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Schuster \& Paliwal(1997)Schuster and
  Paliwal]{schuster1997bidirectional}
Schuster, M. and Paliwal, K.~K.
\newblock Bidirectional recurrent neural networks.
\newblock \emph{IEEE Transactions on Signal Processing}, 45\penalty0
  (11):\penalty0 2673--2681, 1997.

\bibitem[Shinners()]{pygame}
Shinners, P.
\newblock Pygame.
\newblock URL \url{http://pygame.org/}.
\newblock Accessed 2020-02-18.

\bibitem[Steenbrugge et~al.(2018)Steenbrugge, Leroux, Verbelen, and
  Dhoedt]{steenbrugge2018improving}
Steenbrugge, X., Leroux, S., Verbelen, T., and Dhoedt, B.
\newblock Improving generalization for abstract reasoning tasks using
  disentangled feature representations.
\newblock \emph{arXiv preprint arXiv:1811.04784}, 2018.

\bibitem[Sutton et~al.(2000)Sutton, McAllester, Singh, and
  Mansour]{sutton2000policy}
Sutton, R.~S., McAllester, D.~A., Singh, S.~P., and Mansour, Y.
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1057--1063, 2000.

\bibitem[Tennenholtz \& Mannor(2019)Tennenholtz and
  Mannor]{tennenholtz2019natural}
Tennenholtz, G. and Mannor, S.
\newblock The natural language of actions.
\newblock \emph{arXiv preprint arXiv:1902.01119}, 2019.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{todorov2012mujoco}
Todorov, E., Erez, T., and Tassa, Y.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{2012 IEEE/RSJ International Conference on Intelligent Robots
  and Systems}, pp.\  5026--5033. IEEE, 2012.

\bibitem[Vapnik(1998)]{vapnik1998statistical}
Vapnik, V.
\newblock Statistical learning theory, 1998.

\bibitem[Vapnik(2013)]{vapnik2013nature}
Vapnik, V.
\newblock \emph{The nature of statistical learning theory}.
\newblock Springer science \& business media, 2013.

\bibitem[Wang et~al.(2018)Wang, Liao, Ba, and Fidler]{wang2018nervenet}
Wang, T., Liao, R., Ba, J., and Fidler, S.
\newblock Nervenet: Learning structured policy with graph neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=S1sqHMZCb}.

\bibitem[Wang et~al.(2017)Wang, Merel, Reed, de~Freitas, Wayne, and
  Heess]{NIPS2017_7116}
Wang, Z., Merel, J.~S., Reed, S.~E., de~Freitas, N., Wayne, G., and Heess, N.
\newblock Robust imitation of diverse behaviors.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 30}, pp.\  5320--5329. Curran Associates,
  Inc., 2017.
\newblock URL
  \url{http://papers.nips.cc/paper/7116-robust-imitation-of-diverse-behaviors.pdf}.

\bibitem[Watkins \& Dayan(1992)Watkins and Dayan]{watkins1992q}
Watkins, C.~J. and Dayan, P.
\newblock Q-learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 279--292, 1992.

\bibitem[Xie et~al.(2019)Xie, Ebert, Levine, and Finn]{xie2019improvisation}
Xie, A., Ebert, F., Levine, S., and Finn, C.
\newblock Improvisation through physical understanding: Using novel objects as
  tools with visual foresight, 2019.

\bibitem[Xu et~al.(2017)Xu, Nair, Zhu, Gao, Garg, Fei-Fei, and
  Savarese]{xu2017neural}
Xu, D., Nair, S., Zhu, Y., Gao, J., Garg, A., Fei-Fei, L., and Savarese, S.
\newblock Neural task programming: Learning to generalize across hierarchical
  tasks.
\newblock In \emph{International Conference on Robotics and Automation}, 2017.

\bibitem[Ziebart et~al.(2008)Ziebart, Maas, Bagnell, and
  Dey]{ziebart2008maximum}
Ziebart, B.~D., Maas, A., Bagnell, J.~A., and Dey, A.~K.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In \emph{Proceedings of the 23rd national conference on Artificial
  intelligence-Volume 3}, pp.\  1433--1438. AAAI Press, 2008.

\end{thebibliography}
