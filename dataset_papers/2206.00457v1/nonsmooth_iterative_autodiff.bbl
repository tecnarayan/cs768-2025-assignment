\begin{thebibliography}{10}

\bibitem{tensorflow2015-whitepaper}
Mart\'{i}n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,
  Craig Citro, Greg~S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin,
  Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard,
  Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh
  Levenberg, Dandelion Man\'{e}, Rajat Monga, Sherry Moore, Derek Murray, Chris
  Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal
  Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi\'{e}gas,
  Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and
  Xiaoqiang Zheng.
\newblock {TensorFlow}: Large-scale machine learning on heterogeneous systems,
  2015.
\newblock Software available from tensorflow.org.

\bibitem{ablin2020super}
Pierre Ablin, Gabriel Peyr{\'e}, and Thomas Moreau.
\newblock Super-efficiency of automatic differentiation for functions defined
  as a minimum.
\newblock In Hal~Daumé III and Aarti Singh, editors, {\em Proceedings of the
  37th International Conference on Machine Learning}, volume 119 of {\em
  Proceedings of Machine Learning Research}, pages 32--41. PMLR, 13--18 Jul
  2020.

\bibitem{agrawal2019differentiable}
Akshay Agrawal, Brandon Amos, Shane Barratt, Stephen Boyd, Steven Diamond, and
  J.~Zico Kolter.
\newblock Differentiable convex optimization layers.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, {\em Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.

\bibitem{aliprantis2006infinite}
Charalambos~D Aliprantis and Kim~C Border.
\newblock {\em Infinite Dimensional Analysis: A Hitchhiker's Guide}.
\newblock Springer Science \& Business Media, 2006.

\bibitem{bai2019deep}
Shaojie Bai, J~Zico Kolter, and Vladlen Koltun.
\newblock Deep equilibrium models.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{bauschke2011convex}
Heinz~H Bauschke, Patrick~L Combettes, et~al.
\newblock {\em Convex analysis and monotone operator theory in Hilbert spaces},
  volume 408.
\newblock Springer, 2011.

\bibitem{bertrand2020implicit}
Quentin Bertrand, Quentin Klopfenstein, Mathieu Blondel, Samuel Vaiter,
  Alexandre Gramfort, and Joseph Salmon.
\newblock Implicit differentiation of lasso-type models for hyperparameter
  optimization.
\newblock In {\em International Conference on Machine Learning}, pages
  810--821. PMLR, 2020.

\bibitem{blondel2022efficient}
Mathieu Blondel, Quentin Berthet, Marco Cuturi, Roy Frostig, Stephan Hoyer,
  Felipe Llinares-López, Fabian Pedregosa, and Jean-Philippe Vert.
\newblock Efficient and modular implicit differentiation, 2021.

\bibitem{bogensperger2022convergence}
Lea Bogensperger, Antonin Chambolle, and Thomas Pock.
\newblock {Convergence of a Piggyback-style method for the differentiation of
  solutions of standard saddle-point problems}.
\newblock Technical report, 2022.

\bibitem{bolte2021nonsmooth}
J{\'e}r{\^o}me Bolte, Tam Le, Edouard Pauwels, and Antonio Silveti-Falls.
\newblock {Nonsmooth Implicit Differentiation for Machine Learning and
  Optimization}.
\newblock In {\em {Advances in Neural Information Processing Systems}}, Online,
  2021.

\bibitem{bolte2020mathematical}
Jerome Bolte and Edouard Pauwels.
\newblock {A mathematical model for automatic differentiation in machine
  learning}.
\newblock In {\em {Conference on Neural Information Processing Systems}},
  Vancouver, Canada, 2020.

\bibitem{bolte2020conservative}
J{\'e}r{\^o}me Bolte and Edouard Pauwels.
\newblock {Conservative set valued fields, automatic differentiation,
  stochastic gradient method and deep learning}.
\newblock {\em {Mathematical Programming}}, 2020.

\bibitem{jax2018github}
James Bradbury, Roy Frostig, Peter Hawkins, Matthew~James Johnson, Chris Leary,
  Dougal Maclaurin, George Necula, Adam Paszke, Jake Vander{P}las, Skye
  Wanderman-{M}ilne, and Qiao Zhang.
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs,
  2018.

\bibitem{chambolle2021learning}
Antonin Chambolle and Thomas Pock.
\newblock Learning consistent discretizations of the total variation.
\newblock {\em SIAM Journal on Imaging Sciences}, 14(2):778--813, 2021.

\bibitem{christianson1994reverse}
Bruce Christianson.
\newblock Reverse accumulation and attractive fixed points.
\newblock {\em Optimization Methods and Software}, 3(4):311--326, 1994.

\bibitem{clarke1983optimization}
Frank~H. Clarke.
\newblock {\em Optimization and nonsmooth analysis}.
\newblock Canadian Mathematical Society Series of Monographs and Advanced
  Texts. John Wiley \& Sons, Inc., New York, 1983.
\newblock A Wiley-Interscience Publication.

\bibitem{coste2000introduction}
Michel Coste.
\newblock {\em An introduction to o-minimal geometry}.
\newblock Istituti editoriali e poligrafici internazionali Pisa, 2000.

\bibitem{coste2000introduction2}
Michel Coste.
\newblock An introduction to semialgebraic geometry, 2000.

\bibitem{efron2004least}
Bradley Efron, Trevor Hastie, Iain Johnstone, Robert Tibshirani, et~al.
\newblock Least angle regression.
\newblock {\em Annals of statistics}, 32(2):407--499, 2004.

\bibitem{elghaoui2021implicit}
Laurent El~Ghaoui, Fangda Gu, Bertrand Travacca, Armin Askari, and Alicia Tsai.
\newblock Implicit deep learning.
\newblock {\em SIAM Journal on Mathematics of Data Science}, 3(3):930--958,
  2021.

\bibitem{friedman2007sparse}
Jerome Friedman, Trevor Hastie, and Robert Tibshirani.
\newblock {Sparse inverse covariance estimation with the graphical lasso}.
\newblock {\em Biostatistics}, 9(3):432--441, 12 2007.

\bibitem{gabay1983chapter}
Daniel Gabay.
\newblock Applications of the method of multipliers to variational
  inequalities.
\newblock In {\em Studies in mathematics and its applications}, volume~15,
  pages 299--331. Elsevier, 1983.

\bibitem{ghadimi2015global}
Euhanna Ghadimi, Hamid~Reza Feyzmahdavian, and Mikael Johansson.
\newblock Global convergence of the heavy-ball method for convex optimization.
\newblock In {\em 2015 European control conference (ECC)}, pages 310--315.
  IEEE, 2015.

\bibitem{gilbert1992automatic}
Jean~Charles Gilbert.
\newblock Automatic differentiation and iterative processes.
\newblock {\em Optimization Methods and Software}, 1(1):13--21, 1992.

\bibitem{giselsson2016linear}
Pontus Giselsson and Stephen Boyd.
\newblock Linear convergence and metric selection for douglas-rachford
  splitting and admm.
\newblock {\em IEEE Transactions on Automatic Control}, 62(2):532--544, 2016.

\bibitem{griewank1993derivative}
Andreas Griewank, Christian Bischof, George Corliss, Alan Carle, and Karen
  Williamson.
\newblock Derivative convergence for iterative equation solvers.
\newblock {\em Optimization Methods and Software}, 2(3-4):321--355, 1993.

\bibitem{griewank2003piggyback}
Andreas Griewank and Christ{\`e}le Faure.
\newblock Piggyback differentiation and optimization.
\newblock In {\em Large-scale PDE-constrained optimization}, pages 148--164.
  Springer, 2003.

\bibitem{griewank2008evaluating}
Andreas Griewank and Andrea Walther.
\newblock {\em Evaluating derivatives: principles and techniques of algorithmic
  differentiation}.
\newblock SIAM, 2008.

\bibitem{harris2020array}
Charles~R. Harris, K.~Jarrod Millman, St{\'{e}}fan~J. van~der Walt, Ralf
  Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, Julian Taylor,
  Sebastian Berg, Nathaniel~J. Smith, Robert Kern, Matti Picus, Stephan Hoyer,
  Marten~H. van Kerkwijk, Matthew Brett, Allan Haldane, Jaime~Fern{\'{a}}ndez
  del R{\'{i}}o, Mark Wiebe, Pearu Peterson, Pierre G{\'{e}}rard-Marchant,
  Kevin Sheppard, Tyler Reddy, Warren Weckesser, Hameer Abbasi, Christoph
  Gohlke, and Travis~E. Oliphant.
\newblock Array programming with {NumPy}.
\newblock {\em Nature}, 585(7825):357--362, September 2020.

\bibitem{hunter2007matplotlib}
J.~D. Hunter.
\newblock Matplotlib: A 2d graphics environment.
\newblock {\em Computing in Science \& Engineering}, 9(3):90--95, 2007.

\bibitem{kakade2018provably}
Sham~M Kakade and Jason~D Lee.
\newblock Provably correct automatic sub-differentiation for qualified
  programs.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~31. Curran Associates, Inc., 2018.

\bibitem{lee2020oncorrectness}
Wonyeol Lee, Hangyeol Yu, Xavier Rival, and Hongseok Yang.
\newblock On correctness of automatic differentiation for non-differentiable
  functions.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin,
  editors, {\em Advances in Neural Information Processing Systems}, volume~33,
  pages 6719--6730. Curran Associates, Inc., 2020.

\bibitem{linnainmaa1970representationcumulative}
Seppo Linnainmaa.
\newblock {The representation of the cumulative rounding error of an algorithm
  as a Taylor expansion of the local rounding errors}.
\newblock Master's thesis, Univ. Helsinki, 1970.

\bibitem{lorraine2020optimizing}
Jonathan Lorraine, Paul Vicol, and David Duvenaud.
\newblock Optimizing millions of hyperparameters by implicit differentiation.
\newblock In Silvia Chiappa and Roberto Calandra, editors, {\em Proceedings of
  the Twenty Third International Conference on Artificial Intelligence and
  Statistics}, volume 108 of {\em Proceedings of Machine Learning Research},
  pages 1540--1552. PMLR, 26--28 Aug 2020.

\bibitem{mairal2012complexity}
Julien Mairal and Bin Yu.
\newblock Complexity analysis of the lasso regularization path.
\newblock In {\em Proceedings of the 29th International Coference on
  International Conference on Machine Learning}, pages 1835--1842, 2012.

\bibitem{marx2022path}
Swann Marx and Edouard Pauwels.
\newblock Path differentiability of ode flows.
\newblock {\em arXiv preprint arXiv:2201.03819}, 2022.

\bibitem{mehmood2020automatic}
Sheheryar Mehmood and Peter Ochs.
\newblock Automatic differentiation of some first-order methods in parametric
  optimization.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1584--1594. PMLR, 2020.

\bibitem{nesterov1994interior}
Yurii Nesterov and Arkadii Nemirovskii.
\newblock {\em Interior-point polynomial algorithms in convex programming}.
\newblock SIAM, 1994.

\bibitem{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, {\em Advances in Neural
  Information Processing Systems 32}, pages 8024--8035. Curran Associates,
  Inc., 2019.

\bibitem{pedregosa2016hyperparameter}
Fabian Pedregosa.
\newblock Hyperparameter optimization with approximate gradient.
\newblock In {\em International conference on machine learning}, pages
  737--746. PMLR, 2016.

\bibitem{polyak1987introduction}
Boris Polyak.
\newblock Introduction to optimization.
\newblock In {\em Optimization Software, Publications Division}. Citeseer,
  1987.

\bibitem{rajeswaran2019meta}
Aravind Rajeswaran, Chelsea Finn, Sham~M Kakade, and Sergey Levine.
\newblock Meta-learning with implicit gradients.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{rockafellar2009variational}
R~Tyrrell Rockafellar and Roger J-B Wets.
\newblock {\em Variational analysis}, volume 317.
\newblock Springer Science \& Business Media, 2009.

\bibitem{royden1988real}
Halsey~Lawrence Royden and Patrick Fitzpatrick.
\newblock {\em Real analysis}, volume~32.
\newblock Macmillan New York, 1988.

\bibitem{rumelhart1986learningrepresentations}
David~E. Rumelhart, Geoffrey~E. Hinton, and Ronald~J. Williams.
\newblock Learning representations by back-propagating errors.
\newblock {\em Nature}, 323(6088):533--536, October 1986.

\bibitem{tibshirani1996regression}
Robert Tibshirani.
\newblock Regression shrinkage and selection via the lasso.
\newblock {\em Journal of the Royal Statistical Society: Series B
  (Methodological)}, 58(1):267--288, 1996.

\bibitem{tibshirani2013lasso}
Ryan~J Tibshirani.
\newblock The lasso problem and uniqueness.
\newblock {\em Electronic Journal of statistics}, 7:1456--1490, 2013.

\bibitem{tibshirani2014trend}
Ryan~J. Tibshirani.
\newblock {Adaptive piecewise polynomial estimation via trend filtering}.
\newblock {\em The Annals of Statistics}, 42(1):285 -- 323, 2014.

\bibitem{wainwright2006high}
Martin~J Wainwright, John Lafferty, and Pradeep Ravikumar.
\newblock High-dimensional graphical model selection using \textbackslash
  ell\_1-regularized logistic regression.
\newblock In B.~Sch\"{o}lkopf, J.~Platt, and T.~Hoffman, editors, {\em Advances
  in Neural Information Processing Systems}, volume~19. MIT Press, 2006.

\bibitem{wengert1964simpleautomatic}
R.~E. Wengert.
\newblock A simple automatic derivative evaluation program.
\newblock {\em Communications of the ACM}, 7(8):463--464, August 1964.

\end{thebibliography}
