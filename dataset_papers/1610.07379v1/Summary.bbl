% Generated by IEEEtran.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Sha16}
B.~Shahriari, K.~Swersky, Z.~Wang, R.~P. Adams, and N.~de~Freitas, ``Taking the
  human out of the loop: A review of {B}ayesian optimization,'' \emph{Proc.
  IEEE}, vol. 104, no.~1, pp. 148--175, 2016.

\bibitem{Got13}
A.~Gotovos, N.~Casati, G.~Hitz, and A.~Krause, ``Active learning for level set
  estimation,'' in \emph{Int. Joint. Conf. Art. Intel.}, 2013.

\bibitem{Sri12}
N.~Srinivas, A.~Krause, S.~Kakade, and M.~Seeger, ``Information-theoretic
  regret bounds for {G}aussian process optimization in the bandit setting,''
  \emph{IEEE Trans. Inf. Theory}, vol.~58, no.~5, pp. 3250--3265, May 2012.

\bibitem{Con13}
E.~Contal, D.~Buffoni, A.~Robicquet, and N.~Vayatis, \emph{Machine Learning and
  Knowledge Discovery in Databases}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer Berlin Heidelberg, 2013, ch. Parallel {G}aussian Process
  Optimization with Upper Confidence Bound and Pure Exploration, pp. 225--240.

\bibitem{Wan14}
Z.~Wang, B.~Shakibi, L.~Jin, and N.~de~Freitas, ``Bayesian multi-scale
  optimistic optimization,'' http://arxiv.org/abs/1402.7005.

\bibitem{Swe13}
K.~Swersky, J.~Snoek, and R.~P. Adams, ``Multi-task {B}ayesian optimization,''
  in \emph{Adv. Neur. Inf. Proc. Sys. (NIPS)}, 2013, pp. 2004--2012.

\bibitem{Bry08}
B.~Bryan and J.~G. Schneider, ``Actively learning level-sets of composite
  functions,'' in \emph{Int. Conf. Mach. Learn. (ICML)}, 2008.

\bibitem{Hen12}
P.~Hennig and C.~J. Schuler, ``Entropy search for information-efficient global
  optimization,'' \emph{J. Mach. Learn. Research}, vol.~13, no.~1, pp.
  1809--1837, 2012.

\bibitem{Her14}
J.~M. Hern{\'a}ndez-Lobato, M.~W. Hoffman, and Z.~Ghahramani, ``Predictive
  entropy search for efficient global optimization of black-box functions,'' in
  \emph{Adv. Neur. Inf. Proc. Sys. (NIPS)}, 2014, pp. 918--926.

\bibitem{Gol97}
P.~W. Goldberg, C.~K. Williams, and C.~M. Bishop, ``Regression with
  input-dependent noise: A {G}aussian process treatment,'' \emph{Adv. Neur.
  Inf. Proc. Sys. (NIPS)}, vol.~10, pp. 493--499, 1997.

\bibitem{Met16}
J.~H. Metzen, ``Minimum regret search for single-and multi-task optimization,''
  in \emph{Int. Conf. Mach. Learn. (ICML)}, 2016.

\bibitem{Bub12}
S.~Bubeck and N.~Cesa-Bianchi, \emph{Regret Analysis of Stochastic and
  Nonstochastic Multi-Armed Bandit Problems}, ser. Found. Trend. Mach.
  Learn.\hskip 1em plus 0.5em minus 0.4em\relax Now Publishers, 2012.

\bibitem{Jam14}
K.~Jamieson and R.~Nowak, ``Best-arm identification algorithms for multi-armed
  bandits in the fixed confidence setting,'' in \emph{Ann. Conf. Inf. Sci. Sys.
  (CISS)}, 2014, pp. 1--6.

\bibitem{Mad14}
O.~Madani, D.~J. Lizotte, and R.~Greiner, ``The budgeted multi-armed bandit
  problem,'' in \emph{Learning Theory}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 2004, pp. 643--645.

\bibitem{Kle08}
R.~Kleinberg, A.~Slivkins, and E.~Upfal, ``Multi-armed bandits in metric
  spaces,'' in \emph{Proc. ACM Symp. Theory Comp.}, 2008.

\bibitem{Ras06}
C.~E. Rasmussen, ``Gaussian processes for machine learning.''\hskip 1em plus
  0.5em minus 0.4em\relax MIT Press, 2006.

\bibitem{Kra12}
A.~Krause and D.~Golovin, ``Submodular function maximization,''
  \emph{Tractability: Practical Approaches to Hard Problems}, vol.~3, 2012.

\bibitem{Das08}
A.~Das and D.~Kempe, ``Algorithms for subset selection in linear regression,''
  in \emph{Proc. ACM Symp. Theory Comp. (STOC)}.\hskip 1em plus 0.5em minus
  0.4em\relax ACM, 2008, pp. 45--54.

\bibitem{Htz2012}
G.~Hitz, F.~Pomerleau, M.-E. Garneau, E.~Pradalier, T.~Posch, J.~Pernthaler,
  and R.~Y. Siegwart, ``Autonomous inland water monitoring: Design and
  application of a surface vessel,'' \emph{IEEE Robot. Autom. Magazine},
  vol.~19, no.~1, pp. 62--72, 2012.

\bibitem{ES_Code}
\url{http://github.com/jmetzen/bayesian_optimization} (accessed 19/05/2016).

\bibitem{Sno12}
J.~Snoek, H.~Larochelle, and R.~P. Adams, ``Practical {B}ayesian optimization
  of machine learning algorithms,'' in \emph{Adv. Neur. Inf. Proc. Sys.}, 2012.

\bibitem{Swe14}
K.~Swersky, J.~Snoek, and R.~P. Adams, ``Freeze-thaw {B}ayesian optimization,''
  2014, http://arxiv.org/abs/1406.3896.

\bibitem{Jon93}
D.~R. Jones, C.~D. Perttunen, and B.~E. Stuckman, ``Lipschitzian optimization
  without the {L}ipschitz constant,'' \emph{J. Opt. Theory Apps.}, vol.~79,
  no.~1, pp. 157--181, 1993.

\bibitem{Kra05}
A.~Krause and C.~Guestrin, ``A note on the budgeted maximization of submodular
  functions,'' 2005, {T}echnical {R}eport.

\end{thebibliography}
