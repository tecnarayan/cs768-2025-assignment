\begin{thebibliography}{10}

\bibitem{anderson2020strong}
Ross Anderson, Joey Huchette, Christian Tjandraatmadja, and Juan~Pablo Vielma.
\newblock Strong convex relaxations and mixed-integer programming formulations
  for trained neural networks.
\newblock In {\em Mathematical Programming}, 2020.

\bibitem{bak2021nfm}
Stanley Bak.
\newblock nnenum: Verification of relu neural networks with optimized
  abstraction refinement.
\newblock In {\em NASA Formal Methods Symposium}, pages 19--36. Springer, 2021.

\bibitem{bak2021second}
Stanley Bak, Changliu Liu, and Taylor Johnson.
\newblock The second international verification of neural networks competition
  (vnn-comp 2021): Summary and results.
\newblock {\em arXiv preprint arXiv:2109.00498}, 2021.

\bibitem{bak2020cav}
Stanley Bak, Hoang-Dung Tran, Kerianne Hobbs, and Taylor~T. Johnson.
\newblock Improved geometric path enumeration for verifying relu neural
  networks.
\newblock In {\em Proceedings of the 32nd International Conference on Computer
  Aided Verification}. Springer, 2020.

\bibitem{Bertsimas2005Optimization}
Dimitris Bertsimas and Robert Weismantel.
\newblock {\em Optimization over integers.}
\newblock Athena Scientific, 2005.

\bibitem{bixby2007progress}
Robert Bixby and Edward Rothberg.
\newblock Progress in computational mixed integer programming—a look back
  from the other side of the tipping point.
\newblock {\em Annals of Operations Research}, 149(1):37--41, 2007.

\bibitem{botoeva2020efficient}
Elena Botoeva, Panagiotis Kouvaros, Jan Kronqvist, Alessio Lomuscio, and Ruth
  Misener.
\newblock Efficient verification of relu-based neural networks via dependency
  analysis.
\newblock In {\em AAAI Conference on Artificial Intelligence (AAAI)}, 2020.

\bibitem{Bunel2020}
Rudy Bunel, Alessandro De~Palma, Alban Desmaison, Krishnamurthy Dvijotham,
  Pushmeet Kohli, Philip H.~S. Torr, and M.~Pawan Kumar.
\newblock Lagrangian decomposition for neural network verification.
\newblock {\em Conference on Uncertainty in Artificial Intelligence (UAI)},
  2020.

\bibitem{bunel2020branch}
Rudy Bunel, Jingyue Lu, Ilker Turkaslan, P~Kohli, P~Torr, and P~Mudigonda.
\newblock Branch and bound for piecewise linear neural network verification.
\newblock {\em Journal of Machine Learning Research (JMLR)}, 2020.

\bibitem{bunel2018unified}
Rudy~R Bunel, Ilker Turkaslan, Philip Torr, Pushmeet Kohli, and Pawan~K
  Mudigonda.
\newblock A unified view of piecewise linear neural network verification.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2018.

\bibitem{chen2021deepsplit}
Shaoru Chen, Eric Wong, J~Zico Kolter, and Mahyar Fazlyab.
\newblock Deepsplit: Scalable verification of deep neural networks via operator
  splitting.
\newblock {\em arXiv preprint arXiv:2106.09117}, 2021.

\bibitem{chvatal1973edmonds}
Vasek Chv{\'a}tal.
\newblock Edmonds polytopes and a hierarchy of combinatorial problems.
\newblock {\em Discrete mathematics}, 4(4):305--337, 1973.

\bibitem{Conforti2014integer}
Michele Conforti, Gérard Cornuéjols, and Giacomo Zambelli.
\newblock {\em Integer programming / Michele Conforti, Gérard Cornuéjols,
  Giacomo Zambelli.}
\newblock Graduate texts in mathematics, . 271. Springer, Cham, 2014.

\bibitem{crowder1983solving}
Harlan Crowder, Ellis~L Johnson, and Manfred Padberg.
\newblock Solving large-scale zero-one linear programming problems.
\newblock {\em Operations Research}, 31(5):803--834, 1983.

\bibitem{dathathri2020enabling}
Sumanth Dathathri, Krishnamurthy Dvijotham, Alexey Kurakin, Aditi Raghunathan,
  Jonathan Uesato, Rudy~R Bunel, Shreya Shankar, Jacob Steinhardt, Ian
  Goodfellow, Percy~S Liang, et~al.
\newblock Enabling certification of verification-agnostic networks via
  memory-efficient semidefinite programming.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2020.

\bibitem{DePalma2021}
Alessandro De~Palma, Harkirat~Singh Behl, Rudy Bunel, Philip H.~S. Torr, and
  M.~Pawan Kumar.
\newblock Scaling the convex barrier with active sets.
\newblock {\em International Conference on Learning Representations (ICLR)},
  2021.

\bibitem{de2021improved}
Alessandro De~Palma, Rudy Bunel, Alban Desmaison, Krishnamurthy Dvijotham,
  Pushmeet Kohli, Philip~HS Torr, and M~Pawan Kumar.
\newblock Improved branch and bound for neural network verification via
  lagrangian decomposition.
\newblock {\em arXiv preprint arXiv:2104.06718}, 2021.

\bibitem{dvijotham2018dual}
Krishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy Mann, and
  Pushmeet Kohli.
\newblock A dual approach to scalable verification of deep networks.
\newblock {\em Conference on Uncertainty in Artificial Intelligence (UAI)},
  2018.

\bibitem{ehlers2017formal}
Ruediger Ehlers.
\newblock Formal verification of piece-wise linear feed-forward neural
  networks.
\newblock In {\em International Symposium on Automated Technology for
  Verification and Analysis (ATVA)}, 2017.

\bibitem{ferrari2022complete}
Claudio Ferrari, Mark~Niklas Muller, Nikola Jovanovic, and Martin Vechev.
\newblock Complete verification via multi-neuron relaxation guided
  branch-and-bound.
\newblock {\em arXiv preprint arXiv:2205.00263}, 2022.

\bibitem{gilmore1961linear}
Paul~C Gilmore and Ralph~E Gomory.
\newblock A linear programming approach to the cutting-stock problem.
\newblock {\em Operations research}, 9(6):849--859, 1961.

\bibitem{gilmore1963linear}
Paul~C Gilmore and Ralph~E Gomory.
\newblock A linear programming approach to the cutting stock problem—part ii.
\newblock {\em Operations research}, 11(6):863--888, 1963.

\bibitem{gowal2018effectiveness}
Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin,
  Jonathan Uesato, Timothy Mann, and Pushmeet Kohli.
\newblock On the effectiveness of interval bound propagation for training
  verifiably robust models.
\newblock {\em Proceedings of the IEEE International Conference on Computer
  Vision (ICCV)}, 2019.

\bibitem{gurobi}
LLC Gurobi~Optimization.
\newblock Gurobi optimizer - gurobi, 2022.

\bibitem{henriksen2020efficient}
Patrick Henriksen and Alessio Lomuscio.
\newblock Efficient neural network verification via adaptive refinement and
  adversarial search.
\newblock In {\em ECAI 2020}, pages 2513--2520. IOS Press, 2020.

\bibitem{henriksen2021deepsplit}
Patrick Henriksen and Alessio Lomuscio.
\newblock Deepsplit: An efficient splitting method for neural network
  verification via indirect effect analysis.
\newblock In {\em Proceedings of the 30th international joint conference on
  artificial intelligence (IJCAI21)}, pages 2549--2555, 2021.

\bibitem{hoffman1993solving}
Karla~L Hoffman and Manfred Padberg.
\newblock Solving airline crew scheduling problems by branch-and-cut.
\newblock {\em Management science}, 39(6):657--682, 1993.

\bibitem{cplex}
IBM.
\newblock Ibm ilog cplex optimizer, 2022.

\bibitem{johnson1982degree}
Ellis~L Johnson and Manfred~W Padberg.
\newblock Degree-two inequalities, clique facets, and biperfect graphs.
\newblock In {\em North-Holland Mathematics Studies}, volume~66, pages
  169--187. Elsevier, 1982.

\bibitem{katz2017reluplex}
Guy Katz, Clark Barrett, David~L Dill, Kyle Julian, and Mykel~J Kochenderfer.
\newblock Reluplex: An efficient smt solver for verifying deep neural networks.
\newblock In {\em International Conference on Computer Aided Verification
  (CAV)}, 2017.

\bibitem{katz2019marabou}
Guy Katz, Derek~A Huang, Duligur Ibeling, Kyle Julian, Christopher Lazarus,
  Rachel Lim, Parth Shah, Shantanu Thakoor, Haoze Wu, Aleksandar Zelji{\'c},
  et~al.
\newblock The marabou framework for verification and analysis of deep neural
  networks.
\newblock In {\em International Conference on Computer Aided Verification
  (CAV)}, 2019.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em International Conference on Learning Representations (ICLR)},
  2015.

\bibitem{kouvaros2021towards}
Panagiotis Kouvaros and Alessio Lomuscio.
\newblock Towards scalable complete verification of relu neural networks via
  dependency-based branching.
\newblock In {\em IJCAI}, pages 2643--2650, 2021.

\bibitem{vnn2020}
Changliu Liu and Taylor Johnson.
\newblock Vnn comp 2020.

\bibitem{lovasz1991cones}
L{\'a}szl{\'o} Lov{\'a}sz and Alexander Schrijver.
\newblock Cones of matrices and set-functions and 0--1 optimization.
\newblock {\em SIAM journal on optimization}, 1(2):166--190, 1991.

\bibitem{lu2019neural}
Jingyue Lu and M~Pawan Kumar.
\newblock Neural network branching for neural network verification.
\newblock {\em International Conference on Learning Representation (ICLR)},
  2020.

\bibitem{marchand2001aggregation}
Hugues Marchand and Laurence~A Wolsey.
\newblock Aggregation and mixed integer rounding to solve mips.
\newblock {\em Operations research}, 49(3):363--371, 2001.

\bibitem{muller2021scaling}
Christoph M{\"u}ller, Francois Serre, Gagandeep Singh, Markus P{\"u}schel, and
  Martin Vechev.
\newblock Scaling polyhedral neural network verification on gpus.
\newblock {\em Proceedings of Machine Learning and Systems}, 3:733--746, 2021.

\bibitem{muller2020neural}
Christoph M{\"u}ller, Gagandeep Singh, Markus P{\"u}schel, and Martin Vechev.
\newblock Neural network robustness verification on gpus.
\newblock {\em arXiv preprint arXiv:2007.10868}, 2020.

\bibitem{muller2021precise}
Mark~Niklas M{\"u}ller, Gleb Makarchuk, Gagandeep Singh, Markus P{\"u}schel,
  and Martin Vechev.
\newblock Precise multi-neuron abstractions for neural network certification.
\newblock {\em arXiv preprint arXiv:2103.03638}, 2021.

\bibitem{nemhauser1990recursive}
George~L Nemhauser and Laurence~A Wolsey.
\newblock A recursive procedure to generate all cuts for 0--1 mixed integer
  programs.
\newblock {\em Mathematical Programming}, 46(1):379--390, 1990.

\bibitem{padberg1985valid}
Manfred~W Padberg, Tony~J Van~Roy, and Laurence~A Wolsey.
\newblock Valid linear inequalities for fixed charge problems.
\newblock {\em Operations Research}, 33(4):842--861, 1985.

\bibitem{qin2019verification}
Chongli Qin, Brendan O'Donoghue, Rudy Bunel, Robert Stanforth, Sven Gowal,
  Jonathan Uesato, Grzegorz Swirszcz, Pushmeet Kohli, et~al.
\newblock Verification of non-linear specifications for neural networks.
\newblock {\em arXiv preprint arXiv:1902.09592}, 2019.

\bibitem{raghunathan2018semidefinite}
Aditi Raghunathan, Jacob Steinhardt, and Percy~S Liang.
\newblock Semidefinite relaxations for certifying robustness to adversarial
  examples.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2018.

\bibitem{salman2019convex}
Hadi Salman, Greg Yang, Huan Zhang, Cho-Jui Hsieh, and Pengchuan Zhang.
\newblock A convex relaxation barrier to tight robustness verification of
  neural networks.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2019.

\bibitem{sherali2013reformulation}
Hanif~D Sherali and Warren~P Adams.
\newblock {\em A reformulation-linearization technique for solving discrete and
  continuous nonconvex problems}, volume~31.
\newblock Springer Science \& Business Media, 2013.

\bibitem{singh2019beyond}
Gagandeep Singh, Rupanshu Ganvir, Markus P{\"u}schel, and Martin Vechev.
\newblock Beyond the single neuron convex barrier for neural network
  certification.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2019.

\bibitem{singh2018fast}
Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus P{\"u}schel, and Martin
  Vechev.
\newblock Fast and effective robustness certification.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2018.

\bibitem{singh2018boosting}
Gagandeep Singh, Timon Gehr, Markus P{\"u}schel, and Martin Vechev.
\newblock Boosting robustness certification of neural networks.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{singh2019abstract}
Gagandeep Singh, Timon Gehr, Markus P{\"u}schel, and Martin Vechev.
\newblock An abstract domain for certifying neural networks.
\newblock {\em Proceedings of the ACM on Programming Languages (POPL)}, 2019.

\bibitem{tan2021building}
Cheng Tan, Yibo Zhu, and Chuanxiong Guo.
\newblock Building verified neural networks with specifications for systems.
\newblock In {\em Proceedings of the 12th ACM SIGOPS Asia-Pacific Workshop on
  Systems}, pages 42--47, 2021.

\bibitem{tjandraatmadja2020convex}
Christian Tjandraatmadja, Ross Anderson, Joey Huchette, Will Ma, Krunal Patel,
  and Juan~Pablo Vielma.
\newblock The convex relaxation barrier, revisited: Tightened single-neuron
  relaxations for neural network verification.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2020.

\bibitem{tjeng2017evaluating}
Vincent Tjeng, Kai Xiao, and Russ Tedrake.
\newblock Evaluating robustness of neural networks with mixed integer
  programming.
\newblock {\em International Conference on Learning Representations (ICLR)},
  2019.

\bibitem{tran2020nnv}
Hoang-Dung Tran, Xiaodong Yang, Diego~Manzanas Lopez, Patrick Musau, Luan~Viet
  Nguyen, Weiming Xiang, Stanley Bak, and Taylor~T Johnson.
\newblock Nnv: The neural network verification tool for deep neural networks
  and learning-enabled cyber-physical systems.
\newblock In {\em International Conference on Computer Aided Verification},
  pages 3--17. Springer, 2020.

\bibitem{wang2018efficient}
Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana.
\newblock Efficient formal safety analysis of neural networks.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2018.

\bibitem{wang2018formal}
Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana.
\newblock Formal security analysis of neural networks using symbolic intervals.
\newblock In {\em USENIX Security Symposium}, 2018.

\bibitem{wang2021beta}
Shiqi Wang, Huan Zhang, Kaidi Xu, Xue Lin, Suman Jana, Cho-Jui Hsieh, and
  J~Zico Kolter.
\newblock Beta-crown: Efficient bound propagation with per-neuron split
  constraints for neural network robustness verification.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{wong2018provable}
Eric Wong and Zico Kolter.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2018.

\bibitem{xu2020automatic}
Kaidi Xu, Zhouxing Shi, Huan Zhang, Yihan Wang, Kai-Wei Chang, Minlie Huang,
  Bhavya Kailkhura, Xue Lin, and Cho-Jui Hsieh.
\newblock Automatic perturbation analysis for scalable certified robustness and
  beyond.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2020.

\bibitem{xu2020fast}
Kaidi Xu, Huan Zhang, Shiqi Wang, Yihan Wang, Suman Jana, Xue Lin, and Cho-Jui
  Hsieh.
\newblock Fast and complete: Enabling complete neural network verification with
  rapid and massively parallel incomplete verifiers.
\newblock {\em International Conference on Learning Representations (ICLR)},
  2021.

\bibitem{zhang2018efficient}
Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel.
\newblock Efficient neural network robustness certification with general
  activation functions.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2018.

\end{thebibliography}
