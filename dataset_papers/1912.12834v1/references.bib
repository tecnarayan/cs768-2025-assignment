@inproceedings{kour2014real,
  title={Real-time segmentation of on-line handwritten arabic script},
  author={Kour, George and Saabne, Raid},
  booktitle={Frontiers in Handwriting Recognition (ICFHR), 2014 14th International Conference on},
  pages={417--422},
  year={2014},
  organization={IEEE}
}

@inproceedings{kour2014fast,
  title={Fast classification of handwritten on-line Arabic characters},
  author={Kour, George and Saabne, Raid},
  booktitle={Soft Computing and Pattern Recognition (SoCPaR), 2014 6th International Conference of},
  pages={312--318},
  year={2014},
  organization={IEEE}
}

@inproceedings{dong2017scalable,
  title={Scalable Log Determinants for Gaussian Process Kernel Learning},
  author={Dong, Kun and Eriksson, David and Nickisch, Hannes and Bindel, David and Wilson, Andrew G},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6330--6340},
  year={2017}
}

@article{herlands2018change,
  author  = {William Herlands and Daniel B. Neill and Hannes Nickisch and Andrew Gordon Wilson},
  title   = {Change Surfaces for Expressive Multidimensional Changepoints and Counterfactual Prediction},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {99},
  pages   = {1-51},
  url     = {http://jmlr.org/papers/v20/17-352.html}
}

@inproceedings{flaxman2015fast,
  title={Fast Kronecker inference in Gaussian processes with non-Gaussian likelihoods},
  author={Flaxman, Seth and Wilson, Andrew and Neill, Daniel and Nickisch, Hannes and Smola, Alex},
  booktitle={International Conference on Machine Learning},
  pages={607--616},
  year={2015}
}

@article{hadash2018estimate,
  title={Estimate and Replace: A Novel Approach to Integrating Deep Neural Networks with Existing Applications},
  author={Hadash, Guy and Kermany, Einat and Carmeli, Boaz and Lavi, Ofer and Kour, George and Jacovi, Alon},
  journal={arXiv preprint arXiv:1804.09028},
  year={2018}
}

@inproceedings{duvenaud2011additive,
  title={Additive gaussian processes},
  author={Duvenaud, David K and Nickisch, Hannes and Rasmussen, Carl E},
  booktitle={Advances in neural information processing systems},
  pages={226--234},
  year={2011}
}

@inproceedings{gardner2017discovering,
  title={Discovering and exploiting additive structure for Bayesian optimization},
  author={Gardner, Jacob and Guo, Chuan and Weinberger, Kilian and Garnett, Roman and Grosse, Roger},
  booktitle={Artificial Intelligence and Statistics},
  pages={1311--1319},
  year={2017}
}

@article{wang2016bayesian,
  title={Bayesian optimization in a billion dimensions via random embeddings},
  author={Wang, Ziyu and Hutter, Frank and Zoghi, Masrour and Matheson, David and de Feitas, Nando},
  journal={Journal of Artificial Intelligence Research},
  volume={55},
  pages={361--387},
  year={2016}
}

@article{hensman2013gaussian,
  title={Gaussian processes for big data},
  author={Hensman, James and Fusi, Nicolo and Lawrence, Neil D},
  journal={arXiv preprint arXiv:1309.6835},
  year={2013}
}

@inproceedings{snelson2006sparse,
  title={Sparse Gaussian processes using pseudo-inputs},
  author={Snelson, Edward and Ghahramani, Zoubin},
  booktitle={Advances in neural information processing systems},
  pages={1257--1264},
  year={2006}
}

@article{wang2019exact,
  title={Exact Gaussian Processes on a Million Data Points},
  author={Wang, Ke Alexander and Pleiss, Geoff and Gardner, Jacob R and Tyree, Stephen and Weinberger, Kilian Q and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:1903.08114},
  year={2019}
}

@inproceedings{gardner2018gpytorch,
  title={Gpytorch: Blackbox matrix-matrix gaussian process inference with gpu acceleration},
  author={Gardner, Jacob and Pleiss, Geoff and Weinberger, Kilian Q and Bindel, David and Wilson, Andrew G},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7576--7586},
  year={2018}
}

@inproceedings{wilson2015kernel,
  title={Kernel interpolation for scalable structured Gaussian processes (KISS-GP)},
  author={Wilson, Andrew and Nickisch, Hannes},
  booktitle={International Conference on Machine Learning},
  pages={1775--1784},
  year={2015}
}

@article{gardner2018product,
  title={Product kernel interpolation for scalable Gaussian processes},
  author={Gardner, Jacob R and Pleiss, Geoff and Wu, Ruihan and Weinberger, Kilian Q and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:1802.08903},
  year={2018}
}

@inproceedings{yang2015carte,
  title={A la carte--learning fast kernels},
  author={Yang, Zichao and Wilson, Andrew and Smola, Alex and Song, Le},
  booktitle={Artificial Intelligence and Statistics},
  pages={1098--1106},
  year={2015}
}

@phdthesis{saatcci2012scalable,
  title={Scalable inference for structured Gaussian process models},
  author={Saat{\c{c}}i, Yunus},
  year={2012},
  school={Citeseer}
}

@article{silverman1985some,
  title={Some aspects of the spline smoothing approach to non-parametric regression curve fitting},
  author={Silverman, Bernhard W},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={47},
  number={1},
  pages={1--21},
  year={1985},
  publisher={Wiley Online Library}
}

@article{banerjee2012efficient,
  title={Efficient Gaussian process regression for large datasets},
  author={Banerjee, Anjishnu and Dunson, David B and Tokdar, Surya T},
  journal={Biometrika},
  volume={100},
  number={1},
  pages={75--89},
  year={2012},
  publisher={Oxford University Press}
}

@inproceedings{li2006very,
  title={Very sparse random projections},
  author={Li, Ping and Hastie, Trevor J and Church, Kenneth W},
  booktitle={Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={287--296},
  year={2006},
  organization={ACM}
}

@inproceedings{sarlos2006improved,
  title={Improved approximation algorithms for large matrices via random projections},
  author={Sarlos, Tamas},
  booktitle={2006 47th Annual IEEE Symposium on Foundations of Computer Science (FOCS'06)},
  pages={143--152},
  year={2006},
  organization={IEEE}
}

@inproceedings{kandasamy2015high,
  title={High dimensional Bayesian optimisation and bandits via additive models},
  author={Kandasamy, Kirthevasan and Schneider, Jeff and P{\'o}czos, Barnab{\'a}s},
  booktitle={International Conference on Machine Learning},
  pages={295--304},
  year={2015}
}

@article{bach2009high,
  title={High-dimensional non-linear variable selection through hierarchical kernel learning},
  author={Bach, Francis},
  journal={arXiv preprint arXiv:0909.0844},
  year={2009}
}

@inproceedings{bach2004multiple,
  title={Multiple kernel learning, conic duality, and the SMO algorithm},
  author={Bach, Francis R and Lanckriet, Gert RG and Jordan, Michael I},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={6},
  year={2004},
  organization={ACM}
}

@inproceedings{wilson2016stochastic,
  title={Stochastic variational deep kernel learning},
  author={Wilson, Andrew G and Hu, Zhiting and Salakhutdinov, Ruslan R and Xing, Eric P},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2586--2594},
  year={2016}
}

@article{hastie1986,
author = "Hastie, Trevor and Tibshirani, Robert",
doi = "10.1214/ss/1177013604",
fjournal = "Statistical Science",
journal = "Statist. Sci.",
month = "08",
number = "3",
pages = "297--310",
publisher = "The Institute of Mathematical Statistics",
title = "Generalized Additive Models",
url = "https://doi.org/10.1214/ss/1177013604",
volume = "1",
year = "1986"
}

@inproceedings{gilboa2013scaling,
  title={Scaling multidimensional Gaussian processes using projected additive approximations},
  author={Gilboa, Elad and Saat{\c{c}}i, Yunus and Cunningham, John},
  booktitle={International Conference on Machine Learning},
  pages={454--461},
  year={2013}
}

@InProceedings{li2016high,
  title = 	 {High Dimensional Bayesian Optimization via Restricted Projection Pursuit Models},
  author = 	 {Chun-Liang Li and Kirthevasan Kandasamy and Barnabas Poczos and Jeff Schneider},
  booktitle = 	 {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {884--892},
  year = 	 {2016},
  editor = 	 {Arthur Gretton and Christian C. Robert},
  volume = 	 {51},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Cadiz, Spain},
  month = 	 {09--11 May},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v51/li16e.pdf},
  url = 	 {http://proceedings.mlr.press/v51/li16e.html},
  abstract = 	 {Bayesian Optimization (BO) is commonly used to optimize blackbox objective functions which are expensive to evaluate. A common approach is based on using Gaussian Process (GP) to model the objective function. Applying GP to higher dimensional settings is generally difficult due to the curse of dimensionality for nonparametric regression. Existing works makes strong assumptions such as the function is low-dimensional embedding (Wang et al., 2013) or is axis-aligned additive (Kandasamy et al., 2015). In this pa- per, we generalize the existing assumption to a projected-additive assumption. Our generalization provides the benefits of i) greatly increasing the space of functions that can be modeled by our approach, which covers the previous works (Wang et al., 2013; Kandasamy et al., 2015) as special cases, and ii) efficiently handling the learning in a larger model space. We prove that the regret for projected-additive functions has only linear dependence on the number of dimensions in this general setting. Directly using projected-additive GP (Gilboa et al., 2013) to BO results in a non-box constraint, which is not easy to optimize. We tackle this problem by proposing a restricted-projection-pursuit GP for BO. We conduct experiments on synthetic examples and scientific and hyper-parameter tuning tasks in many cases. Our method outperforms existing approaches even when the function does not meet the projected additive assumption. Last, we study the validity of the additive and projected-additive assumption in practice.}
}

@book{rasmussen2006gaussian,
  title={Gaussian processes for machine learning},
  author={Rasmussen, Carl Edward and Williams, Christopher KI},
  volume={2},
  number={3},
  year={2006},
  publisher={MIT Press Cambridge, MA}
}

@inproceedings{wilson2016deep,
  title={Deep kernel learning},
  author={Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P},
  booktitle={Artificial Intelligence and Statistics},
  pages={370--378},
  year={2016}
}

@article{lanckriet2004learning,
  title={Learning the kernel matrix with semidefinite programming},
  author={Lanckriet, Gert RG and Cristianini, Nello and Bartlett, Peter and Ghaoui, Laurent El and Jordan, Michael I},
  journal={Journal of Machine learning research},
  volume={5},
  number={Jan},
  pages={27--72},
  year={2004}
}

@article{nickisch2011multiple,
  title={Multiple kernel learning: a unifying probabilistic viewpoint},
  author={Nickisch, Hannes and Seeger, Matthias},
  journal={arXiv preprint arXiv:1103.0897},
  year={2011}
}

@phdthesis{neal1995bayesian,
  title={BAYESIAN LEARNING FOR NEURAL NETWORKS},
  author={Neal, Radford M},
  year={1995},
  school={Citeseer}
}

@inproceedings{wilson2013gaussian,
  title={Gaussian process kernels for pattern discovery and extrapolation},
  author={Wilson, Andrew and Adams, Ryan},
  booktitle={International Conference on Machine Learning},
  pages={1067--1075},
  year={2013}
}

@InProceedings{duvenaud2013structure,
  title = 	 {Structure Discovery in Nonparametric Regression through Compositional Kernel Search},
  author = 	 {David Duvenaud and James Lloyd and Roger Grosse and Joshua Tenenbaum and Ghahramani Zoubin},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {1166--1174},
  year = 	 {2013},
  editor = 	 {Sanjoy Dasgupta and David McAllester},
  volume = 	 {28},
  number =       {3},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/duvenaud13.pdf},
  url = 	 {http://proceedings.mlr.press/v28/duvenaud13.html},
  abstract = 	 {Despite its importance, choosing the structural form of the kernel in nonparametric regression remains a black art. We define a space of kernel structures which are built compositionally by adding and multiplying a small number of base kernels. We present a method for searching over this space of structures which mirrors the scientific discovery process. The learned structures can often decompose functions into interpretable components and enable long-range extrapolation on time-series datasets. Our structure search method outperforms many widely used kernels and kernel combination methods on a variety of prediction tasks.}
}

@inproceedings{wang2017batched,
  title={Batched Large-scale Bayesian Optimization in High-dimensional Spaces},
  author={Zi Wang and Clement Gehring and Pushmeet Kohli and Stefanie Jegelka},
  booktitle={AISTATS},
  year={2017}
}

@misc{trevor2009elements,
  title={The elements of statistical learning: data mining, inference, and prediction},
  author={Trevor, Hastie and Robert, Tibshirani and JH, Friedman},
  year={2009},
  publisher={New York, NY: Springer}
}

@book{cheney2009course,
  title={A course in approximation theory},
  author={Cheney, Elliott Ward and Light, William Allan},
  volume={101},
  year={2009},
  publisher={American Mathematical Soc.}
}

@article{huang2011extreme,
  title={Extreme learning machines: a survey},
  author={Huang, Guang-Bin and Wang, Dian Hui and Lan, Yuan},
  journal={International journal of machine learning and cybernetics},
  volume={2},
  number={2},
  pages={107--122},
  year={2011},
  publisher={Springer}
}

@misc{Dua:2019 ,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@inproceedings{rasmussen2001occam,
  title={Occam's razor},
  author={Rasmussen, Carl Edward and Ghahramani, Zoubin},
  booktitle={Advances in neural information processing systems},
  pages={294--300},
  year={2001}
}

@article{pinkus1997approximating,
  title={Approximating by ridge functions},
  author={Pinkus, Allan},
  journal={Surface fitting and multiresolution methods},
  pages={279--292},
  year={1997},
  publisher={Vanderbilt University Press, Nashville}
}
@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{keys1981cubic,
  title={Cubic convolution interpolation for digital image processing},
  author={Keys, Robert},
  journal={IEEE transactions on acoustics, speech, and signal processing},
  volume={29},
  number={6},
  pages={1153--1160},
  year={1981},
  publisher={Ieee}
}

@inproceedings{wu2017bayesian,
  title={Bayesian optimization with gradients},
  author={Wu, Jian and Poloczek, Matthias and Wilson, Andrew G and Frazier, Peter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5267--5278},
  year={2017}
}

@article{friedman1981projection,
  title={Projection pursuit regression},
  author={Friedman, Jerome H and Stuetzle, Werner},
  journal={Journal of the American statistical Association},
  volume={76},
  number={376},
  pages={817--823},
  year={1981},
  publisher={Taylor \& Francis}
}

@article{stone1985additive,
  title={Additive regression and other nonparametric models},
  author={Stone, Charles J and others},
  journal={The annals of Statistics},
  volume={13},
  number={2},
  pages={689--705},
  year={1985},
  publisher={Institute of Mathematical Statistics}
}

@incollection{womersley2018efficient,
  title={Efficient spherical designs with good geometric properties},
  author={Womersley, Robert S},
  booktitle={Contemporary Computational Mathematics-A Celebration of the 80th Birthday of Ian Sloan},
  pages={1243--1285},
  year={2018},
  publisher={Springer}
}

@inbook{asmussen2007stochastic,
  title={Stochastic simulation: algorithms and analysis},
  author={Asmussen, S{\o}ren and Glynn, Peter W},
  volume={57},
  year={2007},
  publisher={Springer Science \& Business Media},
  pages={270}
}

@inproceedings{Srinivas2019Gaussian,
 author = {Srinivas, Niranjan and Krause, Andreas and Kakade, Sham and Seeger, Matthias},
 title = {Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design},
 booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
 series = {ICML'10},
 year = {2010},
 isbn = {978-1-60558-907-7},
 location = {Haifa, Israel},
 pages = {1015--1022},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=3104322.3104451},
 acmid = {3104451},
 publisher = {Omnipress},
 address = {USA},
}

@article{bull2011convergence,
  title={Convergence rates of efficient global optimization algorithms},
  author={Bull, Adam D},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Oct},
  pages={2879--2904},
  year={2011}
}

@inproceedings{movckus1975bayesian,
  title={On Bayesian methods for seeking the extremum},
  author={Mo{\v{c}}kus, Jonas},
  booktitle={Optimization Techniques IFIP Technical Conference},
  pages={400--404},
  year={1975},
  organization={Springer}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
  pages={465--472},
  year={2011}
}

@inproceedings{Engel2005reinforcement,
 author = {Engel, Yaakov and Mannor, Shie and Meir, Ron},
 title = {Reinforcement Learning with Gaussian Processes},
 booktitle = {Proceedings of the 22Nd International Conference on Machine Learning},
 series = {ICML '05},
 year = {2005},
 isbn = {1-59593-180-5},
 location = {Bonn, Germany},
 pages = {201--208},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1102351.1102377},
 doi = {10.1145/1102351.1102377},
 acmid = {1102377},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@article{vijayakumar2005incremental,
  title={Incremental online learning in high dimensions},
  author={Vijayakumar, Sethu and D'souza, Aaron and Schaal, Stefan},
  journal={Neural computation},
  volume={17},
  number={12},
  pages={2602--2634},
  year={2005},
  publisher={MIT Press}
}

@inproceedings{williams1996gaussian,
  title={Gaussian processes for regression},
  author={Williams, Christopher KI and Rasmussen, Carl Edward},
  booktitle={Advances in neural information processing systems},
  pages={514--520},
  year={1996}
}

@INPROCEEDINGS{vanBeers2004kriging, 
author={W. C. M. {van Beers} and J. P. C. {Kleijnen}}, 
booktitle={Proceedings of the 2004 Winter Simulation Conference, 2004.}, 
title={Kriging interpolation in simulation: a survey}, 
year={2004}, 
volume={1}, 
number={}, 
pages={121}, 
keywords={regression analysis;interpolation;polynomials;computer aided engineering;discrete event simulation;sensitivity analysis;optimisation;Kriging interpolation function;sensitivity analysis;optimization;simulation models;polynomial regression analysis;fractional factorial design;deterministic simulation;computer aided engineering;discrete-event simulation;space filling designs;latin hypercube sampling;customized sequential designs;Interpolation;Computational modeling;Computer simulation;Regression analysis;Analytical models;Sensitivity analysis;Response surface methodology;Polynomials;Predictive models;Computer aided engineering}, 
doi={10.1109/WSC.2004.1371308}, 
ISSN={}, 
month={Dec},}

@phdthesis{duvenaud2014automatic,
  title={Automatic model construction with Gaussian processes},
  author={Duvenaud, David},
  year={2014},
  school={University of Cambridge}
}

@incollection{NIPS2007_3211,
title = {Using Deep Belief Nets to Learn Covariance Kernels for Gaussian Processes},
author = {Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
booktitle = {Advances in Neural Information Processing Systems 20},
editor = {J. C. Platt and D. Koller and Y. Singer and S. T. Roweis},
pages = {1249--1256},
year = {2008},
publisher = {Curran Associates, Inc.}
}



@inproceedings{rahimi2008random,
  title={Random features for large-scale kernel machines},
  author={Rahimi, Ali and Recht, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={1177--1184},
  year={2008}
}

@article{qamar2014additive,
  title={Additive gaussian process regression},
  author={Qamar, Shaan and Tokdar, Surya T},
  journal={arXiv preprint arXiv:1411.7009},
  year={2014}
}

@article{guhaniyogi2016compressed,
  title={Compressed Gaussian process for manifold regression},
  author={Guhaniyogi, Rajarshi and Dunson, David B},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2472--2497},
  year={2016},
  publisher={JMLR. org}
}

@book{ahmed2004multiple,
  title={Multiple random projection for fast, approximate nearest neighbor search in high dimensions},
  author={Ahmed, Yousuf Shamim},
  year={2004},
  publisher={University of Toronto}
}

@article{baraniuk2009random,
  title={Random projections of smooth manifolds},
  author={Baraniuk, Richard G and Wakin, Michael B},
  journal={Foundations of computational mathematics},
  volume={9},
  number={1},
  pages={51--77},
  year={2009},
  publisher={Springer}
}


@book{lantuejoul2013geostatistical,
  title={Geostatistical simulation: models and algorithms},
  author={Lantu{\'e}joul, Christian},
  chapter = {The turning bands method},
  pages = {192-199},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{matheron197.intrinsic,
 ISSN = {00018678},
 URL = {http://www.jstor.org/stable/1425829},
 abstract = {The intrinsic random functions (IRF) are a particular case of the Guelfand generalized processes with stationary increments. They constitute a much wider class than the stationary RF, and are used in practical applications for representing non-stationary phenomena. The most important topics are: existence of a generalized covariance (GC) for which statistical inference is possible from a unique realization; theory of the best linear intrinsic estimator (BLIE) used for contouring and estimating problems; the turning bands method for simulating IRF; and the models with polynomial GC, for which statistical inference may be performed by automatic procedures.},
 author = {G. Matheron},
 journal = {Advances in Applied Probability},
 number = {3},
 pages = {439--468},
 publisher = {Applied Probability Trust},
 title = {The Intrinsic Random Functions and Their Applications},
 volume = {5},
 year = {1973}
}

@article{gneiting1998closed,
  title={Closed form solutions of the two-dimensional turning bands equation},
  author={Gneiting, Tilmann},
  journal={Mathematical Geology},
  volume={30},
  number={4},
  pages={379--390},
  year={1998},
  publisher={Springer}
}


@article{mantoglou1987digital,
  title={Digital simulation of multivariate two-and three-dimensional stochastic processes with a spectral turning bands method},
  author={Mantoglou, Aristotelis},
  journal={Mathematical Geology},
  volume={19},
  number={2},
  pages={129--149},
  year={1987},
  publisher={Springer}
}

@article{mantoglou1982turning,
  title={The turning bands method for simulation of random fields using line generation by a spectral method},
  author={Mantoglou, Aristotelis and Wilson, John L},
  journal={Water Resources Research},
  volume={18},
  number={5},
  pages={1379--1394},
  year={1982},
  publisher={Wiley Online Library}
}

@article{christakos1987stochastic,
  title={Stochastic simulation of spatially correlated geo-processes},
  author={Christakos, George},
  journal={Mathematical Geology},
  volume={19},
  number={8},
  pages={807--831},
  year={1987},
  publisher={Springer}
}

@article{freulon1993revisiting,
  title={Revisiting the turning bands method},
  author={Freulon, Xavier and Lantuejoul, Christian},
  journal={Acta Stereologica},
  year={1993}
}