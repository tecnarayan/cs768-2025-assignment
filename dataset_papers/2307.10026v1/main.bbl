\begin{thebibliography}{10}

\bibitem{torralba2003contextual}
Antonio Torralba.
\newblock Contextual priming for object detection.
\newblock {\em International journal of computer vision}, 53:169--191, 2003.

\bibitem{muandet2013domain}
Krikamol Muandet, David Balduzzi, and Bernhard Sch{\"o}lkopf.
\newblock Domain generalization via invariant feature representation.
\newblock In {\em International conference on machine learning}, pages 10--18.
  PMLR, 2013.

\bibitem{NIPS2011_b571ecea}
Gilles Blanchard, Gyemin Lee, and Clayton Scott.
\newblock Generalizing from several related classification tasks to a new
  unlabeled sample.
\newblock In J.~Shawe-Taylor, R.~Zemel, P.~Bartlett, F.~Pereira, and K.Q.
  Weinberger, editors, {\em Advances in Neural Information Processing Systems},
  volume~24. Curran Associates, Inc., 2011.

\bibitem{gulrajani2020search}
Ishaan Gulrajani and David Lopez-Paz.
\newblock In search of lost domain generalization, 2020.

\bibitem{rosenfeld2021risks}
Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski.
\newblock The risks of invariant risk minimization, 2021.

\bibitem{ettinger2021large}
Scott Ettinger, Shuyang Cheng, Benjamin Caine, Chenxi Liu, Hang Zhao, Sabeek
  Pradhan, Yuning Chai, Ben Sapp, Charles~R Qi, Yin Zhou, et~al.
\newblock Large scale interactive motion forecasting for autonomous driving:
  The waymo open motion dataset.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9710--9719, 2021.

\bibitem{causalagents}
Rebecca Roelofs, Liting Sun, Ben Caine, Khaled~S. Refaat, Ben Sapp, Scott
  Ettinger, and Wei Chai.
\newblock Causalagents: A robustness benchmark for motion forecasting using
  causal relationships, 2022.

\bibitem{hu2018does}
Weihua Hu, Gang Niu, Issei Sato, and Masashi Sugiyama.
\newblock Does distributionally robust supervised learning give robust
  classifiers?
\newblock In {\em International Conference on Machine Learning}, pages
  2029--2037. PMLR, 2018.

\bibitem{sagawa2019distributionally}
Shiori Sagawa, Pang~Wei Koh, Tatsunori~B Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks for group shifts: On the
  importance of regularization for worst-case generalization.
\newblock {\em arXiv preprint arXiv:1911.08731}, 2019.

\bibitem{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em arXiv preprint arXiv:1412.6572}, 2014.

\bibitem{raghunathan2018certified}
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
\newblock Certified defenses against adversarial examples.
\newblock {\em arXiv preprint arXiv:1801.09344}, 2018.

\bibitem{duchi2019distributionally}
John~C Duchi, Tatsunori Hashimoto, and Hongseok Namkoong.
\newblock Distributionally robust losses against mixture covariate shifts.
\newblock {\em Under review}, 2:1, 2019.

\bibitem{liu2014robust}
Anqi Liu and Brian Ziebart.
\newblock Robust classification under sample selection bias.
\newblock {\em Advances in neural information processing systems}, 27, 2014.

\bibitem{li2018learning}
Da~Li, Yongxin Yang, Yi-Zhe Song, and Timothy Hospedales.
\newblock Learning to generalize: Meta-learning for domain generalization.
\newblock In {\em Proceedings of the AAAI conference on artificial
  intelligence}, volume~32, 2018.

\bibitem{ross2011reduction}
St{\'e}phane Ross, Geoffrey Gordon, and Drew Bagnell.
\newblock A reduction of imitation learning and structured prediction to
  no-regret online learning.
\newblock In {\em Proceedings of the fourteenth international conference on
  artificial intelligence and statistics}, pages 627--635. JMLR Workshop and
  Conference Proceedings, 2011.

\bibitem{tien2023causal}
Jeremy Tien, Jerry Zhi-Yang He, Zackory Erickson, Anca Dragan, and Daniel~S
  Brown.
\newblock Causal confusion and reward misidentification in preference-based
  reward learning.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem{de2019causal}
Pim De~Haan, Dinesh Jayaraman, and Sergey Levine.
\newblock Causal confusion in imitation learning.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{lyle2021resolving}
Clare Lyle, Amy Zhang, Minqi Jiang, Joelle Pineau, and Yarin Gal.
\newblock Resolving causal confusion in reinforcement learning via robust
  exploration.
\newblock In {\em Self-Supervision for Reinforcement Learning Workshop-ICLR
  2021}, 2021.

\bibitem{brown2020bayesian}
Daniel Brown, Scott Niekum, and Marek Petrik.
\newblock Bayesian robust optimization for imitation learning.
\newblock {\em Advances in Neural Information Processing Systems},
  33:2479--2491, 2020.

\bibitem{javed2021policy}
Zaynah Javed, Daniel~S Brown, Satvik Sharma, Jerry Zhu, Ashwin Balakrishna,
  Marek Petrik, Anca Dragan, and Ken Goldberg.
\newblock Policy gradient bayesian robust optimization for imitation learning.
\newblock In {\em International Conference on Machine Learning}, pages
  4785--4796. PMLR, 2021.

\bibitem{kohconceptbottleneck}
Pang~Wei Koh, Thao Nguyen, Yew~Siang Tang, Stephen Mussmann, Emma Pierson, Been
  Kim, and Percy Liang.
\newblock Concept bottleneck models, 2020.

\bibitem{Drightforrightreason}
Andrew~Slavin Ross, Michael~C. Hughes, and Finale Doshi{-}Velez.
\newblock Right for the right reasons: Training differentiable models by
  constraining their explanations.
\newblock {\em CoRR}, abs/1703.03717, 2017.

\bibitem{fragilegradients}
Harshay Shah, Prateek Jain, and Praneeth Netrapalli.
\newblock Do input gradients highlight discriminative features?, 2021.

\bibitem{koh2021wilds}
Pang~Wei Koh, Shiori Sagawa, Henrik Marklund, Sang~Michael Xie, Marvin Zhang,
  Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard~Lanas Phillips,
  Irena Gao, et~al.
\newblock Wilds: A benchmark of in-the-wild distribution shifts.
\newblock In {\em International Conference on Machine Learning}, pages
  5637--5664. PMLR, 2021.

\bibitem{beery2021iwildcam}
Sara Beery, Arushi Agarwal, Elijah Cole, and Vighnesh Birodkar.
\newblock The iwildcam 2021 competition dataset.
\newblock {\em arXiv preprint arXiv:2105.03494}, 2021.

\bibitem{zech2018variable}
John~R Zech, Marcus~A Badgeley, Manway Liu, Anthony~B Costa, Joseph~J Titano,
  and Eric~Karl Oermann.
\newblock Variable generalization performance of a deep learning model to
  detect pneumonia in chest radiographs: a cross-sectional study.
\newblock {\em PLoS medicine}, 15(11):e1002683, 2018.

\bibitem{botev2022regularising}
Aleksander Botev, Matthias Bauer, and Soham De.
\newblock Regularising for invariance to data augmentation improves supervised
  learning.
\newblock {\em arXiv preprint arXiv:2203.03304}, 2022.

\bibitem{ross2017right}
Andrew~Slavin Ross, Michael~C Hughes, and Finale Doshi-Velez.
\newblock Right for the right reasons: Training differentiable models by
  constraining their explanations.
\newblock {\em arXiv preprint arXiv:1703.03717}, 2017.

\bibitem{arjovsky2019invariant}
Martin Arjovsky, L{\'e}on Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization.
\newblock {\em arXiv preprint arXiv:1907.02893}, 2019.

\bibitem{heinze2018invariant}
Christina Heinze-Deml, Jonas Peters, and Nicolai Meinshausen.
\newblock Invariant causal prediction for nonlinear models.
\newblock {\em Journal of Causal Inference}, 6(2), 2018.

\bibitem{peters2016causal}
Jonas Peters, Peter B{\"u}hlmann, and Nicolai Meinshausen.
\newblock Causal inference by using invariant prediction: identification and
  confidence intervals.
\newblock {\em Journal of the Royal Statistical Society. Series B (Statistical
  Methodology)}, pages 947--1012, 2016.

\bibitem{activelearningtamkin}
Alex Tamkin, Dat Nguyen, Salil Deshpande, Jesse Mu, and Noah Goodman.
\newblock Active learning helps pretrained models learn the intended task,
  2022.

\bibitem{sagawa2020investigation}
Shiori Sagawa, Aditi Raghunathan, Pang~Wei Koh, and Percy Liang.
\newblock An investigation of why overparameterization exacerbates spurious
  correlations.
\newblock In {\em International Conference on Machine Learning}, pages
  8346--8356. PMLR, 2020.

\bibitem{liu2021decoupling}
Evan~Z Liu, Aditi Raghunathan, Percy Liang, and Chelsea Finn.
\newblock Decoupling exploration and exploitation for meta-reinforcement
  learning without sacrifices.
\newblock In {\em International conference on machine learning}, pages
  6925--6935. PMLR, 2021.

\bibitem{groupdro}
Shiori Sagawa, Pang~Wei Koh, Tatsunori~B. Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks for group shifts: On the
  importance of regularization for worst-case generalization.
\newblock {\em CoRR}, abs/1911.08731, 2019.

\bibitem{jtt}
Evan~Zheran Liu, Behzad Haghgoo, Annie~S. Chen, Aditi Raghunathan, Pang~Wei
  Koh, Shiori Sagawa, Percy Liang, and Chelsea Finn.
\newblock Just train twice: Improving group robustness without training group
  information, 2021.

\bibitem{learnfromfailure}
Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin.
\newblock Learning from failure: Training debiased classifier from biased
  classifier, 2020.

\bibitem{bishop2006pattern}
Christopher~M Bishop.
\newblock {\em {Pattern Recognition and Machine Learning}}.
\newblock Springer, 2006.

\bibitem{duchi2018multiclass}
John Duchi, Khashayar Khosravi, and Feng Ruan.
\newblock Multiclass classification, information, divergence and surrogate
  risk.
\newblock {\em The Annals of Statistics}, 2018.

\bibitem{kakade2008complexity}
Sham~M Kakade, Karthik Sridharan, and Ambuj Tewari.
\newblock On the complexity of linear prediction: Risk bounds, margin bounds,
  and regularization.
\newblock {\em Advances in neural information processing systems}, 21, 2008.

\bibitem{wainwright2019high}
Martin~J Wainwright.
\newblock {\em High-dimensional statistics: A non-asymptotic viewpoint},
  volume~48.
\newblock Cambridge university press, 2019.

\bibitem{multipathpp}
Balakrishnan Varadarajan, Ahmed Hefny, Avikalp Srivastava, Khaled~S. Refaat,
  Nigamaa Nayakanti, Andre Cornman, Kan Chen, Bertrand Douillard, Chi~Pang Lam,
  Dragomir Anguelov, and Benjamin Sapp.
\newblock Multipath++: Efficient information fusion and trajectory aggregation
  for behavior prediction, 2021.

\end{thebibliography}
