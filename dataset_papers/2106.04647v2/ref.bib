@article{raffel2019exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={JMLR},
  year={2020}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-Efficient Transfer Learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and de Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={ICML},
  year={2019}
}





@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}
@inproceedings{rebuffi2018efficient,
  title={Efficient parametrization of multi-domain deep neural networks},
  author={Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{stickland2019bert,
  title={BERT and PALs: Projected Attention Layers for Efficient Adaptation in Multi-Task Learning},
  author={Stickland, Asa Cooper and Murray, Iain},
  booktitle={ICML},
  year={2019}
}

@inproceedings{peters-2019-tune,
  title={To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks},
  author={Peters, Matthew E and Ruder, Sebastian and Smith, Noah A},
  booktitle={RepL4NLP},
  year={2019}
}


@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{
li2018measuring,
title={Measuring the Intrinsic Dimension of Objective Landscapes},
author={Chunyuan Li and Heerad Farkhoor and Rosanne Liu and Jason Yosinski},
booktitle={ICLR},
year={2018},
}

@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={NAACL},
  year={2019}
}

@inproceedings{ustun2020udapter,
  title={UDapter: Language Adaptation for Truly Universal Dependency Parsing},
  author={{\"U}st{\"u}n, Ahmet and Bisazza, Arianna and Bouma, Gosse and van Noord, Gertjan},
  booktitle={EMNLP},
  year={2020}
}

@inproceedings{
wang2018glue,
title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
author={Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
booktitle={ICLR},
year={2019},
}
@inproceedings{zhang2020revisiting,
  title={Revisiting Few-sample BERT Fine-tuning},
  author={Zhang, Tianyi and Wu, Felix and Katiyar, Arzoo and Weinberger, Kilian Q and Artzi, Yoav},
  booktitle ={ICLR},
  year={2021}
}
@inproceedings{wolf-etal2020transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "EMNLP: System Demonstrations",
    year = "2020",
}
@inproceedings{platanios2018contextual,
  title={Contextual Parameter Generation for Universal Neural Machine Translation},
  author={Platanios, Emmanouil Antonios and Sachan, Mrinmaya and Neubig, Graham and Mitchell, Tom},
  booktitle={EMNLP},
  year={2018}
}
@inproceedings{
zhang2021beyond,
title={Beyond Fully-Connected Layers with Quaternions: Parameterization of Hypercomplex Multiplications with 1/n Parameters},
author={Aston Zhang and Yi Tay and SHUAI Zhang and Alvin Chan and Anh Tuan Luu and Siu Hui and Jie Fu},
booktitle={ICLR},
year={2021},
}


@article{le2021parameterized,
   title={Parameterized Hypercomplex Graph Neural Networks for Graph Classification}, 
      author={Tuan Le and Marco Bertolini and Frank Noé and Djork-Arné Clevert},
      year={2021},
     journal={ICANN}
     }



@inproceedings{le2013fastfood,
  title={Fastfood-approximating kernel expansions in loglinear time},
  author={Le, Quoc and Sarl{\'o}s, Tam{\'a}s and Smola, Alex},
  booktitle={ICML},
  year={2013}
}

@inproceedings{              
karimi2021parameter-efficient,              
title={Parameter-efficient Multi-task Fine-tuning for Transformers via Shared Hypernetworks},              
author={Rabeeh Karimi Mahabadi and Sebastian Ruder and Mostafa Dehghani and James Henderson},              
 booktitle={ACL},             
year={2021}         
}
@inproceedings{clark2019what,
  title = {What Does BERT Look At? An Analysis of BERT's Attention},
  author = {Kevin Clark and Urvashi Khandelwal and Omer Levy and Christopher D. Manning},
  booktitle = {BlackBoxNLP@ACL},
  year = {2019}
}
@article{chen2020lottery,
  title={The lottery ticket hypothesis for pre-trained bert networks},
  author={Chen, Tianlong and Frankle, Jonathan and Chang, Shiyu and Liu, Sijia and Zhang, Yang and Wang, Zhangyang and Carbin, Michael},
  journal={NeurIPS},
  year={2020}
}

@inproceedings{prasannaetal2020bert,
    title = "{W}hen {BERT} {P}lays the {L}ottery, {A}ll {T}ickets {A}re {W}inning",
    author = "Prasanna, Sai  and
      Rogers, Anna  and
      Rumshisky, Anna",
    booktitle = "EMNLP",
    year = "2020",
}

@inproceedings{desaietal2019evaluating,
    title = "Evaluating Lottery Tickets Under Distributional Shifts",
    author = "Desai, Shrey  and
      Zhan, Hongyuan  and
      Aly, Ahmed",
    booktitle = "DeepLo",
    year = "2019",
}

@inproceedings{howard-2018-ulmfit,
author = {Howard, Jeremy and Ruder, Sebastian},
booktitle = {ACL},
title = {{Universal Language Model Fine-tuning for Text Classification}},
year = {2018}
}
@inproceedings{pfeifferetal2020adapterhub,
    title = "{A}dapter{H}ub: A Framework for Adapting Transformers",
    author = {Pfeiffer, Jonas  and
      R{\"u}ckl{\'e}, Andreas  and
      Poth, Clifton  and
      Kamath, Aishwarya  and
      Vuli{\'c}, Ivan  and
      Ruder, Sebastian  and
      Cho, Kyunghyun  and
      Gurevych, Iryna},
    booktitle = "EMNLP: System Demonstrations",
    month = oct,
    year = "2020",
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}


@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  year={2019}
}

@inproceedings{Howard2018ulmfit,
author = {Howard, Jeremy and Ruder, Sebastian},
booktitle = {ACL},
title = {{Universal Language Model Fine-tuning for Text Classification}},
year = {2018}
}


@inproceedings{linz-etal-2020-exploring,
    title = "Exploring Versatile Generative Language Model Via Parameter-Efficient Transfer Learning",
    author = "Lin, Zhaojiang  and
      Madotto, Andrea  and
      Fung, Pascale",
    booktitle = "EMNLP Findings",
    year = "2020"
}

@inproceedings{conneau2020unsupervised,
  title={Unsupervised Cross-lingual Representation Learning at Scale},
  author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, {\'E}douard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  booktitle={ACL},
  year={2020}
}


@inproceedings{parcollet2019quaternion,
  title={Quaternion convolutional neural networks for heterogeneous image processing},
  author={Parcollet, Titouan and Morchid, Mohamed and Linar{\`e}s, Georges},
  booktitle={ICASSP},
  year={2019},
}

@inproceedings{tay2019lightweight,
  title={Lightweight and Efficient Neural Natural Language Processing with Quaternion Networks},
  author={Tay, Yi and Zhang, Aston and Luu, Anh Tuan and Rao, Jinfeng and Zhang, Shuai and Wang, Shuohang and Fu, Jie and Hui, Siu Cheung},
  booktitle={ACL},
  year={2019}
}

@article{rishiyur2006neural,
  title={Neural networks with complex and quaternion inputs},
  author={Rishiyur, Adityan},
  journal={arXiv preprint cs/0607090},
  year={2006}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{Ruckle2020adapterdrop,
author = {R{\"{u}}ckl{\'{e}}, Andreas and Geigle, Gregor and Glockner, Max and Beck, Tilman and Pfeiffer, Jonas and Reimers, Nils and Gurevych, Iryna},
journal = {EMNLP},
title = {{AdapterDrop: On the Efficiency of Adapters in Transformers}},
year = {2021}
}

@inproceedings{Wen2020batchensemble,
author = {Wen, Yeming and Tran, Dustin and Ba, Jimmy},
booktitle = {ICLR},
title = {{BatchEnsemble: An Alternative Approach to Efficient Ensemble and Lifelong Learning}},
year = {2020}
}

@inproceedings{gaudet2018deep,
  title={Deep quaternion networks},
  author={Gaudet, Chase J and Maida, Anthony S},
  booktitle={IJCNN},
  year={2018},
}

@inproceedings{parcollet2018quaternion_b,
  title={Quaternion Recurrent Neural Networks},
  author={Parcollet, Titouan and Ravanelli, Mirco and Morchid, Mohamed and Linar{\`e}s, Georges and Trabelsi, Chiheb and De Mori, Renato and Bengio, Yoshua},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{parcollet2018quaternion,
  title={Quaternion Convolutional Neural Networks for End-to-End Automatic Speech Recognition},
  author={Parcollet, Titouan and Zhang, Ying and Morchid, Mohamed and Trabelsi, Chiheb and Linar{\`e}s, Georges and de Mori, Renato and Bengio, Yoshua},
  booktitle={Interspeech},
  year={2018},
}

@inproceedings{zhu2018quaternion,
  title={Quaternion convolutional neural networks},
  author={Zhu, Xuanyu and Xu, Yi and Xu, Hongteng and Chen, Changjian},
  booktitle={ECCV},
  year={2018}
}


@article{aghajanyan2020intrinsic,
  title={Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning},
  author={Aghajanyan, Armen and Zettlemoyer, Luke and Gupta, Sonal},
  journal={ACL},
  year={2021}
}

@article{2020HuggingFace-datasets,
  title={Datasets},
  author={Thomas Wolf and Quentin Lhoest and Patrick von Platen and Yacine Jernite and Mariama Drame and Julien Plu and Julien Chaumond and Clement Delangue and Clara Ma and Abhishek Thakur and Suraj Patil and Joe Davison and Teven Le Scao and Victor Sanh and Canwen Xu and Nicolas Patry and Angie McMillan-Major and Simon Brandeis and Sylvain Gugger and François Lagunas and Lysandre Debut and Morgan Funtowicz and Anthony Moi and Sasha Rush and Philipp Schmidd and Pierric Cistac and Victor Muštar and Jeff Boudier and Anna Tordjmann},
  journal={GitHub. Note: https://github.com/huggingface/datasets},
  year={2020}
}


@inproceedings{brown2020gpt3,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {NeurIPS},
 title = {Language Models are Few-Shot Learners},
 year = {2020}
}


@article{yang2019xlnet,
  title={XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  journal={NeurIPS},
  year={2019}
}
@article{li2021prefix,
  title={Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={ACL},
  year = {2021}
}

@article{jiang2020can,
  title={How can we know what language models know?},
  author={Jiang, Zhengbao and Xu, Frank F and Araki, Jun and Neubig, Graham},
  journal={TACL},
  year={2020},
 }
 
 @article{lester2021power,
  title={The Power of Scale for Parameter-Efficient Prompt Tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={EMNLP},
  year={2021}
}

@article{hambardzumyan2021warp,
  title={WARP: Word-level Adversarial ReProgramming},
  author={Hambardzumyan, Karen and Khachatrian, Hrant and May, Jonathan},
  journal={ACL},
  year={2021}
}


@inproceedings{shin2020autoprompt,
    title = "{A}uto{P}rompt: {E}liciting {K}nowledge from {L}anguage {M}odels with {A}utomatically {G}enerated {P}rompts",
    author = "Shin, Taylor  and
      Razeghi, Yasaman  and
      Logan IV, Robert L.  and
      Wallace, Eric  and
      Singh, Sameer",
    booktitle = "EMNLP",
    year = "2020",
}

@article{Dodge2020fine-tuning,
author = {Dodge, Jesse and Ilharco, Gabriel and Schwartz, Roy and Farhadi, Ali and Hajishirzi, Hannaneh and Smith, Noah},
eprint = {2002.06305},
file = {:Users/ruder/drive/Papers/Fine-Tuning Pretrained Language Models- Weight Initializations, Data Orders, and Early Stopping.pdf:pdf},
journal = {arXiv preprint arXiv:2002.06305},
mendeley-groups = {Adaptation/Transfer Learning},
title = {{Fine-Tuning Pretrained Language Models: Weight Initializations, Data Orders, and Early Stopping}},
year = {2020}
}


@inproceedings{pfeiffer2020mad,
  title={MAD-X: An Adapter-based Framework for Multi-task Cross-lingual Transfer},
  author={Pfeiffer, Jonas and Vuli{\'c}, Ivan and Gurevych, Iryna and Ruder, Sebastian},
  booktitle={EMNLP},
  year={2020}
}

@inproceedings{Pfeiffer2021adapterfusion,
author = {Pfeiffer, Jonas and Kamath, Aishwarya and R{\"{u}}ckĺe, Andreas and Kyunghyun, Cho and Gurevych, Iryna},
booktitle = {EACL},
title = {{AdapterFusion: Non-destructive task composition for transfer learning}},
year = {2021}
}

@article{brock2021high,
  title={High-performance large-scale image recognition without normalization},
  author={Brock, Andrew and De, Soham and Smith, Samuel L and Simonyan, Karen},
  journal={ICML},
  year={2021}
}


@inproceedings{katharopoulos2020transformers,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={ICML},
  year={2020}
}

@article{ravfogel2021bitfit,
  title={Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked languagemodels},
  author={Ravfogel, Shauli and Ben-Zaken, Elad and Goldberg, Yoav},
  journal={arXiv preprint arXiv:2106.10199}
  year={2021}
}


@article{cai2020tinytl,
  title={TinyTL: Reduce Memory, Not Parameters for Efficient On-Device Learning},
  author={Cai, Han and Gan, Chuang and Zhu, Ligeng and Han, Song},
  journal={NeurIPS},
  year={2020}
}

@inproceedings{Chung2021rembert,
author = {Chung, Hyung Won and F{\'{e}}vry, Thibault and Tsai, Henry and Johnson, Melvin and Ruder, Sebastian},
booktitle = {ICLR},
title = {{Rethinking Embedding Coupling in Pre-trained Language Models}},
year = {2021}
}

@inproceedings{Zhang2021revisiting,
author = {Zhang, Tianyi and Wu, Felix and Katiyar, Arzoo and Weinberger, Kilian Q and Artzi, Yoav},
booktitle = {ICLR},
title = {{Revisiting Few-sample BERT Fine-tuning}},
year = {2021}
}

@article{wang2020linformer,
  title={Linformer: Self-attention with linear complexity},
  author={Wang, Sinong and Li, Belinda and Khabsa, Madian and Fang, Han and Ma, Hao},
  journal={arXiv preprint arXiv:2006.04768},
  year={2020}
}

@article{blalock2020state,
  title={What is the state of neural network pruning?},
  author={Blalock, Davis and Ortiz, Jose Javier Gonzalez and Frankle, Jonathan and Guttag, John},
  journal={arXiv preprint arXiv:2003.03033},
  year={2020}
}

@article{warstadt-etal-2019-neural,
    title = "Neural Network Acceptability Judgments",
    author = "Warstadt, Alex  and
      Singh, Amanpreet  and
      Bowman, Samuel R.",
    journal = "TACL",
    year = "2019"
}

@inproceedings{socher-etal-2013-recursive,
    title = "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    author = "Socher, Richard  and
      Perelygin, Alex  and
      Wu, Jean  and
      Chuang, Jason  and
      Manning, Christopher D.  and
      Ng, Andrew  and
      Potts, Christopher",
    booktitle = "EMNLP",
    year = "2013"
}

@inproceedings{dolan-brockett-2005-automatically,
    title = "Automatically Constructing a Corpus of Sentential Paraphrases",
    author = "Dolan, William B.  and
      Brockett, Chris",
    booktitle = "IWP",
    year = "2005"}
    
    @inproceedings{cer-etal-2017-semeval,
    title = "{S}em{E}val-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation",
    author = "Cer, Daniel  and
      Diab, Mona  and
      Agirre, Eneko  and
      Lopez-Gazpio, I{\~n}igo  and
      Specia, Lucia",
    booktitle = "{S}em{E}val",
    year = "2017"
}

@inproceedings{williams-etal-2018-broad,
    title = "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    author = "Williams, Adina  and
      Nangia, Nikita  and
      Bowman, Samuel",
    booktitle = "NAACL",
    year = "2018",
}

@inproceedings{rajpurkar-etal-2016-squad,
    title = "{SQ}u{AD}: 100,000+ Questions for Machine Comprehension of Text",
    author = "Rajpurkar, Pranav  and
      Zhang, Jian  and
      Lopyrev, Konstantin  and
      Liang, Percy",
    booktitle = "EMNLP",
    year = "2016"
}

@inproceedings{dagan2005pascal,
  title={The pascal recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine Learning Challenges Workshop},
  year={2005}
}

@article{rte2,
author = {Bar-Haim, Roy and Dagan, Ido and Dolan, Bill and Ferro, Lisa and Giampiccolo, Danilo},
year = {2006},
title = {The second PASCAL recognising textual entailment challenge},
journal = {Second PASCAL Challenges Workshop on Recognising Textual Entailment}
}

@inproceedings{giampiccolo-etal-2007-third,
    title = "The Third {PASCAL} Recognizing Textual Entailment Challenge",
    author = "Giampiccolo, Danilo  and
      Magnini, Bernardo  and
      Dagan, Ido  and
      Dolan, Bill",
    booktitle = "{ACL}-{PASCAL} Workshop on Textual Entailment and Paraphrasing",
    year = "2007"}
    
@INPROCEEDINGS{Bentivogli09thefifth,
    author = {Luisa Bentivogli and Ido Dagan and Hoa Trang Dang and Danilo Giampiccolo and Bernardo Magnini},
    title = {The Fifth PASCAL Recognizing Textual Entailment Challenge},
    booktitle = {TAC},
    year = {2009}
}

@inproceedings{levesque2012winograd,
  title={The winograd schema challenge},
  author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},
  booktitle={KR},
  year={2012}
}

@article{Perez2021true,
author = {Perez, Ethan and Kiela, Douwe and Cho, Kyunghyun},
eprint = {2105.11447},
file = {:Users/ruder/drive/Papers/2105.11447.pdf:pdf},
journal = {arXiv preprint arXiv:2105.11447},
title = {{True Few-Shot Learning with Language Models}},
url = {http://arxiv.org/abs/2105.11447},
year = {2021}
}

@inproceedings{arora2018optimization,
  title={On the optimization of deep networks: Implicit acceleration by overparameterization},
  author={Arora, Sanjeev and Cohen, Nadav and Hazan, Elad},
  booktitle={ICML},
  year={2018}
  }


@inproceedings{wang2019superglue,
  title={SuperGLUE: a stickier benchmark for general-purpose language understanding systems},
  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  booktitle={NeurIPS},
  year={2019}
}


@inproceedings{
pilault2021conditionally,
title={Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in {NLP} Using Fewer Parameters \& Less Data},
author={Jonathan Pilault and Amine El hattami and Christopher Pal},
booktitle={ICLR},
year={2021}
}


@inproceedings{wang2019superglue,
  title={SuperGLUE: a stickier benchmark for general-purpose language understanding systems},
  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  booktitle={NeurIPS},
  year={2019}
}




@inproceedings{roemmele2011choice,
  title={Choice of plausible alternatives: An evaluation of commonsense causal reasoning},
  author={Roemmele, Melissa and Bejan, Cosmin Adrian and Gordon, Andrew S},
  booktitle={AAAI Spring Symposium Series},
  year={2011}
}

@inproceedings{de2019commitmentbank,
  title={The CommitmentBank: Investigating projection in naturally occurring discourse},
  author={De Marneffe, Marie-Catherine and Simons, Mandy and Tonhauser, Judith},
  booktitle={proceedings of Sinn und Bedeutung},
  year={2019}
}


@inproceedings{khashabi2018looking,
  title={Looking beyond the surface: A challenge set for reading comprehension over multiple sentences},
  author={Khashabi, Daniel and Chaturvedi, Snigdha and Roth, Michael and Upadhyay, Shyam and Roth, Dan},
  booktitle={NAACL},
  year={2018}
}


@article{zhang2018record,
  title={Record: Bridging the gap between human and machine commonsense reading comprehension},
  author={Zhang, Sheng and Liu, Xiaodong and Liu, Jingjing and Gao, Jianfeng and Duh, Kevin and Van Durme, Benjamin},
  journal={arXiv preprint arXiv:1810.12885},
  year={2018}
}

@inproceedings{pilehvar2019wic,
  title={WiC: the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations},
  author={Pilehvar, Mohammad Taher and Camacho-Collados, Jose},
  booktitle={NAACL},
  year={2019}
}


@inproceedings{clark-etal-2019-boolq,
    title = "{B}ool{Q}: Exploring the Surprising Difficulty of Natural Yes/No Questions",
    author = "Clark, Christopher  and
      Lee, Kenton  and
      Chang, Ming-Wei  and
      Kwiatkowski, Tom  and
      Collins, Michael  and
      Toutanova, Kristina",
    booktitle = "NAACL",
    year = "2019"
    }


@article{miller1995wordnet,
  title={WordNet: a lexical database for English},
  author={Miller, George A},
  journal={Communications of the ACM},
  year={1995}
  }
  
  
  @article{schuler2005verbnet,
  title={VerbNet: A broad-coverage, comprehensive verb lexicon},
  author={Schuler, Karin Kipper},
  journal={PhD Thesis},
  year={2005}
}