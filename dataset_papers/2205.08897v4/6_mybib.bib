@article{Relative-Error-CUR-Matrix-Decompositions,
  author    = {Petros Drineas and
               Michael W. Mahoney and
               S. Muthukrishnan},
  title     = {Relative-Error {CUR} Matrix Decompositions},
  journal   = {CoRR},
  volume    = {abs/0708.3696},
  year      = {2007},
  eprinttype = {arXiv},
  eprint    = {0708.3696}
}

@article{Fourier-Neural-Operator,
author    = {Zongyi Li and
               Nikola B. Kovachki and
               Kamyar Azizzadenesheli and
               Burigede Liu and
               Kaushik Bhattacharya and
               Andrew M. Stuart and
               Anima Anandkumar},
  title     = {Fourier Neural Operator for Parametric Partial Differential Equations},
  journal   = {CoRR},
  volume    = {abs/2010.08895},
  year      = {2020},
  eprinttype = {arXiv},
  eprint    = {2010.08895}
}


% Robust Decomp
@inproceedings{WenRobustPeriod20,
author = {Wen, Qingsong and He, Kai and Sun, Liang and Zhang, Yingying and Ke, Min and Xu, Huan},
title = {{RobustPeriod}: Time-Frequency Mining for Robust Multiple Periodicity Detection},
  booktitle={Proceedings of the 2021 International Conference on Management of Data (SIGMOD '21)},
  pages={205--215},
  year={2021}
}

@inproceedings{wen2020fastrobustSTL,
  title={Fast {RobustSTL}: Efficient and Robust Seasonal-Trend Decomposition for Time Series with Complex Patterns},
  author={Wen, Qingsong and Zhang, Zhe and Li, Yan and Sun, Liang},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining (KDD '20)},
  pages={2203--2213},
  year={2020}
}

@inproceedings{wen2019robuststl,
  title={{RobustSTL}: A robust seasonal-trend decomposition algorithm for long time series},
  author={Wen, Qingsong and Gao, Jingkun and Song, Xiaomin and Sun, Liang and Xu, Huan and Zhu, Shenghuo},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={5409--5416},
  year={2019}
}


@article{cleveland1990stl,
  title={{STL}: A seasonal-trend decomposition},
  author={Cleveland, Robert B and Cleveland, William S and McRae, Jean E and Terpenning, Irma},
  journal={Journal of official statistics},
  volume={6},
  number={1},
  pages={3--73},
  year={1990}
}

@inproceedings{wang2018multilevel,
  title={Multilevel wavelet decomposition network for interpretable time series analysis},
  author={Wang, Jingyuan and Wang, Ze and Li, Jianfeng and Wu, Junjie},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2437--2446},
  year={2018}
}


@inproceedings{Multiwavelet-based-Operator-Learning,
      author    = {Gaurav Gupta and
               Xiongye Xiao and
               Paul Bogdan},
  title     = {Multiwavelet-based Operator Learning for Differential Equations},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS), 2021, December
               6-14, 2021, virtual},
  pages     = {24048--24062},
  year      = {2021}
}


@inproceedings{DBLP:conf/iclr/KitaevKL20-reformer,
  author    = {Nikita Kitaev and
               Lukasz Kaiser and
               Anselm Levskaya},
  title     = {Reformer: The Efficient Transformer},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  year      = {2020}
}

@article{DBLP:journals/corr/abs-2006-04768-linformer,
  author    = {Sinong Wang and
               Belinda Z. Li and
               Madian Khabsa and
               Han Fang and
               Hao Ma},
  title     = {Linformer: Self-Attention with Linear Complexity},
  journal   = {CoRR},
  volume    = {abs/2006.04768},
  year      = {2020},
  eprinttype = {arXiv},
  eprint    = {2006.04768}
}

 

@article{DBLP:journals/corr/FlunkertSG17-deepAR,
  title={{DeepAR}: Probabilistic forecasting with autoregressive recurrent networks},
  author={Salinas, David and Flunkert, Valentin and Gasthaus, Jan and Januschowski, Tim},
  journal={International Journal of Forecasting},
  volume={36},
  number={3},
  pages={1181--1191},
  year={2020}
}


@inproceedings{Autoformer,
  title={Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting},
  author    = {Haixu Wu and
              Jiehui Xu and
              Jianmin Wang and
              Mingsheng Long},
  booktitle={Proceedings of the Advances in Neural Information Processing Systems (NeurIPS)},
  pages = {101--112},
  year={2021}
}




@inproceedings{haoyietal-informer-2021,
  author    = {Haoyi Zhou and
               Shanghang Zhang and
               Jieqi Peng and
               Shuai Zhang and
               Jianxin Li and
               Hui Xiong and
               Wancai Zhang},
  title     = {Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting},
  booktitle = {The Thirty-Fifth {AAAI} Conference on Artificial Intelligence, {AAAI} 2021, Virtual Conference},
  volume    = {35},
  number    = {12},
  pages     = {11106--11115},
  year      = {2021},
}


@inproceedings{Log-transformer-shiyang-2019,
 author = {Li, Shiyang and Jin, Xiaoyong and Xuan, Yao and Zhou, Xiyou and Chen, Wenhu and Wang, Yu-Xiang and Yan, Xifeng},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 title = {Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting},
 volume = {32},
 year = {2019}
}


@article{hochreiter_long_1997_lstm,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667, 1530-888X},
	language = {en},
	number = {8},
	urldate = {2019-11-20},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, JÃ¼rgen},
	month = nov,
	year = {1997},
	pages = {1735--1780}
}

@article{GRU_cho_et_al_2014,
  author    = {Junyoung Chung and
               {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
               KyungHyun Cho and
               Yoshua Bengio},
  title     = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence
               Modeling},
  journal   = {CoRR},
  volume    = {abs/1412.3555},
  year      = {2014},
  eprinttype = {arXiv},
  eprint    = {1412.3555}
}
% a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout




@inproceedings{box_distribution_1970,
author = { G. E. P.   Box  and  David A.   Pierce },
title = {Distribution of Residual Autocorrelations in Autoregressive-Integrated Moving Average Time Series Models},
journal = {Journal of the American Statistical Association},
volume = {65},
number = {332},
pages = {1509-1526},
year  = {1970},
publisher = {Taylor \& Francis}
        }
        
@article{box_arima2,
 author = {G. E. P. Box and G. M. Jenkins},
 journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
 number = {2},
 pages = {91--109},
 title = {Some Recent Advances in Forecasting and Control},
 volume = {17},
 year = {1968}
}



        
        
 

@article{attention_is_all_you_need,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{kingma_adam:_2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	language = {en},
	urldate = {2019-12-16},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015}
}



@incollection{NEURIPS2019_9015_pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems},
pages = {8024--8035},
year = {2019}
}

@inproceedings{lai2018modeling-exchange-dataset,
  title={Modeling long-and short-term temporal patterns with deep neural networks},
  author={Lai, Guokun and Chang, Wei-Cheng and Yang, Yiming and Liu, Hanxiao},
  booktitle={The 41st International ACM SIGIR Conference on Research \& Development in Information Retrieval},
  pages={95--104},
  year={2018}
}

@inproceedings{DBLP:MathieuHL13_fft_in_covolution,
  author    = {Micha{\"{e}}l Mathieu and
               Mikael Henaff and
               Yann LeCun},
  title     = {Fast Training of Convolutional Networks through FFTs},
  booktitle = {2nd International Conference on Learning Representations (ICLR),
               Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  year      = {2014}
}


 

@article{DBLP:Global-filter-FNO-in-cv,
  title={Global filter networks for image classification},
  author={Rao, Yongming and Zhao, Wenliang and Zhu, Zheng and Lu, Jiwen and Zhou, Jie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@inproceedings{DBLP:conf/aaai/XiongZCTFLS21/Nystroformer,
  author    = {Yunyang Xiong and
               Zhanpeng Zeng and
               Rudrasis Chakraborty and
               Mingxing Tan and
               Glenn Fung and
               Yin Li and
               Vikas Singh},
  title     = {Nystr{\"{o}}mformer: {A} Nystr{\"{o}}m-based Algorithm for
               Approximating Self-Attention},
  booktitle = {Thirty-Fifth {AAAI} Conference on Artificial Intelligence},
  pages     = {14138--14148},
  year      = {2021}
}

@inproceedings{DBLP:conf/acl/H-transformer,
  author    = {Zhenhai Zhu and
               Radu Soricut},
  title     = {H-Transformer-1D: Fast One-Dimensional Hierarchical Attention for Sequences},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational
               Linguistics (ACL) 2021, Virtual
               Event, August 1-6, 2021},
  pages     = {3801--3815},
  year      = {2021}
}

@inproceedings{DBLP:icml/On-the-difficult-gradient-vanishing-explode,
  author    = {Razvan Pascanu and
               Tom{\'{a}}s Mikolov and
               Yoshua Bengio},
  title     = {On the difficulty of training recurrent neural networks},
  booktitle = {Proceedings of the 30th International Conference on Machine Learning,
               {ICML} 2013, Atlanta, GA, USA, 16-21 June 2013},
  volume    = {28},
  pages     = {1310--1318},
  year      = {2013}
}

@INPROCEEDINGS{IEEE-Homayouni-Autocorrelation-LSTM-anomaly-detection,
  author={Homayouni, Hajar and Ghosh, Sudipto and Ray, Indrakshi and Gondalia, Shlok and Duggan, Jerry and Kahn, Michael G.},
  booktitle={2020 IEEE International Conference on Big Data (Big Data)}, 
  title={An Autocorrelation-based LSTM-Autoencoder for Anomaly Detection on Time-Series Data}, 
  year={2020},
  volume={},
  number={},
  pages={5068-5077}}

@article{DBLP:journals/corr/LUNA,
author    = {Xuezhe Ma and
           Xiang Kong and
           Sinong Wang and
           Chunting Zhou and
           Jonathan May and
           Hao Ma and
           Luke Zettlemoyer},
title     = {Luna: Linear Unified Nested Attention},
journal   = {CoRR},
volume    = {abs/2106.01540},
year      = {2021},
eprinttype = {arXiv},
eprint    = {2106.01540},
}

@inproceedings{DBLP:conf/nips/Zaheer/BIGBIRD,
  author    = {Manzil Zaheer and
               Guru Guruganesh and
               Kumar Avinava Dubey and
               Joshua Ainslie and
               Chris Alberti and
               Santiago Onta{\~{n}}{\'{o}}n and
               Philip Pham and
               Anirudh Ravula and
               Qifan Wang and
               Li Yang and
               Amr Ahmed},
  title     = {Big Bird: Transformers for Longer Sequences},
  booktitle = {Annual Conference on Neural Information Processing Systems (NeurIPS), December
               6-12, 2020, virtual},
  year      = {2020}
}

@inproceedings{DBLP:conf/iclr/Choromanski/Performer,
  author    = {Krzysztof Marcin Choromanski and
               Valerii Likhosherstov and
               David Dohan and
               Xingyou Song and
               Andreea Gane and
               Tam{\'{a}}s Sarl{\'{o}}s and
               Peter Hawkins and
               Jared Quincy Davis and
               Afroz Mohiuddin and
               Lukasz Kaiser and
               David Benjamin Belanger and
               Lucy J. Colwell and
               Adrian Weller},
  title     = {Rethinking Attention with Performers},
  booktitle = {9th International Conference on Learning Representations (ICLR),
               Virtual Event, Austria, May 3-7, 2021},
  year      = {2021}
}

@inproceedings{Hassanieh/simple-pratical-algo-sparse-fourier-transform,
author = {Hassanieh, Haitham and Indyk, Piotr and Katabi, Dina and Price, Eric},
title = {Simple and Practical Algorithm for Sparse Fourier Transform},
year = {2012},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
booktitle = {Proceedings of the Twenty-Third Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {1183â1194},
numpages = {12},
location = {Kyoto, Japan},
series = {SODA '12}}

@ARTICLE{Tao/Near-Optimal-Signal-Recovery-From-Random-Projections,  author={Candes, Emmanuel J. and Tao, Terence},  journal={IEEE Transactions on Information Theory},   title={Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?},   year={2006},  volume={52},  number={12},  pages={5406-5425}}

@inproceedings{deep-state-space-models-for-time-series-forecasting,
 author = {Rangapuram, Syama Sundar and Seeger, Matthias W and Gasthaus, Jan and Stella, Lorenzo and Wang, Yuyang and Januschowski, Tim},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 title = {Deep State Space Models for Time Series Forecasting},
 volume = {31},
 year = {2018}
}
  
  
@article{on-sparse-reconstruction-fourier-is-rip,
author = {Rudelson, Mark and Vershynin, Roman},
title = {On sparse reconstruction from Fourier and Gaussian measurements},
journal = {Communications on Pure and Applied Mathematics},
volume = {61},
number = {8},
pages = {1025-1045}
}

@article{Johnson1984ExtensionsOL,
  title={Extensions of Lipschitz mappings into Hilbert space},
  author={William B. Johnson},
  journal={Contemporary mathematics},
  year={1984},
  volume={26},
  pages={189-206}
}

@article{robust-concepets-random-projection-arriaga-vempala-2006,
  author    = {Rosa I. Arriaga and
               Santosh S. Vempala},
  title     = {An algorithmic theory of learning: Robust concepts and random projection},
  journal   = {Mach. Learn.},
  volume    = {63},
  number    = {2},
  pages     = {161--182},
  year      = {2006}
}

@inproceedings{dual-state-attention-rnn-qin,
  author    = {Yao Qin and
               Dongjin Song and
               Haifeng Chen and
               Wei Cheng and
               Guofei Jiang and
               Garrison W. Cottrell},
  title     = {A Dual-Stage Attention-Based Recurrent Neural Network for Time Series
               Prediction},
  booktitle = {Proceedings of the Twenty-Sixth International Joint Conference on
               Artificial Intelligence (IJCAI), Melbourne, Australia, August
               19-25, 2017},
  pages     = {2627--2633},
  publisher = {ijcai.org},
  year      = {2017}
}
% a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout


@inproceedings{Think_globally_act_locally_tcn_time_series_2019,
  author    = {Rajat Sen and
               Hsiang{-}Fu Yu and
               Inderjit S. Dhillon},
  title     = {Think Globally, Act Locally: {A} Deep Neural Network Approach to High-Dimensional
               Time Series Forecasting},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS), December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {4838--4847},
  year      = {2019}
}
@inproceedings{Bert/NAACL/Jacob,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), Minneapolis, MN, USA, June 2-7, 2019},
  pages     = {4171--4186},
  year      = {2019}
}

@inproceedings{liu2022pyraformer,
title={Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting},
author={Liu, Shizhan and Yu, Hang and Liao, Cong and Li, Jianguo and Lin, Weiyao and Liu, Alex X and Dustdar, Schahram},
booktitle={International Conference on Learning Representations},
year={2022}
}

@inproceedings{Transformers-for-image-at-scale/iclr/DosovitskiyB0WZ21,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition
               at Scale},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  year      = {2021}
}

@inproceedings{Block-wise-attention/emnlp/QiuMLYW020,
  author    = {Jiezhong Qiu and
               Hao Ma and
               Omer Levy and
               Wen{-}tau Yih and
               Sinong Wang and
               Jie Tang},
  title     = {Blockwise Self-Attention for Long Document Understanding},
  booktitle = {Findings of the Association for Computational Linguistics: {EMNLP}
               2020, Online Event, 16-20 November 2020},
  series    = {Findings of {ACL}},
  volume    = {{EMNLP} 2020},
  pages     = {2555--2565},
  publisher = {Association for Computational Linguistics},
  year      = {2020}
}

@article{Longformer/2020/Iz-Beltagy/corr/abs-2004-05150,
  author    = {Iz Beltagy and
               Matthew E. Peters and
               Arman Cohan},
  title     = {Longformer: The Long-Document Transformer},
  journal   = {CoRR},
  volume    = {abs/2004.05150},
  year      = {2020},
  eprinttype = {arXiv},
  eprint    = {2004.05150}
}

@inproceedings{sparse-sinkhorn-attention/YiTay/icml/TayBYMJ20,
  author    = {Yi Tay and
               Dara Bahri and
               Liu Yang and
               Donald Metzler and
               Da{-}Cheng Juan},
  title     = {Sparse Sinkhorn Attention},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning,
               {ICML} 2020, 13-18 July 2020, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {119},
  pages     = {9438--9447},
  publisher = {{PMLR}},
  year      = {2020}
}

@inproceedings{Random-features-for-large-scale-kernel-machines/NIPS2007_013a006f,
 author = {Rahimi, Ali and Recht, Benjamin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Platt and D. Koller and Y. Singer and S. Roweis},
 pages = {},
 title = {Random Features for Large-Scale Kernel Machines},
 volume = {20},
 year = {2008}
}

@inproceedings{Sampled-softmax-with-random-Fourier-Features/nips/RawatCYSK19,
  author    = {Ankit Singh Rawat and
               Jiecao Chen and
               Felix X. Yu and
               Ananda Theertha Suresh and
               Sanjiv Kumar},
  title     = {Sampled Softmax with Random Fourier Features},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS), December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {13834--13844},
  year      = {2019}
}

@article{donoho2006compressed,
  title={Compressed sensing},
  author={Donoho, David L},
  journal={IEEE Transactions on information theory},
  volume={52},
  number={4},
  pages={1289--1306},
  year={2006},
  publisher={IEEE}
}

@inproceedings{tropp2006random,
  title={Random filters for compressive sampling and reconstruction},
  author={Tropp, Joel A and Wakin, Michael B and Duarte, Marco F and Baron, Dror and Baraniuk, Richard G},
  booktitle={2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings},
  volume={3},
  pages={III--III},
  year={2006},
  organization={IEEE}
}

@inproceedings{nbeats,
  title={{N-BEATS}: Neural basis expansion analysis for interpretable time series forecasting},
  author={Oreshkin, Boris N and Carpov, Dmitri and Chapados, Nicolas and Bengio, Yoshua},
  booktitle={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2019}
}

@article{FNet,
  author    = {James Lee{-}Thorp and
               Joshua Ainslie and
               Ilya Eckstein and
               Santiago Onta{\~{n}}{\'{o}}n},
  title     = {{FNet}: Mixing Tokens with Fourier Transforms},
  journal   = {CoRR},
  volume    = {abs/2105.03824},
  year      = {2021},
  eprinttype = {arXiv},
  eprint    = {2105.03824}
}


@inproceedings{FedFormer,
  title={{FEDformer}: Frequency enhanced decomposed transformer for long-term series forecasting},
  author={Zhou, Tian and Ma, Ziqing and Wen, Qingsong and Wang, Xue and Sun, Liang and Jin, Rong},
  booktitle={39th International Conference on Machine Learning (ICML)},
  year={2022}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}


@article{S4,
  title={Efficiently Modeling Long Sequences with Structured State Spaces},
  author={Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2111.00396},
  year={2021}
}
 
@article{LSSL,
  title={Combining Recurrent, Convolutional, and Continuous-time Models with Linear State Space Layers},
  author={Gu, Albert and Johnson, Isys and Goel, Karan and Saab, Khaled and Dao, Tri and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@article{Hippo,
  title={Hippo: Recurrent memory with optimal polynomial projections},
  author={Gu, Albert and Dao, Tri and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1474--1487},
  year={2020}
}

@inproceedings{LMU,
 author = {Voelker, Aaron and Kaji\'{c}, Ivana and Eliasmith, Chris},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 title = {Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks},
 volume = {32},
 year = {2019}
}




@article{LRA,
  title={Long range arena: A benchmark for efficient transformers},
  author={Tay, Yi and Dehghani, Mostafa and Abnar, Samira and Shen, Yikang and Bahri, Dara and Pham, Philip and Rao, Jinfeng and Yang, Liu and Ruder, Sebastian and Metzler, Donald},
  journal={arXiv preprint arXiv:2011.04006},
  year={2020}
}



@inproceedings{reversible,
  title={Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift},
  author={Kim, Taesung and Kim, Jinhee and Tae, Yunwon and Park, Cheonbok and Choi, Jang-Ho and Choo, Jaegul},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

 @article{wen2022transformers,
      title={Transformers in Time Series: A Survey}, 
      author={Qingsong Wen and Tian Zhou and Chaoli Zhang and Weiqi Chen and Ziqing Ma and Junchi Yan and Liang Sun},
  journal={arXiv preprint arXiv:2202.07125},
  year={2022}
}

@inproceedings{FourierRecurrentUnits,
  author    = {Jiong Zhang and
               Yibo Lin and
               Zhao Song and
               Inderjit S. Dhillon},
  title     = {Learning Long Term Dependencies via Fourier Recurrent Units},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning (ICML), Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July
               10-15, 2018},
  volume    = {80},
  pages     = {5810--5818},
  year      = {2018}
}

@article{challu2022n,
  title={N-hits: Neural hierarchical interpolation for time series forecasting},
  author={Challu, Cristian and Olivares, Kin G and Oreshkin, Boris N and Garza, Federico and Mergenthaler, Max and Dubrawski, Artur},
  journal={arXiv preprint arXiv:2201.12886},
  year={2022}
}

@article{seasonal-naive,
author = {Makridakis, S. and Andersen, A. and Carbone, R. and Fildes, R. and Hibon, M. and Lewandowski, R. and Newton, J. and Parzen, E. and Winkler, R.},
title = {The accuracy of extrapolation (time series) methods: Results of a forecasting competition},
journal = {Journal of Forecasting},
volume = {1},
number = {2},
pages = {111-153},
keywords = {Forecasting, Time series, Evaluation, Accuracy, Comparison, Empirical study},
doi = {https://doi.org/10.1002/for.3980010202},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/for.3980010202},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/for.3980010202},
abstract = {Abstract In the last few decades many methods have become available for forecasting. As always, when alternatives exist, choices need to be made so that an appropriate forecasting method can be selected and used for the specific situation being considered. This paper reports the results of a forecasting competition that provides information to facilitate such choice. Seven experts in each of the 24 methods forecasted up to 1001 series for six up to eighteen time horizons. The results of the competition are presented in this paper whose purpose is to provide empirical evidence about differences found to exist among the various extrapolative (time series) methods used in the competition.},
year = {1982}
}