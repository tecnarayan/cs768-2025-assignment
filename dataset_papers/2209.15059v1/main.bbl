\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Barcel{\'o} et~al.(2020)Barcel{\'o}, Kostylev, Monet, P{\'e}rez,
  Reutter, and Silva]{Barcelo2020}
P.~Barcel{\'o}, E.~V. Kostylev, M.~Monet, J.~P{\'e}rez, J.~L. Reutter, and
  J.-P. Silva.
\newblock The logical expressiveness of graph neural networks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Cappart et~al.(2021)Cappart, Ch{\'{e}}telat, Khalil, Lodi, Morris, and
  Velickovic]{Cappart21}
Q.~Cappart, D.~Ch{\'{e}}telat, E.~B. Khalil, A.~Lodi, C.~Morris, and
  P.~Velickovic.
\newblock Combinatorial optimization and reasoning with graph neural networks.
\newblock In \emph{International Joint Conference on Artificial Intelligence
  (IJCAI)}, 2021.

\bibitem[Chamberlain et~al.(2021)Chamberlain, Rowbottom, Gorinova, Bronstein,
  Webb, and Rossi]{Grand21}
B.~Chamberlain, J.~Rowbottom, M.~Gorinova, M.~M. Bronstein, S.~Webb, and
  E.~Rossi.
\newblock {GRAND:} graph neural diffusion.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2021.

\bibitem[Chen et~al.(2020)Chen, Wei, Huang, Ding, and Li]{chen2020}
M.~Chen, Z.~Wei, Z.~Huang, B.~Ding, and Y.~Li.
\newblock Simple and deep graph convolutional networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Cho et~al.(2014)Cho, van Merri{\"e}nboer, Gulcehre, Bahdanau,
  Bougares, Schwenk, and Bengio]{GRU}
K.~Cho, B.~van Merri{\"e}nboer, C.~Gulcehre, D.~Bahdanau, F.~Bougares,
  H.~Schwenk, and Y.~Bengio.
\newblock Learning phrase representations using {RNN} encoder{--}decoder for
  statistical machine translation.
\newblock In \emph{Empirical Methods in Natural Language Processing ({EMNLP})},
  2014.

\bibitem[Dehmamy et~al.(2019)Dehmamy, Barab{\'a}si, and
  Yu]{dehmamy2019understanding}
N.~Dehmamy, A.-L. Barab{\'a}si, and R.~Yu.
\newblock Understanding the representation power of graph neural networks in
  learning graph topology.
\newblock In \emph{Advances in neural information processing systems
  (NeurIPS)}, 2019.

\bibitem[Derrow-Pinion et~al.(2021)Derrow-Pinion, She, Wong, Lange, Hester,
  Perez, Nunkesser, Lee, Guo, Wiltshire, Battaglia, Gupta, Li, Xu,
  Sanchez-Gonzalez, Li, and Velickovic]{Pinion2021}
A.~Derrow-Pinion, J.~She, D.~Wong, O.~Lange, T.~Hester, L.~Perez, M.~Nunkesser,
  S.~Lee, X.~Guo, B.~Wiltshire, P.~W. Battaglia, V.~Gupta, A.~Li, Z.~Xu,
  A.~Sanchez-Gonzalez, Y.~Li, and P.~Velickovic.
\newblock Eta prediction with graph neural networks in google maps.
\newblock In \emph{Conference on Information and Knowledge Management (CIKM)},
  2021.

\bibitem[Du et~al.(2019)Du, Hou, Salakhutdinov, P{\'{o}}czos, Wang, and
  Xu]{du2019}
S.~S. Du, K.~Hou, R.~Salakhutdinov, B.~P{\'{o}}czos, R.~Wang, and K.~Xu.
\newblock Graph neural tangent kernel: Fusing graph neural networks with graph
  kernels.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem[Garg et~al.(2020)Garg, Jegelka, and Jaakkola]{Garg2020}
V.~Garg, S.~Jegelka, and T.~Jaakkola.
\newblock Generalization and representational limits of graph neural networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Gilmer et~al.(2017)Gilmer, Schoenholz, Riley, Vinyals, and
  Dahl]{Gilmer2017}
J.~Gilmer, S.~S. Schoenholz, P.~F. Riley, O.~Vinyals, and G.~E. Dahl.
\newblock Neural message passing for quantum chemistry.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2017.

\bibitem[Gori et~al.(2005)Gori, Monfardini, and Scarselli]{Gori2005}
M.~Gori, G.~Monfardini, and F.~Scarselli.
\newblock A new model for learning in graph domains.
\newblock In \emph{IEEE International Joint Conference on Neural Networks
  (IJCNN)}, 2005.

\bibitem[Hamilton et~al.(2017)Hamilton, Ying, and Leskovec]{graphsage}
W.~Hamilton, Z.~Ying, and J.~Leskovec.
\newblock Inductive representation learning on large graphs.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2017.

\bibitem[Hochreiter and Schmidhuber(1997)]{lstm}
S.~Hochreiter and J.~Schmidhuber.
\newblock Long short-term memory.
\newblock \emph{Neural Computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Kazemi et~al.(2020)Kazemi, Goel, Jain, Kobyzev, Sethi, Forsyth, and
  Poupart]{Kazemi2020}
S.~Kazemi, R.~Goel, K.~Jain, I.~Kobyzev, A.~Sethi, P.~Forsyth, and P.~Poupart.
\newblock Representation learning for dynamic graphs: A survey.
\newblock \emph{Journal of Machine Learning Research}, 21\penalty0
  (70):\penalty0 1--73, 2020.

\bibitem[Kazemi et~al.(2019)Kazemi, Goel, Eghbali, Ramanan, Sahota, Thakur, Wu,
  Smyth, Poupart, and Brubaker]{Kazemi2019}
S.~M. Kazemi, R.~Goel, S.~Eghbali, J.~Ramanan, J.~Sahota, S.~Thakur, S.~Wu,
  C.~Smyth, P.~Poupart, and M.~Brubaker.
\newblock Time2vec: Learning a vector representation of time.
\newblock \emph{ArXiv: 1907.05321}, 2019.

\bibitem[Kumar et~al.(2019)Kumar, Zhang, and Leskovec]{jodie}
S.~Kumar, X.~Zhang, and J.~Leskovec.
\newblock Predicting dynamic embedding trajectory in temporal interaction
  networks.
\newblock In \emph{International Conference on Knowledge Discovery \& Data
  Mining (KDD)}, 2019.

\bibitem[Liao et~al.(2021)Liao, Urtasun, and Zemel]{liao2021}
R.~Liao, R.~Urtasun, and R.~Zemel.
\newblock A {PAC}-bayesian approach to generalization bounds for graph neural
  networks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2021.

\bibitem[Liben-Nowell and Kleinberg(2007)]{Kleinberg2007}
D.~Liben-Nowell and J.~Kleinberg.
\newblock The link prediction problem for social networks.
\newblock \emph{Journal of the American Society for Information Science and
  Technology}, 58\penalty0 (7):\penalty0 1019--1031, 2007.

\bibitem[Loukas(2020{\natexlab{a}})]{Loukas2020}
A.~Loukas.
\newblock What graph neural networks cannot learn: depth vs width.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020{\natexlab{a}}.

\bibitem[Loukas(2020{\natexlab{b}})]{Loukas2020-how-hard}
A.~Loukas.
\newblock How hard is to distinguish graphs with graph neural networks?
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2020{\natexlab{b}}.

\bibitem[Maron et~al.(2019)Maron, Ben-Hamu, Serviansky, and Lipman]{Maron2019}
H.~Maron, H.~Ben-Hamu, H.~Serviansky, and Y.~Lipman.
\newblock Provably powerful graph networks.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem[Morris et~al.(2019)Morris, Ritzert, Fey, Hamilton, Lenssen, Rattan,
  and Grohe]{Morris2019}
C.~Morris, M.~Ritzert, M.~Fey, W.~L. Hamilton, J.~E. Lenssen, G.~Rattan, and
  M.~Grohe.
\newblock Weisfeiler and leman go neural: Higher-order graph neural networks.
\newblock In \emph{AAAI Conference on Artificial Intelligence (AAAI)}, 2019.

\bibitem[Nguyen and Maehara(2020)]{pmlr-v119-nguyen20c}
H.~Nguyen and T.~Maehara.
\newblock Graph homomorphism convolution.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Orsini et~al.(2015)Orsini, Frasconi, and Raedt]{Orsini2015}
F.~Orsini, P.~Frasconi, and L.~D. Raedt.
\newblock Graph invariant kernels.
\newblock In \emph{International Joint Conference on Artificial Intelligence
  (IJCAI)}, 2015.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{pytorch}
A.~Paszke, S.~Gross, S.~Chintala, G.~Chanan, E.~Yang, Z.~DeVito, Z.~Lin,
  A.~Desmaison, L.~Antiga, and A.~Lerer.
\newblock Automatic differentiation in pytorch.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS -
  Workshop)}, 2017.

\bibitem[Pérez et~al.(2019)Pérez, Marinković, and Barceló]{Perez2019}
J.~Pérez, J.~Marinković, and P.~Barceló.
\newblock On the turing completeness of modern neural network architectures.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Rossi et~al.(2020)Rossi, Chamberlain, Frasca, Eynard, Monti, and
  Bronstein]{tgn}
E.~Rossi, B.~Chamberlain, F.~Frasca, D.~Eynard, E.~Monti, and M.~Bronstein.
\newblock Temporal graph networks for deep learning on dynamic graphs.
\newblock In \emph{ICML 2020 Workshop on Graph Representation Learning}, 2020.

\bibitem[Sanchez-Gonzalez et~al.(2020)Sanchez-Gonzalez, Godwin, Pfaff, Ying,
  Leskovec, and Battaglia]{ComplexPhysics}
A.~Sanchez-Gonzalez, J.~Godwin, T.~Pfaff, R.~Ying, J.~Leskovec, and
  P.~Battaglia.
\newblock Learning to simulate complex physics with graph networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Sato et~al.(2019)Sato, Yamada, and Kashima]{Sato2019}
R.~Sato, M.~Yamada, and H.~Kashima.
\newblock Approximation ratios of graph neural networks for combinatorial
  problems.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem[Scarselli et~al.(2009)Scarselli, Gori, Tsoi, Hagenbuchner, and
  Monfardini]{scarselli2009}
F.~Scarselli, M.~Gori, A.~C. Tsoi, M.~Hagenbuchner, and G.~Monfardini.
\newblock The graph neural network model.
\newblock \emph{IEEE Transactions on Neural Networks}, 20\penalty0
  (1):\penalty0 61–80, 2009.

\bibitem[Stokes et~al.(2020)Stokes, Yang, Swanson, Jin, Cubillos-Ruiz, Donghia,
  MacNair, French, Carfrae, Bloom-Ackermann, Tran, Chiappino-Pepe, Badran,
  Andrews, Chory, Church, Brown, Jaakkola, Barzilay, and
  Collins]{antibiotic_design}
J.~M. Stokes, K.~Yang, K.~Swanson, W.~Jin, A.~Cubillos-Ruiz, N.~M. Donghia,
  C.~R. MacNair, S.~French, L.~A. Carfrae, Z.~Bloom-Ackermann, V.~M. Tran,
  A.~Chiappino-Pepe, A.~H. Badran, I.~W. Andrews, E.~J. Chory, G.~M. Church,
  E.~D. Brown, T.~S. Jaakkola, R.~Barzilay, and J.~J. Collins.
\newblock A deep learning approach to antibiotic discovery.
\newblock \emph{Cell}, 180\penalty0 (4):\penalty0 688 -- 702, 2020.

\bibitem[Trivedi et~al.(2019)Trivedi, Farajtabar, Biswal, and Zha]{DyRep}
R.~Trivedi, M.~Farajtabar, P.~Biswal, and H.~Zha.
\newblock {DyRep}: Learning representations over dynamic graphs.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{Vaswani2017}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  L.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2017.

\bibitem[Velickovic et~al.(2018)Velickovic, Cucurull, Casanova, Romero,
  Li{\`o}, and Bengio]{gat}
P.~Velickovic, G.~Cucurull, A.~Casanova, A.~Romero, P.~Li{\`o}, and Y.~Bengio.
\newblock {G}raph {A}ttention {N}etworks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Verma and Zhang(2019)]{Verma2019}
S.~Verma and Z.-L. Zhang.
\newblock Stability and generalization of graph convolutional neural networks.
\newblock In \emph{International Conference on Knowledge Discovery \& Data
  Mining (KDD)}, 2019.

\bibitem[Verma et~al.(2022)Verma, Kaski, Heinonen, and Garg]{Modular2022}
Y.~Verma, S.~Kaski, M.~Heinonen, and V.~Garg.
\newblock Modular flows: Differential molecular generation.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2022.

\bibitem[Vignac et~al.(2020)Vignac, Loukas, and Frossard]{Vignac2020}
C.~Vignac, A.~Loukas, and P.~Frossard.
\newblock Building powerful and equivariant graph neural networks with
  structural message-passing.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem[Wang et~al.(2021)Wang, Chang, Liu, Leskovec, and Li]{caw}
Y.~Wang, Y.~Chang, Y.~Liu, J.~Leskovec, and P.~Li.
\newblock Inductive representation learning in temporal networks via causal
  anonymous walks.
\newblock In \emph{{International Conference on Learning Representations
  (ICLR)}}, 2021.

\bibitem[Wu et~al.(2020)Wu, Pan, Chen, Long, Zhang, and Yu]{survey}
Z.~Wu, S.~Pan, F.~Chen, G.~Long, C.~Zhang, and P.~S. Yu.
\newblock A comprehensive survey on graph neural networks.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  pages 1--21, 2020.

\bibitem[Xu et~al.(2019{\natexlab{a}})Xu, Cheng, Luo, Gu, Liu, Ni, Zong, Chen,
  and Zhang]{Xu2019}
D.~Xu, W.~Cheng, D.~Luo, Y.~Gu, X.~Liu, J.~Ni, B.~Zong, H.~Chen, and X.~Zhang.
\newblock Adaptive neural network for node classification in dynamic networks.
\newblock In \emph{IEEE International Conference on Data Mining (ICDM)},
  2019{\natexlab{a}}.

\bibitem[Xu et~al.(2019{\natexlab{b}})Xu, Ruan, Korpeoglu, Kumar, and
  Achan]{DaXu2019}
D.~Xu, C.~Ruan, E.~Korpeoglu, S.~Kumar, and K.~Achan.
\newblock Self-attention with functional time representation learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019{\natexlab{b}}.

\bibitem[Xu et~al.(2020{\natexlab{a}})Xu, Ruan, Korpeoglu, Kumar, and
  Achan]{tgat}
D.~Xu, C.~Ruan, E.~Korpeoglu, S.~Kumar, and K.~Achan.
\newblock Inductive representation learning on temporal graphs.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020{\natexlab{a}}.

\bibitem[Xu et~al.(2019{\natexlab{c}})Xu, Hu, Leskovec, and Jegelka]{gin}
K.~Xu, W.~Hu, J.~Leskovec, and S.~Jegelka.
\newblock How powerful are graph neural networks?
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019{\natexlab{c}}.

\bibitem[Xu et~al.(2020{\natexlab{b}})Xu, Li, Zhang, Du, Kawarabayashi, and
  Jegelka]{Xu2020What}
K.~Xu, J.~Li, M.~Zhang, S.~S. Du, K.-I. Kawarabayashi, and S.~Jegelka.
\newblock What can neural networks reason about?
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020{\natexlab{b}}.

\bibitem[Xu et~al.(2021)Xu, Zhang, Li, Du, Kawarabayashi, and
  Jegelka]{xu2021how}
K.~Xu, M.~Zhang, J.~Li, S.~S. Du, K.-I. Kawarabayashi, and S.~Jegelka.
\newblock How neural networks extrapolate: From feedforward to graph neural
  networks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2021.

\bibitem[Zhang et~al.(2020)Zhang, Wu, and Lee]{factorGNNs}
Z.~Zhang, F.~Wu, and W.~S. Lee.
\newblock Factor graph neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2020.

\end{thebibliography}
