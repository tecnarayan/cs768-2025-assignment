\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbeel and Ng(2004)]{abbeel2004apprenticeship}
Pieter Abbeel and Andrew~Y Ng.
\newblock Apprenticeship learning via inverse reinforcement learning.
\newblock In \emph{Proceedings of the 21st International Conference on Machine
  Learning (ICML)}, 2004.

\bibitem[Degris et~al.(2012)Degris, White, and Sutton]{degris2012off}
Thomas Degris, Martha White, and Richard~S Sutton.
\newblock Off-policy actor-critic.
\newblock In \emph{Proceedings of the 29th International Conference on Machine
  Learning (ICML)}, pages 179--186, 2012.

\bibitem[Ding et~al.(2019)Ding, Florensa, Abbeel, and Phielipp]{ding2019goal}
Yiming Ding, Carlos Florensa, Pieter Abbeel, and Mariano Phielipp.
\newblock Goal-conditioned imitation learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 15298--15309, 2019.

\bibitem[Finn et~al.(2016{\natexlab{a}})Finn, Christiano, Abbeel, and
  Levine]{finn2016connection}
Chelsea Finn, Paul Christiano, Pieter Abbeel, and Sergey Levine.
\newblock A connection between generative adversarial networks, inverse
  reinforcement learning, and energy-based models.
\newblock \emph{arXiv preprint arXiv:1611.03852}, 2016{\natexlab{a}}.

\bibitem[Finn et~al.(2016{\natexlab{b}})Finn, Levine, and
  Abbeel]{finn2016guided}
Chelsea Finn, Sergey Levine, and Pieter Abbeel.
\newblock Guided cost learning: Deep inverse optimal control via policy
  optimization.
\newblock In \emph{Proceedings of the 33rd International Conference on Machine
  Learning (ICML)}, pages 49--58, 2016{\natexlab{b}}.

\bibitem[Fu et~al.(2017)Fu, Luo, and Levine]{fu2017learning}
Justin Fu, Katie Luo, and Sergey Levine.
\newblock Learning robust rewards with adversarial inverse reinforcement
  learning.
\newblock In \emph{Proceedings of the 5th International Conference on Learning
  Representations (ICLR)}, 2017.

\bibitem[Ghasemipour et~al.(2019)Ghasemipour, Zemel, and
  Gu]{ghasemipour2019divergence}
Seyed Kamyar~Seyed Ghasemipour, Richard Zemel, and Shixiang Gu.
\newblock A divergence minimization perspective on imitation learning methods.
\newblock In \emph{Proceedings of the 3rd Conference on Robot Learning (CoRL)},
  2019.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 2672--2680, 2014.

\bibitem[Gulrajani et~al.(2017)Gulrajani, Ahmed, Arjovsky, Dumoulin, and
  Courville]{gulrajani2017improved}
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron~C
  Courville.
\newblock Improved training of {W}asserstein {GAN}s.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 5767--5777, 2017.

\bibitem[Haarnoja et~al.(2017)Haarnoja, Tang, Abbeel, and
  Levine]{haarnoja2017reinforcement}
Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, and Sergey Levine.
\newblock Reinforcement learning with deep energy-based policies.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning (ICML)}, pages 1352--1361, 2017.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Hartikainen, Tucker, Ha, Tan,
  Kumar, Zhu, Gupta, Abbeel, et~al.]{haarnoja2018soft}
Tuomas Haarnoja, Aurick Zhou, Kristian Hartikainen, George Tucker, Sehoon Ha,
  Jie Tan, Vikash Kumar, Henry Zhu, Abhishek Gupta, Pieter Abbeel, et~al.
\newblock Soft actor-critic algorithms and applications.
\newblock \emph{arXiv preprint arXiv:1812.05905}, 2018.

\bibitem[Hazan et~al.(2018)Hazan, Kakade, Singh, and
  Van~Soest]{hazan2018provably}
Elad Hazan, Sham~M Kakade, Karan Singh, and Abby Van~Soest.
\newblock Provably efficient maximum entropy exploration.
\newblock \emph{arXiv preprint arXiv:1812.02690}, 2018.

\bibitem[Ho and Ermon(2016)]{ho2016generative}
Jonathan Ho and Stefano Ermon.
\newblock Generative adversarial imitation learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 4565--4573, 2016.

\bibitem[Kostrikov et~al.(2019)Kostrikov, Agrawal, Dwibedi, Levine, and
  Tompson]{kostrikov2018discriminatoractorcritic}
Ilya Kostrikov, Kumar~Krishna Agrawal, Debidatta Dwibedi, Sergey Levine, and
  Jonathan Tompson.
\newblock Discriminator-actor-critic: Addressing sample inefficiency and reward
  bias in adversarial imitation learning.
\newblock In \emph{Proceedings of the 7th International Conference on Learning
  Representations (ICLR)}, 2019.

\bibitem[Kostrikov et~al.(2020)Kostrikov, Nachum, and
  Tompson]{Kostrikov2020Imitation}
Ilya Kostrikov, Ofir Nachum, and Jonathan Tompson.
\newblock Imitation learning via off-policy distribution matching.
\newblock In \emph{Proceedings of the 8th International Conference on Learning
  Representations (ICLR)}, 2020.

\bibitem[Kuefler et~al.(2017)Kuefler, Morton, Wheeler, and
  Kochenderfer]{kuefler2017imitating}
Alex Kuefler, Jeremy Morton, Tim Wheeler, and Mykel Kochenderfer.
\newblock Imitating driver behavior with generative adversarial networks.
\newblock In \emph{Proceedings of 2017 IEEE Intelligent Vehicles Symposium
  (IV)}, pages 204--211, 2017.

\bibitem[Nachum et~al.(2018)Nachum, Norouzi, Xu, and
  Schuurmans]{nachum2018trustpcl}
Ofir Nachum, Mohammad Norouzi, Kelvin Xu, and Dale Schuurmans.
\newblock Trust-{PCL}: An off-policy trust region method for continuous
  control.
\newblock In \emph{Proceedings of the 6th International Conference on Learning
  Representations (ICLR)}, 2018.

\bibitem[Nachum et~al.(2019)Nachum, Chow, Dai, and Li]{nachum2019dualdice}
Ofir Nachum, Yinlam Chow, Bo~Dai, and Lihong Li.
\newblock Dual{DICE}: Behavior-agnostic estimation of discounted stationary
  distribution corrections.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 2318--2328, 2019.

\bibitem[Pomerleau(1991)]{pomerleau1991efficient}
Dean~A Pomerleau.
\newblock Efficient training of artificial neural networks for autonomous
  navigation.
\newblock \emph{Neural computation}, 3\penalty0 (1):\penalty0 88--97, 1991.

\bibitem[Reddy et~al.(2019)Reddy, Dragan, and Levine]{reddy2019sqil}
Siddharth Reddy, Anca~D. Dragan, and Sergey Levine.
\newblock {SQIL}: Imitation learning via reinforcement learning with sparse
  rewards, 2019.

\bibitem[Resnick et~al.(2018)Resnick, Eldridge, Ha, Britz, Foerster, Togelius,
  Cho, and Bruna]{resnick2018pommerman}
Cinjon Resnick, Wes Eldridge, David Ha, Denny Britz, Jakob Foerster, Julian
  Togelius, Kyunghyun Cho, and Joan Bruna.
\newblock Pommerman: A multi-agent playground.
\newblock \emph{arXiv preprint arXiv:1809.07124}, 2018.

\bibitem[Rezende and Mohamed(2015)]{rezende2015variational}
Danilo Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning (ICML)}, pages 1530--1538, 2015.

\bibitem[Ross and Bagnell(2010)]{ross2010efficient}
St{\'e}phane Ross and Drew Bagnell.
\newblock Efficient reductions for imitation learning.
\newblock In \emph{Proceedings of the 13th International Conference on
  Artificial Intelligence and Statistics (AISTATS)}, pages 661--668, 2010.

\bibitem[Ross et~al.(2011)Ross, Gordon, and Bagnell]{ross2011reduction}
St{\'e}phane Ross, Geoffrey Gordon, and Drew Bagnell.
\newblock A reduction of imitation learning and structured prediction to
  no-regret online learning.
\newblock In \emph{Proceedings of the 14th International Conference on
  Artificial Intelligence and Statistics (AISTATS)}, pages 627--635, 2011.

\bibitem[Sasaki et~al.(2018)Sasaki, Yohira, and Kawaguchi]{sasaki2018sample}
Fumihiro Sasaki, Tetsuya Yohira, and Atsuo Kawaguchi.
\newblock Sample efficient imitation learning for continuous control.
\newblock In \emph{Proceedings of the 6th International Conference on Learning
  Representations (ICLR)}, 2018.

\bibitem[Schulman et~al.(2015)Schulman, Levine, Abbeel, Jordan, and
  Moritz]{schulman2015trust}
John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp
  Moritz.
\newblock Trust region policy optimization.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning (ICML)}, pages 1889--1897, 2015.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Zhou et~al.(2018)Zhou, Gong, Mugrai, Khalifa, Nealen, and
  Togelius]{zhou2018hybrid}
Hongwei Zhou, Yichen Gong, Luvneesh Mugrai, Ahmed Khalifa, Andy Nealen, and
  Julian Togelius.
\newblock A hybrid search agent in pommerman.
\newblock In \emph{Proceedings of the 13th International Conference on the
  Foundations of Digital Games (FDG)}, pages 1--4, 2018.

\bibitem[Ziebart(2010)]{ziebart2010modeling}
Brian~D Ziebart.
\newblock \emph{Modeling purposeful adaptive behavior with the principle of
  maximum causal entropy}.
\newblock PhD thesis, 2010.

\bibitem[Ziebart et~al.(2008)Ziebart, Maas, Bagnell, and
  Dey]{ziebart2008maximum}
Brian~D Ziebart, Andrew~L Maas, J~Andrew Bagnell, and Anind~K Dey.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In \emph{Proceedings of the 23rd AAAI Conference on Artificial
  Intelligence}, pages 1433--1438, 2008.

\end{thebibliography}
