\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{AZLOW17}

\bibitem[ABKS21]{ABKS21}
Deeksha Adil, Brian Bullins, Rasmus Kyng, and Sushant Sachdeva.
\newblock Almost-linear-time weighted $\ell_p$-norm solvers in slightly dense
  graphs via sparsification, 2021.

\bibitem[AKPS19]{adil2019iterative}
Deeksha Adil, Rasmus Kyng, Richard Peng, and Sushant Sachdeva.
\newblock Iterative refinement for $\ell_p$-norm regression.
\newblock In {\em Proceedings of the Thirtieth Annual ACM-SIAM Symposium on
  Discrete Algorithms}, pages 1405--1424. SIAM, 2019.

\bibitem[AS20]{adil2020faster}
Deeksha Adil and Sushant Sachdeva.
\newblock Faster $p$-norm minimizing flows, via smoothed $q$-norm problems.
\newblock In {\em Proceedings of the Fourteenth Annual ACM-SIAM Symposium on
  Discrete Algorithms}, pages 892--910. SIAM, 2020.

\bibitem[ASS19]{arjevani2019oracle}
Yossi Arjevani, Ohad Shamir, and Ron Shiff.
\newblock Oracle complexity of second-order methods for smooth convex
  optimization.
\newblock {\em Mathematical Programming}, 178(1):327--360, 2019.

\bibitem[AZLOW17]{allen2017much}
Zeyuan Allen-Zhu, Yuanzhi Li, Rafael Oliveira, and Avi Wigderson.
\newblock Much faster algorithms for matrix scaling.
\newblock In {\em 2017 IEEE 58th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 890--901. IEEE, 2017.

\bibitem[Bac10]{bach2010self}
Francis Bach.
\newblock Self-concordant analysis for logistic regression.
\newblock {\em Electronic Journal of Statistics}, 4:384--414, 2010.

\bibitem[BCLL18]{bubeck2018homotopy}
S{\'e}bastien Bubeck, Michael~B Cohen, Yin~Tat Lee, and Yuanzhi Li.
\newblock An homotopy method for lp regression provably beyond self-concordance
  and in input-sparsity time.
\newblock In {\em Proceedings of the 50th Annual ACM SIGACT Symposium on Theory
  of Computing}, pages 1130--1137, 2018.

\bibitem[Bul20]{bullins2020highly}
Brian Bullins.
\newblock Highly smooth minimization of non-smooth problems.
\newblock In {\em Conference on Learning Theory}, pages 988--1030. PMLR, 2020.

\bibitem[CJJ{\etalchar{+}}20]{CJJJLST}
Yair Carmon, Arun Jambulapati, Qijia Jiang, Yujia Jin, Yin~Tat Lee, Aaron
  Sidford, and Kevin Tian.
\newblock Acceleration with a ball optimization oracle.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, {\em Advances in Neural Information Processing Systems}, volume~33,
  pages 19052--19063. Curran Associates, Inc., 2020.

\bibitem[CKM{\etalchar{+}}11]{CKMST}
Paul Christiano, Jonathan~A Kelner, Aleksander Madry, Daniel~A Spielman, and
  Shang-Hua Teng.
\newblock Electrical flows, laplacian systems, and faster approximation of
  maximum flow in undirected graphs.
\newblock In {\em Proceedings of the forty-third annual ACM symposium on Theory
  of computing}, pages 273--282, 2011.

\bibitem[CMMP13]{chin2013runtime}
Hui~Han Chin, Aleksander Madry, Gary~L Miller, and Richard Peng.
\newblock Runtime guarantees for regression problems.
\newblock In {\em Proceedings of the 4th conference on Innovations in
  Theoretical Computer Science}, pages 269--282, 2013.

\bibitem[CMTV17]{cohen2017matrix}
Michael~B Cohen, Aleksander Madry, Dimitris Tsipras, and Adrian Vladu.
\newblock Matrix scaling and balancing via box constrained newton's method and
  interior point methods.
\newblock In {\em 2017 IEEE 58th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 902--913. IEEE, 2017.

\bibitem[EV19]{ene2019improved}
Alina Ene and Adrian Vladu.
\newblock Improved convergence for $\ell_1$ and $\ell_\infty$ regression via
  iteratively reweighted least squares.
\newblock In {\em International Conference on Machine Learning}, pages
  1794--1801. PMLR, 2019.

\bibitem[GDG{\etalchar{+}}19]{gasnikov2019near}
Alexander Gasnikov, Pavel~E. Dvurechensky, Eduard~A. Gorbunov, Evgeniya~A.
  Vorontsova, Daniil Selikhanovych, César~A. Uribe, Bo~Jiang, Haoyue Wang,
  Shuzhong Zhang, Sébastien Bubeck, Qijia Jiang, Yin~Tat Lee, Yuanzhi Li, and
  Aaron Sidford.
\newblock Near optimal methods for minimizing convex functions with lipschitz
  $p$-th derivatives.
\newblock In {\em COLT}, pages 1392--1393, 2019.

\bibitem[KLS20]{kathuria2020unit}
Tarun Kathuria, Yang~P Liu, and Aaron Sidford.
\newblock Unit capacity maxflow in almost $m^{4/3}$ time.
\newblock In {\em 2020 IEEE 61st Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 119--130. IEEE, 2020.

\bibitem[KPSW19]{kyng2019flows}
Rasmus Kyng, Richard Peng, Sushant Sachdeva, and Di~Wang.
\newblock Flows in almost linear time via adaptive preconditioning.
\newblock In {\em Proceedings of the 51st Annual ACM SIGACT Symposium on Theory
  of Computing}, pages 902--913, 2019.

\bibitem[KSJ18]{karimireddy2018global}
Sai~Praneeth Karimireddy, Sebastian~U Stich, and Martin Jaggi.
\newblock Global linear convergence of newton's method without strong-convexity
  or lipschitz gradients.
\newblock {\em arXiv preprint arXiv:1806.00413}, 2018.

\bibitem[LS20]{liu2020faster}
Yang~P Liu and Aaron Sidford.
\newblock Faster energy maximization for faster maximum flow.
\newblock In {\em Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory
  of Computing}, pages 803--814, 2020.

\bibitem[MS13]{monteiro2013accelerated}
Renato~DC Monteiro and Benar~Fux Svaiter.
\newblock An accelerated hybrid proximal extragradient method for convex
  optimization and its implications to second-order methods.
\newblock {\em SIAM Journal on Optimization}, 23(2):1092--1125, 2013.

\bibitem[Nes05]{nesterov2005smooth}
Yu~Nesterov.
\newblock Smooth minimization of non-smooth functions.
\newblock {\em Mathematical programming}, 103(1):127--152, 2005.

\bibitem[NW06]{nocedal2006numerical}
Jorge Nocedal and Stephen Wright.
\newblock {\em Numerical optimization}.
\newblock Springer Science \& Business Media, 2006.

\bibitem[STD19]{SunT19}
Tianxiao Sun and Quoc Tran-Dinh.
\newblock Generalized self-concordant functions: a recipe for newton-type
  methods.
\newblock {\em Mathematical Programming}, 178(1):145--213, 2019.

\end{thebibliography}
