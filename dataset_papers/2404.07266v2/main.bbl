\begin{thebibliography}{59}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{mnih2013playing}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1312.5602}, 2013.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van
  Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot,
  et~al.]{silver2016mastering}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George
  Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{nature}, 529\penalty0 (7587):\penalty0 484--489, 2016.

\bibitem[Silver et~al.(2017)Silver, Hubert, Schrittwieser, Antonoglou, Lai,
  Guez, Lanctot, Sifre, Kumaran, Graepel, et~al.]{silver2017mastering}
David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew
  Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore
  Graepel, et~al.
\newblock Mastering chess and shogi by self-play with a general reinforcement
  learning algorithm.
\newblock \emph{arXiv preprint arXiv:1712.01815}, 2017.

\bibitem[Silver et~al.(2014)Silver, Lever, Heess, Degris, Wierstra, and
  Riedmiller]{silver2014deterministic}
David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra, and
  Martin Riedmiller.
\newblock Deterministic policy gradient algorithms.
\newblock In \emph{International conference on machine learning}, pages
  387--395. Pmlr, 2014.

\bibitem[Lillicrap et~al.(2015)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap2015continuous}
Timothy~P Lillicrap, Jonathan~J Hunt, Alexander Pritzel, Nicolas Heess, Tom
  Erez, Yuval Tassa, David Silver, and Daan Wierstra.
\newblock Continuous control with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1509.02971}, 2015.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin,
  Zhang, Agarwal, Slama, Ray, et~al.]{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela
  Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 27730--27744, 2022.

\bibitem[Wagenmaker and Pacchiano(2023)]{wagenmaker2023leveraging}
Andrew Wagenmaker and Aldo Pacchiano.
\newblock Leveraging offline data in online reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  35300--35338. PMLR, 2023.

\bibitem[Song et~al.(2022)Song, Zhou, Sekhari, Bagnell, Krishnamurthy, and
  Sun]{song2022hybrid}
Yuda Song, Yifei Zhou, Ayush Sekhari, J~Andrew Bagnell, Akshay Krishnamurthy,
  and Wen Sun.
\newblock Hybrid rl: Using both offline and online data can make rl efficient.
\newblock \emph{arXiv preprint arXiv:2210.06718}, 2022.

\bibitem[Ball et~al.(2023)Ball, Smith, Kostrikov, and
  Levine]{ball2023efficient}
Philip~J Ball, Laura Smith, Ilya Kostrikov, and Sergey Levine.
\newblock Efficient online reinforcement learning with offline data.
\newblock In \emph{International Conference on Machine Learning}, pages
  1577--1594. PMLR, 2023.

\bibitem[Nair et~al.(2018)Nair, McGrew, Andrychowicz, Zaremba, and
  Abbeel]{nair2018overcoming}
Ashvin Nair, Bob McGrew, Marcin Andrychowicz, Wojciech Zaremba, and Pieter
  Abbeel.
\newblock Overcoming exploration in reinforcement learning with demonstrations.
\newblock In \emph{2018 IEEE international conference on robotics and
  automation (ICRA)}, pages 6292--6299. IEEE, 2018.

\bibitem[Cabi et~al.(2019)Cabi, Colmenarejo, Novikov, Konyushkova, Reed, Jeong,
  Zolna, Aytar, Budden, Vecerik, et~al.]{cabi2019scaling}
Serkan Cabi, Sergio~G{\'o}mez Colmenarejo, Alexander Novikov, Ksenia
  Konyushkova, Scott Reed, Rae Jeong, Konrad Zolna, Yusuf Aytar, David Budden,
  Mel Vecerik, et~al.
\newblock Scaling data-driven robotics with reward sketching and batch
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1909.12200}, 2019.

\bibitem[Briesch et~al.(2010)Briesch, Chintagunta, and
  Matzkin]{briesch_nonparametric_2010}
Richard~A. Briesch, Pradeep~K. Chintagunta, and Rosa~L. Matzkin.
\newblock Nonparametric {Discrete} {Choice} {Models} {With} {Unobserved}
  {Heterogeneity}.
\newblock \emph{Journal of Business \& Economic Statistics}, 28\penalty0
  (2):\penalty0 291--307, 2010.
\newblock ISSN 0735-0015.
\newblock Publisher: [American Statistical Association, Taylor \& Francis,
  Ltd.].

\bibitem[Yu et~al.(2019)Yu, Yu, Finn, and Ermon]{yu2019meta}
Lantao Yu, Tianhe Yu, Chelsea Finn, and Stefano Ermon.
\newblock Meta-inverse reinforcement learning with probabilistic context
  variables.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Kallus and Zhou(2021)]{kallus_minimax-optimal_2021}
Nathan Kallus and Angela Zhou.
\newblock Minimax-{Optimal} {Policy} {Learning} {Under} {Unobserved}
  {Confounding}.
\newblock \emph{Management Science}, 67\penalty0 (5):\penalty0 2870--2890, May
  2021.
\newblock ISSN 0025-1909, 1526-5501.
\newblock \doi{10.1287/mnsc.2020.3699}.

\bibitem[Bennett et~al.(2021)Bennett, Kallus, Li, and
  Mousavi]{bennett_off-policy_2021}
Andrew Bennett, Nathan Kallus, Lihong Li, and Ali Mousavi.
\newblock Off-policy {Evaluation} in {Infinite}-{Horizon} {Reinforcement}
  {Learning} with {Latent} {Confounders}.
\newblock In \emph{Proceedings of {The} 24th {International} {Conference} on
  {Artificial} {Intelligence} and {Statistics}}, pages 1999--2007. PMLR, March
  2021.
\newblock ISSN: 2640-3498.

\bibitem[Choudhury et~al.(2018)Choudhury, Bhardwaj, Arora, Kapoor, Ranade,
  Scherer, and Dey]{choudhury2018data}
Sanjiban Choudhury, Mohak Bhardwaj, Sankalp Arora, Ashish Kapoor, Gireeja
  Ranade, Sebastian Scherer, and Debadeepta Dey.
\newblock Data-driven planning via imitation learning.
\newblock \emph{The International Journal of Robotics Research}, 37\penalty0
  (13-14):\penalty0 1632--1672, 2018.

\bibitem[Warrington et~al.(2021)Warrington, Lavington, Scibior, Schmidt, and
  Wood]{warrington2021robust}
Andrew Warrington, Jonathan~W Lavington, Adam Scibior, Mark Schmidt, and Frank
  Wood.
\newblock Robust asymmetric learning in pomdps.
\newblock In \emph{International Conference on Machine Learning}, pages
  11013--11023. PMLR, 2021.

\bibitem[Walsman et~al.(2022)Walsman, Zhang, Choudhury, Fox, and
  Farhadi]{walsman2022impossibly}
Aaron Walsman, Muru Zhang, Sanjiban Choudhury, Dieter Fox, and Ali Farhadi.
\newblock Impossibly good experts and how to follow them.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2022.

\bibitem[Shenfeld et~al.(2023)Shenfeld, Hong, Tamar, and
  Agrawal]{pmlr-v202-shenfeld23a}
Idan Shenfeld, Zhang-Wei Hong, Aviv Tamar, and Pulkit Agrawal.
\newblock {TGRL}: An algorithm for teacher guided reinforcement learning.
\newblock In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt,
  Sivan Sabato, and Jonathan Scarlett, editors, \emph{Proceedings of the 40th
  International Conference on Machine Learning}, volume 202 of
  \emph{Proceedings of Machine Learning Research}, pages 31077--31093. PMLR,
  23--29 Jul 2023.

\bibitem[Zhang et~al.(2020)Zhang, Kumor, and Bareinboim]{zhang2020causal}
Junzhe Zhang, Daniel Kumor, and Elias Bareinboim.
\newblock Causal imitation learning with unobserved confounders.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 12263--12274, 2020.

\bibitem[Swamy et~al.(2022)Swamy, Choudhury, Bagnell, and
  Wu]{swamy2022sequence}
Gokul Swamy, Sanjiban Choudhury, J~Bagnell, and Steven~Z Wu.
\newblock Sequence model imitation learning with unobserved contexts.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 17665--17676, 2022.

\bibitem[Hao et~al.(2023{\natexlab{a}})Hao, Jain, Lattimore, Van~Roy, and
  Wen]{hao2023leveraging}
Botao Hao, Rahul Jain, Tor Lattimore, Benjamin Van~Roy, and Zheng Wen.
\newblock Leveraging demonstrations to improve online learning: Quality
  matters.
\newblock In \emph{International Conference on Machine Learning}, pages
  12527--12545. PMLR, 2023{\natexlab{a}}.

\bibitem[Hao et~al.(2023{\natexlab{b}})Hao, Jain, Tang, and
  Wen]{hao2023bridging}
Botao Hao, Rahul Jain, Dengwang Tang, and Zheng Wen.
\newblock Bridging imitation and online reinforcement learning: An optimistic
  tale.
\newblock \emph{arXiv preprint arXiv:2303.11369}, 2023{\natexlab{b}}.

\bibitem[Weihs et~al.(2021)Weihs, Jain, Liu, Salvador, Lazebnik, Kembhavi, and
  Schwing]{weihs2021bridging}
Luca Weihs, Unnat Jain, Iou-Jen Liu, Jordi Salvador, Svetlana Lazebnik,
  Aniruddha Kembhavi, and Alex Schwing.
\newblock Bridging the imitation gap by adaptive insubordination.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 19134--19146, 2021.

\bibitem[Cella et~al.(2020)Cella, Lazaric, and Pontil]{cella2020meta}
Leonardo Cella, Alessandro Lazaric, and Massimiliano Pontil.
\newblock Meta-learning with stochastic linear bandits.
\newblock In \emph{International Conference on Machine Learning}, pages
  1360--1370. PMLR, 2020.

\bibitem[Cella and Pontil(2021)]{cella2021multi}
Leonardo Cella and Massimiliano Pontil.
\newblock Multi-task and meta-learning with sparse linear bandits.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 1692--1702.
  PMLR, 2021.

\bibitem[Mardia et~al.(2020)Mardia, Jiao, T{\'a}nczos, Nowak, and
  Weissman]{mardia2020concentration}
Jay Mardia, Jiantao Jiao, Ervin T{\'a}nczos, Robert~D Nowak, and Tsachy
  Weissman.
\newblock Concentration inequalities for the empirical distribution of discrete
  distributions: beyond the method of types.
\newblock \emph{Information and Inference: A Journal of the IMA}, 9\penalty0
  (4):\penalty0 813--850, 2020.

\bibitem[Osband et~al.(2013)Osband, Russo, and Van~Roy]{osband2013more}
Ian Osband, Daniel Russo, and Benjamin Van~Roy.
\newblock (more) efficient reinforcement learning via posterior sampling.
\newblock \emph{Advances in Neural Information Processing Systems}, 26, 2013.

\bibitem[Rajeswaran et~al.(2017)Rajeswaran, Kumar, Gupta, Vezzani, Schulman,
  Todorov, and Levine]{rajeswaran2017learning}
Aravind Rajeswaran, Vikash Kumar, Abhishek Gupta, Giulia Vezzani, John
  Schulman, Emanuel Todorov, and Sergey Levine.
\newblock Learning complex dexterous manipulation with deep reinforcement
  learning and demonstrations.
\newblock \emph{arXiv preprint arXiv:1709.10087}, 2017.

\bibitem[Nair et~al.(2020)Nair, Gupta, Dalal, and Levine]{nair2020awac}
Ashvin Nair, Abhishek Gupta, Murtaza Dalal, and Sergey Levine.
\newblock Awac: Accelerating online reinforcement learning with offline
  datasets.
\newblock \emph{arXiv preprint arXiv:2006.09359}, 2020.

\bibitem[Vecerik et~al.(2017)Vecerik, Hester, Scholz, Wang, Pietquin, Piot,
  Heess, Roth{\"o}rl, Lampe, and Riedmiller]{vecerik2017leveraging}
Mel Vecerik, Todd Hester, Jonathan Scholz, Fumin Wang, Olivier Pietquin, Bilal
  Piot, Nicolas Heess, Thomas Roth{\"o}rl, Thomas Lampe, and Martin Riedmiller.
\newblock Leveraging demonstrations for deep reinforcement learning on robotics
  problems with sparse rewards.
\newblock \emph{arXiv preprint arXiv:1707.08817}, 2017.

\bibitem[Hester et~al.(2018)Hester, Vecerik, Pietquin, Lanctot, Schaul, Piot,
  Horgan, Quan, Sendonaris, Osband, et~al.]{hester2018deep}
Todd Hester, Matej Vecerik, Olivier Pietquin, Marc Lanctot, Tom Schaul, Bilal
  Piot, Dan Horgan, John Quan, Andrew Sendonaris, Ian Osband, et~al.
\newblock Deep q-learning from demonstrations.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, 2018.

\bibitem[Gupta et~al.(2018)Gupta, Mendonca, Liu, Abbeel, and
  Levine]{gupta2018meta}
Abhishek Gupta, Russell Mendonca, YuXuan Liu, Pieter Abbeel, and Sergey Levine.
\newblock Meta-reinforcement learning of structured exploration strategies.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Nagabandi et~al.(2018)Nagabandi, Clavera, Liu, Fearing, Abbeel,
  Levine, and Finn]{nagabandi2018learning}
Anusha Nagabandi, Ignasi Clavera, Simin Liu, Ronald~S Fearing, Pieter Abbeel,
  Sergey Levine, and Chelsea Finn.
\newblock Learning to adapt in dynamic, real-world environments through
  meta-reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1803.11347}, 2018.

\bibitem[Beck et~al.(2023)Beck, Vuorio, Liu, Xiong, Zintgraf, Finn, and
  Whiteson]{beck2023survey}
Jacob Beck, Risto Vuorio, Evan~Zheran Liu, Zheng Xiong, Luisa Zintgraf, Chelsea
  Finn, and Shimon Whiteson.
\newblock A survey of meta-reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2301.08028}, 2023.

\bibitem[Verma et~al.(2020)Verma, Brahma, and Rai]{verma2020meta}
Vinay~Kumar Verma, Dhanajit Brahma, and Piyush Rai.
\newblock Meta-learning for generalized zero-shot learning.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, volume~34, pages 6062--6069, 2020.

\bibitem[Jiang et~al.(2023)Jiang, Lerman, and Ferrara]{jiang2023zero}
Julie Jiang, Kristina Lerman, and Emilio Ferrara.
\newblock Zero-shot meta-learning for small-scale data from human subjects.
\newblock In \emph{2023 IEEE 11th International Conference on Healthcare
  Informatics (ICHI)}, pages 311--320. IEEE, 2023.

\bibitem[Li et~al.(2024)Li, Zhang, Ghosh, Zhang, and
  Levine]{li2024accelerating}
Qiyang Li, Jason Zhang, Dibya Ghosh, Amy Zhang, and Sergey Levine.
\newblock Accelerating exploration with unlabeled prior data.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Mendonca et~al.(2019)Mendonca, Gupta, Kralev, Abbeel, Levine, and
  Finn]{mendonca2019guided}
Russell Mendonca, Abhishek Gupta, Rosen Kralev, Pieter Abbeel, Sergey Levine,
  and Chelsea Finn.
\newblock Guided meta-policy search.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Zhou et~al.(2019)Zhou, Jang, Kappler, Herzog, Khansari, Wohlhart, Bai,
  Kalakrishnan, Levine, and Finn]{zhou2019watch}
Allan Zhou, Eric Jang, Daniel Kappler, Alex Herzog, Mohi Khansari, Paul
  Wohlhart, Yunfei Bai, Mrinal Kalakrishnan, Sergey Levine, and Chelsea Finn.
\newblock Watch, try, learn: Meta-learning from demonstrations and reward.
\newblock \emph{arXiv preprint arXiv:1906.03352}, 2019.

\bibitem[Rakelly et~al.(2019)Rakelly, Zhou, Finn, Levine, and
  Quillen]{rakelly2019efficient}
Kate Rakelly, Aurick Zhou, Chelsea Finn, Sergey Levine, and Deirdre Quillen.
\newblock Efficient off-policy meta-reinforcement learning via probabilistic
  context variables.
\newblock In \emph{International conference on machine learning}, pages
  5331--5340. PMLR, 2019.

\bibitem[Lee et~al.(2024)Lee, Xie, Pacchiano, Chandak, Finn, Nachum, and
  Brunskill]{lee2024supervised}
Jonathan Lee, Annie Xie, Aldo Pacchiano, Yash Chandak, Chelsea Finn, Ofir
  Nachum, and Emma Brunskill.
\newblock Supervised pretraining can learn in-context reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Russo et~al.(2018)Russo, Van~Roy, Kazerouni, Osband, Wen,
  et~al.]{russo2018tutorial}
Daniel~J Russo, Benjamin Van~Roy, Abbas Kazerouni, Ian Osband, Zheng Wen,
  et~al.
\newblock A tutorial on thompson sampling.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  11\penalty0 (1):\penalty0 1--96, 2018.

\bibitem[Hallak et~al.(2015)Hallak, Di~Castro, and
  Mannor]{hallak2015contextual}
Assaf Hallak, Dotan Di~Castro, and Shie Mannor.
\newblock Contextual markov decision processes.
\newblock \emph{arXiv preprint arXiv:1502.02259}, 2015.

\bibitem[Carlin and Louis(2000)]{carlin2000empirical}
Bradley~P Carlin and Thomas~A Louis.
\newblock Empirical bayes: Past, present and future.
\newblock \emph{Journal of the American Statistical Association}, 95\penalty0
  (452):\penalty0 1286--1289, 2000.

\bibitem[Fu(2006)]{fu2006chapter}
Michael~C Fu.
\newblock Chapter 19 gradient estimation.
\newblock \emph{Simulation}, 13:\penalty0 575--616, 2006.

\bibitem[Rockafellar(1997)]{rockafellar1997convex}
R~Tyrrell Rockafellar.
\newblock \emph{Convex analysis}, volume~11.
\newblock Princeton university press, 1997.

\bibitem[Dud{\'\i}k et~al.(2007)Dud{\'\i}k, Phillips, and
  Schapire]{dudik2007maximum}
Miroslav Dud{\'\i}k, Steven~J Phillips, and Robert~E Schapire.
\newblock Maximum entropy density estimation with generalized regularization
  and an application to species distribution modeling.
\newblock \emph{Journal of Machine Learning Research}, 2007.

\bibitem[Welling and Teh(2011)]{welling2011bayesian}
Max Welling and Yee~W Teh.
\newblock Bayesian learning via stochastic gradient langevin dynamics.
\newblock In \emph{Proceedings of the 28th international conference on machine
  learning (ICML-11)}, pages 681--688, 2011.

\bibitem[Russo and Van~Roy(2016)]{russo2016information}
Daniel Russo and Benjamin Van~Roy.
\newblock An information-theoretic analysis of thompson sampling.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 2442--2471, 2016.

\bibitem[Even-Dar et~al.(2002)Even-Dar, Mannor, and Mansour]{even2002pac}
Eyal Even-Dar, Shie Mannor, and Yishay Mansour.
\newblock Pac bounds for multi-armed bandit and markov decision processes.
\newblock In \emph{Computational Learning Theory: 15th Annual Conference on
  Computational Learning Theory, COLT 2002 Sydney, Australia, July 8--10, 2002
  Proceedings 15}, pages 255--270. Springer, 2002.

\bibitem[Dwaracherla and Van~Roy(2020)]{dwaracherla2020langevin}
Vikranth Dwaracherla and Benjamin Van~Roy.
\newblock Langevin dqn.
\newblock \emph{arXiv preprint arXiv:2002.07282}, 2020.

\bibitem[Ishfaq et~al.(2024)Ishfaq, Lan, Xu, Mahmood, Precup, Anandkumar, and
  Azizzadenesheli]{ishfaq2023provable}
Haque Ishfaq, Qingfeng Lan, Pan Xu, A.~Rupam Mahmood, Doina Precup, Anima
  Anandkumar, and Kamyar Azizzadenesheli.
\newblock Provable and practical: Efficient exploration in reinforcement
  learning via langevin monte carlo.
\newblock In \emph{The Twelfth International Conference on Learning
  Representations}, 2024.

\bibitem[Osband et~al.(2016)Osband, Blundell, Pritzel, and
  Van~Roy]{osband2016deep}
Ian Osband, Charles Blundell, Alexander Pritzel, and Benjamin Van~Roy.
\newblock Deep exploration via bootstrapped dqn.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Osband et~al.(2018)Osband, Aslanides, and
  Cassirer]{osband2018randomized}
Ian Osband, John Aslanides, and Albin Cassirer.
\newblock Randomized prior functions for deep reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Osband et~al.(2019{\natexlab{a}})Osband, Van~Roy, Russo, Wen,
  et~al.]{osband2019deep}
Ian Osband, Benjamin Van~Roy, Daniel~J Russo, Zheng Wen, et~al.
\newblock Deep exploration via randomized value functions.
\newblock \emph{J. Mach. Learn. Res.}, 20\penalty0 (124):\penalty0 1--62,
  2019{\natexlab{a}}.

\bibitem[Osband et~al.(2023)Osband, Wen, Asghari, Dwaracherla, Ibrahimi, Lu,
  and Van~Roy]{osband2023approximate}
Ian Osband, Zheng Wen, Seyed~Mohammad Asghari, Vikranth Dwaracherla, Morteza
  Ibrahimi, Xiuyuan Lu, and Benjamin Van~Roy.
\newblock Approximate thompson sampling via epistemic neural networks.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 1586--1595.
  PMLR, 2023.

\bibitem[Osband et~al.(2019{\natexlab{b}})Osband, Doron, Hessel, Aslanides,
  Sezener, Saraiva, McKinney, Lattimore, Szepesvari, Singh,
  et~al.]{osband2019behaviour}
Ian Osband, Yotam Doron, Matteo Hessel, John Aslanides, Eren Sezener, Andre
  Saraiva, Katrina McKinney, Tor Lattimore, Csaba Szepesvari, Satinder Singh,
  et~al.
\newblock Behaviour suite for reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1908.03568}, 2019{\natexlab{b}}.

\bibitem[Borwein and Zhu(2004)]{borwein2004techniques}
Jonathan~M Borwein and Qiji~J Zhu.
\newblock Techniques of variational analysis, 2004.

\end{thebibliography}
