\begin{thebibliography}{57}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Shrikumar et~al.(2017)Shrikumar, Greenside, Shcherbina, and
  Kundaje]{shrikumar2016not}
Avanti Shrikumar, Peyton Greenside, Anna Shcherbina, and Anshul Kundaje.
\newblock Learning important features through propagating activation
  differences.
\newblock \emph{{International Conference of Machine Learning}}, 2017.

\bibitem[Lipton(2016)]{lipton2016mythos}
Zachary~C Lipton.
\newblock The mythos of model interpretability.
\newblock \emph{arXiv preprint arXiv:1606.03490}, 2016.

\bibitem[Kindermans et~al.(2017)Kindermans, Hooker, Adebayo, Alber, Sch{\"u}tt,
  D{\"a}hne, Erhan, and Kim]{kindermans2017reliability}
Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber, Kristof~T
  Sch{\"u}tt, Sven D{\"a}hne, Dumitru Erhan, and Been Kim.
\newblock The (un) reliability of saliency methods.
\newblock \emph{arXiv preprint arXiv:1711.00867}, 2017.

\bibitem[Smilkov et~al.(2017)Smilkov, Thorat, Kim, Vi{\'e}gas, and
  Wattenberg]{smilkov2017smoothgrad}
Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Vi{\'e}gas, and Martin
  Wattenberg.
\newblock Smoothgrad: removing noise by adding noise.
\newblock \emph{arXiv preprint arXiv:1706.03825}, 2017.

\bibitem[Doshi-Velez and Kim(2017)]{doshi2017towards}
Finale Doshi-Velez and Been Kim.
\newblock Towards a rigorous science of interpretable machine learning.
\newblock \emph{arXiv preprint arXiv:1702.08608}, 2017.

\bibitem[Lundberg and Lee(2017)]{lundberg2017unified}
Scott~M Lundberg and Su-In Lee.
\newblock A unified approach to interpreting model predictions.
\newblock In \emph{{Advances in Neural Information Processing Systems}}, pages
  4768--4777, 2017.

\bibitem[Baehrens et~al.(2010)Baehrens, Schroeter, Harmeling, Kawanabe, Hansen,
  and M\"{u}ller]{baehrens2010explain}
David Baehrens, Timon Schroeter, Stefan Harmeling, Motoaki Kawanabe, Katja
  Hansen, and Klaus-Robert M\"{u}ller.
\newblock How to explain individual classification decisions.
\newblock \emph{Journal of Machine Learning Research}, 11\penalty0
  (Jun):\penalty0 1803--1831, 2010.

\bibitem[Simonyan et~al.(2014)Simonyan, Vedaldi, and
  Zisserman]{simonyan2013deep}
Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock \emph{{International Conference on Learning Representations}}, 2014.

\bibitem[Zeiler and Fergus(2014)]{zeiler2014visualizing}
Matthew~D Zeiler and Rob Fergus.
\newblock Visualizing and understanding convolutional networks.
\newblock In \emph{{European Conference on Computer Vision}}, pages 818--833.
  Springer, 2014.

\bibitem[Sundararajan et~al.(2017)Sundararajan, Taly, and
  Yan]{sundararajan2017axiomatic}
Mukund Sundararajan, Ankur Taly, and Qiqi Yan.
\newblock Axiomatic attribution for deep networks.
\newblock \emph{International Conference on Machine Learning}, 2017.

\bibitem[Xu et~al.(2015)Xu, Ba, Kiros, Cho, Courville, Salakhudinov, Zemel, and
  Bengio]{xu2015show}
Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan
  Salakhudinov, Rich Zemel, and Yoshua Bengio.
\newblock {Show, attend and tell: Neural image caption generation with visual
  attention}.
\newblock In \emph{{International Conference on Machine Learning}}, pages
  2048--2057, 2015.

\bibitem[Choi et~al.(2016)Choi, Bahadori, Sun, Kulas, Schuetz, and
  Stewart]{choi2016retain}
Edward Choi, Mohammad~Taha Bahadori, Jimeng Sun, Joshua Kulas, Andy Schuetz,
  and Walter Stewart.
\newblock Retain: An interpretable predictive model for healthcare using
  reverse time attention mechanism.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3504--3512, 2016.

\bibitem[Schwab et~al.(2017)Schwab, Scebba, Zhang, Delai, and
  Karlen]{schwab2017beat}
Patrick Schwab, Gaetano~C. Scebba, Jia Zhang, Marco Delai, and Walter Karlen.
\newblock {Beat by Beat: Classifying Cardiac Arrhythmias with Recurrent Neural
  Networks}.
\newblock In \emph{{Computing in Cardiology}}, 2017.

\bibitem[Schwab et~al.(2019)Schwab, Miladinovic, and Karlen]{schwab2018granger}
Patrick Schwab, Djordje Miladinovic, and Walter Karlen.
\newblock {Granger-causal Attentive Mixtures of Experts: Learning Important
  Features with Neural Networks}.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2019.

\bibitem[Schwab and Karlen(2019)]{schwab2019phonemd}
Patrick Schwab and Walter Karlen.
\newblock {PhoneMD: Learning to diagnose Parkinson's disease from smartphone
  data}.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2019.

\bibitem[Ribeiro et~al.(2016)Ribeiro, Singh, and Guestrin]{ribeiro2016should}
Marco~Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.
\newblock Why should i trust you?: Explaining the predictions of any
  classifier.
\newblock In \emph{Proceedings of the 22nd ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pages 1135--1144. ACM, 2016.

\bibitem[Adebayo et~al.(2018)Adebayo, Gilmer, Muelly, Goodfellow, Hardt, and
  Kim]{adebayo2018sanity}
Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt,
  and Been Kim.
\newblock Sanity checks for saliency maps.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  9505--9515, 2018.

\bibitem[Fen et~al.(2019)Fen, Song, Udell, Sun, Zhang, et~al.]{fen2019should}
Hui Fen, Kuangyan Song, Madeilene Udell, Yiming Sun, Yujia Zhang, et~al.
\newblock {Why should you trust my interpretation? Understanding uncertainty in
  LIME predictions}.
\newblock \emph{arXiv preprint arXiv:1904.12991}, 2019.

\bibitem[Ghorbani et~al.(2019)Ghorbani, Abid, and
  Zou]{ghorbani2019interpretation}
Amirata Ghorbani, Abubakar Abid, and James Zou.
\newblock Interpretation of neural networks is fragile.
\newblock \emph{{AAAI Conference on Artificial Intelligence}}, 2019.

\bibitem[{\v{S}}trumbelj et~al.(2009){\v{S}}trumbelj, Kononenko, and
  {\v{S}}ikonja]{vstrumbelj2009explaining}
Erik {\v{S}}trumbelj, Igor Kononenko, and M~Robnik {\v{S}}ikonja.
\newblock Explaining instance classifications with interactions of subsets of
  feature values.
\newblock \emph{Data \& Knowledge Engineering}, 68\penalty0 (10):\penalty0
  886--904, 2009.

\bibitem[Zintgraf et~al.(2017)Zintgraf, Cohen, Adel, and
  Welling]{zintgraf2017visualizing}
Luisa~M Zintgraf, Taco~S Cohen, Tameem Adel, and Max Welling.
\newblock Visualizing deep neural network decisions: Prediction difference
  analysis.
\newblock In \emph{{International Conference on Learning Representations}},
  2017.

\bibitem[Li et~al.(2016)Li, Monroe, and Jurafsky]{li2016understanding}
Jiwei Li, Will Monroe, and Dan Jurafsky.
\newblock Understanding neural networks through representation erasure.
\newblock \emph{arXiv preprint arXiv:1612.08220}, 2016.

\bibitem[Fong and Vedaldi(2017)]{fong2017interpretable}
Ruth~C Fong and Andrea Vedaldi.
\newblock Interpretable explanations of black boxes by meaningful perturbation.
\newblock In \emph{IEEE International Conference on Computer Vision}, 2017.

\bibitem[Dabkowski and Gal(2017)]{dabkowski2017real}
Piotr Dabkowski and Yarin Gal.
\newblock Real time image saliency for black box classifiers.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6967--6976, 2017.

\bibitem[Schwab and Hlavacs(2015)]{schwab2015capturing}
Patrick Schwab and Helmut Hlavacs.
\newblock Capturing the essence: Towards the automated generation of
  transparent behavior models.
\newblock In \emph{AAAI Conference on Artificial Intelligence and Interactive
  Digital Entertainment}, 2015.

\bibitem[Che et~al.(2016)Che, Purushotham, Khemani, and
  Liu]{che2016interpretable}
Zhengping Che, Sanjay Purushotham, Robinder Khemani, and Yan Liu.
\newblock Interpretable deep models for {ICU} outcome prediction.
\newblock In \emph{AMIA Annual Symposium Proceedings}, volume 2016, page 371.
  American Medical Informatics Association, 2016.

\bibitem[Bastani et~al.(2017)Bastani, Kim, and
  Bastani]{bastani2017interpreting}
Osbert Bastani, Carolyn Kim, and Hamsa Bastani.
\newblock Interpreting blackbox models via model extraction.
\newblock \emph{arXiv preprint arXiv:1705.08504}, 2017.

\bibitem[Andrews et~al.(1995)Andrews, Diederich, and Tickle]{andrews1995survey}
Robert Andrews, Joachim Diederich, and Alan~B Tickle.
\newblock Survey and critique of techniques for extracting rules from trained
  artificial neural networks.
\newblock \emph{{Knowledge-based Systems}}, 8\penalty0 (6):\penalty0 373--389,
  1995.

\bibitem[Chattopadhyay et~al.(2019)Chattopadhyay, Manupriya, Sarkar, and
  Balasubramanian]{chattopadhyay2019neural}
Aditya Chattopadhyay, Piyushi Manupriya, Anirban Sarkar, and Vineeth~N
  Balasubramanian.
\newblock Neural network attributions: A causal perspective.
\newblock \emph{arXiv preprint arXiv:1902.02302}, 2019.

\bibitem[Montavon et~al.(2017)Montavon, Lapuschkin, Binder, Samek, and
  M{\"u}ller]{montavon2017explaining}
Gr{\'e}goire Montavon, Sebastian Lapuschkin, Alexander Binder, Wojciech Samek,
  and Klaus-Robert M{\"u}ller.
\newblock Explaining nonlinear classification decisions with deep taylor
  decomposition.
\newblock \emph{Pattern Recognition}, 65:\penalty0 211--222, 2017.

\bibitem[Chen et~al.(2018)Chen, Song, Wainwright, and Jordan]{chen2018learning}
Jianbo Chen, Le~Song, Martin~J Wainwright, and Michael~I Jordan.
\newblock Learning to explain: An information-theoretic perspective on model
  interpretation.
\newblock \emph{{International Conference on Machine Learning}}, 2018.

\bibitem[Guo et~al.(2018)Guo, Huang, Tao, Xing, and Lin]{guo2018explaining}
Wenbo Guo, Sui Huang, Yunzhe Tao, Xinyu Xing, and Lin Lin.
\newblock Explaining deep learning models--a bayesian non-parametric approach.
\newblock In \emph{{Advances in Neural Information Processing Systems}}, pages
  4514--4524, 2018.

\bibitem[Tsang et~al.(2017)Tsang, Cheng, and Liu]{tsang2017detecting}
Michael Tsang, Dehua Cheng, and Yan Liu.
\newblock Detecting statistical interactions from neural network weights.
\newblock \emph{{International Conference on Learning Representations}}, 2017.

\bibitem[Kim et~al.(2018)Kim, Wattenberg, Gilmer, Cai, Wexler, Viegas, and
  Sayres]{kim2017interpretability}
Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda
  Viegas, and Rory Sayres.
\newblock {Interpretability beyond feature attribution: Quantitative testing
  with concept activation vectors (TCAV)}.
\newblock \emph{{International Conference on Machine Learning}}, 2018.

\bibitem[Koh and Liang(2017)]{koh2017understanding}
Pang~Wei Koh and Percy Liang.
\newblock Understanding black-box predictions via influence functions.
\newblock \emph{{International Conference of Machine Learning}}, 2017.

\bibitem[Granger(1969)]{granger1969investigating}
Clive~WJ Granger.
\newblock Investigating causal relations by econometric models and
  cross-spectral methods.
\newblock \emph{Econometrica: Journal of the Econometric Society}, pages
  424--438, 1969.

\bibitem[Stone(1993)]{stone1993assumptions}
Richard Stone.
\newblock The assumptions on which causal inferences rest.
\newblock \emph{Journal of the Royal Statistical Society. Series B
  (Methodological)}, pages 455--466, 1993.

\bibitem[Janzing et~al.(2013)Janzing, Balduzzi, Grosse-Wentrup, and
  Sch{\"o}lkopf]{janzing2013quantifying}
Dominik Janzing, David Balduzzi, Moritz Grosse-Wentrup, and Bernhard
  Sch{\"o}lkopf.
\newblock Quantifying causal influences.
\newblock \emph{{The Annals of Statistics}}, 41\penalty0 (5):\penalty0
  2324--2358, 2013.

\bibitem[Khosravi et~al.(2019)Khosravi, Liang, Choi, and
  Broeck]{khosravi2019expect}
Pasha Khosravi, Yitao Liang, YooJung Choi, and Guy Van~den Broeck.
\newblock {What to expect of classifiers? Reasoning about logistic regression
  with missing features}.
\newblock \emph{arXiv preprint arXiv:1903.01620}, 2019.

\bibitem[Kullback(1997)]{kullback1997information}
Solomon Kullback.
\newblock \emph{Information theory and statistics}.
\newblock Courier Corporation, 1997.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, and
  Courville]{goodfellow2016deep}
Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
\newblock \emph{Deep learning}.
\newblock MIT Press, 2016.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy2016rethinking}
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew
  Wojna.
\newblock {Rethinking the Inception architecture for computer vision}.
\newblock In \emph{{IEEE Conference on Computer Vision and Pattern
  Recognition}}, pages 2818--2826, 2016.

\bibitem[Kaiser et~al.(2017)Kaiser, Gomez, Shazeer, Vaswani, Parmar, Jones, and
  Uszkoreit]{kaiser2017one}
Lukasz Kaiser, Aidan~N Gomez, Noam Shazeer, Ashish Vaswani, Niki Parmar, Llion
  Jones, and Jakob Uszkoreit.
\newblock {One Model To Learn Them All}.
\newblock \emph{arXiv preprint arXiv:1706.05137}, 2017.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and
  Brox]{ronneberger2015u}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{{International Conference on Medical Image Computing and
  Computer-assisted Intervention}}, pages 234--241. Springer, 2015.

\bibitem[Efron(1982)]{efron1982jackknife}
Bradley Efron.
\newblock \emph{The jackknife, the bootstrap, and other resampling plans},
  volume~38.
\newblock Siam, 1982.

\bibitem[Breiman(2001)]{breiman2001random}
Leo Breiman.
\newblock Random forests.
\newblock \emph{Machine Learning}, 45\penalty0 (1):\penalty0 5--32, 2001.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and
  Blundell]{lakshminarayanan2017simple}
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6402--6413, 2017.

\bibitem[Gal and Ghahramani(2016)]{gal2016dropout}
Yarin Gal and Zoubin Ghahramani.
\newblock {Dropout as a Bayesian approximation: Representing model uncertainty
  in deep learning}.
\newblock In \emph{{International Conference on Machine Learning}}, pages
  1050--1059, 2016.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{srivastava2014dropout}
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
  Salakhutdinov.
\newblock Dropout: A simple way to prevent neural networks from overfitting.
\newblock \emph{The Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 1929--1958, 2014.

\bibitem[Hollander and Wolfe(1973)]{hollander1973nonparametric}
Myles Hollander and Douglas~A Wolfe.
\newblock \emph{Nonparametric statistical methods}.
\newblock Wiley New York, NY, USA, 1973.

\bibitem[LeCun et~al.(2010)LeCun, Cortes, and Burges]{lecun2010mnist}
Yann LeCun, Corinna Cortes, and CJ~Burges.
\newblock {MNIST handwritten digit database}.
\newblock \emph{AT\&T Labs [Online]. Available:
  http://yann.lecun.com/exdb/mnist}, 2:\penalty0 18, 2010.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{{IEEE Conference on Computer Vision and Pattern
  Recognition}}, pages 248--255. IEEE, 2009.

\bibitem[Silver and Dunlap(1987)]{silver1987averaging}
N~Clayton Silver and William~P Dunlap.
\newblock {Averaging correlation coefficients: Should Fisher's z transformation
  be used?}
\newblock \emph{{Journal of Applied Psychology}}, 72\penalty0 (1):\penalty0
  146, 1987.

\bibitem[Abadi et~al.(2016)Abadi, Agarwal, Barham, Brevdo, Chen, Citro,
  Corrado, Davis, Dean, Devin, et~al.]{abadi2016tensorflow}
Mart{\'\i}n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,
  Craig Citro, Greg~S Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, et~al.
\newblock Tensorflow: Large-scale machine learning on heterogeneous distributed
  systems.
\newblock \emph{arXiv preprint arXiv:1603.04467}, 2016.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{International Conference on Machine Learning}, pages
  448--456, 2015.

\bibitem[Kingma and Ba(2015)]{kingma2014adam}
Diederik Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Klambauer et~al.(2017)Klambauer, Unterthiner, Mayr, and
  Hochreiter]{klambauer2017self}
G{\"u}nter Klambauer, Thomas Unterthiner, Andreas Mayr, and Sepp Hochreiter.
\newblock Self-normalizing neural networks.
\newblock In \emph{{Advances in Neural Information Processing Systems}}, pages
  971--980, 2017.

\end{thebibliography}
