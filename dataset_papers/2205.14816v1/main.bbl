\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{BYJKS04}

\bibitem[AC09]{ac09}
Nir Ailon and Bernard Chazelle.
\newblock The fast johnson--lindenstrauss transform and approximate nearest
  neighbors.
\newblock {\em SIAM Journal on computing}, 39(1):302--322, 2009.

\bibitem[AFS12]{afs12}
Andreas Argyriou, Rina Foygel, and Nathan Srebro.
\newblock Sparse prediction with the $ k $-support norm.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)},
  25, 2012.

\bibitem[Alm19]{a19}
Josh Alman.
\newblock An illuminating algorithm for the light bulb problem.
\newblock In {\em 2nd Symposium on Simplicity in Algorithms (SOSA)}. Schloss
  Dagstuhl-Leibniz-Zentrum fuer Informatik, 2019.

\bibitem[ALS{\etalchar{+}}18]{als+18}
Alexandr Andoni, Chengyu Lin, Ying Sheng, Peilin Zhong, and Ruiqi Zhong.
\newblock Subspace embedding and linear regression with orlicz norm.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  224--233. PMLR, 2018.

\bibitem[AMS99]{ams99}
Noga Alon, Yossi Matias, and Mario Szegedy.
\newblock The space complexity of approximating the frequency moments.
\newblock {\em Journal of Computer and system sciences}, 58(1):137--147, 1999.

\bibitem[ANN{\etalchar{+}}17]{ann+17}
Alexandr Andoni, Huy~L Nguyen, Aleksandar Nikolov, Ilya Razenshteyn, and Erik
  Waingarten.
\newblock Approximate near neighbors for general symmetric norms.
\newblock In {\em Proceedings of the 49th Annual ACM SIGACT Symposium on Theory
  of Computing (STOC)}, pages 902--913, 2017.

\bibitem[ANN{\etalchar{+}}18]{ann+18}
Alexandr Andoni, Assaf Naor, Aleksandar Nikolov, Ilya Razenshteyn, and Erik
  Waingarten.
\newblock H{\"o}lder homeomorphisms and approximate nearest neighbors.
\newblock In {\em 2018 IEEE 59th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 159--169. IEEE, 2018.

\bibitem[AWY14]{awy14}
Amir Abboud, Ryan Williams, and Huacheng Yu.
\newblock More applications of the polynomial method to algorithm design.
\newblock In {\em Proceedings of the twenty-sixth annual ACM-SIAM symposium on
  Discrete algorithms}, pages 218--230. SIAM, 2014.

\bibitem[AWY18]{awy18}
Josh Alman, Joshua~R Wang, and Huacheng Yu.
\newblock Cell-probe lower bounds from online communication complexity.
\newblock In {\em Proceedings of the 50th Annual ACM SIGACT Symposium on Theory
  of Computing}, pages 1003--1012, 2018.

\bibitem[BBC{\etalchar{+}}17]{bbc+17}
Jaros{\l}aw B{\l}asiok, Vladimir Braverman, Stephen~R Chestnut, Robert
  Krauthgamer, and Lin~F Yang.
\newblock Streaming symmetric norms via measure concentration.
\newblock In {\em Proceedings of the 49th Annual ACM SIGACT Symposium on Theory
  of Computing}, pages 716--729, 2017.

\bibitem[Bha97]{b97}
Rajendra Bhatia.
\newblock Matrix analysis, volume 169 of.
\newblock {\em Graduate texts in mathematics}, 1997.

\bibitem[BYJKS04]{bjks04}
Ziv Bar-Yossef, Thathachar~S Jayram, Ravi Kumar, and D~Sivakumar.
\newblock An information statistics approach to data stream and communication
  complexity.
\newblock {\em Journal of Computer and System Sciences}, 68(4):702--732, 2004.

\bibitem[CCF04]{ccf04}
Moses Charikar, Kevin~C. Chen, and Martin Farach{-}Colton.
\newblock Finding frequent items in data streams.
\newblock {\em Theor. Comput. Sci.}, 312(1):3--15, 2004.

\bibitem[Che52]{che52}
Herman Chernoff.
\newblock A measure of asymptotic efficiency for tests of a hypothesis based on
  the sum of observations.
\newblock {\em The Annals of Mathematical Statistics}, pages 493--507, 1952.

\bibitem[CLP{\etalchar{+}}20]{clp20}
Beidi Chen, Zichang Liu, Binghui Peng, Zhaozhuo Xu, Jonathan~Lingjie Li, Tri
  Dao, Zhao Song, Anshumali Shrivastava, and Christopher Re.
\newblock Mongoose: A learnable lsh framework for efficient neural network
  training.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2020.

\bibitem[CMF{\etalchar{+}}20]{cmf+20}
Beidi Chen, Tharun Medini, James Farwell, Charlie Tai, Anshumali Shrivastava,
  et~al.
\newblock Slide: In defense of smart algorithms over hardware acceleration for
  large-scale deep learning systems.
\newblock {\em Proceedings of Machine Learning and Systems}, 2:291--306, 2020.

\bibitem[CN20]{cn20}
Yeshwanth Cherapanamjeri and Jelani Nelson.
\newblock On adaptive distance estimation.
\newblock In {\em Advances in Neural Information Processing Systems}, 2020.

\bibitem[CS09]{cho09}
Youngmin Cho and Lawrence Saul.
\newblock Kernel methods for deep learning.
\newblock {\em Advances in neural information processing systems}, 22, 2009.

\bibitem[DKJ{\etalchar{+}}07]{dkj+07}
Jason~V Davis, Brian Kulis, Prateek Jain, Suvrit Sra, and Inderjit~S Dhillon.
\newblock Information-theoretic metric learning.
\newblock In {\em Proceedings of the 24th international conference on Machine
  learning}, pages 209--216, 2007.

\bibitem[GMS86]{ms86}
M~Gromov, V~Milman, and G~Schechtman.
\newblock Asymptotic theory of finite dimensional normed spaces, volume 1200 of
  lectures notes in mathematics, 1986.

\bibitem[GPPR04]{gpp04}
Cyril Gavoille, David Peleg, St{\'e}phane P{\'e}rennes, and Ran Raz.
\newblock Distance labeling in graphs.
\newblock {\em Journal of Algorithms}, 53(1):85--112, 2004.

\bibitem[HIKP12]{hikp12a}
Haitham Hassanieh, Piotr Indyk, Dina Katabi, and Eric Price.
\newblock Nearly optimal sparse fourier transform.
\newblock In {\em Proceedings of the forty-fourth annual ACM symposium on
  Theory of computing (STOC)}, pages 563--578, 2012.

\bibitem[HKNS15]{hkns15}
Monika Henzinger, Sebastian Krinninger, Danupon Nanongkai, and Thatchaphol
  Saranurak.
\newblock Unifying and strengthening hardness for dynamic problems via the
  online matrix-vector multiplication conjecture.
\newblock In {\em Proceedings of the forty-seventh annual ACM symposium on
  Theory of computing}, pages 21--30, 2015.

\bibitem[Ind06]{i06}
Piotr Indyk.
\newblock Stable distributions, pseudorandom generators, embeddings, and data
  stream computation.
\newblock {\em Journal of the ACM (JACM)}, 53(3):307--323, 2006.

\bibitem[IRW17]{irw17}
Piotr Indyk, Ilya Razenshteyn, and Tal Wagner.
\newblock Practical data-dependent metric compression with provable guarantees.
\newblock {\em Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[IW05]{iw05}
Piotr Indyk and David Woodruff.
\newblock Optimal approximations of the frequency moments of data streams.
\newblock In {\em Proceedings of the thirty-seventh annual ACM symposium on
  Theory of computing}, pages 202--208, 2005.

\bibitem[JKDG08]{jkdg08}
Prateek Jain, Brian Kulis, Inderjit~S Dhillon, and Kristen Grauman.
\newblock Online metric learning and fast similarity search.
\newblock In {\em NIPS}, volume~8, pages 761--768. Citeseer, 2008.

\bibitem[JL84]{jl84}
William~B Johnson and Joram Lindenstrauss.
\newblock Extensions of lipschitz mappings into a hilbert space.
\newblock {\em Contemporary mathematics}, 26(189-206):1, 1984.

\bibitem[KNPW11]{knpw11}
Daniel~M Kane, Jelani Nelson, Ely Porat, and David~P Woodruff.
\newblock Fast moment estimation in data streams in optimal space.
\newblock In {\em Proceedings of the forty-third annual ACM symposium on Theory
  of computing}, pages 745--754, 2011.

\bibitem[KNW10]{knw10}
Daniel~M Kane, Jelani Nelson, and David~P Woodruff.
\newblock On the exact space complexity of sketching and streaming small norms.
\newblock In {\em Proceedings of the twenty-first annual ACM-SIAM symposium on
  Discrete Algorithms}, pages 1161--1178. SIAM, 2010.

\bibitem[LDFU13]{ldfu13}
Yichao Lu, Paramveer Dhillon, Dean~P Foster, and Lyle Ungar.
\newblock Faster ridge regression via the subsampled randomized hadamard
  transform.
\newblock In {\em Advances in neural information processing systems (NIPS)},
  pages 369--377, 2013.

\bibitem[LNNT16]{lnnt16}
Kasper~Green Larsen, Jelani Nelson, Huy~L Nguy{\^e}n, and Mikkel Thorup.
\newblock Heavy hitters via cluster-preserving clustering.
\newblock In {\em 2016 IEEE 57th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 61--70. IEEE, 2016.

\bibitem[LNRW19]{lnrw19}
Jerry Li, Aleksandar Nikolov, Ilya Razenshteyn, and Erik Waingarten.
\newblock On mean estimation for general norms with statistical queries.
\newblock In {\em Conference on Learning Theory (COLT)}, pages 2158--2172.
  PMLR, 2019.

\bibitem[LSV18]{lsv18}
Yin~Tat Lee, Zhao Song, and Santosh~S Vempala.
\newblock Algorithmic theory of odes and sampling from well-conditioned
  logconcave densities.
\newblock {\em arXiv preprint arXiv:1812.06243}, 2018.

\bibitem[LW17]{lw17}
Kasper~Green Larsen and Ryan Williams.
\newblock Faster online matrix-vector multiplication.
\newblock In {\em Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on
  Discrete Algorithms}, pages 2182--2189. SIAM, 2017.

\bibitem[MMR22]{mmr19}
Konstantin Makarychev, Yury Makarychev, and Ilya Razenshteyn.
\newblock Performance of johnson--lindenstrauss transform for k-means and
  k-medians clustering.
\newblock {\em SIAM Journal on Computing}, (0):STOC19--269, 2022.

\bibitem[MPS14]{mps14}
Andrew~M McDonald, Massimiliano Pontil, and Dimitris Stamos.
\newblock Spectral k-support norm regularization.
\newblock {\em Advances in neural information processing systems}, 27, 2014.

\bibitem[NS19]{ns19}
Vasileios Nakos and Zhao Song.
\newblock Stronger l2/l2 compressed sensing; without iterating.
\newblock In {\em Proceedings of the 51st Annual ACM SIGACT Symposium on Theory
  of Computing}, pages 289--297, 2019.

\bibitem[Pag13]{p13}
Rasmus Pagh.
\newblock Compressed matrix multiplication.
\newblock {\em ACM Transactions on Computation Theory (TOCT)}, 5(3):1--17,
  2013.

\bibitem[Pel00]{pel00}
David Peleg.
\newblock Proximity-preserving labeling schemes.
\newblock {\em Journal of Graph Theory}, 33(3):167--176, 2000.

\bibitem[Pri11]{pri11}
Eric Price.
\newblock Efficient sketches for the set query problem.
\newblock In {\em Proceedings of the Twenty-Second Annual {ACM-SIAM} Symposium
  on Discrete Algorithms, {SODA} 2011, San Francisco, California, USA, January
  23-25, 2011}, pages 41--56, 2011.

\bibitem[SS02]{ss02}
Michael Saks and Xiaodong Sun.
\newblock Space lower bounds for distance approximation in the data stream
  model.
\newblock In {\em Proceedings of the thiry-fourth annual ACM symposium on
  Theory of computing}, pages 360--369, 2002.

\bibitem[SSSSC11]{ssy11}
Shai Shalev-Shwartz, Yoram Singer, Nathan Srebro, and Andrew Cotter.
\newblock Pegasos: Primal estimated sub-gradient solver for svm.
\newblock {\em Mathematical programming}, 127(1):3--30, 2011.

\bibitem[SSWZ22]{sswz22}
Zhao Song, Baocheng Sun, Omri Weinstein, and Ruizhe Zhang.
\newblock Sparse fourier transform over lattices: A unified approach to signal
  reconstruction.
\newblock http://arxiv.org/abs/2205.00658, 2022.

\bibitem[SSX21]{ssx21}
Anshumali Shrivastava, Zhao Song, and Zhaozhuo Xu.
\newblock Sublinear least-squares value iteration via locality sensitive
  hashing.
\newblock {\em arXiv preprint arXiv:2105.08285}, 2021.

\bibitem[SWY{\etalchar{+}}19]{swy+19}
Zhao Song, Ruosong Wang, Lin Yang, Hongyang Zhang, and Peilin Zhong.
\newblock Efficient symmetric norm regression via linear sketching.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[SWZ19]{swz19}
Zhao Song, David Woodruff, and Peilin Zhong.
\newblock Towards a zero-one law for column subset selection.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[SXZ22]{sxz22}
Zhao Song, Zhaozhuo Xu, and Lichen Zhang.
\newblock Speeding up sparsification with inner product search data structures.
\newblock {\em arXiv preprint arXiv:2204.03209}, 2022.

\bibitem[TZ12]{tz12}
Mikkel Thorup and Yin Zhang.
\newblock Tabulation-based 5-independent hashing with applications to linear
  probing and second moment estimation.
\newblock {\em {SIAM} J. Comput.}, 41(2):293--331, 2012.

\bibitem[Val12]{v12}
Gregory Valiant.
\newblock Finding correlations in subquadratic time, with applications to
  learning parities and juntas.
\newblock In {\em 2012 IEEE 53rd Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 11--20. IEEE, 2012.

\bibitem[WP11]{wp11}
Oren Weimann and David Peleg.
\newblock A note on exact distance labeling.
\newblock {\em Information processing letters}, 111(14):671--673, 2011.

\bibitem[XSS21]{xss21}
Zhaozhuo Xu, Zhao Song, and Anshumali Shrivastava.
\newblock Breaking the linear iteration cost barrier for some well-known
  conditional gradient methods using maxip data-structures.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)},
  34, 2021.

\end{thebibliography}
