


@inproceedings{ouyang2022training,
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  title={Training language models to follow instructions with human feedback},
  booktitle = {NeurIPS},
  year={2022}
}

@inproceedings{wu2020skip,
                      title={Skip Connections Matter: On the Transferability of Adversarial Examples Generated with ResNets},
                      author={Dongxian Wu and Yisen Wang and Shu-Tao Xia and James Bailey and Xingjun Ma},
                      booktitle={ICLR},
                      year={2020}}

@article{bai2023query,
                        title={Query efficient black-box adversarial attack on deep neural networks},
                        author={Bai, Yang and Wang, Yisen and Zeng, Yuyuan and Jiang, Yong and Xia, Shu-Tao},
                        journal={Pattern Recognition},
                        volume={133},
                        pages={109037},
                        year={2023},
                        publisher={Elsevier}}







@article{zheng2023judging,
      title={Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric P. Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      journal={arXiv preprint arXiv:2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@inproceedings{touvron2023llama,
      title={Llama 2: Open Foundation and Fine-Tuned Chat Models}, 
      author={Hugo Touvron and Louis Martin and Kevin Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Dan Bikel and Lukas Blecher and Cristian Canton Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel Kloumann and Artem Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and Ranjan Subramanian and Xiaoqing Ellen Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zheng Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
      year={2023},
      booktitle={arXiv},
}




@inproceedings{shayegani2023survey,
      title={Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks}, 
      author={Erfan Shayegani and Md Abdullah Al Mamun and Yu Fu and Pedram Zaree and Yue Dong and Nael Abu-Ghazaleh},
      year={2023},
      booktitle={arXiv},
}



@misc{walker2022dan,
  author       = {Walker Spider},
  title        = {Dan is my new friend},
  year         = {2022},
  howpublished ={\url{https://www.reddit.com/r/ChatGPT/comments/zlcyr9/dan_is_my_new_friend/}}
}

@misc{burgess2023hacking,
  author       = {Matt Burgess},
  title        = {The Hacking of {ChatGPT} Is Just Getting Started},
  year         = {2023},
  howpublished = {\url{https://www.wired.com/story/chatgpt-jailbreak-generative-ai-hacking/}}
}





@inproceedings{li2023multistep,
      title={Multi-step Jailbreaking Privacy Attacks on ChatGPT}, 
      author={Haoran Li and Dadi Guo and Wei Fan and Mingshi Xu and Jie Huang and Fanpu Meng and Yangqiu Song},
      year={2023},
      booktitle={EMNLP}
}


@inproceedings{GCG,
      title={Universal and Transferable Adversarial Attacks on Aligned Language Models}, 
      author={Andy Zou and Zifan Wang and J. Zico Kolter and Matt Fredrikson},
      year={2023},
      booktitle={arXiv},
}

@article{bai2022training,
      title={Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback}, 
      author={Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
      year={2022},
      journal={arXiv preprint arXiv:2204.05862},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{chung2022scaling,
      title={Scaling Instruction-Finetuned Language Models}, 
      author={Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
      year={2022},
      journal={arXiv preprint arXiv:2210.11416},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{jain2023baseline,
      title={Baseline Defenses for Adversarial Attacks Against Aligned Language Models}, 
      author={Neel Jain and Avi Schwarzschild and Yuxin Wen and Gowthami Somepalli and John Kirchenbauer and Ping-yeh Chiang and Micah Goldblum and Aniruddha Saha and Jonas Geiping and Tom Goldstein},
      year={2023},
      booktitle={arXiv}
}

@inproceedings{kumar2023certifying,
      title={Certifying LLM Safety against Adversarial Prompting}, 
      author={Aounon Kumar and Chirag Agarwal and Suraj Srinivas and Aaron Jiaxun Li and Soheil Feizi and Himabindu Lakkaraju},
      year={2023},
      booktitle={arXiv}
}

@inproceedings{
phute2023llm,
title={LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked},
author={Mansi Phute and Alec Helbling and Matthew Daniel Hull and ShengYun Peng and Sebastian Szyller and Cory Cornelius and Duen Horng Chau},
booktitle={The Second Tiny Papers Track at ICLR},
year={2024}
}





@inproceedings{sabir2023interpretability,
      title={Interpretability and Transparency-Driven Detection and Transformation of Textual Adversarial Examples (IT-DT)}, 
      author={Bushra Sabir and M. Ali Babar and Sharif Abuadbba},
      year={2023},
      booktitle={arXiv},
}

@inproceedings{bhardwaj2023redteaming,
      title={Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment}, 
      author={Rishabh Bhardwaj and Soujanya Poria},
      year={2023},
      booktitle={arXiv}
}



@inproceedings{zhang2023textcrs,
  title={Text-crs: A generalized certified robustness framework against textual adversarial attacks},
  author={Zhang, Xinyu and Hong, Hanbin and Hong, Yuan and Huang, Peng and Wang, Binghui and Ba, Zhongjie and Ren, Kui},
  booktitle={S\&P},
  year={2024}
}





@article{perez2022red,
      title={Red Teaming Language Models with Language Models}, 
      author={Ethan Perez and Saffron Huang and Francis Song and Trevor Cai and Roman Ring and John Aslanides and Amelia Glaese and Nat McAleese and Geoffrey Irving},
      year={2022},
      journal={arXiv preprint arXiv:2202.03286},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{liu2023jailbreaking,
      title={Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study}, 
      author={Yi Liu and Gelei Deng and Zhengzi Xu and Yuekang Li and Yaowen Zheng and Ying Zhang and Lida Zhao and Tianwei Zhang and Yang Liu},
      year={2023},
      journal={arXiv preprint arXiv:2305.13860},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}


@inproceedings{autodan,
  title={AutoDAN: Interpretable Gradient-Based Adversarial Attacks on Large Language Models},
  author={Zhu, Sicheng and Zhang, Ruiyi and An, Bang and Wu, Gang and Barrow, Joe and Wang, Zichao and Huang, Furong and Nenkova, Ani and Sun, Tong},
  booktitle={COLM},
  year={2024}
}


@inproceedings{wei_jailbreak_2023,
  title={Jailbreak and guard aligned language models with only few in-context demonstrations},
  author={Wei, Zeming and Wang, Yifei and Wang, Yisen},
  booktitle={arXiv},
  year={2023}
}


@inproceedings{bespalov-etal-2023-towards,
    title = "Towards Building a Robust Toxicity Predictor",
    author = "Bespalov, Dmitriy  and
      Bhabesh, Sourav  and
      Xiang, Yi  and
      Zhou, Liutong  and
      Qi, Yanjun",
    booktitle = "ACL",
    year = "2023",
}



@inproceedings{
robey2023smoothllm,
title={SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks},
author={Alexander Robey and Eric Wong and Hamed Hassani and George Pappas},
booktitle={NeurIPS Workshop R0-FoMo},
year={2023},
}






@article{carlini2023aligned,
      title={Are aligned neural networks adversarially aligned?}, 
      author={Nicholas Carlini and Milad Nasr and Christopher A. Choquette-Choo and Matthew Jagielski and Irena Gao and Anas Awadalla and Pang Wei Koh and Daphne Ippolito and Katherine Lee and Florian Tramer and Ludwig Schmidt},
      year={2023},
      journal={arXiv preprint arXiv:2306.15447},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{goodfellow2015explaining,
      title={Explaining and Harnessing Adversarial Examples}, 
      author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
      year={2015},
      journal={arXiv preprint arXiv:1412.6572},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{ms-marco,
      title={MS MARCO: A Human Generated MAchine Reading COmprehension Dataset}, 
      author={Payal Bajaj and Daniel Campos and Nick Craswell and Li Deng and Jianfeng Gao and Xiaodong Liu and Rangan Majumder and Andrew McNamara and Bhaskar Mitra and Tri Nguyen and Mir Rosenberg and Xia Song and Alina Stoica and Saurabh Tiwary and Tong Wang},
      year={2018},
      booktitle={arXiv}
}

@article{Guanaco,
      title={QLoRA: Efficient Finetuning of Quantized LLMs}, 
      author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
      year={2023},
      journal={arXiv preprint arXiv:2305.14314},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{biderman2023pythia,
      title={Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling}, 
      author={Stella Biderman and Hailey Schoelkopf and Quentin Anthony and Herbie Bradley and Kyle O'Brien and Eric Hallahan and Mohammad Aflah Khan and Shivanshu Purohit and USVSN Sai Prashanth and Edward Raff and Aviya Skowron and Lintang Sutawika and Oskar van der Wal},
      year={2023},
      journal={arXiv preprint arXiv:2304.01373},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{falcon,
      title={The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only}, 
      author={Guilherme Penedo and Quentin Malartic and Daniel Hesslow and Ruxandra Cojocaru and Alessandro Cappelli and Hamza Alobeidli and Baptiste Pannier and Ebtesam Almazrouei and Julien Launay},
      year={2023},
      journal={arXiv preprint arXiv:2306.01116},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{du-etal-2022-glm,
    title = "{GLM}: General Language Model Pretraining with Autoregressive Blank Infilling",
    author = "Du, Zhengxiao  and
      Qian, Yujie  and
      Liu, Xiao  and
      Ding, Ming  and
      Qiu, Jiezhong  and
      Yang, Zhilin  and
      Tang, Jie",
    booktitle = "ACL",
    year = "2022",
}

@article{mosaicml2023mpt7b,
    author = {{MosaicML NLP Team}},
    title = {Introducing mpt-7b: A new standard for open-source, commercially usable llms},
    year = {2023},
    url = {www.mosaicml.com/blog/mpt-7b},
    note = {Accessed: 2023-05-05}
}

@inproceedings{cao2023defending,
  title={Defending against alignment-breaking attacks via robustly aligned llm},
  author={Cao, Bochuan and Cao, Yuanpu and Lin, Lu and Chen, Jinghui},
  booktitle={arXiv},
  year={2023}
}


@inproceedings{alon2023detecting,
      title={Detecting Language Model Attacks with Perplexity}, 
      author={Gabriel Alon and Michael Kamfonas},
      year={2023},
      booktitle={arXiv},
}


@article{piet2023jatmo,
  title={Jatmo: Prompt Injection Defense by Task-Specific Finetuning},
  author={Piet, Julien and Alrashed, Maha and Sitawarin, Chawin and Chen, Sizhe and Wei, Zeming and Sun, Elizabeth and Alomair, Basel and Wagner, David},
  journal={arXiv preprint arXiv:2312.17673},
  year={2023}
}


@inproceedings{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  booktitle={arXiv},
  year={2017}
}

@article{liu2023autodan,
      title={AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models}, 
      author={Xiaogeng Liu and Nan Xu and Muhao Chen and Chaowei Xiao},
      year={2023},
      journal={arXiv preprint arXiv:2310.04451},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}



@inproceedings{shin2020autoprompt,
  title={AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts},
  author={Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L and Wallace, Eric and Singh, Sameer},
  booktitle={EMNLP},
  year={2020}
}




@inproceedings{dong2022survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Sui, Zhifang},
  booktitle={arXiv},
  year={2022}
}


@inproceedings{wang2019improving,
  title={Improving adversarial robustness requires revisiting misclassified examples},
  author={Wang, Yisen and Zou, Difan and Yi, Jinfeng and Bailey, James and Ma, Xingjun and Gu, Quanquan},
  booktitle={ICLR},
  year={2019}
}


@inproceedings{wu2020adversarial,
  title={Adversarial weight perturbation helps robust generalization},
  author={Wu, Dongxian and Xia, Shu-Tao and Wang, Yisen},
    booktitle={NeurIPS},
  year={2020}
}

@inproceedings{zhang2019theoretically,
  title={Theoretically principled trade-off between robustness and accuracy},
  author={Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael},
  booktitle={ICML},
year={2019}
}

@inproceedings{athalye2018obfuscated,
  title={Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples},
  author={Athalye, Anish and Carlini, Nicholas and Wagner, David},
  booktitle={ICML},
  year={2018},
}

@inproceedings{mo2022adversarial,
  title={When adversarial training meets vision transformers: Recipes from training to architecture},
  author={Mo, Yichuan and Wu, Dongxian and Wang, Yifei and Guo, Yiwen and Wang, Yisen},
  booktitle={NeurIPS},
  year={2022},
}

@inproceedings{zhang2024boosting,
title={Boosting Jailbreak Attack with Momentum},
author={Yihao Zhang and Zeming Wei},
booktitle={ICLR 2024 Workshop on Reliable and Responsible Foundation Models},
year={2024}
}

@inproceedings{wei2023cfa,
title={Cfa: Class-wise calibrated fair adversarial training},
author={Wei, Zeming and Wang, Yifei and Guo, Yiwen and Wang, Yisen},
booktitle={CVPR},
year={2023}
}


@inproceedings{openai2023gpt4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  booktitle={arXiv},
  year={2023}
}

@article{wu2023brief,
  title={A brief overview of ChatGPT: The history, status quo and potential future development},
  author={Wu, Tianyu and He, Shizhu and Liu, Jingping and Sun, Siqi and Liu, Kang and Han, Qing-Long and Tang, Yang},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={10},
  number={5},
  pages={1122--1136},
  year={2023},
  publisher={IEEE}
}



@article{xie2023defending,
  title={Defending chatgpt against jailbreak attack via self-reminders},
  author={Xie, Yueqi and Yi, Jingwei and Shao, Jiawei and Curl, Justin and Lyu, Lingjuan and Chen, Qifeng and Xie, Xing and Wu, Fangzhao},
  journal={Nature Machine Intelligence},
  volume={5},
  number={12},
  pages={1486--1496},
  year={2023},
  publisher={Nature Publishing Group UK London}
}


@inproceedings{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  booktitle={NeurIPS},
  year={2024}
}


@inproceedings{cold-attack,
  title={COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability},
  author={Guo, Xingang and Yu, Fangxu and Zhang, Huan and Qin, Lianhui and Hu, Bin},
  booktitle={ICML},
  year={2024}
}



@article{jiang2023mistral,
  title={Mistral 7B},
  author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal={arXiv preprint arXiv:2310.06825},
  year={2023}
}


@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{zhou2024robust,
  title={Robust prompt optimization for defending language models against jailbreaking attacks},
  author={Zhou, Andy and Li, Bo and Wang, Haohan},
  journal={arXiv preprint arXiv:2401.17263},
  year={2024}
}



@misc{christian2023jailbreak,
  author       = {Jon Christian},
  title        = {Amazing "Jailbreak" Bypasses {ChatGPT}'s Ethics Safeguards},
  year         = {2023},
  howpublished = {\url{https://futurism.com/amazing-jailbreak-chatgpt}},
}


@inproceedings{chao2023jailbreaking,
  title={Jailbreaking black box large language models in twenty queries},
  author={Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric},
  booktitle={arXiv},
  year={2023}
}


@inproceedings{mehrotra2023tree,
  title={Tree of attacks: Jailbreaking black-box llms automatically},
  author={Mehrotra, Anay and Zampetakis, Manolis and Kassianik, Paul and Nelson, Blaine and Anderson, Hyrum and Singer, Yaron and Karbasi, Amin},
  booktitle={arXiv},
  year={2023}
}


@inproceedings{xu2024safedecoding,
  title={Safedecoding: Defending against jailbreak attacks via safety-aware decoding},
  author={Xu, Zhangchen and Jiang, Fengqing and Niu, Luyao and Jia, Jinyuan and Lin, Bill Yuchen and Poovendran, Radha},
  booktitle={ACL},
  year={2024}
}


@inproceedings{zheng2024prompt,
  title={On prompt-driven safeguarding for large language models},
  author={Zheng, Chujie and Yin, Fan and Zhou, Hao and Meng, Fandong and Zhou, Jie and Chang, Kai-Wei and Huang, Minlie and Peng, Nanyun},
  booktitle={ICML},
  year={2024}
}


@inproceedings{shen2023anything,
  title={" do anything now": Characterizing and evaluating in-the-wild jailbreak prompts on large language models},
  author={Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Shen, Yun and Zhang, Yang},
  booktitle={CCS},
  year={2024}
}

@inproceedings{deng2023multilingual,
  title={Multilingual jailbreak challenges in large language models},
  author={Deng, Yue and Zhang, Wenxuan and Pan, Sinno Jialin and Bing, Lidong},
  booktitle={ICLR},
  year={2024}
}


@article{chao2024jailbreakbench,
  title={Jailbreakbench: An open robustness benchmark for jailbreaking large language models},
  author={Chao, Patrick and Debenedetti, Edoardo and Robey, Alexander and Andriushchenko, Maksym and Croce, Francesco and Sehwag, Vikash and Dobriban, Edgar and Flammarion, Nicolas and Pappas, George J and Tramer, Florian and others},
  journal={arXiv preprint arXiv:2404.01318},
  year={2024}
}


@inproceedings{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  booktitle={ICLR},
  year={2021}
}


@inproceedings{wei2023jailbroken,
  title={Jailbroken: How does llm safety training fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  booktitle={NeurIPS},
  year={2023}
}





@inproceedings{zhang2023planning,
  title={Planning with large language models for code generation},
  author={Zhang, Shun and Chen, Zhenfang and Shen, Yikang and Ding, Mingyu and Tenenbaum, Joshua B and Gan, Chuang},
  booktitle={ICLR},
  year={2023}
}



@inproceedings{liu2024your,
  title={Is your code generated by chatgpt really correct? rigorous evaluation of large language models for code generation},
  author={Liu, Jiawei and Xia, Chunqiu Steven and Wang, Yuyao and Zhang, Lingming},
  booktitle={NeurIPS},
  year={2024}
}


@inproceedings{liu2023improving,
  title={Improving large language model fine-tuning for solving math problems},
  author={Liu, Yixin and Singh, Avi and Freeman, C Daniel and Co-Reyes, John D and Liu, Peter J},
  booktitle={arXiv},
  year={2023}
}




@inproceedings{imani2023mathprompter,
  title={Mathprompter: Mathematical reasoning using large language models},
  author={Imani, Shima and Du, Liang and Shrivastava, Harsh},
  booktitle={SIGIR},
  year={2023}
}


@article{shanahan2023role,
  title={Role play with large language models},
  author={Shanahan, Murray and McDonell, Kyle and Reynolds, Laria},
  journal={Nature},
  volume={623},
  number={7987},
  pages={493--498},
  year={2023}
}

@inproceedings{wang2023rolellm,
  title={Rolellm: Benchmarking, eliciting, and enhancing role-playing abilities of large language models},
  author={Wang, Zekun Moore and Peng, Zhongyuan and Que, Haoran and Liu, Jiaheng and Zhou, Wangchunshu and Wu, Yuhan and Guo, Hongcheng and Gan, Ruitong and Ni, Zehao and Yang, Jian and others},
  booktitle={arXiv},
  year={2023}
}


@article{yao2024survey,
  title={A survey on large language model (llm) security and privacy: The good, the bad, and the ugly},
  author={Yao, Yifan and Duan, Jinhao and Xu, Kaidi and Cai, Yuanfang and Sun, Zhibo and Zhang, Yue},
  journal={High-Confidence Computing},
  pages={100211},
  year={2024},
  publisher={Elsevier}
}



@inproceedings{rafailov2024direct,
  title={Direct preference optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
  booktitle={NeurIPS},
  year={2024}
}


@inproceedings{wang2024adversarial,
  title={On the Adversarial Transferability of Generalized" Skip Connections"},
  author={Wang, Yisen and Mo, Yichuan and Wu, Dongxian and Li, Mingjie and Ma, Xingjun and Lin, Zhouchen},
  booktitle={arXiv},
  year={2024}
}

@inproceedings{li2022improving,
  title={Improving generative adversarial networks via adversarial learning in latent space},
  author={Li, Yang and Mo, Yichuan and Shi, Liangliang and Yan, Junchi},
  booktitle={NeurIPS},
  year={2022}
}



@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={S$\&$P},
  year={2017},
}


@inproceedings{ren2022dice,
  title={Dice: Domain-attack invariant causal learning for improved data privacy protection and adversarial robustness},
  author={Ren, Qibing and Chen, Yiting and Mo, Yichuan and Wu, Qitian and Yan, Junchi},
  booktitle={SIGKDD},
  year={2022}
}

@inproceedings{wang2019dynamic,
                        title={On the Convergence and Robustness of Adversarial Training},
                        author={Wang, Yisen and Ma, Xingjun and Bailey, James and Yi, Jinfeng and Zhou, Bowen and Gu, Quanquan},
                        booktitle={ICML},
                        year={2019}}

@inproceedings{wang2020improving,
                      title={Improving Adversarial Robustness Requires Revisiting Misclassified Examples},
                      author={Yisen Wang and Difan Zou and Jinfeng Yi and James Bailey and Xingjun Ma and Quanquan Gu},
                      booktitle={ICLR},
                      year={2020}}

@inproceedings{zou2024system,
  title={Is the System Message Really Important to Jailbreaks in Large Language Models?},
  author={Zou, Xiaotian and Chen, Yongkang and Li, Ke},
  booktitle={arXiv},
  year={2024}
}

@inproceedings{wang2022self,
                        title={Self-Ensemble Adversarial Training for Improved Robustness},
                        author={Wang, Hongjun and Wang, Yisen},
                        booktitle={ICLR},
                        year={2022}}

@article{chu2024comprehensive,
  title={Comprehensive assessment of jailbreak attacks against llms},
  author={Chu, Junjie and Liu, Yugeng and Yang, Ziqing and Shen, Xinyue and Backes, Michael and Zhang, Yang},
  journal={arXiv preprint arXiv:2402.05668},
  year={2024}
}

@inproceedings{ma2021finding,
                      title={Finding Optimal Tangent Points for Reducing Distortions of Hard-label Attacks},
                      author={Ma, Chen and Guo, Xiangyu and Chen, Li and Yong, Jun-Hai and Wang, Yisen},
                      booktitle={NeurIPS},
                      year={2021}}

@inproceedings{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  booktitle={arXiv},
  year={2022}
}

@inproceedings{huang2021unlearnable,
                        title={Unlearnable Examples: Making Personal Data Unexploitable},
                        author={Huang, Hanxun and Ma, Xingjun and Erfani, Sarah Monazam and Bailey, James and Wang, Yisen},
                        booktitle={ICLR},
                        year={2021}}

@inproceedings{wang2023simple,
                        title={Generalist: Decoupling Natural and Robust Generalization},
                        author={Hongjun Wang and Yisen Wang},
                        booktitle={CVPR},
                        year={2023}}

@inproceedings{zhou2024virtual,
  title={Virtual Context: Enhancing Jailbreak Attacks with Special Token Injection},
  author={Zhou, Yuqi and Lu, Lin and Sun, Hanchi and Zhou, Pan and Sun, Lichao},
  booktitle={arXiv},
  year={2024}
}


@inproceedings{perez2022ignore,
  title={Ignore previous prompt: Attack techniques for language models},
  author={Perez, F{\'a}bio and Ribeiro, Ian},
  booktitle={arXiv},
  year={2022}
}


@inproceedings{li2024cross,
  title={A cross-language investigation into jailbreak attacks in large language models},
  author={Li, Jie and Liu, Yi and Liu, Chongyang and Shi, Ling and Ren, Xiaoning and Zheng, Yaowen and Liu, Yang and Xue, Yinxing},
  booktitle={arXiv},
  year={2024}
}



@inproceedings{
yong2023lowresource,
title={Low-Resource Languages Jailbreak {GPT}-4},
author={Zheng Xin Yong and Cristina Menghini and Stephen Bach},
booktitle={Socially Responsible Language Modelling Research},
year={2023}
}


@article{kanepajs2024towards,
  title={Towards Safe Multilingual Frontier AI},
  author={Kanepajs, Art{\=u}rs and Ivanov, Vladimir and Moulange, Richard},
  journal={arXiv preprint arXiv:2409.13708},
  year={2024}
}


@inproceedings{deng2023attack,
  title={Attack prompt generation for red teaming and defending large language models},
  author={Deng, Boyi and Wang, Wenjie and Feng, Fuli and Deng, Yang and Wang, Qifan and He, Xiangnan},
  booktitle={arXiv},
  year={2023}
}


@inproceedings{bhardwaj2023red,
  title={Red-teaming large language models using chain of utterances for safety-alignment},
  author={Bhardwaj, Rishabh and Poria, Soujanya},
  booktitle={arXiv},
  year={2023}
}


@inproceedings{bianchi2023safety,
  title={Safety-tuned llamas: Lessons from improving the safety of large language models that follow instructions},
  author={Bianchi, Federico and Suzgun, Mirac and Attanasio, Giuseppe and R{\"o}ttger, Paul and Jurafsky, Dan and Hashimoto, Tatsunori and Zou, James},
  booktitle={arXiv},
  year={2023}
}


@inproceedings{zhang2024safe,
  title={Safe unlearning: A surprisingly effective and generalizable solution to defend against jailbreak attacks},
  author={Zhang, Zhexin and Yang, Junxiao and Ke, Pei and Cui, Shiyao and Zheng, Chujie and Wang, Hongning and Huang, Minlie},
  booktitle={arXiv},
  year={2024}
}





@inproceedings{wang2024theoretical,
  title={A Theoretical Understanding of Self-Correction through In-context Alignment},
  author={Wang, Yifei and Wu, Yuyang and Wei, Zeming and Jegelka, Stefanie and Wang, Yisen},
  booktitle={arXiv},
  year={2024}
}


@inproceedings{zhang2024towards,
  title={Towards General Conceptual Model Editing via Adversarial Representation Engineering},
  author={Zhang, Yihao and Wei, Zeming and Sun, Jun and Sun, Meng},
  booktitle={NeurIPS},
  year={2024}
}

@inproceedings{zhang2024duality,
  title={On the Duality Between Sharpness-Aware Minimization and Adversarial Training},
  author={Zhang, Yihao and He, Hangzhou and Zhu, Jingyu and Chen, Huanran and Wang, Yifei and Wei, Zeming},
  booktitle={ICML 2024},
  year={2024}
}

@inproceedings{jia2024improved,
  title={Improved techniques for optimization-based jailbreaking on large language models},
  author={Jia, Xiaojun and Pang, Tianyu and Du, Chao and Huang, Yihao and Gu, Jindong and Liu, Yang and Cao, Xiaochun and Lin, Min},
  booktitle={arXiv},
  year={2024}
}

@inproceedings{li2020implicit,
  title={Implicit euler skip connections: Enhancing adversarial robustness via numerical stability},
  author={Li, Mingjie and He, Lingshen and Lin, Zhouchen},
  booktitle={ICML},
  year={2020}
}


