\begin{thebibliography}{23}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Belkin et~al.(2019{\natexlab{a}})Belkin, Hsu, Ma, and
  Mandal]{belkin2019reconciling}
Belkin, M., Hsu, D., Ma, S., and Mandal, S.
\newblock Reconciling modern machine-learning practice and the classical
  bias--variance trade-off.
\newblock \emph{Proceedings of the National Academy of Sciences}, 116\penalty0
  (32):\penalty0 15849--15854, 2019{\natexlab{a}}.

\bibitem[Belkin et~al.(2019{\natexlab{b}})Belkin, Hsu, and Xu]{belkin2019two}
Belkin, M., Hsu, D., and Xu, J.
\newblock Two models of double descent for weak features.
\newblock \emph{arXiv preprint arXiv:1903.07571}, 2019{\natexlab{b}}.

\bibitem[Breiman \& Freedman(1983)Breiman and Freedman]{breiman1983many}
Breiman, L. and Freedman, D.
\newblock How many variables should be entered in a regression equation?
\newblock \emph{Journal of the American Statistical Association}, 78\penalty0
  (381):\penalty0 131--136, 1983.

\bibitem[Denton et~al.(2019)Denton, Parke, Tao, and
  Zhang]{denton2019eigenvectors}
Denton, P.~B., Parke, S.~J., Tao, T., and Zhang, X.
\newblock Eigenvectors from eigenvalues: {A} survey of a basic identity in
  linear algebra.
\newblock \emph{arXiv preprint arXiv:1908.03795}, 2019.

\bibitem[Geiger et~al.(2019)Geiger, Jacot, Spigler, Gabriel, Sagun, d'Ascoli,
  Biroli, Hongler, and Wyart]{geiger2019scaling}
Geiger, M., Jacot, A., Spigler, S., Gabriel, F., Sagun, L., d'Ascoli, S.,
  Biroli, G., Hongler, C., and Wyart, M.
\newblock Scaling description of generalization with number of parameters in
  deep learning.
\newblock \emph{arXiv preprint arXiv:1901.01608}, 2019.

\bibitem[Gower et~al.(2004)Gower, Dijksterhuis, et~al.]{gower2004procrustes}
Gower, J.~C., Dijksterhuis, G.~B., et~al.
\newblock \emph{Procrustes {P}roblems}, volume~30.
\newblock Oxford University Press on Demand, 2004.

\bibitem[Hastie et~al.(2019)Hastie, Montanari, Rosset, and
  Tibshirani]{hastie2019surprises}
Hastie, T., Montanari, A., Rosset, S., and Tibshirani, R.~J.
\newblock Surprises in high-dimensional ridgeless least squares interpolation.
\newblock \emph{arXiv preprint arXiv:1903.08560}, 2019.

\bibitem[Hwang(2004)]{hwang2004cauchy}
Hwang, S.-G.
\newblock Cauchy's interlace theorem for eigenvalues of {H}ermitian matrices.
\newblock \emph{The American Mathematical Monthly}, 111\penalty0 (2):\penalty0
  157--159, 2004.

\bibitem[Johnstone \& Lu(2009)Johnstone and Lu]{johnstone2009consistency}
Johnstone, I.~M. and Lu, A.~Y.
\newblock On consistency and sparsity for principal components analysis in high
  dimensions.
\newblock \emph{Journal of the American Statistical Association}, 104\penalty0
  (486):\penalty0 682--693, 2009.

\bibitem[Jolliffe(1972)]{jolliffe1972discarding}
Jolliffe, I.~T.
\newblock Discarding variables in a principal component analysis. i: Artificial
  data.
\newblock \emph{Journal of the Royal Statistical Society: Series C (Applied
  Statistics)}, 21\penalty0 (2):\penalty0 160--173, 1972.

\bibitem[Jolliffe(1973)]{jolliffe1973discarding}
Jolliffe, I.~T.
\newblock Discarding variables in a principal component analysis. ii: Real
  data.
\newblock \emph{Journal of the Royal Statistical Society: Series C (Applied
  Statistics)}, 22\penalty0 (1):\penalty0 21--31, 1973.

\bibitem[Kahan(2011)]{Kahan11}
Kahan, W.
\newblock The nearest orthogonal or unitary matrix, August 2011.
\newblock "URL:
  \url{https://people.eecs.berkeley.edu/~wkahan/Math128/NearestQ.pdf}. Last
  visited on 2020/02/06".

\bibitem[Keller(1975)]{keller1975closest}
Keller, J.~B.
\newblock Closest unitary, orthogonal and {H}ermitian operators to a given
  operator.
\newblock \emph{Mathematics Magazine}, 48\penalty0 (4):\penalty0 192--197,
  1975.

\bibitem[Mei \& Montanari(2019)Mei and Montanari]{mei2019generalization}
Mei, S. and Montanari, A.
\newblock The generalization error of random features regression: Precise
  asymptotics and double descent curve.
\newblock \emph{arXiv preprint arXiv:1908.05355}, 2019.

\bibitem[Nie et~al.(2010)Nie, Xu, Tsang, and Zhang]{nie2010flexible}
Nie, F., Xu, D., Tsang, I. W.-H., and Zhang, C.
\newblock Flexible manifold embedding: A framework for semi-supervised and
  unsupervised dimension reduction.
\newblock \emph{IEEE Transactions on Image Processing}, 19\penalty0
  (7):\penalty0 1921--1932, 2010.

\bibitem[Paul(2007)]{paul2007asymptotics}
Paul, D.
\newblock Asymptotics of sample eigenstructure for a large dimensional spiked
  covariance model.
\newblock \emph{Statistica Sinica}, pp.\  1617--1642, 2007.

\bibitem[Shen et~al.(2016)Shen, Shen, and Marron]{shen2016general}
Shen, D., Shen, H., and Marron, J.
\newblock A general framework for consistency of principal component analysis.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 5218--5251, 2016.

\bibitem[Spigler et~al.(2018)Spigler, Geiger, d'Ascoli, Sagun, Biroli, and
  Wyart]{spigler2018jamming}
Spigler, S., Geiger, M., d'Ascoli, S., Sagun, L., Biroli, G., and Wyart, M.
\newblock A jamming transition from under-to over-parametrization affects loss
  landscape and generalization.
\newblock \emph{arXiv preprint arXiv:1810.09665}, 2018.

\bibitem[Sugiyama(2006)]{sugiyama2006local}
Sugiyama, M.
\newblock Local fisher discriminant analysis for supervised dimensionality
  reduction.
\newblock In \emph{Proceedings of the 23rd International Conference on Machine
  Learning}, pp.\  905--912, 2006.

\bibitem[Ulfarsson \& Solo(2011)Ulfarsson and Solo]{ulfarsson2011vector}
Ulfarsson, M.~O. and Solo, V.
\newblock Vector $ l\_0 $ sparse variable {PCA}.
\newblock \emph{IEEE Transactions on Signal Processing}, 59\penalty0
  (5):\penalty0 1949--1958, 2011.

\bibitem[Xu \& Hsu(2019)Xu and Hsu]{xu2019number}
Xu, J. and Hsu, D.~J.
\newblock On the number of variables to use in principal component regression.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  5095--5104, 2019.

\bibitem[Yang et~al.(2006)Yang, Fu, Zha, and Barlow]{yang2006semi}
Yang, X., Fu, H., Zha, H., and Barlow, J.
\newblock Semi-supervised nonlinear dimensionality reduction.
\newblock In \emph{Proceedings of the 23rd International Conference on Machine
  Learning}, pp.\  1065--1072, 2006.

\bibitem[Zhang et~al.(2007)Zhang, Zhou, and Chen]{zhang2007semi}
Zhang, D., Zhou, Z.-H., and Chen, S.
\newblock Semi-supervised dimensionality reduction.
\newblock In \emph{Proceedings of the 2007 {SIAM} International Conference on
  Data Mining}, pp.\  629--634. SIAM, 2007.

\end{thebibliography}
