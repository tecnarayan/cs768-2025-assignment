\begin{thebibliography}{57}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Addepalli et~al.(2022)Addepalli, Jain, Sriramanan, and
  Radhakrishnan]{addepalli2021oaat}
S.~Addepalli, S.~Jain, G.~Sriramanan, and V.~B. Radhakrishnan.
\newblock Scaling adversarial training to large perturbation bounds.
\newblock In \emph{The European Conference on Computer Vision (ECCV)}, 2022.

\bibitem[Andriushchenko et~al.(2020)Andriushchenko, Croce, Flammarion, and
  Hein]{andriushchenko2019square}
M.~Andriushchenko, F.~Croce, N.~Flammarion, and M.~Hein.
\newblock Square attack: a query-efficient black-box adversarial attack via
  random search.
\newblock In \emph{The European Conference on Computer Vision (ECCV)}, 2020.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye2018obfuscated}
A.~Athalye, N.~Carlini, and D.~Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2018.

\bibitem[Ben-David et~al.(2010)Ben-David, Blitzer, Crammer, Kulesza, Pereira,
  and Vaughan]{ben2010theory}
S.~Ben-David, J.~Blitzer, K.~Crammer, A.~Kulesza, F.~Pereira, and J.~W.
  Vaughan.
\newblock A theory of learning from different domains.
\newblock \emph{Machine learning}, 79\penalty0 (1):\penalty0 151--175, 2010.

\bibitem[Bui et~al.(2022)Bui, Le, Tran, Zhao, and Phung]{bui2022a}
A.~T. Bui, T.~Le, Q.~H. Tran, H.~Zhao, and D.~Phung.
\newblock A unified wasserstein distributional robustness framework for
  adversarial training.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2022.

\bibitem[Cai et~al.(2018)Cai, Liu, and Song]{CaiCAT}
Q.-Z. Cai, C.~Liu, and D.~Song.
\newblock Curriculum adversarial training.
\newblock In \emph{Proceedings of the 27th International Joint Conference on
  Artificial Intelligence (IJCAI)}, 2018.

\bibitem[Carmon et~al.(2019)Carmon, Raghunathan, Schmidt, Duchi, and
  Liang]{carmon2019unlabeled}
Y.~Carmon, A.~Raghunathan, L.~Schmidt, J.~C. Duchi, and P.~S. Liang.
\newblock Unlabeled data improves adversarial robustness.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem[Croce and Hein(2020)]{croce2020reliable}
F.~Croce and M.~Hein.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Croce et~al.(2021)Croce, Andriushchenko, Sehwag, Debenedetti,
  Flammarion, Chiang, Mittal, and Hein]{croce2021robustbench}
F.~Croce, M.~Andriushchenko, V.~Sehwag, E.~Debenedetti, N.~Flammarion,
  M.~Chiang, P.~Mittal, and M.~Hein.
\newblock Robustbench: a standardized adversarial robustness benchmark.
\newblock In \emph{Thirty-fifth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track (Round 2)}, 2021.

\bibitem[Cubuk et~al.(2019)Cubuk, Zoph, Mane, Vasudevan, and
  Le]{cubuk2018autoaugment}
E.~D. Cubuk, B.~Zoph, D.~Mane, V.~Vasudevan, and Q.~V. Le.
\newblock Autoaugment: Learning augmentation strategies from data.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, June 2019.

\bibitem[Cubuk et~al.(2020)Cubuk, Zoph, Shlens, and Le]{cubuk2020randaugment}
E.~D. Cubuk, B.~Zoph, J.~Shlens, and Q.~V. Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR) Workshops}, 2020.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{imagenet_cvpr09}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock {ImageNet: A Large-Scale Hierarchical Image Database}.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2009.

\bibitem[DeVries and Taylor(2017)]{cutout}
T.~DeVries and G.~W. Taylor.
\newblock Improved regularization of convolutional neural networks with cutout.
\newblock \emph{arXiv preprint arXiv:1708.04552}, 2017.

\bibitem[Dong et~al.(2022)Dong, Xu, Yang, Pang, Deng, Su, and
  Zhu]{dong2022exploring}
Y.~Dong, K.~Xu, X.~Yang, T.~Pang, Z.~Deng, H.~Su, and J.~Zhu.
\newblock Exploring memorization in adversarial training.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2022.

\bibitem[Fan et~al.(2021)Fan, Liu, Chen, Zhang, and Gan]{advcl}
L.~Fan, S.~Liu, P.-Y. Chen, G.~Zhang, and C.~Gan.
\newblock When does contrastive learning preserve adversarial robustness from
  pretraining to finetuning?
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  34, 2021.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville, and Y.~Bengio.
\newblock Generative adversarial nets.
\newblock \emph{Advances in neural information processing systems (NeurIPS)},
  27, 2014.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2015.

\bibitem[Gowal et~al.(2020)Gowal, Qin, Uesato, Mann, and
  Kohli]{gowal2020uncovering}
S.~Gowal, C.~Qin, J.~Uesato, T.~Mann, and P.~Kohli.
\newblock Uncovering the limits of adversarial training against norm-bounded
  adversarial examples.
\newblock \emph{arXiv preprint arXiv:2010.03593}, 2020.

\bibitem[Gowal et~al.(2021)Gowal, Rebuffi, Wiles, Stimberg, Calian, and
  Mann]{gowal2021improving}
S.~Gowal, S.-A. Rebuffi, O.~Wiles, F.~Stimberg, D.~A. Calian, and T.~A. Mann.
\newblock Improving robustness using generated data.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  34, 2021.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{RN18}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition, 2015.

\bibitem[Hendrycks and Dietterich(2019)]{hendrycks2019benchmarking}
D.~Hendrycks and T.~Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Hendrycks* et~al.(2020)Hendrycks*, Mu*, Cubuk, Zoph, Gilmer, and
  Lakshminarayanan]{hendrycks2020augmix}
D.~Hendrycks*, N.~Mu*, E.~D. Cubuk, B.~Zoph, J.~Gilmer, and
  B.~Lakshminarayanan.
\newblock Augmix: A simple method to improve robustness and uncertainty under
  data shift.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
J.~Ho, A.~Jain, and P.~Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  33, 2020.

\bibitem[Howard and Gugger(2020)]{howard2020fastai}
J.~Howard and S.~Gugger.
\newblock Fastai: a layered api for deep learning.
\newblock \emph{Information}, 11\penalty0 (2):\penalty0 108, 2020.

\bibitem[Ioffe and Szegedy(2015)]{pmlr-v37-ioffe15}
S.~Ioffe and C.~Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning (ICML)}, Proceedings of Machine Learning Research. PMLR, 2015.

\bibitem[Izmailov et~al.(2018)Izmailov, Podoprikhin, Garipov, Vetrov, and
  Wilson]{izmailov2018averaging}
P.~Izmailov, D.~Podoprikhin, T.~Garipov, D.~Vetrov, and A.~G. Wilson.
\newblock Averaging weights leads to wider optima and better generalization.
\newblock \emph{arXiv preprint arXiv:1803.05407}, 2018.

\bibitem[Jiang et~al.(2020)Jiang, Chen, Chen, and Wang]{acl}
Z.~Jiang, T.~Chen, T.~Chen, and Z.~Wang.
\newblock Robust pre-training by adversarial contrastive learning.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2020.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Advances in neural information processing systems (NeurIPS)},
  2012.

\bibitem[Krizhevsky et~al.(2009)]{krizhevsky2009learning}
A.~Krizhevsky et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Li et~al.(2022)Li, Wu, Chen, Fang, and Huang]{li2021subspace}
T.~Li, Y.~Wu, S.~Chen, K.~Fang, and X.~Huang.
\newblock Subspace adversarial training.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, 2022.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Dimitris, and
  Vladu]{madry-iclr-2018}
A.~Madry, A.~Makelov, L.~Schmidt, T.~Dimitris, and A.~Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Merchant et~al.(2020)Merchant, Zoph, and Cubuk]{Merchant2020DoesDA}
A.~Merchant, B.~Zoph, and E.~D. Cubuk.
\newblock Does data augmentation benefit from split batchnorms.
\newblock \emph{ArXiv}, abs/2010.07810, 2020.

\bibitem[Pang et~al.(2021)Pang, Yang, Dong, Su, and Zhu]{pang2020bag}
T.~Pang, X.~Yang, Y.~Dong, H.~Su, and J.~Zhu.
\newblock Bag of tricks for adversarial training.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2021.

\bibitem[Papernot et~al.(2017)Papernot, McDaniel, Goodfellow, Jha, Celik, and
  Swami]{papernot2017practical}
N.~Papernot, P.~McDaniel, I.~Goodfellow, S.~Jha, Z.~B. Celik, and A.~Swami.
\newblock Practical black-box attacks against machine learning.
\newblock In \emph{Proceedings of the ACM Asia Conference on Computer and
  Communications Security (ACM ASIACCS)}, 2017.

\bibitem[Rade(2021)]{rade2021pytorch}
R.~Rade.
\newblock {PyTorch} implementation of uncovering the limits of adversarial
  training against norm-bounded adversarial examples, 2021.
\newblock URL \url{https://github.com/imrahulr/adversarial_robustness_pytorch}.

\bibitem[Rade and Moosavi-Dezfooli(2022)]{rade2022reducing}
R.~Rade and S.-M. Moosavi-Dezfooli.
\newblock Reducing excessive margin to achieve a better accuracy vs. robustness
  trade-off.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2022.

\bibitem[Rebuffi et~al.(2021)Rebuffi, Gowal, Calian, Stimberg, Wiles, and
  Mann]{rebuffi2021data}
S.-A. Rebuffi, S.~Gowal, D.~A. Calian, F.~Stimberg, O.~Wiles, and T.~A. Mann.
\newblock Data augmentation can improve robustness.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  34, 2021.

\bibitem[Rice et~al.(2020)Rice, Wong, and Kolter]{rice2020overfitting}
L.~Rice, E.~Wong, and J.~Z. Kolter.
\newblock Overfitting in adversarially robust deep learning.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  Madry]{schmidt2018adversarially}
L.~Schmidt, S.~Santurkar, D.~Tsipras, K.~Talwar, and A.~Madry.
\newblock Adversarially robust generalization requires more data.
\newblock \emph{Advances in neural information processing systems (NeurIPS)},
  31, 2018.

\bibitem[Shaeiri et~al.(2020)Shaeiri, Nobahari, and Rohban]{shaeiri2020towards}
A.~Shaeiri, R.~Nobahari, and M.~H. Rohban.
\newblock Towards deep learning models resistant to large perturbations.
\newblock \emph{arXiv preprint arXiv:2003.13370}, 2020.

\bibitem[Sitawarin et~al.(2020)Sitawarin, Chakraborty, and
  Wagner]{Sitawarin2020ImprovingAR}
C.~Sitawarin, S.~Chakraborty, and D.~A. Wagner.
\newblock Improving adversarial robustness through progressive hardening.
\newblock \emph{ArXiv}, abs/2003.09347, 2020.

\bibitem[Sriramanan et~al.(2020)Sriramanan, Addepalli, Baburaj, and
  Venkatesh~Babu]{sriramanan2020gama}
G.~Sriramanan, S.~Addepalli, A.~Baburaj, and R.~Venkatesh~Babu.
\newblock {Guided Adversarial Attack for Evaluating and Enhancing Adversarial
  Defenses}.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2020.

\bibitem[Sriramanan et~al.(2021)Sriramanan, Addepalli, Baburaj, and
  Venkatesh~Babu]{sriramanan2021nuat}
G.~Sriramanan, S.~Addepalli, A.~Baburaj, and R.~Venkatesh~Babu.
\newblock {Towards Efficient and Effective Adversarial Training}.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2021.

\bibitem[Stutz et~al.(2021)Stutz, Hein, and Schiele]{stutz2021relating}
D.~Stutz, M.~Hein, and B.~Schiele.
\newblock Relating adversarially robust generalization to flat minima.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, 2021.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{intriguing-iclr-2014}
C.~Szegedy, W.~Zaremba, I.~Sutskever, J.~Bruna, D.~Erhan, I.~J. Goodfellow, and
  R.~Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2013.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{Szegedy2016RethinkingTI}
C.~Szegedy, V.~Vanhoucke, S.~Ioffe, J.~Shlens, and Z.~Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock \emph{2016 IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pages 2818--2826, 2016.

\bibitem[Wang and Wang(2022)]{wang2022selfensemble}
H.~Wang and Y.~Wang.
\newblock Self-ensemble adversarial training for improved robustness.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2022.

\bibitem[Wang et~al.(2020)Wang, Chen, Gui, Hu, Liu, and
  Wang]{wang2020onceforall}
H.~Wang, T.~Chen, S.~Gui, T.-K. Hu, J.~Liu, and Z.~Wang.
\newblock Once-for-all adversarial training: In-situ tradeoff between
  robustness and accuracy for free.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2020.

\bibitem[Wang et~al.(2021)Wang, Xiao, Kossaifi, Yu, Anandkumar, and
  Wang]{wangAugmax}
H.~Wang, C.~Xiao, J.~Kossaifi, Z.~Yu, A.~Anandkumar, and Z.~Wang.
\newblock Augmax: Adversarial composition of random augmentations for robust
  training.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2021.

\bibitem[Wu et~al.(2020)Wu, Xia, and Wang]{wu2020adversarial}
D.~Wu, S.-T. Xia, and Y.~Wang.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2020.

\bibitem[Xie and Yuille(2020)]{Xieintriguing}
C.~Xie and A.~Yuille.
\newblock Intriguing properties of adversarial training at scale.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Xie et~al.(2020{\natexlab{a}})Xie, Tan, Gong, Wang, Yuille, and
  Le]{Xie_2020_CVPR}
C.~Xie, M.~Tan, B.~Gong, J.~Wang, A.~L. Yuille, and Q.~V. Le.
\newblock Adversarial examples improve image recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, June 2020{\natexlab{a}}.

\bibitem[Xie et~al.(2020{\natexlab{b}})Xie, Tan, Gong, Yuille, and
  Le]{xie2020smooth}
C.~Xie, M.~Tan, B.~Gong, A.~Yuille, and Q.~V. Le.
\newblock Smooth adversarial training.
\newblock \emph{arXiv preprint arXiv:2006.14536}, 2020{\natexlab{b}}.

\bibitem[Yun et~al.(2019)Yun, Han, Oh, Chun, Choe, and Yoo]{yun2019cutmix}
S.~Yun, D.~Han, S.~J. Oh, S.~Chun, J.~Choe, and Y.~Yoo.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, 2019.

\bibitem[Zagoruyko and Komodakis(2016)]{zagoruyko2016wide}
S.~Zagoruyko and N.~Komodakis.
\newblock Wide residual networks.
\newblock \emph{arXiv preprint arXiv:1605.07146}, 2016.

\bibitem[Zhang et~al.(2018)Zhang, Cisse, Dauphin, and
  Lopez-Paz]{zhang2017mixup}
H.~Zhang, M.~Cisse, Y.~N. Dauphin, and D.~Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, El~Ghaoui, and
  Jordan]{zhang2019theoretically}
H.~Zhang, Y.~Yu, J.~Jiao, E.~Xing, L.~El~Ghaoui, and M.~I. Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2019.

\end{thebibliography}
