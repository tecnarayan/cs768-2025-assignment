@article{held63movement,
  title={Movement-produced stimulation in the development of visually guided behavior},
  author={Held, Richard and Hein, Alan},
  journal={Journal of Comparative and Physiological Psychology},
  volume={56},
  number={5},
  pages={872--876},
  year={1963},
}

@article{dqn,
	Author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	Journal = {Nature},
	Number = {7540},
	Pages = {529--533},
	Title = {Human-level control through deep reinforcement learning},
	Volume = {518},
	Year = {2015}
}

@inproceedings{vanhasselt16deep,
    title={{Deep reinforcement learning with double Q-learning}},
    author={van Hasselt, Hado and Guez, Arthur and Silver, David},
    booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
    year={2016},
}

@article{van2018deep,
  title={Deep reinforcement learning and the deadly triad},
  author={van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@book{sutton2018reinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, Richard S. and Barto, Andrew G.},
  year={2018},
  publisher={MIT press}
}

@inproceedings{kapturowski2018recurrent,
  title={Recurrent experience replay in distributed reinforcement learning},
  author={Kapturowski, Steven and Ostrovski, Georg and Quan, John and Munos, Remi and Dabney, Will},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{fedus20a,
  title = 	 {Revisiting Fundamentals of Experience Replay},
  author =       {Fedus, William and Ramachandran, Prajit and Agarwal, Rishabh and Bengio, Yoshua and Larochelle, Hugo and Rowland, Mark and Dabney, Will},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {3061--3071},
  year = 	 {2020},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
}

@InProceedings{fujimoto19offPolicy,
  title = {Off-Policy Deep Reinforcement Learning without Exploration},
  author = {Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages = {2052--2062},
  year = {2019},
  volume = {97},
  publisher = {PMLR},
}

@article{achiam19towards,
  author    = {Joshua Achiam and
               Ethan Knight and
               Pieter Abbeel},
  title     = {Towards Characterizing Divergence in Deep {Q}-Learning},
  journal={arXiv preprint arXiv:1903.08894},
  year={2019}
}

@InProceedings{jacq19learning,
  title = {Learning from a Learner},
  author = {Jacq, Alexis and Geist, Matthieu and Paiva, Ana and Pietquin, Olivier},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages = {2990--2999},
  year = {2019},
  volume = {97},
}

@article{schulman17ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017},
  archivePrefix = {arXiv},
  eprint    = {1707.06347},
}

@incollection{baird95residual,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  booktitle={Machine Learning Proceedings 1995},
  pages={30--37},
  year={1995},
  publisher={Elsevier}
}

@inproceedings{tsitsiklis96analysis,
  author = {Tsitsiklis, John N. and Van Roy, Benjamin},
  title = {Analysis of Temporal-Difference Learning with Function Approximation},
  year = {1996},
  publisher = {MIT Press},
  address = {Cambridge, MA, USA},
  booktitle = {Proceedings of the 9th International Conference on Neural Information Processing Systems},
  pages = {1075â€“1081},
}

@inproceedings{kumar20discor,
 author = {Kumar, Aviral and Gupta, Abhishek and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {18560--18572},
 title = {{DisCor}: Corrective Feedback in Reinforcement Learning via Distribution Correction},
 volume = {33},
 year = {2020}
}


@inproceedings{kidambi20,
	author = {Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
	booktitle = {Advances in Neural Information Processing Systems},
	pages = {21810--21823},
	title = {{MOReL}: Model-Based Offline Reinforcement Learning},
	volume = {33},
	year = {2020},
}


@inproceedings{agarwal20optimistic,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={Proceedings of the 37th International Conference on Machine Learning},
  volume    = {119},
  pages     = {104--114},
  publisher = {{PMLR}},
  year={2020}
}


@inproceedings{buckman21pessimism,
title={The Importance of Pessimism in Fixed-Dataset Policy Optimization},
author={Jacob Buckman and Carles Gelada and Marc G. Bellemare},
booktitle={International Conference on Learning Representations},
year={2021},
}

@techreport{lin1993reinforcement,
  title={Reinforcement learning for robots using neural networks},
  author={Lin, Long-Ji},
  year={1993},
  institution={Carnegie-Mellon Univ Pittsburgh PA School of Computer Science}
}

@article{bellemare13arcade,
  title={{The Arcade Learning Environment: an evaluation platform for general agents}},
  author={Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S.},
  journal={Machine learning},
  volume={3},
  number={1},
  pages={9--44},
  year={1988},
  publisher={Springer}
}

@techreport{rummery1994line,
  title={On-line {Q-learning} using connectionist systems},
  author={Rummery, Gavin A. and Niranjan, Mahesan},
  year={1994},
  institution={University of Cambridge, Department of Engineering Cambridge, UK}
}

@article{machado2018revisiting,
  title={Revisiting the {Arcade Learning Environment}: Evaluation protocols and open problems for general agents},
  author={Machado, Marlos C and Bellemare, Marc G. and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={61},
  pages={523--562},
  year={2018}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{obando2020revisiting,
  title={Revisiting {Rainbow}: Promoting more insightful and inclusive deep reinforcement learning research},
  author={Obando-Ceron, Johan S. and Castro, Pablo Samuel},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  year = {2021},
  publisher = {PMLR},
}

@article{tieleman2012lecture,
  title={Lecture 6.5: {RMSProp}},
  author={Tieleman, Tijmen and Hinton, Geoffrey},
  journal={COURSERA: Neural Networks for Machine Learning},
  year={2012}
}

@article{kingma2014adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Kingma, Diederik and Ba, Jimmy},
  journal={Proceedings of the International Conference on Learning Representations},
  year={2015}
}

@inproceedings{distillation,
title	= {Distilling the Knowledge in a Neural Network},
author	= {Geoffrey Hinton and Oriol Vinyals and Jeffrey Dean},
year	= {2015},
booktitle	= {NIPS Deep Learning and Representation Learning Workshop}
}

@inproceedings{igl2021transient,
title={Transient Non-stationarity and Generalisation in Deep Reinforcement Learning},
author={Maximilian Igl and Gregory Farquhar and Jelena Luketina and Wendelin Boehmer and Shimon Whiteson},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=Qun8fv4qSby}
}

@article{brockman2016openai,
  title={{OpenAI Gym}},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{hasselt2010,
 author = {van Hasselt, Hado},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 title = {{Double Q-learning}},
 volume = {23},
 year = {2010}
}

@inproceedings{bengio2020interference,
  title={Interference and generalization in temporal difference learning},
  author={Bengio, Emmanuel and Pineau, Joelle and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={767--777},
  year={2020},
}

@inproceedings{hamrick2021on,
title={On the role of planning in model-based deep reinforcement learning},
author={Jessica B Hamrick and Abram L. Friesen and Feryal Behbahani and Arthur Guez and Fabio Viola and Sims Witherspoon and Thomas Anthony and Lars Holger Buesing and Petar Veli{\v{c}}kovi{\'c} and Theophane Weber},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=IrM64DGB21}
}

@article{schrittwieser2021online,
  title={Online and Offline Reinforcement Learning by Planning with a Learned Model},
  author={Schrittwieser, Julian and Hubert, Thomas and Mandhane, Amol and Barekatain, Mohammadamin and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:2104.06294},
  year={2021}
}

@article{liu2020provably,
  title={Provably good batch reinforcement learning without great exploration},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={arXiv preprint arXiv:2007.08202},
  year={2020}
}

@misc{dqnzoo2020github,
  title = {{DQN} {Zoo}: Reference implementations of {DQN}-based agents},
  author = {John Quan and Georg Ostrovski},
  url = {http://github.com/deepmind/dqn_zoo},
  version = {1.0.0},
  year = {2020},
}

@misc{rlax2020github,
  author = {David Budden and Matteo Hessel and John Quan and Steven Kapturowski
            and Kate Baumli and Surya Bhupatiraju and Aurelia Guy and Michael
            King},
  title = {{RL}ax: {R}einforcement {L}earning in {JAX}},
  url = {http://github.com/deepmind/rlax},
  version = {0.0.2},
  year = {2020},
}

@misc{haiku2020github,
  author = {Tom Hennigan and Trevor Cai and Tamara Norman and Igor Babuschkin},
  title = {{H}aiku: {S}onnet for {JAX}},
  url = {http://github.com/deepmind/dm-haiku},
  version = {0.0.3},
  year = {2020},
}

@misc{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.2.5},
  year = {2018},
}

@misc{optax2020github,
  author = {Matteo Hessel and David Budden and Fabio Viola and Mihaela Rosca
            and Eren Sezener and Tom Hennigan},
  title = {Optax: Composable gradient transformation and optimisation, in {JAX!}},
  url = {http://github.com/deepmind/optax},
  version = {0.0.1},
  year = {2020},
}

@article{fakoor2021continuous,
  title={Continuous Doubly Constrained Batch Reinforcement Learning},
  author={Fakoor, Rasool and Mueller, Jonas and Chaudhari, Pratik and Smola, Alexander J.},
  journal={arXiv preprint arXiv:2102.09225},
  year={2021}
}

@article{huh21low,
  author    = {Minyoung Huh and
               Hossein Mobahi and
               Richard Zhang and
               Brian Cheung and
               Pulkit Agrawal and
               Phillip Isola},
  title     = {The Low-Rank Simplicity Bias in Deep Networks},
  journal={arXiv preprint arXiv:2103.10427},
  year      = {2021},
}

@article{levine20offline,
  author    = {Sergey Levine and
               Aviral Kumar and
               George Tucker and
               Justin Fu},
  title     = {Offline Reinforcement Learning: Tutorial, Review, and Perspectives
               on Open Problems},
  journal={arXiv preprint arXiv:2005.01643},
  year      = {2020},
}

@article{fujimoto19benchmarking,
  author    = {Scott Fujimoto and
               Edoardo Conti and
               Mohammad Ghavamzadeh and
               Joelle Pineau},
  title     = {Benchmarking Batch Deep Reinforcement Learning Algorithms},
  journal={arXiv preprint arXiv:1910.01708},
  year      = {2019},
}

@inproceedings{
endrawis21efficient,
title={Efficient Self-Supervised Data Collection for Offline Robot Learning},
author={Shadi Endrawis and Gal Leibovich and Guy Jacob and Gal Novik and Aviv Tamar},
booktitle={IEEE International Conference on Robotics and Automation (ICRA)},
year={2021},
}

@inproceedings{wu21uncertainty,
  title={Uncertainty Weighted Actor-Critic for Offline Reinforcement Learning},
  author={Yue Wu and Shuangfei Zhou and Nitish Srivastava and Joshua Susskind and Jian Zhang and Ruslan Salakhutdinov and Hanlin Goh},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  year = {2021},
  publisher = {PMLR},
}

@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and {\.Z}o{\l}na, Konrad and Springenberg, Jost Tobias and Reed, Scott and Shahriari, Bobak and Siegel, Noah and Merel, Josh and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={arXiv preprint arXiv:2006.15134},
  year={2020}
}

@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G. and Munos, R{\'e}mi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2018}
}

@inproceedings{kumar2019,
 author = {Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 title = {Stabilizing Off-Policy {Q-learning} via Bootstrapping Error Reduction},
 volume = {32},
 year = {2019}
}

@inproceedings{kumar2020,
 author = {Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {1179--1191},
 title = {Conservative {Q-learning} for Offline Reinforcement Learning},
 volume = {33},
 year = {2020}
}

@inproceedings{thomas2015high,
  title={High confidence policy improvement},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={2380--2388},
  year={2015},
  organization={PMLR}
}

@Article{young19minatar,
  author = {{Young}, Kenny and {Tian}, Tian},
  title = {{MinAtar}: An {Atari}-Inspired Testbed for Thorough and Reproducible Reinforcement Learning Experiments},
  journal = {arXiv preprint arXiv:1903.03176},
  year = "2019"
}

@article{castro18dopamine,
  author    = {Pablo Samuel Castro and
               Subhodeep Moitra and
               Carles Gelada and
               Saurabh Kumar and
               Marc G. Bellemare},
  title     = {Dopamine: {A} research framework for deep reinforcement learning},
  journal={arXiv preprint arXiv:1812.06110},
  year={2018},
}

@article{xiao2021sample,
  title={On the Sample Complexity of Batch Reinforcement Learning with Policy-Induced Data},
  author={Xiao, Chenjun and Lee, Ilbin and Dai, Bo and Schuurmans, Dale and Szepesvari, Csaba},
  journal={arXiv preprint arXiv:2106.09973},
  year={2021}
}

@article{wang2020statistical,
  title={What are the Statistical Limits of Offline {RL} with Linear Function Approximation?},
  author={Wang, Ruosong and Foster, Dean P. and Kakade, Sham M.},
  journal={arXiv preprint arXiv:2010.11895},
  year={2020}
}

@article{wang2021instabilities,
  title={Instabilities of offline {RL} with pre-trained neural representation},
  author={Wang, Ruosong and Wu, Yifan and Salakhutdinov, Ruslan and Kakade, Sham M.},
  journal={arXiv preprint arXiv:2103.04947},
  year={2021}
}

@article{matsushima2020deployment,
  title={Deployment-efficient reinforcement learning via model-based offline optimization},
  author={Matsushima, Tatsuya and Furuta, Hiroki and Matsuo, Yutaka and Nachum, Ofir and Gu, Shixiang},
  journal={arXiv preprint arXiv:2006.03647},
  year={2020}
}

@article{nair2020accelerating,
  title={Accelerating online reinforcement learning with offline datasets},
  author={Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{yu2020mopo,
  title={{MOPO}: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}

@article{kumar2020implicit,
  title={Implicit under-parameterization inhibits data-efficient deep reinforcement learning},
  author={Kumar, Aviral and Agarwal, Rishabh and Ghosh, Dibya and Levine, Sergey},
  journal={arXiv preprint arXiv:2010.14498},
  year={2020}
}


