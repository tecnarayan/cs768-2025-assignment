\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aghajanyan et~al.(2021)Aghajanyan, Gupta, and Zettlemoyer]{aghajanyan2021intrinsic}
Aghajanyan, A., Gupta, S., and Zettlemoyer, L.
\newblock Intrinsic dimensionality explains the effectiveness of language model fine-tuning.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)}, pp.\  7319--7328, 2021.

\bibitem[{Angeli} \& {Marinova}(2013){Angeli} and {Marinova}]{2013ADNDT..99...69A}
{Angeli}, I. and {Marinova}, K.~P.
\newblock {Table of experimental nuclear ground state charge radii: An update}.
\newblock \emph{Atomic Data and Nuclear Data Tables}, 99\penalty0 (1):\penalty0 69--95, January 2013.
\newblock \doi{10.1016/j.adt.2011.12.006}.

\bibitem[Antognini \& Sohl-Dickstein(2018)Antognini and Sohl-Dickstein]{antognini2018pca}
Antognini, J. and Sohl-Dickstein, J.
\newblock Pca of high dimensional random walks with comparison to neural network training.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Ashkboos et~al.(2024)Ashkboos, Croci, do~Nascimento, Hoefler, and Hensman]{ashkboos2024slicegpt}
Ashkboos, S., Croci, M.~L., do~Nascimento, M.~G., Hoefler, T., and Hensman, J.
\newblock Slicegpt: Compress large language models by deleting rows and columns, 2024.

\bibitem[{Benchekroun} et~al.(2023){Benchekroun}, {Dervishi}, {Ibrahim}, {Gaya}, {Martinet}, {Mialon}, {Scialom}, {Dupoux}, {Hupkes}, and {Vincent}]{2023arXiv231115930B}
{Benchekroun}, Y., {Dervishi}, M., {Ibrahim}, M., {Gaya}, J.-B., {Martinet}, X., {Mialon}, G., {Scialom}, T., {Dupoux}, E., {Hupkes}, D., and {Vincent}, P.
\newblock {WorldSense: A Synthetic Benchmark for Grounded Reasoning in Large Language Models}.
\newblock \emph{arXiv e-prints}, art. arXiv:2311.15930, November 2023.
\newblock \doi{10.48550/arXiv.2311.15930}.

\bibitem[Bengio et~al.(2013)Bengio, Courville, and Vincent]{bengio2013representation}
Bengio, Y., Courville, A., and Vincent, P.
\newblock Representation learning: A review and new perspectives.
\newblock \emph{IEEE transactions on pattern analysis and machine intelligence}, 35\penalty0 (8):\penalty0 1798--1828, 2013.

\bibitem[Bethe \& Bacher(1936)Bethe and Bacher]{Bethe:1936zz}
Bethe, H.~A. and Bacher, R.~F.
\newblock {Nuclear Physics A. Stationary States of Nuclei}.
\newblock \emph{Rev. Mod. Phys.}, 8:\penalty0 82--229, 1936.
\newblock \doi{10.1103/RevModPhys.8.82}.

\bibitem[{Bowman}(2023)]{2023arXiv230400612B}
{Bowman}, S.~R.
\newblock {Eight Things to Know about Large Language Models}.
\newblock \emph{arXiv e-prints}, art. arXiv:2304.00612, April 2023.
\newblock \doi{10.48550/arXiv.2304.00612}.

\bibitem[Burgess et~al.(2018)Burgess, Higgins, Pal, Matthey, Watters, Desjardins, and Lerchner]{burgess2018understanding}
Burgess, C.~P., Higgins, I., Pal, A., Matthey, L., Watters, N., Desjardins, G., and Lerchner, A.
\newblock Understanding disentangling in $\beta$-vae.
\newblock In \emph{NeurIPS Workshop on Learning Disentangled Representations}, 2018.

\bibitem[Chen et~al.(2018)Chen, Li, Grosse, and Duvenaud]{chen2018isolating}
Chen, R.~T., Li, X., Grosse, R.~B., and Duvenaud, D.~K.
\newblock Isolating sources of disentanglement in variational autoencoders.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\  2610--2620, 2018.

\bibitem[Cranmer(2023)]{cranmer2023interpretable}
Cranmer, M.
\newblock Interpretable machine learning for science with pysr and symbolicregression. jl.
\newblock \emph{arXiv preprint arXiv:2305.01582}, 2023.

\bibitem[Davis \& Jin(2023)Davis and Jin]{davis2023discovery}
Davis, B.~L. and Jin, Z.
\newblock Discovery of a planar black hole mass scaling relation for spiral galaxies.
\newblock \emph{The Astrophysical Journal Letters}, 956\penalty0 (1):\penalty0 L22, 2023.

\bibitem[{Dettmers} et~al.(2023){Dettmers}, {Pagnoni}, {Holtzman}, and {Zettlemoyer}]{2023arXiv230514314D}
{Dettmers}, T., {Pagnoni}, A., {Holtzman}, A., and {Zettlemoyer}, L.
\newblock {QLoRA: Efficient Finetuning of Quantized LLMs}.
\newblock \emph{arXiv e-prints}, art. arXiv:2305.14314, May 2023.
\newblock \doi{10.48550/arXiv.2305.14314}.

\bibitem[Elhage et~al.(2021)Elhage, Nanda, Olsson, Henighan, Joseph, Mann, Askell, Bai, Chen, Conerly, DasSarma, Drain, Ganguli, Hatfield-Dodds, Hernandez, Jones, Kernion, Lovitt, Ndousse, Amodei, Brown, Clark, Kaplan, McCandlish, and Olah]{elhage2021mathematical}
Elhage, N., Nanda, N., Olsson, C., Henighan, T., Joseph, N., Mann, B., Askell, A., Bai, Y., Chen, A., Conerly, T., DasSarma, N., Drain, D., Ganguli, D., Hatfield-Dodds, Z., Hernandez, D., Jones, A., Kernion, J., Lovitt, L., Ndousse, K., Amodei, D., Brown, T., Clark, J., Kaplan, J., McCandlish, S., and Olah, C.
\newblock A mathematical framework for transformer circuits.
\newblock \emph{Transformer Circuits Thread}, 2021.
\newblock https://transformer-circuits.pub/2021/framework/index.html.

\bibitem[{Gurnee} \& {Tegmark}(2023){Gurnee} and {Tegmark}]{2023arXiv231002207G}
{Gurnee}, W. and {Tegmark}, M.
\newblock {Language Models Represent Space and Time}.
\newblock \emph{arXiv e-prints}, art. arXiv:2310.02207, October 2023.
\newblock \doi{10.48550/arXiv.2310.02207}.

\bibitem[Hassid et~al.(2022)Hassid, Peng, Rotem, Kasai, Montero, Smith, and Schwartz]{hassid2022much}
Hassid, M., Peng, H., Rotem, D., Kasai, J., Montero, I., Smith, N.~A., and Schwartz, R.
\newblock How much does attention actually attend? questioning the importance of attention in pretrained transformers.
\newblock \emph{arXiv preprint arXiv:2211.03495}, 2022.

\bibitem[Higgins et~al.(2018)Higgins, Amos, Pfau, Racaniere, Matthey, Rezende, and Lerchner]{higgins2018towards}
Higgins, I., Amos, D., Pfau, D., Racaniere, S., Matthey, L., Rezende, D., and Lerchner, A.
\newblock Towards a definition of disentangled representations.
\newblock \emph{arXiv preprint arXiv:1812.02230}, 2018.

\bibitem[Hu et~al.(2021)Hu, Shen, Wallis, Allen-Zhu, Li, Wang, Wang, and Chen]{hu2021lora}
Hu, E.~J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., and Chen, W.
\newblock Lora: Low-rank adaptation of large language models.
\newblock \emph{arXiv preprint arXiv:2106.09685}, 2021.

\bibitem[Kadir \& Brady(2001)Kadir and Brady]{kadir2001saliency}
Kadir, T. and Brady, M.
\newblock Saliency, scale and image description.
\newblock \emph{International Journal of Computer Vision}, 45\penalty0 (2):\penalty0 83--105, 2001.

\bibitem[Kim \& Mnih(2018)Kim and Mnih]{kim2018disentangling}
Kim, H. and Mnih, A.
\newblock Disentangling by factorising.
\newblock In \emph{International Conference on Machine Learning}, pp.\  2649--2658. PMLR, 2018.

\bibitem[Kirson(2008)]{Kirson:2008yvv}
Kirson, M.~W.
\newblock {Mutual influence of terms in a semi-empirical mass formula}.
\newblock \emph{Nucl. Phys. A}, 798:\penalty0 29--60, 2008.
\newblock \doi{10.1016/j.nuclphysa.2007.10.011}.

\bibitem[Lebedev et~al.(2019)Lebedev, Ossadtchi, Mill, Urp{\'\i}, Cervera, and Nicolelis]{lebedev2019analysis}
Lebedev, M.~A., Ossadtchi, A., Mill, N.~A., Urp{\'\i}, N.~A., Cervera, M.~R., and Nicolelis, M.~A.
\newblock Analysis of neuronal ensemble activity reveals the pitfalls and shortcomings of rotation dynamics.
\newblock \emph{Scientific Reports}, 9\penalty0 (1):\penalty0 18978, 2019.

\bibitem[Lemos et~al.(2023)Lemos, Jeffrey, Cranmer, Ho, and Battaglia]{lemos2023rediscovering}
Lemos, P., Jeffrey, N., Cranmer, M., Ho, S., and Battaglia, P.
\newblock Rediscovering orbital mechanics with machine learning.
\newblock \emph{Machine Learning: Science and Technology}, 4\penalty0 (4):\penalty0 045002, 2023.

\bibitem[Li et~al.(2018)Li, Farkhoor, Liu, and Yosinski]{li2018measuring}
Li, C., Farkhoor, H., Liu, R., and Yosinski, J.
\newblock Measuring the intrinsic dimension of objective landscapes.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[{Li} et~al.(2022){Li}, {Hopkins}, {Bau}, {Vi{\'e}gas}, {Pfister}, and {Wattenberg}]{2022arXiv221013382L}
{Li}, K., {Hopkins}, A.~K., {Bau}, D., {Vi{\'e}gas}, F., {Pfister}, H., and {Wattenberg}, M.
\newblock {Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task}.
\newblock \emph{arXiv e-prints}, art. arXiv:2210.13382, October 2022.
\newblock \doi{10.48550/arXiv.2210.13382}.

\bibitem[Liu et~al.(2022)Liu, Kitouni, Nolte, Michaud, Tegmark, and Williams]{liu2022towards}
Liu, Z., Kitouni, O., Nolte, N.~S., Michaud, E., Tegmark, M., and Williams, M.
\newblock Towards understanding grokking: An effective theory of representation learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 34651--34663, 2022.

\bibitem[Locatello et~al.(2019)Locatello, Bauer, Lucic, Raetsch, Gelly, Sch{"o}lkopf, and Bachem]{locatello2019challenging}
Locatello, F., Bauer, S., Lucic, M., Raetsch, G., Gelly, S., Sch{"o}lkopf, B., and Bachem, O.
\newblock Challenging common assumptions in the unsupervised learning of disentangled representations.
\newblock In \emph{International Conference on Machine Learning}, pp.\  4114--4124. PMLR, 2019.

\bibitem[Mengel et~al.(2023)Mengel, Steffanic, Hughes, da~Silva, and Nattrass]{mengel2023interpretable}
Mengel, T., Steffanic, P., Hughes, C., da~Silva, A. C.~O., and Nattrass, C.
\newblock Interpretable machine learning methods applied to jet background subtraction in heavy ion collisions.
\newblock \emph{arXiv preprint arXiv:2303.08275}, 2023.

\bibitem[Mikolov et~al.(2013)Mikolov, Chen, Corrado, and Dean]{mikolov2013efficient}
Mikolov, T., Chen, K., Corrado, G., and Dean, J.
\newblock Efficient estimation of word representations in vector space.
\newblock \emph{arXiv preprint arXiv:1301.3781}, 2013.

\bibitem[Nanda et~al.(2023)Nanda, Chan, Lieberum, Smith, and Steinhardt]{nanda2023progress}
Nanda, N., Chan, L., Lieberum, T., Smith, J., and Steinhardt, J.
\newblock Progress measures for grokking via mechanistic interpretability.
\newblock \emph{arXiv preprint arXiv:2301.05217}, 2023.

\bibitem[Novembre \& Stephens(2008)Novembre and Stephens]{novembre2008interpreting}
Novembre, J. and Stephens, M.
\newblock Interpreting principal component analyses of spatial population genetic variation.
\newblock \emph{Nature genetics}, 40\penalty0 (5):\penalty0 646--649, 2008.

\bibitem[Olah(2022)]{olah2022mechinterp}
Olah, C.
\newblock Mechanistic interpretability, variables, and the importance of interpretable bases.
\newblock \emph{Transformer Circuits Thread}, 2022.
\newblock https://transformer-circuits.pub/2022/mech-interp-essay/index.html.

\bibitem[Olah et~al.(2017)Olah, Schubert, and Mordvintsev]{olah2017feature}
Olah, C., Schubert, L., and Mordvintsev, A.
\newblock Feature visualization.
\newblock \emph{Distill}, 2017.
\newblock URL \url{https://distill.pub/2017/feature-visualization/}.

\bibitem[Pauli(1925)]{Pauli1925}
Pauli, W.
\newblock {\"U}ber den zusammenhang des abschlusses der elektronengruppen im atom mit der komplexstruktur der spektren.
\newblock \emph{Zeitschrift f{\"u}r Physik}, 31\penalty0 (1):\penalty0 765--783, Feb 1925.
\newblock ISSN 0044-3328.
\newblock \doi{10.1007/BF02980631}.
\newblock URL \url{https://doi.org/10.1007/BF02980631}.

\bibitem[Proix et~al.(2022)Proix, Perich, and Milekovic]{proix2022interpreting}
Proix, T., Perich, M.~G., and Milekovic, T.
\newblock Interpreting dynamics of neural activity after dimensionality reduction.
\newblock \emph{bioRxiv}, pp.\  2022--03, 2022.

\bibitem[{Roberts} et~al.(2023){Roberts}, {L{\"u}ddecke}, {Das}, {Han}, and {Albanie}]{2023arXiv230600020R}
{Roberts}, J., {L{\"u}ddecke}, T., {Das}, S., {Han}, K., and {Albanie}, S.
\newblock {GPT4GEO: How a Language Model Sees the World's Geography}.
\newblock \emph{arXiv e-prints}, art. arXiv:2306.00020, May 2023.
\newblock \doi{10.48550/arXiv.2306.00020}.

\bibitem[Shinn(2023)]{shinn2023phantom}
Shinn, M.
\newblock Phantom oscillations in principal component analysis.
\newblock \emph{bioRxiv}, pp.\  2023--06, 2023.

\bibitem[Simonyan et~al.(2013)Simonyan, Vedaldi, and Zisserman]{simonyan2013deep}
Simonyan, K., Vedaldi, A., and Zisserman, A.
\newblock Deep inside convolutional networks: Visualising image classification models and saliency maps.
\newblock \emph{arXiv preprint arXiv:1312.6034}, 2013.

\bibitem[Wang et~al.(2021)Wang, Huang, Kondev, Audi, and Naimi]{Wang:2021xhn}
Wang, M., Huang, W.~J., Kondev, F.~G., Audi, G., and Naimi, S.
\newblock {The AME 2020 atomic mass evaluation (II). Tables, graphs and references}.
\newblock \emph{Chin. Phys. C}, 45\penalty0 (3):\penalty0 030003, 2021.
\newblock \doi{10.1088/1674-1137/abddaf}.

\bibitem[Weizs{\"a}cker(1935)]{semf1935}
Weizs{\"a}cker, C. F.~v.
\newblock Zur theorie der kernmassen.
\newblock \emph{Zeitschrift f{\"u}r Physik}, 96\penalty0 (7):\penalty0 431--458, Jul 1935.
\newblock ISSN 0044-3328.
\newblock \doi{10.1007/BF01337700}.
\newblock URL \url{https://doi.org/10.1007/BF01337700}.

\bibitem[Zeiler \& Fergus(2014)Zeiler and Fergus]{zeiler2014visualizing}
Zeiler, M.~D. and Fergus, R.
\newblock Visualizing and understanding convolutional networks.
\newblock In \emph{Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13}, pp.\  818--833. Springer, 2014.

\bibitem[{Zhang} et~al.(2023){Zhang}, {Chen}, {Bukharin}, {Karampatziakis}, {He}, {Cheng}, {Chen}, and {Zhao}]{2023arXiv230310512Z}
{Zhang}, Q., {Chen}, M., {Bukharin}, A., {Karampatziakis}, N., {He}, P., {Cheng}, Y., {Chen}, W., and {Zhao}, T.
\newblock {AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning}.
\newblock \emph{arXiv e-prints}, art. arXiv:2303.10512, March 2023.
\newblock \doi{10.48550/arXiv.2303.10512}.

\bibitem[Zhang et~al.(2021)Zhang, Tiňo, Leonardis, and Tang]{interp-survey}
Zhang, Y., Tiňo, P., Leonardis, A., and Tang, K.
\newblock A survey on neural network interpretability.
\newblock \emph{IEEE Transactions on Emerging Topics in Computational Intelligence}, 5\penalty0 (5):\penalty0 726--742, 2021.
\newblock \doi{10.1109/TETCI.2021.3100641}.

\bibitem[Zhong et~al.(2023)Zhong, Liu, Tegmark, and Andreas]{zhong2023clock}
Zhong, Z., Liu, Z., Tegmark, M., and Andreas, J.
\newblock The clock and the pizza: Two stories in mechanistic explanation of neural networks.
\newblock \emph{arXiv preprint arXiv:2306.17844}, 2023.

\end{thebibliography}
