\begin{thebibliography}{27}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Allen-Zhu et~al.(2019)Allen-Zhu, Li, and Song]{allen2019convergence}
Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song.
\newblock A convergence theory for deep learning via over-parameterization.
\newblock In \emph{International Conference on Machine Learning}, pages
  242--252. PMLR, 2019.

\bibitem[Arora et~al.(2019)Arora, Du, Hu, Li, and Wang]{arora2019fine}
Sanjeev Arora, Simon Du, Wei Hu, Zhiyuan Li, and Ruosong Wang.
\newblock Fine-grained analysis of optimization and generalization for
  overparameterized two-layer neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  322--332. PMLR, 2019.

\bibitem[Bartlett et~al.(2021)Bartlett, Bubeck, and
  Cherapanamjeri]{bartlett2021adversarial}
Peter Bartlett, S{\'e}bastien Bubeck, and Yeshwanth Cherapanamjeri.
\newblock Adversarial examples in multi-layer random {ReLU} networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Biggio et~al.(2013)Biggio, Corona, Maiorca, Nelson,
  {$\check{\textrm{S}}$}rndi{\'c}, Laskov, Giacinto, and
  Roli]{biggio2013evasion}
Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim
  {$\check{\textrm{S}}$}rndi{\'c}, Pavel Laskov, Giorgio Giacinto, and Fabio
  Roli.
\newblock Evasion attacks against machine learning at test time.
\newblock In \emph{Joint European conference on machine learning and knowledge
  discovery in databases}, pages 387--402. Springer, 2013.

\bibitem[Bubeck et~al.(2021)Bubeck, Cherapanamjeri, Gidel, and
  Combes]{bubeck2021single}
S{\'e}bastien Bubeck, Yeshwanth Cherapanamjeri, Gauthier Gidel, and R{\'e}mi
  Tachet~des Combes.
\newblock A single gradient step finds adversarial examples on random
  two-layers neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Cao and Gu(2020)]{cao2020generalization}
Yuan Cao and Quanquan Gu.
\newblock Generalization error bounds of gradient descent for learning
  over-parameterized deep {ReLU} networks.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 3349--3356, 2020.

\bibitem[Carlini and Wagner(2017{\natexlab{a}})]{carlini2017adversarial}
Nicholas Carlini and David Wagner.
\newblock Adversarial examples are not easily detected: Bypassing ten detection
  methods.
\newblock In \emph{Proceedings of the 10th ACM workshop on artificial
  intelligence and security}, pages 3--14, 2017{\natexlab{a}}.

\bibitem[Carlini and Wagner(2017{\natexlab{b}})]{carlini2017towards}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{2017 IEEE symposium on security and privacy ({SP})}, pages
  39--57. IEEE, 2017{\natexlab{b}}.

\bibitem[Carlini et~al.(2019)Carlini, Athalye, Papernot, Brendel, Rauber,
  Tsipras, Goodfellow, Madry, and Kurakin]{carlini2019evaluating}
Nicholas Carlini, Anish Athalye, Nicolas Papernot, Wieland Brendel, Jonas
  Rauber, Dimitris Tsipras, Ian Goodfellow, Aleksander Madry, and Alexey
  Kurakin.
\newblock On evaluating adversarial robustness.
\newblock \emph{arXiv preprint arXiv:1902.06705}, 2019.

\bibitem[Chen et~al.(2021)Chen, Cao, Zou, and Gu]{chen2019much}
Zixiang Chen, Yuan Cao, Difan Zou, and Quanquan Gu.
\newblock How much over-parameterization is sufficient to learn deep relu
  networks?
\newblock In \emph{9th International Conference on Learning Representations},
  2021.

\bibitem[Chizat et~al.(2019)Chizat, Oyallon, and Bach]{chizat2018lazy}
Lenaic Chizat, Edouard Oyallon, and Francis Bach.
\newblock On lazy training in differentiable programming.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Daniely and Shacham(2020)]{daniely2020most}
Amit Daniely and Hadas Shacham.
\newblock Most {ReLU} networks suffer from $\ell^{2}$ adversarial
  perturbations.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 6629--6636, 2020.

\bibitem[Du et~al.(2018)Du, Zhai, Poczos, and Singh]{du2018gradient}
Simon~S Du, Xiyu Zhai, Barnabas Poczos, and Aarti Singh.
\newblock Gradient descent provably optimizes over-parameterized neural
  networks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Gao et~al.(2019)Gao, Cai, Li, Hsieh, Wang, and
  Lee]{gao2019convergence}
Ruiqi Gao, Tianle Cai, Haochuan Li, Cho-Jui Hsieh, Liwei Wang, and Jason~D Lee.
\newblock Convergence of adversarial training in overparametrized neural
  networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 13029--13040, 2019.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Ian~J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{3rd International Conference on Learning Representations},
  2015.

\bibitem[Jacot et~al.(2018)Jacot, Gabriel, and Hongler]{jacot2018neural}
Arthur Jacot, Franck Gabriel, and Cl{\'e}ment Hongler.
\newblock Neural tangent kernel: Convergence and generalization in neural
  networks.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Ji and Telgarsky(2020)]{ji2019polylogarithmic}
Ziwei Ji and Matus Telgarsky.
\newblock Polylogarithmic width suffices for gradient descent to achieve
  arbitrarily small test error with shallow {ReLU} networks.
\newblock In \emph{8th International Conference on Learning Representations},
  2020.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Papernot et~al.(2016)Papernot, McDaniel, Jha, Fredrikson, Celik, and
  Swami]{papernot2016limitations}
Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z~Berkay
  Celik, and Ananthram Swami.
\newblock The limitations of deep learning in adversarial settings.
\newblock In \emph{2016 IEEE European symposium on security and privacy
  (EuroS\&P)}, pages 372--387. IEEE, 2016.

\bibitem[Sch{\"{o}}nherr et~al.(2019)Sch{\"{o}}nherr, Kohls, Zeiler, Holz, and
  Kolossa]{schonherr2018adversarial}
Lea Sch{\"{o}}nherr, Katharina Kohls, Steffen Zeiler, Thorsten Holz, and
  Dorothea Kolossa.
\newblock Adversarial attacks against automatic speech recognition systems via
  psychoacoustic hiding.
\newblock In \emph{26th Annual Network and Distributed System Security
  Symposium}, 2019.

\bibitem[Shamir et~al.(2019)Shamir, Safran, Ronen, and
  Dunkelman]{shamir2019simple}
Adi Shamir, Itay Safran, Eyal Ronen, and Orr Dunkelman.
\newblock A simple explanation for the existence of adversarial examples with
  small hamming distance.
\newblock \emph{arXiv preprint arXiv:1901.10861}, 2019.

\bibitem[Sitawarin et~al.(2018)Sitawarin, Bhagoji, Mosenia, Mittal, and
  Chiang]{sitawarin2018rogue}
Chawin Sitawarin, Arjun~Nitin Bhagoji, Arsalan Mosenia, Prateek Mittal, and
  Mung Chiang.
\newblock Rogue signs: Deceiving traffic sign recognition with malicious ads
  and logos.
\newblock \emph{arXiv preprint arXiv:1801.02780}, 2018.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian~J. Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{2nd International Conference on Learning Representations},
  2014.

\bibitem[Tram{\`{e}}r et~al.(2020)Tram{\`{e}}r, Carlini, Brendel, and
  Madry]{tramer2020adaptive}
Florian Tram{\`{e}}r, Nicholas Carlini, Wieland Brendel, and Aleksander Madry.
\newblock On adaptive attacks to adversarial example defenses.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Vardi et~al.(2022)Vardi, Yehudai, and Shamir]{vardi2022gradient}
Gal Vardi, Gilad Yehudai, and Ohad Shamir.
\newblock Gradient methods provably converge to non-robust networks.
\newblock \emph{arXiv preprint arXiv:2202.04347}, 2022.

\bibitem[Wainwright(2019)]{wainwright2019high}
Martin~J Wainwright.
\newblock \emph{High-dimensional statistics: A non-asymptotic viewpoint},
  volume~48.
\newblock Cambridge University Press, 2019.

\end{thebibliography}
