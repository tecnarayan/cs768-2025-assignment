\begin{thebibliography}{10}

\bibitem{bengio2013}
Y.~Bengio.
\newblock Deep learning of representations: Looking forward.
\newblock Technical Report arXiv:1305.0445, Universit{\'e} de Montr{\'e}al,
  2013.

\bibitem{ciresan2012multi}
D.~Cire\c{s}an, U.~Meier, and J.~Schmidhuber.
\newblock Multi-column deep neural networks for image classification.
\newblock In {\em IEEE Computer Vision and Pattern Recognition}, pages
  3642--3649, 2012.

\bibitem{ciresan2011}
D.~Cire\c{s}an, U.~Meier, and J.~Masci.
\newblock High-performance neural networks for visual object classification.
\newblock {\em arXiv:1102.0183}, 2011.

\bibitem{coates2012emergence}
A.~Coates, A.~Karpathy, and A.~Ng.
\newblock Emergence of object-selective features in unsupervised feature
  learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2690--2698, 2012.

\bibitem{coates11}
A.~Coates and A.~Y. Ng.
\newblock Selecting receptive fields in deep networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2528--2536, 2011.

\bibitem{coates_analysis}
A.~Coates, A.~Y. Ng, and H.~Lee.
\newblock An analysis of single-layer networks in unsupervised feature
  learning.
\newblock In {\em Artificial Intelligence and Statistics}, 2011.

\bibitem{dean2012}
J.~Dean, G.~Corrado, R.~Monga, K.~Chen, M.~Devin, Q.~Le, M.~Mao, M.~Ranzato,
  A.~Senior, P.~Tucker, K.~Yang, and A.~Ng.
\newblock Large scale distributed deep networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1232--1240, 2012.

\bibitem{deng2012scalable}
L.~Deng, D.~Yu, and J.~Platt.
\newblock Scalable stacking and learning for building deep architectures.
\newblock In {\em International Conference on Acoustics, Speech, and Signal
  Processing}, pages 2133--2136, 2012.

\bibitem{goodfellow_maxout}
I.~J. Goodfellow, D.~Warde-Farley, M.~Mirza, A.~Courville, and Y.~Bengio.
\newblock Maxout networks.
\newblock In {\em International Conference on Machine Learning}, 2013.

\bibitem{gregor2010emergence}
K.~Gregor and Y.~LeCun.
\newblock Emergence of complex-like cells in a temporal product network with
  local receptive fields.
\newblock {\em arXiv preprint arXiv:1006.0448}, 2010.

\bibitem{gulcehre2013}
C.~G\"ul\c{c}ehre and Y.~Bengio.
\newblock Knowledge matters: Importance of prior information for optimization.
\newblock In {\em International Conference on Learning Representations}, 2013.

\bibitem{hinton_dropout}
G.~E. Hinton, N.~Srivastava, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov.
\newblock Improving neural networks by preventing co-adaptation of feature
  detectors.
\newblock {\em CoRR}, abs/1207.0580, 2012.

\bibitem{alex_imagenet}
A.~Krizhevsky, I.~Sutskever, and G.~Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1106--1114, 2012.

\bibitem{hinton1990}
K.~Lang and G.~Hinton.
\newblock Dimensionality reduction and prior knowledge in e-set recognition.
\newblock In {\em Advances in Neural Information Processing Systems}, 1990.

\bibitem{Le-RICA}
Q.~V. Le, A.~Karpenko, J.~Ngiam, and A.~Y. Ng.
\newblock {ICA} with reconstruction cost for efficient overcomplete feature
  learning.
\newblock {\em Advances in Neural Information Processing Systems},
  24:1017--1025, 2011.

\bibitem{quoc2012}
Q.~V. Le, M.~Ranzato, R.~Monga, M.~Devin, K.~Chen, G.~Corrado, J.~Dean, and
  A.~Ng.
\newblock Building high-level features using large scale unsupervised learning.
\newblock In {\em International Conference on Machine Learning}, 2012.

\bibitem{lecun_old}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE}, 86(11):2278--2324, 1998.

\bibitem{lecun90}
Y.~LeCun, J.~S. Denker, S.~Solla, R.~E. Howard, and L.~D. Jackel.
\newblock Optimal brain damage.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  598--605, 1990.

\bibitem{lee1989speaker}
K.-F. Lee and H.-W. Hon.
\newblock Speaker-independent phone recognition using hidden markov models.
\newblock {\em Acoustics, Speech and Signal Processing, IEEE Transactions on},
  37(11):1641--1648, 1989.

\bibitem{nair2010rectified}
V.~Nair and G.~E. Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In {\em Proc. 27th International Conference on Machine Learning},
  pages 807--814. Omnipress Madison, WI, 2010.

\bibitem{marc2010factored}
M.~Ranzato, A.~Krizhevsky, and G.~E. Hinton.
\newblock Factored 3-way restricted {Boltzmann} machines for modeling natural
  images.
\newblock In {\em Artificial Intelligence and Statistics}, 2010.

\bibitem{rigamonti2013}
R.~Rigamonti, A.~Sironi, V.~Lepetit, and P.~Fua.
\newblock Learning separable filters.
\newblock In {\em IEEE Computer Vision and Pattern Recognition}, 2013.

\bibitem{rube2010}
R.~Rubinstein, M.~Zibulevsky, and M.~Elad.
\newblock Double sparsity: learning sparse dictionaries for sparse signal
  approximation.
\newblock {\em IEEE Transactions on Signal Processing}, 58:1553--1564, 2010.

\bibitem{rumelhart1986learning}
D.~E. Rumelhart, G.~E. Hinton, and R.~J. Williams.
\newblock Learning representations by back-propagating errors.
\newblock {\em Nature}, 323(6088):533--536, 1986.

\bibitem{Shawe-Taylor:2004}
J.~Shawe-Taylor and N.~Cristianini.
\newblock {\em Kernel Methods for Pattern Analysis}.
\newblock Cambridge University Press, New York, NY, USA, 2004.

\bibitem{ICML2011Swersky}
K.~Swersky, M.~Ranzato, D.~Buchman, B.~Marlin, and N.~Freitas.
\newblock On autoencoders and score matching for energy based models.
\newblock In {\em International Conference on Machine Learning}, pages
  1201--1208, 2011.

\bibitem{vincent2000neural}
P.~Vincent and Y.~Bengio.
\newblock A neural support vector network architecture with adaptive kernels.
\newblock In {\em International Joint Conference on Neural Networks}, pages
  187--192, 2000.

\end{thebibliography}
