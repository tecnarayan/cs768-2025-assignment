% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{schuster1997bidirectional,
  title={Bidirectional recurrent neural networks},
  author={Schuster, Mike and Paliwal, Kuldip K},
  journal={IEEE transactions on Signal Processing},
  volume={45},
  number={11},
  pages={2673--2681},
  year={1997},
  publisher={IEEE}
}

@book{Imbens2015,
  title={Causal inference in statistics, social, and biomedical sciences},
  author={Imbens, Guido W and Rubin, Donald B},
  year={2015},
  publisher={Cambridge University Press}
}

@misc{lillicrap2019does,
      title={What does it mean to understand a neural network?}, 
      author={Timothy P. Lillicrap and Konrad P. Kording},
      year={2019},
      eprint={1907.06374},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{richardson2019probing,
    title={Probing Natural Language Inference Models through Semantic Fragments},
    author={Kyle Richardson and Hai Hu and Lawrence S. Moss and Ashish Sabharwal},
    year={2019},
    eprint={1909.07521},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{Hu2019MonaLogAL,
  title={{MonaLog}: A Lightweight System for Natural Language Inference Based on Monotonicity},
  author={Hai Hu and Qi Chen and Kyle Richardson and Atreyee Mukherjee and Lawrence S. Moss and Sandra K{\"u}bler},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.08772}
}

@inproceedings{Sundararajan:2017,
author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
title = {Axiomatic Attribution for Deep Networks},
year = {2017},
publisher = {JMLR.org},
abstract = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms— Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
pages = {3319–3328},
numpages = {10},
location = {Sydney, NSW, Australia},
series = {ICML'17}
}

@misc{hupkes2019compositionality,
    title={Compositionality decomposed: how do neural networks generalise?},
    author={Dieuwke Hupkes and Verna Dankers and Mathijs Mul and Elia Bruni},
    year={2019},
    eprint={1908.08351},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}


@Incollection{Kindermans2019,
author="Kindermans, Pieter-Jan
and Hooker, Sara
and Adebayo, Julius
and Alber, Maximilian
and Sch{\"u}tt, Kristof T.
and D{\"a}hne, Sven
and Erhan, Dumitru
and Kim, Been",
editor="Samek, Wojciech
and Montavon, Gr{\'e}goire
and Vedaldi, Andrea
and Hansen, Lars Kai
and M{\"u}ller, Klaus-Robert",
title="The (Un)reliability of Saliency Methods",
bookTitle="Explainable AI: Interpreting, Explaining and Visualizing Deep Learning",
year="2019",
publisher="Springer",
pages="267--280",
}


@misc{yanaka2020neural,
    title={Do Neural Models Learn Systematicity of Monotonicity Inference in Natural Language?},
    author={Hitomi Yanaka and Koji Mineshima and Daisuke Bekki and Kentaro Inui},
    year={2020},
    eprint={2004.14839},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{vig2020causal,
    title={Causal Mediation Analysis for Interpreting Neural NLP: The Case of Gender Bias},
    author={Jesse Vig and Sebastian Gehrmann and Yonatan Belinkov and Sharon Qian and Daniel Nevo and Yaron Singer and Stuart Shieber},
    year={2020},
    eprint={2004.12265},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{Chalmers96,
   author={ Chalmers, David},
   title={Does a Rock Implement Every Finite-State Automaton?},
   journal={Synthese},
   volume={108},
   year=1996,
   pages={310-333}
}

@InProceedings{williams:2018,
  author = "Williams, Adina
            and Nangia, Nikita
            and Bowman, Samuel",
  title = "A Broad-Coverage Challenge Corpus for 
           Sentence Understanding through Inference",
  booktitle = "Proceedings of the 2018 Conference of 
               the North American Chapter of the 
               Association for Computational Linguistics:
               Human Language Technologies, Volume 1 (Long
               Papers)",
  year = "2018",
  publisher = "Association for Computational Linguistics",
  pages = "1112--1122",
  location = "New Orleans, Louisiana",
  url = "http://aclweb.org/anthology/N18-1101"
}

@book{Marr:1982:VCI:1095712,
  added-at = {2012-10-25T15:58:41.000+0200},
  address = {New York, NY, USA},
  author = {Marr, David},
  biburl = {https://www.bibsonomy.org/bibtex/2771360e49193a390e85f280dd207de20/daill},
  description = {Vision},
  interhash = {31060780234ce2036de55d261cc63a61},
  intrahash = {771360e49193a390e85f280dd207de20},
  isbn = {0716715678},
  keywords = {computer vision},
  publisher = {Henry Holt and Co., Inc.},
  timestamp = {2012-10-25T15:58:41.000+0200},
  title = {Vision: A Computational Investigation into the Human Representation and Processing of Visual Information},
  year = {1982}
}


@inproceedings{pearl,
author = {Pearl, Judea},
title = {Direct and Indirect Effects},
year = {2001},
isbn = {1558608001},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence},
pages = {411–420},
numpages = {10},
location = {Seattle, Washington},
series = {UAI’01}
}

@article{copeland96,
   author={B. J. Copeland},
   title={What is Computation?},
   journal={Synthese},
   volume={108},
   issue={3},
   year=1996,
   pages={335-359}
}

@inproceedings{Bahdanau:2018,
	Address = {Beijing},
	Author = {Bahdanau, Dzmitry and Murty, Shikhar and Noukhovitch, Michael and Nguyen, Thien Huu and de Vries, Harm and Courville, Aaron},
	Booktitle = {In Proceedings of the 6th International Conference on Learning Representations},
	Month = {August},
	Title = {Systematic generalization: What is required and can it be learned? },
	Year = {2018}}
	
	@inproceedings{McCoy:2019,
		Address = {New Orleans, USA},
  author    = {R. Thomas McCoy and
               Tal Linzen and
               Ewan Dunbar and
               Paul Smolensky},
  title     = {RNNs Implicitly Implement Tensor Product Representations},
  	Month = {May},
  booktitle = {In Proceedings of the 7th International Conference on Learning Representations},
  year      = {2019}
}

@inproceedings{lakeandbaroni2018,
  author    = {Lake, Brenden M. and  Baroni, Marco},
  title     = {Generalization without Systematicity: On the Compositional Skills
               of Sequence-to-Sequence Recurrent Networks},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  series    = {Proceedings of Machine Learning Research},
  volume    = {80},
  pages     = {2879--2888},
  publisher = {{PMLR}},
  year      = {2018},
}


@misc{nie2019adversarial,
    title={Adversarial {NLI}: A New Benchmark for Natural Language Understanding},
    author={Yixin Nie and Adina Williams and Emily Dinan and Mohit Bansal and Jason Weston and Douwe Kiela},
    year={2019},
    eprint={1910.14599},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{Geiger-etal:2019,
	address = {Stroudsburg, PA},
	author = {Geiger, Atticus and Cases, Ignacio and Karttunen, Lauri and Potts, Christopher},
	booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
	doi = {10.18653/v1/D19-1456},
	location = {Hong Kong},
	month = {November},
	pages = {4475--4485},
	publisher = {Association for Computational Linguistics},
	title = {Posing Fair Generalization Tasks for Natural Language Inference},
	url = {https://www.aclweb.org/anthology/D19-1456},
	year = {2019}}

	
@article{Liu:2019,
	Archiveprefix = {arXiv},
	Author = {Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
	Eprint = {1907.11692},
	Journal = {CoRR},
	Timestamp = {Thu, 01 Aug 2019 08:59:33 +0200},
	Title = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
	Url = {http://arxiv.org/abs/1907.11692},
	Volume = {abs/1907.11692},
	Year = {2019},
	Bdsk-Url-1 = {http://arxiv.org/abs/1907.11692}}
	
@article{Brown:2020,
	Author = {T. Brown and B. Mann and Nick Ryder and Melanie Subbiah and J. Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and G. Kr{\"u}ger and Tom Henighan and R. Child and Aditya Ramesh and D. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and E. Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and J. Clark and Christopher Berner and Sam McCandlish and A. Radford and Ilya Sutskever and Dario Amodei},
	Journal = {ArXiv},
	Title = {Language Models are Few-Shot Learners},
	Volume = {abs/2005.14165},
	Year = {2020}}
	
@article{Radford:2019,
	Author = {Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
	Title = {Language Models are Unsupervised Multitask Learners},
	Journal = {OpenAI Blog},
	Year = {2019}}

@book{Fodor1983-FODTMO,
	title = {The Modularity of Mind},
	year = {1983},
	publisher = {MIT Press},
	author = {Jerry A. Fodor}
}

@inproceedings{Elazar-etal-2020,
    title = "Amnesic Probing: Behavioral Explanation with Amnesic Counterfactuals",
    author = "Elazar,Yanai and Ravfogel,Shauli and Jacovi, Alon and  Goldberg, Yoav
",
    booktitle = "Proceedings of the 2020 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP}",
    month = nov,
    year = "2020",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/W18-5426",
}

@inproceedings{Geiger-etal-2020,
    title = "Neural Natural Language Inference Models Partially Embed Theories of
Lexical Entailment and Negation",
    author = "Geiger, Atticus and Richardson, Kyle and Potts, Chris",
    booktitle = "Proceedings of the 2020 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP}",
    month = nov,
    year = "2020",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/W18-5426",
}

@article{GEURTS2003223,
title = "Reasoning with quantifiers",
journal = "Cognition",
volume = "86",
number = "3",
pages = "223 - 251",
year = "2003",
issn = "0010-0277",
doi = "https://doi.org/10.1016/S0010-0277(02)00180-4",
url = "http://www.sciencedirect.com/science/article/pii/S0010027702001804",
author = "Bart Geurts",
keywords = "Syllogistic reasoning, Semantics, Quantification, Generalized quantifiers",
abstract = "In the semantics of natural language, quantification may have received more attention than any other subject, and one of the main topics in psychological studies on deductive reasoning is syllogistic inference, which is just a restricted form of reasoning with quantifiers. But thus far the semantical and psychological enterprises have remained disconnected. This paper aims to show how our understanding of syllogistic reasoning may benefit from semantical research on quantification. I present a very simple logic that pivots on the monotonicity properties of quantified statements – properties that are known to be crucial not only to quantification but to a much wider range of semantical phenomena. This logic is shown to account for the experimental evidence available in the literature as well as for the data from a new experiment with cardinal quantifiers (“at least n” and “at most n”), which cannot be explained by any other theory of syllogistic reasoning."
}


@misc{goodwin2020probing,
    title={Probing Linguistic Systematicity},
    author={Emily Goodwin and Koustuv Sinha and Timothy J. O'Donnell},
    year={2020},
    eprint={2005.04315},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@InProceedings{linzen2020,
    title="How can we accelerate progress towards human-like linguistic generalization?",
    author="Tal Linzen",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Seattle, Washington",
    publisher = "Association for Computational Linguistics"
}

@Booklet{Hupolar,
  author = {Hai Hu and Thomas Icard and Larry Moss},
  title = {Automated Reasoning from Polarized Parse Trees},
  howpublished = {EasyChair Preprint no. 225},
  doi = {10.29007/69wv},
  year = {EasyChair, 2018}}


@article{Fodor:Pylyshyn:1988,
	Author = {Jerry A. Fodor and Zenon W. Pylyshyn},
	Doi = {https://doi.org/10.1016/0010-0277(88)90031-5},
	Issn = {0010-0277},
	Journal = {Cognition},
	Number = {1},
	Pages = {3--71},
	Title = {Connectionism and Cognitive architecture: A critical analysis},
	Url = {http://www.sciencedirect.com/science/article/pii/0010027788900315},
	Volume = {28},
	Year = {1988}}
	
@article{Chen-etal-2016,
  author    = {Qian Chen and
               Xiaodan Zhu and
               Zhen{-}Hua Ling and
               Si Wei and
               Hui Jiang},
  title     = {Enhancing and Combining Sequential and Tree {LSTM} for Natural Language
               Inference},
  journal   = {CoRR},
  volume    = {abs/1609.06038},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.06038},
  archivePrefix = {arXiv},
  eprint    = {1609.06038},
  timestamp = {Mon, 13 Aug 2018 16:48:17 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ChenZLWJ16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{icard2017,
    title="From programs to causal models",
    author="Thomas F. Icard",
    booktitle = "Proceedings of the 21st Amsterdam Colloquium",
    year = "2017",
	Editor = {Alexandre Cremers and Thom van Gessel and
Floris Roelofsen},
	Organization = {University of Amsterdam},
	Pages = {35-44},
}

@article{Parikh-etal-2016,
  author    = {Ankur P. Parikh and
               Oscar T{\"{a}}ckstr{\"{o}}m and
               Dipanjan Das and
               Jakob Uszkoreit},
  title     = {A Decomposable Attention Model for Natural Language Inference},
  journal   = {CoRR},
  volume    = {abs/1606.01933},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.01933},
  archivePrefix = {arXiv},
  eprint    = {1606.01933},
  timestamp = {Mon, 13 Aug 2018 16:49:14 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ParikhT0U16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{talmor2019olmpics,
    title={oLMpics -- On what Language Model Pre-training Captures},
    author={Alon Talmor and Yanai Elazar and Yoav Goldberg and Jonathan Berant},
    year={2019},
    eprint={1912.13283},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{jia-and-liang-2017,
  author    = {Robin Jia and
               Percy Liang},
  title     = {Adversarial Examples for Evaluating Reading Comprehension Systems},
  journal   = {CoRR},
  volume    = {abs/1707.07328},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.07328},
  archivePrefix = {arXiv},
  eprint    = {1707.07328},
  timestamp = {Mon, 13 Aug 2018 16:49:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/JiaL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Levesque:2013,
	Address = {Beijing},
	Author = {Levesque, Hector J.},
	Booktitle = {Proceedings of the Twenty-third International Conference on Artificial Intelligence},
	Month = {August},
	Title = {On our Best Behaviour},
	Year = {2013}}


@book{Fodor75,
	Address = {New York},
	Author = {Fodor, Jerry A.},
	Publisher = {Thomas A.~Crowell Co.},
	Title = {The Language of Thought},
	Topic = {philosophy-of-mind;mental-representations;mental-language;},
	Year = {1975}}


@phdthesis{MacCartney09,
	Author = {MacCartney, Bill},
	School = {Stanford University},
	Title = {Natural Language Inference},
	Year = {2009}}
	

@inproceedings{Moss09,
	Address = {Berlin},
	Author = {Moss, Lawrence S},
	Booktitle = {Proceedings of the 18th Amsterdam Colloquium: Revised Selected Papers},
	Editor = {Aloni, Maria and Bastiaanse, Harald and de Jager, Tikitu and van Ormondt, Peter and Schulz, Katrin},
	Organization = {University of Amsterdam},
	Pages = {71--80},
	Publisher = {Springer},
	Title = {Natural Logic and Semantics},
	Year = {2009}}

@article{Icard:2012,
	Author = {Icard, Thomas F.},
	Journal = {Studia Logica},
	Number = {4},
	Pages = {705--725},
	Title = {Inclusion and Exclusion in Natural Language},
	Volume = {100},
	Year = {2012}}

@inproceedings{Icard:Moss:2013,
	Author = {Icard, Thomas F. and Moss, Lawrence S.},
	Booktitle = {Proceedings of Topology, Algebra, and Categories in Logic},
	Editor = {Galatos, Nikolaos and Kurz, Alexander and Tsinakis, Constantine},
	Month = {July},
	Pages = {96--99},
	Title = {A Complete Calculus of Monotone and Antitone Higher-Order Functions},
	Year = {2013}}
	
	
@article{Icard:Moss:2013:LILT,
	Author = {Icard, Thomas F. and Moss, Lawrence S.},
	Journal = {Linguistic Issues in Language Technology},
	Month = {January},
	Number = {7},
	Pages = {1--31},
	Title = {Recent Progress on Monotonicity},
	Volume = {9},
	Year = {2013}}


@book{WordNet98,
	Address = {Cambridge, MA},
	Editor = {Fellbaum, Christiane},
	Publisher = {MIT Press},
	Title = {Word{N}et: An Electronic Database},
	Year = {1998}}


@incollection{Vaswani-etal:2017,
	Author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
	Booktitle = {Advances in Neural Information Processing Systems 30},
	Editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	Pages = {5998--6008},
	Publisher = {Curran Associates, Inc.},
	Title = {Attention is All you Need},
	Url = {http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf},
	Year = {2017}}

@article{Wolf2019HuggingFacesTS,
  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R'emi Louf and Morgan Funtowicz and Jamie Brew},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.03771}
}

@article{Potts:2018:PATER,
  Author = {Potts, Christopher},
  Journal = {Language},
  Volume = {95},
  Number = {1},
  Pages = {e115--e125},
  Title = {A Case for Deep Learning in Semantics: Response to {P}ater},
  Year = {2019}}


@incollection{Janssen97,
	Author = {Janssen, Theo M.~V.},
	Booktitle = {Handbook of Logic and Language},
	Crossref = {vanBenthem97},
	Pages = {417--473},
	Title = {Compositionality}}


@incollection{Partee84,
	Address = {Dordrecht},
	Author = {Partee, Barbara H.},
	Booktitle = {Varieties of Formal Semantics},
	Editor = {Fred Landman and Frank Veltman},
	Pages = {281--311},
	Publisher = {Foris},
	Title = {Compositionality},
	Year = {1984}}
	
@misc{ravichander2020probing,
      title={Probing the Probing Paradigm: Does Probing Accuracy Entail Task Relevance?}, 
      author={Abhilasha Ravichander and Yonatan Belinkov and Eduard Hovy},
      year={2020},
      eprint={2005.00719},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
	
@inproceedings{nie2019analyzing,
	Author = {Nie, Yixin and Wang, Yicheng and Bansal, Mohit},
	Booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
	Pages = {6867--6874},
	Title = {Analyzing compositionality-sensitivity of {NLI} models},
	Volume = {33},
	Year = {2019}}


@phdthesis{SanchezValencia91,
	Author = {S{\'a}nchez-Valencia, V{\'\i}ctor},
	School = {University of Amsterdam},
	Title = {Studies in Natural Logic and Categorial Grammar},
	Year = {1991}}

@inproceedings{vanBenthem08NATLOG,
	Author = {van Benthem, Johan},
	Booktitle = {Logic, Navya-Nyaya and Applications: Homage to {B}imal {M}atilal},
	Editor = {Chakraborty, M and L{\"o}we, B and Nath Mitra, M. and Sarukki, S.},
	Title = {A Brief History of Natural Logic},
	Year = {2008}}

@book{vanBenthem97,
	Address = {Cambridge, MA and Amsterdam},
	Editor = {van Benthem, Johan and ter Meulen, Alice},
	Publisher = {MIT Press and North-Holland},
	Title = {Handbook of Logic and Language},
	Year = {1997}}
	
	
@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

@article{Hochreiter:97,
 author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
 title = {Long Short-Term Memory},
 journal = {Neural Comput.},
 issue_date = {November 15, 1997},
 volume = {9},
 number = {8},
 month = nov,
 year = {1997},
 issn = {0899-7667},
 pages = {1735--1780},
 numpages = {46},
 url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
 doi = {10.1162/neco.1997.9.8.1735},
 acmid = {1246450},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
}

@book{valencia:91,
  title={Studies on Natural Logic and Categorial Grammar},
  author={S\'{a}nchez-Valencia, V.M.S.},
  url={https://books.google.com/books?id=qH0sAAAAIAAJ},
  year={1991},
  publisher={Universiteit van Amsterdam}
}
@inproceedings{MacCartney:07,
 author = {MacCartney, Bill and Manning, Christopher D.},
 title = {Natural Logic for Textual Inference},
 booktitle = {Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing},
 series = {RTE '07},
 year = {2007},
 location = {Prague, Czech Republic},
 pages = {193--200},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=1654536.1654575},
 acmid = {1654575},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
}
@inproceedings{vanBenthem:08,
	Author = {van Benthem, Johan},
	Booktitle = {Logic, Navya-Nyaya and Applications: Homage to {B}imal {M}atilal},
	Editor = {Chakraborty, M and L{\"o}we, B and Nath Mitra, M. and Sarukki, S.},
	Title = {A Brief History of Natural Logic},
	Year = {2008}}

	
@article{Beckers_Halpern_2019, title={Abstracting Causal Models}, volume={33}, url={https://ojs.aaai.org/index.php/AAAI/article/view/4117}, DOI={10.1609/aaai.v33i01.33012678}, abstractNote={&lt;p&gt;We consider a sequence of successively more restrictive definitions of abstraction for causal models, starting with a notion introduced by Rubenstein et al. (2017) called &lt;em&gt;exact transformation&lt;/em&gt; that applies to probabilistic causal models, moving to a notion of &lt;em&gt;uniform transformation&lt;/em&gt; that applies to deterministic causal models and does not allow differences to be hidden by the “right” choice of distribution, and then to &lt;em&gt;abstraction&lt;/em&gt;, where the interventions of interest are determined by the map from low-level states to high-level states, and &lt;em&gt;strong abstraction&lt;/em&gt;, which takes more seriously all potential interventions in a model, not just the allowed interventions. We show that procedures for combining micro-variables into macro-variables are instances of our notion of strong abstraction, as are all the examples considered by Rubenstein et al.&lt;/p&gt;}, number={01}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Beckers, Sander and Halpern, Joseph Y.}, year={2019}, month={Jul.}, pages={2678-2685} }

@InProceedings{chalupka16,
  title = 	 {Multi-Level Cause-Effect Systems},
  author = 	 {Krzysztof Chalupka and Frederick Eberhardt and Pietro Perona},
  booktitle = 	 {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {361--369},
  year = 	 {2016},
  editor = 	 {Arthur Gretton and Christian C. Robert},
  volume = 	 {51},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Cadiz, Spain},
  month = 	 {09--11 May},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v51/chalupka16.pdf},
  url = 	 {http://proceedings.mlr.press/v51/chalupka16.html},
  abstract = 	 {We present a domain-general account of causation that applies to settings in which macro-level causal relations between two systems are of interest, but the relevant causal features are poorly understood and have to be aggregated from vast arrays of micro-measurements. Our approach generalizes that of Chalupka et. al. (2015) to the setting in which the macro-level effect is not specified. We formalize the connection between micro- and macro-variables in such situations and provide a coherent framework describing causal relations at multiple levels of analysis. We present an algorithm that discovers macro-variable causes and effects from micro-level measurements obtained from an experiment. We further show how to design experiments to discover macro-variables from observational micro-variable data. Finally, we show that under specific conditions, one can identify multiple levels of causal structure. Throughout the article, we use a simulated neuroscience multi-unit recording experiment to illustrate the ideas and the algorithms.}}
  
  @conference{Rubensteinetal17,
  title = {Causal Consistency of Structural Equation Models},
  author = {Rubenstein, P. K. and Weichwald, S. and Bongers, S. and Mooij, J. M. and Janzing, D. and Grosse-Wentrup, M. and Sch{\"o}lkopf, B.},
  booktitle = {Proceedings of the 33rd Conference on Uncertainty in Artificial Intelligence (UAI)},
  editors = {Gal Elidan, Kristian Kersting, and Alexander T. Ihler},
  publisher = {Association for Uncertainty in Artificial Intelligence (AUAI)},
  month = aug,
  year = {2017},
  note = {*equal contribution},
  url = {http://auai.org/uai2017/proceedings/papers/11.pdf},
  month_numeric = {8}
}

@InProceedings{sundararajan17a,
  title = 	 {Axiomatic Attribution for Deep Networks},
  author =       {Mukund Sundararajan and Ankur Taly and Qiqi Yan},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {3319--3328},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/sundararajan17a/sundararajan17a.pdf},
  url = 	 {http://proceedings.mlr.press/v70/sundararajan17a.html},
  abstract = 	 {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms—Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.}}
  
  @article{Shrikumar16,
  author    = {Avanti Shrikumar and
               Peyton Greenside and
               Anna Shcherbina and
               Anshul Kundaje},
  title     = {Not Just a Black Box: Learning Important Features Through Propagating
               Activation Differences},
  journal   = {CoRR},
  volume    = {abs/1605.01713},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.01713},
  archivePrefix = {arXiv},
  eprint    = {1605.01713},
  timestamp = {Mon, 13 Aug 2018 16:48:14 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ShrikumarGSK16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Binder16,
  author    = {Alexander Binder and
               Gr{\'{e}}goire Montavon and
               Sebastian Bach and
               Klaus{-}Robert M{\"{u}}ller and
               Wojciech Samek},
  title     = {Layer-wise Relevance Propagation for Neural Networks with Local Renormalization
               Layers},
  journal   = {CoRR},
  volume    = {abs/1604.00825},
  year      = {2016},
  url       = {http://arxiv.org/abs/1604.00825},
  archivePrefix = {arXiv},
  eprint    = {1604.00825},
  timestamp = {Mon, 13 Aug 2018 16:47:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BinderMBMS16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{springerberg2014,
author = {Springenberg, Jost and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
year = {2014},
  journal   = {CoRR},
month = {12},
pages = {},
title = {Striving for Simplicity: The All Convolutional Net}
}

@InProceedings{Zeiler2014,
author="Zeiler, Matthew D.
and Fergus, Rob",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Visualizing and Understanding Convolutional Networks",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="818--833",
abstract="Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.",
isbn="978-3-319-10590-1"
}

@article{CausalLM,
    author = {Feder, Amir and Oved, Nadav and Shalit, Uri and Reichart, Roi},
    title = "{CausaLM: Causal Model Explanation Through Counterfactual Language Models}",
    journal = {Computational Linguistics},
    pages = {1-54},
    year = {2021},
    month = {05},
    abstract = "{Understanding predictions made by deep neural networks is notoriously difficult, but also crucial to their dissemination. As all machine learning–based methods, they are as good as their training data, and can also capture unwanted biases. While there are tools that can help understand whether such biases exist, they do not distinguish between correlation and causation, and might be ill-suited for text-based models and for reasoning about high level language concepts. A key problem of estimating the causal effect of a concept of interest on a given model is that this estimation requires the generation of counterfactual examples, which is challenging with existing generation technology. To bridge that gap, we propose CausaLM, a framework for producing causal model explanations using counterfactual language representation models. Our approach is based on fine-tuning of deep contextualized embedding models with auxiliary adversarial tasks derived from the causal graph of the problem. Concretely, we show that by carefully choosing auxiliary adversarial pre-training tasks, language representation models such as BERT can effectively learn a counterfactual representation for a given concept of interest, and be used to estimate its true causal effect on model performance. A byproduct of our method is a language representation model that is unaffected by the tested concept, which can be useful in mitigating unwanted bias ingrained in the data.}",
    issn = {0891-2017},
    doi = {10.1162/coli_a_00404},
    url = {https://doi.org/10.1162/coli\_a\_00404},
    eprint = {https://direct.mit.edu/coli/article-pdf/doi/10.1162/coli\_a\_00404/1919753/coli\_a\_00404.pdf},
}

@inproceedings{SHAP,
 author = {Lundberg, Scott M and Lee, Su-In},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {A Unified Approach to Interpreting Model Predictions},
 url = {https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf},
 volume = {30},
 year = {2017}
}



@book{molnar2019,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  note       = {\url{https://christophm.github.io/interpretable-ml-book/}},
  year       = {2019},
  subtitle   = {A Guide for Making Black Box Models Explainable}
}

@InProceedings{beckers20a,
  title = 	 {Approximate Causal Abstractions},
  author =       {Beckers, Sander and Eberhardt, Frederick and Halpern, Joseph Y.},
  booktitle = 	 {Proceedings of The 35th Uncertainty in Artificial Intelligence Conference},
  pages = 	 {606--615},
  year = 	 {2020},
  editor = 	 {Ryan P. Adams and Vibhav Gogate},
  volume = 	 {115},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Tel Aviv, Israel},
  month = 	 {22--25 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v115/beckers20a/beckers20a.pdf},
  url = 	 {http://proceedings.mlr.press/v115/beckers20a.html},
  abstract = 	 {Scientific models describe natural phenomena at different levels of abstraction. Abstract descriptions can provide the basis for interventions on the system and explanation of observed phenomena at a level of granularity that is coarser than the most fundamental account of the system. Beckers and Halpern (2019), building on prior work of Rubinstein et al. (2017), developed an account of abstraction for causal models that is exact. Here we extend this account to the more realistic case where an abstract causal model only offers an approximation of the underlying system. We show how the resulting account handles the discrepancy that can arise between low- and high-level causal models of the same system, and in the process provide an account of how one causal model approximates another, a topic of independent interest. Finally, we extend the account of approximate abstractions to probabilistic causal models, indicating how and where uncertainty can enter into an approximate abstraction.}
}
@book{spirtes,
    title = {{Causation, Prediction, and Search}},
    year = {2001},
    author = {Spirtes, Peter and Glymour, Clark N and Scheines, Richard},
    edition = {2nd},
    publisher = {MIT Press},
    isbn = {9780262194402}
}
@inproceedings{10.1145/2939672.2939778,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939778},
doi = {10.1145/2939672.2939778},
abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1135–1144},
numpages = {10},
keywords = {interpretable machine learning, interpretability, black box classifier, explaining machine learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@InProceedings{chattopadhyay19a,
  title = 	 {Neural Network Attributions: A Causal Perspective},
  author =       {Chattopadhyay, Aditya and Manupriya, Piyushi and Sarkar, Anirban and Balasubramanian, Vineeth N},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {981--990},
  year = 	 {2019},
  editor = 	 {Kamalika Chaudhuri and Ruslan Salakhutdinov},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Long Beach, California, USA},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/chattopadhyay19a/chattopadhyay19a.pdf},
  url = 	 {http://proceedings.mlr.press/v97/chattopadhyay19a.html},
}


@article{Bongers2016,
  author = "Stephan Bongers and Patrick Forr{\'e} and Jonas Peters and Bernhard Sch{\"o}lkopf and Joris M. Mooij",
  journal = "arXiv.org preprint",
  title = "Foundations of Structural Causal Models with Cycles and Latent Variables",
  volume = "arXiv:1611.06221v4 [stat.ME]",
  month = Oct,
  year = 2020,
  url = "https://arxiv.org/abs/1611.06221v4"
}

@article{Jonas:2017,
    doi = {10.1371/journal.pcbi.1005268},
    author = {Jonas, Eric AND Kording, Konrad Paul},
    journal = {PLOS Computational Biology},
    publisher = {Public Library of Science},
    title = {Could a Neuroscientist Understand a Microprocessor?},
    year = {2017},
    month = {01},
    volume = {13},
    url = {https://doi.org/10.1371/journal.pcbi.1005268},
    pages = {1-24},
    abstract = {There is a popular belief in neuroscience that we are primarily data limited, and that producing large, multimodal, and complex datasets will, with the help of advanced data analysis algorithms, lead to fundamental insights into the way the brain processes information. These datasets do not yet exist, and if they did we would have no way of evaluating whether or not the algorithmically-generated insights were sufficient or even correct. To address this, here we take a classical microprocessor as a model organism, and use our ability to perform arbitrary experiments on it to see if popular data analysis methods from neuroscience can elucidate the way it processes information. Microprocessors are among those artificial information processing systems that are both complex and that we understand at all levels, from the overall logical flow, via logical gates, to the dynamics of transistors. We show that the approaches reveal interesting structure in the data but do not meaningfully describe the hierarchy of information processing in the microprocessor. This suggests current analytic approaches in neuroscience may fall short of producing meaningful understanding of neural systems, regardless of the amount of data. Additionally, we argue for scientists using complex non-linear dynamical systems with known ground truth, such as the microprocessor as a validation platform for time-series and structure discovery methods.},
    number = {1},

}