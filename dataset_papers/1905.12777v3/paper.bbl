\begin{thebibliography}{32}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
Arjovsky, M., Chintala, S., and Bottou, L.
\newblock Wasserstein generative adversarial networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  214--223, 2017.

\bibitem[Bengio et~al.(2013)Bengio, Yao, Alain, and
  Vincent]{bengio2013generalized}
Bengio, Y., Yao, L., Alain, G., and Vincent, P.
\newblock Generalized denoising auto-encoders as generative models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  899--907, 2013.

\bibitem[Bowman et~al.(2016)Bowman, Vilnis, Vinyals, Dai, Jozefowicz, and
  Bengio]{bowman2015generating}
Bowman, S.~R., Vilnis, L., Vinyals, O., Dai, A.~M., Jozefowicz, R., and Bengio,
  S.
\newblock Generating sentences from a continuous space.
\newblock In \emph{Conference on Computational Natural Language Learning},
  2016.

\bibitem[Chen et~al.(2016)Chen, Kingma, Salimans, Duan, Dhariwal, Schulman,
  Sutskever, and Abbeel]{chen2016variational}
Chen, X., Kingma, D.~P., Salimans, T., Duan, Y., Dhariwal, P., Schulman, J.,
  Sutskever, I., and Abbeel, P.
\newblock Variational lossy autoencoder.
\newblock \emph{arXiv preprint arXiv:1611.02731}, 2016.

\bibitem[C{\'\i}fka et~al.(2018)C{\'\i}fka, Severyn, Alfonseca, and
  Filippova]{cifka2018eval}
C{\'\i}fka, O., Severyn, A., Alfonseca, E., and Filippova, K.
\newblock Eval all, trust a few, do wrong to none: Comparing sentence
  generation models.
\newblock \emph{arXiv preprint arXiv:1804.07972}, 2018.

\bibitem[Creswell \& Bharath(2018)Creswell and Bharath]{creswell2018denoising}
Creswell, A. and Bharath, A.~A.
\newblock Denoising adversarial autoencoders.
\newblock \emph{IEEE transactions on neural networks and learning systems},
  \penalty0 (99):\penalty0 1--17, 2018.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2672--2680, 2014.

\bibitem[He et~al.(2019)He, Spokoyny, Neubig, and
  Berg-Kirkpatrick]{he2019lagging}
He, J., Spokoyny, D., Neubig, G., and Berg-Kirkpatrick, T.
\newblock Lagging inference networks and posterior collapse in variational
  autoencoders.
\newblock \emph{arXiv preprint arXiv:1901.05534}, 2019.

\bibitem[Higgins et~al.(2017)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{higgins2017beta}
Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M.,
  Mohamed, S., and Lerchner, A.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock In \emph{International Conference on Learning Representations},
  volume~3, 2017.

\bibitem[Hu et~al.(2017)Hu, Yang, Liang, Salakhutdinov, and Xing]{hu2017toward}
Hu, Z., Yang, Z., Liang, X., Salakhutdinov, R., and Xing, E.~P.
\newblock Toward controlled generation of text.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  1587--1596. JMLR. org, 2017.

\bibitem[Im et~al.(2017)Im, Ahn, Memisevic, and Bengio]{im2017denoising}
Im, D. I.~J., Ahn, S., Memisevic, R., and Bengio, Y.
\newblock Denoising criterion for variational auto-encoding framework.
\newblock In \emph{Thirty-First AAAI Conference on Artificial Intelligence},
  2017.

\bibitem[Kim et~al.(2018)Kim, Wiseman, Miller, Sontag, and Rush]{kim2018semi}
Kim, Y., Wiseman, S., Miller, A.~C., Sontag, D., and Rush, A.~M.
\newblock Semi-amortized variational autoencoders.
\newblock \emph{arXiv preprint arXiv:1802.02550}, 2018.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{kingma2013auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Logeswaran et~al.(2018)Logeswaran, Lee, and
  Bengio]{logeswaran2018content}
Logeswaran, L., Lee, H., and Bengio, S.
\newblock Content preserving text generation with attribute controls.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  5103--5113, 2018.

\bibitem[Makhzani et~al.(2015)Makhzani, Shlens, Jaitly, Goodfellow, and
  Frey]{makhzani2015adversarial}
Makhzani, A., Shlens, J., Jaitly, N., Goodfellow, I., and Frey, B.
\newblock Adversarial autoencoders.
\newblock \emph{arXiv preprint arXiv:1511.05644}, 2015.

\bibitem[Mikolov et~al.(2013)Mikolov, Yih, and Zweig]{mikolov2013linguistic}
Mikolov, T., Yih, W.-t., and Zweig, G.
\newblock Linguistic regularities in continuous space word representations.
\newblock In \emph{Proceedings of the 2013 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pp.\  746--751, 2013.

\bibitem[Mueller et~al.(2017)Mueller, Gifford, and
  Jaakkola]{mueller2017sequence}
Mueller, J., Gifford, D., and Jaakkola, T.
\newblock Sequence to better sequence: continuous revision of combinatorial
  structures.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  2536--2544. JMLR. org, 2017.

\bibitem[Papineni et~al.(2002)Papineni, Roukos, Ward, and
  Zhu]{papineni2002bleu}
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock In \emph{Proceedings of the 40th annual meeting on association for
  computational linguistics}, pp.\  311--318. Association for Computational
  Linguistics, 2002.

\bibitem[Poole et~al.(2014)Poole, Sohl-Dickstein, and
  Ganguli]{poole2014analyzing}
Poole, B., Sohl-Dickstein, J., and Ganguli, S.
\newblock Analyzing noise in autoencoders and deep networks.
\newblock \emph{arXiv preprint arXiv:1406.1831}, 2014.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{radford2019language}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI Blog}, 1:\penalty0 8, 2019.

\bibitem[Rubenstein et~al.(2018)Rubenstein, Schoelkopf, and
  Tolstikhin]{rubenstein2018latent}
Rubenstein, P.~K., Schoelkopf, B., and Tolstikhin, I.
\newblock On the latent space of wasserstein auto-encoders.
\newblock \emph{arXiv preprint arXiv:1802.03761}, 2018.

\bibitem[Sch{\"a}fer \& Zimmermann(2006)Sch{\"a}fer and
  Zimmermann]{schafer2006recurrent}
Sch{\"a}fer, A.~M. and Zimmermann, H.~G.
\newblock Recurrent neural networks are universal approximators.
\newblock In \emph{International Conference on Artificial Neural Networks},
  pp.\  632--640. Springer, 2006.

\bibitem[Shen et~al.(2017)Shen, Lei, Barzilay, and Jaakkola]{shen2017style}
Shen, T., Lei, T., Barzilay, R., and Jaakkola, T.
\newblock Style transfer from non-parallel text by cross-alignment.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  6830--6841, 2017.

\bibitem[Subramanian et~al.(2018)Subramanian, Lample, Smith, Denoyer, Ranzato,
  and Boureau]{subramanian2018multiple}
Subramanian, S., Lample, G., Smith, E.~M., Denoyer, L., Ranzato, M., and
  Boureau, Y.-L.
\newblock Multiple-attribute text style transfer.
\newblock \emph{arXiv preprint arXiv:1811.00552}, 2018.

\bibitem[Tolstikhin et~al.(2017)Tolstikhin, Bousquet, Gelly, and
  Schoelkopf]{tolstikhin2017wasserstein}
Tolstikhin, I., Bousquet, O., Gelly, S., and Schoelkopf, B.
\newblock Wasserstein auto-encoders.
\newblock \emph{arXiv preprint arXiv:1711.01558}, 2017.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  5998--6008, 2017.

\bibitem[Vincent et~al.(2008)Vincent, Larochelle, Bengio, and
  Manzagol]{vincent2008extracting}
Vincent, P., Larochelle, H., Bengio, Y., and Manzagol, P.-A.
\newblock Extracting and composing robust features with denoising autoencoders.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, pp.\  1096--1103. ACM, 2008.

\bibitem[Yang et~al.(2017)Yang, Hu, Salakhutdinov, and
  Berg-Kirkpatrick]{yang2017improved}
Yang, Z., Hu, Z., Salakhutdinov, R., and Berg-Kirkpatrick, T.
\newblock Improved variational autoencoders for text modeling using dilated
  convolutions.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  3881--3890. JMLR. org, 2017.

\bibitem[Zhang et~al.(2017)Zhang, Bengio, Hardt, Recht, and Vinyals]{zhang2017}
Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals, O.
\newblock Understanding deep learning requires rethinking generalization.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Zhao et~al.(2018)Zhao, Kim, Zhang, Rush, LeCun,
  et~al.]{zhao2018adversarially}
Zhao, J., Kim, Y., Zhang, K., Rush, A.~M., LeCun, Y., et~al.
\newblock Adversarially regularized autoencoders.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, 2018.

\end{thebibliography}
