@article{yao2022learning,
  title={Learning Latent Causal Dynamics},
  author={Yao, Weiran and Chen, Guangyi and Zhang, Kun},
  journal={arXiv preprint arXiv:2202.04828},
  year={2022}
}

@book{peters2017elements,
  title={Elements of causal inference: foundations and learning algorithms},
  author={Peters, Jonas and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  year={2017},
  publisher={The MIT Press}
}

@inproceedings{bhattacharya2021differentiable,
  title={Differentiable causal discovery under unmeasured confounding},
  author={Bhattacharya, Rohit and Nagarajan, Tushar and Malinsky, Daniel and Shpitser, Ilya},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2314--2322},
  year={2021},
  organization={PMLR}
}

@article{berrevoets2023causal,
  title={Causal Deep Learning},
  author={Berrevoets, Jeroen and Kacprzyk, Krzysztof and Qian, Zhaozhi and van der Schaar, Mihaela},
  journal={arXiv preprint arXiv:2303.02186},
  year={2023}
}

@inproceedings{ng2022convergence,
  title={On the convergence of continuous constrained optimization for structure learning},
  author={Ng, Ignavier and Lachapelle, S{\'e}bastien and Ke, Nan Rosemary and Lacoste-Julien, Simon and Zhang, Kun},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={8176--8198},
  year={2022},
  organization={PMLR}
}

@article{gao2021federated,
  title={Federated causal discovery},
  author={Gao, Erdun and Chen, Junjia and Shen, Li and Liu, Tongliang and Gong, Mingming and Bondell, Howard},
  journal={arXiv preprint arXiv:2112.03555},
  year={2021}
}


@article{huang2020causal,
  title={Causal Discovery from Heterogeneous/Nonstationary Data.},
  author={Huang, Biwei and Zhang, Kun and Zhang, Jiji and Ramsey, Joseph D and Sanchez-Romero, Ruben and Glymour, Clark and Sch{\"o}lkopf, Bernhard},
  journal={J. Mach. Learn. Res.},
  volume={21},
  number={89},
  pages={1--53},
  year={2020}
}

@article{peters2015,
 ISSN = {13697412, 14679868},
 URL = {http://www.jstor.org/stable/44682904},
 abstract = {What is the difference between a prediction that is made with a causal model and that with a non-causal model? Suppose that we intervene on the predictor variables or change the whole environment. The predictions from a causal model will in general work as well under interventions as for observational data. In contrast, predictions from a non-causal model can potentially be very wrong if we actively intervene on variables. Here, we propose to exploit this invariance of a prediction under a causal model for causal inference: given different experimental settings (e.g. various interventions) we collect all models that do show invariance in their predictive accuracy across settings and interventions. The causal model will be a member of this set of models with high probability. This approach yields valid confidence intervals for the causal relationships in quite general scenarios. We examine the example of structural equation models in more detail and provide sufficient assumptions under which the set of causal predictors becomes identifiable. We further investigate robustness properties of our approach under model misspecification and discuss possible extensions. The empirical properties are studied for various data sets, including large-scale gene perturbation experiments.},
 author = {Jonas Peters and Peter Bühlmann and Nicolai Meinshausen},
 journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
 number = {5},
 pages = {947--1012},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Causal inference by using invariant prediction: identification and confidence intervals},
 urldate = {2022-11-16},
 volume = {78},
 year = {2016}
}



@article{ghassami2018multi,
  title={Multi-domain causal structure learning in linear systems},
  author={Ghassami, AmirEmad and Kiyavash, Negar and Huang, Biwei and Zhang, Kun},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{ng2022towards,
  title={Towards federated bayesian network structure learning with continuous optimization},
  author={Ng, Ignavier and Zhang, Kun},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={8095--8111},
  year={2022},
  organization={PMLR}
}

@article{wei2020dags,
  title={DAGs with No Fears: A closer look at continuous optimization for learning Bayesian networks},
  author={Wei, Dennis and Gao, Tian and Yu, Yue},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3895--3906},
  year={2020}
}

@book{walter2014identifiability,
  title={Identifiability of parametric models},
  author={Walter, Eric},
  year={2014},
  publisher={Elsevier}
}

@article{meek2013strong,
  title={Strong completeness and faithfulness in Bayesian networks},
  author={Meek, Christopher},
  journal={arXiv preprint arXiv:1302.4973},
  year={2013}
}

@article{eberhardt2017introduction,
  title={Introduction to the foundations of causal discovery},
  author={Eberhardt, Frederick},
  journal={International Journal of Data Science and Analytics},
  volume={3},
  number={2},
  pages={81--91},
  year={2017},
  publisher={Springer}
}


@article{glymour2019review,
  title={Review of causal discovery methods based on graphical models},
  author={Glymour, Clark and Zhang, Kun and Spirtes, Peter},
  journal={Frontiers in genetics},
  volume={10},
  pages={524},
  year={2019},
  publisher={Frontiers Media SA}
}

@article{vowels2021d,
  title={D’ya like DAGs? A survey on structure learning and causal discovery},
  author={Vowels, Matthew J and Camgoz, Necati Cihan and Bowden, Richard},
  journal={ACM Computing Surveys (CSUR)},
  year={2021},
  publisher={ACM New York, NY}
}

@incollection{robinson1977counting,
  title={Counting unlabeled acyclic digraphs},
  author={Robinson, Robert W},
  booktitle={Combinatorial mathematics V},
  pages={28--43},
  year={1977},
  publisher={Springer}
}

@book{lauritzen1996graphical,
  title={Graphical models},
  author={Lauritzen, Steffen L},
  volume={17},
  year={1996},
  publisher={Clarendon Press}
}

@article{wainwright2008graphical,
  title={Graphical models, exponential families, and variational inference},
  author={Wainwright, Martin J and Jordan, Michael I and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={1},
  number={1--2},
  pages={1--305},
  year={2008},
  publisher={Now Publishers, Inc.}
}

@article{van2021decaf,
  title={DECAF: Generating Fair Synthetic Data Using Causally-Aware Generative Networks},
  author={van Breugel, Boris and Kyono, Trent and Berrevoets, Jeroen and van der Schaar, Mihaela},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{kyono2021miracle,
  title={MIRACLE: Causally-Aware Imputation via Learning Missing Data Mechanisms},
  author={Kyono, Trent and Zhang, Yao and Bellot, Alexis and van der Schaar, Mihaela},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{pamfil2020dynotears,
  title={Dynotears: Structure learning from time-series data},
  author={Pamfil, Roxana and Sriwattanaworachai, Nisara and Desai, Shaan and Pilgerstorfer, Philip and Georgatzis, Konstantinos and Beaumont, Paul and Aragam, Bryon},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1595--1605},
  year={2020},
  organization={PMLR}
}

@article{kyono2020castle,
  title={Castle: Regularization via auxiliary causal graph discovery},
  author={Kyono, Trent and Zhang, Yao and van der Schaar, Mihaela},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1501--1512},
  year={2020}
}

@book{bertsekas1999,
  title={Nonlinear Programming},
  author={Dimitri P. Bertsekas},
  year={2016},
  edition={3\textsuperscript{rd}},
  isbn={978-1-886529-05-2},
  pages=880,
  publisher={Athena Scientific},
}

@article{reisach2021beware,
  title={Beware of the simulated dag! varsortability in additive noise models},
  author={Reisach, Alexander G and Seiler, Christof and Weichwald, Sebastian},
  journal={arXiv preprint arXiv:2102.13647},
  year={2021}
}

@book{jordan1999learning,
  title={Learning in graphical models},
  author={Jordan, Michael Irwin},
  year={1999},
  publisher={MIT press}
}

@article{byrd1995limited,
  title={A limited memory algorithm for bound constrained optimization},
  author={Byrd, Richard H and Lu, Peihuang and Nocedal, Jorge and Zhu, Ciyou},
  journal={SIAM Journal on scientific computing},
  volume={16},
  number={5},
  pages={1190--1208},
  year={1995},
  publisher={SIAM}
}

@book{pearl1988probabilistic,
  title={Probabilistic reasoning in intelligent systems: networks of plausible inference},
  author={Pearl, Judea},
  year={1988},
  publisher={Morgan kaufmann}
}

@book{pearl2009causality,
  title={Causality},
  author={Pearl, Judea},
  year={2009},
  publisher={Cambridge university press}
}

@article{davies2021advancing,
  title={Advancing mathematics by guiding human intuition with AI},
  author={Davies, Alex and Veli{\v{c}}kovi{\'c}, Petar and Buesing, Lars and Blackwell, Sam and Zheng, Daniel and Toma{\v{s}}ev, Nenad and Tanburn, Richard and Battaglia, Peter and Blundell, Charles and Juh{\'a}sz, Andr{\'a}s and others},
  journal={Nature},
  volume={600},
  number={7887},
  pages={70--74},
  year={2021},
  publisher={Nature Publishing Group}
}

@inproceedings{zheng2018dags,
    author = {Zheng, Xun and Aragam, Bryon and Ravikumar, Pradeep and Xing, Eric P.},
    booktitle = {Advances in Neural Information Processing Systems},
    title = {{DAGs with NO TEARS: Continuous Optimization for Structure Learning}},
    year = {2018}
}

@inproceedings{zheng2020learning,
    author = {Zheng, Xun and Dan, Chen and Aragam, Bryon and Ravikumar, Pradeep and Xing, Eric P.},
    booktitle = {International Conference on Artificial Intelligence and Statistics},
    title = {{Learning sparse nonparametric DAGs}},
    year = {2020}
}



@article{wright1934method,
  title={The method of path coefficients},
  author={Wright, Sewall},
  journal={The annals of mathematical statistics},
  volume={5},
  number={3},
  pages={161--215},
  year={1934},
  publisher={JSTOR}
}

@article{stodden2010scientific,
  title={The scientific method in practice: Reproducibility in the computational sciences},
  author={Stodden, Victoria},
  year={2010},
  publisher={MIT Sloan research paper}
}

@book{merton1973sociology,
  title={The sociology of science: Theoretical and empirical investigations},
  author={Merton, Robert K},
  year={1973},
  publisher={University of Chicago press}
}

@article{camerer2016evaluating,
  title={Evaluating replicability of laboratory experiments in economics},
  author={Camerer, Colin F and Dreber, Anna and Forsell, Eskil and Ho, Teck-Hua and Huber, J{\"u}rgen and Johannesson, Magnus and Kirchler, Michael and Almenberg, Johan and Altmejd, Adam and Chan, Taizan and others},
  journal={Science},
  volume={351},
  number={6280},
  pages={1433--1436},
  year={2016},
  publisher={American Association for the Advancement of Science}
}

@article{baker20161,
  title={1,500 scientists lift the lid on reproducibility},
  author={Baker, Monya},
  journal={Nature},
  volume={533},
  number={7604},
  year={2016}
}

@InProceedings{meek1995strong,
  title={Strong completeness and faithfulness in Bayesian networks},
  author={Meek, Christopher},
  booktitle={Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence},
  pdf={https://arxiv.org/pdf/1302.4973},
  year={1995}
}

@inproceedings{becker2000perfect,
  title={Perfect tree-like markovian distributions},
  author={Becker, Ann and Geiger, Dan and Meek, Christopher},
  booktitle={Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence},
  url={https://arxiv.org/abs/1301.3834},
  year={2000}
}


@article{seedat2022data,
  title={{Data-SUITE}: Data-centric identification of in-distribution incongruous examples},
  author={Seedat, Nabeel and Crabbe, Jonathan and van der Schaar, Mihaela},
  journal={arXiv preprint arXiv:2202.08836},
  year={2022}
}

@article{kaiser2022unsuitability,
  title={Unsuitability of {NOTEARS} for Causal Graph Discovery when Dealing with Dimensional Quantities},
  author={Kaiser, Marcus and Sipos, Maksim},
  journal={Neural Processing Letters},
  pages={1--9},
  year={2022},
  publisher={Springer}
}

@article{geiger1993logical,
  title={Logical and algorithmic properties of conditional independence and graphical models},
  author={Geiger, Dan and Pearl, Judea},
  journal={The annals of statistics},
  volume={21},
  number={4},
  pages={2001--2021},
  year={1993},
  publisher={Institute of Mathematical Statistics}
}

@article{geiger1990identifying,
  title={Identifying independence in Bayesian networks},
  author={Geiger, Dan and Verma, Thomas and Pearl, Judea},
  journal={Networks},
  volume={20},
  number={5},
  pages={507--534},
  year={1990},
  publisher={Wiley Online Library}
}

@incollection{geiger1990d,
  title={d-separation: From theorems to algorithms},
  author={Geiger, Dan and Verma, Thomas and Pearl, Judea},
  booktitle={Machine Intelligence and Pattern Recognition},
  volume={10},
  pages={139--148},
  year={1990},
  publisher={Elsevier}
}

@incollection{geiger1990logic,
  title={On the logic of causal models},
  author={Geiger, Dan and Pearl, Judea},
  booktitle={Machine Intelligence and Pattern Recognition},
  volume={9},
  pages={3--14},
  year={1990},
  publisher={Elsevier}
}

@incollection{verma1990causal,
  title={Causal networks: Semantics and expressiveness},
  author={Verma, Thomas and Pearl, Judea},
  booktitle={Machine intelligence and pattern recognition},
  volume={9},
  pages={69--76},
  year={1990},
  publisher={Elsevier}
}

@InProceedings{verma1990,
  title = 	 {Equivalence and Synthesis of Causal Models},
  author =       {Verma, Thomas S. and Pearl, Judea},
  booktitle = 	 {Proceedings of the Sixth Conference on Uncertainty in Artificial Intelligence},
  year = 	 {1990},
  pdf = 	 {https://arxiv.org/pdf/1304.1108.pdf},
 
}

@article{uhler2013geometry,
  title={Geometry of the faithfulness assumption in causal inference},
  author={Uhler, Caroline and Raskutti, Garvesh and B{\"u}hlmann, Peter and Yu, Bin},
  journal={The Annals of Statistics},
  pages={436--463},
  year={2013},
  publisher={JSTOR}
}
@inproceedings{
bello2022dagma,
title={{DAGMA}: Learning {DAG}s via M-matrices and a Log-Determinant Acyclicity Characterization},
author={Kevin Bello and Bryon Aragam and Pradeep Kumar Ravikumar},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=8rZYMpFUgK}
}

@incollection{heckerman2006bayesian,
  title={A Bayesian approach to causal discovery},
  author={Heckerman, David and Meek, Christopher and Cooper, Gregory},
  booktitle={Innovations in Machine Learning},
  pages={1--28},
  year={2006},
  publisher={Springer}
}

@book{pearl2018book,
  title={The Book of Why: The New Science of Cause and Effect},
  author={Pearl, Judea and Mackenzie, Dana},
  year={2018},
  publisher={Hachette UK}
}

@incollection{geiger1994learning,
  title={Learning gaussian networks},
  author={Geiger, Dan and Heckerman, David},
  booktitle={Uncertainty Proceedings 1994},
  pages={235--243},
  year={1994},
  publisher={Elsevier}
}

@article{zhang2012strong,
  title={Strong faithfulness and uniform consistency in causal inference},
  author={Zhang, Jiji and Spirtes, Peter L},
  journal={arXiv preprint arXiv:1212.2506},
  year={2012}
}

@article{kalisch2007estimating,
  title={Estimating high-dimensional directed acyclic graphs with the PC-algorithm.},
  author={Kalisch, Markus and B{\"u}hlman, Peter},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={3},
  year={2007}
}


@InProceedings{tian1999causal,
  title={Causal discovery from changes},
  author={Tian, Jin and Pearl, Judea},
  booktitle = {Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence},
  year={1999}
}






@article{RUFF2021167208,
title = {AlphaFold and Implications for Intrinsically Disordered Proteins},
journal = {Journal of Molecular Biology},
volume = {433},
number = {20},
pages = {167208},
year = {2021},
note = {From Protein Sequence to Structure at Warp Speed: How Alphafold Impacts Biology},
issn = {0022-2836},
doi = {https://doi.org/10.1016/j.jmb.2021.167208},
url = {https://www.sciencedirect.com/science/article/pii/S0022283621004411},
author = {Kiersten M. Ruff and Rohit V. Pappu},
keywords = {AlphaFold, intrinsically disordered proteins, cautionary notes},
abstract = {Accurate predictions of the three-dimensional structures of proteins from their amino acid sequences have come of age. AlphaFold, a deep learning-based approach to protein structure prediction, shows remarkable success in independent assessments of prediction accuracy. A significant epoch in structural bioinformatics was the structural annotation of over 98\% of protein sequences in the human proteome. Interestingly, many predictions feature regions of very low confidence, and these regions largely overlap with intrinsically disordered regions (IDRs). That over 30\% of regions within the proteome are disordered is congruent with estimates that have been made over the past two decades, as intense efforts have been undertaken to generalize the structure–function paradigm to include the importance of conformational heterogeneity and dynamics. With structural annotations from AlphaFold in hand, there is the temptation to draw inferences regarding the “structures” of IDRs and their interactomes. Here, we offer a cautionary note regarding the misinterpretations that might ensue and highlight efforts that provide concrete understanding of sequence-ensemble-function relationships of IDRs. This perspective is intended to emphasize the importance of IDRs in sequence-function relationships (SERs) and to highlight how one might go about extracting quantitative SERs to make sense of how IDRs function.}
}

@article{tunyasuvunakool2021highly,
  title={Highly accurate protein structure prediction for the human proteome},
  author={Tunyasuvunakool, Kathryn and Adler, Jonas and Wu, Zachary and Green, Tim and Zielinski, Michal and {\v{Z}}{\'\i}dek, Augustin and Bridgland, Alex and Cowie, Andrew and Meyer, Clemens and Laydon, Agata and others},
  journal={Nature},
  volume={596},
  number={7873},
  pages={590--596},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{jumper2021highly,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
  journal={Nature},
  volume={596},
  number={7873},
  pages={583--589},
  year={2021},
  publisher={Nature Publishing Group}
}


@article{kehoe2015survey,
  title={A survey of research on cloud robotics and automation},
  author={Kehoe, Ben and Patil, Sachin and Abbeel, Pieter and Goldberg, Ken},
  journal={IEEE Transactions on automation science and engineering},
  volume={12},
  number={2},
  pages={398--409},
  year={2015},
  publisher={IEEE}
}

@inproceedings{ring2019jumping,
  title={Jumping in at the deep end: how to experiment with machine learning in post-production software},
  author={Ring, Dan and Barbier, Johanna and Gales, Guillaume and Kent, Ben and Lutz, Sebastian},
  booktitle={Proceedings of the 2019 Digital Production Symposium},
  pages={1--5},
  year={2019}
}

@inproceedings{wang2022film,
  title={Film and Television Special Effects Production Based on Modern Technology: from the Perspective of Statistical Machine Learning},
  author={Wang, Yi},
  booktitle={2022 4th International Conference on Smart Systems and Inventive Technology (ICSSIT)},
  pages={833--836},
  year={2022},
  organization={IEEE}
}

@incollection{kleiman2019boosting,
  title={Boosting VFX production with deep learning},
  author={Kleiman, Yanir and Pabst, Simon and Nagle, Patrick},
  booktitle={ACM SIGGRAPH 2019 Talks},
  pages={1--2},
  year={2019}
}

@article{abbeel2010autonomous,
  title={Autonomous helicopter aerobatics through apprenticeship learning},
  author={Abbeel, Pieter and Coates, Adam and Ng, Andrew Y},
  journal={The International Journal of Robotics Research},
  volume={29},
  number={13},
  pages={1608--1639},
  year={2010},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{peng2018sim,
  title={Sim-to-real transfer of robotic control with dynamics randomization},
  author={Peng, Xue Bin and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={3803--3810},
  year={2018},
  organization={IEEE}
}

@book{peters2007machine,
  title={Machine learning of motor skills for robotics},
  author={Peters, Jan Reinhard},
  year={2007},
  publisher={University of Southern California}
}

@article{udrescu2020ai,
  title={AI Feynman: A physics-inspired method for symbolic regression},
  author={Udrescu, Silviu-Marian and Tegmark, Max},
  journal={Science Advances},
  volume={6},
  number={16},
  pages={eaay2631},
  year={2020},
  publisher={American Association for the Advancement of Science}
}

@article{breen2020newton,
  title={Newton versus the machine: solving the chaotic three-body problem using deep neural networks},
  author={Breen, Philip G and Foley, Christopher N and Boekholt, Tjarda and Zwart, Simon Portegies},
  journal={Monthly Notices of the Royal Astronomical Society},
  volume={494},
  number={2},
  pages={2465--2470},
  year={2020},
  publisher={Oxford University Press}
}

@article{karniadakis2021physics,
  title={Physics-informed machine learning},
  author={Karniadakis, George Em and Kevrekidis, Ioannis G and Lu, Lu and Perdikaris, Paris and Wang, Sifan and Yang, Liu},
  journal={Nature Reviews Physics},
  volume={3},
  number={6},
  pages={422--440},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{sarma2019machine,
  title={Machine learning meets quantum physics},
  author={Sarma, Sankar Das and Deng, Dong-Ling and Duan, Lu-Ming},
  journal={arXiv preprint arXiv:1903.03516},
  year={2019}
}

@article{radovic2018machine,
  title={Machine learning at the energy and intensity frontiers of particle physics},
  author={Radovic, Alexander and Williams, Mike and Rousseau, David and Kagan, Michael and Bonacorsi, Daniele and Himmel, Alexander and Aurisano, Adam and Terao, Kazuhiro and Wongjirad, Taritree},
  journal={Nature},
  volume={560},
  number={7716},
  pages={41--48},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{carleo2019machine,
  title={Machine learning and the physical sciences},
  author={Carleo, Giuseppe and Cirac, Ignacio and Cranmer, Kyle and Daudet, Laurent and Schuld, Maria and Tishby, Naftali and Vogt-Maranto, Leslie and Zdeborov{\'a}, Lenka},
  journal={Reviews of Modern Physics},
  volume={91},
  number={4},
  pages={045002},
  year={2019},
  publisher={APS}
}

@article{mullainathan2017machine,
  title={Machine learning: an applied econometric approach},
  author={Mullainathan, Sendhil and Spiess, Jann},
  journal={Journal of Economic Perspectives},
  volume={31},
  number={2},
  pages={87--106},
  year={2017}
}

@article{athey2019machine,
  title={Machine learning methods that economists should know about},
  author={Athey, Susan and Imbens, Guido W},
  journal={Annual Review of Economics},
  volume={11},
  pages={685--725},
  year={2019},
  publisher={Annual Reviews}
}

@article{athey2018impact,
  title={The impact of machine learning on economics},
  author={Athey, Susan and others},
  journal={The economics of artificial intelligence: An agenda},
  pages={507--547},
  year={2018},
  publisher={University of Chicago Press Chicago, IL}
}

@article{rajkomar2019machine,
  title={Machine learning in medicine},
  author={Rajkomar, Alvin and Dean, Jeffrey and Kohane, Isaac},
  journal={New England Journal of Medicine},
  volume={380},
  number={14},
  pages={1347--1358},
  year={2019},
  publisher={Mass Medical Soc}
}

@inproceedings{bhardwaj2017study,
  title={A study of machine learning in healthcare},
  author={Bhardwaj, Rohan and Nambiar, Ankita R and Dutta, Debojyoti},
  booktitle={2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC)},
  volume={2},
  pages={236--241},
  year={2017},
  organization={IEEE}
}

@article{van2021artificial,
  title={How artificial intelligence and machine learning can help healthcare systems respond to COVID-19},
  author={van der Schaar, Mihaela and Alaa, Ahmed M and Floto, Andres and Gimson, Alexander and Scholtes, Stefan and Wood, Angela and McKinney, Eoin and Jarrett, Daniel and Lio, Pietro and Ercole, Ari},
  journal={Machine Learning},
  volume={110},
  number={1},
  pages={1--14},
  year={2021},
  publisher={Springer}
}

@inproceedings{berrevoets2021learning,
  title={Learning Queueing Policies for Organ Transplantation Allocation using Interpretable Counterfactual Survival Analysis},
  author={Berrevoets, Jeroen and Alaa, Ahmed and Qian, Zhaozhi and Jordon, James and Gimson, Alexander ES and Van Der Schaar, Mihaela},
  booktitle={International Conference on Machine Learning},
  pages={792--802},
  year={2021},
  organization={PMLR}
}

@article{berrevoets2020organite,
  title={OrganITE: Optimal transplant donor organ offering using an individual treatment effect},
  author={Berrevoets, Jeroen and Jordon, James and Bica, Ioana and van der Schaar, Mihaela and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={20037--20050},
  year={2020}
}


@InProceedings{pathak2019,
  title = 	 {Self-Supervised Exploration via Disagreement},
  author =       {Pathak, Deepak and Gandhi, Dhiraj and Gupta, Abhinav},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {5062--5071},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/pathak19a/pathak19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/pathak19a.html},
  abstract = 	 {Efficient exploration is a long-standing problem in sensorimotor learning. Major advances have been demonstrated in noise-free, non-stochastic domains such as video games and simulation. However, most of these formulations either get stuck in environments with stochastic dynamics or are too inefficient to be scalable to real robotics setups. In this paper, we propose a formulation for exploration inspired by the work in active learning literature. Specifically, we train an ensemble of dynamics models and incentivize the agent to explore such that the disagreement of those ensembles is maximized. This allows the agent to learn skills by exploring in a self-supervised manner without any external reward. Notably, we further leverage the disagreement objective to optimize the agent’s policy in a differentiable manner, without using reinforcement learning, which results in a sample-efficient exploration. We demonstrate the efficacy of this formulation across a variety of benchmark environments including stochastic-Atari, Mujoco and Unity. Finally, we implement our differentiable exploration on a real robot which learns to interact with objects completely from scratch. Project videos and code are at https://pathak22.github.io/exploration-by-disagreement/}
}



@article{tank2018neural,
  title={Neural granger causality},
  author={Tank, Alex and Covert, Ian and Foti, Nicholas and Shojaie, Ali and Fox, Emily},
  journal={arXiv preprint arXiv:1802.05842},
  year={2018}
}

@inproceedings{johnson2016,
 author = {Johnson, Matthew J and Duvenaud, David K and Wiltschko, Alex and Adams, Ryan P and Datta, Sandeep R},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Composing graphical models with neural networks for structured representations and fast inference},
 url = {https://proceedings.neurips.cc/paper/2016/file/7d6044e95a16761171b130dcb476a43e-Paper.pdf},
 volume = {29},
 year = {2016}
}

@article{kaiser2021unsuitability,
  title={Unsuitability of NOTEARS for Causal Graph Discovery},
  author={Kaiser, Marcus and Sipos, Maksim},
  journal={arXiv preprint arXiv:2104.05441},
  year={2021}
}

@book{koller2009probabilistic,
  title={Probabilistic graphical models: principles and techniques},
  author={Koller, Daphne and Friedman, Nir},
  year={2009},
  publisher={MIT press}
}

@article{barabasi1999emergence,
  title={Emergence of scaling in random networks},
  author={Barab{\'a}si, Albert-L{\'a}szl{\'o} and Albert, R{\'e}ka},
  journal={science},
  volume={286},
  number={5439},
  pages={509--512},
  year={1999},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{notears_sparsity2020,
 author = {Ng, Ignavier and Ghassami, AmirEmad and Zhang, Kun},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {17943--17954},
 publisher = {Curran Associates, Inc.},
 title = {On the Role of Sparsity and DAG Constraints for Learning Linear DAGs},
 url = {https://proceedings.neurips.cc/paper/2020/file/d04d42cdf14579cd294e5079e0745411-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{de2006scoring,
  title={A scoring function for learning Bayesian networks based on mutual information and conditional independence tests.},
  author={De Campos, Luis M and Friedman, Nir},
  journal={Journal of Machine Learning Research},
  volume={7},
  number={10},
  year={2006}
}

@book{spirtes2000causation,
  title={Causation, prediction, and search},
  author={Spirtes, Peter and Glymour, Clark N and Scheines, Richard and Heckerman, David},
  year={2000},
  publisher={MIT press}
}

@article{zhang2008detection,
  title={Detection of unfaithfulness and robust causal inference},
  author={Zhang, Jiji and Spirtes, Peter},
  journal={Minds and Machines},
  volume={18},
  number={2},
  pages={239--271},
  year={2008},
  publisher={Springer}
}

@article{chen2021multi,
  title={Multi-task Learning of Order-Consistent Causal Graphs},
  author={Chen, Xinshi and Sun, Haoran and Ellington, Caleb and Xing, Eric and Song, Le},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={11083--11095},
  year={2021}
}

@inproceedings{
Lachapelle2020Gradient,
title={Gradient-Based Neural DAG Learning},
author={Sébastien Lachapelle and Philippe Brouillard and Tristan Deleu and Simon Lacoste-Julien},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rklbKA4YDS}
}

@article{smith1989influence,
  title={Influence diagrams for statistical modeling},
  author={Smith, JQ},
  journal={The Annals of Statistics},
  volume={1},
  year={1989}
}

@article{pearl1986fusion,
  title={Fusion, propagation, and structuring in belief networks},
  author={Pearl, Judea},
  journal={Artificial intelligence},
  volume={29},
  number={3},
  pages={241--288},
  year={1986},
  publisher={Elsevier}
}

@article{howard1984principles,
  title={The principles and applications of decision analysis},
  author={Howard, Ronald A and Matheson, James E},
  journal={Strategic Decisions Group, Palo Alto, CA},
  pages={719--762},
  year={1984}
}

@inproceedings{chickering1995learning,
  title={Learning Bayesian networks: Search methods and experimental results},
  author={Chickering, Max and Geiger, Dan and Heckerman, David},
  booktitle={Proceedings of the fifth international workshop on artificial intelligence and statistics},
  year={1995}
}

@article{zhang2019d,
  title={D-vae: A variational autoencoder for directed acyclic graphs},
  author={Zhang, Muhan and Jiang, Shali and Cui, Zhicheng and Garnett, Roman and Chen, Yixin},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}



@article{khemakhem2020ice,
  title={Ice-beem: Identifiable conditional energy-based deep models based on nonlinear ica},
  author={Khemakhem, Ilyes and Monti, Ricardo and Kingma, Diederik and Hyvarinen, Aapo},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12768--12778},
  year={2020}
}

@inproceedings{khemakhem2020variational,
  title={Variational autoencoders and nonlinear ica: A unifying framework},
  author={Khemakhem, Ilyes and Kingma, Diederik and Monti, Ricardo and Hyvarinen, Aapo},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2207--2217},
  year={2020},
  organization={PMLR}
}

@article{keller2021topographic,
  title={Topographic vaes learn equivariant capsules},
  author={Keller, Thomas and Welling, Max},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{lowe2020amortized,
  title={Amortized causal discovery: Learning to infer causal graphs from time-series data},
  author={L{\"o}we, Sindy and Madras, David and Zemel, Richard and Welling, Max},
  journal={arXiv preprint arXiv:2006.10833},
  year={2020}
}



@inproceedings{zhang2021identifiable,
  title={Identifiable Energy-based Representations: An Application to Estimating Heterogeneous Causal Effects},
  author={Zhang, Yao and Berrevoets, Jeroen and Van Der Schaar, Mihaela},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4158--4177},
  year={2022},
  organization={PMLR}
}


@InProceedings{yu19a,
  title = 	 {{DAG}-{GNN}: {DAG} Structure Learning with Graph Neural Networks},
  author =       {Yu, Yue and Chen, Jie and Gao, Tian and Yu, Mo},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {7154--7163},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/yu19a/yu19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/yu19a.html},
  abstract = 	 {Learning a faithful directed acyclic graph (DAG) from samples of a joint distribution is a challenging combinatorial problem, owing to the intractable search space superexponential in the number of graph nodes. A recent breakthrough formulates the problem as a continuous optimization with a structural constraint that ensures acyclicity (Zheng et al., 2018). The authors apply the approach to the linear structural equation model (SEM) and the least-squares loss function that are statistically well justified but nevertheless limited. Motivated by the widespread success of deep learning that is capable of capturing complex nonlinear mappings, in this work we propose a deep generative model and apply a variant of the structural constraint to learn the DAG. At the heart of the generative model is a variational autoencoder parameterized by a novel graph neural network architecture, which we coin DAG-GNN. In addition to the richer capacity, an advantage of the proposed model is that it naturally handles discrete variables as well as vector-valued ones. We demonstrate that on synthetic data sets, the proposed method learns more accurate graphs for nonlinearly generated samples; and on benchmark data sets with discrete variables, the learned graphs are reasonably close to the global optima. The code is available at \url{https://github.com/fishmoon1234/DAG-GNN}.}
}



@InProceedings{yu21a,
  title = 	 {DAGs with No Curl: An Efficient DAG Structure Learning Approach},
  author =       {Yu, Yue and Gao, Tian and Yin, Naiyu and Ji, Qiang},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {12156--12166},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/yu21a/yu21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/yu21a.html},
  abstract = 	 {Recently directed acyclic graph (DAG) structure learning is formulated as a constrained continuous optimization problem with continuous acyclicity constraints and was solved iteratively through subproblem optimization. To further improve efficiency, we propose a novel learning framework to model and learn the weighted adjacency matrices in the DAG space directly. Specifically, we first show that the set of weighted adjacency matrices of DAGs are equivalent to the set of weighted gradients of graph potential functions, and one may perform structure learning by searching in this equivalent set of DAGs. To instantiate this idea, we propose a new algorithm, DAG-NoCurl, which solves the optimization problem efficiently with a two-step procedure: $1)$ first we find an initial non-acyclic solution to the optimization problem, and $2)$ then we employ the Hodge decomposition of graphs and learn an acyclic graph by projecting the non-acyclic graph to the gradient of a potential function. Experimental studies on benchmark datasets demonstrate that our method provides comparable accuracy but better efficiency than baseline DAG structure learning methods on both linear and generalized structural equation models, often by more than one order of magnitude.}
}

