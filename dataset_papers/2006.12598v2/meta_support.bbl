\begin{thebibliography}{40}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Boyd et~al.(2004)Boyd, Boyd, and Vandenberghe]{boyd2004convex}
Stephen Boyd, Stephen~P Boyd, and Lieven Vandenberghe.
\newblock \emph{Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem[Buldygin and Kozachenko(1980)]{buldygin1980sub}
Valerii~V Buldygin and Yu~V Kozachenko.
\newblock Sub-gaussian random variables.
\newblock \emph{Ukrainian Mathematical Journal}, 32\penalty0 (6):\penalty0
  483--489, 1980.

\bibitem[Buldygin and Kozachenko(2000)]{buldygin2000metric}
Valeri{\u\i}~Vladimirovich Buldygin and IU~V Kozachenko.
\newblock \emph{Metric characterization of random variables and random
  processes}, volume 188.
\newblock American Mathematical Soc., 2000.

\bibitem[Cai et~al.(2011)Cai, Liu, and Luo]{cai2011constrained}
Tony Cai, Weidong Liu, and Xi~Luo.
\newblock A constrained $\ell_1$ minimization approach to sparse precision
  matrix estimation.
\newblock \emph{Journal of the American Statistical Association}, 106\penalty0
  (494):\penalty0 594--607, 2011.

\bibitem[Chen et~al.(2013)Chen, Xu, Wu, et~al.]{chen2013covariance}
Xiaohui Chen, Mengyu Xu, Wei~Biao Wu, et~al.
\newblock Covariance and precision matrix estimation for high-dimensional time
  series.
\newblock \emph{Annals of Statistics}, 41\penalty0 (6):\penalty0 2994--3021,
  2013.

\bibitem[Chiquet et~al.(2011)Chiquet, Grandvalet, and
  Ambroise]{chiquet2011inferring}
Julien Chiquet, Yves Grandvalet, and Christophe Ambroise.
\newblock Inferring multiple graphical structures.
\newblock \emph{Statistics and Computing}, 21\penalty0 (4):\penalty0 537--553,
  2011.

\bibitem[{El Ghaoui}(2002)]{ELGHAOUI2002171}
Laurent {El Ghaoui}.
\newblock Inversion error, condition number, and approximate inverses of
  uncertain matrices.
\newblock \emph{Linear Algebra and its Applications}, 343-344:\penalty0
  171--193, 2002.
\newblock ISSN 0024-3795.
\newblock \doi{https://doi.org/10.1016/S0024-3795(01)00273-7}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S0024379501002737}.
\newblock Special Issue on Structured and Infinite Systems of Linear equations.

\bibitem[Fan et~al.(2016)Fan, Liao, and Liu]{fan2016overview}
Jianqing Fan, Yuan Liao, and Han Liu.
\newblock An overview of the estimation of large covariance and precision
  matrices.
\newblock \emph{The Econometrics Journal}, 19\penalty0 (1):\penalty0 C1--C32,
  2016.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 1126--1135. JMLR. org, 2017.

\bibitem[Friedman et~al.(2008)Friedman, Hastie, and
  Tibshirani]{friedman2008sparse}
Jerome Friedman, Trevor Hastie, and Robert Tibshirani.
\newblock Sparse inverse covariance estimation with the graphical lasso.
\newblock \emph{Biostatistics}, 9\penalty0 (3):\penalty0 432--441, 2008.

\bibitem[Ghoshal and Honorio(2017)]{ghoshal2017information}
Asish Ghoshal and Jean Honorio.
\newblock Information-theoretic limits of bayesian network structure learning.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 767--775.
  PMLR, 2017.

\bibitem[Golub and Van~Loan(2012)]{golub2012matrix}
Gene~H Golub and Charles~F Van~Loan.
\newblock \emph{Matrix computations}, volume~3.
\newblock JHU press, 2012.

\bibitem[Guo et~al.(2011)Guo, Levina, Michailidis, and Zhu]{guo2011joint}
Jian Guo, Elizaveta Levina, George Michailidis, and Ji~Zhu.
\newblock Joint estimation of multiple graphical models.
\newblock \emph{Biometrika}, 98\penalty0 (1):\penalty0 1--15, 2011.

\bibitem[Honorio and Samaras(2010)]{Honorio10b}
J.~Honorio and D.~Samaras.
\newblock Multi-task learning of \uppercase{G}aussian graphical models.
\newblock \emph{International Conference on Machine Learning}, pages 447--454,
  2010.

\bibitem[Honorio et~al.(2012)Honorio, Jaakkola, and
  Samaras]{honorio2012statistical}
Jean Honorio, Tommi Jaakkola, and Dimitris Samaras.
\newblock On the statistical efficiency of $\ell_{1,p}$ multi-task learning of
  gaussian graphical models.
\newblock \emph{arXiv preprint arXiv:1207.4255}, 2012.

\bibitem[Horn and Johnson(2012)]{horn2012matrix}
Roger~A Horn and Charles~R Johnson.
\newblock \emph{Matrix analysis}.
\newblock Cambridge university press, 2012.

\bibitem[Horn et~al.(1994)Horn, Horn, and Johnson]{horn1994topics}
Roger~A Horn, Roger~A Horn, and Charles~R Johnson.
\newblock \emph{Topics in matrix analysis}.
\newblock Cambridge university press, 1994.

\bibitem[Hsieh et~al.(2012)Hsieh, Banerjee, Dhillon, and
  Ravikumar]{hsieh2012divide}
Cho-Jui Hsieh, Arindam Banerjee, Inderjit~S Dhillon, and Pradeep~K Ravikumar.
\newblock A divide-and-conquer method for sparse inverse covariance estimation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2330--2338, 2012.

\bibitem[Hsieh et~al.(2013)Hsieh, Sustik, Dhillon, Ravikumar, and
  Poldrack]{hsieh2013big}
Cho-Jui Hsieh, M{\'a}ty{\'a}s~A Sustik, Inderjit~S Dhillon, Pradeep~K
  Ravikumar, and Russell Poldrack.
\newblock Big \& quic: Sparse inverse covariance estimation for a million
  variables.
\newblock In \emph{Advances in neural information processing systems}, pages
  3165--3173, 2013.

\bibitem[Johnson et~al.(2012)Johnson, Jalali, and Ravikumar]{johnson2012high}
Christopher Johnson, Ali Jalali, and Pradeep Ravikumar.
\newblock High-dimensional sparse inverse covariance estimation using greedy
  methods.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 574--582,
  2012.

\bibitem[Johnstone(2001)]{johnstone2001distribution}
Iain~M Johnstone.
\newblock On the distribution of the largest eigenvalue in principal components
  analysis.
\newblock \emph{Annals of statistics}, pages 295--327, 2001.

\bibitem[Koch et~al.(2015)Koch, Zemel, and Salakhutdinov]{koch2015siamese}
Gregory Koch, Richard Zemel, and Ruslan Salakhutdinov.
\newblock Siamese neural networks for one-shot image recognition.
\newblock In \emph{ICML deep learning workshop}, volume~2. Lille, 2015.

\bibitem[Kouno et~al.(2013)Kouno, de~Hoon, Mar, Tomaru, Kawano, Carninci,
  Suzuki, Hayashizaki, and Shin]{kouno2013temporal}
Tsukasa Kouno, Michiel de~Hoon, Jessica~C Mar, Yasuhiro Tomaru, Mitsuoki
  Kawano, Piero Carninci, Harukazu Suzuki, Yoshihide Hayashizaki, and Jay~W
  Shin.
\newblock Temporal dynamics and transcriptional control using single-cell gene
  expression analysis.
\newblock \emph{Genome biology}, 14\penalty0 (10):\penalty0 1--12, 2013.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and Tenenbaum]{lake2015human}
Brenden~M Lake, Ruslan Salakhutdinov, and Joshua~B Tenenbaum.
\newblock Human-level concept learning through probabilistic program induction.
\newblock \emph{Science}, 350\penalty0 (6266):\penalty0 1332--1338, 2015.

\bibitem[Ma and Michailidis(2016)]{ma2016joint}
Jing Ma and George Michailidis.
\newblock Joint structural estimation of multiple graphical models.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 5777--5824, 2016.

\bibitem[Marshall et~al.(2010)Marshall, Olkin, and Arnold]{marshall2010matrix}
Albert~W Marshall, Ingram Olkin, and Barry~C Arnold.
\newblock Matrix theory.
\newblock In \emph{Inequalities: Theory of Majorization and Its Applications},
  pages 297--365. Springer, 2010.

\bibitem[Meinshausen et~al.(2006)Meinshausen, B{\"u}hlmann,
  et~al.]{meinshausen2006high}
Nicolai Meinshausen, Peter B{\"u}hlmann, et~al.
\newblock High-dimensional graphs and variable selection with the lasso.
\newblock \emph{Annals of statistics}, 34\penalty0 (3):\penalty0 1436--1462,
  2006.

\bibitem[Mohan et~al.(2014)Mohan, Palma~London, Witten, and Lee]{mohan2014node}
Karthik Mohan, Maryam~Fazel Palma~London, Daniela Witten, and Su-In Lee.
\newblock Node-based learning of multiple gaussian graphical models.
\newblock \emph{Journal of machine learning research: JMLR}, 15\penalty0
  (1):\penalty0 445, 2014.

\bibitem[Munkhdalai and Yu(2017)]{munkhdalai2017meta}
Tsendsuren Munkhdalai and Hong Yu.
\newblock Meta networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 2554--2563. JMLR. org, 2017.

\bibitem[Ortega and Rheinboldt(2000)]{ortega2000iterative}
James~M Ortega and Werner~C Rheinboldt.
\newblock \emph{Iterative solution of nonlinear equations in several
  variables}.
\newblock SIAM, 2000.

\bibitem[Ravikumar et~al.(2011)Ravikumar, Wainwright, Raskutti, Yu,
  et~al.]{ravikumar2011high}
Pradeep Ravikumar, Martin~J Wainwright, Garvesh Raskutti, Bin Yu, et~al.
\newblock High-dimensional covariance estimation by minimizing
  $\ell_1$-penalized log-determinant divergence.
\newblock \emph{Electronic Journal of Statistics}, 5:\penalty0 935--980, 2011.

\bibitem[Santoro et~al.(2016)Santoro, Bartunov, Botvinick, Wierstra, and
  Lillicrap]{santoro2016meta}
Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy
  Lillicrap.
\newblock Meta-learning with memory-augmented neural networks.
\newblock In \emph{International conference on machine learning}, pages
  1842--1850, 2016.

\bibitem[Sung et~al.(2018)Sung, Yang, Zhang, Xiang, Torr, and
  Hospedales]{sung2018learning}
Flood Sung, Yongxin Yang, Li~Zhang, Tao Xiang, Philip~HS Torr, and Timothy~M
  Hospedales.
\newblock Learning to compare: Relation network for few-shot learning.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 1199--1208, 2018.

\bibitem[Tropp(2011)]{Tropp2011}
Joel~A. Tropp.
\newblock User-friendly tail bounds for sums of random matrices.
\newblock \emph{Foundations of Computational Mathematics}, 12\penalty0
  (4):\penalty0 389–434, Aug 2011.
\newblock ISSN 1615-3383.
\newblock \doi{10.1007/s10208-011-9099-z}.
\newblock URL \url{http://dx.doi.org/10.1007/s10208-011-9099-z}.

\bibitem[Vanschoren(2019)]{Vanschoren19}
J.~Vanschoren.
\newblock Meta-learning: A survey.
\newblock \emph{The Springer Series on Challenges in Machine Learning:
  Automated Machine Learning}, pages 35--61|, 2019.

\bibitem[Varoquaux et~al.(2010)Varoquaux, Gramfort, Poline, and
  Thirion]{Varoquaux10}
G.~Varoquaux, A.~Gramfort, J.~Poline, and B.~Thirion.
\newblock Brain covariance selection: Better individual functional connectivity
  models using population prior.
\newblock \emph{Neural Information Processing Systems}, 23:\penalty0
  2334--2342, 2010.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Wierstra,
  et~al.]{vinyals2016matching}
Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et~al.
\newblock Matching networks for one shot learning.
\newblock In \emph{Advances in neural information processing systems}, pages
  3630--3638, 2016.

\bibitem[Wang et~al.(2016)Wang, Ren, and Gu]{wang2016precision}
Lingxiao Wang, Xiang Ren, and Quanquan Gu.
\newblock Precision matrix estimation in high dimensional gaussian graphical
  models with faster rates.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 177--185.
  PMLR, 2016.

\bibitem[Weiss et~al.(2005)Weiss, Holmes, and Hardy]{weiss2005course}
N.A. Weiss, P.T. Holmes, and M.~Hardy.
\newblock \emph{A Course in Probability}.
\newblock Pearson Addison Wesley, 2005.
\newblock ISBN 9780321189547.
\newblock URL \url{https://books.google.com/books?id=p-rwJAAACAAJ}.

\bibitem[Yuan and Lin(2007)]{yuan2007model}
Ming Yuan and Yi~Lin.
\newblock Model selection and estimation in the gaussian graphical model.
\newblock \emph{Biometrika}, 94\penalty0 (1):\penalty0 19--35, 2007.

\end{thebibliography}
