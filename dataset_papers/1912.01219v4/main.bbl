\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ar{\i}k et~al.(2017{\natexlab{a}})Ar{\i}k, Chrzanowski, Coates,
  Diamos, Gibiansky, Kang, Li, Miller, Raiman, Sengupta, and
  Shoeybi]{arik2017DV1}
Ar{\i}k, S.~O., Chrzanowski, M., Coates, A., Diamos, G., Gibiansky, A., Kang,
  Y., Li, X., Miller, J., Raiman, J., Sengupta, S., and Shoeybi, M.
\newblock Deep {V}oice: Real-time neural text-to-speech.
\newblock In \emph{ICML}, 2017{\natexlab{a}}.

\bibitem[Ar{\i}k et~al.(2017{\natexlab{b}})Ar{\i}k, Diamos, Gibiansky, Miller,
  Peng, Ping, Raiman, and Zhou]{arik2017DV2}
Ar{\i}k, S.~O., Diamos, G., Gibiansky, A., Miller, J., Peng, K., Ping, W.,
  Raiman, J., and Zhou, Y.
\newblock Deep {V}oice 2: Multi-speaker neural text-to-speech.
\newblock In \emph{NIPS}, 2017{\natexlab{b}}.

\bibitem[Berg et~al.(2018)Berg, Hasenclever, Tomczak, and
  Welling]{berg2018sylvester}
Berg, R. v.~d., Hasenclever, L., Tomczak, J.~M., and Welling, M.
\newblock Sylvester normalizing flows for variational inference.
\newblock \emph{arXiv preprint arXiv:1803.05649}, 2018.

\bibitem[Bi{\'n}kowski et~al.(2019)Bi{\'n}kowski, Donahue, Dieleman, Clark,
  Elsen, Casagrande, Cobo, and Simonyan]{binkowski2019high}
Bi{\'n}kowski, M., Donahue, J., Dieleman, S., Clark, A., Elsen, E., Casagrande,
  N., Cobo, L.~C., and Simonyan, K.
\newblock High fidelity speech synthesis with adversarial networks.
\newblock \emph{arXiv preprint arXiv:1909.11646}, 2019.

\bibitem[Brock et~al.(2018)Brock, Donahue, and Simonyan]{brock2018large}
Brock, A., Donahue, J., and Simonyan, K.
\newblock Large scale {GAN} training for high fidelity natural image synthesis.
\newblock \emph{arXiv preprint arXiv:1809.11096}, 2018.

\bibitem[Dieleman et~al.(2018)Dieleman, van~den Oord, and
  Simonyan]{dieleman2018challenge}
Dieleman, S., van~den Oord, A., and Simonyan, K.
\newblock The challenge of realistic music generation: modelling raw audio at
  scale.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Dinh et~al.(2014)Dinh, Krueger, and Bengio]{dinh2014nice}
Dinh, L., Krueger, D., and Bengio, Y.
\newblock {NICE}: Non-linear independent components estimation.
\newblock \emph{arXiv preprint arXiv:1410.8516}, 2014.

\bibitem[Dinh et~al.(2017)Dinh, Sohl-Dickstein, and Bengio]{dinh2016density}
Dinh, L., Sohl-Dickstein, J., and Bengio, S.
\newblock Density estimation using {R}eal {NVP}.
\newblock In \emph{ICLR}, 2017.

\bibitem[Donahue et~al.(2018)Donahue, McAuley, and
  Puckette]{donahue2018adversarial}
Donahue, C., McAuley, J., and Puckette, M.
\newblock Adversarial audio synthesis.
\newblock \emph{arXiv preprint arXiv:1802.04208}, 2018.

\bibitem[Ho et~al.(2019)Ho, Chen, Srinivas, Duan, and Abbeel]{ho2019flow++}
Ho, J., Chen, X., Srinivas, A., Duan, Y., and Abbeel, P.
\newblock Flow++: Improving flow-based generative models with variational
  dequantization and architecture design.
\newblock \emph{arXiv preprint arXiv:1902.00275}, 2019.

\bibitem[Hoogeboom et~al.(2019)Hoogeboom, Berg, and
  Welling]{hoogeboom2019emerging}
Hoogeboom, E., Berg, R. v.~d., and Welling, M.
\newblock Emerging convolutions for generative normalizing flows.
\newblock \emph{arXiv preprint arXiv:1901.11137}, 2019.

\bibitem[Huang et~al.(2018)Huang, Krueger, Lacoste, and
  Courville]{huang2018neural}
Huang, C.-W., Krueger, D., Lacoste, A., and Courville, A.
\newblock Neural autoregressive flows.
\newblock \emph{arXiv preprint arXiv:1804.00779}, 2018.

\bibitem[Ito(2017)]{Ito2017ljspeech}
Ito, K.
\newblock The {LJ} speech dataset.
\newblock 2017.

\bibitem[Kalchbrenner et~al.(2018)Kalchbrenner, Elsen, Simonyan, Noury,
  Casagrande, Lockhart, Stimberg, Oord, Dieleman, and
  Kavukcuoglu]{kalchbrenner2018efficient}
Kalchbrenner, N., Elsen, E., Simonyan, K., Noury, S., Casagrande, N., Lockhart,
  E., Stimberg, F., Oord, A. v.~d., Dieleman, S., and Kavukcuoglu, K.
\newblock Efficient neural audio synthesis.
\newblock In \emph{ICML}, 2018.

\bibitem[Kim et~al.(2019)Kim, Lee, Song, and Yoon]{kim2018flowavenet}
Kim, S., Lee, S.-g., Song, J., and Yoon, S.
\newblock Flo{W}ave{N}et: A generative flow for raw audio.
\newblock In \emph{ICML}, 2019.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{ICLR}, 2015.

\bibitem[Kingma \& Dhariwal(2018)Kingma and Dhariwal]{kingma2018glow}
Kingma, D.~P. and Dhariwal, P.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  10215--10224, 2018.

\bibitem[Kingma et~al.(2016)Kingma, Salimans, Jozefowicz, Chen, Sutskever, and
  Welling]{kingma2016improved}
Kingma, D.~P., Salimans, T., Jozefowicz, R., Chen, X., Sutskever, I., and
  Welling, M.
\newblock Improving variational inference with inverse autoregressive flow.
\newblock In \emph{NIPS}, 2016.

\bibitem[Kumar et~al.(2019)Kumar, Kumar, de~Boissiere, Gestin, Teoh, Sotelo,
  de~Br{\'e}bisson, Bengio, and Courville]{kumar2019melgan}
Kumar, K., Kumar, R., de~Boissiere, T., Gestin, L., Teoh, W.~Z., Sotelo, J.,
  de~Br{\'e}bisson, A., Bengio, Y., and Courville, A.~C.
\newblock Melgan: Generative adversarial networks for conditional waveform
  synthesis.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  14881--14892, 2019.

\bibitem[Li et~al.(2019)Li, Liu, Liu, Zhao, Liu, and Zhou]{li2019neural}
Li, N., Liu, S., Liu, Y., Zhao, S., Liu, M., and Zhou, M.
\newblock Neural speech synthesis with transformer network.
\newblock AAAI, 2019.

\bibitem[Mehri et~al.(2017)Mehri, Kumar, Gulrajani, Kumar, Jain, Sotelo,
  Courville, and Bengio]{mehri2016samplernn}
Mehri, S., Kumar, K., Gulrajani, I., Kumar, R., Jain, S., Sotelo, J.,
  Courville, A., and Bengio, Y.
\newblock Sample{RNN}: An unconditional end-to-end neural audio generation
  model.
\newblock In \emph{ICLR}, 2017.

\bibitem[Menick \& Kalchbrenner(2018)Menick and
  Kalchbrenner]{menick2018generating}
Menick, J. and Kalchbrenner, N.
\newblock Generating high fidelity images with subscale pixel networks and
  multidimensional upscaling.
\newblock \emph{arXiv preprint arXiv:1812.01608}, 2018.

\bibitem[Paine et~al.(2016)Paine, Khorrami, Chang, Zhang, Ramachandran,
  Hasegawa-Johnson, and Huang]{paine2016fast}
Paine, T.~L., Khorrami, P., Chang, S., Zhang, Y., Ramachandran, P.,
  Hasegawa-Johnson, M.~A., and Huang, T.~S.
\newblock Fast wavenet generation algorithm.
\newblock \emph{arXiv preprint arXiv:1611.09482}, 2016.

\bibitem[Papamakarios et~al.(2017)Papamakarios, Pavlakou, and
  Murray]{papamakarios2017masked}
Papamakarios, G., Pavlakou, T., and Murray, I.
\newblock Masked autoregressive flow for density estimation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2338--2347, 2017.

\bibitem[Peng et~al.(2019)Peng, Ping, Song, and Zhao]{peng2019parallel}
Peng, K., Ping, W., Song, Z., and Zhao, K.
\newblock Parallel neural text-to-speech.
\newblock \emph{arXiv preprint arXiv:1905.08459}, 2019.

\bibitem[Pharris(2018)]{nv-wavenet18}
Pharris, B.
\newblock N{V}-{W}ave{N}et: Better speech synthesis using gpu-enabled
  {W}ave{N}et inference.
\newblock In \emph{NVIDIA Developer Blog}, 2018.

\bibitem[Ping et~al.(2018)Ping, Peng, Gibiansky, Arik, Kannan, Narang, Raiman,
  and Miller]{ping2017deep}
Ping, W., Peng, K., Gibiansky, A., Arik, S.~O., Kannan, A., Narang, S., Raiman,
  J., and Miller, J.
\newblock Deep {V}oice 3: Scaling text-to-speech with convolutional sequence
  learning.
\newblock In \emph{ICLR}, 2018.

\bibitem[Ping et~al.(2019)Ping, Peng, and Chen]{ping2018clarinet}
Ping, W., Peng, K., and Chen, J.
\newblock Clari{N}et: Parallel wave generation in end-to-end text-to-speech.
\newblock In \emph{ICLR}, 2019.

\bibitem[Prenger et~al.(2019)Prenger, Valle, and
  Catanzaro]{prenger2019waveglow}
Prenger, R., Valle, R., and Catanzaro, B.
\newblock Wave{G}low: A flow-based generative network for speech synthesis.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 2019.

\bibitem[Radford et~al.(2015)Radford, Metz, and
  Chintala]{radford2015unsupervised}
Radford, A., Metz, L., and Chintala, S.
\newblock Unsupervised representation learning with deep convolutional
  generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1511.06434}, 2015.

\bibitem[Ren et~al.(2019)Ren, Ruan, Tan, Qin, Zhao, Zhao, and
  Liu]{ren2019fastspeech}
Ren, Y., Ruan, Y., Tan, X., Qin, T., Zhao, S., Zhao, Z., and Liu, T.-Y.
\newblock Fastspeech: Fast, robust and controllable text to speech.
\newblock \emph{arXiv preprint arXiv:1905.09263}, 2019.

\bibitem[Rezende \& Mohamed(2015)Rezende and Mohamed]{rezende2015variational}
Rezende, D.~J. and Mohamed, S.
\newblock Variational inference with normalizing flows.
\newblock In \emph{ICML}, 2015.

\bibitem[Ribeiro et~al.(2011)Ribeiro, Flor{\^e}ncio, Zhang, and
  Seltzer]{ribeiro2011crowdmos}
Ribeiro, F., Flor{\^e}ncio, D., Zhang, C., and Seltzer, M.
\newblock Crowd{MOS}: An approach for crowdsourcing mean opinion score studies.
\newblock In \emph{ICASSP}, 2011.

\bibitem[Salimans \& Kingma(2016)Salimans and Kingma]{salimans2016weight}
Salimans, T. and Kingma, D.~P.
\newblock Weight normalization: A simple reparameterization to accelerate
  training of deep neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  901--909, 2016.

\bibitem[Serr{\`a} et~al.(2019)Serr{\`a}, Pascual, and Segura]{serra2019blow}
Serr{\`a}, J., Pascual, S., and Segura, C.
\newblock Blow: a single-scale hyperconditioned flow for non-parallel raw-audio
  voice conversion.
\newblock \emph{arXiv preprint arXiv:1906.00794}, 2019.

\bibitem[Shen et~al.(2018)Shen, Pang, Weiss, Schuster, Jaitly, Yang, Chen,
  Zhang, Wang, Skerry-Ryan, et~al.]{shen2018tacotron2}
Shen, J., Pang, R., Weiss, R.~J., Schuster, M., Jaitly, N., Yang, Z., Chen, Z.,
  Zhang, Y., Wang, Y., Skerry-Ryan, R., et~al.
\newblock Natural {TTS} synthesis by conditioning {W}ave{N}et on mel
  spectrogram predictions.
\newblock In \emph{ICASSP}, 2018.

\bibitem[Sotelo et~al.(2017)Sotelo, Mehri, Kumar, Santos, Kastner, Courville,
  and Bengio]{sotelo2017char2wav}
Sotelo, J., Mehri, S., Kumar, K., Santos, J.~F., Kastner, K., Courville, A.,
  and Bengio, Y.
\newblock Char2wav: End-to-end speech synthesis.
\newblock \emph{ICLR workshop}, 2017.

\bibitem[Taigman et~al.(2018)Taigman, Wolf, Polyak, and
  Nachmani]{taigman2018voiceloop}
Taigman, Y., Wolf, L., Polyak, A., and Nachmani, E.
\newblock Voice{L}oop: Voice fitting and synthesis via a phonological loop.
\newblock In \emph{ICLR}, 2018.

\bibitem[Tran et~al.(2019)Tran, Vafa, Agrawal, Dinh, and
  Poole]{tran2019discrete}
Tran, D., Vafa, K., Agrawal, K.~K., Dinh, L., and Poole, B.
\newblock Discrete flows: Invertible generative models of discrete data.
\newblock \emph{arXiv preprint arXiv:1905.10347}, 2019.

\bibitem[van~den Oord et~al.(2016)van~den Oord, Dieleman, Zen, Simonyan,
  Vinyals, Graves, Kalchbrenner, Senior, and Kavukcuoglu]{oord2016wavenet}
van~den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A.,
  Kalchbrenner, N., Senior, A., and Kavukcuoglu, K.
\newblock Wave{N}et: A generative model for raw audio.
\newblock \emph{arXiv preprint arXiv:1609.03499}, 2016.

\bibitem[Van~den Oord et~al.(2016)Van~den Oord, Kalchbrenner, Espeholt,
  Vinyals, Graves, et~al.]{van2016conditional}
Van~den Oord, A., Kalchbrenner, N., Espeholt, L., Vinyals, O., Graves, A.,
  et~al.
\newblock Conditional image generation with pixelcnn decoders.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  4790--4798, 2016.

\bibitem[van~den Oord et~al.(2018)van~den Oord, Li, Babuschkin, Simonyan,
  Vinyals, Kavukcuoglu, Driessche, Lockhart, Cobo, Stimberg,
  et~al.]{oord2017parallel}
van~den Oord, A., Li, Y., Babuschkin, I., Simonyan, K., Vinyals, O.,
  Kavukcuoglu, K., Driessche, G. v.~d., Lockhart, E., Cobo, L.~C., Stimberg,
  F., et~al.
\newblock Parallel {W}ave{N}et: Fast high-fidelity speech synthesis.
\newblock In \emph{ICML}, 2018.

\bibitem[Wang et~al.(2019)Wang, Takaki, and Yamagishi]{wang2019neural}
Wang, X., Takaki, S., and Yamagishi, J.
\newblock Neural source-filter-based waveform model for statistical parametric
  speech synthesis.
\newblock In \emph{ICASSP 2019-2019 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  5916--5920. IEEE, 2019.

\bibitem[Wang et~al.(2017)Wang, Skerry-Ryan, Stanton, Wu, Weiss, Jaitly, Yang,
  Xiao, Chen, Bengio, Le, Agiomyrgiannakis, Clark, and
  Saurous]{wang2017tacotron}
Wang, Y., Skerry-Ryan, R., Stanton, D., Wu, Y., Weiss, R.~J., Jaitly, N., Yang,
  Z., Xiao, Y., Chen, Z., Bengio, S., Le, Q., Agiomyrgiannakis, Y., Clark, R.,
  and Saurous, R.~A.
\newblock Tacotron: Towards end-to-end speech synthesis.
\newblock In \emph{Interspeech}, 2017.

\bibitem[Yamamoto et~al.(2019{\natexlab{a}})Yamamoto, Song, and
  Kim]{yamamoto2019parallel}
Yamamoto, R., Song, E., and Kim, J.-M.
\newblock Parallel wavegan: A fast waveform generation model based on
  generative adversarial networks with multi-resolution spectrogram.
\newblock \emph{arXiv preprint arXiv:1910.11480}, 2019{\natexlab{a}}.

\bibitem[Yamamoto et~al.(2019{\natexlab{b}})Yamamoto, Song, and
  Kim]{yamamoto2019probability}
Yamamoto, R., Song, E., and Kim, J.-M.
\newblock Probability density distillation with generative adversarial networks
  for high-quality parallel waveform generation.
\newblock \emph{arXiv preprint arXiv:1904.04472}, 2019{\natexlab{b}}.

\bibitem[Yu \& Koltun(2015)Yu and Koltun]{yu2015multi}
Yu, F. and Koltun, V.
\newblock Multi-scale context aggregation by dilated convolutions.
\newblock \emph{arXiv preprint arXiv:1511.07122}, 2015.

\end{thebibliography}
