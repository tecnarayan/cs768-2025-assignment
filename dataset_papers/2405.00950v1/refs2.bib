@article{singh2018throughput,
  title={{Throughput Optimal Decentralized Scheduling of Multihop Networks with End-to-End Deadline Constraints: Unreliable Links}},
  author={Singh, Rahul and Kumar, PR},
  journal={IEEE Transactions on Automatic Control},
  volume={64},
  number={1},
  pages={127--142},
  year={2018},
  publisher={IEEE}
}

@article{duran2018asymptotic,
  title={Asymptotic optimal control of Markov-modulated restless bandits},
  author={Duran, Santiago and Verloop, Ina Maria},
  journal={Proceedings of the ACM on Measurement and Analysis of Computing Systems},
  volume={2},
  number={1},
  pages={1--25},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{liu2010indexability,
  title={Indexability of restless bandit problems and optimality of whittle index for dynamic multichannel access},
  author={Liu, Keqin and Zhao, Qing},
  journal={IEEE Transactions on Information Theory},
  volume={56},
  number={11},
  pages={5547--5567},
  year={2010},
  publisher={IEEE}
}

@article{cinlar1975introduction,
  title={Introduction to stochastic processes Prentice-Hall},
  author={Cinlar, Erhan},
  journal={Englewood Cliffs, New Jersey (420p)},
  year={1975}
}

@article{liu2010indexability,
  title={Indexability of restless bandit problems and optimality of whittle index for dynamic multichannel access},
  author={Liu, Keqin and Zhao, Qing},
  journal={IEEE Transactions on Information Theory},
  volume={56},
  number={11},
  pages={5547--5567},
  year={2010},
  publisher={IEEE}
}

@book{altman1999constrained,
  title={Constrained Markov decision processes},
  author={Altman, Eitan},
  volume={7},
  year={1999},
  publisher={CRC Press}
}

@book{puterman1994markov,
  title={{Markov Decision Processes: Discrete Stochastic Dynamic Programming}},
  author={Puterman, Martin L},
  year={1994},
  publisher={John Wiley \& Sons}
}

@book{powell2007approximate,
  title={{Approximate Dynamic Programming: Solving the curses of dimensionality}},
  author={Powell, Warren B},
  volume={703},
  year={2007},
  publisher={John Wiley \& Sons}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Offline RMAB%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{gast2010mean,
  title={A mean field model of work stealing in large-scale systems},
  author={Gast, Nicolas and Bruno, Gaujal},
  journal={ACM SIGMETRICS Performance Evaluation Review},
  volume={38},
  number={1},
  pages={13--24},
  year={2010},
  publisher={ACM New York, NY, USA}
}

@article{whittle1988restless,
  title={{Restless Bandits: Activity Allocation in A Changing World}},
  author={Whittle, Peter},
  journal={Journal of Applied Probability},
  pages={287--298},
  year={1988},
  publisher={JSTOR}
}

@article{weber1990index,
  title={{On An Index Policy for Restless Bandits}},
  author={Weber, Richard R and Weiss, Gideon},
  journal={Journal of Applied Probability},
  pages={637--648},
  year={1990},
  publisher={JSTOR}
}

@article{nino2001restless,
  title={{Restless Bandits, Partial Conservation Laws and Indexability}},
  author={Nino-Mora, Jose},
  journal={Advances in Applied Probability},
  pages={76--98},
  year={2001},
  publisher={JSTOR}
}

@article{bertsimas2000restless,
  title={{Restless Bandits, Linear Programming Relaxations, and A Primal-Dual Index Heuristic}},
  author={Bertsimas, Dimitris and Ni{\~n}o-Mora, Jos{\'e}},
  journal={Operations Research},
  volume={48},
  number={1},
  pages={80--90},
  year={2000},
  publisher={INFORMS}
}

@article{verloop2016asymptotically,
  title={{Asymptotically Optimal Priority Policies for Indexable and Nonindexable Restless Bandits}},
  author={Verloop, Ina Maria},
  journal={The Annals of Applied Probability},
  volume={26},
  number={4},
  pages={1947--1995},
  year={2016},
  publisher={Institute of Mathematical Statistics}
}

@article{nino2007dynamic,
  title={{Dynamic Priority Allocation via Restless Bandit Marginal Productivity Indices}},
  author={Ni{\~n}o-Mora, Jos{\'e}},
  journal={Top},
  volume={15},
  number={2},
  pages={161--198},
  year={2007},
  publisher={Springer}
}

@article{jacko2010restless,
  title={{Restless Bandits Approach to the Job Scheduling Problem and Its Extensions}},
  author={Jacko, Peter},
  journal={Modern trends in controlled stochastic processes: theory and applications},
  pages={248--267},
  year={2010},
  publisher={Luniver Press United Kingdom}
}

@article{sheng2014data,
  title={{Data-Driven Channel Modeling Using Spectrum Measurement}},
  author={Sheng, Shang-Pin and Liu, Mingyan and Saigal, Romesh},
  journal={IEEE Transactions on Mobile Computing},
  volume={14},
  number={9},
  pages={1794--1805},
  year={2014},
  publisher={IEEE}
}

@incollection{mahajan2008multi,
  title={{Multi-Armed Bandit Problems}},
  author={Mahajan, Aditya and Teneketzis, Demosthenis},
  booktitle={Foundations and applications of sensor management},
  pages={121--151},
  year={2008},
  publisher={Springer}
}

@article{ahmad2009optimality,
  title={{Optimality of Myopic Sensing in Multichannel Opportunistic Access}},
  author={Ahmad, Sahand Haji Ali and Liu, Mingyan and Javidi, Tara and Zhao, Qing and Krishnamachari, Bhaskar},
  journal={IEEE Transactions on Information Theory},
  volume={55},
  number={9},
  pages={4040--4050},
  year={2009},
  publisher={IEEE}
}

@article{lee2019optimal,
  title={{Optimal Screening for Hepatocellular Carcinoma: A Restless Bandit Model}},
  author={Lee, Elliot and Lavieri, Mariel S and Volk, Michael},
  journal={Manufacturing \& Service Operations Management},
  volume={21},
  number={1},
  pages={198--212},
  year={2019},
  publisher={INFORMS}
}

@article{deo2013improving,
  title={{Improving Health Outcomes Through Better Capacity Allocation in A Community-based Chronic Care Model}},
  author={Deo, Sarang and Iravani, Seyed and Jiang, Tingting and Smilowitz, Karen and Samuelson, Stephen},
  journal={Operations Research},
  volume={61},
  number={6},
  pages={1277--1294},
  year={2013},
  publisher={INFORMS}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Online RMAB%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{tekin2012online,
  title={{Online Learning of Rested and Restless Bandits}},
  author={Tekin, Cem and Liu, Mingyan},
  journal={IEEE Transactions on Information Theory},
  volume={58},
  number={8},
  pages={5588--5611},
  year={2012},
  publisher={IEEE}
}

@inproceedings{dai2011non,
  title={{The Non-Bayesian Restless Multi-Armed Bandit: A Case of Near-Logarithmic Regret}},
  author={Dai, Wenhan and Gai, Yi and Krishnamachari, Bhaskar and Zhao, Qing},
  booktitle={Proc. of IEEE ICASSP},
  year={2011}
}

@article{jung2019regret,
  title={{Regret Bounds for Thompson Sampling in Episodic Restless Bandit Problems}},
  author={Jung, Young Hun and Tewari, Ambuj},
  journal={Proc. of  NeurIPS},
  year={2019}
}

@article{jung2019thompson,
  title={{Thompson Sampling in Non-Episodic Restless Bandits}},
  author={Jung, Young Hun and Abeille, Marc and Tewari, Ambuj},
  journal={arXiv preprint arXiv:1910.05654},
  year={2019}
}

@inproceedings{liu2011logarithmic,
  title={{Logarithmic Weak Regret of Non-Bayesian Restless Multi-Armed Bandit}},
  author={Liu, Haoyang and Liu, Keqin and Zhao, Qing},
  booktitle={Proc of IEEE ICASSP},
  year={2011}
}

@inproceedings{ortner2012regret,
  title={{Regret Bounds for Restless Markov Bandits}},
  author={Ortner, Ronald and Ryabko, Daniil and Auer, Peter and Munos, R{\'e}mi},
  booktitle={Proc. of Algorithmic Learning Theory},
  year={2012}
}


@inproceedings{wang2020restless,
  title={{Restless-UCB, an Efficient and Low-complexity Algorithm for Online Restless Bandits}},
  author={Wang, Siwei and Huang, Longbo and Lui, John},
  booktitle={Proc. of  NeurIPS},
  year={2020}
}


@article{liu2012learning,
  title={{Learning in A Changing World: Restless Multi-Armed Bandit with Unknown Dynamics}},
  author={Liu, Haoyang and Liu, Keqin and Zhao, Qing},
  journal={IEEE Transactions on Information Theory},
  volume={59},
  number={3},
  pages={1902--1916},
  year={2012},
  publisher={IEEE}
}

@inproceedings{tekin2011adaptive,
  title={{Adaptive Learning of Uncontrolled Restless Bandits with Logarithmic Regret}},
  author={Tekin, Cem and Liu, Mingyan},
  booktitle={Proc. of Allerton},
  year={2011}
}

@inproceedings{mate2021risk,
  title={{Risk-Aware Interventions in Public Health: Planning with Restless Multi-Armed Bandits}},
  author={Mate, Aditya and Perrault, Andrew and Tambe, Milind},
  booktitle={Proc.of AAMAS},
  year={2021}
}

@inproceedings{killian2021beyond,
  title={{Beyond" To Act or Not to Act": Fast Lagrangian Approaches to General Multi-Action Restless Bandits}},
  author={Killian, Jackson A and Perrault, Andrew and Tambe, Milind},
  booktitle={Proc.of AAMAS},
  year={2021}
}

@incollection{hoeffding1994probability,
  title={{Probability Inequalities for Sums of Bounded Random Variables}},
  author={Hoeffding, Wassily},
  booktitle={The Collected Works of Wassily Hoeffding},
  pages={409--426},
  year={1994},
  publisher={Springer}
}

@article{yu2018deadline,
  title={{Deadline Scheduling as Restless Bandits}},
  author={Yu, Zhe and Xu, Yunjian and Tong, Lang},
  journal={IEEE Transactions on Automatic Control},
  volume={63},
  number={8},
  pages={2343--2358},
  year={2018},
  publisher={IEEE}
}



@article{glazebrook2011general,
  title={General notions of indexability for queueing control and asset management},
  author={Glazebrook, Kevin D and Hodge, David J and Kirkbride, Chris},
  journal={The Annals of Applied Probability},
  volume={21},
  number={3},
  pages={876--907},
  year={2011},
  publisher={Institute of Mathematical Statistics}
}

@article{nguyen2016capture,
  title={Capture: A new predictive anti-poaching tool for wildlife protection},
  author={Nguyen, Thanh H and Sinha, Arunesh and Gholami, Shahrzad and Plumptre, Andrew and Joppa, Lucas and Tambe, Milind and Driciru, Margaret and Wanyama, Fred and Rwetsiba, Aggrey and Critchlow, Rob},
  year={2016}
}

@article{gittins1974dynamic,
  title={{A Dynamic Allocation Index for the Sequential Design of Experiments}},
  author={Gittins, John},
  journal={Progress in Statistics},
  pages={241--266},
  year={1974},
  publisher={North Holland}
}

@inproceedings{papadimitriou1994complexity,
  title={{The Complexity of Optimal Queueing Network Control}},
  author={Papadimitriou, Christos H and Tsitsiklis, John N},
  booktitle={Proc. of IEEE Conference on Structure in Complexity Theory},
  year={1994}
}



@article{hu2017asymptotically,
  title={{An Asymptotically Optimal Index Policy for Finite-Horizon Restless Bandits}},
  author={Hu, Weici and Frazier, Peter},
  journal={arXiv preprint arXiv:1707.00205},
  year={2017}
}

@article{zayas2019asymptotically,
  title={{An Asymptotically Optimal Heuristic for General Nonstationary Finite-Horizon Restless Multi-Armed, Multi-Action Bandits}},
  author={Zayas-Cab{\'a}n, Gabriel and Jasin, Stefanus and Wang, Guihua},
  journal={Advances in Applied Probability},
  volume={51},
  number={3},
  pages={745--772},
  year={2019},
  publisher={Cambridge University Press}
}

@article{brown2020index,
  title={{Index Policies and Performance Bounds for Dynamic Selection Problems}},
  author={Brown, David B and Smith, James E},
  journal={Management Science},
  volume={66},
  number={7},
  pages={3029--3050},
  year={2020},
  publisher={INFORMS}
}

@inproceedings{xiong2022reinforcement,
  title={Reinforcement Learning Augmented Asymptotically Optimal Index Policy for Finite-Horizon Restless Bandits},
  author={Xiong, Guojun and Li, Jian and Singh, Rahul},
 booktitle={Proc. of AAAI},
  year={2022}
}

@article{xiong2021learning,
  title={{Learning Augmented Index Policy for Optimal Service Placement at the Network Edge}},
  author={Xiong, Guojun and Singh, Rahul and Li, Jian},
  journal={arXiv preprint arXiv:2101.03641},
  year={2021}
}

@article{hodge2011dynamic,
  title={{Dynamic Resource Allocation In A Multi-Product Make-to-Stock Production System}},
  author={Hodge, DJ and Glazebrook, Kevin D},
  journal={Queueing Systems},
  volume={67},
  number={4},
  pages={333--364},
  year={2011},
  publisher={Springer}
}

@book{shiryaev2007optimal,
  title={{Optimal Stopping Rules}},
  author={Shiryaev, Albert N},
  volume={8},
  year={2007},
  publisher={Springer Science \& Business Media}
}

@article{maurer2009empirical,
  title={{Empirical Bernstein Bounds and Sample Variance Penalization}},
  author={Maurer, Andreas and Pontil, Massimiliano},
  journal={arXiv preprint arXiv:0907.3740},
  year={2009}
}

@book{bellmanbook,
author = {Bellman, Richard},
title = {{Dynamic Programming}},
year = {2010},
isbn = {0691146683},
publisher = {Princeton University Press},
address = {USA},
}
@article{nakhleh2021neurwin,
  title={NeurWIN: Neural Whittle Index Network For Restless Bandits Via Deep RL},
  author={Nakhleh, Khaled and Ganji, Santosh and Hsieh, Ping-Chun and Hou, I and Shakkottai, Srinivas and others},
  journal={Proc. of NeurIPS},
  year={2021}
}


@inproceedings{killian2021q,
  title={Q-Learning Lagrange Policies for Multi-Action Restless Bandits},
  author={Killian, Jackson A and Biswas, Arpita and Shah, Sanket and Tambe, Milind},
  booktitle={Proc. of ACM SIGKDD},
  year={2021}
}

@article{zhang2021restless,
  title={Restless Bandits with Many Arms: Beating the Central Limit Theorem},
  author={Zhang, Xiangyu and Frazier, Peter I},
  journal={arXiv preprint arXiv:2107.11911},
  year={2021}
}
@inproceedings{fu2019towards,
  title={Towards q-learning the whittle index for restless bandits},
  author={Fu, Jing and Nazarathy, Yoni and Moka, Sarat and Taylor, Peter G},
  booktitle={2019 Australian \& New Zealand Control Conference (ANZCC)},
  pages={249--254},
  year={2019},
  organization={IEEE}
}

@article{avrachenkov2022whittle,
  title={Whittle index based Q-learning for restless bandits with average reward},
  author={Avrachenkov, Konstantin E and Borkar, Vivek S},
  journal={Automatica},
  volume={139},
  pages={110186},
  year={2022},
  publisher={Elsevier}
}

@article{akbarzadeh2022learning,
  title={On learning Whittle index policy for restless bandits with scalable regret},
  author={Akbarzadeh, Nima and Mahajan, Aditya},
  journal={arXiv preprint arXiv:2202.03463},
  year={2022}
}

@book{bertsekas1995dynamic,
  title={{Dynamic Programming and Optimal Control}},
  author={Bertsekas, Dimitri P},
  volume={1},
  number={2},
  year={1995},
  publisher={Athena Scientific Belmont, MA}
}

@article{jaksch2010near,
  title={{Near-Optimal Regret Bounds for Reinforcement Learning}},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={4},
  year={2010}
}

@article{jin2019learning,
  title={{Learning Adversarial MDPs with Bandit Feedback and Unknown Transition}},
  author={Jin, Chi and Jin, Tiancheng and Luo, Haipeng and Sra, Suvrit and Yu, Tiancheng},
  journal={arXiv preprint arXiv:1912.01192},
  year={2019}
}

@inproceedings{rosenberg2019online,
  title={{Online Convex Optimization in Adversarial Markov Decision Processes}},
  author={Rosenberg, Aviv and Mansour, Yishay},
  booktitle={Proc. of ICML},
  year={2019}
}

@inproceedings{kalagarla2020sample,
  title={{A Sample-Efficient Algorithm for Episodic Finite-Horizon MDP with Constraints}},
  author={Kalagarla, Krishna C and Jain, Rahul and Nuzzo, Pierluigi},
  booktitle={Proc. of AAAI},
  year={2021}
}

@inproceedings{hasanzadezonuzy2020learning,
  title={{Learning with Safety Constraints: Sample Complexity of Reinforcement Learning for Constrained MDPs}},
  author={HasanzadeZonuzy, Aria and Kalathil, Dileep and Shakkottai, Srinivas},
  booktitle={Proc. of AAAI},
  year={2021}
}

@inproceedings{hasanzadezonuzy2021model,
  title={Model-Based Reinforcement Learning for Infinite-Horizon Discounted Constrained Markov Decision Processes},
  author={HasanzadeZonuzy, Aria and Kalathil, Dileep and Shakkottai, Srinivas},
  booktitle={Proc. of IJCAI},
  year={2021}
}



@article{efroni2020exploration,
  title={{Exploration-Exploitation in Constrained MDPs}},
  author={Efroni, Yonathan and Mannor, Shie and Pirotta, Matteo},
  journal={arXiv preprint arXiv:2003.02189},
  year={2020}
}

@incollection{kallenberg2003finite,
  title={{Finite State and Action MDPs}},
  author={Kallenberg, Lodewijk},
  booktitle={Handbook of Markov decision processes},
  pages={21--87},
  year={2003},
  publisher={Springer}
}


@book{lattimore2020bandit,
  title={{Bandit Algorithms}},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@inproceedings{zou2021minimizing,
  title={{Minimizing Age-of-Information in Heterogeneous Multi-Channel Systems: A New Partial-Index Approach}},
  author={Zou, Yihan and Kim, Kwang Taik and Lin, Xiaojun and Chiang, Mung},
  booktitle={Proc. of ACM MobiHoc},
  year={2021}
}

@article{hodge2015asymptotic,
  title={On the asymptotic optimality of greedy index heuristics for multi-action restless bandits},
  author={Hodge, David J and Glazebrook, Kevin D},
  journal={Advances in Applied Probability},
  volume={47},
  number={3},
  pages={652--667},
  year={2015},
  publisher={Cambridge University Press}
}


@article{garivier2016explore,
  title={On explore-then-commit strategies},
  author={Garivier, Aur{\'e}lien and Lattimore, Tor and Kaufmann, Emilie},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}

@article{dann2017unifying,
  title={Unifying PAC and regret: Uniform PAC bounds for episodic reinforcement learning},
  author={Dann, Christoph and Lattimore, Tor and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{avrachenkov2013congestion,
  title={Congestion control of TCP flows in Internet routers by means of index policy},
  author={Avrachenkov, Konstantin and Ayesta, Urtzi and Doncel, Josu and Jacko, Peter},
  journal={Computer Networks},
  volume={57},
  number={17},
  pages={3463--3478},
  year={2013},
  publisher={Elsevier}
}

@inproceedings{avrachenkov2017controlling,
  title={Controlling G-AIMD using index policy},
  author={Avrachenkov, K and Borkar, VS and Pattathil, S},
  booktitle={The 56th IEEE Conference on Decision and Control, Melbourne, December},
  pages={12--15},
  year={2017}
}

@article{borkar2017index,
  title={An index policy for dynamic pricing in cloud computing under price commitments},
  author={Borkar, Vivek S and Ravikumar, K and Saboo, Krishnakant},
  journal={Applicationes Mathematicae},
  volume={44},
  pages={215--245},
  year={2017},
  publisher={Instytut Matematyczny Polskiej Akademii Nauk}
}

@article{nino2012admission,
  title={Admission and routing of soft real-time jobs to multiclusters: Design and comparison of index policies},
  author={Ni{\~n}o-Mora, Jos{\'e}},
  journal={Computers \& operations research},
  volume={39},
  number={12},
  pages={3431--3444},
  year={2012},
  publisher={Elsevier}
}

@inproceedings{xiong2022reinforcementcache,
  title={{Reinforcement Learning for Dynamic Dimensioning of Cloud Caches: A Restless Bandit Approach}},
  author={Xiong, Guojun and Wang, Shufan and Yan, Gang and Li, Jian},
  booktitle={Proc. of IEEE INFOCOM},
  year={2022}
}

@article{archibald2009indexability,
  title={Indexability and index heuristics for a simple class of inventory routing problems},
  author={Archibald, Thomas W and Black, DP and Glazebrook, Kevin D},
  journal={Operations research},
  volume={57},
  number={2},
  pages={314--326},
  year={2009},
  publisher={INFORMS}
}

@article{borkar2017whittle,
  title={Whittle indexability in egalitarian processor sharing systems},
  author={Borkar, Vivek S and Pattathil, Sarath},
  journal={Annals of Operations Research},
  pages={1--21},
  year={2017},
  publisher={Springer}
}

@article{larrnaaga2016dynamic,
  title={{Dynamic Control of Birth-and-Death Restless Bandits: Application to Resource-Allocation Problems}},
  author={Larrnaaga, Maialen and Ayesta, Urtzi and Verloop, Ina Maria},
  journal={IEEE/ACM Transactions on Networking},
  volume={24},
  number={6},
  pages={3812--3825},
  year={2016},
  publisher={IEEE}
}

@inproceedings{larranaga2014index,
  title={{Index Policies for A Multi-Class Queue with Convex Holding Cost and Abandonments}},
  author={Larra{\~n}aga, Maialen and Ayesta, Urtzi and Verloop, Ina Maria},
  booktitle={Proc. of ACM Sigmetrics},
  year={2014}
}


@inproceedings{biswas2021learn,
  title={Learn to intervene: An adaptive learning policy for restless bandits in application to preventive healthcare},
  author={Biswas, Arpita and Aggarwal, Gaurav and Varakantham, Pradeep and Tambe, Milind},
 booktitle={Proc. of IJCAI},
  year={2021}
}

@article{bagheri2015restless,
  title={The restless multi-armed bandit formulation of the cognitive compressive sensing problem},
  author={Bagheri, Saeed and Scaglione, Anna},
  journal={IEEE Transactions on Signal Processing},
  volume={63},
  number={5},
  pages={1183--1198},
  year={2015},
  publisher={IEEE}
}

@inproceedings{cohen2014restless,
  title={Restless multi-armed bandits under time-varying activation constraints for dynamic spectrum access},
  author={Cohen, Kobi and Zhao, Qing and Scaglione, Anna},
  booktitle={2014 48th Asilomar Conference on Signals, Systems and Computers},
  pages={1575--1578},
  year={2014},
  organization={IEEE}
}

@article{zhao2008myopic,
  title={On myopic sensing for multi-channel opportunistic access: structure, optimality, and performance},
  author={Zhao, Qing and Krishnamachari, Bhaskar and Liu, Keqin},
  journal={IEEE Transactions on Wireless Communications},
  volume={7},
  number={12},
  pages={5431--5440},
  year={2008},
  publisher={IEEE}
}

@article{mate2020collapsing,
  title={Collapsing Bandits and Their Application to Public Health Intervention},
  author={Mate, Aditya and Killian, Jackson and Xu, Haifeng and Perrault, Andrew and Tambe, Milind},
  journal={Proc. of NeurIPS},
  year={2020}
}

@inproceedings{bhattacharya2018restless,
  title={Restless bandits visiting villages: A preliminary study on distributing public health services},
  author={Bhattacharya, Biswarup},
  booktitle={Proceedings of the 1st ACM SIGCAS Conference on Computing and Sustainable Societies},
  pages={1--8},
  year={2018}
}

@article{arapostathis1993discrete,
  title={Discrete-time controlled Markov processes with average cost criterion: A survey},
  author={Arapostathis, Aristotle and Borkar, Vivek S and Fern{\'a}ndez-Gaucherand, Emmanuel and Ghosh, Mrinal K and Marcus, Steven I},
  journal={SIAM Journal on Control and Optimization},
  volume={31},
  number={2},
  pages={282--344},
  year={1993},
  publisher={SIAM}
}

@inproceedings{aalto2015whittle,
  title={Whittle index approach to size-aware scheduling with time-varying channels},
  author={Aalto, Samuli and Lassila, Pasi and Osti, Prajwal},
  booktitle={Proc. of ACM SIGMETRICS},
  year={2015}
}

@article{li2019combinatorial,
  title={Combinatorial sleeping bandits with fairness constraints},
  author={Li, Fengjiao and Liu, Jia and Ji, Bo},
  journal={IEEE Transactions on Network Science and Engineering},
  volume={7},
  number={3},
  pages={1799--1813},
  year={2019},
  publisher={IEEE}
}

@inproceedings{meshram2016optimal,
  title={Optimal recommendation to users that react: Online learning for a class of POMDPs},
  author={Meshram, Rahul and Gopalan, Aditya and Manjunath, D},
  booktitle={2016 IEEE 55th Conference on Decision and Control (CDC)},
  pages={7210--7215},
  year={2016},
  organization={IEEE}
}

@inproceedings{lan2010axiomatic,
  title={An axiomatic theory of fairness in network resource allocation},
  author={Lan, Tian and Kao, David and Chiang, Mung and Sabharwal, Ashutosh},
  booktitle={Proc. of IEEE INFOCOM},
  year={2010}
}

@inproceedings{li2022efficient,
  title={Efficient Resource Allocation with Fairness Constraints in Restless Multi-Armed Bandits},
  author={Li, Dexun and Varakantham, Pradeep},
  booktitle={Proc. of UAI},
  year={2022}
}

@article{herlihy2021planning,
  title={Planning to Fairly Allocate: Probabilistic Fairness in the Restless Bandit Setting},
  author={Herlihy, Christine and Prins, Aviva and Srinivasan, Aravind and Dickerson, John},
  journal={arXiv preprint arXiv:2106.07677},
  year={2021}
}

@article{chen2022learning,
  title={Learning Infinite-Horizon Average-Reward Markov Decision Processes with Constraints},
  author={Chen, Liyu and Jain, Rahul and Luo, Haipeng},
  journal={arXiv preprint arXiv:2202.00150},
  year={2022}
}

@article{singh2020learning,
  title={Learning in Markov decision processes under constraints},
  author={Singh, Rahul and Gupta, Abhishek and Shroff, Ness B},
  journal={arXiv preprint arXiv:2002.12435},
  year={2020}
}

@article{li2022towards,
  title={Towards Soft Fairness in Restless Multi-Armed Bandits},
  author={Li, Dexun and Varakantham, Pradeep},
  journal={arXiv preprint arXiv:2207.13343},
  year={2022}
}

@inproceedings{kang2013markov,
  title={Markov models for treatment adherence in obstructive sleep apnea},
  author={Kang, Yuncheol and Prabhu, Vittaldas V and Sawyer, Amy M and Griffin, Paul M},
  booktitle={IIE Annual Conference. Proceedings},
  pages={1592},
  year={2013},
  organization={Institute of Industrial and Systems Engineers (IISE)}
}


@misc{COMPAS,
  title = {COMPAS Recidivism Racial Bias},
  howpublished = {\url{https://www.kaggle.com/datasets/danofer/compass}},

}

@inproceedings{nabi2019learning,
  title={Learning optimal fair policies},
  author={Nabi, Razieh and Malinsky, Daniel and Shpitser, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={4674--4682},
  year={2019},
  organization={PMLR}
}

@incollection{angwin2016machine,
  title={Machine bias},
  author={Angwin, Julia and Larson, Jeff and Mattu, Surya and Kirchner, Lauren},
  booktitle={Ethics of Data and Analytics},
  pages={254--264},
  year={2016},
  publisher={Auerbach Publications}
}

@article{mitrophanov2005sensitivity,
  title={Sensitivity and convergence of uniformly ergodic Markov chains},
  author={Mitrophanov, A Yu},
  journal={Journal of Applied Probability},
  volume={42},
  number={4},
  pages={1003--1014},
  year={2005},
  publisher={Cambridge University Press}
}

@inproceedings{chen2020fair,
  title={Fair contextual multi-armed bandits: Theory and experiments},
  author={Chen, Yifang and Cuellar, Alex and Luo, Haipeng and Modi, Jignesh and Nemlekar, Heramb and Nikolaidis, Stefanos},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  pages={181--190},
  year={2020},
  organization={PMLR}
}

@inproceedings{claure2020multi,
  title={Multi-armed bandits with fairness constraints for distributing resources to human teammates},
  author={Claure, Houston and Chen, Yifang and Modi, Jignesh and Jung, Malte and Nikolaidis, Stefanos},
  booktitle={Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction},
  pages={299--308},
  year={2020}
}

@inproceedings{
yu2022policy,
title={Policy Optimization with Advantage Regularization for Long-Term Fairness in Decision Systems},
author={Eric Yang Yu and Zhizhen Qin and Min Kyung Lee and Sicun Gao},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=1wVBLK1Xuc}
}

@inproceedings{d2020fairness,
  title={Fairness is not static: deeper understanding of long term fairness via simulation studies},
  author={D'Amour, Alexander and Srinivasan, Hansa and Atwood, James and Baljekar, Pallavi and Sculley, David and Halpern, Yoni},
  booktitle={Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
  pages={525--534},
  year={2020}
}

@inproceedings{xiong2022learning,
  title={Learning Infinite-Horizon Average-Reward Restless Multi-Action Bandits via Index Awareness},
  author={Xiong, Guojun and Wang, Shufan and Li, Jian},
  booktitle={Proc. of NeurIPS},
  year={2022}
}

@inproceedings{nakhleh2022deeptop,
  title={DeepTOP: Deep Threshold-Optimal Policy for MDPs and RMABs},
  author={Nakhleh, Khaled and Hou, I and others},
  booktitle={Proc. of NeurIPS},
  year={2022}
}

@article{yin2023long,
  title={Long-Term Fairness with Unknown Dynamics},
  author={Yin, Tongxin and Raab, Reilly and Liu, Mingyan and Liu, Yang},
  journal={arXiv preprint arXiv:2304.09362},
  year={2023}
}

@inproceedings{snow2008cheap,
  title={Cheap and fast--but is it good? evaluating non-expert annotations for natural language tasks},
  author={Snow, Rion and O’connor, Brendan and Jurafsky, Dan and Ng, Andrew Y},
  booktitle={Proceedings of the 2008 conference on empirical methods in natural language processing},
  pages={254--263},
  year={2008}
}

@article{biswas2023fairness,
  title={Fairness for Workers Who Pull the Arms: An Index Based Policy for Allocation of Restless Bandit Tasks},
  author={Biswas, Arpita and Killian, Jackson A and Diaz, Paula Rodriguez and Ghosh, Susobhan and Tambe, Milind},
  journal={arXiv preprint arXiv:2303.00799},
  year={2023}
}

@inproceedings{dagan2006pascal,
  title={The pascal recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment: First PASCAL Machine Learning Challenges Workshop, MLCW 2005, Southampton, UK, April 11-13, 2005, Revised Selected Papers},
  pages={177--190},
  year={2006},
  organization={Springer}
}

@article{villacieros2011versatile,
  title={Versatile Two State Model For Land Mobile Satellite Systems: Parameter Extraction And Time Series Synthesis},
  author={Villacieros, B Montenegro},
  journal={PhD Thesis},
  year={2011},
  publisher={UCL}
}

@article{https://doi.org/10.1002/sat.964,
author = {Prieto-Cerdeira, R. and Perez-Fontan, F. and Burzigotti, P. and Bolea-Alamañac, A. and Sanchez-Lago, I.},
title = {Versatile two-state land mobile satellite channel model with first application to DVB-SH analysis},
journal = {International Journal of Satellite Communications and Networking},
volume = {28},
number = {5-6},
pages = {291-315},
keywords = {Land Mobile Satellite, statistical propagation model, narrowband propagation, Markov chain, semi-Markov chain, DVB-SH},
doi = {https://doi.org/10.1002/sat.964},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sat.964},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sat.964},
abstract = {Abstract Standardization activities on Digital Video Broadcasting–Satellite services to Handheld Devices (DVB-SH) have driven the need for a consolidated Land Mobile Satellite (LMS) narrowband channel model. In the DVB-SH system, the satellite broadcasts a signal carrying multimedia services aimed directly to a variety of mobile (handheld or vehicular) and fixed terminals. A three-state LMS channel model that describes the narrowband propagation channel in three possible shadowing states—line-of-sight conditions, moderate shadowing and deep shadowing—had been selected as a baseline for physical layer simulation of the DVB-SH waveform. This type of model, capable of generating complex time series, was originally selected, because it is the simplest model that allows the simulation of first- and second-order effects of the LMS channel in a realistic manner. The main limitations of such model are, first of all, that a classification in three states does not necessarily correspond with reality and, secondly, that the statistical parameters for each state were fixed for a given scenario and elevation angle. Those limitations may impact the selection of Physical Layer parameters of the DVB-SH standard. A new channel model is proposed based on the original three-state model including two major modifications: a reduction in the number of states and the introduction of a versatile selection of statistical parameters describing each state. Furthermore, the state machine is governed either by Markov or by semi-Markov chains. The new-state classification does not necessarily correspond to intuitive physical definitions of the states as before (line-of-sight, shadowing) but instead to channel variations that share similar statistical characteristics. The two-states are termed for convenience, Good and Bad states, representing a range of LOS-to-moderate shadowing and moderate-to-deep shadowing, respectively. For the model parameters selection, datasets at L- and S-band have been analysed using an iterative algorithm that includes automatic data classification and parameter extraction. The proposed model is considered more suitable for the analysis of DVB-SH test cases. This study starts with an overview of the main DVB-SH system parameters and assumptions. The original three-state model is briefly introduced; the new model is presented in detail, including simulator implementation. Finally, both models and experimental data sets are compared on a statistical basis. The performance of both models are discussed to show how effective the model is for the representation of shadowed conditions and therefore, its suitability for the analysis and optimal configuration of the physical and link layer parameters (namely physical layer interleaver size, link layer protection time, overall redundancy, etc.). Copyright © 2010 John Wiley \& Sons, Ltd.},
year = {2010}
}

@misc{PASCAL-RTE1,
author = {Snow, Rion and O’connor, Brendan and Jurafsky, Dan and Ng, Andrew Y},
  title = {NLP Annotations},
  howpublished = {\url{https://sites.google.com/site/nlpannotations/}},
}


@article{nino2023markovian,
  title={Markovian Restless Bandits and Index Policies: A Review},
  author={Ni{\~n}o-Mora, Jos{\'e}},
  journal={Mathematics},
  volume={11},
  number={7},
  pages={1639},
  year={2023},
  publisher={MDPI}
}