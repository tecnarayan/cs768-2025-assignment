\begin{thebibliography}{10}

\bibitem{murphy2012machine}
Kevin~P. Murphy.
\newblock {\em Machine learning: a probabilistic perspective}.
\newblock MIT press, 2012.

\bibitem{2005clusteringSurvey}
Rui Xu and Donald Wunsch.
\newblock Survey of clustering algorithms.
\newblock {\em IEEE Transactions on neural networks}, 16(3):645--678, 2005.

\bibitem{hansen1997cluster}
Pierre Hansen and Brigitte Jaumard.
\newblock Cluster analysis and mathematical programming.
\newblock {\em Mathematical programming}, 79(1-3):191--215, 1997.

\bibitem{von2012clustering}
Ulrike Von~Luxburg, Robert~C. Williamson, and Isabelle Guyon.
\newblock Clustering: Science or art?
\newblock In {\em Proceedings of ICML workshop on unsupervised and transfer
  learning}, pages 65--79. JMLR Workshop and Conference Proceedings, 2012.

\bibitem{lecun2010mnist}
Yann LeCun, Corinna Cortes, and C.~J. Burges.
\newblock {MNIST} handwritten digit database.
\newblock \url{http://yann.lecun.com/exdb/mnist/}, 2010.

\bibitem{min2018survey}
Erxue Min, Xifeng Guo, Qiang Liu, Gen Zhang, Jianjing Cui, and Jun Long.
\newblock A survey of clustering with deep learning: From the perspective of
  network architecture.
\newblock {\em IEEE Access}, 6:39501--39514, 2018.

\bibitem{aljalbout2018taxonomy}
Elie Aljalbout, Vladimir Golkov, Yawar Siddiqui, Maximilian Strobel, and Daniel
  Cremers.
\newblock Clustering with deep learning: Taxonomy and new methods.
\newblock {\em arXiv preprint arXiv:1801.07648}, 2018.

\bibitem{dec}
Junyuan Xie, Ross Girshick, and Ali Farhadi.
\newblock Unsupervised deep embedding for clustering analysis.
\newblock In {\em International Conference on Machine Learning}, pages
  478--487. PMLR, 2016.

\bibitem{dcn}
Bo~Yang, Xiao Fu, Nicholas~D. Sidiropoulos, and Mingyi Hong.
\newblock Towards k-means-friendly spaces: Simultaneous deep learning and
  clustering.
\newblock In {\em International Conference on Machine Learning}, pages
  3861--3870. PMLR, 2017.

\bibitem{vade}
Zhuxi Jiang, Yin Zheng, Huachun Tan, Bangsheng Tang, and Hanning Zhou.
\newblock Variational deep embedding: An unsupervised and generative approach
  to clustering.
\newblock In {\em Proceedings of the Twenty-Sixth International Joint
  Conference on Artificial Intelligence, {IJCAI-17}}, pages 1965--1972, 2017.

\bibitem{imsat}
Weihua Hu, Takeru Miyato, Seiya Tokui, Eiichi Matsumoto, and Masashi Sugiyama.
\newblock Learning discrete representations via information maximizing
  self-augmented training.
\newblock In {\em International Conference on Machine Learning}, pages
  1558--1567. PMLR, 2017.

\bibitem{spectralnet}
Uri Shaham, Kelly Stanton, Henry Li, Boaz Nadler, Ronen Basri, and Yuval
  Kluger.
\newblock {SpectralNet}: Spectral clustering using deep neural networks.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{yang2019deep}
Xu~Yang, Cheng Deng, Feng Zheng, Junchi Yan, and Wei Liu.
\newblock Deep spectral clustering using dual autoencoder network.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 4066--4075, 2019.

\bibitem{clustergan}
Sudipto Mukherjee, Himanshu Asnani, Eugene Lin, and Sreeram Kannan.
\newblock {ClusterGAN}: Latent space clustering in generative adversarial
  networks.
\newblock In {\em Proceedings of the AAAI conference on artificial
  intelligence}, volume~33, pages 4610--4617, 2019.

\bibitem{acol-gar}
Ozsel Kilinc and Ismail Uysal.
\newblock Learning latent representations in neural networks for clustering
  through pseudo supervision and graph-based activity regularization.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{maddison2016concrete}
Chris~J. Maddison, Andriy Mnih, and Yee~Whye Teh.
\newblock The concrete distribution: A continuous relaxation of discrete random
  variables.
\newblock In {\em International Conference on Learning Representations}, 2017.

\bibitem{jang2016categorical}
Eric Jang, Shixiang Gu, and Ben Poole.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock In {\em International Conference on Learning Representations}, 2017.

\bibitem{lievin2019towards}
Valentin Li{\'e}vin, Andrea Dittadi, Lars Maal{\o}e, and Ole Winther.
\newblock Towards hierarchical discrete variational autoencoders.
\newblock In {\em 2nd Symposium on Advances in Approximate Bayesian Inference},
  2019.

\bibitem{grathwohl2018backprop}
Will Grathwohl, Dami Choi, Yuhuai Wu, Geoffrey Roeder, and David Duvenaud.
\newblock Backpropagation through the void: Optimizing control variates for
  black-box gradient estimation.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{pervez2020low}
Adeel Pervez, Taco Cohen, and Efstratios Gavves.
\newblock Low bias low variance gradient estimates for boolean stochastic
  networks.
\newblock In {\em International Conference on Machine Learning}, pages
  7632--7640. PMLR, 2020.

\bibitem{kingma2013auto}
Diederik~P. Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{vlae}
Shengjia Zhao, Jiaming Song, and Stefano Ermon.
\newblock Learning hierarchical features from deep generative models.
\newblock In {\em International Conference on Learning Representations}, 2017.

\bibitem{ProVLAE}
Zhiyuan Li, Jaideep~Vitthal Murkute, Prashnna~Kumar Gyawali, and Linwei Wang.
\newblock Progressive learning and disentanglement of hierarchical
  representations.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{3dshapes18}
Chris Burgess and Hyunjik Kim.
\newblock {3D} shapes dataset.
\newblock https://github.com/deepmind/3dshapes-dataset/, 2018.

\bibitem{svhn}
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo~Wu, and Andrew~Y.
  Ng.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In {\em NIPS Workshop on Deep Learning and Unsupervised Feature
  Learning}, 2011.

\bibitem{pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock {PyTorch}: An imperative style, high-performance deep learning
  library.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  8024--8035, 2019.

\bibitem{ltvae}
Xiaopeng Li, Zhourong Chen, Leonard K.~M. Poon, and Nevin~L. Zhang.
\newblock Learning latent superstructures in variational autoencoders for deep
  multidimensional clustering.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{willetts2019disentangling}
Matthew Willetts, Stephen~J. Roberts, and Chris Holmes.
\newblock Disentangling to cluster: Gaussian mixture variational ladder
  autoencoders.
\newblock In {\em 4th Workshop on Bayesian Deep Learning (NeurIPS 2019)}, 2019.

\bibitem{gmvae}
Nat Dilokthanakul, Pedro A.~M. Mediano, Marta Garnelo, Matthew C.~H. Lee, Hugh
  Salimbeni, Kai Arulkumaran, and Murray Shanahan.
\newblock Deep unsupervised clustering with gaussian mixture {VAE}.
\newblock {\em arXiv preprint arXiv:1611.02648}, 2017.

\bibitem{Nalisnick2016_gm}
Eric Nalisnick, Lars Hertel, and Padhraic Smyth.
\newblock Approximate inference for deep latent gaussian mixtures.
\newblock In {\em Workshop on Bayesian Deep Learning Workshop (NIPS 2016)},
  2016.

\bibitem{Willetts2018_sus}
Matthew Willetts, Stephen~J. Roberts, and Christopher~C. Holmes.
\newblock Semi-unsupervised learning using deep generative models.
\newblock In {\em 3rd Workshop on Bayesian Deep Learning (NeurIPS 2018)}, 2018.

\bibitem{Willetts2020}
Matthew Willetts, Stephen~J. Roberts, and Christopher~C. Holmes.
\newblock Semi-unsupervised learning: Clustering and classifying using
  ultra-sparse labels.
\newblock In {\em IEEE Big Data Workshop}, 2020.

\bibitem{hdpvae}
Prasoon Goyal, Zhiting Hu, Xiaodan Liang, Chenyu Wang, and Eric~P. Xing.
\newblock Nonparametric variational auto-encoders for hierarchical
  representation learning.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 5094--5102, 2017.

\bibitem{Kingma2016}
Diederik~P. Kingma, Tim Salimans, Rafal Jozefowicz, Xi~Chen, Ilya Sutskever,
  and Max Welling.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock In {\em Advances in Neural Information Processing Systems}, 2016.

\bibitem{lvae}
Casper~Kaae S{\o}nderby, Tapani Raiko, Lars Maal{\o}e, S{\o}ren~Kaae
  S{\o}nderby, and Ole Winther.
\newblock Ladder variational autoencoders.
\newblock In {\em Advances in Neural Information Processing Systems}, 2016.

\bibitem{biva}
Lars Maal{\o}e, Marco Fraccaro, Valentin Li{\'{e}}vin, and Ole Winther.
\newblock {BIVA}: A very deep hierarchy of latent variables for generative
  modeling.
\newblock In {\em Advances in Neural Information Processing Systems}, 2019.

\bibitem{Vahdat2020}
Arash Vahdat and Jan Kautz.
\newblock {NVAE}: A deep hierarchical variational autoencoder.
\newblock In {\em Advances in Neural Information Processing Systems}, 2020.

\bibitem{Child2020}
Rewon Child.
\newblock Very deep {VAEs} generalize autoregressive models and can outperform
  them on images.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{higgins2016beta}
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot,
  Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner.
\newblock beta-{VAE}: Learning basic visual concepts with a constrained
  variational framework.
\newblock In {\em International Conference on Learning Representations}, 2017.

\bibitem{mathieu2019disentangling}
Emile Mathieu, Tom Rainforth, N.~Siddharth, and Yee~Whye Teh.
\newblock Disentangling disentanglement in variational autoencoders.
\newblock In {\em International Conference on Machine Learning}, pages
  4402--4412. PMLR, 2019.

\bibitem{kim2018disentangling}
Hyunjik Kim and Andriy Mnih.
\newblock Disentangling by factorising.
\newblock In {\em International Conference on Machine Learning}, pages
  2649--2658. PMLR, 2018.

\bibitem{chen2018isolating}
Ricky T.~Q. Chen, Xuechen Li, Roger Grosse, and David Duvenaud.
\newblock Isolating sources of disentanglement in variational autoencoders.
\newblock {\em arXiv preprint arXiv:1802.04942}, 2018.

\bibitem{rolinek2019variational}
Michal Rolinek, Dominik Zietlow, and Georg Martius.
\newblock Variational autoencoders pursue pca directions (by accident).
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12406--12415, 2019.

\bibitem{locatello2019challenging}
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly,
  Bernhard Sch{\"o}lkopf, and Olivier Bachem.
\newblock Challenging common assumptions in the unsupervised learning of
  disentangled representations.
\newblock In {\em International Conference on Machine Learning}, pages
  4114--4124. PMLR, 2019.

\bibitem{Cui2007}
Ying Cui, Xiaoli~Z. Fern, and Jennifer~G. Dy.
\newblock Non-redundant multi-view clustering via orthogonalization.
\newblock {\em Proceedings - IEEE International Conference on Data Mining,
  ICDM}, 3:133--142, 2007.

\bibitem{Davidson2008}
Ian Davidson and Zijie Qi.
\newblock Finding alternative clusterings using constraints.
\newblock {\em Proceedings - IEEE International Conference on Data Mining,
  ICDM}, pages 773--778, 2008.

\bibitem{Qi2009}
Zijie Qi and Ian Davidson.
\newblock A principled and flexible framework for finding alternative
  clusterings.
\newblock {\em Proceedings of the ACM SIGKDD International Conference on
  Knowledge Discovery and Data Mining}, pages 717--725, 2009.

\bibitem{muller2012discovering}
Emmanuel Muller, Stephan Gunnemann, Ines Farber, and Thomas Seidl.
\newblock Discovering multiple clustering solutions: Grouping objects in
  different views of the data.
\newblock In {\em 2012 IEEE 28th International Conference on Data Engineering},
  pages 1207--1210. IEEE, 2012.

\bibitem{svae}
Matthew~James Johnson, David Duvenaud, Alexander~B. Wiltschko, Sandeep~R.
  Datta, and Ryan~P. Adams.
\newblock Composing graphical models with neural networks for structured
  representations and fast inference.
\newblock In {\em Advances in Neural Information Processing Systems}, 2016.

\bibitem{peebles2020hessian}
William Peebles, John Peebles, Jun-Yan Zhu, Alexei~A. Efros, and Antonio
  Torralba.
\newblock The hessian penalty: A weak prior for unsupervised disentanglement.
\newblock In {\em Proceedings of European Conference on Computer Vision
  (ECCV)}, 2020.

\bibitem{gqn}
S.~M.~Ali Eslami, Danilo~Jimenez Rezende, Frederic Besse, Fabio Viola, Ari~S.
  Morcos, Marta Garnelo, Avraham Ruderman, Andrei~A. Rusu, Ivo Danihelka, Karol
  Gregor, et~al.
\newblock Neural scene representation and rendering.
\newblock {\em Science}, 360(6394):1204--1210, 2018.

\bibitem{harris2020array}
Charles~R. Harris, K.~Jarrod Millman, St{\'e}fan~J. van~der Walt, Ralf Gommers,
  Pauli Virtanen, David Cournapeau, Eric Wieser, Julian Taylor, Sebastian Berg,
  Nathaniel~J. Smith, et~al.
\newblock Array programming with {NumPy}.
\newblock {\em Nature}, 585(7825):357--362, 2020.

\bibitem{wandb}
Lukas Biewald.
\newblock Experiment tracking with weights and biases, 2020.
\newblock Software available from wandb.com.

\bibitem{matplotlib}
J.~D. Hunter.
\newblock Matplotlib: A {2D} graphics environment.
\newblock {\em Computing in Science \& Engineering}, 9(3):90--95, 2007.

\bibitem{seaborn}
Michael~L. Waskom.
\newblock seaborn: statistical data visualization.
\newblock {\em Journal of Open Source Software}, 6(60):3021, 2021.

\bibitem{pickle}
Guido Van~Rossum.
\newblock {\em The {Python} Library Reference, release 3.8.2}.
\newblock Python Software Foundation, 2020.

\bibitem{h5py}
Andrew Collette.
\newblock {\em Python and {HDF5}}.
\newblock O'Reilly, 2013.

\bibitem{opencv}
G.~Bradski.
\newblock The {OpenCV} library.
\newblock {\em Dr. Dobb's Journal of Software Tools}, 2000.

\bibitem{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock {\em Journal of Machine Learning Research}, 12:2825--2830, 2011.

\bibitem{glorot_init}
Xavier Glorot and Yoshua Bengio.
\newblock Understanding the difficulty of training deep feedforward neural
  networks.
\newblock In {\em Proceedings of the thirteenth international conference on
  artificial intelligence and statistics}, pages 249--256, 2010.

\bibitem{data_init}
Philipp Kr{\"a}henb{\"u}hl, Carl Doersch, Jeff Donahue, and Trevor Darrell.
\newblock Data-dependent initializations of convolutional neural networks.
\newblock In {\em International Conference on Learning Representations}, 2016.

\bibitem{vincent2010stacked}
Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, Pierre-Antoine
  Manzagol, and L{\'e}on Bottou.
\newblock Stacked denoising autoencoders: Learning useful representations in a
  deep network with a local denoising criterion.
\newblock {\em Journal of machine learning research}, 11(12), 2010.

\bibitem{kuhn1955hungarian}
Harold~W. Kuhn.
\newblock The {Hungarian} method for the assignment problem.
\newblock {\em Naval research logistics quarterly}, 2(1-2):83--97, 1955.

\bibitem{zhang2018unreasonable}
Richard Zhang, Phillip Isola, Alexei~A Efros, Eli Shechtman, and Oliver Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 586--595, 2018.

\bibitem{kingma2018glow}
Diederik~P. Kingma and Prafulla Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In {\em Advances in Neural Information Processing Systems}, 2018.

\bibitem{parmar2018image}
Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer,
  Alexander Ku, and Dustin Tran.
\newblock Image transformer.
\newblock In {\em International Conference on Machine Learning}, pages
  4055--4064. PMLR, 2018.

\end{thebibliography}
