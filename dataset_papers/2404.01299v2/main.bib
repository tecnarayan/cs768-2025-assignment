@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@article{yin2017peer,
  title={Peer learning with concept cartoons enhance critical thinking and performance in secondary school economics},
  author={Yin, Khoo Yin and Fitzgerald, Robert},
  journal={Journal of economics and economic education research},
  volume={18},
  number={1},
  pages={1--13},
  year={2017}
}


@article{siong2023use,
  title={The use of concept cartoons in overcoming the misconception in electricity concepts},
  author={Siong, La{\i} Chin and Ong, Yunn and Phang, Fatin Aliah and Pusppanathan, Jaysuman},
  journal={Participatory Educational Research},
  volume={10},
  number={1},
  pages={310--329},
  year={2023},
  publisher={{\"O}zgen KORKMAZ}
}

@article{schnotz2008functions,
  title={Functions of animation in comprehension and learning},
  author={Schnotz, Wolfgang and Rasch, Thorsten},
  journal={Learning with animation: Research implications for design},
  pages={93--113},
  year={2008},
  publisher={Cambridge University Press New York}
}

@article{shreesha2016does,
  title={Does animation facilitate better learning in primary education? A comparative study of three different subjects},
  author={Shreesha, Mairaru and Tyagi, Sanjay Kumar},
  journal={Creative Education},
  volume={7},
  number={13},
  pages={1800--1809},
  year={2016},
  publisher={Scientific Research Publishing}
}

@article{meringoff1983children,
  title={How is children's learning from television distinctive? Exploiting the medium methodologically},
  author={Meringoff, Laurene K and Vibbert, Martha M and Char, Cynthia A and Fernie, David E and Banker, Gail S and Gardner, Howard},
  journal={Children's understanding of television: Research on attention and comprehension},
  pages={151--180},
  year={1983},
  publisher={Academic Press New York}
}

@article{han2023caricaturing,
  title={Caricaturing shapes in visual memory},
  author={Han, Subin and Sun, Zekun and Firestone, Chaz},
  journal={Journal of Vision},
  volume={23},
  number={9},
  pages={4756--4756},
  year={2023},
  publisher={The Association for Research in Vision and Ophthalmology}
}

@article{mauro1992caricature,
  title={Caricature and face recognition},
  author={Mauro, Robert and Kubovy, Michael},
  journal={Memory \& Cognition},
  volume={20},
  pages={433--440},
  year={1992},
  publisher={Springer}
}

@incollection{davis2022improving,
  title={Improving Face Recognition Using Artistic Interpretations of Prominent Features: Leveraging Caricatures in Modern Surveillance Systems},
  author={Davis, Sara R and Hand, Emily M},
  booktitle={Intelligent Video Surveillance-New Perspectives},
  year={2022},
  publisher={IntechOpen}
}

@article{rhodes1987,
title = {Identification and ratings of caricatures: Implications for mental representations of faces},
journal = {Cognitive Psychology},
volume = {19},
number = {4},
pages = {473-497},
year = {1987},
issn = {0010-0285},
doi = {https://doi.org/10.1016/0010-0285(87)90016-8},
url = {https://www.sciencedirect.com/science/article/pii/0010028587900168},
author = {Gillian Rhodes and Susan Brennan and Susan Carey}
}

@inproceedings{li2024image,
  title={Image content generation with causal reasoning},
  author={Li, Xiaochuan and Fan, Baoyu and Zhang, Runze and Jin, Liang and Wang, Di and Guo, Zhenhua and Zhao, Yaqian and Li, Rengang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={12},
  pages={13646--13654},
  year={2024}
}

@article{videochat2,
  title={Mvbench: A comprehensive multi-modal video understanding benchmark},
  author={Li, Kunchang and Wang, Yali and He, Yinan and Li, Yizhuo and Wang, Yi and Liu, Yi and Wang, Zun and Xu, Jilan and Chen, Guo and Luo, Ping and others},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  year={2024}
}

@inproceedings{blip2,
      title={{BLIP-2:} Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models}, 
      author={Junnan Li and Dongxu Li and Silvio Savarese and Steven Hoi},
      year={2023},
      booktitle={ICML},
}

@inproceedings{videollama,
    title = {Video-{LL}a{MA}: An Instruction-tuned Audio-Visual Language Model for Video Understanding},
    author = {Zhang, Hang  and Li, Xin  and Bing, Lidong},
    editor = "Feng, Yansong  and
      Lefever, Els",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-demo.49",
    doi = "10.18653/v1/2023.emnlp-demo.49",
    pages = "543--553",
}


@article{gpt2,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{evqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2425--2433},
  year={2015}
}


@inproceedings{stvqa,
  title={Tgif-qa: Toward spatio-temporal reasoning in visual question answering},
  author={Jang, Yunseok and Song, Yale and Yu, Youngjae and Kim, Youngjin and Kim, Gunhee},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2758--2766},
  year={2017}
}

@article{stvqa2,
  title={Video question answering with spatio-temporal reasoning},
  author={Jang, Yunseok and Song, Yale and Kim, Chris Dongjoo and Yu, Youngjae and Kim, Youngjin and Kim, Gunhee},
  journal={International Journal of Computer Vision},
  volume={127},
  pages={1385--1412},
  year={2019},
  publisher={Springer}
}


@inproceedings{comem,
  title={Motion-appearance co-memory networks for video question answering},
  author={Gao, Jiyang and Ge, Runzhou and Chen, Kan and Nevatia, Ram},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6576--6585},
  year={2018}
}


@inproceedings{hme,
  title={Heterogeneous memory enhanced multimodal attention model for video question answering},
  author={Fan, Chenyou and Zhang, Xiaofan and Zhang, Shu and Wang, Wensheng and Zhang, Chi and Huang, Heng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1999--2007},
  year={2019}
}


@inproceedings{hcrn,
  title={Hierarchical conditional relation networks for video question answering},
  author={Le, Thao Minh and Le, Vuong and Venkatesh, Svetha and Tran, Truyen},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9972--9981},
  year={2020}
}


@inproceedings{hga,
  title={Reasoning with heterogeneous graph alignment for video question answering},
  author={Jiang, Pin and Han, Yahong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={07},
  pages={11109--11116},
  year={2020}
}


@inproceedings{nextqa,
  title={Next-qa: Next phase of question-answering to explaining temporal actions},
  author={Xiao, Junbin and Shang, Xindi and Yao, Angela and Chua, Tat-Seng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9777--9786},
  year={2021}
}


@inproceedings{mist,
  title={MIST: Multi-modal Iterative Spatial-Temporal Transformer for Long-form Video Question Answering},
  author={Gao, Difei and Zhou, Luowei and Ji, Lei and Zhu, Linchao and Yang, Yi and Shou, Mike Zheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14773--14783},
  year={2023}
}


@inproceedings{activitynetqa,
  title={Activitynet-qa: A dataset for understanding complex web videos via question answering},
  author={Yu, Zhou and Xu, Dejing and Yu, Jun and Yu, Ting and Zhao, Zhou and Zhuang, Yueting and Tao, Dacheng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={9127--9134},
  year={2019}
}


@ARTICLE{uatt,
  author={Xue, Hongyang and Zhao, Zhou and Cai, Deng},
  journal={IEEE Transactions on Image Processing}, 
  title={Unifying the Video and Question Attentions for Open-Ended Video Question Answering}, 
  year={2017},
  volume={26},
  number={12},
  pages={5656-5666},
  doi={10.1109/TIP.2017.2746267}}

@inproceedings{moviefib,
  title={A dataset and exploration of models for understanding video data through fill-in-the-blank question-answering},
  author={Maharaj, Tegan and Ballas, Nicolas and Rohrbach, Anna and Courville, Aaron and Pal, Christopher},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6884--6893},
  year={2017}
}

@inproceedings{msvd,
  title={Video question answering via gradually refined attention over appearance and motion},
  author={Xu, Dejing and Zhao, Zhou and Xiao, Jun and Wu, Fei and Zhang, Hanwang and He, Xiangnan and Zhuang, Yueting},
  booktitle={Proceedings of the 25th ACM international conference on Multimedia},
  pages={1645--1653},
  year={2017}
}

@inproceedings{zeng2017leveraging,
  title={Leveraging video descriptions to learn video question answering},
  author={Zeng, Kuo-Hao and Chen, Tseng-Hung and Chuang, Ching-Yao and Liao, Yuan-Hong and Niebles, Juan Carlos and Sun, Min},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={31},
  number={1},
  year={2017}
}

@inproceedings{openendedqa_zhou,
  title     = {Open-Ended Long-form Video Question Answering via Adaptive Hierarchical Reinforced Networks},
  author    = {Zhou Zhao and Zhu Zhang and Shuwen Xiao and Zhou Yu and Jun Yu and Deng Cai and Fei Wu and Yueting Zhuang},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence, {IJCAI-18}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  pages     = {3683--3689},
  year      = {2018},
  month     = {7},
  doi       = {10.24963/ijcai.2018/512},
  url       = {https://doi.org/10.24963/ijcai.2018/512},
}

@inproceedings{wu_star,
author={Wu, Bo and Yu, Shoubin and Chen, Zhenfang and Tenenbaum, Joshua B and Gan, Chuang},
title = {{STAR}: A Benchmark for Situated Reasoning in Real-World Videos},
booktitle = {Thirty-fifth Conference on Neural Information Processing Systems (NeurIPS)},
year = {2021}
}

@inproceedings{youtube2text,
  title={Youtube2text: Recognizing and describing arbitrary activities using semantic hierarchies and zero-shot recognition},
  author={Guadarrama, Sergio and Krishnamoorthy, Niveda and Malkarnenkar, Girish and Venugopalan, Subhashini and Mooney, Raymond and Darrell, Trevor and Saenko, Kate},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2712--2719},
  year={2013}
}

@article{Videocontextqa,
  title={Uncovering the temporal context for video question answering},
  author={Zhu, Linchao and Xu, Zhongwen and Yang, Yi and Hauptmann, Alexander G},
  journal={International Journal of Computer Vision},
  volume={124},
  pages={409--421},
  year={2017},
  publisher={Springer}
}
@inproceedings{socialiq,
  title={Social-iq: A question answering benchmark for artificial social intelligence},
  author={Zadeh, Amir and Chan, Michael and Liang, Paul Pu and Tong, Edmund and Morency, Louis-Philippe},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8807--8817},
  year={2019}
}

@article{clevrer,
  title={Clevrer: Collision events for video representation and reasoning},
  author={Yi, Kexin and Gan, Chuang and Li, Yunzhu and Kohli, Pushmeet and Wu, Jiajun and Torralba, Antonio and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:1910.01442},
  year={2019}
}

@article{clevrerhumans,
  title={CLEVRER-Humans: Describing Physical and Causal Events the Human Way},
  author={Mao, Jiayuan and Yang, Xuelin and Zhang, Xikun and Goodman, Noah and Wu, Jiajun},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={7755--7768},
  year={2022}
}
@inproceedings{agqa,
  title={Agqa: A benchmark for compositional spatio-temporal reasoning},
  author={Grunde-McLaughlin, Madeleine and Krishna, Ranjay and Agrawala, Maneesh},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11287--11297},
  year={2021}
}
@inproceedings{bleu,
  title={Bleu: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{meteor,
  title={METEOR: An automatic metric for MT evaluation with improved correlation with human judgments},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization},
  pages={65--72},
  year={2005}
}

@inproceedings{rouge,
  title={Rouge: A package for automatic evaluation of summaries},
  author={Lin, Chin-Yew},
  booktitle={Text summarization branches out},
  pages={74--81},
  year={2004}
}

@inproceedings{spice,
  title={Spice: Semantic propositional image caption evaluation},
  author={Anderson, Peter and Fernando, Basura and Johnson, Mark and Gould, Stephen},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part V 14},
  pages={382--398},
  year={2016},
  organization={Springer}
}
@inproceedings{cider,
  title={Cider: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4566--4575},
  year={2015}
}
@article{sentencebert,
  title={Sentence-bert: Sentence embeddings using siamese bert-networks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

@article{wups,
  title={A multi-world approach to question answering about real-world scenes based on uncertain input},
  author={Malinowski, Mateusz and Fritz, Mario},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{clipcap,
  title={ClipCap: CLIP Prefix for Image Captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}

@InProceedings{causalvidqa,
    author    = {Li, Jiangtong and Niu, Li and Zhang, Liqing},
    title     = {From Representation to Reasoning: Towards both Evidence and Commonsense Reasoning for Video Question-Answering},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022}
}

@InProceedings{intentqa,
    author    = {Li, Jiapeng and Wei, Ping and Han, Wenjuan and Fan, Lifeng},
    title     = {IntentQA: Context-aware Video Intent Reasoning},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {11963-11974}
}

@book{principles_animations,
  author    = "Thomas, Frank and Johnston, Ollie",
  title     = "The illusion of life : Disney animation",
  publisher = "Disney Editions",
  year      = "1981",
  URL       = "https://ci.nii.ac.jp/ncid/BB19687341"
}

@article{gpt4,
  title={GPT-4 Technical Report}, 
  author={OpenAI, team},
  year={2023},
  journal={arXiv preprint arXiv:2303.08774},
}

@inproceedings{pavlakos2022human,
  title={Human mesh recovery from multiple shots},
  author={Pavlakos, Georgios and Malik, Jitendra and Kanazawa, Angjoo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1485--1495},
  year={2022}
}

@article{zhong2022video,
  title={Video question answering: Datasets, algorithms and challenges},
  author={Zhong, Yaoyao and Xiao, Junbin and Ji, Wei and Li, Yicong and Deng, Weihong and Chua, Tat-Seng},
  journal={arXiv preprint arXiv:2203.01225},
  year={2022}
}

@article{sun2023alpha,
  title={Alpha-CLIP: A clip model focusing on wherever you want},
  author={Sun, Zeyi and Fang, Ye and Wu, Tong and Zhang, Pan and Zang, Yuhang and Kong, Shu and Xiong, Yuanjun and Lin, Dahua and Wang, Jiaqi},
  journal={arXiv preprint arXiv:2312.03818},
  year={2023}
}

@inproceedings{ding2023open,
  title={Open-vocabulary universal image segmentation with MaskCLIP},
  author={Ding, Zheng and Wang, Jieke and Tu, Zhuowen},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  pages={8090--8102},
  year={2023}
}

@inproceedings{xu2023open,
  title={Open-vocabulary panoptic segmentation with text-to-image diffusion models},
  author={Xu, Jiarui and Liu, Sifei and Vahdat, Arash and Byeon, Wonmin and Wang, Xiaolong and De Mello, Shalini},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2955--2966},
  year={2023}
}

@inproceedings{xu2023side,
  title={Side adapter network for open-vocabulary semantic segmentation},
  author={Xu, Mengde and Zhang, Zheng and Wei, Fangyun and Hu, Han and Bai, Xiang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2945--2954},
  year={2023}
}

@misc{tom_and_jerry_wiki, 
title={Tom and Jerry Wiki Fandom},
url={https://tomandjerry.fandom.com/wiki/Tom_and_Jerry_Wiki}, 
journal={Tom and Jerry Wiki Fandom}, 
author={Tom and Jerry Wiki Fandom}
} 

@inproceedings{he2016human,
  title={Human action recognition without human},
  author={He, Yun and Shirakabe, Soma and Satoh, Yutaka and Kataoka, Hirokatsu},
  booktitle={Computer Vision--ECCV 2016 Workshops: Amsterdam, The Netherlands, October 8-10 and 15-16, 2016, Proceedings, Part III 14},
  pages={11--17},
  year={2016},
  organization={Springer}
}

@article{barbu2019objectnet,
  title={Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models},
  author={Barbu, Andrei and Mayo, David and Alverio, Julian and Luo, William and Wang, Christopher and Gutfreund, Dan and Tenenbaum, Josh and Katz, Boris},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{li2024dawn,
  title={The dawn after the dark: An empirical study on factuality hallucination in large language models},
  author={Li, Junyi and Chen, Jie and Ren, Ruiyang and Cheng, Xiaoxue and Zhao, Wayne Xin and Nie, Jian-Yun and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2401.03205},
  year={2024}
}

@article{liu2024survey,
  title={A survey on hallucination in large vision-language models},
  author={Liu, Hanchao and Xue, Wenyuan and Chen, Yifei and Chen, Dapeng and Zhao, Xiutian and Wang, Ke and Hou, Liping and Li, Rongjun and Peng, Wei},
  journal={arXiv preprint arXiv:2402.00253},
  year={2024}
}

@article{zhou2023explore,
  title={Explore Spurious Correlations at the Concept Level in Language Models for Text Classification},
  author={Zhou, Yuhang and Xu, Paiheng and Liu, Xiaoyu and An, Bang and Ai, Wei and Huang, Furong},
  journal={arXiv preprint arXiv:2311.08648},
  year={2023}
}

@article{liu2024large,
  title={Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey},
  author={Liu, Xiaoyu and Xu, Paiheng and Wu, Junda and Yuan, Jiaxin and Yang, Yifan and Zhou, Yuhang and Liu, Fuxiao and Guan, Tianrui and Wang, Haoliang and Yu, Tong and others},
  journal={arXiv preprint arXiv:2403.09606},
  year={2024}
}

@article{wong2015data,
  title={Data association for semantic world modeling from partial views},
  author={Wong, Lawson LS and Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
  journal={International Journal of Robotics Research},
  volume={34},
  number={7},
  pages={1064--1082},
  year={2015},
  publisher={Sage Publications, Inc. Thousand Oaks, CA, USA}
}


@misc{gpt4o,
    author = "{OpenAI}",
    title = "Hello GPT-4o",
    year = "2024",
    howpublished = "\url{https://openai.com/index/hello-gpt-4o/}",
    note = "[Online; accessed 31-May-2024]"
}
