\begin{thebibliography}{86}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aggarwal(2017)]{aggarwal2017introduction}
Charu~C Aggarwal.
\newblock An introduction to outlier analysis.
\newblock In \emph{Outlier analysis}, pages 1--34. Springer, 2017.

\bibitem[Alvarez et~al.(2022)Alvarez, Verdier, Nkashama, Frappier, Tardif, and Kabanza]{alvarez2022revealing}
Maxime Alvarez, Jean-Charles Verdier, D'Jeff~K Nkashama, Marc Frappier, Pierre-Martin Tardif, and Froduald Kabanza.
\newblock A revealing large-scale evaluation of unsupervised anomaly detection algorithms.
\newblock \emph{arXiv preprint arXiv:2204.09825}, 2022.

\bibitem[Baxter(2000)]{baxter2000model}
Jonathan Baxter.
\newblock A model of inductive bias learning.
\newblock \emph{Journal of artificial intelligence research}, 12:\penalty0 149--198, 2000.

\bibitem[Bergman and Hoshen(2020)]{bergman2020classification}
Liron Bergman and Yedid Hoshen.
\newblock Classification-based anomaly detection for general data.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Bergmann et~al.(2019)Bergmann, Fauser, Sattlegger, and Steger]{bergmann2019mvtec}
Paul Bergmann, Michael Fauser, David Sattlegger, and Carsten Steger.
\newblock Mvtec ad--a comprehensive real-world dataset for unsupervised anomaly detection.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 9592--9600, 2019.

\bibitem[Breunig et~al.(2000)Breunig, Kriegel, Ng, and Sander]{breunig2000lof}
Markus~M Breunig, Hans-Peter Kriegel, Raymond~T Ng, and J{\"o}rg Sander.
\newblock Lof: identifying density-based local outliers.
\newblock In \emph{Proceedings of the 2000 ACM SIGMOD international conference on Management of data}, pages 93--104, 2000.

\bibitem[Chefer et~al.(2021)Chefer, Gur, and Wolf]{chefer2021generic}
Hila Chefer, Shir Gur, and Lior Wolf.
\newblock Generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 397--406, 2021.

\bibitem[Chen et~al.(2022)Chen, Bondi, and Das]{chen2022learning}
Bingqing Chen, Luca Bondi, and Samarjit Das.
\newblock Learning to adapt to domain shifts with few-shot samples in anomalous sound detection.
\newblock In \emph{2022 26th International Conference on Pattern Recognition (ICPR)}, pages 133--139. IEEE, 2022.

\bibitem[Chen and Konukoglu(2018)]{chen2018unsupervised}
Xiaoran Chen and Ender Konukoglu.
\newblock Unsupervised detection of lesions in brain mri using constrained adversarial auto-encoders.
\newblock In \emph{MIDL Conference book}. MIDL, 2018.

\bibitem[Choi et~al.(2022)Choi, Yang, Choi, and Yun]{choi2022improving}
Sungha Choi, Seunghan Yang, Seokeon Choi, and Sungrack Yun.
\newblock Improving test-time adaptation via shift-agnostic weight regularization and nearest source prototypes.
\newblock In \emph{Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXIII}, pages 440--458. Springer, 2022.

\bibitem[Cohen et~al.(2017)Cohen, Afshar, Tapson, and Van~Schaik]{cohen2017emnist}
Gregory Cohen, Saeed Afshar, Jonathan Tapson, and Andre Van~Schaik.
\newblock Emnist: Extending mnist to handwritten letters.
\newblock In \emph{2017 international joint conference on neural networks (IJCNN)}, pages 2921--2926. IEEE, 2017.

\bibitem[Cohen and Hoshen(2020)]{cohen2020sub}
Niv Cohen and Yedid Hoshen.
\newblock Sub-image anomaly detection with deep pyramid correspondences.
\newblock \emph{arXiv preprint arXiv:2005.02357}, 2020.

\bibitem[Deecke et~al.(2018)Deecke, Vandermeulen, Ruff, Mandt, and Kloft]{deecke2018image}
Lucas Deecke, Robert Vandermeulen, Lukas Ruff, Stephan Mandt, and Marius Kloft.
\newblock Image anomaly detection with generative adversarial networks.
\newblock In \emph{Joint european conference on machine learning and knowledge discovery in databases}, pages 3--17. Springer, 2018.

\bibitem[Deecke et~al.(2021)Deecke, Ruff, Vandermeulen, and Bilen]{deecke2021transfer}
Lucas Deecke, Lukas Ruff, Robert~A Vandermeulen, and Hakan Bilen.
\newblock Transfer-based semantic anomaly detection.
\newblock In \emph{International Conference on Machine Learning}, pages 2546--2558. PMLR, 2021.

\bibitem[Defard et~al.(2021)Defard, Setkov, Loesch, and Audigier]{defard2021padim}
Thomas Defard, Aleksandr Setkov, Angelique Loesch, and Romaric Audigier.
\newblock Padim: a patch distribution modeling framework for anomaly detection and localization.
\newblock In \emph{Pattern Recognition. ICPR International Workshops and Challenges: Virtual Event, January 10--15, 2021, Proceedings, Part IV}, pages 475--489. Springer, 2021.

\bibitem[Ding et~al.(2021)Ding, Zhou, Tong, and Liu]{Ding2021FewshotNA}
Kaize Ding, Qinghai Zhou, Hanghang Tong, and Huan Liu.
\newblock Few-shot network anomaly detection via cross-network meta-learning.
\newblock \emph{Proceedings of the Web Conference 2021}, 2021.

\bibitem[Dragoi et~al.(2022)Dragoi, Burceanu, Haller, Manolache, and Brad]{dragoianoshift}
Marius Dragoi, Elena Burceanu, Emanuela Haller, Andrei Manolache, and Florin Brad.
\newblock Anoshift: A distribution shift benchmark for unsupervised anomaly detection.
\newblock In \emph{Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track}, 2022.

\bibitem[Esmaeilpour et~al.(2022)Esmaeilpour, Liu, Robertson, and Shu]{esmaeilpour2022zero}
Sepideh Esmaeilpour, Bing Liu, Eric Robertson, and Lei Shu.
\newblock Zero-shot out-of-distribution detection based on the pretrained model clip.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, 2022.

\bibitem[Fallah et~al.(2021)Fallah, Mokhtari, and Ozdaglar]{fallah2021generalization}
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar.
\newblock Generalization of model-agnostic meta-learning algorithms: Recurring and unseen tasks.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 5469--5480, 2021.

\bibitem[Feng et~al.(2021)Feng, Qi, Wang, and Liao]{Feng2021FewShotCA}
Tongtong Feng, Q.~Qi, Jingyu Wang, and Jianxin Liao.
\newblock Few-shot class-adaptive anomaly detection with model-agnostic meta-learning.
\newblock \emph{2021 IFIP Networking Conference (IFIP Networking)}, pages 1--9, 2021.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International conference on machine learning}, pages 1126--1135. PMLR, 2017.

\bibitem[Frikha et~al.(2021)Frikha, Krompaß, Köpken, and Tresp]{ocmaml2021}
Ahmed Frikha, Denis Krompaß, Hans-Georg Köpken, and Volker Tresp.
\newblock Few-shot one-class classification via meta-learning.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, 35\penalty0 (8):\penalty0 7448--7456, May 2021.

\bibitem[Golan and El-Yaniv(2018)]{golan2018deep}
Izhak Golan and Ran El-Yaniv.
\newblock Deep anomaly detection using geometric transformations.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages 9758--9769, 2018.

\bibitem[Goodge et~al.(2022)Goodge, Hooi, Ng, and Ng]{goodge2022lunar}
Adam Goodge, Bryan Hooi, See-Kiong Ng, and Wee~Siong Ng.
\newblock Lunar: Unifying local outlier detection methods via graph neural networks.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~36, pages 6737--6745, 2022.

\bibitem[Gupta et~al.(2013)Gupta, Gao, Aggarwal, and Han]{gupta2013outlier}
Manish Gupta, Jing Gao, Charu~C Aggarwal, and Jiawei Han.
\newblock Outlier detection for temporal data: A survey.
\newblock \emph{IEEE Transactions on Knowledge and data Engineering}, 26\penalty0 (9):\penalty0 2250--2267, 2013.

\bibitem[Han et~al.(2022)Han, Hu, Huang, Jiang, and Zhao]{hanadbench}
Songqiao Han, Xiyang Hu, Hailiang Huang, Minqi Jiang, and Yue Zhao.
\newblock Adbench: Anomaly detection benchmark.
\newblock In \emph{Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track}, 2022.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 770--778, 2016.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and Girshick]{he2022masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 16000--16009, 2022.

\bibitem[Hendrycks and Dietterich(2019)]{hendrycks2018benchmarking}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and perturbations.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Hendrycks et~al.(2018)Hendrycks, Mazeika, and Dietterich]{hendrycks2018deep}
Dan Hendrycks, Mantas Mazeika, and Thomas Dietterich.
\newblock Deep anomaly detection with outlier exposure.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Mazeika, Kadavath, and Song]{hendrycks2019using}
Dan Hendrycks, Mantas Mazeika, Saurav Kadavath, and Dawn Song.
\newblock Using self-supervised learning can improve model robustness and uncertainty.
\newblock \emph{Advances in Neural Information Processing Systems}, 32:\penalty0 15663--15674, 2019.

\bibitem[Huang et~al.(2022)Huang, Guan, Jiang, Zhang, Spratling, and Wang]{huang2022registration}
Chaoqin Huang, Haoyan Guan, Aofan Jiang, Ya~Zhang, Michael Spratling, and Yan-Feng Wang.
\newblock Registration based few-shot anomaly detection.
\newblock In \emph{Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XXIV}, pages 303--319. Springer, 2022.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and Weinberger]{huang2017densely}
Gao Huang, Zhuang Liu, Laurens Van Der~Maaten, and Kilian~Q Weinberger.
\newblock Densely connected convolutional networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 4700--4708, 2017.

\bibitem[Huynh et~al.(2017)Huynh, Ng, and Ariyapala]{huynh2017new}
Ngoc~Anh Huynh, Wee~Keong Ng, and Kanishka Ariyapala.
\newblock A new adaptive learning algorithm and its application to online malware detection.
\newblock In \emph{International Conference on Discovery Science}, pages 18--32. Springer, 2017.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing internal covariate shift.
\newblock In \emph{International conference on machine learning}, pages 448--456. pmlr, 2015.

\bibitem[Jeong et~al.(2023)Jeong, Zou, Kim, Zhang, Ravichandran, and Dabeer]{jeong2023winclip}
Jongheon Jeong, Yang Zou, Taewan Kim, Dongqing Zhang, Avinash Ravichandran, and Onkar Dabeer.
\newblock Winclip: Zero-/few-shot anomaly classification and segmentation.
\newblock 2023.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and Duerig]{jia2021scaling}
Chao Jia, Yinfei Yang, Ye~Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with noisy text supervision.
\newblock In \emph{International Conference on Machine Learning}, pages 4904--4916. PMLR, 2021.

\bibitem[Kouw and Loog(2019)]{kouw2019review}
Wouter~M Kouw and Marco Loog.
\newblock A review of domain adaptation without target labels.
\newblock \emph{IEEE transactions on pattern analysis and machine intelligence}, 43\penalty0 (3):\penalty0 766--785, 2019.

\bibitem[Kozerawski and Turk(2018)]{Kozerawski2018CLEARCL}
Jedrzej Kozerawski and Matthew~A. Turk.
\newblock Clear: Cumulative learning for one-shot one-class image recognition.
\newblock \emph{2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 3446--3455, 2018.

\bibitem[Kruspe(2019)]{Kruspe2019OneWayPN}
Anna Kruspe.
\newblock One-way prototypical networks.
\newblock \emph{ArXiv}, abs/1906.00820, 2019.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and Tenenbaum]{lake2015human}
Brenden~M Lake, Ruslan Salakhutdinov, and Joshua~B Tenenbaum.
\newblock Human-level concept learning through probabilistic program induction.
\newblock \emph{Science}, 350\penalty0 (6266):\penalty0 1332--1338, 2015.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and Haffner]{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0 2278--2324, 1998.

\bibitem[Li et~al.(2021{\natexlab{a}})Li, Boyd, Smyth, and Mandt]{li2021detecting}
Aodong Li, Alex Boyd, Padhraic Smyth, and Stephan Mandt.
\newblock Detecting and adapting to irregular distribution shifts in bayesian online learning.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 6816--6828, 2021{\natexlab{a}}.

\bibitem[Li et~al.(2023)Li, Qiu, Kloft, Smyth, Mandt, and Rudolph]{li2023deep}
Aodong Li, Chen Qiu, Marius Kloft, Padhraic Smyth, Stephan Mandt, and Maja Rudolph.
\newblock Deep anomaly detection under labeling budget constraints.
\newblock In \emph{International Conference on Machine Learning}, pages 19882--19910. PMLR, 2023.

\bibitem[Li et~al.(2021{\natexlab{b}})Li, Sohn, Yoon, and Pfister]{li2021cutpaste}
Chun-Liang Li, Kihyuk Sohn, Jinsung Yoon, and Tomas Pfister.
\newblock Cutpaste: Self-supervised learning for anomaly detection and localization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 9664--9674, 2021{\natexlab{b}}.

\bibitem[Li et~al.(2018)Li, Yang, Song, and Hospedales]{li2018learning}
Da~Li, Yongxin Yang, Yi-Zhe Song, and Timothy Hospedales.
\newblock Learning to generalize: Meta-learning for domain generalization.
\newblock In \emph{Proceedings of the AAAI conference on artificial intelligence}, volume~32, 2018.

\bibitem[Li et~al.(2020)Li, Zhao, Botta, Ionescu, and Hu]{li2020copod}
Zheng Li, Yue Zhao, Nicola Botta, Cezar Ionescu, and Xiyang Hu.
\newblock Copod: copula-based outlier detection.
\newblock In \emph{2020 IEEE international conference on data mining (ICDM)}, pages 1118--1123. IEEE, 2020.

\bibitem[Li et~al.(2022)Li, Zhao, Hu, Botta, Ionescu, and Chen]{li2022ecod}
Zheng Li, Yue Zhao, Xiyang Hu, Nicola Botta, Cezar Ionescu, and George Chen.
\newblock Ecod: Unsupervised outlier detection using empirical cumulative distribution functions.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering}, 2022.

\bibitem[Lim et~al.(2023)Lim, Kim, Choo, and Choi]{limttn}
Hyesu Lim, Byeonggeun Kim, Jaegul Choo, and Sungha Choi.
\newblock Ttn: A domain-shift aware batch normalization in test-time adaptation.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[Liu et~al.(2012)Liu, Ting, and Zhou]{liu2012isolation}
Fei~Tony Liu, Kai~Ming Ting, and Zhi-Hua Zhou.
\newblock Isolation-based anomaly detection.
\newblock \emph{ACM Transactions on Knowledge Discovery from Data (TKDD)}, 6\penalty0 (1):\penalty0 1--39, 2012.

\bibitem[Liznerski et~al.(2022)Liznerski, Ruff, Vandermeulen, Franks, Muller, and Kloft]{liznerski2022exposing}
Philipp Liznerski, Lukas Ruff, Robert~A Vandermeulen, Billy~Joe Franks, Klaus~Robert Muller, and Marius Kloft.
\newblock Exposing outlier exposure: What can be learned from few, one, and zero outlier images.
\newblock \emph{Transactions on Machine Learning Research}, 2022.

\bibitem[Lu et~al.(2020)Lu, Yu, Reddy, and Wang]{Lu2020FewshotSA}
Yiwei Lu, Frank Yu, Mahesh Kumar~Krishna Reddy, and Yang Wang.
\newblock Few-shot scene-adaptive anomaly detection.
\newblock In \emph{ECCV}, 2020.

\bibitem[Nado et~al.(2020)Nado, Padhy, Sculley, D'Amour, Lakshminarayanan, and Snoek]{nado2020evaluating}
Zachary Nado, Shreyas Padhy, D~Sculley, Alexander D'Amour, Balaji Lakshminarayanan, and Jasper Snoek.
\newblock Evaluating prediction-time batch normalization for robustness under covariate shift.
\newblock \emph{arXiv preprint arXiv:2006.10963}, 2020.

\bibitem[Nichol et~al.(2018)Nichol, Achiam, and Schulman]{nichol2018first}
Alex Nichol, Joshua Achiam, and John Schulman.
\newblock On first-order meta-learning algorithms.
\newblock \emph{arXiv preprint arXiv:1803.02999}, 2018.

\bibitem[Principi et~al.(2017)Principi, Vesperini, Squartini, and Piazza]{principi2017acoustic}
Emanuele Principi, Fabio Vesperini, Stefano Squartini, and Francesco Piazza.
\newblock Acoustic novelty detection with adversarial autoencoders.
\newblock In \emph{2017 International Joint Conference on Neural Networks (IJCNN)}, pages 3324--3330. IEEE, 2017.

\bibitem[Qiu et~al.(2021)Qiu, Pfrommer, Kloft, Mandt, and Rudolph]{qiu2021neural}
Chen Qiu, Timo Pfrommer, Marius Kloft, Stephan Mandt, and Maja Rudolph.
\newblock Neural transformation learning for deep anomaly detection beyond images.
\newblock In \emph{International Conference on Machine Learning}, pages 8703--8714. PMLR, 2021.

\bibitem[Qiu et~al.(2022{\natexlab{a}})Qiu, Kloft, Mandt, and Rudolph]{ijcai2022p305}
Chen Qiu, Marius Kloft, Stephan Mandt, and Maja Rudolph.
\newblock Raising the bar in graph-level anomaly detection.
\newblock In \emph{Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, {IJCAI-22}}, pages 2196--2203, 2022{\natexlab{a}}.

\bibitem[Qiu et~al.(2022{\natexlab{b}})Qiu, Li, Kloft, Rudolph, and Mandt]{pmlr-v162-qiu22b}
Chen Qiu, Aodong Li, Marius Kloft, Maja Rudolph, and Stephan Mandt.
\newblock Latent outlier exposure for anomaly detection with contaminated data.
\newblock In Kamalika Chaudhuri, Stefanie Jegelka, Le~Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, \emph{Proceedings of the 39th International Conference on Machine Learning}, volume 162 of \emph{Proceedings of Machine Learning Research}, pages 18153--18167. PMLR, 17--23 Jul 2022{\natexlab{b}}.
\newblock URL \url{https://proceedings.mlr.press/v162/qiu22b.html}.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International Conference on Machine Learning}, pages 8748--8763. PMLR, 2021.

\bibitem[Radosavovic et~al.(2020)Radosavovic, Kosaraju, Girshick, He, and Doll{\'a}r]{radosavovic2020designing}
Ilija Radosavovic, Raj~Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
\newblock Designing network design spaces.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10428--10436, 2020.

\bibitem[Ramaswamy et~al.(2000)Ramaswamy, Rastogi, and Shim]{ramaswamy2000efficient}
Sridhar Ramaswamy, Rajeev Rastogi, and Kyuseok Shim.
\newblock Efficient algorithms for mining outliers from large data sets.
\newblock In \emph{Proceedings of the 2000 ACM SIGMOD international conference on Management of data}, pages 427--438, 2000.

\bibitem[Rippel et~al.(2021)Rippel, Mertens, and Merhof]{rippel2021modeling}
Oliver Rippel, Patrick Mertens, and Dorit Merhof.
\newblock Modeling the distribution of normal data in pre-trained deep features for anomaly detection.
\newblock In \emph{2020 25th International Conference on Pattern Recognition (ICPR)}, pages 6726--6733. IEEE, 2021.

\bibitem[Ruff et~al.(2018)Ruff, Vandermeulen, Goernitz, Deecke, Siddiqui, Binder, M{\"u}ller, and Kloft]{ruff2018deep}
Lukas Ruff, Robert Vandermeulen, Nico Goernitz, Lucas Deecke, Shoaib~Ahmed Siddiqui, Alexander Binder, Emmanuel M{\"u}ller, and Marius Kloft.
\newblock Deep one-class classification.
\newblock In \emph{International conference on machine learning}, pages 4393--4402. PMLR, 2018.

\bibitem[Ruff et~al.(2019)Ruff, Vandermeulen, G{\"o}rnitz, Binder, M{\"u}ller, M{\"u}ller, and Kloft]{ruff2019deep}
Lukas Ruff, Robert~A Vandermeulen, Nico G{\"o}rnitz, Alexander Binder, Emmanuel M{\"u}ller, Klaus-Robert M{\"u}ller, and Marius Kloft.
\newblock Deep semi-supervised anomaly detection.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Ruff et~al.(2021)Ruff, Kauffmann, Vandermeulen, Montavon, Samek, Kloft, Dietterich, and M{\"u}ller]{ruff2021unifying}
Lukas Ruff, Jacob~R Kauffmann, Robert~A Vandermeulen, Gr{\'e}goire Montavon, Wojciech Samek, Marius Kloft, Thomas~G Dietterich, and Klaus-Robert M{\"u}ller.
\newblock A unifying review of deep and shallow anomaly detection.
\newblock \emph{Proceedings of the IEEE}, 2021.

\bibitem[Schlegl et~al.(2017)Schlegl, Seeb{\"o}ck, Waldstein, Schmidt-Erfurth, and Langs]{schlegl2017unsupervised}
Thomas Schlegl, Philipp Seeb{\"o}ck, Sebastian~M Waldstein, Ursula Schmidt-Erfurth, and Georg Langs.
\newblock Unsupervised anomaly detection with generative adversarial networks to guide marker discovery.
\newblock In \emph{International conference on information processing in medical imaging}, pages 146--157. Springer, 2017.

\bibitem[Schneider et~al.(2020)Schneider, Rusak, Eck, Bringmann, Brendel, and Bethge]{schneider2020improving}
Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge.
\newblock Improving robustness against common corruptions by covariate shift adaptation.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 11539--11551, 2020.

\bibitem[Schneider et~al.(2022)Schneider, Qiu, Kloft, Latif, Staab, Mandt, and Rudolph]{schneider2022detecting}
Tim Schneider, Chen Qiu, Marius Kloft, Decky~Aspandi Latif, Steffen Staab, Stephan Mandt, and Maja Rudolph.
\newblock Detecting anomalies within time series using local neural transformations.
\newblock \emph{arXiv preprint arXiv:2202.03944}, 2022.

\bibitem[Sch{\"o}lkopf et~al.(1999)Sch{\"o}lkopf, Williamson, Smola, Shawe-Taylor, and Platt]{scholkopf1999support}
Bernhard Sch{\"o}lkopf, Robert~C Williamson, Alex Smola, John Shawe-Taylor, and John Platt.
\newblock Support vector method for novelty detection.
\newblock \emph{Advances in neural information processing systems}, 12, 1999.

\bibitem[Sch{\"o}lkopf et~al.(2001)Sch{\"o}lkopf, Platt, Shawe-Taylor, Smola, and Williamson]{scholkopf2001estimating}
Bernhard Sch{\"o}lkopf, John~C Platt, John Shawe-Taylor, Alex~J Smola, and Robert~C Williamson.
\newblock Estimating the support of a high-dimensional distribution.
\newblock \emph{Neural computation}, 13\penalty0 (7):\penalty0 1443--1471, 2001.

\bibitem[Schwartz et~al.(2022)Schwartz, Arbelle, Karlinsky, Harary, Scheidegger, Doveh, and Giryes]{schwartz2022maeday}
Eli Schwartz, Assaf Arbelle, Leonid Karlinsky, Sivan Harary, Florian Scheidegger, Sivan Doveh, and Raja Giryes.
\newblock Maeday: Mae for few and zero shot anomaly-detection.
\newblock \emph{arXiv preprint arXiv:2211.14307}, 2022.

\bibitem[Shenkar and Wolf(2021)]{shenkar2021anomaly}
Tom Shenkar and Lior Wolf.
\newblock Anomaly detection for tabular data with internal contrastive learning.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Sheynin et~al.(2021)Sheynin, Benaim, and Wolf]{Sheynin_2021_ICCV}
Shelly Sheynin, Sagie Benaim, and Lior Wolf.
\newblock A hierarchical transformation-discriminating generative model for few shot anomaly detection.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pages 8495--8504, October 2021.

\bibitem[Shulman(2019)]{shulman2019unsupervised}
Yaniv Shulman.
\newblock Unsupervised contextual anomaly detection using joint deep variational generative models.
\newblock \emph{arXiv preprint arXiv:1904.00548}, 2019.

\bibitem[Sohn et~al.(2020)Sohn, Li, Yoon, Jin, and Pfister]{sohn2020learning}
Kihyuk Sohn, Chun-Liang Li, Jinsung Yoon, Minho Jin, and Tomas Pfister.
\newblock Learning and evaluating representations for deep one-class classification.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Wang et~al.(2021)Wang, Shelhamer, Liu, Olshausen, and Darrell]{wangtent}
Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell.
\newblock Tent: Fully test-time adaptation by entropy minimization.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Wang et~al.(2022)Wang, Zhou, Wang, Lin, Shah, and Lim]{wangfew}
Ze~Wang, Yipin Zhou, Rui Wang, Tsung-Yu Lin, Ashish Shah, and Ser-Nam Lim.
\newblock Few-shot fast-adaptive anomaly detection.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Wu et~al.(2021)Wu, Chen, Fuh, and Liu]{Wu_2021_ICCV}
Jhih-Ciang Wu, Ding-Jie Chen, Chiou-Shann Fuh, and Tyng-Luh Liu.
\newblock Learning unsupervised metaformer for anomaly detection.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pages 4369--4378, October 2021.

\bibitem[Xian et~al.(2018)Xian, Lampert, Schiele, and Akata]{xian2018zero}
Yongqin Xian, Christoph~H Lampert, Bernt Schiele, and Zeynep Akata.
\newblock Zero-shot learning—a comprehensive evaluation of the good, the bad and the ugly.
\newblock \emph{IEEE transactions on pattern analysis and machine intelligence}, 41\penalty0 (9):\penalty0 2251--2265, 2018.

\bibitem[Xiao et~al.(2023)Xiao, Zhen, Liao, and Snoek]{xiaoenergy}
Zehao Xiao, Xiantong Zhen, Shengcai Liao, and Cees~GM Snoek.
\newblock Energy-based test sample adaptation for domain generalization.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[Yang et~al.(2021)Yang, Shi, and Ni]{yang2021medmnist}
Jiancheng Yang, Rui Shi, and Bingbing Ni.
\newblock Medmnist classification decathlon: A lightweight automl benchmark for medical image analysis.
\newblock In \emph{2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)}, pages 191--195. IEEE, 2021.

\bibitem[Yu et~al.(2022)Yu, Wang, Vasudevan, Yeung, Seyedhosseini, and Wu]{yu2022coca}
Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, and Yonghui Wu.
\newblock Coca: Contrastive captioners are image-text foundation models.
\newblock \emph{Transactions on Machine Learning Research}, 2022.

\bibitem[Yuan et~al.(2021)Yuan, Chen, Chen, Codella, Dai, Gao, Hu, Huang, Li, Li, et~al.]{yuan2021florence}
Lu~Yuan, Dongdong Chen, Yi-Ling Chen, Noel Codella, Xiyang Dai, Jianfeng Gao, Houdong Hu, Xuedong Huang, Boxin Li, Chunyuan Li, et~al.
\newblock Florence: A new foundation model for computer vision.
\newblock \emph{arXiv preprint arXiv:2111.11432}, 2021.

\bibitem[Zhang et~al.(2020)Zhang, Ye, Wang, and Habetler]{Zhang2020FewShotBA}
Shen Zhang, Fei Ye, Bingnan Wang, and Thomas~G. Habetler.
\newblock Few-shot bearing anomaly detection via model-agnostic meta-learning.
\newblock \emph{2020 23rd International Conference on Electrical Machines and Systems (ICEMS)}, pages 1341--1346, 2020.

\bibitem[Zhou and Paffenroth(2017)]{zhou2017anomaly}
Chong Zhou and Randy~C Paffenroth.
\newblock Anomaly detection with robust deep autoencoders.
\newblock In \emph{Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining}, pages 665--674, 2017.

\bibitem[Zhou et~al.(2021)Zhou, Loy, and Dai]{zhou2021denseclip}
Chong Zhou, Chen~Change Loy, and Bo~Dai.
\newblock Denseclip: Extract free dense labels from clip.
\newblock \emph{arXiv preprint arXiv:2112.01071}, 2021.

\end{thebibliography}
