\begin{thebibliography}{100}

\bibitem{von1947theory}
John Von~Neumann and Oskar Morgenstern.
\newblock Theory of games and economic behavior.
\newblock {\em Princeton University Press}, 1947.

\bibitem{nash1950equilibrium}
John~F Nash~Jr.
\newblock Equilibrium points in n-person games.
\newblock {\em Proceedings of the National Academy of sciences}, 36(1):48--49, 1950.

\bibitem{cesa2006prediction}
Nicolo Cesa-Bianchi and G{\'a}bor Lugosi.
\newblock {\em Prediction, learning, and games}.
\newblock Cambridge University press, 2006.

\bibitem{fudenberg1998theory}
Drew Fudenberg and David~K Levine.
\newblock {\em The theory of learning in games}, volume~2.
\newblock MIT Press, 1998.

\bibitem{brown1951iterative}
George~W Brown.
\newblock Iterative solution of games by fictitious play.
\newblock {\em Act. Anal. Prod Allocation}, 13(1):374, 1951.

\bibitem{robinson1951iterative}
Julia Robinson.
\newblock An iterative method of solving a game.
\newblock {\em Annals of mathematics}, pages 296--301, 1951.

\bibitem{ref:Fudenberg93}
Drew Fudenberg and David~M Kreps.
\newblock Learning mixed equilibria.
\newblock {\em Games and Economic Behavior}, 5:320--367, 1993.

\bibitem{monderer1996fictitious}
Dov Monderer and Lloyd~S Shapley.
\newblock Fictitious play property for games with identical interests.
\newblock {\em Journal of economic theory}, 68(1):258--265, 1996.

\bibitem{miyasawa1961convergence}
Koichi Miyasawa.
\newblock On the convergence of the learning process in a 2 x 2 non-zero-sum two-person game.
\newblock {\em Princeton University Press}, 1961.

\bibitem{berger2005fictitious}
Ulrich Berger.
\newblock Fictitious play in 2 x n games.
\newblock {\em Journal of Economic Theory}, 120(2):139--154, 2005.

\bibitem{sela1999fictitious}
Aner Sela.
\newblock Fictitious play in ``one-against-all'' multi-player games.
\newblock {\em Economic Theory}, 14(3):635--651, 1999.

\bibitem{ewerhart2020fictitious}
Christian Ewerhart and Kremena Valkanova.
\newblock Fictitious play in networks.
\newblock {\em Games and Economic Behavior}, 123:182--206, 2020.

\bibitem{shapley1953stochastic}
Lloyd~S Shapley.
\newblock Stochastic games.
\newblock {\em Proceedings of the national academy of sciences}, 39(10):1095--1100, 1953.

\bibitem{leslie2020best}
David~S Leslie, Steven Perkins, and Zibo Xu.
\newblock Best-response dynamics in zero-sum stochastic games.
\newblock {\em Journal of Economic Theory}, 189:105095, 2020.

\bibitem{sayin2021decentralized}
Muhammed Sayin, Kaiqing Zhang, David Leslie, Tamer Basar, and Asuman Ozdaglar.
\newblock Decentralized {Q}-learning in zero-sum {M}arkov games.
\newblock {\em NeurIPS}, 2021.

\bibitem{sayin2022fictitious}
Muhammed~O Sayin, Francesca Parise, and Asuman Ozdaglar.
\newblock Fictitious play in zero-sum stochastic games.
\newblock {\em SIAM Journal on Control and Optimization}, 60(4):2095--2114, 2022.

\bibitem{baudin2022fictitious}
Lucas Baudin and Rida Laraki.
\newblock Fictitious play and best-response dynamics in identical interest and zero-sum stochastic games.
\newblock {\em ICML}, 2022.

\bibitem{chen2023finite}
Zaiwei Chen, Kaiqing Zhang, Eric Mazumdar, Asuman Ozdaglar, and Adam Wierman.
\newblock A finite-sample analysis of payoff-based independent learning in zero-sum stochastic games.
\newblock {\em NeurIPS}, 2023.

\bibitem{sayin2022fictitiousb}
Muhammed~O Sayin, Kaiqing Zhang, and Asuman Ozdaglar.
\newblock Fictitious play in markov games with single controller.
\newblock {\em EC}, 2022.

\bibitem{daskalakis2009complexity}
Constantinos Daskalakis, Paul~W Goldberg, and Christos~H Papadimitriou.
\newblock The complexity of computing a nash equilibrium.
\newblock {\em SIAM Journal on Computing}, 39(1):195--259, 2009.

\bibitem{chen2009settling}
Xi~Chen, Xiaotie Deng, and Shang-Hua Teng.
\newblock Settling the complexity of computing two-player nash equilibria.
\newblock {\em Journal of the ACM (JACM)}, 56(3):1--57, 2009.

\bibitem{papadimitriou2008computing}
Christos~H Papadimitriou and Tim Roughgarden.
\newblock Computing correlated equilibria in multi-player games.
\newblock {\em Journal of the ACM (JACM)}, 55(3):1--29, 2008.

\bibitem{cai2011minmax}
Yang Cai and Constantinos Daskalakis.
\newblock On minmax theorems for multiplayer games.
\newblock {\em SODA}, 2011.

\bibitem{cai2016zero}
Yang Cai, Ozan Candogan, Constantinos Daskalakis, and Christos Papadimitriou.
\newblock Zero-sum polymatrix games: A generalization of minmax.
\newblock {\em Mathematics of Operations Research}, 41(2):648--655, 2016.

\bibitem{cao2013fashion}
Zhigang Cao, Haoyu Gao, Xinglong Qu, Mingmin Yang, and Xiaoguang Yang.
\newblock Fashion, cooperation, and social interactions.
\newblock {\em PLoS One}, 8(1):e49441, 2013.

\bibitem{cao2014fashion}
Zhigang Cao and Xiaoguang Yang.
\newblock The fashion game: Network extension of matching pennies.
\newblock {\em Theoretical Computer Science}, 540:169--181, 2014.

\bibitem{zhang2018fashion}
Boyu Zhang, Zhigang Cao, Cheng-Zhong Qin, and Xiaoguang Yang.
\newblock Fashion and homophily.
\newblock {\em Operations Research}, 66(6):1486--1497, 2018.

\bibitem{bergman1998separable}
L~M Bergman and I~N Fokin.
\newblock On separable non-cooperative zero-sum games.
\newblock {\em Optimization}, 44(1):69--84, 1998.

\bibitem{jin2022complexity}
Yujia Jin, Vidya Muthukumar, and Aaron Sidford.
\newblock The complexity of infinite-horizon general-sum stochastic games.
\newblock {\em ITCS}, 2022.

\bibitem{daskalakis2022complexity}
Constantinos Daskalakis, Noah Golowich, and Kaiqing Zhang.
\newblock The complexity of markov equilibrium in stochastic games.
\newblock {\em COLT}, 2023.

\bibitem{bergman1987methods}
L~M Bergman and I~N Fokin.
\newblock Methods of determining equilibrium situations in zero-sum polymatrix games.
\newblock {\em Optimizatsia}, 40(57):70--82, 1987.

\bibitem{papadimitriou1994complexity}
Christos~H Papadimitriou.
\newblock On the complexity of the parity argument and other inefficient proofs of existence.
\newblock {\em Journal of Computer and System Sciences}, 48(3):498--532, 1994.

\bibitem{flesch2007stochastic}
J{\'a}nos Flesch, Frank Thuijsman, and Okko~Jan Vrieze.
\newblock Stochastic games with additive transitions.
\newblock {\em European Journal of Operational Research}, 179(2):483--497, 2007.

\bibitem{filar2012competitive}
Jerzy Filar and Koos Vrieze.
\newblock {\em Competitive {M}arkov decision processes}.
\newblock Springer Science \& Business Media, 2012.

\bibitem{grossklags2008secure}
Jens Grossklags, Nicolas Christin, and John Chuang.
\newblock Secure or insure? a game-theoretic analysis of information security games.
\newblock {\em WWW}, 2008.

\bibitem{wilson1985game}
Robert Wilson.
\newblock Game-theoretic analysis of trading processes.
\newblock Technical report, Stanford University, 1985.

\bibitem{wilson1989game}
Robert Wilson.
\newblock Game theoretic analysis of trading.
\newblock In {\em Advances in Economic Theory: Fifth World Congress}, number~12, page~33. CUP Archive, 1989.

\bibitem{zhang2019economic}
Dayong Zhang, Lei Lei, Qiang Ji, and Ali~M Kutan.
\newblock Economic policy uncertainty in the us and china and their impact on the global markets.
\newblock {\em Economic Modelling}, 79:47--56, 2019.

\bibitem{beckley2018power}
Michael Beckley.
\newblock The power of nations: Measuring what matters.
\newblock {\em International Security}, 43(2):7--44, 2018.

\bibitem{freedman2010global}
Charles Freedman, Michael Kumhof, Douglas Laxton, Dirk Muir, and Susanna Mursula.
\newblock Global effects of fiscal stimulus during the crisis.
\newblock {\em Journal of monetary economics}, 57(5):506--526, 2010.

\bibitem{armingeon2012politics}
Klaus Armingeon.
\newblock The politics of fiscal responses to the crisis of 2008--2009.
\newblock {\em Governance}, 25(4):543--565, 2012.

\bibitem{gomes2022government}
F{\'a}bio Augusto~Reis Gomes, Sergio~Naruhiko Sakurai, and Gian~Paulo Soave.
\newblock Government spending multipliers in good times and bad times: The case of emerging markets.
\newblock {\em Macroeconomic Dynamics}, 26(3):726--768, 2022.

\bibitem{daskalakis2020independent}
Constantinos Daskalakis, Dylan~J Foster, and Noah Golowich.
\newblock Independent policy gradient methods for competitive reinforcement learning.
\newblock {\em NeurIPS}, 2020.

\bibitem{wei2021last}
Chen-Yu Wei, Chung-Wei Lee, Mengxiao Zhang, and Haipeng Luo.
\newblock Last-iterate convergence of decentralized optimistic gradient descent/ascent in infinite-horizon competitive {M}arkov games.
\newblock {\em COLT}, 2021.

\bibitem{zhao2021provably}
Yulai Zhao, Yuandong Tian, Jason~D Lee, and Simon~S Du.
\newblock Provably efficient policy gradient methods for two-player zero-sum markov games.
\newblock {\em AISTATS}, 2022.

\bibitem{chen2021sample}
Ziyi Chen, Shaocong Ma, and Yi~Zhou.
\newblock Sample efficient stochastic policy extragradient algorithm for zero-sum markov game.
\newblock {\em ICLR}, 2021.

\bibitem{cen2021fast}
Shicong Cen, Yuting Wei, and Yuejie Chi.
\newblock Fast policy extragradient methods for competitive games with entropy regularization.
\newblock {\em NeurIPS}, 2021.

\bibitem{alacaoglu2022natural}
Ahmet Alacaoglu, Luca Viano, Niao He, and Volkan Cevher.
\newblock A natural actor-critic framework for zero-sum markov games.
\newblock {\em ICML}, 2022.

\bibitem{zeng2022regularized}
Sihan Zeng, Thinh~T Doan, and Justin Romberg.
\newblock Regularized gradient descent ascent for two-player zero-sum markov games.
\newblock {\em NeurIPS}, 2022.

\bibitem{cen2022faster}
Shicong Cen, Yuejie Chi, Simon~S Du, and Lin Xiao.
\newblock Faster last-iterate convergence of policy optimization in zero-sum markov games.
\newblock {\em ICLR}, 2023.

\bibitem{babichenko2015can}
Yakov Babichenko, Christos Papadimitriou, and Aviad Rubinstein.
\newblock Can almost everybody be almost happy? pcp for ppad and the inapproximability of nash.
\newblock {\em arXiv preprint arXiv:1504.02411}, 2015.

\bibitem{benaim2005stochastic}
Michel Bena{\"\i}m, Josef Hofbauer, and Sylvain Sorin.
\newblock Stochastic approximations and differential inclusions.
\newblock {\em SIAM Journal on Control and Optimization}, 44(1):328--348, 2005.

\bibitem{ao2022asynchronous}
Ruicheng Ao, Shicong Cen, and Yuejie Chi.
\newblock Asynchronous gradient play in zero-sum multi-agent games.
\newblock {\em ICLR}, 2023.

\bibitem{anagnostides2022last}
Ioannis Anagnostides, Ioannis Panageas, Gabriele Farina, and Tuomas Sandholm.
\newblock On last-iterate convergence beyond zero-sum games.
\newblock {\em ICML}, 2022.

\bibitem{daskalakis2021near}
Constantinos Daskalakis, Maxwell Fishelson, and Noah Golowich.
\newblock Near-optimal no-regret learning in general games.
\newblock {\em NeurIPS}, 2021.

\bibitem{anagnostides2022uncoupled}
Ioannis Anagnostides, Gabriele Farina, Christian Kroer, Chung-Wei Lee, Haipeng Luo, and Tuomas Sandholm.
\newblock Uncoupled learning dynamics with $o(\backslash \log t)$ swap regret in multiplayer games.
\newblock {\em NeurIPS}, 2022.

\bibitem{farina2022near}
Gabriele Farina, Ioannis Anagnostides, Haipeng Luo, Chung-Wei Lee, Christian Kroer, and Tuomas Sandholm.
\newblock Near-optimal no-regret learning dynamics for general convex games.
\newblock {\em NeurIPS}, 2022.

\bibitem{mertikopoulos2018cycles}
Panayotis Mertikopoulos, Christos Papadimitriou, and Georgios Piliouras.
\newblock Cycles in adversarial regularized learning.
\newblock {\em SODA}, 2018.

\bibitem{daskalakis2018training}
Constantinos Daskalakis, Andrew Ilyas, Vasilis Syrgkanis, and Haoyang Zeng.
\newblock Training {GANs} with optimism.
\newblock {\em ICLR}, 2018.

\bibitem{daskalakis2018last}
Constantinos Daskalakis and Ioannis Panageas.
\newblock Last-iterate convergence: Zero-sum games and constrained min-max optimization.
\newblock {\em ITCS}, 2019.

\bibitem{bailey2018multiplicative}
James~P Bailey and Georgios Piliouras.
\newblock Multiplicative weights update in zero-sum games.
\newblock {\em EC}, 2018.

\bibitem{mertikopoulos2018optimistic}
Panayotis Mertikopoulos, Bruno Lecouat, Houssam Zenati, Chuan-Sheng Foo, Vijay Chandrasekhar, and Georgios Piliouras.
\newblock Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile.
\newblock {\em ICLR}, 2019.

\bibitem{cen2022independent}
Shicong Cen, Fan Chen, and Yuejie Chi.
\newblock Independent natural policy gradient methods for potential games: Finite-time global convergence with entropy regularization.
\newblock {\em CDC}, 2022.

\bibitem{pattathil2022symmetric}
Sarath Pattathil, Kaiqing Zhang, and Asuman Ozdaglar.
\newblock Symmetric (optimistic) natural policy gradient for multi-agent learning with parameter convergence.
\newblock {\em AISTATS}, 2023.

\bibitem{weilinear}
Chen-Yu Wei, Chung-Wei Lee, Mengxiao Zhang, and Haipeng Luo.
\newblock Linear last-iterate convergence in constrained saddle-point optimization.
\newblock {\em ICLR}, 2022.

\bibitem{arora2012multiplicative}
Sanjeev Arora, Elad Hazan, and Satyen Kale.
\newblock The multiplicative weights update method: {A} meta-algorithm and applications.
\newblock {\em Theory of Computing}, 8(1):121--164, 2012.

\bibitem{busoniu2008comprehensive}
Lucian Busoniu, Robert Babuska, and Bart De~Schutter.
\newblock A comprehensive survey of multiagent reinforcement learning.
\newblock {\em IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)}, 38(2):156--172, 2008.

\bibitem{zhang2021multi}
Kaiqing Zhang, Zhuoran Yang, and Tamer Ba{\c{s}}ar.
\newblock Multi-agent reinforcement learning: {A} selective overview of theories and algorithms.
\newblock {\em Handbook of Reinforcement Learning and Control}, pages 321--384, 2021.

\bibitem{littman1994markov}
Michael~L Littman.
\newblock Markov games as a framework for multi-agent reinforcement learning.
\newblock {\em Machine learning proceedings 1994}, pages 157--163, 1994.

\bibitem{littman2001friend}
Michael~L Littman et~al.
\newblock Friend-or-foe q-learning in general-sum games.
\newblock {\em ICML}, 2001.

\bibitem{littman2001value}
Michael~L Littman.
\newblock Value-function reinforcement learning in markov games.
\newblock {\em Cognitive systems research}, 2(1):55--66, 2001.

\bibitem{hu2003nash}
Junling Hu and Michael~P Wellman.
\newblock Nash q-learning for general-sum stochastic games.
\newblock {\em JMLR}, 2003.

\bibitem{bai2020provable}
Yu~Bai and Chi Jin.
\newblock Provable self-play algorithms for competitive reinforcement learning.
\newblock {\em ICML}, 2020.

\bibitem{sidford2020solving}
Aaron Sidford, Mengdi Wang, Lin Yang, and Yinyu Ye.
\newblock Solving discounted stochastic two-player games with near-optimal time and sample complexity.
\newblock {\em AISTATS}, 2020.

\bibitem{xie2020learning}
Qiaomin Xie, Yudong Chen, Zhaoran Wang, and Zhuoran Yang.
\newblock Learning zero-sum simultaneous-move markov games using function approximation and correlated equilibrium.
\newblock {\em COLT}, 2020.

\bibitem{bai2020near}
Yu~Bai, Chi Jin, and Tiancheng Yu.
\newblock Near-optimal reinforcement learning with self-play.
\newblock {\em NeurIPS}, 2020.

\bibitem{liu2021sharp}
Qinghua Liu, Tiancheng Yu, Yu~Bai, and Chi Jin.
\newblock A sharp analysis of model-based reinforcement learning with self-play.
\newblock {\em ICML}, 2021.

\bibitem{zhang2020model}
Kaiqing Zhang, Sham Kakade, Tamer Basar, and Lin Yang.
\newblock Model-based multi-agent rl in zero-sum markov games with near-optimal sample complexity.
\newblock {\em NeurIPS}, 2020.

\bibitem{li2022minimax}
Gen Li, Yuejie Chi, Yuting Wei, and Yuxin Chen.
\newblock Minimax-optimal multi-agent rl in {M}arkov games with a generative model.
\newblock {\em NeurIPS}, 2022.

\bibitem{subramanian2023robustness}
Jayakumar Subramanian, Amit Sinha, and Aditya Mahajan.
\newblock Robustness and sample complexity of model-based {MARL} for general-sum {Markov} games.
\newblock {\em Dynamic Games and Applications}, pages 1--33, 2023.

\bibitem{song2021can}
Ziang Song, Song Mei, and Yu~Bai.
\newblock When can we learn general-sum markov games with a large number of players sample-efficiently?
\newblock {\em ICLR}, 2021.

\bibitem{jin2021v}
Chi Jin, Qinghua Liu, Yuanhao Wang, and Tiancheng Yu.
\newblock V-learning--a simple, efficient, decentralized algorithm for multiagent {RL}.
\newblock {\em ICLR 2022 workshop ``Gamification and Multiagent Solutions''}, 2022.

\bibitem{mao2022improving}
Weichao Mao, Lin Yang, Kaiqing Zhang, and Tamer Basar.
\newblock On improving model-free algorithms for decentralized multi-agent reinforcement learning.
\newblock {\em ICML}, 2022.

\bibitem{mao2022provably}
Weichao Mao and Tamer Ba{\c{s}}ar.
\newblock Provably efficient reinforcement learning in decentralized general-sum {M}arkov games.
\newblock {\em Dynamic Games and Applications}, pages 1--22, 2022.

\bibitem{cui2023breaking}
Qiwen Cui, Kaiqing Zhang, and Simon~S Du.
\newblock Breaking the curse of multiagents in a large state space: {RL} in {M}arkov games with independent linear function approximation.
\newblock {\em COLT}, 2023.

\bibitem{wang2023breaking}
Yuanhao Wang, Qinghua Liu, Yu~Bai, and Chi Jin.
\newblock Breaking the curse of multiagency: {P}rovably efficient decentralized multi-agent {RL} with function approximation.
\newblock {\em COLT}, 2023.

\bibitem{erez2022regret}
Liad Erez, Tal Lancewicki, Uri Sherman, Tomer Koren, and Yishay Mansour.
\newblock Regret minimization and convergence to equilibria in general-sum markov games.
\newblock {\em ICML}, 2023.

\bibitem{rubinstein2017settling}
Aviad Rubinstein.
\newblock Settling the complexity of computing approximate two-player {N}ash equilibria.
\newblock {\em ACM SIGecom Exchanges}, 15(2):45--49, 2017.

\bibitem{daskalakis2022non}
Constantinos Daskalakis.
\newblock Non-concave games: A challenge for game theoryâ€™s next 100 years.
\newblock 2022.

\bibitem{jackson2015games}
Matthew~O Jackson and Yves Zenou.
\newblock Games on networks.
\newblock In {\em Handbook of game theory with economic applications}, volume~4, pages 95--163. Elsevier, 2015.

\bibitem{kearns2013graphical}
Michael Kearns, Michael~L Littman, and Satinder Singh.
\newblock Graphical models for game theory.
\newblock {\em UAI}, 2001.

\bibitem{kakade2003correlated}
Sham Kakade, Michael Kearns, John Langford, and Luis Ortiz.
\newblock Correlated equilibria in graphical games.
\newblock {\em EC}, 2003.

\bibitem{daskalakis2009network}
Constantinos Daskalakis and Christos~H Papadimitriou.
\newblock On a network generalization of the minmax theorem.
\newblock In {\em International Colloquium on Automata, Languages, and Programming}, pages 423--434. Springer, 2009.

\bibitem{leonardos2021exploration}
Stefanos Leonardos, Georgios Piliouras, and Kelly Spendlove.
\newblock Exploration-exploitation in multi-agent competition: convergence with bounded rationality.
\newblock {\em NeurIPS}, 2021.

\bibitem{zhang2018fully}
Kaiqing Zhang, Zhuoran Yang, Han Liu, Tong Zhang, and Tamer Ba\c{s}ar.
\newblock Fully decentralized multi-agent reinforcement learning with networked agents.
\newblock {\em ICML}, 2018.

\bibitem{zhang2018networked}
Kaiqing Zhang, Zhuoran Yang, and Tamer Basar.
\newblock Networked multi-agent reinforcement learning in continuous spaces.
\newblock {\em CDC}, 2018.

\bibitem{qu2022scalable}
Guannan Qu, Adam Wierman, and Na~Li.
\newblock Scalable reinforcement learning for multiagent networked systems.
\newblock {\em Operations Research}, 2022.

\bibitem{liu2022scalable}
Xin Liu, Honghao Wei, and Lei Ying.
\newblock Scalable and sample efficient distributed policy gradient algorithms in multi-agent networked systems.
\newblock {\em arXiv preprint arXiv:2212.06357}, 2022.

\bibitem{zhang2023global}
Yizhou Zhang, Guannan Qu, Pan Xu, Yiheng Lin, Zaiwei Chen, and Adam Wierman.
\newblock Global convergence of localized policy iteration in networked multi-agent reinforcement learning.
\newblock {\em Proceedings of the ACM on Measurement and Analysis of Computing Systems}, 7(1):1--51, 2023.

\bibitem{zhou2023convergence}
Zhaoyi Zhou, Zaiwei Chen, Yiheng Lin, and Adam Wierman.
\newblock Convergence rates for localized actor-critic in networked markov potential games.
\newblock {\em UAI}, 2023.

\bibitem{piliouras2022fast}
Georgios Piliouras, Lillian Ratliff, Ryann Sim, and Stratis Skoulakis.
\newblock Fast convergence of optimistic gradient ascent in network zero-sum extensive form games.
\newblock {\em SAGT}, 2022.

\bibitem{williams1991function}
Ronald~J Williams and Jing Peng.
\newblock Function optimization using connectionist reinforcement learning algorithms.
\newblock {\em Connection Science}, 3(3):241--268, 1991.

\bibitem{peters2010relative}
Jan Peters, Katharina Mulling, and Yasemin Altun.
\newblock Relative entropy policy search.
\newblock 2010.

\bibitem{neu2017unified}
Gergely Neu, Anders Jonsson, and Vicen{\c{c}} G{\'o}mez.
\newblock A unified view of entropy-regularized {M}arkov decision processes.
\newblock {\em NeurIPS}, 2017.

\bibitem{haarnoja2017reinforcement}
Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, and Sergey Levine.
\newblock Reinforcement learning with deep energy-based policies.
\newblock {\em ICML}, 2017.

\bibitem{mei2020global}
Jincheng Mei, Chenjun Xiao, Csaba Szepesvari, and Dale Schuurmans.
\newblock On the global convergence rates of softmax policy gradient methods.
\newblock {\em ICML}, 2020.

\bibitem{cen2022fast}
Shicong Cen, Chen Cheng, Yuxin Chen, Yuting Wei, and Yuejie Chi.
\newblock Fast global convergence of natural policy gradient methods with entropy regularization.
\newblock {\em Operations Research}, 70(4):2563--2578, 2022.

\bibitem{liu2023the}
Mingyang Liu, Asuman~E. Ozdaglar, Tiancheng Yu, and Kaiqing Zhang.
\newblock The power of regularization in solving extensive-form games.
\newblock {\em ICLR}, 2023.

\bibitem{sokota2023a}
Samuel Sokota, Ryan D'Orazio, J~Zico Kolter, Nicolas Loizou, Marc Lanctot, Ioannis Mitliagkas, Noam Brown, and Christian Kroer.
\newblock A unified approach to reinforcement learning, quantal response equilibria, and two-player zero-sum games.
\newblock {\em ICLR}, 2023.

\bibitem{shapley1964some}
Lloyd Shapley.
\newblock Some topics in two-person games.
\newblock {\em Advances in game theory}, 52:1--29, 1964.

\bibitem{sayin2022global}
Muhammed~O Sayin.
\newblock On the global convergence of stochastic fictitious play in stochastic games with turn-based controllers.
\newblock {\em CDC}, 2022.

\bibitem{ozdaglar2021independent}
Asuman Ozdaglar, Muhammed~O Sayin, and Kaiqing Zhang.
\newblock Independent learning in stochastic games.
\newblock {\em International Congress of Mathematicians}, 2022.

\bibitem{kalogiannis2023zero}
Fivos Kalogiannis and Ioannis Panageas.
\newblock Zero-sum polymatrix {M}arkov games: {E}quilibrium collapse and efficient computation of {N}ash equilibria.
\newblock {\em NeurIPS}, 2023.

\bibitem{mckelvey1995quantal}
Richard~D McKelvey and Thomas~R Palfrey.
\newblock Quantal response equilibria for normal form games.
\newblock {\em Games and economic behavior}, 10(1):6--38, 1995.

\bibitem{mckelvey1998quantal}
Richard~D McKelvey and Thomas~R Palfrey.
\newblock Quantal response equilibria for extensive form games.
\newblock {\em Experimental economics}, 1:9--41, 1998.

\bibitem{mertikopoulos2016learning}
Panayotis Mertikopoulos and William~H Sandholm.
\newblock Learning in games via reinforcement and regularization.
\newblock {\em Mathematics of Operations Research}, 41(4):1297--1324, 2016.

\bibitem{reeb2015tight}
David Reeb and Michael~M Wolf.
\newblock Tight bound on relative entropy by entropy difference.
\newblock {\em IEEE Transactions on Information Theory}, 61(3):1458--1473, 2015.

\bibitem{luo2022online}
Haipeng Luo.
\newblock Introduction to online optimization/learning (fall 2022), lecture note 1.

\bibitem{cai2023uncoupled}
Yang Cai, Haipeng Luo, Chen-Yu Wei, and Weiqiang Zheng.
\newblock Uncoupled and convergent learning in two-player zero-sum markov games.
\newblock {\em arXiv preprint arXiv:2303.02738}, 2023.

\end{thebibliography}
