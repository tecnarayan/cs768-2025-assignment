\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and Wagner]{best}
Athalye, A., Carlini, N., and Wagner, D.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{Proc.\ ICML}, pp.\  274--283, 2018.

\bibitem[Bartlett et~al.(2003)Bartlett, Jordan, and
  McAuliffe]{bartlett2003convexity}
Bartlett, P.~L., Jordan, M.~I., and McAuliffe, J.~D.
\newblock Convexity, classification, and risk bounds.
\newblock 2003.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{candw}
Carlini, N. and Wagner, D.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{2017 IEEE Symposium on Security and Privacy (SP)}, pp.\
  39--57. IEEE, 2017.

\bibitem[Carmon et~al.(2019)Carmon, Raghunathan, Schmidt, Duchi, and
  Liang]{carmon2019unlabeled}
Carmon, Y., Raghunathan, A., Schmidt, L., Duchi, J.~C., and Liang, P.~S.
\newblock Unlabeled data improves adversarial robustness.
\newblock In \emph{Proc.\ NeurIPS}, pp.\  11190--11201, 2019.

\bibitem[Cisse et~al.(2017)Cisse, Bojanowski, Grave, Dauphin, and
  Usunier]{parseval}
Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., and Usunier, N.
\newblock Parseval networks: Improving robustness to adversarial examples.
\newblock In \emph{Proc.\ ICML}, pp.\  854--863, 2017.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{cohen2019certified}
Cohen, J., Rosenfeld, E., and Kolter, Z.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock In \emph{Proc.\ ICML}, pp.\  1310--1320, 2019.

\bibitem[Corless et~al.(1996)Corless, Gonnet, Hare, Jeffrey, and
  Knuth]{Wfunction1}
Corless, R.~M., Gonnet, G.~H., Hare, D.~E., Jeffrey, D.~J., and Knuth, D.~E.
\newblock On the lambertw function.
\newblock \emph{Advances in Computational mathematics}, 5\penalty0
  (1):\penalty0 329--359, 1996.

\bibitem[Croce \& Hein(2020)Croce and Hein]{AutoAttack}
Croce, F. and Hein, M.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In \emph{Proc.\ ICML}, 2020.

\bibitem[Ding et~al.(2020)Ding, Sharma, Lui, and Huang]{MMA}
Ding, G.~W., Sharma, Y., Lui, K. Y.~C., and Huang, R.
\newblock Mma training: Direct input space margin maximization through
  adversarial training.
\newblock In \emph{Proc.\ ICLR}, 2020.

\bibitem[Dong et~al.(2022)Dong, Xu, Yang, Pang, Deng, Su, and
  Zhu]{dong2022exploring}
Dong, Y., Xu, K., Yang, X., Pang, T., Deng, Z., Su, H., and Zhu, J.
\newblock Exploring memorization in adversarial training.
\newblock In \emph{Proc.\ ICLR}, 2022.

\bibitem[Elkabetz \& Cohen(2021)Elkabetz and Cohen]{elkabetz2021continuous}
Elkabetz, O. and Cohen, N.
\newblock Continuous vs. discrete optimization of deep neural networks.
\newblock \emph{Proc.\ NeurIPS}, 34:\penalty0 4947--4960, 2021.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and Szegedy]{fgsm}
Goodfellow, I., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Gowal et~al.(2021)Gowal, Rebuffi, Wiles, Stimberg, Calian, and
  Mann]{gowal2021generated}
Gowal, S., Rebuffi, S.-A., Wiles, O., Stimberg, F., Calian, D.~A., and Mann, T.
\newblock Improving robustness using generated data.
\newblock \emph{arXiv preprint arXiv:2110.09468}, 2021.
\newblock URL \url{https://arxiv.org/pdf/2110.09468}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proc.\ CVPR}, pp.\  770--778, 2016.

\bibitem[Hitaj et~al.(2021)Hitaj, Pagnotta, Masi, and
  Mancini]{hitaj2021evaluating}
Hitaj, D., Pagnotta, G., Masi, I., and Mancini, L.~V.
\newblock Evaluating the robustness of geometry-aware instance-reweighted
  adversarial training.
\newblock \emph{arXiv preprint arXiv:2103.01914}, 2021.

\bibitem[Hoorfar \& Hassani(2007)Hoorfar and Hassani]{Wfunction2}
Hoorfar, A. and Hassani, M.
\newblock Approximation of the lambert w function and hyperpower function.
\newblock \emph{Research report collection}, 10\penalty0 (2), 2007.

\bibitem[Jordan \& Dimakis(2020)Jordan and Dimakis]{jordan2020exactly}
Jordan, M. and Dimakis, A.~G.
\newblock Exactly computing the local lipschitz constant of relu networks.
\newblock \emph{Proc.\ NeurIPS}, 33:\penalty0 7344--7353, 2020.

\bibitem[Kim et~al.(2021)Kim, Tack, Shin, and Hwang]{EWAT}
Kim, M., Tack, J., Shin, J., and Hwang, S.~J.
\newblock Entropy weighted adversarial training.
\newblock In \emph{ICML 2021 Workshop on Adversarial Machine Learning}, 2021.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and Hinton]{cifar}
Krizhevsky, A. and Hinton, G.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, 2009.

\bibitem[Kunin et~al.(2021)Kunin, Sagastuy-Brena, Ganguli, Yamins, and
  Tanaka]{kunin2020neural}
Kunin, D., Sagastuy-Brena, J., Ganguli, S., Yamins, D.~L., and Tanaka, H.
\newblock Neural mechanics: Symmetry and broken conservation laws in deep
  learning dynamics.
\newblock In \emph{Proc.\ ICLR}, 2021.

\bibitem[Kurakin et~al.(2016)Kurakin, Goodfellow, and Bengio]{pgd}
Kurakin, A., Goodfellow, I., and Bengio, S.
\newblock Adversarial machine learning at scale.
\newblock \emph{arXiv preprint arXiv:1611.01236}, 2016.

\bibitem[Lin(2002)]{lin2002support}
Lin, Y.
\newblock Support vector machines and the bayes rule in classification.
\newblock \emph{Data Mining and Knowledge Discovery}, 6\penalty0 (3):\penalty0
  259--275, 2002.

\bibitem[Liu et~al.(2021)Liu, Han, Liu, Gong, Niu, Zhou, Sugiyama,
  et~al.]{MAIL}
Liu, F., Han, B., Liu, T., Gong, C., Niu, G., Zhou, M., Sugiyama, M., et~al.
\newblock Probabilistic margins for instance reweighting in adversarial
  training.
\newblock \emph{Proc.\ NeurIPS}, 34, 2021.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and Vladu]{pgd2}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{Proc.\ ICLR}, 2018.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and Ng]{svhn}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In \emph{NIPS Workshop on Deep Learning and Unsupervised Feature
  Learning}, 2011.

\bibitem[Padhy et~al.(2020)Padhy, Nado, Ren, Liu, Snoek, and
  Lakshminarayanan]{padhy2020revisiting}
Padhy, S., Nado, Z., Ren, J., Liu, J., Snoek, J., and Lakshminarayanan, B.
\newblock Revisiting one-vs-all classifiers for predictive uncertainty and
  out-of-distribution detection in neural networks.
\newblock In \emph{ICML Workshop on Uncertainty and Robustness in Deep
  Learning}, 2020.

\bibitem[Rade(2021)]{rade2021pytorch}
Rade, R.
\newblock {PyTorch} implementation of uncovering the limits of adversarial
  training against norm-bounded adversarial examples, 2021.
\newblock URL \url{https://github.com/imrahulr/adversarial_robustness_pytorch}.

\bibitem[Rebuffi et~al.(2021)Rebuffi, Gowal, Calian, Stimberg, Wiles, and
  Mann]{rebuffi2021fixing}
Rebuffi, S.-A., Gowal, S., Calian, D.~A., Stimberg, F., Wiles, O., and Mann, T.
\newblock Fixing data augmentation to improve adversarial robustness.
\newblock \emph{arXiv preprint arXiv:2103.01946}, 2021.
\newblock URL \url{https://arxiv.org/pdf/2103.01946}.

\bibitem[Saito \& Saenko(2021)Saito and Saenko]{saito2021ovanet}
Saito, K. and Saenko, K.
\newblock Ovanet: One-vs-all network for universal domain adaptation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  9000--9009, 2021.

\bibitem[Sanyal et~al.(2021)Sanyal, Dokania, Kanade, and Torr]{sanyal2021how}
Sanyal, A., Dokania, P.~K., Kanade, V., and Torr, P.
\newblock How benign is benign overfitting?
\newblock In \emph{Proc.\ ICLR}, 2021.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  Madry]{schmidt2018adversarially}
Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., and Madry, A.
\newblock Adversarially robust generalization requires more data.
\newblock \emph{Proc.\ NeurIPS}, 31, 2018.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Tsuzuku et~al.(2018)Tsuzuku, Sato, and Sugiyama]{lmt}
Tsuzuku, Y., Sato, I., and Sugiyama, M.
\newblock Lipschitz-margin training: Scalable certification of perturbation
  invariance for deep neural networks.
\newblock In \emph{Proc.\ NeurIPS}, pp.\  6542--6551, 2018.

\bibitem[Uesato et~al.(2018)Uesato, O'Donoghue, Kohli, and van~den Oord]{SPSA}
Uesato, J., O'Donoghue, B., Kohli, P., and van~den Oord, A.
\newblock Adversarial risk and the dangers of evaluating against weak attacks.
\newblock In \emph{Proc.\ ICML}, volume~80, pp.\  5025--5034. PMLR, 2018.

\bibitem[Wang \& Wang(2022)Wang and Wang]{SEAT}
Wang, H. and Wang, Y.
\newblock Self-ensemble adversarial training for improved robustness.
\newblock In \emph{Proc.\ ICLR}, 2022.

\bibitem[Wang et~al.(2020{\natexlab{a}})Wang, Zou, Yi, Bailey, Ma, and
  Gu]{MART}
Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., and Gu, Q.
\newblock Improving adversarial robustness requires revisiting misclassified
  examples.
\newblock In \emph{Proc.\ ICLR}, 2020{\natexlab{a}}.

\bibitem[Wang et~al.(2020{\natexlab{b}})Wang, Zou, Yi, Bailey, Ma, and
  Gu]{Wang2020Improving}
Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., and Gu, Q.
\newblock Improving adversarial robustness requires revisiting misclassified
  examples.
\newblock In \emph{Proc.\ ICLR}, 2020{\natexlab{b}}.

\bibitem[Wu et~al.(2020)Wu, tao Xia, and Wang]{AWP}
Wu, D., tao Xia, S., and Wang, Y.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock In \emph{Proc.\ NeurIPS}, 2020.
\newblock URL \url{https://github.com/csdongxian/AWP}.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and Komodakis]{WRN}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock \emph{arXiv preprint arXiv:1605.07146}, 2016.

\bibitem[Zhang et~al.(2021{\natexlab{a}})Zhang, Cai, Lu, He, and
  Wang]{pmlr-v139-zhang21b}
Zhang, B., Cai, T., Lu, Z., He, D., and Wang, L.
\newblock Towards certifying l-infinity robustness using neural networks with
  l-inf-dist neurons.
\newblock In \emph{Proc.\ ICML}, volume 139, pp.\  12368--12379,
  2021{\natexlab{a}}.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, Ghaoui, and Jordan]{TRADES}
Zhang, H., Yu, Y., Jiao, J., Xing, E., Ghaoui, L.~E., and Jordan, M.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{Proc.\ ICML}, volume~97, pp.\  7472--7482. PMLR, 2019.

\bibitem[Zhang et~al.(2020)Zhang, Xu, Han, Niu, Cui, Sugiyama, and
  Kankanhalli]{FAT}
Zhang, J., Xu, X., Han, B., Niu, G., Cui, L., Sugiyama, M., and Kankanhalli, M.
\newblock Attacks which do not kill training make adversarial learning
  stronger.
\newblock 119:\penalty0 11278--11287, 2020.

\bibitem[Zhang et~al.(2021{\natexlab{b}})Zhang, Zhu, Niu, Han, Sugiyama, and
  Kankanhalli]{GAIRAT}
Zhang, J., Zhu, J., Niu, G., Han, B., Sugiyama, M., and Kankanhalli, M.
\newblock Geometry-aware instance-reweighted adversarial training.
\newblock In \emph{Proc.\ ICLR}, 2021{\natexlab{b}}.

\bibitem[Zhang(2004)]{SAForMC}
Zhang, T.
\newblock Statistical analysis of some multi-category large margin
  classification methods.
\newblock \emph{Journal of Machine Learning Research}, 5\penalty0
  (Oct):\penalty0 1225--1251, 2004.

\end{thebibliography}
