\begin{thebibliography}{20}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Auer(2003)]{Auer2003}
P.~Auer.
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock \emph{Journal of Machine Learning Research}, 3:\penalty0 397--422,
  2003.

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, and Fischer]{Auer2002}
P.~Auer, N.~Cesa-Bianchi, and P.~Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock \emph{Machine Learning}, 47\penalty0 (2-3):\penalty0 235--256, 2002.

\bibitem[Bogunovic et~al.(2016)Bogunovic, Scarlett, Krause, and
  Cevher]{Bogunovic2016}
I.~Bogunovic, J.~Scarlett, A.~Krause, and V.~Cevher.
\newblock Truncated variance reduction: A unified approach to bayesian
  optimization and level-set estimation.
\newblock In \emph{Proceedings of the 30th International Conference on Neural
  Information Processing Systems (NIPS)}, pages 1515--1523, USA, 2016.

\bibitem[Bull(2011)]{Bull2011}
A.D. Bull.
\newblock Convergence rates of efficient global optimization algorithms.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2879--2904,
  2011.

\bibitem[Dani et~al.(2008)Dani, Hayes, and Kakade]{Dani2008}
V.~Dani, T.P. Hayes, and S.M. Kakade.
\newblock Stochastic linear optimization under bandit feedback.
\newblock In \emph{COLT}, 2008.

\bibitem[Hennig and Schuler(2012)]{Hennig2012}
P.~Hennig and C.J. Schuler.
\newblock Entropy search for information-efficient global optimization.
\newblock \emph{Journal of Machine Learning Research}, 13\penalty0
  (1):\penalty0 1809--1837, 2012.

\bibitem[Henr\'{a}ndez-Lobato et~al.(2014)Henr\'{a}ndez-Lobato, Hoffman, and
  Ghahramani]{HenrandezLobato2014}
J.M. Henr\'{a}ndez-Lobato, M.W. Hoffman, and Z.~Ghahramani.
\newblock Predictive entropy search for efficient global optimization of
  black-box functions.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 918--926, 2014.

\bibitem[Jones(2001)]{Jones2001}
D.R. Jones.
\newblock A taxonomy of global optimization methods based on response surfaces.
\newblock \emph{Journal of Global Optimization}, 21\penalty0 (4):\penalty0
  345--383, 2001.

\bibitem[Jones et~al.(1998)Jones, Schonlau, and Welch]{Jones1998}
D.R. Jones, M.~Schonlau, and W.J. Welch.
\newblock Efficient global optimization of expensive black-box functions.
\newblock \emph{Journal of Global Optimization}, 13\penalty0 (4):\penalty0
  455--492, December 1998.

\bibitem[Kushner(1964)]{Kushner1964}
H.J. Kushner.
\newblock A new method of locating the maximum point of an arbitrary multipeak
  curve in the presence of noise.
\newblock \emph{Journal of Basic Engineering}, 86\penalty0 (1):\penalty0
  97--106, 1964.

\bibitem[Mo\u{c}kus et~al.(1978)Mo\u{c}kus, Tiesis, and
  \u{Z}ilinskas]{Mockus1978}
J.~Mo\u{c}kus, V.~Tiesis, and A.~\u{Z}ilinskas.
\newblock \emph{The application of Bayesian methods for seeking the extremum},
  volume~2 of \emph{Toward Global Optimization}.
\newblock Elsevier, 1978.

\bibitem[Nguyen et~al.(2017)Nguyen, Gupta, Rane, Li, and Venkatesh]{Nguyen2017}
V.~Nguyen, S.~Gupta, S.~Rane, C.~Li, and S.~Venkatesh.
\newblock Bayesian optimization in weakly specified search space.
\newblock In \emph{2017 IEEE International Conference on Data Mining (ICDM)},
  pages 347--356, 2017.

\bibitem[Pedregosa and et~al(2011)]{Pedregosa2011}
F.~Pedregosa and G.~Varoquaux et~al.
\newblock Scikit-learn: Machine learning in python.
\newblock \emph{The Journal of Machine Learning Research}, 12:\penalty0
  2825--2830, 2011.

\bibitem[Rasmussen and Williams(2006)]{Rasmussen2006}
C.E. Rasmussen and C.K.I. Williams.
\newblock \emph{Gaussian Processes for Machine Learning}.
\newblock The MIT Press, 2006.

\bibitem[Scarlett(2018)]{Scarlett18}
J.~Scarlett.
\newblock Tight regret bounds for {B}ayesian optimization in one dimension.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning (ICML)}, pages 4500--4508, Stockholmsm√§ssan, Stockholm, Sweden,
  2018.

\bibitem[Shahriari et~al.(2016{\natexlab{a}})Shahriari, Bouchard-Cote, and
  Freitas]{Shahriari16b}
B.~Shahriari, A.~Bouchard-Cote, and N.~De Freitas.
\newblock Unbounded bayesian optimization via regularization.
\newblock In \emph{Proceedings of the 19th International Conference on
  Artificial Intelligence and Statistics (AISTATS)}, volume~51, pages
  1168--1176, 2016{\natexlab{a}}.

\bibitem[Shahriari et~al.(2016{\natexlab{b}})Shahriari, Swersky, Wang, Adams,
  and de~Freitas]{Shahriari16a}
B.~Shahriari, K.~Swersky, Z.~Wang, R.~P. Adams, and N.~de~Freitas.
\newblock Taking the human out of the loop: A review of bayesian optimization.
\newblock \emph{Proceedings of the IEEE}, 104\penalty0 (1):\penalty0 148--175,
  2016{\natexlab{b}}.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{Snoek2012}
J.~Snoek, H.~Larochelle, and R.P Adams.
\newblock Practical bayesian optimization of machine learning algorithms.
\newblock In \emph{Proceedings of the 25th International Conference on Neural
  Information Processing Systems - Volume 2 (NIPS)}, NIPS'12, pages 2951--2959,
  USA, 2012.

\bibitem[Srinivas et~al.(2010)Srinivas, Krause, Kakade, and
  Seeger]{Srinivas2010}
N.~Srinivas, A.~Krause, S.M. Kakade, and M.~Seeger.
\newblock Gaussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock In \emph{Proceedings of the 27th International Conference on
  International Conference on Machine Learning (ICML)}, pages 1015--1022, 2010.

\bibitem[Wang and Jegelka(2017)]{Wang2017}
Z.~Wang and S.~Jegelka.
\newblock Max-value entropy search for efficient bayesian optimization.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning (ICML)}, pages 3627--3635, 2017.

\end{thebibliography}
