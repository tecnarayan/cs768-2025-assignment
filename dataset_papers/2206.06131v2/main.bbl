\begin{thebibliography}{10}

\bibitem{ives2003estimating}
A.~R. Ives, B.~Dennis, K.~L. Cottingham, and S.~R. Carpenter, ``Estimating
  community stability and ecological interactions from time-series data,'' {\em
  Ecological Monographs}, vol.~73, no.~2, pp.~301--330, 2003.

\bibitem{gordon2014ecology}
D.~M. Gordon, ``The ecology of collective behavior,'' {\em PLOS Biology},
  vol.~12, no.~3, p.~e1001805, 2014.

\bibitem{cattuto2009collective}
C.~Cattuto, A.~Barrat, A.~Baldassarri, G.~Schehr, and V.~Loreto, ``Collective
  dynamics of social annotation,'' {\em Proceedings of the National Academy of
  Sciences}, vol.~106, no.~26, pp.~10511--10515, 2009.

\bibitem{moussaid2013social}
M.~Moussa{\"\i}d, J.~E. K{\"a}mmer, P.~P. Analytis, and H.~Neth, ``Social
  influence and the collective dynamics of opinion formation,'' {\em PloS one},
  vol.~8, no.~11, p.~e78433, 2013.

\bibitem{pinheiro2016linking}
F.~L. Pinheiro, F.~C. Santos, and J.~M. Pacheco, ``Linking individual and
  collective behavior in adaptive social networks,'' {\em Physical Review
  Letters}, vol.~116, no.~12, p.~128702, 2016.

\bibitem{van2022global}
S.~van Vliet, C.~Hauert, K.~Fridberg, M.~Ackermann, and A.~Dal~Co, ``Global
  dynamics of microbial communities emerge from local interaction rules,'' {\em
  PLOS Computational Biology}, vol.~18, no.~3, p.~e1009877, 2022.

\bibitem{vyas2020computation}
S.~Vyas, M.~D. Golub, D.~Sussillo, and K.~V. Shenoy, ``Computation through
  neural population dynamics,'' {\em {A}nnual {R}eview of {N}euroscience},
  vol.~43, pp.~249--275, 2020.

\bibitem{li2015motor}
N.~Li, T.-W. Chen, Z.~V. Guo, C.~R. Gerfen, and K.~Svoboda, ``A motor cortex
  circuit for motor planning and movement,'' {\em Nature}, vol.~519, no.~7541,
  pp.~51--56, 2015.

\bibitem{li2022functional}
Y.~Li and M.~Meister, ``Functional cell types in the mouse superior
  colliculus,'' {\em bioRxiv}, 2022.

\bibitem{schneider2022transcriptomic}
A.~Schneider, M.~Azabou, L.~McDougall-Vigier, D.~B. Parks, S.~Ensley,
  K.~Bhaskaran-Nair, T.~J. Nowakowski, E.~L. Dyer, and K.~B. Hengen,
  ``Transcriptomic cell type structures in vivo neuronal activity across
  multiple time scales.,'' {\em bioRxiv}, 2022.

\bibitem{polikov2005response}
V.~S. Polikov, P.~A. Tresco, and W.~M. Reichert, ``Response of brain tissue to
  chronically implanted neural electrodes,'' {\em Journal of Neuroscience
  Methods}, vol.~148, no.~1, pp.~1--18, 2005.

\bibitem{grill2009implanted}
W.~M. Grill, S.~E. Norman, and R.~V. Bellamkonda, ``Implanted neural
  interfaces: biochallenges and engineered solutions,'' {\em Annual Review of
  Biomedical Engineering}, vol.~11, pp.~1--24, 2009.

\bibitem{mccreery2010neuronal}
D.~McCreery, V.~Pikov, and P.~R. Troyk, ``Neuronal loss due to prolonged
  controlled-current stimulation with chronically implanted microelectrodes in
  the cat cerebral cortex,'' {\em Journal of Neural Engineering}, vol.~7,
  no.~3, p.~036005, 2010.

\bibitem{dyer2017cryptography}
E.~L. Dyer, M.~G. Azar, M.~G. Perich, H.~L. Fernandes, S.~Naufel, L.~E. Miller,
  and K.~P. K{\"o}rding, ``A cryptography-based approach for movement
  decoding,'' {\em Nature Biomedical Engineering}, vol.~1, no.~12,
  pp.~967--976, 2017.

\bibitem{gallego2018cortical}
J.~A. Gallego, M.~G. Perich, S.~N. Naufel, C.~Ethier, S.~A. Solla, and L.~E.
  Miller, ``Cortical population activity within a preserved neural manifold
  underlies multiple motor behaviors,'' {\em Nature Communications}, vol.~9,
  no.~1, pp.~1--13, 2018.

\bibitem{gallego2020long}
J.~A. Gallego, M.~G. Perich, R.~H. Chowdhury, S.~A. Solla, and L.~E. Miller,
  ``Long-term stability of cortical population dynamics underlying consistent
  behavior,'' {\em Nature Neuroscience}, vol.~23, no.~2, pp.~260--270, 2020.

\bibitem{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  {\L}.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' in {\em
  Advances in neural information processing systems}, pp.~5998--6008, 2017.

\bibitem{geneva2022transformers}
N.~Geneva and N.~Zabaras, ``Transformers for modeling physical systems,'' {\em
  Neural Networks}, vol.~146, pp.~272--289, 2022.

\bibitem{bai2022characterization}
T.~Bai and P.~Tahmasebi, ``Characterization of groundwater contamination: A
  transformer-based deep learning model,'' {\em Advances in Water Resources},
  p.~104217, 2022.

\bibitem{plizzari2021spatial}
C.~Plizzari, M.~Cannici, and M.~Matteucci, ``Spatial temporal transformer
  network for skeleton-based action recognition,'' in {\em International
  Conference on Pattern Recognition}, pp.~694--701, Springer, 2021.

\bibitem{girdhar2019video}
R.~Girdhar, J.~Carreira, C.~Doersch, and A.~Zisserman, ``Video action
  transformer network,'' in {\em Proceedings of the IEEE/CVF Conference on
  Computer Vision and Pattern Recognition}, pp.~244--253, 2019.

\bibitem{chen2021nast}
K.~Chen, G.~Chen, D.~Xu, L.~Zhang, Y.~Huang, and A.~Knoll, ``Nast:
  non-autoregressive spatial-temporal transformer for time series
  forecasting,'' {\em arXiv preprint arXiv:2102.05624}, 2021.

\bibitem{xu2020spatial}
M.~Xu, W.~Dai, C.~Liu, X.~Gao, W.~Lin, G.-J. Qi, and H.~Xiong,
  ``Spatial-temporal transformer networks for traffic flow forecasting,'' {\em
  arXiv preprint arXiv:2001.02908}, 2020.

\bibitem{li2021groupformer}
S.~Li, Q.~Cao, L.~Liu, K.~Yang, S.~Liu, J.~Hou, and S.~Yi, ``Groupformer: Group
  activity recognition with clustered spatial-temporal transformer,'' in {\em
  Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pp.~13668--13677, 2021.

\bibitem{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, J.~Uszkoreit,
  and N.~Houlsby, ``An image is worth 16x16 words: Transformers for image
  recognition at scale,'' in {\em International Conference on Learning
  Representations}, 2021.

\bibitem{arnab2021vivit}
A.~Arnab, M.~Dehghani, G.~Heigold, C.~Sun, M.~Lučić, and C.~Schmid, ``Vivit:
  A video vision transformer,'' in {\em 2021 IEEE/CVF International Conference
  on Computer Vision (ICCV)}, pp.~6816--6826, 2021.

\bibitem{liu2021video}
Z.~Liu, J.~Ning, Y.~Cao, Y.~Wei, Z.~Zhang, S.~Lin, and H.~Hu, ``Video swin
  transformer,'' {\em Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2022.

\bibitem{bertasius2021space}
G.~Bertasius, H.~Wang, and L.~Torresani, ``Is space-time attention all you need
  for video understanding?,'' in {\em International Conference on Machine
  Learning}, PMLR, 2021.

\bibitem{hsieh2018learning}
J.-T. Hsieh, B.~Liu, D.-A. Huang, L.~F. Fei-Fei, and J.~C. Niebles, ``Learning
  to decompose and disentangle representations for video prediction,'' {\em
  Advances in neural information processing systems}, vol.~31, 2018.

\bibitem{kosiorek2018sequential}
A.~Kosiorek, H.~Kim, Y.~W. Teh, and I.~Posner, ``Sequential attend, infer,
  repeat: Generative modelling of moving objects,'' {\em Advances in Neural
  Information Processing Systems}, vol.~31, 2018.

\bibitem{wu2021generative}
Y.-F. Wu, J.~Yoon, and S.~Ahn, ``Generative video transformer: Can objects be
  the words?,'' in {\em International Conference on Machine Learning},
  pp.~11307--11318, PMLR, 2021.

\bibitem{singh2022simple}
G.~Singh, Y.-F. Wu, and S.~Ahn, ``Simple unsupervised object-centric learning
  for complex and naturalistic videos,'' {\em arXiv preprint arXiv:2205.14065},
  2022.

\bibitem{battaglia2016interaction}
P.~Battaglia, R.~Pascanu, M.~Lai, D.~Jimenez~Rezende, {\em et~al.},
  ``Interaction networks for learning about objects, relations and physics,''
  {\em Advances in neural information processing systems}, vol.~29, 2016.

\bibitem{wu2020deep}
A.~Wu, E.~K. Buchanan, M.~Whiteway, M.~Schartner, G.~Meijer, J.-P. Noel,
  E.~Rodriguez, C.~Everett, A.~Norovich, E.~Schaffer, {\em et~al.}, ``Deep
  graph pose: a semi-supervised deep graphical model for improved animal pose
  tracking,'' {\em Advances in Neural Information Processing Systems}, vol.~33,
  pp.~6040--6052, 2020.

\bibitem{azabou2022learning}
M.~Azabou, M.~Mendelson, M.~Sorokin, S.~Thakoor, N.~Ahad, C.~Urzay, and E.~L.
  Dyer, ``Learning behavior representations through multi-timescale
  bootstrapping,'' {\em arXiv preprint arXiv:2206.07041}, 2022.

\bibitem{hodgkin1952quantitative}
A.~L. Hodgkin and A.~F. Huxley, ``A quantitative description of membrane
  current and its application to conduction and excitation in nerve,'' {\em The
  Journal of Physiology}, vol.~117, no.~4, p.~500, 1952.

\bibitem{kistler1997reduction}
W.~M. Kistler, W.~Gerstner, and J.~L.~v. Hemmen, ``Reduction of the
  hodgkin-huxley equations to a single-variable threshold model,'' {\em Neural
  Computation}, vol.~9, no.~5, pp.~1015--1045, 1997.

\bibitem{traub1991model}
R.~D. Traub, R.~K. Wong, R.~Miles, and H.~Michelson, ``A model of a ca3
  hippocampal pyramidal neuron incorporating voltage-clamp data on intrinsic
  conductances,'' {\em Journal of Neurophysiology}, vol.~66, no.~2,
  pp.~635--650, 1991.

\bibitem{panahi2021generative}
M.~R. Panahi, G.~Abrevaya, J.-C. Gagnon-Audet, V.~Voleti, I.~Rish, and
  G.~Dumas, ``Generative models of brain dynamics--a review,'' {\em arXiv
  preprint arXiv:2112.12147}, 2021.

\bibitem{semedo2020statistical}
J.~D. Semedo, E.~Gokcen, C.~K. Machens, A.~Kohn, and M.~Y. Byron, ``Statistical
  methods for dissecting interactions between brain areas,'' {\em Current
  Opinion in Neurobiology}, vol.~65, pp.~59--69, 2020.

\bibitem{perich2020rethinking}
M.~G. Perich and K.~Rajan, ``Rethinking brain-wide interactions through
  multi-region ‘network of networks’ models,'' {\em Current Opinion in
  Neurobiology}, vol.~65, pp.~146--151, 2020.

\bibitem{keeley2020modeling}
S.~L. Keeley, D.~M. Zoltowski, M.~C. Aoi, and J.~W. Pillow, ``Modeling
  statistical dependencies in multi-region spike train data,'' {\em Current
  Opinion in Neurobiology}, vol.~65, pp.~194--202, 2020.

\bibitem{azabou2021mine}
M.~Azabou, M.~G. Azar, R.~Liu, C.-H. Lin, E.~C. Johnson, K.~Bhaskaran-Nair,
  M.~Dabagia, K.~B. Hengen, W.~Gray-Roncal, M.~Valko, and E.~Dyer, ``Mine your
  own view: Self-supervised learning through across-sample prediction,'' {\em
  arXiv preprint arXiv:2102.10106}, 2021.

\bibitem{ye2021representation}
J.~Ye and C.~Pandarinath, ``Representation learning for neural population
  activity with {Neural} {Data} {Transformers},'' {\em Neurons, Behavior, Data
  analysis, and Theory}, Aug. 2021.

\bibitem{pei2021neural}
F.~Pei, J.~Ye, D.~M. Zoltowski, A.~Wu, R.~H. Chowdhury, H.~Sohn, J.~E.
  O’Doherty, K.~V. Shenoy, M.~T. Kaufman, M.~Churchland, M.~Jazayeri, L.~E.
  Miller, J.~Pillow, I.~M. Park, E.~L. Dyer, and C.~Pandarinath, ``Neural
  latents benchmark 21: Evaluating latent variable models of neural population
  activity,'' {\em Advances in Neural Information Processing Systems (NeurIPS),
  Track on Datasets and Benchmarks}, 2021.

\bibitem{nassar2018tree}
J.~Nassar, S.~W. Linderman, M.~Bugallo, and I.~M. Park, ``Tree-structured
  recurrent switching linear dynamical systems for multi-scale modeling,'' in
  {\em International Conference on Learning Representations}, 2019.

\bibitem{pandarinath2018inferring}
C.~Pandarinath, D.~J. O’Shea, J.~Collins, R.~Jozefowicz, S.~D. Stavisky,
  J.~C. Kao, E.~M. Trautmann, M.~T. Kaufman, S.~I. Ryu, L.~R. Hochberg, {\em
  et~al.}, ``Inferring single-trial neural population dynamics using sequential
  auto-encoders,'' {\em Nature {M}ethods}, vol.~15, no.~10, pp.~805--815, 2018.

\bibitem{liu2021drop}
R.~Liu, M.~Azabou, M.~Dabagia, C.-H. Lin, M.~Gheshlaghi~Azar, K.~Hengen,
  M.~Valko, and E.~Dyer, ``Drop, swap, and generate: A self-supervised approach
  for generating neural activity,'' {\em Advances in Neural Information
  Processing Systems}, vol.~34, 2021.

\bibitem{urai2022large}
A.~E. Urai, B.~Doiron, A.~M. Leifer, and A.~K. Churchland, ``Large-scale neural
  recordings call for new insights to link brain and behavior,'' {\em Nature
  Neuroscience}, pp.~1--9, 2022.

\bibitem{dabagia2022comparing}
M.~Dabagia, K.~P. Kording, and E.~L. Dyer, ``Comparing high-dimensional neural
  recordings by aligning their low-dimensional latent representations,'' {\em
  arXiv preprint arXiv:2205.08413}, 2022.

\bibitem{degenhart2020stabilization}
A.~D. Degenhart, W.~E. Bishop, E.~R. Oby, E.~C. Tyler-Kabara, S.~M. Chase,
  A.~P. Batista, and B.~M. Yu, ``Stabilization of a brain--computer interface
  via the alignment of low-dimensional spaces of neural activity,'' {\em Nature
  Biomedical Engineering}, vol.~4, no.~7, pp.~672--685, 2020.

\bibitem{farshchian2018adversarial}
A.~Farshchian, J.~A. Gallego, J.~P. Cohen, Y.~Bengio, L.~E. Miller, and S.~A.
  Solla, ``Adversarial domain adaptation for stable brain-machine interfaces,''
  2019.

\bibitem{jude2022robust}
J.~Jude, M.~G. Perich, L.~E. Miller, and M.~H. Hennig, ``Robust alignment of
  cross-session recordings of neural population activity by behaviour via
  unsupervised domain adaptation,'' {\em arXiv preprint arXiv:2202.06159},
  2022.

\bibitem{chen2020simple}
T.~Chen, S.~Kornblith, M.~Norouzi, and G.~Hinton, ``A simple framework for
  contrastive learning of visual representations,'' in {\em International
  Conference on Machine Learning}, pp.~1597--1607, PMLR, 2020.

\bibitem{grill2020bootstrap}
J.-B. Grill, F.~Strub, F.~Altch{\'e}, C.~Tallec, P.~H. Richemond,
  E.~Buchatskaya, C.~Doersch, B.~A. Pires, Z.~D. Guo, M.~G. Azar, {\em et~al.},
  ``Bootstrap your own latent: A new approach to self-supervised learning,''
  {\em arXiv preprint arXiv:2006.07733}, 2020.

\bibitem{cuturi2013sinkhorn}
M.~Cuturi, ``Sinkhorn distances: Lightspeed computation of optimal transport,''
  {\em Advances in neural information processing systems}, vol.~26, 2013.

\bibitem{peyre2019computational}
G.~Peyr{\'e}, M.~Cuturi, {\em et~al.}, ``Computational optimal transport: With
  applications to data science,'' {\em Foundations and Trends{\textregistered}
  in Machine Learning}, vol.~11, no.~5-6, pp.~355--607, 2019.

\bibitem{jastrow1955many}
R.~Jastrow, ``Many-body problem with strong forces,'' {\em Physical Review},
  vol.~98, no.~5, p.~1479, 1955.

\bibitem{kipf2018neural}
T.~Kipf, E.~Fetaya, K.-C. Wang, M.~Welling, and R.~Zemel, ``Neural relational
  inference for interacting systems,'' in {\em International Conference on
  Machine Learning}, pp.~2688--2697, PMLR, 2018.

\bibitem{graber2020dynamic}
C.~Graber and A.~Schwing, ``Dynamic neural relational inference for forecasting
  trajectories,'' in {\em Proceedings of the IEEE/CVF Conference on Computer
  Vision and Pattern Recognition Workshops}, pp.~1018--1019, 2020.

\bibitem{duncker2019learning}
L.~Duncker, G.~Bohner, J.~Boussard, and M.~Sahani, ``Learning interpretable
  continuous-time models of latent stochastic dynamical systems,'' in {\em
  International Conference on Machine Learning}, pp.~1726--1734, PMLR, 2019.

\bibitem{kim2021inferring}
T.~D. Kim, T.~Z. Luo, J.~W. Pillow, and C.~Brody, ``Inferring latent dynamics
  underlying neural population activity via neural differential equations,'' in
  {\em International Conference on Machine Learning}, pp.~5551--5561, PMLR,
  2021.

\bibitem{greydanus2019hamiltonian}
S.~Greydanus, M.~Dzamba, and J.~Yosinski, ``Hamiltonian neural networks,'' {\em
  Advances in Neural Information Processing Systems}, vol.~32, 2019.

\bibitem{dormand1980family}
J.~R. Dormand and P.~J. Prince, ``A family of embedded runge-kutta formulae,''
  {\em Journal of Computational and Applied Mathematics}, vol.~6, no.~1,
  pp.~19--26, 1980.

\bibitem{churchland2010cortical}
M.~M. Churchland, J.~P. Cunningham, M.~T. Kaufman, S.~I. Ryu, and K.~V. Shenoy,
  ``Cortical preparatory activity: representation of movement or first cog in a
  dynamical machine?,'' {\em Neuron}, vol.~68, no.~3, pp.~387--400, 2010.

\bibitem{xiong2016dynamic}
C.~Xiong, S.~Merity, and R.~Socher, ``Dynamic memory networks for visual and
  textual question answering,'' in {\em International Conference on Machine
  Learning}, pp.~2397--2406, PMLR, 2016.

\bibitem{dutta2021redesigning}
S.~Dutta, T.~Gautam, S.~Chakrabarti, and T.~Chakraborty, ``Redesigning the
  transformer architecture with insights from multi-particle dynamical
  systems,'' {\em Advances in Neural Information Processing Systems}, vol.~34,
  2021.

\bibitem{guo2019attention}
S.~Guo, Y.~Lin, N.~Feng, C.~Song, and H.~Wan, ``Attention based
  spatial-temporal graph convolutional networks for traffic flow forecasting,''
  in {\em Proceedings of the AAAI conference on artificial intelligence},
  vol.~33, pp.~922--929, 2019.

\bibitem{guo2019exploring}
T.~Guo, T.~Lin, and N.~Antulov-Fantulin, ``Exploring interpretable lstm neural
  networks over multi-variable data,'' in {\em International conference on
  machine learning}, pp.~2494--2504, PMLR, 2019.

\bibitem{shalova2020tensorized}
A.~Shalova and I.~Oseledets, ``Tensorized transformer for dynamical systems
  modeling,'' {\em arXiv preprint arXiv:2006.03445}, 2020.

\bibitem{he2021masked}
K.~He, X.~Chen, S.~Xie, Y.~Li, P.~Doll{\'a}r, and R.~Girshick, ``Masked
  autoencoders are scalable vision learners,'' {\em arXiv preprint
  arXiv:2111.06377}, 2021.

\bibitem{bao2021beit}
H.~Bao, L.~Dong, and F.~Wei, ``Beit: Bert pre-training of image transformers,''
  {\em arXiv preprint arXiv:2106.08254}, 2021.

\bibitem{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova, ``Bert: Pre-training of deep
  bidirectional transformers for language understanding,'' {\em arXiv preprint
  arXiv:1810.04805}, 2018.

\bibitem{brown2020language}
T.~B. Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~Kaplan, P.~Dhariwal,
  A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, {\em et~al.}, ``Language
  models are few-shot learners,'' {\em arXiv preprint arXiv:2005.14165}, 2020.

\bibitem{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark, {\em et~al.}, ``Learning transferable visual
  models from natural language supervision,'' in {\em International Conference
  on Machine Learning}, pp.~8748--8763, PMLR, 2021.

\bibitem{siegle2021survey}
J.~H. Siegle, X.~Jia, S.~Durand, S.~Gale, C.~Bennett, N.~Graddis, G.~Heller,
  T.~K. Ramirez, H.~Choi, J.~A. Luviano, {\em et~al.}, ``Survey of spiking in
  the mouse visual system reveals functional hierarchy,'' {\em Nature},
  vol.~592, no.~7852, pp.~86--92, 2021.

\bibitem{de2020large}
S.~E. de~Vries, J.~A. Lecoq, M.~A. Buice, P.~A. Groblewski, G.~K. Ocker,
  M.~Oliver, D.~Feng, N.~Cain, P.~Ledochowitsch, D.~Millman, {\em et~al.}, ``A
  large-scale standardized physiological survey reveals functional organization
  of the mouse visual cortex,'' {\em Nature Neuroscience}, vol.~23, no.~1,
  pp.~138--151, 2020.

\bibitem{guo2021pct}
M.-H. Guo, J.-X. Cai, Z.-N. Liu, T.-J. Mu, R.~R. Martin, and S.-M. Hu, ``Pct:
  Point cloud transformer,'' {\em Computational Visual Media}, vol.~7, no.~2,
  pp.~187--199, 2021.

\bibitem{higgins2016beta}
I.~Higgins, L.~Matthey, A.~Pal, C.~Burgess, X.~Glorot, M.~Botvinick,
  S.~Mohamed, and A.~Lerchner, ``beta-vae: Learning basic visual concepts with
  a constrained variational framework,'' {\em International Conference on
  Learning Representations}, 2016.

\end{thebibliography}
