\begin{thebibliography}{10}

\bibitem{aumann1974subjectivity}
Robert~J Aumann.
\newblock Subjectivity and correlation in randomized strategies.
\newblock {\em Journal of mathematical Economics}, 1(1):67--96, 1974.

\bibitem{barber2011bayesian}
David Barber, A~Taylan Cemgil, and Silvia Chiappa.
\newblock {\em Bayesian time series models}.
\newblock Cambridge University Press, 2011.

\bibitem{bishop2006pattern}
Christopher~M Bishop.
\newblock {\em Pattern recognition and machine learning}.
\newblock springer, 2006.

\bibitem{boyd2004convex}
Stephen Boyd and Lieven Vandenberghe.
\newblock {\em Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem{busoniu_comprehensive_2008}
Lucian Busoniu, Robert Babuska, and Bart De~Schutter.
\newblock A {Comprehensive} {Survey} of {Multiagent} {Reinforcement}
  {Learning}.
\newblock {\em IEEE Transactions on Systems, Man, and Cybernetics, Part C
  (Applications and Reviews)}, 38(2):156--172, 2008.

\bibitem{cao_overview_2012}
Yongcan Cao, Wenwu Yu, Wei Ren, and Guanrong Chen.
\newblock An {Overview} of {Recent} {Progress} in the {Study} of {Distributed}
  {Multi}-agent {Coordination}.
\newblock {\em IEEE Transactions on Industrial Informatics}, 9(1):427--438,
  2013.

\bibitem{dimakopoulou2018coordinated}
Maria Dimakopoulou and Benjamin Van~Roy.
\newblock Coordinated exploration in concurrent reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  1270--1278, 2018.

\bibitem{eysenbach2018diversity}
Benjamin Eysenbach, Abhishek Gupta, Julian Ibarz, and Sergey Levine.
\newblock Diversity is all you need: Learning skills without a reward function.
\newblock {\em arXiv preprint arXiv:1802.06070}, 2018.

\bibitem{fellows2018virel}
Matthew Fellows, Anuj Mahajan, Tim~GJ Rudner, and Shimon Whiteson.
\newblock Virel: A variational inference framework for reinforcement learning.
\newblock {\em arXiv preprint arXiv:1811.01132}, 2018.

\bibitem{florensa2017stochastic}
Carlos Florensa, Yan Duan, and Pieter Abbeel.
\newblock Stochastic neural networks for hierarchical reinforcement learning.
\newblock {\em arXiv preprint arXiv:1704.03012}, 2017.

\bibitem{foerster2016learning}
Jakob Foerster, Ioannis~Alexandros Assael, Nando de~Freitas, and Shimon
  Whiteson.
\newblock Learning to communicate with deep multi-agent reinforcement learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2137--2145, 2016.

\bibitem{foerster_stabilising_2017}
Jakob Foerster, Nantas Nardelli, Gregory Farquhar, Triantafyllos Afouras,
  Philip H.~S. Torr, Pushmeet Kohli, and Shimon Whiteson.
\newblock Stabilising {Experience} {Replay} for {Deep} {Multi}-{Agent}
  {Reinforcement} {Learning}.
\newblock In {\em Proceedings of {The} 34th {International} {Conference} on
  {Machine} {Learning}}, pages 1146--1155, 2017.

\bibitem{foerster2018counterfactual}
Jakob~N Foerster, Gregory Farquhar, Triantafyllos Afouras, Nantas Nardelli, and
  Shimon Whiteson.
\newblock Counterfactual multi-agent policy gradients.
\newblock In {\em Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem{gregor2016variational}
Karol Gregor, Danilo~Jimenez Rezende, and Daan Wierstra.
\newblock Variational intrinsic control.
\newblock {\em arXiv preprint arXiv:1611.07507}, 2016.

\bibitem{guckelsberger2018new}
Christian Guckelsberger, Christoph Salge, and Julian Togelius.
\newblock New and surprising ways to be mean. adversarial npcs with coupled
  empowerment minimisation.
\newblock {\em arXiv preprint arXiv:1806.01387}, 2018.

\bibitem{guestrin_multiagent_2002}
Carlos Guestrin, Daphne Koller, and Ronald Parr.
\newblock Multiagent {Planning} with {Factored} {MDPs}.
\newblock In {\em Advances in {Neural} {Information} {Processing} {Systems}},
  pages 1523--1530. MIT Press, 2002.

\bibitem{guestrin2003efficient}
Carlos Guestrin, Daphne Koller, Ronald Parr, and Shobha Venkataraman.
\newblock Efficient solution algorithms for factored mdps.
\newblock {\em Journal of Artificial Intelligence Research}, 19:399--468, 2003.

\bibitem{haarnoja2018latent}
Tuomas Haarnoja, Kristian Hartikainen, Pieter Abbeel, and Sergey Levine.
\newblock Latent space policies for hierarchical reinforcement learning.
\newblock {\em arXiv preprint arXiv:1804.02808}, 2018.

\bibitem{hausknecht_deep_2015}
Matthew Hausknecht and Peter Stone.
\newblock Deep {Recurrent} {Q}-{Learning} for {Partially} {Observable} {MDPs}.
\newblock In {\em AAAI Fall Symposium on Sequential Decision Making for
  Intelligent Agents}, 2015.

\bibitem{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural computation}, 9(8):1735--1780, 1997.

\bibitem{houthooft2016vime}
Rein Houthooft, Xi~Chen, Yan Duan, John Schulman, Filip De~Turck, and Pieter
  Abbeel.
\newblock Vime: Variational information maximizing exploration.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1109--1117, 2016.

\bibitem{huttenrauch_guided_2017}
Maximilian H{\"u}ttenrauch, Adrian {\v S}o{\v s}i{\'c}, and Gerhard Neumann.
\newblock Guided {Deep} {Reinforcement} {Learning} for {Swarm} {Systems}.
\newblock In {\em AAMAS 2017 Autonomous Robots and Multirobot Systems (ARMS)
  Workshop}, 2017.

\bibitem{jiang2018learning}
Jiechuan Jiang and Zongqing Lu.
\newblock Learning attentional communication for multi-agent cooperation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  7254--7264, 2018.

\bibitem{kingma2014stochastic}
Diederik~P Kingma and Max Welling.
\newblock Stochastic gradient vb and the variational auto-encoder.
\newblock In {\em Second International Conference on Learning Representations,
  ICLR}, 2014.

\bibitem{kingma2016improved}
Durk~P Kingma, Tim Salimans, Rafal Jozefowicz, Xi~Chen, Ilya Sutskever, and Max
  Welling.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock In {\em Advances in neural information processing systems}, pages
  4743--4751, 2016.

\bibitem{kraemer_multi-agent_2016}
Landon Kraemer and Bikramjit Banerjee.
\newblock Multi-agent reinforcement learning as a rehearsal for decentralized
  planning.
\newblock {\em Neurocomputing}, 190:82--94, 2016.

\bibitem{lin2019cesma}
Alex~Tong Lin, Mark~J Debord, Katia Estabridis, Gary Hewer, and Stanley Osher.
\newblock Cesma: Centralized expert supervises multi-agents.
\newblock {\em arXiv preprint arXiv:1902.02311}, 2019.

\bibitem{lowe2017multi}
Ryan Lowe, Yi~Wu, Aviv Tamar, Jean Harb, OpenAI~Pieter Abbeel, and Igor
  Mordatch.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6379--6390, 2017.

\bibitem{maaten2008visualizing}
Laurens van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock {\em Journal of machine learning research}, 9(Nov):2579--2605, 2008.

\bibitem{mahajan2017symmetry}
Anuj Mahajan and Theja Tulabandhula.
\newblock Symmetry detection and exploitation for function approximation in
  deep rl.
\newblock In {\em Proceedings of the 16th Conference on Autonomous Agents and
  MultiAgent Systems}, pages 1619--1621. International Foundation for
  Autonomous Agents and Multiagent Systems, 2017.

\bibitem{mahajan2017asymmetry}
Anuj Mahajan and Theja Tulabandhula.
\newblock Symmetry learning for function approximation in reinforcement
  learning.
\newblock {\em arXiv preprint arXiv:1706.02999}, 2017.

\bibitem{mnih2014neural}
Andriy Mnih and Karol Gregor.
\newblock Neural variational inference and learning in belief networks.
\newblock {\em arXiv preprint arXiv:1402.0030}, 2014.

\bibitem{mnih2013playing}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1312.5602}, 2013.

\bibitem{oliehoek_concise_2016}
Frans~A. Oliehoek and Christopher Amato.
\newblock {\em A {Concise} {Introduction} to {Decentralized} {POMDPs}}.
\newblock {SpringerBriefs} in {Intelligent} {Systems}. Springer, 2016.

\bibitem{omidshafiei_deep_2017}
Shayegan Omidshafiei, Jason Pazis, Christopher Amato, Jonathan~P. How, and John
  Vian.
\newblock Deep {Decentralized} {Multi}-task {Multi}-{Agent} {RL} under
  {Partial} {Observability}.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning}, pages 2681--2690, 2017.

\bibitem{osband2016deep}
Ian Osband, Charles Blundell, Alexander Pritzel, and Benjamin Van~Roy.
\newblock Deep exploration via bootstrapped dqn.
\newblock In {\em Advances in neural information processing systems}, pages
  4026--4034, 2016.

\bibitem{osband2017deep}
Ian Osband, Benjamin Van~Roy, Daniel Russo, and Zheng Wen.
\newblock Deep exploration via randomized value functions.
\newblock {\em arXiv preprint arXiv:1703.07608}, 2017.

\bibitem{pathakICMl17curiosity}
Deepak Pathak, Pulkit Agrawal, Alexei~A. Efros, and Trevor Darrell.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In {\em ICML}, 2017.

\bibitem{peng_multiagent_2017}
Peng Peng, Ying Wen, Yaodong Yang, Quan Yuan, Zhenkun Tang, Haitao Long, and
  Jun Wang.
\newblock Multiagent {Bidirectionally}-{Coordinated} {Nets}: {Emergence} of
  {Human}-level {Coordination} in {Learning} to {Play} {StarCraft} {Combat}
  {Games}.
\newblock {\em arXiv preprint arXiv:1703.10069}, 2017.

\bibitem{rashid2018qmix}
Tabish Rashid, Mikayel Samvelyan, Christian~Schroeder de~Witt, Gregory
  Farquhar, Jakob Foerster, and Shimon Whiteson.
\newblock {QMIX}: {Monotonic} {Value} {Function} {Factorisation} for {Deep}
  {Multi-Agent} {Reinforcement} {Learning}.
\newblock In {\em Proceedings of the 35th International Conference on Machine
  Learning}, pages 4295--4304, 2018.

\bibitem{rezende2015variational}
Danilo~Jimenez Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock {\em arXiv preprint arXiv:1505.05770}, 2015.

\bibitem{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock {\em arXiv preprint arXiv:1401.4082}, 2014.

\bibitem{samvelyan2019starcraft}
Mikayel Samvelyan, Tabish Rashid, Christian~Schroeder de~Witt, Gregory
  Farquhar, Nantas Nardelli, Tim~GJ Rudner, Chia-Man Hung, Philip~HS Torr,
  Jakob Foerster, and Shimon Whiteson.
\newblock {The} {StarCraft} {Multi-Agent} {Challenge}.
\newblock In {\em Proceedings of the 18th International Conference on
  Autonomous Agents and MultiAgent Systems}, 2019.

\bibitem{son2019qtran}
Kyunghwan Son, Daewoo Kim, Wan~Ju Kang, David~Earl Hostallero, and Yung Yi.
\newblock Qtran: Learning to factorize with transformation for cooperative
  multi-agent reinforcement learning.
\newblock {\em arXiv preprint arXiv:1905.05408}, 2019.

\bibitem{sukhbaatar2016learning}
Sainbayar Sukhbaatar, Rob Fergus, et~al.
\newblock Learning multiagent communication with backpropagation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2244--2252, 2016.

\bibitem{sunehag2017value}
Peter Sunehag, Guy Lever, Audrunas Gruslys, Wojciech~Marian Czarnecki, Vinicius
  Zambaldi, Max Jaderberg, Marc Lanctot, Nicolas Sonnerat, Joel~Z Leibo, Karl
  Tuyls, et~al.
\newblock Value-decomposition networks for cooperative multi-agent learning.
\newblock {\em arXiv preprint arXiv:1706.05296}, 2017.

\bibitem{tampuu_multiagent_2015}
Ardi Tampuu, Tambet Matiisen, Dorian Kodelja, Ilya Kuzovkin, Kristjan Korjus,
  Juhan Aru, Jaan Aru, and Raul Vicente.
\newblock Multiagent cooperation and competition with deep reinforcement
  learning.
\newblock {\em PloS one}, 2017.

\bibitem{tan1993multi}
Ming Tan.
\newblock Multi-agent reinforcement learning: Independent vs. cooperative
  agents.
\newblock In {\em Proceedings of the tenth international conference on machine
  learning}, pages 330--337, 1993.

\bibitem{todorov2007linearly}
Emanuel Todorov.
\newblock Linearly-solvable markov decision problems.
\newblock In {\em Advances in neural information processing systems}, pages
  1369--1376, 2007.

\bibitem{wainwright2008graphical}
Martin~J Wainwright, Michael~I Jordan, et~al.
\newblock Graphical models, exponential families, and variational inference.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  1(1--2):1--305, 2008.

\bibitem{yang_multiagent_2004}
Erfu Yang and Dongbing Gu.
\newblock Multiagent reinforcement learning for multi-robot systems: {A}
  survey.
\newblock Technical report, University of Strathclyde, 2004.

\bibitem{zheng2018structured}
Stephan Zheng and Yisong Yue.
\newblock Structured exploration via hierarchical variational policy networks.
\newblock {\em openreview}, 2018.

\bibitem{ziebart2008maximum}
Brian~D Ziebart, Andrew~L Maas, J~Andrew Bagnell, and Anind~K Dey.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In {\em Aaai}, volume~8, pages 1433--1438. Chicago, IL, USA, 2008.

\end{thebibliography}
