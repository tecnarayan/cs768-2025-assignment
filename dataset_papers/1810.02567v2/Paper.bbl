\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi-Yadkori et~al.(2011)Abbasi-Yadkori, P\'{a}l, and
  Szepesv\'{a}ri]{AST11}
Abbasi-Yadkori, Y., P\'{a}l, D., and Szepesv\'{a}ri, C.
\newblock Improved algorithms for linear stochastic bandits.
\newblock In Shawe-Taylor, J., Zemel, R.~S., Bartlett, P.~L., Pereira, F., and
  Weinberger, K.~Q. (eds.), \emph{Advances in Neural Information Processing
  Systems 24}, NIPS, pp.\  2312--2320. Curran Associates, Inc., 2011.

\bibitem[Abbasi-Yadkori et~al.(2012)Abbasi-Yadkori, Pal, and
  Szepesv{\'a}ri]{APS12}
Abbasi-Yadkori, Y., Pal, D., and Szepesv{\'a}ri, C.
\newblock Online-to-confidence-set conversions and application to sparse
  stochastic bandits.
\newblock In Lawrence, N.~D. and Girolami, M. (eds.), \emph{Proceedings of the
  15th International Conference on Artificial Intelligence and Statistics},
  volume~22 of \emph{Proceedings of Machine Learning Research}, pp.\  1--9, La
  Palma, Canary Islands, 21--23 Apr 2012. PMLR.

\bibitem[Abe \& Long(1999)Abe and Long]{AL99}
Abe, N. and Long, P.~M.
\newblock Associative reinforcement learning using linear probabilistic
  concepts.
\newblock In \emph{Proceedings of the 16th International Conference on Machine
  Learning}, ICML, pp.\  3--11, San Francisco, CA, USA, 1999. Morgan Kaufmann
  Publishers Inc.

\bibitem[Auer(2002)]{Aue02}
Auer, P.
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0
  (Nov):\penalty0 397--422, 2002.

\bibitem[Boyd \& Vandenberghe(2004)Boyd and Vandenberghe]{BV04}
Boyd, S. and Vandenberghe, L.
\newblock \emph{Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem[Bubeck et~al.(2012)Bubeck, Cesa-Bianchi, and Kakade]{BCK12}
Bubeck, S., Cesa-Bianchi, N., and Kakade, S.
\newblock Towards minimax policies for online linear optimization with bandit
  feedback.
\newblock In \emph{Annual Conference on Learning Theory}, volume~23, pp.\
  41--1. Microtome, 2012.

\bibitem[Chaudhuri(2016)]{Cha16}
Chaudhuri, S.
\newblock \emph{Learning to Rank: Online Learning, Statistical Theory and
  Applications.}
\newblock PhD thesis, 2016.

\bibitem[Chen \& Hofmann(2015)Chen and Hofmann]{CH15}
Chen, Y. and Hofmann, K.
\newblock Online learning to rank: Absolute vs. relative.
\newblock In \emph{Proceedings of the 24th International Conference on World
  Wide Web}, pp.\  19--20. ACM, 2015.

\bibitem[Chuklin et~al.(2015)Chuklin, Markov, and de~Rijke]{CMR15}
Chuklin, A., Markov, I., and de~Rijke, M.
\newblock \emph{Click Models for Web Search}.
\newblock Morgan \& Claypool Publishers, 2015.

\bibitem[Combes et~al.(2015)Combes, Magureanu, Proutiere, and Laroche]{CMP15}
Combes, R., Magureanu, S., Proutiere, A., and Laroche, C.
\newblock Learning to rank: Regret lower bounds and efficient algorithms.
\newblock In \emph{Proceedings of the 2015 ACM SIGMETRICS International
  Conference on Measurement and Modeling of Computer Systems}, pp.\  231--244.
  ACM, 2015.
\newblock ISBN 978-1-4503-3486-0.

\bibitem[Filippi et~al.(2010)Filippi, Cappe, Garivier, and
  Szepesv\'{a}ri]{FCGS10}
Filippi, S., Cappe, O., Garivier, A., and Szepesv\'{a}ri, C.
\newblock Parametric bandits: The generalized linear case.
\newblock In Lafferty, J.~D., Williams, C. K.~I., Shawe-Taylor, J., Zemel,
  R.~S., and Culotta, A. (eds.), \emph{Advances in Neural Information
  Processing Systems 23}, NIPS, pp.\  586--594. Curran Associates, Inc., 2010.

\bibitem[Harper \& Konstan(2016)Harper and Konstan]{harper2016movielens}
Harper, F.~M. and Konstan, J.~A.
\newblock The movielens datasets: History and context.
\newblock \emph{Acm transactions on interactive intelligent systems (tiis)},
  5\penalty0 (4):\penalty0 19, 2016.
\newblock URL \url{https://grouplens.org/datasets/movielens/20m/}.

\bibitem[Hazan \& Karnin(2016)Hazan and Karnin]{H16volumetric}
Hazan, E. and Karnin, Z.
\newblock Volumetric spanners: an efficient exploration basis for learning.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 4062--4095, 2016.

\bibitem[Hofmann et~al.(2011)Hofmann, Whiteson, and De~Rijke]{HW11}
Hofmann, K., Whiteson, S., and De~Rijke, M.
\newblock A probabilistic method for inferring preferences from clicks.
\newblock In \emph{Proceedings of the 20th ACM international conference on
  Information and knowledge management}, pp.\  249--258. ACM, 2011.

\bibitem[Jun et~al.(2017)Jun, Bhargava, Nowak, and Willett]{JBNW17}
Jun, K., Bhargava, A., Nowak, R., and Willett, R.
\newblock Scalable generalized linear bandits: Online computation and hashing.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 30}, pp.\  99--109. Curran Associates, Inc.,
  2017.

\bibitem[Katariya et~al.(2016)Katariya, Kveton, Szepesv{\'a}ri, and Wen]{KKS16}
Katariya, S., Kveton, B., Szepesv{\'a}ri, C., and Wen, Z.
\newblock {DCM} bandits: Learning to rank with multiple clicks.
\newblock In \emph{Proceedings of the 33rd International Conference on Machine
  Learning}, pp.\  1215--1224, 2016.

\bibitem[Katariya et~al.(2017{\natexlab{a}})Katariya, Kveton, Szepesv{\'a}ri,
  Vernade, and Wen]{KKS17}
Katariya, S., Kveton, B., Szepesv{\'a}ri, C., Vernade, C., and Wen, Z.
\newblock Bernoulli rank-1 bandits for click feedback.
\newblock In \emph{Proceedings of the 26th International Joint Conference on
  Artificial Intelligence}, 2017{\natexlab{a}}.

\bibitem[Katariya et~al.(2017{\natexlab{b}})Katariya, Kveton, Szepesv{\'a}ri,
  Vernade, and Wen]{KKS17b}
Katariya, S., Kveton, B., Szepesv{\'a}ri, C., Vernade, C., and Wen, Z.
\newblock Stochastic rank-1 bandits.
\newblock In \emph{Proceedings of the 20th International Conference on
  Artificial Intelligence and Statistics}, 2017{\natexlab{b}}.

\bibitem[Kiefer \& Wolfowitz(1960)Kiefer and Wolfowitz]{KW60}
Kiefer, J. and Wolfowitz, J.
\newblock The equivalence of two extremum problems.
\newblock \emph{Canadian Journal of Mathematics}, 12\penalty0 (5):\penalty0
  363--365, 1960.

\bibitem[Kveton et~al.(2015)Kveton, Szepesv\'{a}ri, Wen, and Ashkan]{KSWA15}
Kveton, B., Szepesv\'{a}ri, C., Wen, Z., and Ashkan, A.
\newblock Cascading bandits: Learning to rank in the cascade model.
\newblock In \emph{Proceedings of the 32nd International Conference on
  International Conference on Machine Learning - Volume 37}, pp.\  767--776.
  JMLR.org, 2015.

\bibitem[Lagree et~al.(2016)Lagree, Vernade, and Capp{\'e}]{LVC16}
Lagree, P., Vernade, C., and Capp{\'e}, O.
\newblock Multiple-play bandits in the position-based model.
\newblock In \emph{Advances in Neural Information Processing Systems 29}, NIPS,
  pp.\  1597--1605. Curran Associates Inc., 2016.

\bibitem[Lattimore \& Szepesv\'{a}ri(2018)Lattimore and
  Szepesv\'{a}ri]{LS18book}
Lattimore, T. and Szepesv\'{a}ri, C.
\newblock \emph{Bandit Algorithms}.
\newblock preprint, 2018.

\bibitem[Lattimore et~al.(2018)Lattimore, Kveton, Li, and
  Szepesv{\'a}ri]{LKLS18ranking}
Lattimore, T., Kveton, B., Li, S., and Szepesv{\'a}ri, C.
\newblock Toprank: A practical algorithm for online stochastic ranking.
\newblock In \emph{Proceedings of the 31st Conference on Neural Information
  Processing Systems}. 2018.

\bibitem[Li et~al.(2010)Li, Chu, Langford, and Schapire]{LC10}
Li, L., Chu, W., Langford, J., and Schapire, R.~E.
\newblock A contextual-bandit approach to personalized news article
  recommendation.
\newblock In \emph{Proceedings of the 19th international conference on world
  wide web}, pp.\  661--670. ACM, 2010.

\bibitem[Li \& Zhang(2018)Li and Zhang]{li18clustering}
Li, S. and Zhang, S.
\newblock Online clustering of contextual cascading bandits.
\newblock In \emph{The 32nd AAAI Conference on Artificial Intelligence}, pp.\
  3554--3561, 2018.

\bibitem[Li et~al.(2016)Li, Wang, Zhang, and Chen]{LWZC16}
Li, S., Wang, B., Zhang, S., and Chen, W.
\newblock Contextual combinatorial cascading bandits.
\newblock In \emph{Proceedings of the 33rd International Conference on Machine
  Learning}, pp.\  1245--1253, 2016.

\bibitem[Liu et~al.(2018)Liu, Li, and Zhang]{LLZ18}
Liu, W., Li, S., and Zhang, S.
\newblock Contextual dependent click bandit algorithm for web recommendation.
\newblock In \emph{International Computing and Combinatorics Conference}, pp.\
  39--50. Springer, 2018.

\bibitem[Radlinski et~al.(2008)Radlinski, Kleinberg, and Joachims]{RKJ08}
Radlinski, F., Kleinberg, R., and Joachims, T.
\newblock Learning diverse rankings with multi-armed bandits.
\newblock In \emph{Proceedings of the 25th International Conference on Machine
  Learning}, pp.\  784--791. ACM, 2008.

\bibitem[Rustichini(1999)]{Rus99}
Rustichini, A.
\newblock Minimizing regret: The general case.
\newblock \emph{Games and Economic Behavior}, 29\penalty0 (1):\penalty0
  224--243, 1999.

\bibitem[Slivkins et~al.(2013)Slivkins, Radlinski, and Gollapudi]{SRG13}
Slivkins, A., Radlinski, F., and Gollapudi, S.
\newblock Ranked bandits in metric spaces: learning diverse rankings over large
  document collections.
\newblock \emph{Journal of Machine Learning Research}, 14\penalty0
  (Feb):\penalty0 399--436, 2013.

\bibitem[Soare et~al.(2014)Soare, Lazaric, and Munos]{SLM14}
Soare, M., Lazaric, A., and Munos, R.
\newblock Best-arm identification in linear bandits.
\newblock In Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N.~D., and
  Weinberger, K.~Q. (eds.), \emph{Advances in Neural Information Processing
  Systems 27}, NIPS, pp.\  828--836. Curran Associates, Inc., 2014.

\bibitem[Todd(2016)]{Tod16}
Todd, M.~J.
\newblock \emph{Minimum-volume ellipsoids: Theory and algorithms}.
\newblock SIAM, 2016.

\bibitem[Valko et~al.(2014)Valko, Munos, Kveton, and Koc{\'a}k]{VMKK14}
Valko, M., Munos, R., Kveton, B., and Koc{\'a}k, T.
\newblock Spectral bandits for smooth graph functions.
\newblock In Xing, E.~P. and Jebara, T. (eds.), \emph{Proceedings of the 31st
  International Conference on Machine Learning}, volume~32 of \emph{Proceedings
  of Machine Learning Research}, pp.\  46--54, Bejing, China, 22--24 Jun 2014.
  PMLR.

\bibitem[Wang et~al.(2018)Wang, Golbandi, Bendersky, Metzler, and
  Najork]{wang2018position}
Wang, X., Golbandi, N., Bendersky, M., Metzler, D., and Najork, M.
\newblock Position bias estimation for unbiased learning to rank in personal
  search.
\newblock In \emph{Proceedings of the Eleventh ACM International Conference on
  Web Search and Data Mining}, pp.\  610--618. ACM, 2018.

\bibitem[Xu et~al.(2017)Xu, Honda, and Sugiyama]{XHS17}
Xu, L., Honda, J., and Sugiyama, M.
\newblock Fully adaptive algorithm for pure exploration in linear bandits.
\newblock \emph{arXiv preprint arXiv:1710.05552}, 2017.

\bibitem[Zoghi et~al.(2017)Zoghi, Tunys, Ghavamzadeh, Kveton, {Sz}epesv{\'a}ri,
  and Wen]{ZTG17}
Zoghi, M., Tunys, T., Ghavamzadeh, M., Kveton, B., {Sz}epesv{\'a}ri, C., and
  Wen, Z.
\newblock Online learning to rank in stochastic click models.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, volume~70 of \emph{PMLR}, pp.\  4199--4208, 2017.

\bibitem[Zong et~al.(2016)Zong, Ni, Sung, Ke, Wen, and Kveton]{ZNK16}
Zong, S., Ni, H., Sung, K., Ke, R.~N., Wen, Z., and Kveton, B.
\newblock Cascading bandits for large-scale recommendation problems.
\newblock In \emph{Proceedings of the 32nd Conference on Uncertainty in
  Artificial Intelligence}, UAI, 2016.

\end{thebibliography}
