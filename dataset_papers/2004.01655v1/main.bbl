\begin{thebibliography}{27}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bengio et~al.(2009)Bengio, Louradour, Collobert, and
  Weston]{bengio2009curriculum}
Bengio, Y., Louradour, J., Collobert, R., and Weston, J.
\newblock Curriculum learning.
\newblock In \emph{Proceedings of the 26th Annual International Conference on
  Machine Learning}, pp.\  41--48, 2009.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Ghazvininejad et~al.(2019)Ghazvininejad, Levy, Liu, and
  Zettlemoyer]{ghazvininejad2019}
Ghazvininejad, M., Levy, O., Liu, Y., and Zettlemoyer, L.
\newblock Mask-predict: Parallel decoding of conditional masked language
  models.
\newblock In \emph{Proc.\ of EMNLP-IJCNLP}, 2019.
\newblock URL \url{https://www.aclweb.org/anthology/D19-1633}.

\bibitem[Ghazvininejad et~al.(2020)Ghazvininejad, Levy, and
  Zettlemoyer]{ghazvininejad2020semi}
Ghazvininejad, M., Levy, O., and Zettlemoyer, L.
\newblock Semi-autoregressive training improves mask-predict decoding.
\newblock \emph{arXiv preprint arXiv:2001.08785}, 2020.

\bibitem[Gu et~al.(2018)Gu, Bradbury, Xiong, Li, and Socher]{gu2017}
Gu, J., Bradbury, J., Xiong, C., Li, V.~O., and Socher, R.
\newblock Non-autoregressive neural machine translation.
\newblock In \emph{Proc. of ICLR}, 2018.

\bibitem[Gu et~al.(2019)Gu, Wang, and Zhao]{gu2019levenshtein}
Gu, J., Wang, C., and Zhao, J.
\newblock Levenshtein transformer.
\newblock In \emph{Proc. of NeurIPS}, 2019.
\newblock URL \url{https://arxiv.org/abs/1905.11006}.

\bibitem[Kasai et~al.(2020)Kasai, Cross, Ghazvininejad, and
  Gu]{kasai2020parallel}
Kasai, J., Cross, J., Ghazvininejad, M., and Gu, J.
\newblock Parallel machine translation with disentangled context transformer.
\newblock \emph{arXiv preprint arXiv:2001.05136}, 2020.

\bibitem[Kim \& Rush(2016)Kim and Rush]{Kim2016SequenceLevelKD}
Kim, Y. and Rush, A.~M.
\newblock Sequence-level knowledge distillation.
\newblock In \emph{Proc.\ of EMNLP}, 2016.
\newblock URL \url{https://arxiv.org/abs/1606.07947}.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{Kingma2015}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference for Learning Representations},
  2015.

\bibitem[Lee et~al.(2018)Lee, Mansimov, and Cho]{lee2018}
Lee, J.~D., Mansimov, E., and Cho, K.
\newblock Deterministic non-autoregressive neural sequence modeling by
  iterative refinement.
\newblock In \emph{Proc. of EMNLP}, 2018.
\newblock URL \url{https://arxiv.org/abs/1802.06901}.

\bibitem[Li et~al.(2019)Li, Lin, He, Tian, Qin, Wang, and Liu]{li2019}
Li, Z., Lin, Z., He, D., Tian, F., Qin, T., Wang, L., and Liu, T.-Y.
\newblock Hint-based training for non-autoregressive machine translation.
\newblock \emph{arXiv preprint arXiv:1909.06708}, 2019.

\bibitem[Libovick{\'y} \& Helcl(2018)Libovick{\'y} and Helcl]{libovicky2018}
Libovick{\'y}, J. and Helcl, J.
\newblock End-to-end non-autoregressive neural machine translation with
  connectionist temporal classification.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  3016--3021, Brussels, Belgium, 2018.
  Association for Computational Linguistics.
\newblock URL \url{http://www.aclweb.org/anthology/D18-1336}.

\bibitem[Ma et~al.(2019)Ma, Zhou, Li, Neubig, and Hovy]{ma2019flowseq}
Ma, X., Zhou, C., Li, X., Neubig, G., and Hovy, E.
\newblock Flowseq: Non-autoregressive conditional sequence generation with
  generative flow.
\newblock \emph{arXiv preprint arXiv:1909.02480}, 2019.

\bibitem[Neubig et~al.(2019)Neubig, Dou, Hu, Michel, Pruthi, and
  Wang]{neubig2019}
Neubig, G., Dou, Z.-Y., Hu, J., Michel, P., Pruthi, D., and Wang, X.
\newblock compare-mt: A tool for holistic comparison of language generation
  systems.
\newblock In \emph{Meeting of the North American Chapter of the Association for
  Computational Linguistics (NAACL) Demo Track}, Minneapolis, USA, June 2019.
\newblock URL \url{http://arxiv.org/abs/1903.07926}.

\bibitem[Papineni et~al.(2002)Papineni, Roukos, Ward, and Zhu]{papineni2002}
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.
\newblock {B}leu: a method for automatic evaluation of machine translation.
\newblock In \emph{Proceedings of the 40th Annual Meeting of the Association
  for Computational Linguistics}. Association for Computational Linguistics,
  July 2002.
\newblock URL \url{https://www.aclweb.org/anthology/P02-1040}.

\bibitem[Post(2018)]{post2018}
Post, M.
\newblock A call for clarity in reporting {BLEU} scores.
\newblock In \emph{Proceedings of the Third Conference on Machine Translation:
  Research Papers}. Association for Computational Linguistics, October 2018.
\newblock URL \url{https://www.aclweb.org/anthology/W18-6319}.

\bibitem[Sakoe \& Chiba(1978)Sakoe and Chiba]{dtw}
Sakoe, H. and Chiba, S.
\newblock Dynamic programming algorithm optimization for spoken word
  recognition.
\newblock \emph{IEEE transactions on acoustics, speech, and signal processing},
  26\penalty0 (1):\penalty0 43--49, 1978.

\bibitem[Sennrich et~al.(2016)Sennrich, Haddow, and Birch]{sennrich2016}
Sennrich, R., Haddow, B., and Birch, A.
\newblock Neural machine translation of rare words with subword units.
\newblock In \emph{Proceedings of the 54th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, August 2016.
\newblock URL \url{https://www.aclweb.org/anthology/P16-1162}.

\bibitem[Shao et~al.(2019)Shao, Zhang, Feng, Meng, and
  Zhou]{shao2019minimizing}
Shao, C., Zhang, J., Feng, Y., Meng, F., and Zhou, J.
\newblock Minimizing the bag-of-ngrams difference for non-autoregressive neural
  machine translation.
\newblock \emph{arXiv preprint arXiv:1911.09320}, 2019.

\bibitem[Shu et~al.(2019)Shu, Lee, Nakayama, and Cho]{shu2019latent}
Shu, R., Lee, J., Nakayama, H., and Cho, K.
\newblock Latent-variable non-autoregressive neural machine translation with
  deterministic inference using a delta posterior.
\newblock \emph{arXiv preprint arXiv:1908.07181}, 2019.

\bibitem[Stern et~al.(2019)Stern, Chan, Kiros, and Uszkoreit]{stern2019}
Stern, M., Chan, W., Kiros, J.~R., and Uszkoreit, J.
\newblock Insertion transformer: Flexible sequence generation via insertion
  operations.
\newblock In \emph{Proc.\ of ICML}, 2019.
\newblock URL \url{https://arxiv.org/abs/1902.03249}.

\bibitem[Sun et~al.(2019)Sun, Li, Wang, He, Lin, and Deng]{sun2019}
Sun, Z., Li, Z., Wang, H., He, D., Lin, Z., and Deng, Z.
\newblock Fast structured decoding for sequence models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3011--3020, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  5998--6008, 2017.

\bibitem[Wang et~al.(2019)Wang, Tian, He, Qin, Zhai, and
  Liu]{Wang2019NonAutoregressiveMT}
Wang, Y., Tian, F., He, D., Qin, T., Zhai, C., and Liu, T.-Y.
\newblock Non-autoregressive machine translation with auxiliary regularization.
\newblock In \emph{Proc.\ of AAAI}, 2019.
\newblock URL \url{https://arxiv.org/abs/1902.10245}.

\bibitem[Wu et~al.(2019)Wu, Fan, Baevski, Dauphin, and Auli]{wu2019pay}
Wu, F., Fan, A., Baevski, A., Dauphin, Y.~N., and Auli, M.
\newblock Pay less attention with lightweight and dynamic convolutions.
\newblock \emph{International Conference on Learning Representations}, 2019.

\bibitem[Yang et~al.(2019)Yang, Liu, and Zou]{yang2019non}
Yang, B., Liu, F., and Zou, Y.
\newblock Non-autoregressive video captioning with iterative refinement.
\newblock \emph{arXiv preprint arXiv:1911.12018}, 2019.

\bibitem[Zhou et~al.(2019)Zhou, Neubig, and Gu]{zhou2019understanding}
Zhou, C., Neubig, G., and Gu, J.
\newblock Understanding knowledge distillation in non-autoregressive machine
  translation.
\newblock \emph{arXiv preprint arXiv:1911.02727}, 2019.

\end{thebibliography}
