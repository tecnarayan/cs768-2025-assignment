@article{10.1007/s00158-020-02748-4,
	title        = {TOuNN: Topology Optimization Using Neural Networks},
	author       = {Chandrasekhar, Aaditya and Suresh, Krishnan},
	year         = {2021},
	month        = {mar},
	journal      = {Struct. Multidiscip. Optim.},
	publisher    = {Springer-Verlag},
	address      = {Berlin, Heidelberg},
	volume       = {63},
	number       = {3},
	pages        = {1135–1149},
	doi          = {10.1007/s00158-020-02748-4},
	issn         = {1615-147X},
	url          = {https://doi.org/10.1007/s00158-020-02748-4},
	issue_date   = {Mar 2021},
	abstract     = {Neural networks, and more broadly, machine learning techniques, have been recently exploited to accelerate topology optimization through data-driven training and image processing. In this paper, we demonstrate that one can directly execute topology optimization (TO) using neural networks (NN). The primary concept is to use the NN’s activation functions to represent the popular Solid Isotropic Material with Penalization (SIMP) density field. In other words, the density function is parameterized by the weights and bias associated with the NN, and spanned by NN’s activation functions; the density representation is thus independent of the finite element mesh. Then, by relying on the NN’s built-in backpropogation, and a conventional finite element solver, the density field is optimized. Methods to impose design and manufacturing constraints within the proposed framework are described and illustrated. A byproduct of representing the density field via activation functions is that it leads to a crisp and differentiable boundary. The proposed framework is simple to implement and is illustrated through 2D and 3D examples. Some of the unresolved challenges with the proposed framework are also summarized.},
	numpages     = {15},
	keywords     = {Topology optimization, Neural networks, Machine learning}
}
@article{10.1115/1.2916916,
	title        = {A New Graph Representation for the Automatic Kinematic Analysis of Planetary Spur-Gear Trains},
	author       = {Hsu, Cheng-Ho and Lam, Kin-Tak},
	year         = {1992},
	month        = {03},
	journal      = {Journal of Mechanical Design},
	volume       = {114},
	number       = {1},
	pages        = {196--200},
	doi          = {10.1115/1.2916916},
	issn         = {1050-0472},
	url          = {https://doi.org/10.1115/1.2916916},
	abstract     = {The purpose of this paper is to propose a new graph representation to represent the kinematic structure of a planetary spur-gear train efficiently. Based on the graph representation, the kinematic analysis of planetary spur-gear trains is largely simplified. An interactive computer program is developed for the kinematic analysis of planetary spur-gear trains with any number of degrees of freedom. By only inputting the graph representation of a planetary spur-gear train and the data for the mating gear pairs, all possible fundamental circuits are determined and the rotational displacement equations are derived and solved automatically.},
	eprint       = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/114/1/196/5506580/196\_1.pdf}
}
@article{10.1115/1.4038303,
	title        = {New Graph Representation for Planetary Gear Trains},
	author       = {Yang, Wenjian and Ding, Huafeng and Zi, Bin and Zhang, Dan},
	year         = {2017},
	month        = {11},
	journal      = {Journal of Mechanical Design},
	volume       = {140},
	number       = {1},
	doi          = {10.1115/1.4038303},
	issn         = {1050-0472},
	url          = {https://doi.org/10.1115/1.4038303},
	note         = {012303},
	abstract     = {Planetary gear trains (PGTs) are widely used in machinery to transmit angular velocity ratios or torque ratios. The graph theory has been proved to be an effective tool to synthesize and analyze PGTs. This paper aims to propose a new graph model, which has some merits relative to the existing ones, to represent the structure of PGTs. First, the rotation graph and canonical rotation graph of PGTs are defined. Then, by considering the edge levels in the rotation graph, the displacement graph and canonical displacement graph are defined. Each displacement graph corresponds to a PGT having the specified functional characteristics. The synthesis of five-link one degree-of-freedom (1DOF) PGTs is used as an example to interpret and demonstrate the applicability of the present graph representation in the synthesis process. The present graph representation can completely avoid the generation of pseudo-isomorphic graphs and can be used in the computer-aided synthesis and analysis of PGTs.},
	eprint       = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/140/1/012303/6231560/md\_140\_01\_012303.pdf}
}
@article{10.1115/1.4048422,
	title        = {An Image-Based Approach to Variational Path Synthesis of Linkages},
	author       = {Deshpande, Shrinath and Purwar, Anurag},
	year         = {2020},
	month        = {10},
	journal      = {Journal of Computing and Information Science in Engineering},
	volume       = {21},
	number       = {2},
	doi          = {10.1115/1.4048422},
	issn         = {1530-9827},
	url          = {https://doi.org/10.1115/1.4048422},
	note         = {021005},
	abstract     = {This paper brings together computer vision, mechanism synthesis, and machine learning to create an image-based variational path synthesis approach for linkage mechanisms. An image-based approach is particularly amenable to mechanism synthesis when the input from mechanism designers is deliberately imprecise or inherently uncertain due to the nature of the problem. In addition, it also lends itself naturally to the creation of a unified approach to mechanism synthesis for different types of mechanisms, since for example, images are formed from a collection of pixels, which themselves could be generated from a four-bar or six-bar. Path synthesis problems have generally been solved for a set of precision points on the intended path such that the designed mechanism passes through those points. This approach usually leads to a small set of over-fitted solutions to particular precision points. However, most kinematic synthesis problems are concept generation problems, where a designer cares more about generating a large number of plausible solutions, which could reach given precision points only approximately. This paper models the input curve as a probability distribution of image pixels and employs a probabilistic generative model to capture the inherent uncertainty in the input. In addition, it gives feedback on the input quality and provides corrections for a more conducive input. The image representation allows for capturing local spatial correlations, which plays an important role in finding a variety of solutions with similar semantics as the input curve. This approach is also conducive to implementation for pressure-sensitive touch-based design interfaces, where the input is not a zero-thickness curve, but the sweep of a small patch on the finger.},
	eprint       = {https://asmedigitalcollection.asme.org/computingengineering/article-pdf/21/2/021005/6577132/jcise\_21\_2\_021005.pdf}
}
@article{10.1115/1.4053859,
	title        = {Deep Generative Models in Engineering Design: A Review},
	author       = {Regenwetter, Lyle and Nobari, Amin Heyrani and Ahmed, Faez},
	year         = {2022},
	month        = {03},
	journal      = {Journal of Mechanical Design},
	volume       = {144},
	number       = {7},
	doi          = {10.1115/1.4053859},
	issn         = {1050-0472},
	url          = {https://doi.org/10.1115/1.4053859},
	note         = {071704},
	eprint       = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/144/7/071704/6866682/md\_144\_7\_071704.pdf}
}
@inproceedings{10.1115/DETC2013-13058,
	title        = {Topology Optimization of Fluid Channels Using Generative Graph Grammars},
	author       = {Hooshmand, Amir and Campbell, Matthew I.},
	year         = {2013},
	month        = {08},
	series       = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {Volume 3A: 39th Design Automation Conference},
	doi          = {10.1115/DETC2013-13058},
	url          = {https://doi.org/10.1115/DETC2013-13058},
	note         = {V03AT03A009},
	abstract     = {This paper presents a new technique for topology optimization of fluid channels using generative design methods. The proposed method uses the generative abilities of graph grammars with simulation and analysis power of conventional CFD methods. The graph grammar interpreter GraphSynth is used to carry out graph transformations, which define different topologies for a given multi-inlet multi-outlet problem. The generated graphs are first transformed into meaningful 3D shapes. These solutions are then analyzed by a CFD solver to find the optimum. The effectiveness of the proposed method is checked by solving a variety of available test problems and comparing them with those found in the literature. Furthermore by solving complex problems the robustness and effectiveness of the method is tested.},
	eprint       = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2013/55881/V03AT03A009/4253648/v03at03a009-detc2013-13058.pdf}
}
@inproceedings{10.1115/DETC2014-35652,
	title        = {Graph Based Representation and Analyses for Conceptual Stages},
	author       = {Coatanéa, Eric and Nonsiri, Sarayut and Christophe, Francois and Mokammel, Faisal},
	year         = {2014},
	month        = {08},
	series       = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {Volume 1A: 34th Computers and Information in Engineering Conference},
	doi          = {10.1115/DETC2014-35652},
	url          = {https://doi.org/10.1115/DETC2014-35652},
	note         = {V01AT02A071},
	abstract     = {What is the fundamental similarity between investing in stock of a company, because you like the products of this company, and selecting a design concept, because you have been impressed by the esthetic quality of the presentation made by the team developing the concept?Except that both decisions are based on a surface analysis of the situations, they both reflect a fundamental human’s cognitive feature. Human brain is profoundly trying to minimize the efforts required to solve a cognitive task and is using when possible an automatic mode relying on recognition, memory, and causality. This mode is even used in some occasion without the engineer being conscious of it. Such type of tendencies are naturally pushing engineers to rush into known solutions, to avoid analyzing the context of a design problem, to avoid modelling design problems and to take decision based on isolated evidences. Those behaviors are familiar to experience teachers and engineers. This tendency is magnified by the time pressure imposed to the engineering design process. Early phases in particular have to be kept short despite the large impact of decisions taken at this stage. Few support tools are capable of supporting a deep analysis of the early design conditions and problems regarding the fuzziness and complexity of the early stage. The present article is hypothesizing that the natural ability of humans to deal with cause-effects relations push toward the massive usage of causal graphs analysis during the design process and specifically during the early phases. A global framework based on graphs is presented in this paper to efficiently support the early stages. The approach used to generate graphs, to analyze them and to support creativity based on the analysis is forming the central contribution of this paper.},
	eprint       = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2014/46285/V01AT02A071/4257819/v01at02a071-detc2014-35652.pdf}
}
@inproceedings{10.1115/DETC2016-59404,
	title        = {Deep Network-Based Feature Extraction and Reconstruction of Complex Material Microstructures},
	author       = {Cang, Ruijin and Ren, Max Yi},
	year         = {2016},
	month        = {08},
	series       = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {Volume 2B: 42nd Design Automation Conference},
	doi          = {10.1115/DETC2016-59404},
	url          = {https://doi.org/10.1115/DETC2016-59404},
	note         = {V02BT03A008},
	abstract     = {Computational material design (CMD) aims to accelerate optimal design of complex material systems by integrating material science and design automation. For tractable CMD, it is required that (1) a feature space be identified to allow reconstruction of new designs, and (2) the reconstruction process be property-preserving. Existing solutions rely on the designer’s understanding of specific material systems to identify geometric and statistical features, which could be insufficient for reconstructing physically meaningful microstructures of complex material systems. This paper develops a feature learning mechanism that automates a two-way conversion between microstructures and their lower-dimensional feature representations. The proposed model is applied to four material systems: Ti-6Al-4V alloy, Pb-Sn alloy, Fontainebleau sandstone, and spherical colloids, to produce random reconstructions that are visually similar to the samples. This capability is not achieved by existing synthesis methods relying on the Markovian assumption of material systems. For Ti-6Al-4V alloy, we also show that the reconstructions preserve the mean critical fracture force of the system for a fixed processing setting. Source code and datasets are available.},
	eprint       = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2016/50114/V02BT03A008/2471310/v02bt03a008-detc2016-59404.pdf}
}
@inproceedings{10.1115/DETC2018-85529,
	title        = {Kinematic Synthesis Using Reinforcement Learning},
	author       = {Vermeer, Kaz and Kuppens, Reinier and Herder, Justus},
	year         = {2018},
	month        = {08},
	series       = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {Volume 2A: 44th Design Automation Conference},
	doi          = {10.1115/DETC2018-85529},
	url          = {https://doi.org/10.1115/DETC2018-85529},
	note         = {V02AT03A009},
	abstract     = {The presented research demonstrates the synthesis of two-dimensional kinematic mechanisms using feature-based reinforcement learning. As a running example the classic challenge of designing a straight-line mechanism is adopted: a mechanism capable of tracing a straight line as part of its trajectory. This paper presents a basic framework, consisting of elements such as mechanism representations, kinematic simulations and learning algorithms, as well as some of the resulting mechanisms and a comparison to prior art. Series of successful mechanisms have been synthesized for path generation of a straight line and figure-eight.},
	eprint       = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2018/51753/V02AT03A009/2475681/v02at03a009-detc2018-85529.pdf}
}
@inproceedings{10.1115/DETC2019-97711,
	title        = {Reinforcement Learning Content Generation for Virtual Reality Applications},
	author       = {Lopez, Christian E. and Ashour, Omar and Tucker, Conrad S.},
	year         = {2019},
	month        = {08},
	series       = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {Volume 1: 39th Computers and Information in Engineering Conference},
	doi          = {10.1115/DETC2019-97711},
	url          = {https://doi.org/10.1115/DETC2019-97711},
	note         = {V001T02A009},
	abstract     = {This work presents a Procedural Content Generation (PCG) method based on a Neural Network Reinforcement Learning (RL) approach that generates new environments for Virtual Reality (VR) learning applications. The primary objective of PCG methods is to algorithmically generate new content (e.g., environments, levels) in order to improve user experience. Researchers have started exploring the integration of Machine Learning (ML) algorithms into their PCG methods. These ML approaches help explore the design space and generate new content more efficiently. The capability to provide users with new content has great potential for learning applications. However, these ML algorithms require large datasets to train their generative models. In contrast, RL based methods take advantage of simulation to train their models. Moreover, even though VR has become an emerging technology to engage users, there have been few studies that explore PCG for learning purposes and fewer in the context of VR. Considering these limitations, this work presents a method that generates new VR environments by training an RL agent using a simulation platform. This PCG method has the potential to maintain users’ engagement over time by presenting them with new environments in VR learning applications.},
	eprint       = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2019/59179/V001T02A009/6452689/v001t02a009-detc2019-97711.pdf}
}
@inproceedings{10.1115/DETC2020-22355,
	title        = {Graph Representation of 3D CAD Models for Machining Feature Recognition With Deep Learning},
	author       = {Cao, Weijuan and Robinson, Trevor and Hua, Yang and Boussuge, Flavien and Colligan, Andrew R. and Pan, Wanbin},
	year         = {2020},
	month        = {08},
	series       = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {Volume 11A: 46th Design Automation Conference (DAC)},
	doi          = {10.1115/DETC2020-22355},
	url          = {https://doi.org/10.1115/DETC2020-22355},
	note         = {V11AT11A003},
	abstract     = {In this paper, the application of deep learning methods to the task of machining feature recognition in CAD models is studied. Four contributions are made:1. An automatic method to generate large datasets of 3D CAD models is proposed, where each model contains multiple machining features with face labels.2. A concise and informative graph representation for 3D CAD models is presented. This is shown to be applicable to graph neural networks.3. The graph representation is compared with voxels on their performance of training deep neural networks to segment 3D CAD models.4. Experiments are also conducted to evaluate the effectiveness of graph-based deep learning for interacting feature recognition.Results show that the proposed graph representation is a more efficient representation of 3D CAD models than voxels for deep learning. It is also shown that graph neural networks can be used to recognize individual features on the model and also identify complex interacting features.},
	eprint       = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2020/84003/V11AT11A003/6587023/v11at11a003-detc2020-22355.pdf}
}
@inproceedings{10.1115/DETC2020-22624,
	title        = {Multi-Context Generation in Virtual Reality Environments Using Deep Reinforcement Learning},
	author       = {Cunningham, James and Lopez, Christian and Ashour, Omar and Tucker, Conrad S.},
	year         = {2020},
	month        = {08},
	series       = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {Volume 9: 40th Computers and Information in Engineering Conference (CIE)},
	doi          = {10.1115/DETC2020-22624},
	url          = {https://doi.org/10.1115/DETC2020-22624},
	note         = {V009T09A072},
	abstract     = {In this work, a Deep Reinforcement Learning (RL) approach is proposed for Procedural Content Generation (PCG) that seeks to automate the generation of multiple related virtual reality (VR) environments for enhanced personalized learning. This allows for the user to be exposed to multiple virtual scenarios that demonstrate a consistent theme, which is especially valuable in an educational context. RL approaches to PCG offer the advantage of not requiring training data, as opposed to other PCG approaches that employ supervised learning approaches. This work advances the state of the art in RL-based PCG by demonstrating the ability to generate a diversity of contexts in order to teach the same underlying concept. A case study is presented that demonstrates the feasibility of the proposed RL-based PCG method using examples of probability distributions in both manufacturing facility and grocery store virtual environments. The method demonstrated in this paper has the potential to enable the automatic generation of a variety of virtual environments that are connected by a common concept or theme.},
	eprint       = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2020/83983/V009T09A072/6586781/v009t09a072-detc2020-22624.pdf}
}
%NO BETTER BIBTEX
@article{99code_matlab,
	title        = {A 99 Line Topology Optimization Code Written in Matlab},
	author       = {Sigmund, O.},
	year         = {2001},
	month        = {apr},
	journal      = {Struct. Multidiscip. Optim.},
	publisher    = {Springer-Verlag},
	address      = {Berlin, Heidelberg},
	volume       = {21},
	number       = {2},
	pages        = {120–127},
	doi          = {10.1007/s001580050176},
	issn         = {1615-147X},
	url          = {https://doi.org/10.1007/s001580050176},
	issue_date   = {April     2001},
	abstract     = {The paper presents a compact Matlab implementation of a topology optimization code for compliance minimization of statically loaded structures. The total number of Matlab input lines is 99 including optimizer and Finite Element subroutine. The 99 lines are divided into 36 lines for the main program, 12 lines for the Optimality Criteria based optimizer, 16 lines for a mesh-independency filter and 35 lines for the finite element code. In fact, excluding comment lines and lines associated with output and finite element analysis, it is shown that only 49 Matlab input lines are required for solving a well-posed topology optimization problem. By adding three additional lines, the program can solve problems with multiple load cases. The code is intended for educational purposes. The complete Matlab code is given in the Appendix and can be down-loaded from the web-site http://www.topopt.dtu.dk.},
	numpages     = {8},
	keywords     = {world-wide web, Key words: topology optimization, Matlab code, education, optimality criteria}
}
@article{AbueiddaAlsmarietal2019,
	title        = {Prediction and optimization of mechanical properties of composites using convolutional neural networks},
	author       = {Abueidda, Diab W. and Almasri, Mohammad and Ammourah, Rami and Ravaioli, Umberto and Jasiuk, Iwona M. and Sobh, Nahil A.},
	year         = {2019},
	month        = {11},
	journal      = {Composite Structures},
	volume       = {227},
	pages        = {111264},
	doi          = {10.1016/j.compstruct.2019.111264},
	issn         = {02638223},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0263822319312383}
}
@article{Abueiddaetal2020,
	title        = {Topology optimization of 2D structures with nonlinearities using deep learning},
	author       = {Abueidda, Diab W. and Koric, Seid and Sobh, Nahil A.},
	year         = {2020},
	month        = {9},
	journal      = {Computers {\&} Structures},
	publisher    = {Elsevier Ltd},
	volume       = {237},
	pages        = {106283},
	doi          = {10.1016/j.compstruc.2020.106283},
	issn         = {00457949},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0045794920300869},
	keywords     = {Adjoint sensitivity, Finite element analysis (FEA), Machine learning, Neo-Hookean materials, Stress constraint}
}
@article{achille2018emergence,
	title        = {Emergence of invariance and disentanglement in deep representations},
	author       = {Achille, Alessandro and Soatto, Stefano},
	year         = {2018},
	journal      = {The Journal of Machine Learning Research},
	publisher    = {JMLR. org},
	volume       = {19},
	number       = {1},
	pages        = {1947--1980}
}
@article{achille2018information,
	title        = {Information dropout: Learning optimal representations through noisy computation},
	author       = {Achille, Alessandro and Soatto, Stefano},
	year         = {2018},
	journal      = {IEEE transactions on pattern analysis and machine intelligence},
	publisher    = {IEEE},
	volume       = {40},
	number       = {12},
	pages        = {2897--2905}
}
@inproceedings{achille2018life,
	title        = {Life-long disentangled representation learning with cross-domain latent homologies},
	author       = {Achille, Alessandro and Eccles, Tom and Matthey, Loic and Burgess, Chris and Watters, Nicholas and Lerchner, Alexander and Higgins, Irina},
	year         = {2018},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {9895--9905}
}
@article{AdeliPark1995,
	title        = {A neural dynamics model for structural optimization—Theory},
	author       = {Adeli, H. and Park, Hyo Seon},
	year         = {1995},
	month        = {11},
	journal      = {Computers {\&} Structures},
	volume       = {57},
	number       = {3},
	pages        = {383--390},
	doi          = {10.1016/0045-7949(95)00048-L},
	issn         = {00457949},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/004579499500048L}
}
@article{AdeliPark1995b,
	title        = {Optimization of space structures by neural dynamics},
	author       = {Adeli, Hojjat and Park, Hyo Seon},
	year         = {1995},
	month        = {1},
	journal      = {Neural Networks},
	volume       = {8},
	number       = {5},
	pages        = {769--781},
	doi          = {10.1016/0893-6080(95)00026-V},
	issn         = {08936080},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/089360809500026V},
	keywords     = {Design automation, Lyapunov function, Neural networks, minimum weight design, optimization, trusses}
}
@article{affNIST,
	title        = {The affNIST dataset},
	author       = {Tijmen Tieleman},
	year         = {2013},
	url          = {http://www.cs.toronto.edu/~tijmen/affNIST}
}
@inproceedings{ahmed2013constructive,
	title        = {Constructive solid geometry based topology optimization using evolutionary algorithm},
	author       = {Ahmed, Faez and Bhattacharya, Bishakh and Deb, Kalyanmoy},
	year         = {2013},
	booktitle    = {Proceedings of seventh international conference on bio-inspired computing: theories and applications (BIC-TA 2012)},
	pages        = {227--238},
	organization = {Springer}
}
@inproceedings{ahmed2016discovering,
	title        = {Discovering diverse, high quality design ideas from a large corpus},
	author       = {Ahmed, Faez and Fuge, Mark and Gorbunov, Lev D},
	year         = {2016},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {50190},
	pages        = {V007T06A008},
	organization = {American Society of Mechanical Engineers}
}
@article{allaire2002level,
	title        = {A level-set method for shape optimization},
	author       = {Allaire, Gr{\'e}goire and Jouve, Fran{\c{c}}ois and Toader, Anca-Maria},
	year         = {2002},
	journal      = {Comptes Rendus Mathematique},
	publisher    = {Elsevier},
	volume       = {334},
	number       = {12},
	pages        = {1125--1130}
}
@article{Allaireetal2002,
	title        = {A level-set method for shape optimization},
	author       = {Allaire, Grégoire and Jouve, François and Toader, Anca-Maria},
	year         = {2002},
	month        = {1},
	journal      = {Comptes Rendus Mathematique},
	volume       = {334},
	number       = {12},
	pages        = {1125--1130},
	doi          = {10.1016/S1631-073X(02)02412-3},
	issn         = {1631073X},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S1631073X02024123}
}
@book{ambrosio2008gradient,
	title        = {Gradient flows: in metric spaces and in the space of probability measures},
	author       = {Ambrosio, Luigi and Gigli, Nicola and Savar{\'e}, Giuseppe},
	year         = {2008},
	publisher    = {Springer Science \& Business Media}
}
@article{AmirSigmund2011,
	title        = {On reducing computational effort in topology optimization: how far can we go?},
	author       = {Amir, Oded and Sigmund, Ole},
	year         = {2011},
	month        = {7},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {44},
	number       = {1},
	pages        = {25--29},
	doi          = {10.1007/s00158-010-0586-7},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-010-0586-7}
}
@article{anderson1987shifter,
	title        = {Shifter circuits: a computational strategy for dynamic aspects of visual processing},
	author       = {Anderson, Charles H and Van Essen, David C},
	year         = {1987},
	journal      = {Proceedings of the National Academy of Sciences},
	publisher    = {National Acad Sciences},
	volume       = {84},
	number       = {17},
	pages        = {6297--6301}
}
@article{Andreassenetal2011,
	title        = {Efficient topology optimization in MATLAB using 88 lines of code},
	author       = {Andreassen, Erik and Clausen, Anders and Schevenels, Mattias and Lazarov, Boyan S. and Sigmund, Ole},
	year         = {2011},
	month        = {1},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {43},
	number       = {1},
	pages        = {1--16},
	doi          = {10.1007/s00158-010-0594-7},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-010-0594-7},
	keywords     = {Computational efficiency, Education, MATLAB, Topology optimization}
}
@inproceedings{andrychowicz2016learning,
	title        = {Learning to learn by gradient descent by gradient descent},
	author       = {Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W and Pfau, David and Schaul, Tom and Shillingford, Brendan and De Freitas, Nando},
	year         = {2016},
	booktitle    = {Advances in neural information processing systems},
	pages        = {3981--3989}
}
@article{ansari2018hyperprior,
	title        = {Hyperprior Induced Unsupervised Disentanglement of Latent Representations},
	author       = {Ansari, Abdul Fatir and Soh, Harold},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1809.04497}
}
@techreport{anselmi2014representation,
	title        = {Representation learning in sensory cortex: a theory},
	author       = {Anselmi, Fabio and Poggio, Tomaso},
	year         = {2014},
	institution  = {Center for Brains, Minds and Machines (CBMM)}
}
@article{arjovsky2017towards,
	title        = {Towards principled methods for training generative adversarial networks},
	author       = {Arjovsky, Martin and Bottou, L{\'e}on},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1701.04862}
}
@inproceedings{arjovsky2017wasserstein,
	title        = {Wasserstein generative adversarial networks},
	author       = {Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
	year         = {2017},
	booktitle    = {International conference on machine learning},
	pages        = {214--223},
	organization = {PMLR}
}
% BibTeX database for the paper asme2e.tex
%% bibtexfile{
%% author    = 
"Harry H. Cheng",
%% version   =  "2",
%% date      =  "January  01,
2003",
%% filename  =  "asme2e.bib",
%% address   =  "Integration
Engineering Laboratory
%%              Department of Mechanical and
Aeronautical Engineering
%%              University of California
%%        
     Davis, CA 95616",
%% telephone =  "(530) 752-5020 (office)
%%          
    (530) 752-1028 (lab)
%%               (530) 752-4158 (Fax:)",
%% email  
  =  "<hhcheng at ucdavis.edu>" }
@article{art,
	title        = {Article title},
	author       = {A. Author and B. Author and C. Author},
	year         = {1994},
	month        = {May},
	journal      = {Journal {N}ame},
	volume       = {1},
	number       = {5},
	pages        = {1--3}
}
@article{arvanitidis2017latent,
	title        = {Latent space oddity: on the curvature of deep generative models},
	author       = {Arvanitidis, Georgios and Hansen, Lars Kai and Hauberg, S{\o}ren},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1710.11379}
}
@article{ashual2022knn,
	title        = {KNN-Diffusion: Image Generation via Large-Scale Retrieval},
	author       = {Ashual, Oron and Sheynin, Shelly and Polyak, Adam and Singer, Uriel and Gafni, Oran and Nachmani, Eliya and Taigman, Yaniv},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2204.02849}
}
@manual{asmemanual,
	title        = {{ASME} Manual {MS-4}, An {ASME} Paper},
	author       = {ASME},
	year         = {2003},
	address      = {New York},
	note         = {See also URL \verb+http://www.asme.org/pubs/MS4.html+},
	organization = {The American Society of Mechanical Engineers},
	edition      = {latest}
}
@article{AtesGorguluarslan2021,
	title        = {Two-stage convolutional encoder-decoder network to improve the performance and reliability of deep learning models for topology optimization},
	author       = {Ates, Gorkem Can and Gorguluarslan, Recep M.},
	year         = {2021},
	month        = {4},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	volume       = {63},
	number       = {4},
	pages        = {1927--1950},
	doi          = {10.1007/s00158-020-02788-w},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-020-02788-w},
	keywords     = {Convolutional neural network, Deep learning, Encoder and decoder network, Neural network, Topology optimization}
}
@inproceedings{aubry2014seeing,
	title        = {Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models},
	author       = {Aubry, Mathieu and Maturana, Daniel and Efros, Alexei A and Russell, Bryan C and Sivic, Josef},
	year         = {2014},
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {3762--3769}
}
@inproceedings{AuligOlhofer2013,
	title        = {Evolutionary generation of neural network update signals for the topology optimization of structures},
	author       = {Aulig, Nikola and Olhofer, Markus},
	year         = {2013},
	month        = {7},
	booktitle    = {Proceedings of the 15th annual conference companion on Genetic and evolutionary computation},
	publisher    = {ACM},
	address      = {New York, NY, USA},
	pages        = {213--214},
	doi          = {10.1145/2464576.2464685},
	isbn         = {9781450319645},
	url          = {https://dl.acm.org/doi/10.1145/2464576.2464685},
	keywords     = {Evolutionary learning, Evolutionary strategy, Neural net- work, Structural optimization, Topology optimization, Update signal}
}
@techreport{AuligOlhofer2014,
	title        = {TOPOLOGY OPTIMIZATION BY PREDICTING SENSITIVITIES BASED ON LOCAL STATE FEATURES},
	author       = {Olhofer, Markus and O{\~{n}}ate, E and Oliver, J and Huerta, A and Aulig, Nikola},
	year         = {2014},
	url          = {https://www.researchgate.net/publication/265593998},
	keywords     = {Finite Differencing, Linear Regression, Local State Features, Sensitivity Prediction, Support Vector Regression, Topology Optimization}
}
@book{AuligOlhofer2015,
	title        = {Applications of Evolutionary Computation},
	author       = {Aulig, Nikola and Olhofer, Markus},
	year         = {2015},
	booktitle    = {Applications of Evolutionary Computation, 18th European Conference, EvoApplications 2015, Copenhagen, Denmark, April 8–10, 2015},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	series       = {Lecture Notes in Computer Science},
	volume       = {9028},
	pages        = {655--666},
	doi          = {10.1007/978-3-319-16549-3},
	isbn         = {978-3-319-16548-6},
	url          = {http://link.springer.com/10.1007/978-3-319-16549-3},
	editor       = {Mora, Antonio M. and Squillero, Giovanni}
}
@article{austin2021structured,
	title        = {Structured denoising diffusion models in discrete state-spaces},
	author       = {Austin, Jacob and Johnson, Daniel and Ho, Jonathan and Tarlow, Daniel and van den Berg, Rianne},
	year         = {2021},
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {34}
}
@article{Baandrup2020,
	title        = {Closing the gap towards super-long suspension bridges using computational morphogenesis},
	author       = {Baandrup, Mads and Sigmund, Ole and Polk, Henrik and Aage, Niels},
	year         = {2020},
	month        = {12},
	journal      = {Nature Communications},
	volume       = {11},
	number       = {1},
	pages        = {2735},
	doi          = {10.1038/s41467-020-16599-6},
	issn         = {2041-1723}
}
@article{bahdanau2014neural,
	title        = {Neural machine translation by jointly learning to align and translate},
	author       = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	year         = {2014},
	journal      = {arXiv preprint arXiv:1409.0473}
}
@book{Balasetal2020,
	title        = {Recent Trends and Advances in Artificial Intelligence and Internet of Things},
	author       = {Balas, Valentina E and Kumar, Raghvendra and Srivastava, Rajshree},
	year         = {2020},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	series       = {Intelligent Systems Reference Library},
	volume       = {172},
	doi          = {10.1007/978-3-030-32644-9},
	isbn         = {978-3-030-32643-2},
	url          = {http://link.springer.com/10.1007/978-3-030-32644-9},
	editor       = {Balas, Valentina E. and Kumar, Raghvendra and Srivastava, Rajshree}
}
@article{Bangaetal2018,
	title        = {3D Topology Optimization using Convolutional Neural Networks},
	author       = {Banga, Saurabh and Gehani, Harsh and Bhilare, Sanket and Patel, Sagar and Kara, Levent},
	year         = {2018},
	month        = {8},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/1808.07440},
	arxivid      = {1808.07440}
}
@article{bao2021beit,
	title        = {Beit: Bert pre-training of image transformers},
	author       = {Bao, Hangbo and Dong, Li and Wei, Furu},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2106.08254}
}
@article{bao2022analytic,
	title        = {Analytic-dpm: an analytic estimate of the optimal reverse variance in diffusion probabilistic models},
	author       = {Bao, Fan and Li, Chongxuan and Zhu, Jun and Zhang, Bo},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2201.06503}
}
@article{baranchuk2021label,
	title        = {Label-Efficient Semantic Segmentation with Diffusion Models},
	author       = {Baranchuk, Dmitry and Rubachev, Ivan and Voynov, Andrey and Khrulkov, Valentin and Babenko, Artem},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2112.03126}
}
@article{Barmadaetal2021,
	title        = {A Deep Learning Surrogate Model for Topology Optimization},
	author       = {Barmada, Sami and Fontana, Nunzia and Formisano, Alessandro and Thomopulos, Dimitri and Tucci, Mauro},
	year         = {2021},
	month        = {6},
	journal      = {IEEE Transactions on Magnetics},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	volume       = {57},
	number       = {6},
	pages        = {1--4},
	doi          = {10.1109/TMAG.2021.3063470},
	issn         = {0018-9464},
	url          = {https://ieeexplore.ieee.org/document/9367238/},
	keywords     = {Deep learning (DL), inverse problems, optimization}
}
@book{barton1989elements,
	title        = {Elements of Green's functions and propagation: potentials, diffusion, and waves},
	author       = {Barton, Gy{\"o}rgy and Barton, Gabriel},
	year         = {1989},
	publisher    = {Oxford University Press}
}
@inproceedings{bartunov2018few,
	title        = {Few-shot generative modelling with generative matching networks},
	author       = {Bartunov, Sergey and Vetrov, Dmitry},
	year         = {2018},
	booktitle    = {International Conference on Artificial Intelligence and Statistics},
	pages        = {670--678}
}
@article{battaglia2018relational,
	title        = {Relational inductive biases, deep learning, and graph networks},
	author       = {Battaglia, Peter W and Hamrick, Jessica B and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and others},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1806.01261}
}
@article{bayer2014learning,
	title        = {Learning stochastic recurrent networks},
	author       = {Bayer, Justin and Osendorfer, Christian},
	year         = {2014},
	journal      = {arXiv preprint arXiv:1411.7610}
}
@article{Behzadi_Ilies2021,
	title        = {Real-Time Topology Optimization in 3D via Deep Transfer Learning},
	author       = {Behzadi, Mohammad Mahdi and Ilie{\c{s}}, Horea T.},
	year         = {2021},
	month        = {6},
	journal      = {Computer-Aided Design},
	publisher    = {Elsevier Ltd},
	volume       = {135},
	pages        = {103014},
	doi          = {10.1016/j.cad.2021.103014},
	issn         = {00104485},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0010448521000257},
	keywords     = {Deep learning, Design space explorations, Real-time predictions, Topology optimization, Transfer learning}
}
@article{BEHZADI2021103014,
	title        = {Real-Time Topology Optimization in 3D via Deep Transfer Learning},
	author       = {Mohammad Mahdi Behzadi and Horea T. Ilieş},
	year         = {2021},
	journal      = {Computer-Aided Design},
	volume       = {135},
	pages        = {103014},
	doi          = {https://doi.org/10.1016/j.cad.2021.103014},
	issn         = {0010-4485},
	url          = {https://www.sciencedirect.com/science/article/pii/S0010448521000257}
}
@article{behzadi2021real,
	title        = {Real-time topology optimization in 3d via deep transfer learning},
	author       = {Behzadi, Mohammad Mahdi and Ilie{\c{s}}, Horea T},
	year         = {2021},
	journal      = {Computer-Aided Design},
	publisher    = {Elsevier},
	volume       = {135},
	pages        = {103014}
}
@article{BehzadiIllies2021,
	title        = {GANTL: Towards Practical and Real-Time Topology Optimization with Conditional GANs and Transfer Learning},
	author       = {Behzadi, Mohammad Mahdi and Ilies, Horea T.},
	year         = {2021},
	month        = {10},
	journal      = {Journal of Mechanical Design},
	pages        = {1--32},
	doi          = {10.1115/1.4052757},
	issn         = {1050-0472},
	url          = {https://asmedigitalcollection.asme.org/mechanicaldesign/article/doi/10.1115/1.4052757/1121902/GANTL-Towards-Practical-and-Real-Time-Topology}
}
@article{bendsoe1988generating,
	title        = {Generating optimal topologies in structural design using a homogenization method},
	author       = {Bends{\o}e, Martin Philip and Kikuchi, Noboru},
	year         = {1988},
	journal      = {Computer methods in applied mechanics and engineering},
	publisher    = {Elsevier},
	volume       = {71},
	number       = {2},
	pages        = {197--224}
}
@article{Bendsoe1989,
	title        = {Optimal shape design as a material distribution problem},
	author       = {Bends{\o}e, M. P.},
	year         = {1989},
	month        = {12},
	journal      = {Structural Optimization},
	volume       = {1},
	number       = {4},
	pages        = {193--202},
	doi          = {10.1007/BF01650949},
	issn         = {0934-4373},
	url          = {http://link.springer.com/10.1007/BF01650949}
}
@article{bendsoe1989optimal,
	title        = {Optimal shape design as a material distribution problem},
	author       = {Bends{\o}e, Martin P},
	year         = {1989},
	journal      = {Structural optimization},
	publisher    = {Springer-Verlag},
	volume       = {1},
	pages        = {193--202}
}
@book{bendsoe2003topology,
	title        = {Topology optimization: theory, methods, and applications},
	author       = {Bendsoe, Martin Philip and Sigmund, Ole},
	year         = {2003},
	publisher    = {Springer Science \& Business Media}
}
@article{BendsoeKikuchi1988,
	title        = {Generating optimal topologies in structural design using a homogenization method},
	author       = {Bends{\o}e, Martin Philip and Kikuchi, Noboru},
	year         = {1988},
	month        = {11},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	volume       = {71},
	number       = {2},
	pages        = {197--224},
	doi          = {10.1016/0045-7825(88)90086-2},
	issn         = {00457825},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/0045782588900862}
}
@article{bengio2009learning,
	title        = {Learning deep architectures for AI},
	author       = {Bengio, Yoshua and others},
	year         = {2009},
	journal      = {Foundations and trends{\textregistered} in Machine Learning},
	publisher    = {Now Publishers, Inc.},
	volume       = {2},
	number       = {1},
	pages        = {1--127}
}
@article{bengio2013representation,
	title        = {Representation learning: A review and new perspectives},
	author       = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	year         = {2013},
	journal      = {IEEE transactions on pattern analysis and machine intelligence},
	publisher    = {IEEE},
	volume       = {35},
	number       = {8},
	pages        = {1798--1828}
}
@book{bers1964partial,
	title        = {Partial differential equations},
	author       = {Bers, Lipman and John, Fritz and Schechter, Martin},
	year         = {1964},
	publisher    = {American Mathematical Soc.}
}
@article{berthelot2017began,
	title        = {Began: Boundary equilibrium generative adversarial networks},
	author       = {Berthelot, David and Schumm, Thomas and Metz, Luke},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1703.10717}
}
@article{Bieleckietal2021,
	title        = {Multi-stage deep neural network accelerated topology optimization},
	author       = {Bielecki, Dustin and Patel, Darshil and Rai, Rahul and Dargush, Gary F.},
	year         = {2021},
	month        = {12},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {64},
	number       = {6},
	pages        = {3473--3487},
	doi          = {10.1007/s00158-021-03028-5},
	issn         = {1615-147X},
	url          = {https://link.springer.com/10.1007/s00158-021-03028-5}
}
@book{bishop2006pattern,
	title        = {Pattern recognition and machine learning},
	author       = {Bishop, Christopher M},
	year         = {2006},
	publisher    = {springer}
}
@article{blattmann2022retrieval,
	title        = {Retrieval-Augmented Diffusion Models},
	author       = {Blattmann, Andreas and Rombach, Robin and Oktay, Kaan and Ommer, Bj{\"o}rn},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2204.11824}
}
@article{blei2003latent,
	title        = {Latent dirichlet allocation},
	author       = {Blei, David M and Ng, Andrew Y and Jordan, Michael I},
	year         = {2003},
	journal      = {Journal of machine Learning research},
	volume       = {3},
	number       = {Jan},
	pages        = {993--1022}
}
@inproceedings{bloem2018neural,
	title        = {Neural network models of exchangeable sequences},
	author       = {Bloem-Reddy, Benjamin and Teh, Yee Whye},
	year         = {2018},
	booktitle    = {NeurIPS Workshop on Bayesian Deep Learning}
}
@article{bloem2019probabilistic,
	title        = {Probabilistic symmetry and invariant neural networks},
	author       = {Bloem-Reddy, Benjamin and Teh, Yee Whye},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1901.06082}
}
@article{bloem2020probabilistic,
	title        = {Probabilistic symmetries and invariant neural networks},
	author       = {Bloem-Reddy, Benjamin and Teh, Yee Whye},
	year         = {2020},
	journal      = {Journal of Machine Learning Research},
	publisher    = {Journal of Machine Learning Research},
	volume       = {21},
	number       = {90},
	pages        = {1--61}
}
@article{bloice2017augmentor,
	title        = {Augmentor: an image augmentation library for machine learning},
	author       = {Bloice, Marcus D and Stocker, Christof and Holzinger, Andreas},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1708.04680}
}
@booklet{blt,
	title        = {Booklet title},
	author       = {A. Booklet},
	year         = {1994},
	month        = {May},
	address      = {at \verb+http://www.abc.edu+},
	note         = {PDF file},
	howpublished = {On the WWW}
}
@article{blundell2015weight,
	title        = {Weight uncertainty in neural networks},
	author       = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
	year         = {2015},
	journal      = {arXiv preprint arXiv:1505.05424}
}
@inproceedings{bojchevski2018netgan,
	title        = {NetGAN: Generating Graphs via Random Walks},
	author       = {Bojchevski, Aleksandar and Shchur, Oleksandr and Z{\"u}gner, Daniel and G{\"u}nnemann, Stephan},
	year         = {2018},
	booktitle    = {International Conference on Machine Learning},
	pages        = {609--618}
}
% compression__________________________________________________________________
% compression__________________________________________________________________
% structure____________________________________________________________________
% relaxations_____________________________________________________
% uncertainty___________________________________________________________________
% disentanglement______________________________________________
% dataset____________________________________________________________________________________
% factorisation_____________________________________________________________________________
% Variational Inference
%__________________________________________________________________________________________________________
%______________________________________________________________________
% datasets
@string{JAIR = {{J. Artif. Intell. Res.(JAIR)}}}
@string{AIJ = {{Artificial Intelligence}}}
@string{IEEE = {{Proc. of the IEEE}}}
@string{ECAI = {{Proc. of European Conference on Artificial Intelligence}}}
@string{IJCAI = {{Proc. of International Joint Conference on Artificial Intelligence (IJCAI)}}}
@string{KEPS = {{Proc. of the ICAPS Workshop on Knowledge Engineering for Planning and Scheduling(KEPS)}}}
@string{SPARK = {{Proc. of the ICAPS Workshop on Scheduling and Planning Applications (SPARK)}}}
@string{PRL = {{Proc. of the ICAPS Workshop on Bridging the Gap Between AI Planning and Reinforcement Learning (PRL)}}}
@string{ICAPS = {{Proc. of the International Conference on Automated Planning and Scheduling (ICAPS)}}}
@string{IPC = {{Proc. of the International Planning Competition}}}
@string{ECP = {{Proc. of European Conference on Planning}}}
@string{AIPS = {{Proc. of the International Conference on Artificial Intelligence Planning and Scheduling}}}
@string{SOCS = {{Proc. of Annual Symposium on Combinatorial Search}}}
@string{SARA = {{Proc. of Symposium on Abstraction, Reformulation, and Approximation}}}
@string{AAAI = {{Proc. of AAAI Conference on Artificial Intelligence}}}
@string{IAAI = {{Proc. of the Innovative Applications of Artificial Intelligence Conference}}}
@string{ICRA = {{Proc. of IEEE International Conference on Robotics and Automaton (ICRA)}}}
@string{IROS = {{Proc. of IEEE International Workshop on Intelligent Robots and Systems (IROS)}}}
@string{AAMAS = {{Proc. of the International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS)}}}
@string{UAI = {{Proc. of the International Conference on Uncertainty in Artificial Intelligence (UAI)}}}
@string{NIPS = {{Advances in Neural Information Processing Systems}}}
@string{ICML = {{Proc. of the International Conference on Machine Learning}}}
@string{ICLR = {{Proc. of the International Conference on Learning Representations}}}
@string{CVPR = {{Proc. of IEEE Conference on Computer Vision and Pattern Recognition}}}
@string{ICASSP = {{Proc. of IEEE Conference on Acoustics, Speech and Signal Processing}}}
@string{IJCCI = {{Proc. of International Joint Conference on Computational Intelligence (IJCCI)}}}
@string{ILP = {{Proc. of International Conference on Inductive Logic Programming ({ILP})}}}
@string{SIGMOD = {{Proc. of the International Conference on Management of Data (SIGMOD)}}}
@string{SIGKDD = {{Proc. of ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)}}}
@string{ECCV = {{Proc. of the European Conference on Computer Vision (ECCV)}}}
@string{ICPR = {{Proc. of the International Conference on Pattern Recognition (ICPR)}}}
@string{TPAMI = {{IEEE Transactions on Pattern Analysis and Machine Intelligence}}}
@string{ACL = {{Proc. of the Annual Meeting of the Association for Computational Linguistics}}}
@string{COLING = {{Proc. of the International Conference on Computational Linguistics}}}
@string{COMPINT = {Computational Intelligence}}
@string{ECML = {{Proc. of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases}}}
@string{AMAI = {{Annals of Mathematics and Artificial Intelligence}}}
@string{AISTATS = {Proc. of the International Conference on Artificial Intelligence and Statistics (AISTATS)}}
@string{ICCV = {Proc. of the IEEE International Conference on Computer Vision}}
%NO BETTER BIBTEX
%NO BETTER BIBTEX
%NO BETTER BIBTEX
%NO BETTER BIBTEX
%NO BETTER BIBTEX
%NO BETTER BIBTEX
% BibTeX database for the paper asme2e.tex
%% bibtexfile{
%% author    = 
"Harry H. Cheng",
%% version   =  "2",
%% date      =  "January  01,
2003",
%% filename  =  "asme2e.bib",
%% address   =  "Integration
Engineering Laboratory
%%              Department of Mechanical and
Aeronautical Engineering
%%              University of California
%%        
     Davis, CA 95616",
%% telephone =  "(530) 752-5020 (office)
%%          
    (530) 752-1028 (lab)
%%               (530) 752-4158 (Fax:)",
%% email  
  =  "<hhcheng at ucdavis.edu>" }
@article{bond2021deep,
	title        = {Deep generative modelling: A comparative review of vaes, gans, normalizing flows, energy-based and autoregressive models},
	author       = {Bond-Taylor, Sam and Leach, Adam and Long, Yang and Willcocks, Chris G},
	year         = {2021},
	journal      = {IEEE transactions on pattern analysis and machine intelligence},
	publisher    = {IEEE}
}
@article{Bonfatietal2020,
	title        = {Automatic design of mechanical metamaterial actuators},
	author       = {Bonfanti, Silvia and Guerra, Roberto and Font-Clos, Francesc and Rayneau-Kirkhope, Daniel and Zapperi, Stefano},
	year         = {2020},
	month        = {12},
	journal      = {Nature Communications},
	volume       = {11},
	number       = {1},
	pages        = {4162},
	doi          = {10.1038/s41467-020-17947-2},
	issn         = {2041-1723},
	url          = {https://www.nature.com/articles/s41467-020-17947-2}
}
@article{borrvall2003topology,
	title        = {Topology optimization of fluids in Stokes flow},
	author       = {Borrvall, Thomas and Petersson, Joakim},
	year         = {2003},
	journal      = {International journal for numerical methods in fluids},
	publisher    = {Wiley Online Library},
	volume       = {41},
	number       = {1},
	pages        = {77--107}
}
@article{bostanabad2018computational,
	title        = {Computational microstructure characterization and reconstruction: Review of the state-of-the-art techniques},
	author       = {Bostanabad, Ramin and Zhang, Yichi and Li, Xiaolin and Kearney, Tucker and Brinson, L Catherine and Apley, Daniel W and Liu, Wing Kam and Chen, Wei},
	year         = {2018},
	journal      = {Progress in Materials Science},
	publisher    = {Elsevier},
	volume       = {95},
	pages        = {1--41}
}
@incollection{bottou2018geometrical,
	title        = {Geometrical insights for implicit generative modeling},
	author       = {Bottou, Leon and Arjovsky, Martin and Lopez-Paz, David and Oquab, Maxime},
	year         = {2018},
	booktitle    = {Braverman Readings in Machine Learning. Key Ideas from Inception to Current State},
	publisher    = {Springer},
	pages        = {229--268}
}
@article{bourdin2003design,
	title        = {Design-dependent loads in topology optimization},
	author       = {Bourdin, Blaise and Chambolle, Antonin},
	year         = {2003},
	journal      = {ESAIM: Control, Optimisation and Calculus of Variations},
	publisher    = {EDP Sciences},
	volume       = {9},
	pages        = {19--48}
}
@book{boyd2004convex,
	title        = {Convex optimization},
	author       = {Boyd, Stephen and Vandenberghe, Lieven},
	year         = {2004},
	publisher    = {Cambridge university press}
}
% uncertainty___________________________________________________________________
@article{bradshaw2017adversarial,
	title        = {Adversarial examples, uncertainty, and transfer testing robustness in gaussian process hybrid deep networks},
	author       = {Bradshaw, John and Matthews, Alexander G de G and Ghahramani, Zoubin},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1707.02476}
}
@article{brakel2017learning,
	title        = {Learning independent features with adversarial nets for non-linear ica},
	author       = {Brakel, Philemon and Bengio, Yoshua},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1710.05050}
}
@article{bregman1967relaxation,
	title        = {The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming},
	author       = {Bregman, Lev M},
	year         = {1967},
	journal      = {USSR computational mathematics and mathematical physics},
	publisher    = {Elsevier},
	volume       = {7},
	number       = {3},
	pages        = {200--217}
}
@inproceedings{brock2016context,
	title        = {Context-Aware Content Generation for Virtual Environments},
	author       = {Brock, Andrew and Lim, Theodore and Ritchie, James Millar and Weston, Nick},
	year         = {2016},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {50084},
	pages        = {V01BT02A045},
	organization = {American Society of Mechanical Engineers}
}
@article{brock2018large,
	title        = {Large scale gan training for high fidelity natural image synthesis},
	author       = {Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1809.11096}
}
@article{bronstein2017geometric,
	title        = {Geometric deep learning: going beyond euclidean data},
	author       = {Bronstein, Michael M and Bruna, Joan and LeCun, Yann and Szlam, Arthur and Vandergheynst, Pierre},
	year         = {2017},
	journal      = {IEEE Signal Processing Magazine},
	publisher    = {IEEE},
	volume       = {34},
	number       = {4},
	pages        = {18--42}
}
@article{brown2020language,
	title        = {Language models are few-shot learners},
	author       = {Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
	year         = {2020},
	journal      = {arXiv preprint arXiv:2005.14165}
}
@article{bruna2013invariant,
	title        = {Invariant scattering convolution networks},
	author       = {Bruna, Joan and Mallat, St{\'e}phane},
	year         = {2013},
	journal      = {IEEE transactions on pattern analysis and machine intelligence},
	publisher    = {IEEE},
	volume       = {35},
	number       = {8},
	pages        = {1872--1886}
}
@book{budynas2011shigley,
	title        = {Shigley's mechanical engineering design},
	author       = {Budynas, Richard Gordon and Nisbett, J Keith and others},
	year         = {2011},
	publisher    = {McGraw-Hill New York},
	volume       = {9}
}
@article{buede2016engineering,
	title        = {The engineering design of systems: models and methods},
	author       = {Buede, Dennis M and Miller, William D},
	year         = {2016},
	publisher    = {John Wiley \& Sons}
}
@article{Buonamici2018,
	title        = {Reverse engineering modeling methods and tools: a survey},
	author       = {Buonamici, Francesco and Carfagni, Monica and Furferi, Rocco and Governi, Lapo and Lapini, Alessandro and Volpe, Yary},
	year         = {2018},
	month        = {5},
	journal      = {Computer-Aided Design and Applications},
	volume       = {15},
	number       = {3},
	pages        = {443--464},
	doi          = {10.1080/16864360.2017.1397894},
	issn         = {1686-4360}
}
@article{burda2015importance,
	title        = {Importance weighted autoencoders},
	author       = {Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},
	year         = {2015},
	journal      = {arXiv preprint arXiv:1509.00519}
}
@article{burgess2018understanding,
	title        = {Understanding disentangling in $\beta$-VAE},
	author       = {Burgess, Christopher P and Higgins, Irina and Pal, Arka and Matthey, Loic and Watters, Nick and Desjardins, Guillaume and Lerchner, Alexander},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1804.03599}
}
@article{burgess2019monet,
	title        = {MONet: Unsupervised Scene Decomposition and Representation},
	author       = {Burgess, Christopher P and Matthey, Loic and Watters, Nicholas and Kabra, Rishabh and Higgins, Irina and Botvinick, Matt and Lerchner, Alexander},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1901.11390}
}
@inproceedings{burnap2016estimating,
	title        = {Estimating and exploring the product form design space using deep generative models},
	author       = {Burnap, Alexander and Liu, Ye and Pan, Yanxin and Lee, Honglak and Gonzalez, Richard and Papalambros, Panos Y},
	year         = {2016},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {50107},
	pages        = {V02AT03A013},
	organization = {American Society of Mechanical Engineers}
}
@article{cang2017microstructure,
	title        = {Microstructure representation and reconstruction of heterogeneous materials via deep belief network for computational material design},
	author       = {Cang, Ruijin and Xu, Yaopengxiao and Chen, Shaohua and Liu, Yongming and Jiao, Yang and Yi Ren, Max},
	year         = {2017},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers},
	volume       = {139},
	number       = {7},
	pages        = {071404}
}
@inproceedings{cang2017scalable,
	title        = {Scalable microstructure reconstruction with multi-scale pattern preservation},
	author       = {Cang, Ruijin and Vipradas, Aditya and Ren, Yi},
	year         = {2017},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {58134},
	pages        = {V02BT03A010},
	organization = {American Society of Mechanical Engineers}
}
@article{cang2018improving,
	title        = {Improving direct physical properties prediction of heterogeneous materials from imaging data via convolutional neural network and a morphology-aware generative model},
	author       = {Cang, Ruijin and Li, Hechao and Yao, Hope and Jiao, Yang and Ren, Yi},
	year         = {2018},
	journal      = {Computational Materials Science},
	publisher    = {Elsevier},
	volume       = {150},
	pages        = {212--221}
}
@article{CANG201912,
	title        = {One-shot generation of near-optimal topology through theory-driven machine learning},
	author       = {Ruijin Cang and Hope Yao and Yi Ren},
	year         = {2019},
	journal      = {Computer-Aided Design},
	volume       = {109},
	pages        = {12--21},
	doi          = {https://doi.org/10.1016/j.cad.2018.12.008},
	issn         = {0010-4485},
	url          = {https://www.sciencedirect.com/science/article/pii/S0010448518303828},
	keywords     = {Topology optimization, Meta-learning, Active learning},
	abstract     = {We introduce a theory-driven mechanism for learning a neural network model that performs generative topology design in one shot given a problem setting, circumventing the conventional iterative process that computational design tasks usually entail. The proposed mechanism can lead to machines that quickly respond to new design requirements based on its knowledge accumulated through past experiences of design generation. Achieving such a mechanism through supervised learning would require an impractically large amount of problem–solution pairs for training, due to the known limitation of deep neural networks in knowledge generalization. To this end, we introduce an interaction between a student (the neural network) and a teacher (the optimality conditions underlying topology optimization): The student learns from existing data and is tested on unseen problems. Deviation of the student’s solutions from the optimality conditions is quantified, and used for choosing new data points to learn from. We call this learning mechanism “theory-driven”, as it explicitly uses domain-specific theories to guide the learning, thus distinguishing itself from purely data-driven supervised learning. We show through a compliance minimization problem that the proposed learning mechanism leads to topology generation with near-optimal structural compliance, much improved from standard supervised learning under the same computational budget.}
}
@article{CanYaoRen2019,
	title        = {One-shot generation of near-optimal topology through theory-driven machine learning},
	author       = {Cang, Ruijin and Yao, Hope and Ren, Yi},
	year         = {2019},
	month        = {4},
	journal      = {Computer-Aided Design},
	publisher    = {Elsevier Ltd},
	volume       = {109},
	pages        = {12--21},
	doi          = {10.1016/j.cad.2018.12.008},
	issn         = {00104485},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0010448518303828},
	keywords     = {Active learning, Meta-learning, Topology optimization}
}
@inproceedings{caron2021emerging,
	title        = {Emerging properties in self-supervised vision transformers},
	author       = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
	year         = {2021},
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {9650--9660}
}
@article{casanova2021instance,
	title        = {Instance-conditioned gan},
	author       = {Casanova, Arantxa and Careil, Marl{\`e}ne and Verbeek, Jakob and Drozdzal, Michal and Romero Soriano, Adriana},
	year         = {2021},
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {34}
}
@inproceedings{caselles2019symmetry,
	title        = {Symmetry-Based Disentangled Representation Learning requires Interaction with Environments},
	author       = {Caselles-Dupr{\'e}, Hugo and Ortiz, Michael Garcia and Filliat, David},
	year         = {2019},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {4608--4617}
}
@article{cazacu2014overview,
	title        = {Overview of structural topology optimization methods for plane and solid structures},
	author       = {Cazacu, Razvan and Grama, Lucian},
	year         = {2014},
	journal      = {Annals of the University of Oradea, Fascicle of Management and Technological Engineering},
	publisher    = {Citeseer},
	volume       = {23},
	number       = {3},
	pages        = {1583--1591}
}
@article{CFD1,
	title        = {Machine learning–accelerated computational fluid dynamics},
	author       = {Kochkov, Dmitrii and Smith, Jamie A. and Alieva, Ayya and Wang, Qing and Brenner, Michael P. and Hoyer, Stephan},
	year         = {2021},
	journal      = {Proceedings of the National Academy of Sciences},
	volume       = {118},
	number       = {21},
	doi          = {10.1073/pnas.2101784118}
}
@inproceedings{CFD10,
	title        = {Learning Mesh-Based Simulation with Graph Networks},
	author       = {Pfaff, Tobias and Fortunato, Meire and Sanchez-Gonzalez, Alvaro and Battaglia, Peter},
	year         = {2020},
	booktitle    = {International Conference on Learning Representations}
}
@article{CFD2,
	title        = {Reynolds averaged turbulence modelling using deep neural networks with embedded invariance},
	author       = {Ling, Julia and Kurzawski, Andrew and Templeton, Jeremy},
	year         = {2016},
	journal      = {Journal of Fluid Mechanics},
	publisher    = {Cambridge University Press},
	volume       = {807},
	pages        = {155–166},
	doi          = {10.1017/jfm.2016.615}
}
@article{CFD3,
	title        = {Turbulence Modeling in the Age of Data},
	author       = {Duraisamy, Karthik and Iaccarino, Gianluca and Xiao, Heng},
	year         = {2019},
	journal      = {Annual Review of Fluid Mechanics},
	volume       = {51},
	number       = {1},
	pages        = {357--377},
	doi          = {10.1146/annurev-fluid-010518-040547},
	url          = {https://doi.org/10.1146/annurev-fluid-010518-040547},
	eprint       = {https://doi.org/10.1146/annurev-fluid-010518-040547},
	abstract     = {Data from experiments and direct simulations of turbulence have historically been used to calibrate simple engineering models such as those based on the Reynolds-averaged Navier–Stokes (RANS) equations. In the past few years, with the availability of large and diverse data sets, researchers have begun to explore methods to systematically inform turbulence models with data, with the goal of quantifying and reducing model uncertainties. This review surveys recent developments in bounding uncertainties in RANS models via physical constraints, in adopting statistical inference to characterize model coefficients and estimate discrepancy, and in using machine learning to improve turbulence models. Key principles, achievements, and challenges are discussed. A central perspective advocated in this review is that by exploiting foundational knowledge in turbulence modeling and physical constraints, researchers can use data-driven approaches to yield useful predictive models.}
}
@article{CFD4,
	title        = {Subgrid modelling for two-dimensional turbulence using neural networks},
	author       = {Maulik, R. and San, O. and Rasheed, A. and Vedula, P.},
	year         = {2018},
	month        = {Nov},
	journal      = {Journal of Fluid Mechanics},
	publisher    = {Cambridge University Press (CUP)},
	volume       = {858},
	pages        = {122–144},
	doi          = {10.1017/jfm.2018.770},
	issn         = {1469-7645},
	url          = {http://dx.doi.org/10.1017/jfm.2018.770}
}
@article{CFD5,
	title        = {Deep Fluids: A Generative Network for Parameterized Fluid Simulations},
	author       = {Kim, Byungsoo and Azevedo, Vinicius C. and Thuerey, Nils and Kim, Theodore and Gross, Markus and Solenthaler, Barbara},
	year         = {2019},
	month        = {May},
	journal      = {Computer Graphics Forum},
	publisher    = {Wiley},
	volume       = {38},
	number       = {2},
	pages        = {59–70},
	doi          = {10.1111/cgf.13619},
	issn         = {1467-8659},
	url          = {http://dx.doi.org/10.1111/cgf.13619}
}
@misc{CFD6,
	title        = {Towards Physics-informed Deep Learning for Turbulent Flow Prediction},
	author       = {Rui Wang and Karthik Kashinath and Mustafa Mustafa and Adrian Albert and Rose Yu},
	year         = {2020},
	eprint       = {1911.08655},
	archiveprefix = {arXiv},
	primaryclass = {physics.comp-ph}
}
@inproceedings{CFD7,
	title        = {Accelerating eulerian fluid simulation with convolutional networks},
	author       = {Tompson, Jonathan and Schlachter, Kristofer and Sprechmann, Pablo and Perlin, Ken},
	year         = {2017},
	booktitle    = {International Conference on Machine Learning},
	pages        = {3424--3433},
	organization = {PMLR}
}
@inproceedings{CFD8,
	title        = {CFDNet: A Deep Learning-Based Accelerator for Fluid Simulations},
	author       = {Obiols-Sales, Octavi and Vishnu, Abhinav and Malaya, Nicholas and Chandramowliswharan, Aparna},
	year         = {2020},
	booktitle    = {Proceedings of the 34th ACM International Conference on Supercomputing},
	location     = {Barcelona, Spain},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {ICS '20},
	doi          = {10.1145/3392717.3392772},
	isbn         = {9781450379830},
	url          = {https://doi.org/10.1145/3392717.3392772},
	abstract     = {CFD is widely used in physical system design and optimization, where it is used to predict engineering quantities of interest, such as the lift on a plane wing or the drag on a motor vehicle. However, many systems of interest are prohibitively expensive for design optimization, due to the expense of evaluating CFD simulations.To render the computation tractable, reduced-order or surrogate models are used to accelerate simulations while respecting the convergence constraints provided by the higher-fidelity solution. This paper introduces CFDNet - a physical simulation and deep learning coupled framework, for accelerating the convergence of Reynolds Averaged Navier-Stokes simulations. CFDNet is designed to predict the primary physical properties of the fluid including velocity, pressure, and eddy viscosity using a single convolutional neural network at its core. We evaluate CFDNet on a variety of use-cases, both extrapolative and interpolative, where test geometries are observed/not-observed during training. Our results show that CFDNet meets the convergence constraints of the domain-specific physics solver while outperforming it by 1.9 - 7.4X on both steady laminar and turbulent flows. Moreover, we demonstrate the generalization capacity of CFDNet by testing its prediction on new geometries unseen during training. In this case, the approach meets the CFD convergence criterion while still providing significant speedups over traditional domain-only models.},
	articleno    = {3},
	numpages     = {12},
	keywords     = {deep learning, AI for science, physics-machine learning coupled framework, computational fluid dynamics, turbulent flows}
}
@misc{CFD9,
	title        = {Using Machine Learning to Augment Coarse-Grid Computational Fluid Dynamics Simulations},
	author       = {Jaideep Pathak and Mustafa Mustafa and Karthik Kashinath and Emmanuel Motheau and Thorsten Kurth and Marcus Day},
	year         = {2020},
	eprint       = {2010.00072},
	archiveprefix = {arXiv},
	primaryclass = {physics.comp-ph}
}
@article{chakrabarti2011computer,
	title        = {Computer-Based Design Synthesis Research: An Overview},
	author       = {Chakrabarti, Amaresh and Shea, Kristina and Stone, Robert and Cagan, Jonathan and Campbell, Matthew and Hernandez, Noe Vargas and Wood, Kristin L.},
	year         = {2011},
	month        = {06},
	journal      = {Journal of Computing and Information Science in Engineering},
	volume       = {11},
	number       = {2},
	doi          = {10.1115/1.3593409},
	issn         = {1530-9827},
	url          = {https://doi.org/10.1115/1.3593409},
	note         = {021003},
	abstract     = {One of the hallmarks of engineering design is the design synthesis phase where the creativity of the designer most prominently comes into play as solutions are generated to meet underlying needs. Over the past decades, methodologies for generating concepts and design solutions have matured to the point that computation-based synthesis provides a means to explore a wider variety of solutions and take over more tedious design tasks. This paper reviews advances in function-based, grammar-based, and analogy-based synthesis approaches and their contributions to computational design synthesis research in the last decade.},
	eprint       = {https://asmedigitalcollection.asme.org/computingengineering/article-pdf/11/2/021003/5566343/021003\_1.pdf}
}
@article{chan2021metaset,
	title        = {METASET: Exploring shape and property spaces for data-driven metamaterials design},
	author       = {Chan, Yu-Chin and Ahmed, Faez and Wang, Liwei and Chen, Wei},
	year         = {2021},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers},
	volume       = {143},
	number       = {3},
	pages        = {031707}
}
@article{ChanDaWang2021,
	title        = {Remixing Functionally Graded Structures: Data-Driven Topology Optimization with Multiclass Shape Blending},
	author       = {Chan, Yu-Chin and Da, Daicong and Wang, Liwei and Chen, Wei},
	year         = {2021},
	month        = {12},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/2112.00648},
	arxivid      = {2112.00648}
}
@article{chandrasekhar2022gm,
	title        = {GM-TOuNN: Graded Multiscale Topology Optimization using Neural Networks},
	author       = {Chandrasekhar, Aaditya and Sridhara, Saketh and Suresh, Krishnan},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2204.06682}
}
@article{ChandrasekharSuresh2020,
	title        = {TOuNN: Topology Optimization using Neural Networks},
	author       = {Chandrasekhar, Aaditya and Suresh, Krishnan},
	year         = {2021},
	month        = {3},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	volume       = {63},
	number       = {3},
	pages        = {1135--1149},
	doi          = {10.1007/s00158-020-02748-4},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-020-02748-4},
	keywords     = {Machine learning, Neural networks, Topology optimization}
}
@article{ChandraSuresh2021,
	title        = {Multi-Material Topology Optimization Using Neural Networks},
	author       = {Chandrasekhar, Aaditya and Suresh, Krishnan},
	year         = {2021},
	month        = {7},
	journal      = {Computer-Aided Design},
	publisher    = {Elsevier Ltd},
	volume       = {136},
	pages        = {103017},
	doi          = {10.1016/j.cad.2021.103017},
	issn         = {00104485},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0010448521000282},
	keywords     = {Multi-material, Neural networks, SIMP, Thin features, Topology optimization}
}
@article{ChandraSuresh2022,
	title        = {Length Scale Control in Topology Optimization using Fourier Enhanced Neural Networks},
	author       = {Chandrasekhar, Aaditya and Suresh, Krishnan},
	year         = {2021},
	month        = {9},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/2109.01861},
	arxivid      = {2109.01861}
}
@article{chang2015shapenet,
	title        = {Shapenet: An information-rich 3d model repository},
	author       = {Chang, Angel X and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and others},
	year         = {2015},
	journal      = {arXiv preprint arXiv:1512.03012}
}
@article{chang2016compositional,
	title        = {A compositional object-based approach to learning physical dynamics},
	author       = {Chang, Michael B and Ullman, Tomer and Torralba, Antonio and Tenenbaum, Joshua B},
	year         = {2016},
	journal      = {arXiv preprint arXiv:1612.00341}
}
@inproceedings{chen2016infogan,
	title        = {Infogan: Interpretable representation learning by information maximizing generative adversarial nets},
	author       = {Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
	year         = {2016},
	booktitle    = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
	pages        = {2180--2188}
}
@article{chen2016variational,
	title        = {Variational lossy autoencoder},
	author       = {Chen, Xi and Kingma, Diederik P and Salimans, Tim and Duan, Yan and Dhariwal, Prafulla and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
	year         = {2016},
	journal      = {arXiv preprint arXiv:1611.02731}
}
@article{chen2017pixelsnail,
	title        = {Pixelsnail: An improved autoregressive generative model},
	author       = {Chen, Xi and Mishra, Nikhil and Rohaninejad, Mostafa and Abbeel, Pieter},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1712.09763}
}
@article{chen2018b,
	title        = {B{\'e}zierGAN: Automatic Generation of Smooth Curves from Interpretable Low-Dimensional Parameters},
	author       = {Chen, Wei and Fuge, Mark},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1808.08871}
}
@article{chen2018isolating,
	title        = {Isolating Sources of Disentanglement in Variational Autoencoders},
	author       = {Chen, Tian Qi and Li, Xuechen and Grosse, Roger and Duvenaud, David},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1802.04942}
}
%__________________________________________________________________________________________________________
@inproceedings{chen2018sparse,
	title        = {The Sparse Manifold Transform},
	author       = {Chen, Yubei and Paiton, Dylan and Olshausen, Bruno},
	year         = {2018},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {10534--10545}
}
@inproceedings{chen2019aerodynamic,
	title        = {Aerodynamic design optimization and shape exploration using generative adversarial networks},
	author       = {Chen, Wei and Chiu, Kevin and Fuge, Mark},
	year         = {2019},
	booktitle    = {AIAA Scitech 2019 Forum},
	pages        = {2351}
}
@article{chen2019synthesizing,
	title        = {Synthesizing designs with interpart dependencies using hierarchical generative adversarial networks},
	author       = {Chen, Wei and Fuge, Mark},
	year         = {2019},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers},
	volume       = {141},
	number       = {11},
	pages        = {111403}
}
@inproceedings{chen2021geometry,
	title        = {GEOMETRY ENHANCED GENERATIVE ADVERSARIAL NETWORKS FOR RANDOM HETEROGENEOUS MATERIAL REPRESENTATION},
	author       = {Chen, Hongrui and Liu, Xingchen},
	year         = {2021},
	month        = {Aug},
	day          = {17-20},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, {IDETC-21}},
	address      = {Virtual, Online},
	organization = {ASME}
}
@article{chen2021mopadgan,
	title        = {MO-PaDGAN: Reparameterizing Engineering Designs for augmented multi-objective optimization},
	author       = {Chen, Wei and Ahmed, Faez},
	year         = {2021},
	journal      = {Applied Soft Computing},
	publisher    = {Elsevier},
	volume       = {113},
	pages        = {107909}
}
@article{chen2021padgan,
	title        = {Padgan: Learning to generate high-quality novel designs},
	author       = {Chen, Wei and Ahmed, Faez},
	year         = {2021},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers},
	volume       = {143},
	number       = {3},
	pages        = {031703}
}
@inproceedings{chen2022concurrent,
	title        = {Concurrent build direction, part segmentation, and topology optimization for additive manufacturing using neural networks},
	author       = {Chen, Hongrui and Whitefoot, Kate S and Kara, Levent Burak},
	year         = {2022},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {86229},
	pages        = {V03AT03A029},
	organization = {American Society of Mechanical Engineers}
}
@article{cheng2019meshgan,
	title        = {Meshgan: Non-linear 3d morphable models of faces},
	author       = {Cheng, Shiyang and Bronstein, Michael and Zhou, Yuxiang and Kotsia, Irene and Pantic, Maja and Zafeiriou, Stefanos},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1903.10384}
}
@article{ChenGu2020,
	title        = {Generative Deep Neural Networks for Inverse Materials Design Using Backpropagation and Active Learning},
	author       = {Chen, Chun‐Teh and Gu, Grace X.},
	year         = {2020},
	month        = {3},
	journal      = {Advanced Science},
	volume       = {7},
	number       = {5},
	pages        = {1902607},
	doi          = {10.1002/advs.201902607},
	issn         = {2198-3844},
	url          = {https://onlinelibrary.wiley.com/doi/10.1002/advs.201902607}
}
@article{ChenShen2021,
	title        = {A New Topology Optimization Approach by Physics-Informed Deep Learning Process},
	author       = {Chen, Liang and Shen, Mo-How Herman},
	year         = {2021},
	month        = {7},
	journal      = {Advances in Science, Technology and Engineering Systems Journal},
	volume       = {6},
	number       = {4},
	pages        = {233--240},
	doi          = {10.25046/aj060427},
	issn         = {24156698},
	url          = {https://astesj.com/v06/i04/p27/}
}
@article{child2019generating,
	title        = {Generating long sequences with sparse transformers},
	author       = {Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1904.10509}
}
@article{child2020very,
	title        = {Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images},
	author       = {Child, Rewon},
	year         = {2020},
	journal      = {arXiv preprint arXiv:2011.10650}
}
@article{ChiZhangetal2021,
	title        = {Universal machine learning for topology optimization},
	author       = {Chi, Heng and Zhang, Yuyu and Tang, Tsz Ling Elaine and Mirabella, Lucia and Dalloro, Livio and Song, Le and Paulino, Glaucio H.},
	year         = {2021},
	month        = {3},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	publisher    = {Elsevier B.V.},
	volume       = {375},
	pages        = {112739},
	doi          = {10.1016/j.cma.2019.112739},
	issn         = {00457825},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0045782519306292}
}
@inproceedings{choi2019meta,
	title        = {Meta-amortized variational inference and learning},
	author       = {Choi, Kristy and Wu, Mike and Goodman, Noah and Ermon, Stefano},
	year         = {2019},
	booktitle    = {International Conference on Learning Representations}
}
@inproceedings{choi2020stargan,
	title        = {StarGAN v2: Diverse Image Synthesis for Multiple Domains},
	author       = {Choi, Yunjey and Uh, Youngjung and Yoo, Jaejun and Ha, Jung-Woo},
	year         = {2020},
	booktitle    = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	location     = {Seattle, WA, USA},
	volume       = {},
	number       = {},
	pages        = {8185--8194},
	doi          = {10.1109/CVPR42600.2020.00821}
}
@article{choi2021ilvr,
	title        = {Ilvr: Conditioning method for denoising diffusion probabilistic models},
	author       = {Choi, Jooyoung and Kim, Sungwon and Jeong, Yonghyun and Gwon, Youngjune and Yoon, Sungroh},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2108.02938}
}
@article{choi2022perception,
	title        = {Perception Prioritized Training of Diffusion Models},
	author       = {Choi, Jooyoung and Lee, Jungbeom and Shin, Chaehun and Kim, Sungwon and Kim, Hyunwoo and Yoon, Sungroh},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2204.00227}
}
@inproceedings{chopra2005learning,
	title        = {Learning a similarity metric discriminatively, with application to face verification},
	author       = {Chopra, Sumit and Hadsell, Raia and LeCun, Yann and others},
	year         = {2005},
	booktitle    = {CVPR (1)},
	pages        = {539--546}
}
@article{cirecsan2012multi,
	title        = {Multi-column deep neural networks for image classification},
	author       = {Cire{\c{s}}an, Dan and Meier, Ueli and Schmidhuber, J{\"u}rgen},
	year         = {2012},
	journal      = {arXiv preprint arXiv:1202.2745}
}
@article{Ciresan2010DeepBS,
	title        = {Deep, Big, Simple Neural Nets for Handwritten Digit Recognition},
	author       = {Dan C. Ciresan and Ueli Meier and Luca Maria Gambardella and J{\"u}rgen Schmidhuber},
	year         = {2010},
	journal      = {Neural Computation},
	volume       = {22},
	pages        = {3207--3220}
}
@inproceedings{ciresan2011flexible,
	title        = {Flexible, high performance convolutional neural networks for image classification},
	author       = {Ciresan, Dan Claudiu and Meier, Ueli and Masci, Jonathan and Gambardella, Luca Maria and Schmidhuber, J{\"u}rgen},
	year         = {2011},
	booktitle    = {Twenty-Second International Joint Conference on Artificial Intelligence}
}
@article{cohen2014transformation,
	title        = {Transformation properties of learned visual representations},
	author       = {Cohen, Taco S and Welling, Max},
	year         = {2014},
	journal      = {arXiv preprint arXiv:1412.7659}
}
@inproceedings{cohen2016group,
	title        = {Group equivariant convolutional networks},
	author       = {Cohen, Taco and Welling, Max},
	year         = {2016},
	booktitle    = {International conference on machine learning},
	pages        = {2990--2999}
}
@article{cohen2017emnist,
	title        = {EMNIST: an extension of MNIST to handwritten letters},
	author       = {Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and van Schaik, Andr{\'e}},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1702.05373}
}
@article{cohen2018spherical,
	title        = {Spherical cnns},
	author       = {Cohen, Taco S and Geiger, Mario and K{\"o}hler, Jonas and Welling, Max},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1801.10130}
}
%NO BETTER BIBTEX
@article{computational_time_trad_TO,
	title        = {On reducing computational effort in topology optimization: how far can we go?},
	author       = {Oded Amir and Ole Sigmund},
	year         = {2011},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer},
	volume       = {44},
	number       = {1},
	pages        = {25--29},
	doi          = {10.1007/s00158-010-0586-7},
	issn         = {1615-147X},
	abstract     = {An approximate approach to solving the nested analysis equations in topology optimization is proposed. The procedure consists of only one matrix factorization for the whole design process and a small number of iterative corrections for each design cycle. The approach is tested on 3D topology optimization problems. It is shown that the computational cost can be reduced by one order of magnitude without affecting the outcome of the optimization process.},
	keywords     = {Approximations, Topology optimization, Nested approach},
	language     = {English}
}
@misc{Copeland2016,
	title        = {What’s the Difference Between Artificial Intelligence, Machine Learning and Deep Learning?},
	author       = {Copeland, Michael},
	year         = {2016},
	month        = {7},
	booktitle    = {NVIDIA blog (accessed 13/08/2021)},
	url          = {https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/}
}
@article{creswell2018generative,
	title        = {Generative Adversarial Networks: An Overview},
	author       = {Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A.},
	year         = {2018},
	journal      = {IEEE Signal Processing Magazine},
	volume       = {35},
	number       = {1},
	pages        = {53--65},
	doi          = {10.1109/MSP.2017.2765202}
}
@inproceedings{cunningham2018validation,
	title        = {A Validation Neural Network (VNN) metamodel for predicting the performance of deep generative designs},
	author       = {Cunningham, James and Tucker, Conrad S},
	year         = {2018},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {51760},
	pages        = {V02BT03A037},
	organization = {American Society of Mechanical Engineers}
}
@inproceedings{CycleGAN2017,
	title        = {Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks},
	author       = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
	year         = {2017},
	booktitle    = {2017 IEEE International Conference on Computer Vision (ICCV)},
	location     = {Venice, Italy},
	volume       = {},
	number       = {},
	pages        = {2242--2251},
	doi          = {10.1109/ICCV.2017.244}
}
@article{Daetal2022,
	title        = {Data-driven and topological design of structural metamaterials for fracture resistance},
	author       = {Da, Daicong and Chan, Yu-Chin and Wang, Liwei and Chen, Wei},
	year         = {2022},
	month        = {1},
	journal      = {Extreme Mechanics Letters},
	volume       = {50},
	pages        = {101528},
	doi          = {10.1016/j.eml.2021.101528},
	issn         = {23524316},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S2352431621002078}
}
@article{dai2019diagnosing,
	title        = {Diagnosing and enhancing vae models},
	author       = {Dai, Bin and Wipf, David},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1903.05789}
}
@article{daneshmand20183d,
	title        = {3d scanning: A comprehensive survey},
	author       = {Daneshmand, Morteza and Helmi, Ahmed and Avots, Egils and Noroozi, Fatemeh and Alisinanoglu, Fatih and Arslan, Hasan Sait and Gorbova, Jelena and Haamer, Rain Eric and Ozcinar, Cagri and Anbarjafari, Gholamreza},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1801.08863}
}
@article{dbouk2017review,
	title        = {A review about the engineering design of optimal heat transfer systems using topology optimization},
	author       = {Dbouk, Talib},
	year         = {2017},
	journal      = {Applied Thermal Engineering},
	publisher    = {Elsevier},
	volume       = {112},
	pages        = {841--854}
}
@article{de2019hierarchical,
	title        = {Hierarchical Autoregressive Image Models with Auxiliary Decoders},
	author       = {De Fauw, Jeffrey and Dieleman, Sander and Simonyan, Karen},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1903.04933}
}
@incollection{de20209,
	title        = {9. On the Condition of Partial Exchangeability},
	author       = {De Finetti, Bruno},
	year         = {2020},
	booktitle    = {Studies in Inductive Logic and Probability Volume 2},
	publisher    = {University of California Press},
	pages        = {193--206}
}
@misc{decao2018molgan,
	title        = {MolGAN: An implicit generative model for small molecular graphs},
	author       = {Nicola De Cao and Thomas Kipf},
	year         = {2018},
	eprint       = {1805.11973},
	archiveprefix = {arXiv},
	primaryclass = {stat.ML}
}
@article{decost2017uhcsdb,
	title        = {UHCSDB: ultrahigh carbon steel micrograph database},
	author       = {DeCost, Brian L and Hecht, Matthew D and Francis, Toby and Webler, Bryan A and Picard, Yoosuf N and Holm, Elizabeth A},
	year         = {2017},
	journal      = {Integrating Materials and Manufacturing Innovation},
	publisher    = {Springer},
	volume       = {6},
	number       = {2},
	pages        = {197--205}
}
@article{deng2014deep,
	title        = {Deep Learning: Methods and Applications},
	author       = {Deng, Li and Yu, Dong},
	year         = {2014},
	month        = {jun},
	journal      = {Found. Trends Signal Process.},
	publisher    = {Now Publishers Inc.},
	address      = {Hanover, MA, USA},
	volume       = {7},
	number       = {3–4},
	pages        = {197–387},
	doi          = {10.1561/2000000039},
	issn         = {1932-8346},
	url          = {https://doi.org/10.1561/2000000039},
	issue_date   = {June 2014},
	abstract     = {This monograph provides an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria in mind: (1) expertise or knowledge of the authors; (2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and (3) the application areas that have the potential to be impacted significantly by deep learning and that have been experiencing research growth, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning.},
	numpages     = {191},
	keywords     = {Computer vision, Hybrid deep networks, Machine learning, Deep stacking networks, Artificial intelligence, Natural language processing, Deep learning, Unsupervised learning, Supervised learning, Neural networks, Deep neural networks, Multi-task learning, Autoencoders, Language models, Multi-modal processing, Object recognition}
}
@article{DengTo2021,
	title        = {A Parametric Level Set Method for Topology Optimization based on Deep Neural Network (DNN)},
	author       = {Deng, Hao and To, Albert C.},
	year         = {2021},
	month        = {1},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/2101.03286},
	arxivid      = {2101.03286}
}
@article{DenTo2020,
	title        = {Topology optimization based on deep representation learning (DRL) for compliance and stress-constrained design},
	author       = {Deng, Hao and To, Albert C.},
	year         = {2020},
	month        = {8},
	journal      = {Computational Mechanics},
	publisher    = {Springer},
	volume       = {66},
	number       = {2},
	pages        = {449--469},
	doi          = {10.1007/s00466-020-01859-5},
	issn         = {0178-7675},
	url          = {https://link.springer.com/10.1007/s00466-020-01859-5},
	keywords     = {Deep learning, Geometry complexity, Stress-constrained, Topology optimization}
}
@inproceedings{dering2017generative,
	title        = {Generative adversarial networks for increasing the veracity of big data},
	author       = {Dering, Matthew L and Tucker, Conrad S},
	year         = {2017},
	booktitle    = {2017 IEEE International Conference on Big Data (Big Data)},
	pages        = {2595--2602},
	organization = {IEEE}
}
@inproceedings{dering2018physics,
	title        = {A physics-based virtual environment for enhancing the quality of deep generative designs},
	author       = {Dering, Matthew and Cunningham, James and Desai, Raj and Yukish, Michael A and Simpson, Timothy W and Tucker, Conrad S},
	year         = {2018},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {51753},
	pages        = {V02AT03A015},
	organization = {American Society of Mechanical Engineers}
}
@article{deshpande2019computational,
	title        = {Computational creativity via assisted variational synthesis of mechanisms using deep generative models},
	author       = {Deshpande, Shrinath and Purwar, Anurag},
	year         = {2019},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers Digital Collection},
	volume       = {141},
	number       = {12}
}
@article{detlefsen2019explicit,
	title        = {Explicit disentanglement of appearance and perspective in generative models},
	author       = {Detlefsen, Nicki Skafte and Hauberg, S{\o}ren},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1906.11881}
}
@article{devlin2018bert,
	title        = {Bert: Pre-training of deep bidirectional transformers for language understanding},
	author       = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1810.04805}
}
@article{devries2018learning,
	title        = {Learning Confidence for Out-of-Distribution Detection in Neural Networks},
	author       = {DeVries, Terrance and Taylor, Graham W},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1802.04865}
}
@misc{dhariwal2020jukebox,
	title        = {Jukebox: A Generative Model for Music},
	author       = {Prafulla Dhariwal and Heewoo Jun and Christine Payne and Jong Wook Kim and Alec Radford and Ilya Sutskever},
	year         = {2020},
	eprint       = {2005.00341},
	archiveprefix = {arXiv},
	primaryclass = {eess.AS}
}
@article{dhariwal2021diffusion,
	title        = {Diffusion models beat gans on image synthesis},
	author       = {Dhariwal, Prafulla and Nichol, Alexander},
	year         = {2021},
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {34}
}
@article{dhillon2007weighted,
	title        = {Weighted graph cuts without eigenvectors a multilevel approach},
	author       = {Dhillon, Inderjit S and Guan, Yuqiang and Kulis, Brian},
	year         = {2007},
	journal      = {IEEE transactions on pattern analysis and machine intelligence},
	publisher    = {IEEE},
	volume       = {29},
	number       = {11},
	pages        = {1944--1957}
}
@inproceedings{diaconis1988sufficiency,
	title        = {Sufficiency as statistical symmetry},
	author       = {Diaconis, Persi},
	year         = {1988},
	booktitle    = {Proceedings of the AMS Centennial Symposium},
	pages        = {15--26}
}
@inproceedings{dickstein2015,
	title        = {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
	author       = {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
	year         = {2015},
	month        = {07--09 Jul},
	booktitle    = {Proceedings of the 32nd International Conference on Machine Learning},
	publisher    = {PMLR},
	address      = {Lille, France},
	series       = {Proceedings of Machine Learning Research},
	volume       = {37},
	pages        = {2256--2265},
	url          = {https://proceedings.mlr.press/v37/sohl-dickstein15.html},
	editor       = {Bach, Francis and Blei, David},
	pdf          = {http://proceedings.mlr.press/v37/sohl-dickstein15.pdf},
	abstract     = {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.}
}
@article{dilokthanakul2016deep,
	title        = {Deep unsupervised clustering with gaussian mixture variational autoencoders},
	author       = {Dilokthanakul, Nat and Mediano, Pedro AM and Garnelo, Marta and Lee, Matthew CH and Salimbeni, Hugh and Arulkumaran, Kai and Shanahan, Murray},
	year         = {2016},
	journal      = {arXiv preprint arXiv:1611.02648}
}
@inproceedings{ding2020ccgan,
	title        = {CcGAN: Continuous Conditional Generative Adversarial Networks for Image Generation},
	author       = {Xin Ding and Yongwei Wang and Zuheng Xu and William J. Welch and Z. Jane Wang},
	year         = {2021},
	booktitle    = {9th International Conference on Learning Representations, {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021},
	publisher    = {OpenReview.net},
	url          = {https://openreview.net/forum?id=PrzjugOsDeE},
	timestamp    = {Wed, 23 Jun 2021 17:36:39 +0200},
	biburl       = {https://dblp.org/rec/conf/iclr/DingWXW021.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{Dinh2016,
	title        = {Density estimation using Real NVP},
	author       = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
	year         = {2016},
	month        = {5},
	arxivid      = {1605.08803}
}
@article{dinh2016density,
	title        = {Density estimation using real nvp},
	author       = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
	year         = {2016},
	journal      = {arXiv preprint arXiv:1605.08803}
}
@article{Djourachkovitchetal2021,
	title        = {Multiscale topology optimization of 3D structures: A micro-architectured materials database assisted strategy},
	author       = {Djourachkovitch, Tristan and Blal, Nawfal and Hamila, Nahiene and Gravouil, Anthony},
	year         = {2021},
	month        = {10},
	journal      = {Computers {\&} Structures},
	volume       = {255},
	pages        = {106574},
	doi          = {10.1016/j.compstruc.2021.106574},
	issn         = {00457949},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0045794921000961}
}
@article{dong2019inverse,
	title        = {Inverse design of two-dimensional graphene/h-BN hybrids by a regressional and conditional GAN},
	author       = {Yuan Dong and Dawei Li and Chi Zhang and Chuhan Wu and Hong Wang and Ming Xin and Jianlin Cheng and Jian Lin},
	year         = {2020},
	journal      = {Carbon},
	volume       = {169},
	pages        = {9--16},
	doi          = {https://doi.org/10.1016/j.carbon.2020.07.013},
	issn         = {0008-6223},
	url          = {https://www.sciencedirect.com/science/article/pii/S0008622320306734},
	abstract     = {Design of materials with desired properties is currently laborious and heavily relies on intuition of researchers through a trial-and-error process. To tackle this challenge, we propose a novel regressional and conditional generative adversarial network (RCGAN) for inverse design of representative two-dimensional materials, the graphene and boron-nitride (BN) hybrids. RCGAN incorporates a supervised regressor network, thus overcoming the common technical barrier in the traditional unsupervised GANs, which cannot generate data when fed with continuous and quantitative labels. RCGAN can autonomously generate graphene/BN hybrids given any target bandgap values. These structures are distinguished from the ones used for training and exhibit high diversity for a given bandgap. Moreover, they exhibit high fidelity, yielding bandgaps within ∼10% MAEF of the desired bandgaps as validated by density functional theory (DFT) calculations. Analysis by the principle component analysis (PCA) and modified locally linear embedding (MLLE) reveals that the generator has successfully generated structures following the statistical distribution of the real structures. It implies the possibility of the RCGAN in recognizing physical rules hidden in the high-dimensional data. The novel strategy for designing regressional GAN architecture together with the successful application to inverse design of materials would inspire further exploration in research fields beyond materials.}
}
@article{dosovitskiy2020image,
	title        = {An image is worth 16x16 words: Transformers for image recognition at scale},
	author       = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
	year         = {2020},
	journal      = {arXiv preprint arXiv:2010.11929}
}
% dataset____________________________________________________________________________________
@misc{dsprites17,
	title        = {dSprites: Disentanglement testing Sprites dataset},
	author       = {Loic Matthey and Irina Higgins and Demis Hassabis and Alexander Lerchner},
	year         = {2017},
	howpublished = {https://github.com/deepmind/dsprites-dataset/}
}
@article{Duetal2018,
	title        = {InverseCSG},
	author       = {Du, Tao and Inala, Jeevana Priya and Pu, Yewen and Spielberg, Andrew and Schulz, Adriana and Rus, Daniela and Solar-Lezama, Armando and Matusik, Wojciech},
	year         = {2018},
	month        = {12},
	journal      = {ACM Transactions on Graphics},
	volume       = {37},
	number       = {6},
	pages        = {1--16},
	doi          = {10.1145/3272127.3275006},
	issn         = {0730-0301}
}
@book{duffy2015green,
	title        = {Green's functions with applications},
	author       = {Duffy, Dean G},
	year         = {2015},
	publisher    = {Chapman and Hall/CRC}
}
@article{durkan2021maximum,
	title        = {On maximum likelihood training of score-based generative models},
	author       = {Durkan, Conor and Song, Yang},
	year         = {2021},
	journal      = {arXiv e-prints},
	pages        = {arXiv--2101}
}
@inproceedings{dwibedi2019temporal,
	title        = {Temporal Cycle-Consistency Learning},
	author       = {Dwibedi, Debidatta and Aytar, Yusuf and Tompson, Jonathan and Sermanet, Pierre and Zisserman, Andrew},
	year         = {2019},
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {1801--1810}
}
@inproceedings{EckHoppe1996,
	title        = {Automatic reconstruction of B-spline surfaces of arbitrary topological type},
	author       = {Eck, Matthias and Hoppe, Hugues},
	year         = {1996},
	booktitle    = {Proceedings of the 23rd annual conference on Computer graphics and interactive techniques  - SIGGRAPH '96},
	publisher    = {ACM Press},
	address      = {New York, New York, USA},
	pages        = {325--334},
	doi          = {10.1145/237170.237271},
	isbn         = {0897917464}
}
@article{edwards2016towards,
	title        = {Towards a neural statistician},
	author       = {Edwards, Harrison and Storkey, Amos},
	year         = {2016},
	journal      = {arXiv preprint arXiv:1606.02185}
}
@inproceedings{elgammal2017can,
	title        = {CAN: Creative adversarial networks generating “Art” by learning about styles and deviating from style norms},
	author       = {Elgammal, Ahmed and Liu, Bingchen and Elhoseiny, Mohamed and Mazzone, Marian},
	year         = {2017},
	booktitle    = {8th International Conference on Computational Creativity, ICCC 2017},
	organization = {Georgia Institute of Technology}
}
@article{Elingaard2021,
	title        = {De-homogenization using convolutional neural networks},
	author       = {Elingaard, Martin Ohrt and Aage, Niels and B{\ae}rentzen, Jakob Andreas and Sigmund, Ole},
	year         = {2022},
	month        = {1},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	volume       = {388},
	pages        = {114197},
	doi          = {10.1016/j.cma.2021.114197},
	issn         = {00457825},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0045782521005284}
}
@article{eslami2018neural,
	title        = {Neural scene representation and rendering},
	author       = {Eslami, SM Ali and Rezende, Danilo Jimenez and Besse, Frederic and Viola, Fabio and Morcos, Ari S and Garnelo, Marta and Ruderman, Avraham and Rusu, Andrei A and Danihelka, Ivo and Gregor, Karol and others},
	year         = {2018},
	journal      = {Science},
	publisher    = {American Association for the Advancement of Science},
	volume       = {360},
	number       = {6394},
	pages        = {1204--1210}
}
@inproceedings{esteves2018learning,
	title        = {Learning so (3) equivariant representations with spherical cnns},
	author       = {Esteves, Carlos and Allen-Blanchette, Christine and Makadia, Ameesh and Daniilidis, Kostas},
	year         = {2018},
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)},
	pages        = {52--68}
}
@book{evans2022partial,
	title        = {Partial differential equations},
	author       = {Evans, Lawrence C},
	year         = {2022},
	publisher    = {American Mathematical Society},
	volume       = {19}
}
@article{falorsi2018explorations,
	title        = {Explorations in homeomorphic variational auto-encoding},
	author       = {Falorsi, Luca and de Haan, Pim and Davidson, Tim R and De Cao, Nicola and Weiler, Maurice and Forr{\'e}, Patrick and Cohen, Taco S},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1807.04689}
}
@inproceedings{fe2003bayesian,
	title        = {A Bayesian approach to unsupervised one-shot learning of object categories},
	author       = {Fe-Fei, Li and others},
	year         = {2003},
	booktitle    = {Proceedings Ninth IEEE International Conference on Computer Vision},
	pages        = {1134--1141},
	organization = {IEEE}
}
@article{FEA1,
	title        = {A deep learning approach to estimate stress distribution: a fast and accurate surrogate of finite-element analysis},
	author       = {Liang, Liang and Liu, Minliang and Martin, Caitlin and Sun, Wei},
	year         = {2018},
	journal      = {Journal of The Royal Society Interface},
	volume       = {15},
	number       = {138},
	pages        = {20170844},
	doi          = {10.1098/rsif.2017.0844}
}
@inproceedings{FEA2,
	title        = {StressGAN: A Generative Deep Learning Model for 2D Stress Distribution Prediction},
	author       = {Jiang, Haoliang and Nie, Zhenguo and Yeo, Roselyn and Farimani, Amir Barati and Kara, Levent Burak},
	year         = {2020},
	month        = {08},
	series       = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {Volume 11B: 46th Design Automation Conference (DAC)},
	doi          = {10.1115/DETC2020-22682},
	url          = {https://doi.org/10.1115/DETC2020-22682},
	note         = {V11BT11A023},
	abstract     = {Using deep learning to analyze mechanical stress distributions has been gaining interest with the demand for fast stress analysis methods. Deep learning approaches have achieved excellent outcomes when utilized to speed up stress computation and learn the physics without prior knowledge of underlying equations. However, most studies restrict the variation of geometry or boundary conditions, making these methods difficult to be generalized to unseen configurations. We propose a conditional generative adversarial network (cGAN) model for predicting 2D von Mises stress distributions in solid structures. The cGAN learns to generate stress distributions conditioned by geometries, load, and boundary conditions through a two-player minimax game between two neural networks with no prior knowledge. By evaluating the generative network on two stress distribution datasets under multiple metrics, we demonstrate that our model can predict more accurate high-resolution stress distributions than a baseline convolutional neural network model, given various and complex cases of geometry, load and boundary conditions.},
	eprint       = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2020/84010/V11BT11A023/6587193/v11bt11a023-detc2020-22682.pdf}
}
@inproceedings{FEA3,
	title        = {Stress Field Prediction in Cantilevered Structures Using Convolutional Neural Networks},
	author       = {Nie, Zhenguo and Jiang, Haoliang and Kara, Levent Burak},
	year         = {2019},
	month        = {08},
	series       = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {Volume 1: 39th Computers and Information in Engineering Conference},
	doi          = {10.1115/DETC2019-98472},
	url          = {https://doi.org/10.1115/DETC2019-98472},
	note         = {V001T02A011},
	abstract     = {The demand for fast and accurate structural analysis is becoming increasingly more prevalent with the advance of generative design and topology optimization technologies. As one step toward accelerating structural analysis, this work explores a deep learning based approach for predicting the stress fields in 2D linear elastic cantilevered structures subjected to external static loads at its free end using convolutional neural networks (CNN). Two different architectures are implemented that take as input the structure geometry, external loads, and displacement boundary conditions, and output the predicted von Mises stress field. The first is a single input channel network called SCSNet as the baseline architecture, and the second is the multi-channel input network called StressNet. Accuracy analysis shows that StressNet results in significantly lower prediction errors than SCSNet on three loss functions, with a mean relative error of 2.04\\% for testing. These results suggest that deep learning models may offer a promising alternative to classical methods in structural design and topology optimization. Code and dataset are available at https://github.com/zhenguonie/stress\_net.},
	eprint       = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2019/59179/V001T02A011/6452733/v001t02a011-detc2019-98472.pdf}
}
@article{FEA4,
	title        = {Generalizable surrogate model features to approximate stress in 3D trusses},
	author       = {M. Nourbakhsh and J. Irizarry and J. Haymaker},
	year         = {2018},
	journal      = {Eng. Appl. Artif. Intell.},
	volume       = {71},
	pages        = {15--27}
}
@article{FEA5,
	title        = {Deep learning–based stress prediction for bottom-up SLA 3D printing process},
	author       = {Khadilkar, Aditya and Wang, Jun and Rai, Rahul},
	year         = {2019},
	journal      = {The International Journal of Advanced Manufacturing Technology},
	volume       = {102},
	number       = {5-8},
	pages        = {2555–2569},
	doi          = {10.1007/s00170-019-03363-4}
}
@article{FEA6,
	title        = {Prediction of residual stresses in girth welded pipes using an artificial neural network approach},
	author       = {Mathew, J. and Moat, R.j. and Paddea, S. and Fitzpatrick, M.e. and Bouchard, P.j.},
	year         = {2017},
	journal      = {International Journal of Pressure Vessels and Piping},
	volume       = {150},
	pages        = {89–95},
	doi          = {10.1016/j.ijpvp.2017.01.002}
}
@article{FEA7,
	title        = {Shear stress distribution prediction in symmetric compound channels using data mining and machine learning models},
	author       = {Khozani, Zohreh Sheikh and Khosravi, Khabat and Torabi, Mohammadamin and Mosavi, Amir and Rezaei, Bahram and Rabczuk, Timon},
	year         = {2020},
	journal      = {Frontiers of Structural and Civil Engineering},
	volume       = {14},
	number       = {5},
	pages        = {1097–1109},
	doi          = {10.1007/s11709-020-0634-3}
}
@article{FEA8,
	title        = {Stress Field Prediction in Cantilevered Structures Using Convolutional Neural Networks},
	author       = {Nie, Zhenguo and Jiang, Haoliang and Kara, Levent Burak},
	year         = {2019},
	month        = {Sep},
	journal      = {Journal of Computing and Information Science in Engineering},
	publisher    = {ASME International},
	volume       = {20},
	number       = {1},
	doi          = {10.1115/1.4044097},
	issn         = {1944-7078},
	url          = {http://dx.doi.org/10.1115/1.4044097}
}
@article{FEA9,
	title        = {Bridging Finite Element and Machine Learning Modeling: Stress Prediction of Arterial Walls in Atherosclerosis},
	author       = {Madani, Ali and Bakhaty, Ahmed and Kim, Jiwon and Mubarak, Yara and Mofrad, Mohammad R. K.},
	year         = {2019},
	journal      = {Journal of Biomechanical Engineering},
	volume       = {141},
	number       = {8},
	doi          = {10.1115/1.4043290}
}
@article{fei2006one,
	title        = {One-shot learning of object categories},
	author       = {Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
	year         = {2006},
	journal      = {IEEE transactions on pattern analysis and machine intelligence},
	publisher    = {IEEE},
	volume       = {28},
	number       = {4},
	pages        = {594--611}
}
@inproceedings{fey2018splinecnn,
	title        = {SplineCNN: Fast geometric deep learning with continuous B-spline kernels},
	author       = {Fey, Matthias and Eric Lenssen, Jan and Weichert, Frank and M{\"u}ller, Heinrich},
	year         = {2018},
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {869--877}
}
@article{fey2019fast,
	title        = {Fast Graph Representation Learning with PyTorch Geometric},
	author       = {Fey, Matthias and Lenssen, Jan Eric},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1903.02428}
}
@inproceedings{finn2016unsupervised,
	title        = {Unsupervised learning for physical interaction through video prediction},
	author       = {Finn, Chelsea and Goodfellow, Ian and Levine, Sergey},
	year         = {2016},
	booktitle    = {Advances in neural information processing systems},
	pages        = {64--72}
}
@article{finn2017model,
	title        = {Model-agnostic meta-learning for fast adaptation of deep networks},
	author       = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1703.03400}
}
@article{fokina2020microstructure,
	title        = {Microstructure synthesis using style-based generative adversarial networks},
	author       = {Fokina, Daria and Muravleva, Ekaterina and Ovchinnikov, George and Oseledets, Ivan},
	year         = {2020},
	journal      = {Physical Review E},
	publisher    = {APS},
	volume       = {101},
	number       = {4},
	pages        = {043308}
}
@misc{franceschelli2021creativity,
	title        = {Creativity and Machine Learning: A Survey},
	author       = {Giorgio Franceschelli and Mirco Musolesi},
	year         = {2021},
	eprint       = {2104.02726},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@book{friedman2008partial,
	title        = {Partial differential equations of parabolic type},
	author       = {Friedman, Avner},
	year         = {2008},
	publisher    = {Courier Dover Publications}
}
@inproceedings{Fujita2021Design,
	title        = {DESIGN CONCEPT GENERATION WITH VARIATIONAL DEEP EMBEDDING OVER COMPREHENSIVE OPTIMIZATION},
	author       = {Fujita, Kikuo and Minowa, Kazuki and Nomaguchi, Yatuka and Yamasaki, Shintaro and Yaji, Kentaro},
	year         = {2021},
	month        = {Aug},
	day          = {17-20},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, {IDETC-21}},
	address      = {Virtual, Online},
	organization = {ASME}
}
@inproceedings{gal2015modern,
	title        = {On modern deep learning and variational inference},
	author       = {Gal, Yarin and Ghahramani, Zoubin},
	year         = {2015},
	booktitle    = {Advances in Approximate Bayesian Inference workshop, NIPS},
	volume       = {2}
}
@article{gantl,
	title        = {GANTL: Toward Practical and Real-Time Topology Optimization With Conditional Generative Adversarial Networks and Transfer Learning},
	author       = {Behzadi, Mohammad Mahdi and Ilieş, Horea T.},
	year         = {2021},
	month        = {12},
	journal      = {Journal of Mechanical Design},
	volume       = {144},
	number       = {2},
	doi          = {10.1115/1.4052757},
	issn         = {1050-0472},
	url          = {https://doi.org/10.1115/1.4052757},
	note         = {021711},
	abstract     = {A number of machine learning methods have been recently proposed to circumvent the high computational cost of the gradient-based topology optimization solvers. By and large, these methods show tight generalizability to unseen boundary and external loading conditions, require prohibitively large datasets for training, and do not take into consideration topological constraints of the predictions, which results in solutions with unpredictable connectivity. To address these limitations, we propose a design exploration framework for topology optimization that exploits the knowledge transfer capability of the transfer learning methods and the generative power of conditional generative adversarial networks (GANs). We show that the proposed framework significantly exceeds the generalization ability of current methods. Moreover, the proposed architecture is capable of reusing the knowledge learned on low-resolution and computationally inexpensive samples, which notably reduces both the size of the required high-resolution training datasets and the demand on the computational infrastructure needed to generate the training data. Finally, we propose and evaluate novel approaches to improve the structural connectivity of the predicted optimal topology by including topological metrics into the loss function. We show that by including the bottleneck distance between the persistence diagrams of the predicted and ground truth structures, we significantly improve the connectivity of the prediction. Together, our results reveal the ability of generative adversarial networks implemented in a transfer learning environment to serve as powerful and practical real-time design exploration tools in topology optimization.},
	eprint       = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/144/2/021711/6806350/md\_144\_2\_021711.pdf}
}
@article{gao2019sdm,
	title        = {SDM-NET: Deep generative network for structured deformable mesh},
	author       = {Gao, Lin and Yang, Jie and Wu, Tong and Yuan, Yu-Jie and Fu, Hongbo and Lai, Yu-Kun and Zhang, Hao},
	year         = {2019},
	journal      = {ACM Transactions on Graphics (TOG)},
	publisher    = {ACM New York, NY, USA},
	volume       = {38},
	number       = {6},
	pages        = {1--15}
}
@article{garabedian1960partial,
	title        = {Partial differential equations with more than two independent variables in the complex domain},
	author       = {Garabedian, PR},
	year         = {1960},
	journal      = {Journal of Mathematics and Mechanics},
	publisher    = {JSTOR},
	pages        = {241--271}
}
@article{garcia2017few,
	title        = {Few-shot learning with graph neural networks},
	author       = {Garcia, Victor and Bruna, Joan},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1711.04043}
}
@article{Garlandtetal2021,
	title        = {Pragmatic generative optimization of novel structural lattice metamaterials with machine learning},
	author       = {Garland, Anthony P. and White, Benjamin C. and Jensen, Scott C. and Boyce, Brad L.},
	year         = {2021},
	month        = {5},
	journal      = {Materials {\&} Design},
	volume       = {203},
	pages        = {109632},
	doi          = {10.1016/j.matdes.2021.109632},
	issn         = {02641275},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0264127521001854}
}
@article{garnelo2018conditional,
	title        = {Conditional neural processes},
	author       = {Garnelo, Marta and Rosenbaum, Dan and Maddison, Chris J and Ramalho, Tiago and Saxton, David and Shanahan, Murray and Teh, Yee Whye and Rezende, Danilo J and Eslami, SM},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1807.01613}
}
@article{garnelo2018neural,
	title        = {Neural processes},
	author       = {Garnelo, Marta and Schwarz, Jonathan and Rosenbaum, Dan and Viola, Fabio and Rezende, Danilo J and Eslami, SM and Teh, Yee Whye},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1807.01622}
}
@article{GarreltsHuberetal2021,
	title        = {AI-Based Topology Optimization of Freehand Sketches},
	author       = {Garrelts, Enno and Huber, Marco and Roth, Daniel and Binz, Hansgeorg},
	year         = {2021},
	journal      = {Procedia CIRP},
	volume       = {104},
	pages        = {1316--1321},
	doi          = {10.1016/j.procir.2021.11.221},
	issn         = {22128271},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S2212827121011197}
}
@inproceedings{GAT,
	title        = {Graph Attention Networks},
	author       = {Veli{\v{c}}kovi{\'c}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Li{\`o}, Pietro and Bengio, Yoshua},
	year         = {2018},
	booktitle    = {International Conference on Learning Representations}
}
@article{gatys2015texture,
	title        = {Texture synthesis using convolutional neural networks},
	author       = {Gatys, Leon and Ecker, Alexander S and Bethge, Matthias},
	year         = {2015},
	journal      = {Advances in neural information processing systems},
	volume       = {28},
	pages        = {262--270}
}
@inproceedings{gatys2016image,
	title        = {Image style transfer using convolutional neural networks},
	author       = {Gatys, Leon A and Ecker, Alexander S and Bethge, Matthias},
	year         = {2016},
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {2414--2423}
}
@misc{GCN,
	title        = {Deep Convolutional Networks on Graph-Structured Data},
	author       = {Mikael Henaff and Joan Bruna and Yann LeCun},
	year         = {2015},
	eprint       = {1506.05163},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@article{gers1999learning,
	title        = {Learning to forget: Continual prediction with LSTM},
	author       = {Gers, Felix A and Schmidhuber, J{\"u}rgen and Cummins, Fred},
	year         = {1999},
	publisher    = {IET}
}
@inproceedings{gershman2014amortized,
	title        = {Amortized inference in probabilistic reasoning},
	author       = {Gershman, Samuel and Goodman, Noah},
	year         = {2014},
	booktitle    = {Proceedings of the annual meeting of the cognitive science society},
	volume       = {36},
	number       = {36}
}
@article{giannone2019no,
	title        = {No Representation without Transformation},
	author       = {Giannone, Giorgio and Saremi, Saeed and Masci, Jonathan and Osendorfer, Christian},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1912.03845}
}
@article{giannone2021hierarchical,
	title        = {Hierarchical Few-Shot Generative Models},
	author       = {Giannone, Giorgio and Winther, Ole},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2110.12279}
}
@article{giannone2022few,
	title        = {Few-shot diffusion models},
	author       = {Giannone, Giorgio and Nielsen, Didrik and Winther, Ole},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2205.15463}
}
@inproceedings{giannone2022scha,
	title        = {SCHA-VAE: Hierarchical Context Aggregation for Few-Shot Generation},
	author       = {Giannone, Giorgio and Winther, Ole},
	year         = {2022},
	booktitle    = {International Conference on Machine Learning},
	pages        = {7550--7569},
	organization = {PMLR}
}
@article{giannone2023diffusing,
	title        = {Diffusing the Optimal Topology: A Generative Optimization Approach},
	author       = {Giannone, Giorgio and Ahmed, Faez},
	year         = {2023},
	journal      = {arXiv preprint arXiv:2303.09760}
}
@article{gielis2003generic,
	title        = {A generic geometric transformation that unifies a wide range of natural and abstract shapes},
	author       = {Gielis, Johan},
	year         = {2003},
	journal      = {American journal of botany},
	publisher    = {Wiley Online Library},
	volume       = {90},
	number       = {3},
	pages        = {333--338}
}
@article{Glaeseneretal2020,
	title        = {Continuum representation of nonlinear three-dimensional periodic truss networks by on-the-fly homogenization},
	author       = {Glaesener, Raphaël N. and Tr{\"{a}}ff, Erik A. and Telgen, Bastian and Canonica, Renato M. and Kochmann, Dennis M.},
	year         = {2020},
	month        = {12},
	journal      = {International Journal of Solids and Structures},
	volume       = {206},
	pages        = {101--113},
	doi          = {10.1016/j.ijsolstr.2020.08.013},
	issn         = {00207683},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0020768320303127}
}
@inproceedings{goodfellow2014generative,
	title        = {Generative adversarial nets},
	author       = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	year         = {2014},
	booktitle    = {Advances in neural information processing systems},
	pages        = {2672--2680}
}
@book{Goodfellow2016,
	title        = {Deep Learning},
	author       = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year         = {2016},
	publisher    = {The MIT Press},
	isbn         = {0262035618}
}
@article{Goodfellowetal2018,
	title        = {Making machine learning robust against adversarial inputs},
	author       = {Goodfellow, Ian and McDaniel, Patrick and Papernot, Nicolas},
	year         = {2018},
	month        = {6},
	journal      = {Communications of the ACM},
	volume       = {61},
	number       = {7},
	pages        = {56--66},
	doi          = {10.1145/3134599},
	issn         = {0001-0782},
	url          = {https://dl.acm.org/doi/10.1145/3134599}
}
@book{goosens,
	title        = {The \LaTeX\ Companion},
	author       = {M. Goosens and F. Mittelbach and A. Samarin},
	year         = {1994},
	publisher    = {Addison-Wesley},
	address      = {Reading, MA}
}
@article{gordon2019convolutional,
	title        = {Convolutional conditional neural processes},
	author       = {Gordon, Jonathan and Bruinsma, Wessel P and Foong, Andrew YK and Requeima, James and Dubois, Yann and Turner, Richard E},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1910.13556}
}
@article{grant2018recasting,
	title        = {Recasting gradient-based meta-learning as hierarchical bayes},
	author       = {Grant, Erin and Finn, Chelsea and Levine, Sergey and Darrell, Trevor and Griffiths, Thomas},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1801.08930}
}
@inproceedings{graves2009offline,
	title        = {Offline handwriting recognition with multidimensional recurrent neural networks},
	author       = {Graves, Alex and Schmidhuber, J{\"u}rgen},
	year         = {2009},
	booktitle    = {Advances in neural information processing systems},
	pages        = {545--552}
}
@inproceedings{graves2011practical,
	title        = {Practical variational inference for neural networks},
	author       = {Graves, Alex},
	year         = {2011},
	booktitle    = {Advances in neural information processing systems},
	pages        = {2348--2356}
}
@article{graves2013generating,
	title        = {Generating sequences with recurrent neural networks},
	author       = {Graves, Alex},
	year         = {2013},
	journal      = {arXiv preprint arXiv:1308.0850}
}
@article{graves2018acn,
	title        = {Associative Compression Networks for Representation Learning},
	author       = {Alex Graves and Jacob Menick and A{\"{a}}ron van den Oord},
	year         = {2018},
	journal      = {CoRR},
	volume       = {abs/1804.02476},
	url          = {http://arxiv.org/abs/1804.02476},
	archiveprefix = {arXiv},
	eprint       = {1804.02476},
	timestamp    = {Mon, 13 Aug 2018 16:47:16 +0200},
	biburl       = {https://dblp.org/rec/bib/journals/corr/abs-1804-02476},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@book{greenberg2015applications,
	title        = {Applications of Green's functions in science and engineering},
	author       = {Greenberg, Michael D},
	year         = {2015},
	publisher    = {Courier Dover Publications}
}
@article{greff2019multi,
	title        = {Multi-Object Representation Learning with Iterative Variational Inference},
	author       = {Greff, Klaus and Kaufmann, Rapha{\"e}l Lopez and Kabra, Rishab and Watters, Nick and Burgess, Chris and Zoran, Daniel and Matthey, Loic and Botvinick, Matthew and Lerchner, Alexander},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1903.00450}
}
@article{gregor2015draw,
	title        = {Draw: A recurrent neural network for image generation},
	author       = {Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
	year         = {2015},
	journal      = {arXiv preprint arXiv:1502.04623}
}
@inproceedings{gregor2016towards,
	title        = {Towards conceptual compression},
	author       = {Gregor, Karol and Besse, Frederic and Rezende, Danilo Jimenez and Danihelka, Ivo and Wierstra, Daan},
	year         = {2016},
	booktitle    = {Advances In Neural Information Processing Systems},
	pages        = {3549--3557}
}
@article{gregor2018temporal,
	title        = {Temporal difference variational auto-encoder},
	author       = {Gregor, Karol and Papamakarios, George and Besse, Frederic and Buesing, Lars and Weber, Theophane},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1806.03107}
}
@article{gregor2019shaping,
	title        = {Shaping Belief States with Generative Environment Models for RL},
	author       = {Gregor, Karol and Rezende, Danilo Jimenez and Besse, Frederic and Wu, Yan and Merzic, Hamza and Oord, Aaron van den},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1906.09237}
}
@inproceedings{Greminger2020,
	title        = {Generative Adversarial Networks With Synthetic Training Data for Enforcing Manufacturing Constraints on Topology Optimization},
	author       = {Greminger, Michael},
	year         = {2020},
	month        = {8},
	booktitle    = {Volume 11A: 46th Design Automation Conference (DAC)},
	publisher    = {American Society of Mechanical Engineers},
	doi          = {10.1115/DETC2020-22399},
	isbn         = {978-0-7918-8400-3},
	url          = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings/IDETC-CIE2020/84003/Virtual,%20Online/1090207},
	organization = {Proceedings of the ASME 2020 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference.},
	keywords     = {Topology optimization, deep learning, design for manufacturability, generative adversarial networks, manufacturing constraints}
}
@inproceedings{greminger2020generative,
	title        = {Generative Adversarial Networks With Synthetic Training Data for Enforcing Manufacturing Constraints on Topology Optimization},
	author       = {Greminger, Michael},
	year         = {2020},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {84003},
	pages        = {V11AT11A005},
	organization = {American Society of Mechanical Engineers}
}
@inproceedings{gretton2007kernel,
	title        = {A kernel method for the two-sample-problem},
	author       = {Gretton, Arthur and Borgwardt, Karsten and Rasch, Malte and Sch{\"o}lkopf, Bernhard and Smola, Alex J},
	year         = {2007},
	booktitle    = {Advances in neural information processing systems},
	pages        = {513--520}
}
@article{griffiths2003hierarchical,
	title        = {Hierarchical topic models and the nested Chinese restaurant process},
	author       = {Griffiths, Thomas and Jordan, Michael and Tenenbaum, Joshua and Blei, David},
	year         = {2003},
	journal      = {Advances in neural information processing systems},
	volume       = {16}
}
@article{Groen16,
	title        = {Higher-order multi-resolution topology optimization using the finite cell method},
	author       = {Groen, Jeroen P. and Langelaar, Matthijs and Sigmund, Ole and Ruess, Martin},
	year         = {2017},
	month        = {6},
	journal      = {International Journal for Numerical Methods in Engineering},
	publisher    = {John Wiley and Sons Ltd},
	volume       = {110},
	number       = {10},
	pages        = {903--920},
	doi          = {10.1002/nme.5432},
	issn         = {00295981},
	url          = {https://onlinelibrary.wiley.com/doi/10.1002/nme.5432},
	keywords     = {finite cell method, higher-order FEM, topology optimization}
}
@article{Groen18,
	title        = {Homogenization-based topology optimization for high-resolution manufacturable microstructures},
	author       = {Groen, Jeroen P. and Sigmund, Ole},
	year         = {2018},
	month        = {2},
	journal      = {International Journal for Numerical Methods in Engineering},
	publisher    = {John Wiley and Sons Ltd},
	volume       = {113},
	number       = {8},
	pages        = {1148--1163},
	doi          = {10.1002/nme.5575},
	issn         = {00295981},
	url          = {https://onlinelibrary.wiley.com/doi/10.1002/nme.5575},
	keywords     = {high-resolution, homogenization, manufacturing constraints, topology optimization}
}
@techreport{GroenTraeffetal2020,
	title        = {General rights Simple single-scale interpretations of optimal designs in the context of extremal stiffness},
	author       = {Groen, Jeroen ; and Tr{\"{a}}ff, Erik ; and Wang, Yiqiang ; and Sigmund, Ole},
	year         = {2019},
	url          = {https://orbit.dtu.dk/en/publications/simple-single-scale-interpretations-of-optimal-designs-in-the-con}
}
@inproceedings{groueix2018papier,
	title        = {A papier-m{\^a}ch{\'e} approach to learning 3d surface generation},
	author       = {Groueix, Thibault and Fisher, Matthew and Kim, Vladimir G and Russell, Bryan C and Aubry, Mathieu},
	year         = {2018},
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {216--224}
}
@inproceedings{GTN,
	title        = {Graph Transformer Networks},
	author       = {Yun, Seongjun and Jeong, Minbyul and Kim, Raehyun and Kang, Jaewoo and Kim, Hyunwoo J},
	year         = {2019},
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = {32},
	pages        = {},
	url          = {https://proceedings.neurips.cc/paper/2019/file/9d63484abb477c97640154d40595a3bb-Paper.pdf},
	editor       = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett}
}
@article{GuChenBuehler2018,
	title        = {De novo composite design based on machine learning algorithm},
	author       = {Gu, Grace X. and Chen, Chun-Teh and Buehler, Markus J.},
	year         = {2018},
	month        = {1},
	journal      = {Extreme Mechanics Letters},
	volume       = {18},
	pages        = {19--28},
	doi          = {10.1016/j.eml.2017.10.001},
	issn         = {23524316},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S2352431617301256}
}
@article{guest_editorial,
	title        = {Special Issue: Machine Learning for Engineering Design},
	author       = {Panchal, Jitesh H. and Fuge, Mark and Liu, Ying and Missoum, Samy and Tucker, Conrad},
	year         = {2019},
	month        = {10},
	journal      = {Journal of Mechanical Design},
	volume       = {141},
	number       = {11},
	doi          = {10.1115/1.4044690},
	issn         = {1050-0472},
	url          = {https://doi.org/10.1115/1.4044690},
	note         = {110301},
	abstract     = {Modern machine learning (ML) techniques are transforming many disciplines ranging from transportation to healthcare by uncovering patterns in data, developing autonomous systems that mimic human abilities, and supporting human decision-making. Modern ML techniques, such as deep neural networks, are fueling the rapid developments in artificial intelligence. Engineering design researchers have increasingly used and developed ML techniques to support a wide range of activities from preference modeling to uncertainty quantification in high-dimensional design optimization problems. This special issue brings together fundamental scientific contributions across these areas.},
	eprint       = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/141/11/110301/6578324/md\_141\_11\_110301.pdf}
}
@article{guest2004achieving,
	title        = {Achieving minimum length scale in topology optimization using nodal design variables and projection functions},
	author       = {Guest, James K and Pr{\'e}vost, Jean H and Belytschko, Ted},
	year         = {2004},
	journal      = {International journal for numerical methods in engineering},
	publisher    = {Wiley Online Library},
	volume       = {61},
	number       = {2},
	pages        = {238--254}
}
@article{gulrajani2016pixelvae,
	title        = {Pixelvae: A latent variable model for natural images},
	author       = {Gulrajani, Ishaan and Kumar, Kundan and Ahmed, Faruk and Taiga, Adrien Ali and Visin, Francesco and Vazquez, David and Courville, Aaron},
	year         = {2016},
	journal      = {arXiv preprint arXiv:1611.05013}
}
@inproceedings{gulrajani2017improved,
	title        = {Improved Training of Wasserstein GANs},
	author       = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron},
	year         = {2017},
	booktitle    = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
	location     = {Long Beach, California, USA},
	publisher    = {Curran Associates Inc.},
	address      = {Red Hook, NY, USA},
	series       = {NIPS'17},
	pages        = {5769–5779},
	isbn         = {9781510860964},
	abstract     = {Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only poor samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models with continuous generators. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.},
	numpages     = {11}
}
@article{guo2017calibration,
	title        = {On calibration of modern neural networks},
	author       = {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1706.04599}
}
%NO BETTER BIBTEX
@inproceedings{Guo2018,
	title        = {An Indirect Design Representation for Topology Optimization Using Variational Autoencoder and Style Transfer},
	author       = {Guo, Tinghao and Lohan, Danny J and Cang, Ruijin and Ren, Max Yi and Allison, James T},
	year         = {2018},
	month        = jan,
	booktitle    = {2018 AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference, AIAA SciTech Forum},
	number       = {AIAA 2018-0804},
	doi          = {10.2514/6.2018-0804},
	pdf          = {http://systemdesign.illinois.edu/publications/Guo2018a.pdf},
	esdlid       = {C53}
}
@inproceedings{guo2018indirect,
	title        = {An indirect design representation for topology optimization using variational autoencoder and style transfer},
	author       = {Guo, Tinghao and Lohan, Danny J and Cang, Ruijin and Ren, Max Yi and Allison, James T},
	year         = {2018},
	booktitle    = {2018 AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference},
	pages        = {0804}
}
@article{guo2018neural,
	title        = {Neural predictive belief representations},
	author       = {Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and Piot, Bilal and Pires, Bernardo A and Pohlen, Toby and Munos, R{\'e}mi},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1811.06407}
}
@article{Guoetal2014,
	title        = {Doing Topology Optimization Explicitly and Geometrically—A New Moving Morphable Components Based Framework},
	author       = {Guo, Xu and Zhang, Weisheng and Zhong, Wenliang},
	year         = {2014},
	month        = {8},
	journal      = {Journal of Applied Mechanics},
	volume       = {81},
	number       = {8},
	doi          = {10.1115/1.4027609},
	issn         = {0021-8936},
	url          = {https://asmedigitalcollection.asme.org/appliedmechanics/article/doi/10.1115/1.4027609/370419/Doing-Topology-Optimization-Explicitly-and}
}
@inproceedings{Guoetal2018,
	title        = {An Indirect Design Representation for Topology Optimization Using Variational Autoencoder and Style Transfer},
	author       = {Guo, Tinghao and Lohan, Danny J. and Cang, Ruijin and Ren, Max Yi and Allison, James T.},
	year         = {2018},
	month        = {1},
	booktitle    = {2018 AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference},
	publisher    = {American Institute of Aeronautics and Astronautics},
	address      = {Reston, Virginia},
	doi          = {10.2514/6.2018-0804},
	isbn         = {978-1-62410-532-6},
	url          = {https://arc.aiaa.org/doi/10.2514/6.2018-0804}
}
@article{GuoYang2021,
	title        = {Artificial intelligence and machine learning in design of mechanical materials},
	author       = {Guo, Kai and Yang, Zhenze and Yu, Chi-Hua and Buehler, Markus J.},
	year         = {2021},
	journal      = {Materials Horizons},
	volume       = {8},
	number       = {4},
	pages        = {1153--1172},
	doi          = {10.1039/D0MH01451F},
	issn         = {2051-6347},
	url          = {http://xlink.rsc.org/?DOI=D0MH01451F}
}
@article{Gurguisetal2020,
	title        = {Evolutionary Black-Box Topology Optimization: Challenges and Promises},
	author       = {Guirguis, David and Aulig, Nikola and Picelli, Renato and Zhu, Bo and Zhou, Yuqing and Vicente, William and Iorio, Francesco and Olhofer, Markus and Matusiks, Wojciech and Coello Coello, Carlos Artemio and Saitou, Kazuhiro},
	year         = {2020},
	month        = {8},
	journal      = {IEEE Transactions on Evolutionary Computation},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	volume       = {24},
	number       = {4},
	pages        = {613--633},
	doi          = {10.1109/TEVC.2019.2954411},
	issn         = {1089-778X},
	url          = {https://ieeexplore.ieee.org/document/8906012/},
	keywords     = {CADCAM, design automation, design optimization, evolutionary computation, large scale optimization, product design, topology, topology optimization}
}
@inproceedings{ha2018neural,
	title        = {A Neural Representation of Sketch Drawings},
	author       = {Ha, David and Eck, Douglas},
	year         = {2018},
	booktitle    = {International Conference on Learning Representations}
}
@article{ha2018world,
	title        = {World models},
	author       = {Ha, David and Schmidhuber, J{\"u}rgen},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1803.10122}
}
@inproceedings{hadsell2006dimensionality,
	title        = {Dimensionality reduction by learning an invariant mapping},
	author       = {Hadsell, Raia and Chopra, Sumit and LeCun, Yann},
	year         = {2006},
	booktitle    = {2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)},
	volume       = {2},
	pages        = {1735--1742},
	organization = {IEEE}
}
@article{hafner2018learning,
	title        = {Learning Latent Dynamics for Planning from Pixels},
	author       = {Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1811.04551}
}
@article{hahn2018disentangling,
	title        = {Disentangling Latent Factors with Whitening},
	author       = {Hahn, Sangchul and Choi, Heeyoul},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1811.03444}
}
@book{hale2013introduction,
	title        = {Introduction to functional differential equations},
	author       = {Hale, Jack K and Lunel, Sjoerd M Verduyn},
	year         = {2013},
	publisher    = {Springer Science \& Business Media},
	volume       = {99}
}
@article{Halleetal2020,
	title        = {An Artificial Intelligence–Assisted Design Method for Topology Optimization without Pre-Optimized Training Data},
	author       = {Halle, Alex and Campanile, Lucio Flavio and Hasse, Alexander},
	year         = {2021},
	month        = {9},
	journal      = {Applied Sciences},
	volume       = {11},
	number       = {19},
	pages        = {9041},
	doi          = {10.3390/app11199041},
	issn         = {2076-3417},
	url          = {https://www.mdpi.com/2076-3417/11/19/9041}
}
@article{han2019learning,
	title        = {Learning to Discover Novel Visual Categories via Deep Transfer Clustering},
	author       = {Han, Kai and Vedaldi, Andrea and Zisserman, Andrew},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1908.09884}
}
@incollection{Harishetal2020,
	title        = {Topology Optimization Using Convolutional Neural Network},
	author       = {Harish, Baki and Eswara Sai Kumar, Kandula and Srinivasan, Balaji},
	year         = {2020},
	booktitle    = {Lecture Notes in Mechanical Engineering},
	publisher    = {Springer},
	pages        = {301--307},
	doi          = {10.1007/978-981-15-5432-2{\_}26},
	url          = {http://link.springer.com/10.1007/978-981-15-5432-2_26},
	keywords     = {Convolution–deconvolution network, Machine learning, Topology optimization}
}
@article{harvey2022flexible,
	title        = {Flexible Diffusion Modeling of Long Videos},
	author       = {Harvey, William and Naderiparizi, Saeid and Masrani, Vaden and Weilbach, Christian and Wood, Frank},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2205.11495}
}
@article{Hashemietal2021,
	title        = {A supervised machine learning approach for accelerating the design of particulate composites: Application to thermal conductivity},
	author       = {Hashemi, Mohammad Saber and Safdari, Masoud and Sheidaei, Azadeh},
	year         = {2021},
	month        = {9},
	journal      = {Computational Materials Science},
	volume       = {197},
	pages        = {110664},
	doi          = {10.1016/j.commatsci.2021.110664},
	issn         = {09270256},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0927025621003918}
}
@article{hassani2021escaping,
	title        = {Escaping the big data paradigm with compact transformers},
	author       = {Hassani, Ali and Walton, Steven and Shah, Nikhil and Abuduweili, Abulikemu and Li, Jiachen and Shi, Humphrey},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2104.05704}
}
@article{hauberg2018only,
	title        = {Only Bayes should learn a manifold (on the estimation of differential geometric structure from data)},
	author       = {Hauberg, S{\o}ren},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1806.04994}
}
@article{HayashiOhsaki2020,
	title        = {Reinforcement Learning and Graph Embedding for Binary Truss Topology Optimization Under Stress and Displacement Constraints},
	author       = {Hayashi, Kazuki and Ohsaki, Makoto},
	year         = {2020},
	month        = {4},
	journal      = {Frontiers in Built Environment},
	publisher    = {Frontiers Media S.A.},
	volume       = {6},
	doi          = {10.3389/fbuil.2020.00059},
	issn         = {2297-3362},
	url          = {https://www.frontiersin.org/article/10.3389/fbuil.2020.00059/full},
	keywords     = {binary-type approach, graph embedding, machine learning, reinforcement learning, stress and displacement constraints, topology optimization, truss}
}
@inproceedings{he2016deep,
	title        = {Deep residual learning for image recognition},
	author       = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	year         = {2016},
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {770--778}
}
@article{he2019lagging,
	title        = {Lagging Inference Networks and Posterior Collapse in Variational Autoencoders},
	author       = {He, Junxian and Spokoyny, Daniel and Neubig, Graham and Berg-Kirkpatrick, Taylor},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1901.05534}
}
@article{he2021masked,
	title        = {Masked autoencoders are scalable vision learners},
	author       = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2111.06377}
}
@article{Heaven2019,
	title        = {Why deep-learning AIs are so easy to fool},
	author       = {Heaven, Douglas},
	year         = {2019},
	month        = {10},
	journal      = {Nature},
	volume       = {574},
	number       = {7777},
	pages        = {163--166},
	doi          = {10.1038/d41586-019-03013-5},
	issn         = {0028-0836},
	url          = {http://www.nature.com/articles/d41586-019-03013-5}
}
@article{Herath2021,
	title        = {Topologically optimal design and failure prediction using conditional generative adversarial networks},
	author       = {Herath, Sumudu and Haputhanthri, Udith},
	year         = {2021},
	month        = {12},
	journal      = {International Journal for Numerical Methods in Engineering},
	publisher    = {John Wiley and Sons Ltd},
	volume       = {122},
	number       = {23},
	pages        = {6867--6887},
	doi          = {10.1002/nme.6814},
	issn         = {0029-5981},
	url          = {https://onlinelibrary.wiley.com/doi/10.1002/nme.6814},
	keywords     = {Von-Mises stress, conditional generative adversarial networks, data-driven topology optimization, stress prediction, topology optimization}
}
@proceedings{hertlein2022,
	title        = {Generative Adversarial Design Analysis of Non-Convexity in Topology Optimization},
	author       = {Hertlein Nathan and Gillman Andrew and Buskohl Philip R.},
	year         = {2022},
	month        = {08},
	series       = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {Volume 3B: 48th Design Automation Conference (DAC)},
	doi          = {10.1115/DETC2022-89997},
	url          = {https://doi.org/10.1115/DETC2022-89997},
	note         = {V03BT03A044},
	abstract     = {Material penalization and filtering schemes are key strategies applied to topology optimization (TO) to promote more discrete and manufacturable designs. However, these modifications introduce fluctuations in the design landscape that amplify non-convexity and influence the local minima identified by TO. Harnessing the machine learning approach of generative adversarial networks (GAN), we investigate the role of penalization and filtering by comparing the designs between TO and GAN-based TO surrogates. A total of 17 GANs were constructed to predict 2D minimum compliance topologies across a set of penalization factors and filters, each interpolating a design space of 270,000 boundary condition and loading scenarios. The prevalence of GAN-predicted topologies with better compliance than TO-calculated topologies was estimated via a random sampling of the design space. GAN ‘over-performance’ occurs across material penalization and filtering conditions, where the frequency tends to increase as penalization increases. Analysis of this test set is leveraged to highlight trends regarding the conditions under which this ‘over-performance’ occurs, and the geometric characteristics these designs exhibit. Collectively, this study presents an alternative method to characterize the effects of penalization and filtering on design outcomes and motivates the use of data-driven surrogates to augment traditional approaches.},
	eprint       = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2022/86236/V03BT03A044/6943222/v03bt03a044-detc2022-89997.pdf}
}
@article{Hertleinetal2021,
	title        = {Generative adversarial network for early-stage design flexibility in topology optimization for additive manufacturing},
	author       = {Hertlein, Nathan and Buskohl, Philip R. and Gillman, Andrew and Vemaganti, Kumar and Anand, Sam},
	year         = {2021},
	month        = {4},
	journal      = {Journal of Manufacturing Systems},
	publisher    = {Elsevier B.V.},
	volume       = {59},
	pages        = {675--685},
	doi          = {10.1016/j.jmsy.2021.04.007},
	issn         = {02786125},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S027861252100087X},
	keywords     = {Additive manufacturing, Deep learning, Generative adversarial network, Topology optimization}
}
@article{heusel2017gans,
	title        = {Gans trained by a two time-scale update rule converge to a local nash equilibrium},
	author       = {Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
	year         = {2017},
	journal      = {Advances in neural information processing systems},
	volume       = {30}
}
@article{hewitt2018variational,
	title        = {The variational homoencoder: Learning to learn high capacity generative models from few examples},
	author       = {Hewitt, Luke B and Nye, Maxwell I and Gane, Andreea and Jaakkola, Tommi and Tenenbaum, Joshua B},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1807.08919}
}
@article{higgins2016beta,
	title        = {beta-vae: Learning basic visual concepts with a constrained variational framework},
	author       = {Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
	year         = {2016}
}
@article{higgins2018towards,
	title        = {Towards a Definition of Disentangled Representations},
	author       = {Higgins, Irina and Amos, David and Pfau, David and Racaniere, Sebastien and Matthey, Loic and Rezende, Danilo and Lerchner, Alexander},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1812.02230}
}
@inproceedings{hinton1981parallel,
	title        = {A parallel computation that assigns canonical object-based frames of reference},
	author       = {Hinton, Geoffrey F},
	year         = {1981},
	booktitle    = {Proceedings of the 7th international joint conference on Artificial intelligence-Volume 2},
	pages        = {683--685}
}
@inproceedings{hinton2011transforming,
	title        = {Transforming auto-encoders},
	author       = {Hinton, Geoffrey E and Krizhevsky, Alex and Wang, Sida D},
	year         = {2011},
	booktitle    = {International conference on artificial neural networks},
	pages        = {44--51},
	organization = {Springer}
}
@inproceedings{ho2020,
	title        = {Denoising Diffusion Probabilistic Models},
	author       = {Jonathan Ho and Ajay Jain and Pieter Abbeel},
	year         = {2020},
	booktitle    = {Advances in Neural Information Processing Systems 33}
}
@inproceedings{ho2020denoising,
	title        = {Denoising Diffusion Probabilistic Models},
	author       = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
	year         = {2020},
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = {33},
	pages        = {6840--6851},
	url          = {https://proceedings.neurips.cc/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf},
	editor       = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin}
}
%NO BETTER BIBTEX
@inproceedings{ho2021classifierfree,
	title        = {Classifier-Free Diffusion Guidance},
	author       = {Jonathan Ho and Tim Salimans},
	year         = {2021},
	booktitle    = {NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications},
	url          = {https://openreview.net/forum?id=qw8AKxfYbI}
}
@article{ho2022cascaded,
	title        = {Cascaded diffusion models for high fidelity image generation},
	author       = {Ho, Jonathan and Saharia, Chitwan and Chan, William and Fleet, David J and Norouzi, Mohammad and Salimans, Tim},
	year         = {2022},
	journal      = {Journal of Machine Learning Research},
	volume       = {23},
	number       = {47},
	pages        = {1--33}
}
@article{ho2022classifier,
	title        = {Classifier-free diffusion guidance},
	author       = {Ho, Jonathan and Salimans, Tim},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2207.12598}
}
@article{ho2022video,
	title        = {Video Diffusion Models},
	author       = {Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2204.03458}
}
@article{Hoangetal2022,
	title        = {Data-driven geometry-based topology optimization},
	author       = {Hoang, Van-Nam and Nguyen, Ngoc-Linh and Tran, Dat Q. and Vu, Quang-Viet and Nguyen-Xuan, H.},
	year         = {2022},
	month        = {2},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {65},
	number       = {2},
	pages        = {69},
	doi          = {10.1007/s00158-022-03170-8},
	issn         = {1615-147X}
}
@article{hochreiter1997long,
	title        = {Long short-term memory},
	author       = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
	year         = {1997},
	journal      = {Neural computation},
	publisher    = {MIT Press},
	volume       = {9},
	number       = {8},
	pages        = {1735--1780}
}
@article{hochreiter1999feature,
	title        = {Feature extraction through LOCOCODE},
	author       = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
	year         = {1999},
	journal      = {Neural Computation},
	publisher    = {MIT Press},
	volume       = {11},
	number       = {3},
	pages        = {679--714}
}
@inproceedings{hochreiter2001learning,
	title        = {Learning to learn using gradient descent},
	author       = {Hochreiter, Sepp and Younger, A Steven and Conwell, Peter R},
	year         = {2001},
	booktitle    = {International Conference on Artificial Neural Networks},
	pages        = {87--94},
	organization = {Springer}
}
@article{hoffman2013stochastic,
	title        = {Stochastic variational inference},
	author       = {Hoffman, Matthew D and Blei, David M and Wang, Chong and Paisley, John},
	year         = {2013},
	journal      = {The Journal of Machine Learning Research},
	publisher    = {JMLR. org},
	volume       = {14},
	number       = {1},
	pages        = {1303--1347}
}
@inproceedings{hoffman2016elbo,
	title        = {Elbo surgery: yet another way to carve up the variational evidence lower bound},
	author       = {Hoffman, Matthew D and Johnson, Matthew J},
	year         = {2016},
	booktitle    = {Workshop in Advances in Approximate Bayesian Inference, NIPS}
}
@article{hoogeboom2021argmax,
	title        = {Argmax flows and multinomial diffusion: Learning categorical distributions},
	author       = {Hoogeboom, Emiel and Nielsen, Didrik and Jaini, Priyank and Forr{\'e}, Patrick and Welling, Max},
	year         = {2021},
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {34}
}
@article{hoogeboom2022equivariant,
	title        = {Equivariant Diffusion for Molecule Generation in 3D},
	author       = {Hoogeboom, Emiel and Satorras, Victor Garcia and Vignac, Cl{\'e}ment and Welling, Max},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2203.17003}
}
@article{HorvitzMullign2015,
	title        = {Data, privacy, and the greater good},
	author       = {Horvitz, Eric and Mulligan, Deirdre},
	year         = {2015},
	month        = {7},
	journal      = {Science},
	publisher    = {American Association for the Advancement of Science},
	volume       = {349},
	number       = {6245},
	pages        = {253--255},
	doi          = {10.1126/science.aac4520},
	issn         = {0036-8075},
	url          = {https://www.science.org/doi/10.1126/science.aac4520}
}
@article{hospedales2020meta,
	title        = {Meta-learning in neural networks: A survey},
	author       = {Hospedales, Timothy and Antoniou, Antreas and Micaelli, Paul and Storkey, Amos},
	year         = {2020},
	journal      = {arXiv preprint arXiv:2004.05439}
}
@article{Hoyeretal2019,
	title        = {Neural reparameterization improves structural optimization},
	author       = {Hoyer, Stephan and Sohl-Dickstein, Jascha and Greydanus, Sam},
	year         = {2019},
	month        = {9},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/1909.04240},
	arxivid      = {1909.04240}
}
@inproceedings{hu2018squeeze,
	title        = {Squeeze-and-excitation networks},
	author       = {Hu, Jie and Shen, Li and Sun, Gang},
	year         = {2018},
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {7132--7141}
}
@article{huang2009bi,
	title        = {Bi-directional evolutionary topology optimization of continuum structures with one or multiple materials},
	author       = {Huang, Xiaodong and Xie, Yi Min},
	year         = {2009},
	journal      = {Computational Mechanics},
	publisher    = {Springer},
	volume       = {43},
	number       = {3},
	pages        = {393--401}
}
@article{huang2021variational,
	title        = {A variational perspective on diffusion-based generative models and score matching},
	author       = {Huang, Chin-Wei and Lim, Jae Hyun and Courville, Aaron C},
	year         = {2021},
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {34}
}
@misc{Hunter2007william,
	title        = {ToPy - Topology optimization with Python},
	author       = {Hunter, William and others},
	year         = {2017},
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\url{https://github.com/williamhunter/topy}}
}
@misc{hunter2017topy,
	title        = {Topy-topology optimization with python},
	author       = {Hunter, William and others},
	year         = {2017}
}
@inproceedings{hyvarinen2016unsupervised,
	title        = {Unsupervised feature extraction by time-contrastive learning and nonlinear ica},
	author       = {Hyvarinen, Aapo and Morioka, Hiroshi},
	year         = {2016},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {3765--3773}
}
@inbook{ibk,
	title        = {Book title},
	year         = {1991},
	publisher    = {Publisher {N}ame},
	address      = {Publisher address},
	series       = {Series Title},
	volume       = {2},
	pages        = {1--3},
	note         = {See also URL \verb+http://www.abc.edu+},
	editor       = {A. Inbook},
	chapter      = {1},
	edition      = {$1^{st}$},
	type         = {Chap.}
}
@incollection{icn,
	title        = {Article title},
	author       = {A. Incollection},
	year         = {1991},
	month        = {May},
	booktitle    = {Collection {T}itle},
	publisher    = {Publisher {N}ame},
	address      = {Publisher address},
	series       = {Series title},
	volume       = {2},
	pages        = {1--3},
	note         = {See also URL \verb+http://www.abc.edu+},
	editor       = {A. Editor},
	chapter      = {1},
	edition      = {$3^{rd}$},
	type         = {{C}hapter}
}
@article{image_editing,
	title        = {SDEdit: Image Synthesis and Editing with Stochastic Differential Equations},
	author       = {Chenlin Meng and Yang Song and Jiaming Song and Jiajun Wu and Jun{-}Yan Zhu and Stefano Ermon},
	year         = {2021},
	journal      = {CoRR},
	volume       = {abs/2108.01073},
	url          = {https://arxiv.org/abs/2108.01073},
	eprinttype   = {arXiv},
	eprint       = {2108.01073},
	timestamp    = {Thu, 12 Aug 2021 17:50:35 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2108-01073.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{image_gen,
	title        = {Improved Denoising Diffusion Probabilistic Models},
	author       = {Alexander Quinn Nichol and Prafulla Dhariwal},
	year         = {2021},
	booktitle    = {Proceedings of the 38th International Conference on Machine Learning, {ICML} 2021, 18-24 July 2021, Virtual Event},
	publisher    = {PMLR},
	series       = {Proceedings of Machine Learning Research},
	volume       = {139},
	pages        = {8162--8171},
	url          = {http://proceedings.mlr.press/v139/nichol21a.html},
	editor       = {Marina Meila and Tong Zhang},
	timestamp    = {Wed, 25 Aug 2021 17:11:17 +0200},
	biburl       = {https://dblp.org/rec/conf/icml/NicholD21.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{image_segmentation,
	title        = {SegDiff: Image Segmentation with Diffusion Probabilistic Models},
	author       = {Tomer Amit and Eliya Nachmani and Tal Shaharabany and Lior Wolf},
	year         = {2021},
	journal      = {CoRR},
	volume       = {abs/2112.00390},
	url          = {https://arxiv.org/abs/2112.00390},
	eprinttype   = {arXiv},
	eprint       = {2112.00390},
	timestamp    = {Tue, 07 Dec 2021 12:15:54 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2112-00390.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{improvinggan,
	title        = {Improved Techniques for Training GANs},
	author       = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi and Chen, Xi},
	year         = {2016},
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = {29},
	pages        = {2234--2242},
	url          = {https://proceedings.neurips.cc/paper/2016/file/8a3363abe792db2d8761d6403605aeb7-Paper.pdf},
	editor       = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett}
}
@inproceedings{ips,
	title        = {Article title},
	author       = {A. Inproceedings},
	year         = {1991},
	month        = {May},
	booktitle    = {Proceedings {T}itle},
	publisher    = {Publisher {N}ame},
	address      = {Publisher address},
	series       = {Series name},
	volume       = {\bf 1},
	pages        = {1--3},
	note         = {Paper number 1234},
	editor       = {A. Editor and B. Editor},
	organization = {Organization {N}ame}
}
@article{iren2021aachen,
	title        = {Aachen-Heerlen annotated steel microstructure dataset},
	author       = {Iren, Deniz and Ackermann, Marc and Gorfer, Julian and Pujar, Gaurav and Wesselmecking, Sebastian and Krupp, Ulrich and Bromuri, Stefano},
	year         = {2021},
	journal      = {Scientific Data},
	publisher    = {Nature Publishing Group},
	volume       = {8},
	number       = {1},
	pages        = {1--9}
}
@inproceedings{isola2017image,
	title        = {Image-to-image translation with conditional adversarial networks},
	author       = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
	year         = {2017},
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {1125--1134}
}
@article{jang2016categorical,
	title        = {Categorical reparameterization with gumbel-softmax},
	author       = {Jang, Eric and Gu, Shixiang and Poole, Ben},
	year         = {2016},
	journal      = {arXiv preprint arXiv:1611.01144}
}
@article{JangYooKang2020,
	title        = {Generative Design by Reinforcement Learning: Enhancing the Diversity of Topology Optimization Designs},
	author       = {Jang, Seowoo and Yoo, Soyoung and Kang, Namwoo},
	year         = {2022},
	month        = {5},
	journal      = {Computer-Aided Design},
	volume       = {146},
	pages        = {103225},
	doi          = {10.1016/j.cad.2022.103225},
	issn         = {00104485},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0010448522000239}
}
@article{Janieschetal2021,
	title        = {Machine learning and deep learning},
	author       = {Janiesch, Christian and Zschech, Patrick and Heinrich, Kai},
	year         = {2021},
	month        = {9},
	journal      = {Electronic Markets},
	publisher    = {Springer Science and Business Media LLC},
	volume       = {31},
	number       = {3},
	pages        = {685--695},
	doi          = {10.1007/s12525-021-00475-2},
	issn         = {1019-6781},
	url          = {https://link.springer.com/10.1007/s12525-021-00475-2}
}
@inproceedings{jiang2017variational,
	title        = {Variational deep embedding: an unsupervised and generative approach to clustering},
	author       = {Jiang, Zhuxi and Zheng, Yin and Tan, Huachun and Tang, Bangsheng and Zhou, Hanning},
	year         = {2017},
	booktitle    = {Proceedings of the 26th International Joint Conference on Artificial Intelligence},
	pages        = {1965--1972}
}
@article{JiangChenFan2021_nano2,
	title        = {Deep neural networks for the evaluation and design of photonic devices},
	author       = {Jiang, Jiaqi and Chen, Mingkun and Fan, Jonathan A.},
	year         = {2021},
	month        = {8},
	journal      = {Nature Reviews Materials},
	volume       = {6},
	number       = {8},
	pages        = {679--700},
	doi          = {10.1038/s41578-020-00260-1},
	issn         = {2058-8437},
	url          = {https://www.nature.com/articles/s41578-020-00260-1}
}
@article{Jiangetal2020,
	title        = {Machine Learning based parameter tuning strategy for MMC based topology optimization},
	author       = {Jiang, Xinchao and Wang, Hu and Li, Yu and Mo, Kangjia},
	year         = {2020},
	month        = {11},
	journal      = {Advances in Engineering Software},
	publisher    = {Elsevier Ltd},
	volume       = {149},
	pages        = {102841},
	doi          = {10.1016/j.advengsoft.2020.102841},
	issn         = {09659978},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0965997820300363},
	keywords     = {Extra-Trees, Image classification, Machine Learning, Moving morphable component, Parameter tuning, Topology optimization}
}
@article{JiengFan2019_nano1,
	title        = {Global Optimization of Dielectric Metasurfaces Using a Physics-Driven Neural Network},
	author       = {Jiang, Jiaqi and Fan, Jonathan A.},
	year         = {2019},
	month        = {8},
	journal      = {Nano Letters},
	volume       = {19},
	number       = {8},
	pages        = {5366--5372},
	doi          = {10.1021/acs.nanolett.9b01857},
	issn         = {1530-6984},
	url          = {https://pubs.acs.org/doi/10.1021/acs.nanolett.9b01857}
}
@article{jing2022subspace,
	title        = {Subspace Diffusion Generative Models},
	author       = {Jing, Bowen and Corso, Gabriele and Berlinghieri, Renato and Jaakkola, Tommi},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2205.01490}
}
@inproceedings{johnson2017clevr,
	title        = {Clevr: A diagnostic dataset for compositional language and elementary visual reasoning},
	author       = {Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross},
	year         = {2017},
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {2901--2910}
}
@article{jolicoeur2021gotta,
	title        = {Gotta go fast when generating data with score-based models},
	author       = {Jolicoeur-Martineau, Alexia and Li, Ke and Pich{\'e}-Taillefer, R{\'e}mi and Kachman, Tal and Mitliagkas, Ioannis},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2105.14080}
}
@article{jongejan2016quick,
	title        = {The quick, draw!-ai experiment},
	author       = {Jongejan, Jonas and Rowley, Henry and Kawashima, Takashi and Kim, Jongmin and Fox-Gieg, Nick},
	year         = {2016},
	journal      = {Mount View, CA, accessed Feb},
	volume       = {17},
	number       = {2018},
	pages        = {4}
}
@article{JooYuJang2021,
	title        = {Unit Module-Based Convergence Acceleration for Topology Optimization Using the Spatiotemporal Deep Neural Network},
	author       = {Joo, Younghwan and Yu, Yonggyun and Jang, In Gwun},
	year         = {2021},
	journal      = {IEEE Access},
	volume       = {9},
	pages        = {149766--149779},
	doi          = {10.1109/ACCESS.2021.3125014},
	issn         = {2169-3536},
	url          = {https://ieeexplore.ieee.org/document/9599692/}
}
@article{jordan1999introduction,
	title        = {An introduction to variational methods for graphical models},
	author       = {Jordan, Michael I and Ghahramani, Zoubin and Jaakkola, Tommi S and Saul, Lawrence K},
	year         = {1999},
	journal      = {Machine learning},
	publisher    = {Springer},
	volume       = {37},
	number       = {2},
	pages        = {183--233}
}
@article{jumper2021highly,
	title        = {Highly accurate protein structure prediction with AlphaFold},
	author       = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
	year         = {2021},
	journal      = {Nature},
	publisher    = {Nature Publishing Group UK London},
	volume       = {596},
	number       = {7873},
	pages        = {583--589}
}
@article{jung2021super,
	title        = {Super-resolving material microstructure image via deep learning for microstructure characterization and mechanical behavior analysis},
	author       = {Jung, Jaimyun and Na, Juwon and Park, Hyung Keun and Park, Jeong Min and Kim, Gyuwon and Lee, Seungchul and Kim, Hyoung Seop},
	year         = {2021},
	journal      = {npj Computational Materials},
	publisher    = {Nature Publishing Group},
	volume       = {7},
	number       = {1},
	pages        = {1--11}
}
@article{kaelbling1996RL,
	title        = {Reinforcement Learning: A Survey},
	author       = {Kaelbling, Leslie Pack and Littman, Michael L. and Moore, Andrew W.},
	year         = {1996},
	month        = may,
	journal      = {J. Artif. Int. Res.},
	publisher    = {AI Access Foundation},
	address      = {El Segundo, CA, USA},
	volume       = {4},
	number       = {1},
	pages        = {237–285},
	issn         = {1076-9757},
	issue_date   = {Jnauary 1996},
	abstract     = {This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word "reinforcement." The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.},
	numpages     = {49}
}
@article{Kallioras2020,
	title        = {Accelerated topology optimization by means of deep learning},
	author       = {Kallioras, Nikos Ath. and Kazakis, Georgios and Lagaros, Nikos D.},
	year         = {2020},
	month        = {9},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer},
	volume       = {62},
	number       = {3},
	pages        = {1185--1212},
	doi          = {10.1007/s00158-020-02545-z},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-020-02545-z},
	keywords     = {Deep belief networks, Deep learning, Pattern recognition, Restricted Boltzmann machines, SIMP, Topology optimization}
}
@article{KalliorasLagaros2020,
	title        = {DL-SCALE: a novel deep learning-based model order upscaling scheme for solving topology optimization problems},
	author       = {Kallioras, Nikos Ath. and Lagaros, Nikos D.},
	year         = {2021},
	month        = {6},
	journal      = {Neural Computing and Applications},
	publisher    = {Springer},
	volume       = {33},
	number       = {12},
	pages        = {7125--7144},
	doi          = {10.1007/s00521-020-05480-8},
	issn         = {0941-0643},
	url          = {https://link.springer.com/10.1007/s00521-020-05480-8},
	keywords     = {Deep belief networks, Deep learning, Pattern recognition, Restricted Boltzmann machines, SIMP, Topology optimization}
}
@article{KalliorasNordasLagaros2021,
	title        = {Deep Learning-Based Accuracy Upgrade of Reduced Order Models in Topology Optimization},
	author       = {Kallioras, Nikos Ath. and Nordas, Alexandros N. and Lagaros, Nikos D.},
	year         = {2021},
	month        = {12},
	journal      = {Applied Sciences},
	volume       = {11},
	number       = {24},
	pages        = {12005},
	doi          = {10.3390/app112412005},
	issn         = {2076-3417},
	url          = {https://www.mdpi.com/2076-3417/11/24/12005}
}
@article{kalman1960new,
	title        = {A new approach to linear filtering and prediction problems},
	author       = {Kalman, Rudolph Emil},
	year         = {1960},
	journal      = {Journal of basic Engineering},
	publisher    = {American Society of Mechanical Engineers},
	volume       = {82},
	number       = {1},
	pages        = {35--45}
}
@article{karl2016deep,
	title        = {Deep variational bayes filters: Unsupervised learning of state space models from raw data},
	author       = {Karl, Maximilian and Soelch, Maximilian and Bayer, Justin and van der Smagt, Patrick},
	year         = {2016},
	journal      = {arXiv preprint arXiv:1605.06432}
}
@inproceedings{karnewar2020msg,
	title        = {Msg-gan: Multi-scale gradients for generative adversarial networks},
	author       = {Karnewar, Animesh and Wang, Oliver},
	year         = {2020},
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {7799--7808}
}
@inproceedings{karras2019style,
	title        = {A Style-Based Generator Architecture for Generative Adversarial Networks},
	author       = {Karras, Tero and Laine, Samuli and Aila, Timo},
	year         = {2019},
	booktitle    = {2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	location     = {Long Beach, CA, USA},
	volume       = {},
	number       = {},
	pages        = {4396--4405},
	doi          = {10.1109/CVPR.2019.00453}
}
@inproceedings{karras2020analyzing,
	title        = {Analyzing and Improving the Image Quality of StyleGAN},
	author       = {Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
	year         = {2020},
	booktitle    = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	location     = {Seattle, WA, USA},
	volume       = {},
	number       = {},
	pages        = {8107--8116},
	doi          = {10.1109/CVPR42600.2020.00813}
}
@article{katoch2021review,
	title        = {A review on genetic algorithm: past, present, and future},
	author       = {Katoch, Sourabh and Chauhan, Sumit Singh and Kumar, Vijay},
	year         = {2021},
	journal      = {Multimedia Tools and Applications},
	publisher    = {Springer},
	volume       = {80},
	number       = {5},
	pages        = {8091--8126}
}
@inproceedings{keldysh1951characteristic,
	title        = {On the characteristic values and characteristic functions of certain classes of non-self-adjoint equations},
	author       = {Keldysh, Mstislav Vsevolodovich},
	year         = {1951},
	booktitle    = {Dokl. Akad. Nauk SSSR},
	volume       = {77},
	number       = {1},
	pages        = {11--14}
}
@article{kench2021generating,
	title        = {Generating three-dimensional structures from a two-dimensional slice with generative adversarial network-based dimensionality expansion},
	author       = {Kench, Steve and Cooper, Samuel J},
	year         = {2021},
	journal      = {Nature Machine Intelligence},
	publisher    = {Nature Publishing Group UK London},
	volume       = {3},
	number       = {4},
	pages        = {299--305}
}
@article{KesAliTas2021,
	title        = {Image-Based Multiresolution Topology Optimization Using Deep Disjunctive Normal Shape Model},
	author       = {Keshavarzzadeh, Vahid and Alirezaei, Mitra and Tasdizen, Tolga and Kirby, Robert M.},
	year         = {2021},
	month        = {1},
	journal      = {Computer-Aided Design},
	publisher    = {Elsevier Ltd},
	volume       = {130},
	pages        = {102947},
	doi          = {10.1016/j.cad.2020.102947},
	issn         = {00104485},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0010448520301408},
	keywords     = {Deep neural networks, Image-based segmentation, Multiresolution analysis, Topology optimization}
}
@article{KesBidKel2020,
	title        = {V-Dream: Immersive Exploration of Generative Design Solution Space},
	author       = {Keshavarzi, Mohammad and Bidgoli, Ardavan and Kellner, Hans},
	year         = {2020},
	month        = {6},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/2006.11044},
	arxivid      = {2006.11044}
}
@article{KESHAVARZZADEH2021102947,
	title        = {Image-Based Multiresolution Topology Optimization Using Deep Disjunctive Normal Shape Model},
	author       = {Vahid Keshavarzzadeh and Mitra Alirezaei and Tolga Tasdizen and Robert M. Kirby},
	year         = {2021},
	journal      = {Computer-Aided Design},
	volume       = {130},
	pages        = {102947},
	doi          = {https://doi.org/10.1016/j.cad.2020.102947},
	issn         = {0010-4485},
	url          = {https://www.sciencedirect.com/science/article/pii/S0010448520301408},
	keywords     = {Topology optimization, Multiresolution analysis, Image-based segmentation, Deep neural networks},
	abstract     = {We present a machine learning framework for predicting the optimized structural topology designs using multiresolution data. Our approach primarily uses optimized designs from inexpensive coarse mesh finite element simulations for model training and generates high resolution images associated with simulation parameters that are not previously used. Our cost-efficient approach enables the designers to effectively search through possible candidate designs in situations where the design requirements rapidly change. The underlying neural network framework is based on a deep disjunctive normal shape model (DDNSM) which learns the mapping between the simulation parameters and segments of multi resolution images. Using this image-based analysis we provide a practical algorithm which enhances the predictability of the learning machine by determining a limited number of important parametric samples (i.e. samples of the simulation parameters) on which the high resolution training data is generated. We demonstrate our approach on benchmark compliance minimization problems including the 3D topology optimization where we show that the high-fidelity designs from the learning machine are close to optimal designs and can be used as effective initial guesses for the large-scale optimization problem.}
}
@article{KesKirNara2021,
	title        = {Robust topology optimization with low rank approximation using artificial neural networks},
	author       = {Keshavarzzadeh, Vahid and Kirby, Robert M. and Narayan, Akil},
	year         = {2021},
	month        = {12},
	journal      = {Computational Mechanics},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	volume       = {68},
	number       = {6},
	pages        = {1297--1323},
	doi          = {10.1007/s00466-021-02069-3},
	issn         = {0178-7675},
	url          = {https://link.springer.com/10.1007/s00466-021-02069-3},
	keywords     = {Artificial neural networks, Design under uncertainty, Low rank approximation, Robust topology optimization}
}
@article{khemakhem2019variational,
	title        = {Variational autoencoders and nonlinear ica: A unifying framework},
	author       = {Khemakhem, Ilyes and Kingma, Diederik P and Hyv{\"a}rinen, Aapo},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1907.04809}
}
% factorisation_____________________________________________________________________________
@article{kim2011independently,
	title        = {Independently controllable dual-band bandpass filters using asymmetric stepped-impedance resonators},
	author       = {Kim, Chan Ho and Chang, Kai},
	year         = {2011},
	journal      = {IEEE Transactions on Microwave Theory and Techniques},
	publisher    = {IEEE},
	volume       = {59},
	number       = {12},
	pages        = {3037--3047}
}
% disentanglement______________________________________________
@article{kim2018disentangling,
	title        = {Disentangling by factorising},
	author       = {Kim, Hyunjik and Mnih, Andriy},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1802.05983}
}
@article{kim2019attentive,
	title        = {Attentive neural processes},
	author       = {Kim, Hyunjik and Mnih, Andriy and Schwarz, Jonathan and Garnelo, Marta and Eslami, Ali and Rosenbaum, Dan and Vinyals, Oriol and Teh, Yee Whye},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1901.05761}
}
@article{KIM2021102932,
	title        = {Object Synthesis by Learning Part Geometry with Surface and Volumetric Representations},
	author       = {Sangpil Kim and Hyung-gun Chi and Karthik Ramani},
	year         = {2021},
	journal      = {Computer-Aided Design},
	volume       = {130},
	pages        = {102932},
	doi          = {https://doi.org/10.1016/j.cad.2020.102932},
	issn         = {0010-4485},
	url          = {https://www.sciencedirect.com/science/article/pii/S0010448520301251},
	keywords     = {Deep learning, Conditional generative model, Multi-task learning, Object synthesis},
	abstract     = {We propose a conditional generative model, named Part Geometry Network (PG-Net), which synthesizes realistic objects and can be used as a robust feature descriptor for object reconstruction and classification. Surface and volumetric representations of objects have complementary properties of three-dimensional objects. Combining these modalities is more informative than using one modality alone. Therefore, PG-Net utilizes complementary properties of surface and volumetric representations by estimating curvature, surface area, and occupancy in voxel grids of objects with a single decoder as a multi-task learning. Objects are combinations of multiple parts, and therefore part geometry (PG) is essential to synthesize each part of the objects. PG-Net employs a part identifier to learn the part geometry. Additionally, we augmented a dataset by interpolating individual functional parts such as wings of an airplane, which helps learning part geometry and finding local/global minima of PG-Net. To demonstrate the capability of learning object representations of PG-Net, we performed object reconstruction and classification tasks on two standard large-scale datasets. PG-Net outperformed the state-of-the-art methods in object synthesis, classification, and reconstruction in a large margin.}
}
@article{kim2021diffusionclip,
	title        = {Diffusionclip: Text-guided image manipulation using diffusion models},
	author       = {Kim, Gwanghyun and Ye, Jong Chul},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2110.02711}
}
@inproceedings{kim2021setvae,
	title        = {SetVAE: Learning Hierarchical Composition for Generative Modeling of Set-Structured Data},
	author       = {Kim, Jinwoo and Yoo, Jaehoon and Lee, Juho and Hong, Seunghoon},
	year         = {2021},
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {15059--15068}
}
@article{KimLeeYoo2021,
	title        = {Machine learning-combined topology optimization for functionary graded composite structure design},
	author       = {Kim, Cheolwoong and Lee, Jaewook and Yoo, Jeonghoon},
	year         = {2021},
	month        = {12},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	volume       = {387},
	pages        = {114158},
	doi          = {10.1016/j.cma.2021.114158},
	issn         = {00457825},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0045782521004898}
}
@article{KimYang2021,
	title        = {Deep learning framework for material design space exploration using active transfer learning and data augmentation},
	author       = {Kim, Yongtae and Kim, Youngsoo and Yang, Charles and Park, Kundo and Gu, Grace X. and Ryu, Seunghwa},
	year         = {2021},
	month        = {12},
	journal      = {npj Computational Materials},
	volume       = {7},
	number       = {1},
	pages        = {140},
	doi          = {10.1038/s41524-021-00609-2},
	issn         = {2057-3960},
	url          = {https://www.nature.com/articles/s41524-021-00609-2}
}
% VAE
@article{kingma2013auto,
	title        = {Auto-encoding variational bayes},
	author       = {Kingma, Diederik P and Welling, Max},
	year         = {2013},
	journal      = {arXiv preprint arXiv:1312.6114}
}
@inproceedings{kingma2014,
	title        = {Auto-Encoding Variational Bayes},
	author       = {Diederik P. Kingma and Max Welling},
	year         = {2014},
	booktitle    = {2nd International Conference on Learning Representations}
}
@article{kingma2014adam,
	title        = {Adam: A method for stochastic optimization},
	author       = {Kingma, Diederik P and Ba, Jimmy},
	year         = {2014},
	journal      = {arXiv preprint arXiv:1412.6980}
}
@inproceedings{kingma2014semi,
	title        = {Semi-supervised learning with deep generative models},
	author       = {Kingma, Durk P and Mohamed, Shakir and Rezende, Danilo Jimenez and Welling, Max},
	year         = {2014},
	booktitle    = {Advances in neural information processing systems},
	pages        = {3581--3589}
}
@inproceedings{kingma2016improved,
	title        = {Improved variational inference with inverse autoregressive flow},
	author       = {Kingma, Durk P and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
	year         = {2016},
	booktitle    = {Advances in neural information processing systems},
	pages        = {4743--4751}
}
@article{Kingma2018,
	title        = {Glow: Generative Flow with Invertible 1x1 Convolutions},
	author       = {Kingma, Diederik P. and Dhariwal, Prafulla},
	year         = {2018},
	month        = {7},
	arxivid      = {1807.03039}
}
@article{kingma2019introduction,
	title        = {An introduction to variational autoencoders},
	author       = {Kingma, Diederik P and Welling, Max},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1906.02691}
}
@article{kingma2021density,
	title        = {On Density Estimation with Diffusion Models},
	author       = {Kingma, Diederik and Salimans, Tim and Poole, Ben and Ho, Jonathan},
	year         = {2021},
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {34}
}
@article{kingma2021variational,
	title        = {Variational diffusion models},
	author       = {Kingma, Diederik P and Salimans, Tim and Poole, Ben and Ho, Jonathan},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2107.00630}
}
@article{kipf2018compositional,
	title        = {Compositional Imitation Learning: Explaining and executing one task at a time},
	author       = {Kipf, Thomas and Li, Yujia and Dai, Hanjun and Zambaldi, Vinicius and Grefenstette, Edward and Kohli, Pushmeet and Battaglia, Peter},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1812.01483}
}
@inproceedings{klapper2001unsupervised,
	title        = {Unsupervised learning in LSTM recurrent neural networks},
	author       = {Klapper-Rybicka, Magdalena and Schraudolph, Nicol N and Schmidhuber, J{\"u}rgen},
	year         = {2001},
	booktitle    = {International Conference on Artificial Neural Networks},
	pages        = {684--691},
	organization = {Springer}
}
@book{klein,
	title        = {Vergleichende Betrachtungen über neuere geometrische Forschungen},
	author       = {Klein, Felix},
	year         = {1872},
	publisher    = {Erlangen}
}
@book{klein2016elementary,
	title        = {Elementary mathematics from a higher standpoint},
	author       = {Klein, Felix},
	year         = {2016},
	publisher    = {Springer}
}
@article{Kobyzev2021,
	title        = {Normalizing Flows: An Introduction and Review of Current Methods},
	author       = {Kobyzev, Ivan and Prince, Simon J.D. and Brubaker, Marcus A.},
	year         = {2021},
	month        = {11},
	journal      = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	volume       = {43},
	number       = {11},
	pages        = {3964--3979},
	doi          = {10.1109/TPAMI.2020.2992934},
	issn         = {0162-8828}
}
@article{koga2013development,
	title        = {Development of heat sink device by using topology optimization},
	author       = {Koga, Adriano A and Lopes, Edson Comini C and Nova, Helcio F Villa and De Lima, C{\'\i}cero R and Silva, Em{\'\i}lio Carlos Nelli},
	year         = {2013},
	journal      = {International Journal of Heat and Mass Transfer},
	publisher    = {Elsevier},
	volume       = {64},
	pages        = {759--772}
}
@article{Kollmannetal2020,
	title        = {Deep learning for topology optimization of 2D metamaterials},
	author       = {Kollmann, Hunter T. and Abueidda, Diab W. and Koric, Seid and Guleryuz, Erman and Sobh, Nahil A.},
	year         = {2020},
	month        = {11},
	journal      = {Materials {\&} Design},
	volume       = {196},
	pages        = {109098},
	doi          = {10.1016/j.matdes.2020.109098},
	issn         = {02641275},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S026412752030633X}
}
@book{kondor2008group,
	title        = {Group theoretical methods in machine learning},
	author       = {Kondor, Imre Risi},
	year         = {2008},
	publisher    = {Columbia University},
	volume       = {2}
}
@article{kong2020diffwave,
	title        = {Diffwave: A versatile diffusion model for audio synthesis},
	author       = {Kong, Zhifeng and Ping, Wei and Huang, Jiaji and Zhao, Kexin and Catanzaro, Bryan},
	year         = {2020},
	journal      = {arXiv preprint arXiv:2009.09761}
}
@article{kong2021fast,
	title        = {On fast sampling of diffusion probabilistic models},
	author       = {Kong, Zhifeng and Ping, Wei},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2106.00132}
}
@article{korshunova2018bruno,
	title        = {Bruno: A deep recurrent model for exchangeable data},
	author       = {Korshunova, Iryna and Degrave, Jonas and Husz{\'a}r, Ferenc and Gal, Yarin and Gretton, Arthur and Dambre, Joni},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1802.07535}
}
@article{kosiorek2019stacked,
	title        = {Stacked Capsule Autoencoders},
	author       = {Kosiorek, Adam R and Sabour, Sara and Teh, Yee Whye and Hinton, Geoffrey E},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1906.06818}
}
@techreport{Kothlow2021,
	title        = {Siemens blogs: 4 Myths about AI in CFD},
	author       = {Kothlow, Christina},
	year         = {2021},
	url          = {https://blogs.sw.siemens.com/simcenter/4-myths-about-ai-in-cfd/}
}
@book{kowalski2014introduction,
	title        = {An introduction to the representation theory of groups},
	author       = {Kowalski, Emmanuel},
	year         = {2014},
	publisher    = {American Mathematical Society},
	volume       = {155}
}
@article{krizhevsky2010convolutional,
	title        = {Convolutional deep belief networks on cifar-10},
	author       = {Krizhevsky, Alex and Hinton, Geoff},
	year         = {2010},
	journal      = {Unpublished manuscript},
	volume       = {40},
	number       = {7}
}
@inproceedings{krizhevsky2012imagenet,
	title        = {Imagenet classification with deep convolutional neural networks},
	author       = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	year         = {2012},
	booktitle    = {Advances in neural information processing systems},
	pages        = {1097--1105}
}
@article{Krizhevskyetal2017,
	title        = {ImageNet classification with deep convolutional neural networks},
	author       = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	year         = {2017},
	month        = {5},
	journal      = {Communications of the ACM},
	volume       = {60},
	number       = {6},
	pages        = {84--90},
	doi          = {10.1145/3065386},
	issn         = {0001-0782},
	url          = {https://dl.acm.org/doi/10.1145/3065386}
}
@inproceedings{kuleshov2017neural,
	title        = {Neural variational inference and learning in undirected graphical models},
	author       = {Kuleshov, Volodymyr and Ermon, Stefano},
	year         = {2017},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {6734--6743}
}
@article{kulesza2012determinantal,
	title        = {Determinantal Point Processes for Machine Learning},
	author       = {Kulesza, Alex and Taskar, Ben and others},
	year         = {2012},
	journal      = {Foundations and Trends{\textregistered} in Machine Learning},
	publisher    = {Now Publishers, Inc.},
	volume       = {5},
	number       = {2--3},
	pages        = {123--286}
}
@article{kulkarni2019unsupervised,
	title        = {Unsupervised Learning of Object Keypoints for Perception and Control},
	author       = {Kulkarni, Tejas and Gupta, Ankush and Ionescu, Catalin and Borgeaud, Sebastian and Reynolds, Malcolm and Zisserman, Andrew and Mnih, Volodymyr},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1906.11883}
}
@article{kullback1951information,
	title        = {On information and sufficiency},
	author       = {Kullback, Solomon and Leibler, Richard A},
	year         = {1951},
	journal      = {The annals of mathematical statistics},
	publisher    = {JSTOR},
	volume       = {22},
	number       = {1},
	pages        = {79--86}
}
@article{kumar2017variational,
	title        = {Variational inference of disentangled latent concepts from unlabeled observations},
	author       = {Kumar, Abhishek and Sattigeri, Prasanna and Balakrishnan, Avinash},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1711.00848}
}
@article{kumar2018consistent,
	title        = {Consistent Jumpy Predictions for Videos and Scenes},
	author       = {Kumar, Ananya and Eslami, SM Ali and Rezende, Danilo and Garnelo, Marta and Viola, Fabio and Lockhart, Edward and Shanahan, Murray},
	year         = {2018}
}
@article{Kurakinetal2016,
	title        = {Adversarial Machine Learning at Scale},
	author       = {Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
	year         = {2016},
	month        = {11},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/1611.01236},
	arxivid      = {1611.01236}
}
@article{kynkaanniemi2019improved,
	title        = {Improved precision and recall metric for assessing generative models},
	author       = {Kynk{\"a}{\"a}nniemi, Tuomas and Karras, Tero and Laine, Samuli and Lehtinen, Jaakko and Aila, Timo},
	year         = {2019},
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {32}
}
@inproceedings{lake2011one,
	title        = {One shot learning of simple visual concepts},
	author       = {Lake, Brenden and Salakhutdinov, Ruslan and Gross, Jason and Tenenbaum, Joshua},
	year         = {2011},
	booktitle    = {Proceedings of the annual meeting of the cognitive science society},
	volume       = {33},
	number       = {33}
}
@article{lake2015human,
	title        = {Human-level concept learning through probabilistic program induction},
	author       = {Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B},
	year         = {2015},
	journal      = {Science},
	publisher    = {American Association for the Advancement of Science},
	volume       = {350},
	number       = {6266},
	pages        = {1332--1338}
}
@article{lake2017building,
	title        = {Building machines that learn and think like people},
	author       = {Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and Gershman, Samuel J},
	year         = {2017},
	journal      = {Behavioral and brain sciences},
	publisher    = {Cambridge University Press},
	volume       = {40}
}
@inproceedings{lakshminarayanan2017simple,
	title        = {Simple and scalable predictive uncertainty estimation using deep ensembles},
	author       = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
	year         = {2017},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {6402--6413}
}
@article{langelaar2016topology,
	title        = {Topology optimization of 3D self-supporting structures for additive manufacturing},
	author       = {Langelaar, Matthijs},
	year         = {2016},
	journal      = {Additive Manufacturing},
	publisher    = {Elsevier},
	volume       = {12},
	pages        = {60--70}
}
@article{Langelaar2017,
	title        = {An additive manufacturing filter for topology optimization of print-ready designs},
	author       = {Langelaar, Matthijs},
	year         = {2017},
	month        = {3},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {55},
	number       = {3},
	pages        = {871--883},
	doi          = {10.1007/s00158-016-1522-2},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-016-1522-2}
}
@article{larmuseau2020compact,
	title        = {Compact representations of microstructure images using triplet networks},
	author       = {Larmuseau, Michiel and Sluydts, Michael and Theuwissen, Koenraad and Duprez, Lode and Dhaene, Tom and Cottenier, Stefaan},
	year         = {2020},
	journal      = {npj Computational Materials},
	publisher    = {Nature Publishing Group},
	volume       = {6},
	number       = {1},
	pages        = {1--11}
}
@inproceedings{larsen2016autoencoding,
	title        = {Autoencoding beyond pixels using a learned similarity metric},
	author       = {Larsen, Anders Boesen Lindbo and S{\o}nderby, S{\o}ren Kaae and Larochelle, Hugo and Winther, Ole},
	year         = {2016},
	booktitle    = {International conference on machine learning},
	pages        = {1558--1566},
	organization = {PMLR}
}
@book{latex,
	title        = {\LaTeX: a Document Preparation System},
	author       = {L. Lamport},
	year         = {1986},
	publisher    = {Addison-Wesley},
	address      = {Reading, MA}
}
@article{LazarovSigmund2016,
	title        = {Length scale and manufacturability in density-based topology optimization},
	author       = {Lazarov, Boyan S. and Wang, Fengwen and Sigmund, Ole},
	year         = {2016},
	month        = {1},
	journal      = {Archive of Applied Mechanics},
	volume       = {86},
	number       = {1-2},
	pages        = {189--218},
	doi          = {10.1007/s00419-015-1106-4},
	issn         = {0939-1533},
	url          = {http://link.springer.com/10.1007/s00419-015-1106-4}
}
@article{LazarovWang2017,
	title        = {Maximum length scale in density based topology optimization},
	author       = {Lazarov, Boyan S. and Wang, Fengwen},
	year         = {2017},
	month        = {5},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	publisher    = {Elsevier B.V.},
	volume       = {318},
	pages        = {826--844},
	doi          = {10.1016/j.cma.2017.02.018},
	issn         = {00457825},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0045782516302699},
	keywords     = {Length scale, Manufacturability, Robust design, Topology optimization}
}
%______________________________________________________________________
% datasets
@article{lecun1998mnist,
	title        = {The MNIST database of handwritten digits},
	author       = {LeCun, Yann},
	year         = {1998},
	journal      = {http://yann. lecun. com/exdb/mnist/}
}
@inproceedings{ledig2017photo,
	title        = {Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network},
	author       = {Ledig, Christian and Theis, Lucas and Husz{\'a}r, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and others},
	year         = {2017},
	booktitle    = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages        = {105--114},
	organization = {IEEE}
}
@article{Lee_etal2020,
	title        = {CNN-based image recognition for topology optimization},
	author       = {Lee, Seunghye and Kim, Hyunjoo and Lieu, Qui X. and Lee, Jaehong},
	year         = {2020},
	month        = {6},
	journal      = {Knowledge-Based Systems},
	publisher    = {Elsevier B.V.},
	volume       = {198},
	pages        = {105887},
	doi          = {10.1016/j.knosys.2020.105887},
	issn         = {09507051},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0950705120302379},
	keywords     = {Compliance, Convolutional neural network, GPU computing, Topology analysis, Topology image recognition}
}
@article{LEE1996831,
	title        = {Geometric reasoning for knowledge-based parametric design using graph representation},
	author       = {Jae Yeol Lee and Kwangsoo Kim},
	year         = {1996},
	journal      = {Computer-Aided Design},
	volume       = {28},
	number       = {10},
	pages        = {831--841},
	doi          = {https://doi.org/10.1016/0010-4485(96)00016-4},
	issn         = {0010-4485},
	url          = {https://www.sciencedirect.com/science/article/pii/0010448596000164},
	keywords     = {parametric design, geometric reasoning, constraint graph, geometric constraints},
	abstract     = {A promising approach to parametric design is based on the knowledge-based technique. However, one of the major drawbacks in this approach is that the inference process is computationally expensive to be applied to the interactive and intelligent cad systems. This paper presents a new approach to geometric reasoning for knowledge-based parametric design using graph representation to improve the inference process. The geometric reasoning procedure consists of three steps: (1) representing a well-constrained design model and geometric rules into graphs; (2) selecting appropriate subgraphs from the design graph which may be used to induce new facts; and (3) selectively searching for the rule graphs having the same keys as the model subgraphs. The proposed approach is simple in concept, yet realizes significant inference time reduction. The concept presented here has been implemented on an IRIS Indigo workstation, and some implementation results are given to show the efficiency of the proposed approach.}
}
@inproceedings{lee2009convolutional,
	title        = {Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations},
	author       = {Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew Y},
	year         = {2009},
	booktitle    = {Proceedings of the 26th annual international conference on machine learning},
	pages        = {609--616}
}
@article{lee2019case,
	title        = {A case study of deep reinforcement learning for engineering design: Application to microfluidic devices for flow sculpting},
	author       = {Lee, Xian Yeow and Balu, Aditya and Stoecklein, Daniel and Ganapathysubramanian, Baskar and Sarkar, Soumik},
	year         = {2019},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers},
	volume       = {141},
	number       = {11},
	pages        = {111401}
}
@inproceedings{lee2019set,
	title        = {Set transformer: A framework for attention-based permutation-invariant neural networks},
	author       = {Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
	year         = {2019},
	booktitle    = {International Conference on Machine Learning},
	pages        = {3744--3753},
	organization = {PMLR}
}
@article{lee2021priorgrad,
	title        = {Priorgrad: Improving conditional denoising diffusion models with data-driven adaptive prior},
	author       = {Lee, Sang-gil and Kim, Heeseung and Shin, Chaehun and Tan, Xu and Liu, Chang and Meng, Qi and Qin, Tao and Chen, Wei and Yoon, Sungroh and Liu, Tie-Yan},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2106.06406}
}
@article{lee2021virtual,
	title        = {Virtual microstructure design for steels using generative adversarial networks},
	author       = {Lee, Jin-Woong and Goo, Nam Hoon and Park, Woon Bae and Pyo, Myungho and Sohn, Kee-Sun},
	year         = {2021},
	journal      = {Engineering Reports},
	publisher    = {Wiley Online Library},
	volume       = {3},
	number       = {1},
	pages        = {e12274}
}
@article{lee2021vision,
	title        = {Vision Transformer for Small-Size Datasets},
	author       = {Lee, Seung Hoon and Lee, Seunghyun and Song, Byung Cheol},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2112.13492}
}
@article{LeeGeMa2017,
	title        = {On the ability of neural nets to express distributions},
	author       = {Lee, Holden and Ge, Rong and Ma, Tengyu and Risteski, Andrej and Arora, Sanjeev},
	year         = {2017},
	month        = {2},
	arxivid      = {1702.07028}
}
@article{Leietal2019,
	title        = {Machine Learning-Driven Real-Time Topology Optimization Under Moving Morphable Component-Based Framework},
	author       = {Lei, Xin and Liu, Chang and Du, Zongliang and Zhang, Weisheng and Guo, Xu},
	year         = {2019},
	month        = {1},
	journal      = {Journal of Applied Mechanics},
	publisher    = {American Society of Mechanical Engineers (ASME)},
	volume       = {86},
	number       = {1},
	doi          = {10.1115/1.4041319},
	issn         = {0021-8936},
	url          = {https://asmedigitalcollection.asme.org/appliedmechanics/article/doi/10.1115/1.4041319/423490/Machine-LearningDriven-RealTime-Topology},
	keywords     = {machine learning, moving morphable component (MMC), real-time optimization, topology optimization}
}
@inproceedings{lenssen2018group,
	title        = {Group equivariant capsule networks},
	author       = {Lenssen, Jan Eric and Fey, Matthias and Libuschewski, Pascal},
	year         = {2018},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {8844--8853}
}
@article{lesort2018state,
	title        = {State representation learning for control: An overview},
	author       = {Lesort, Timoth{\'e}e and D{\'\i}az-Rodr{\'\i}guez, Natalia and Goudou, Jean-Franois and Filliat, David},
	year         = {2018},
	journal      = {Neural Networks},
	publisher    = {Elsevier}
}
@article{li2006one,
	title        = {One-shot learning of object categories},
	author       = {Li, Fei-Fei and Fergus, Rob and Perona, Pietro},
	year         = {2006},
	journal      = {IEEE transactions on pattern analysis and machine intelligence},
	publisher    = {IEEE},
	volume       = {28},
	number       = {4},
	pages        = {594--611}
}
@inproceedings{li2015generative,
	title        = {Generative moment matching networks},
	author       = {Li, Yujia and Swersky, Kevin and Zemel, Rich},
	year         = {2015},
	booktitle    = {International Conference on Machine Learning},
	pages        = {1718--1727}
}
@misc{li2017gated,
	title        = {Gated Graph Sequence Neural Networks},
	author       = {Yujia Li and Daniel Tarlow and Marc Brockschmidt and Richard Zemel},
	year         = {2017},
	eprint       = {1511.05493},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@article{li2017grass,
	title        = {Grass: Generative recursive autoencoders for shape structures},
	author       = {Li, Jun and Xu, Kai and Chaudhuri, Siddhartha and Yumer, Ersin and Zhang, Hao and Guibas, Leonidas},
	year         = {2017},
	journal      = {ACM Transactions on Graphics (TOG)},
	publisher    = {ACM New York, NY, USA},
	volume       = {36},
	number       = {4},
	pages        = {1--14}
}
@article{li2017meta,
	title        = {Meta-sgd: Learning to learn quickly for few-shot learning},
	author       = {Li, Zhenguo and Zhou, Fengwei and Chen, Fei and Li, Hang},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1707.09835}
}
@misc{li2018learning,
	title        = {Learning Deep Generative Models of Graphs},
	author       = {Yujia Li and Oriol Vinyals and Chris Dyer and Razvan Pascanu and Peter Battaglia},
	year         = {2018},
	eprint       = {1803.03324},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@article{li2018transfer,
	title        = {A transfer learning approach for microstructure reconstruction and structure-property predictions},
	author       = {Li, Xiaolin and Zhang, Yichi and Zhao, He and Burkhart, Craig and Brinson, L Catherine and Chen, Wei},
	year         = {2018},
	journal      = {Scientific reports},
	publisher    = {Nature Publishing Group},
	volume       = {8},
	number       = {1},
	pages        = {1--13}
}
@article{Li2019,
	title        = {Non-iterative structural topology optimization using deep learning},
	author       = {Baotong Li and Congjia Huang and Xin Li and Shuai Zheng and Jun Hong},
	year         = {2019},
	journal      = {Computer-Aided Design},
	volume       = {115},
	pages        = {172--180},
	doi          = {https://doi.org/10.1016/j.cad.2019.05.038},
	issn         = {0010-4485},
	url          = {https://www.sciencedirect.com/science/article/pii/S001044851930185X},
	keywords     = {Topology optimization, Deep learning, Generative adversarial network, Hierarchical refinement, Heat conduction},
	abstract     = {This paper presents a non-iterative topology optimizer for conductive heat transfer structures with the help of deep learning. An artificial neural network is trained to deal with the black-and-white pixel images and generate near-optimal structures. Our design is a two-stage hierarchical prediction–refinement pipeline consisting of two coupled neural networks: a generative adversarial network (GAN) for predicting a low resolution near-optimal structure and a super-resolution generative adversarial network (SRGAN) for predicting the refined structure in high resolution. Training datasets with given boundary conditions and the optimized pixel image structures are obtained after simulating a big amount of topology optimization procedures. For more effective training and inference, these datasets are generated with two different resolutions. Experiments demonstrated that our learning based optimizer can provide accurate estimation of the conductive heat transfer topology using negligible computational time. This effective incorporation of deep learning into topology optimization could enable promising applications in large-scale engineering structure design.}
}
@article{LI2019172,
	title        = {Non-iterative structural topology optimization using deep learning},
	author       = {Baotong Li and Congjia Huang and Xin Li and Shuai Zheng and Jun Hong},
	year         = {2019},
	journal      = {Computer-Aided Design},
	volume       = {115},
	pages        = {172--180},
	doi          = {https://doi.org/10.1016/j.cad.2019.05.038},
	issn         = {0010-4485},
	url          = {https://www.sciencedirect.com/science/article/pii/S001044851930185X},
	keywords     = {Topology optimization, Deep learning, Generative adversarial network, Hierarchical refinement, Heat conduction},
	abstract     = {This paper presents a non-iterative topology optimizer for conductive heat transfer structures with the help of deep learning. An artificial neural network is trained to deal with the black-and-white pixel images and generate near-optimal structures. Our design is a two-stage hierarchical prediction–refinement pipeline consisting of two coupled neural networks: a generative adversarial network (GAN) for predicting a low resolution near-optimal structure and a super-resolution generative adversarial network (SRGAN) for predicting the refined structure in high resolution. Training datasets with given boundary conditions and the optimized pixel image structures are obtained after simulating a big amount of topology optimization procedures. For more effective training and inference, these datasets are generated with two different resolutions. Experiments demonstrated that our learning based optimizer can provide accurate estimation of the conductive heat transfer topology using negligible computational time. This effective incorporation of deep learning into topology optimization could enable promising applications in large-scale engineering structure design.}
}
@article{li2020designing,
	title        = {Designing phononic crystal with anticipated band gap through a deep learning based data-driven method},
	author       = {Li, Xiang and Ning, Shaowu and Liu, Zhanli and Yan, Ziming and Luo, Chengcheng and Zhuang, Zhuo},
	year         = {2020},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	publisher    = {Elsevier},
	volume       = {361},
	pages        = {112737}
}
@article{li2021learning,
	title        = {Learning the aerodynamic design of supercritical airfoils through deep reinforcement learning},
	author       = {Li, Runze and Zhang, Yufei and Chen, Haixin},
	year         = {2021},
	journal      = {AIAA Journal},
	publisher    = {American Institute of Aeronautics and Astronautics},
	pages        = {1--14}
}
@article{LiBetal2019,
	title        = {Non-iterative structural topology optimization using deep learning},
	author       = {Li, Baotong and Huang, Congjia and Li, Xin and Zheng, Shuai and Hong, Jun},
	year         = {2019},
	month        = {10},
	journal      = {Computer-Aided Design},
	volume       = {115},
	pages        = {172--180},
	doi          = {10.1016/j.cad.2019.05.038},
	issn         = {00104485},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S001044851930185X},
	keywords     = {Deep learning, Generative adversarial network, Heat conduction, Hierarchical refinement, Topology optimization}
}
@book{lie1871over,
	title        = {Over en classe geometriske transformationer},
	author       = {Lie, Marius Sophus},
	year         = {1871}
}
@article{LiKirbyZhe2020,
	title        = {Deep Multi-Fidelity Active Learning of High-dimensional Outputs},
	author       = {Li, Shibo and Kirby, Robert M. and Zhe, Shandian},
	year         = {2020},
	month        = {12},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/2012.00901},
	arxivid      = {2012.00901}
}
@article{Lin2018,
	title        = {Investigation into the topology optimization for conductive heat transfer based on deep learning approach},
	author       = {Qiyin Lin and Jun Hong and Zheng Liu and Baotong Li and Jihong Wang},
	year         = {2018},
	journal      = {International Communications in Heat and Mass Transfer},
	volume       = {97},
	pages        = {103--109},
	doi          = {https://doi.org/10.1016/j.icheatmasstransfer.2018.07.001},
	issn         = {0735-1933},
	url          = {https://www.sciencedirect.com/science/article/pii/S0735193318301593},
	keywords     = {Conductive heat transfer, Deep learning, Topology optimization, SIMP},
	abstract     = {A deep learning approach combining with the traditional solid isotropic material with penalization (SIMP) method is presented in this paper to accelerate the topology optimization of the conductive heat transfer. This deep learning predictor is structured based on the deep fully convolutional neural network. The validity and accuracy of this deep learning approach is investigated based on the typical ‘Volume-Point’ heat conduction problems. The time consumption of the optimization process will be reduced significantly by introducing the deep learning approach.}
}
@article{Linetal2018,
	title        = {Investigation into the topology optimization for conductive heat transfer based on deep learning approach},
	author       = {Lin, Qiyin and Hong, Jun and Liu, Zheng and Li, Baotong and Wang, Jihong},
	year         = {2018},
	month        = {10},
	journal      = {International Communications in Heat and Mass Transfer},
	publisher    = {Elsevier Ltd},
	volume       = {97},
	pages        = {103--109},
	doi          = {10.1016/j.icheatmasstransfer.2018.07.001},
	issn         = {07351933},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0735193318301593},
	keywords     = {Conductive heat transfer, Deep learning, SIMP, Topology optimization}
}
@article{LinLin2005,
	title        = {Artificial neural network based hole image interpretation techniques for integrated topology and shape optimization},
	author       = {Lin, Chyi-Yeu and Lin, Shin-Hong},
	year         = {2005},
	month        = {9},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	volume       = {194},
	number       = {36-38},
	pages        = {3817--3837},
	doi          = {10.1016/j.cma.2004.09.005},
	issn         = {00457825},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0045782504004657},
	keywords     = {Artificial neural networks, Configuration design, Hole image interpretation, Shape optimization, Shape templates, Topology optimization}
}
@book{linsen2001point,
	title        = {Point cloud representation},
	author       = {Linsen, Lars},
	year         = {2001},
	publisher    = {Univ., Fak. f{\"u}r Informatik, Bibliothek Technical Report, Faculty of Computer~…}
}
@article{LiShietal2021,
	title        = {Generative adversarial network guided topology optimization of periodic structures via Subset Simulation},
	author       = {Li, Min and Jia, Gaofeng and Cheng, Zhibao and Shi, Zhifei},
	year         = {2021},
	month        = {3},
	journal      = {Composite Structures},
	publisher    = {Elsevier Ltd},
	volume       = {260},
	pages        = {113254},
	doi          = {10.1016/j.compstruct.2020.113254},
	issn         = {02638223},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0263822320331809},
	keywords     = {Frequency bandgap, Generative adversarial network, Machine learning, Periodic structures, Subset Simulation, Topology optimization}
}
@article{liu2014efficient,
	title        = {An efficient 3D topology optimization code written in Matlab},
	author       = {Liu, Kai and Tovar, Andr{\'e}s},
	year         = {2014},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer},
	volume       = {50},
	pages        = {1175--1196}
}
@inproceedings{liu2015deep,
	title        = {Deep learning face attributes in the wild},
	author       = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
	year         = {2015},
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision},
	pages        = {3730--3738}
}
@inproceedings{liu2015faceattributes,
	title        = {Deep Learning Face Attributes in the Wild},
	author       = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
	year         = {2015},
	month        = {December},
	booktitle    = {Proceedings of International Conference on Computer Vision (ICCV)}
}
@article{liu2018large,
	title        = {Large-scale celebfaces attributes (celeba) dataset},
	author       = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
	year         = {2018},
	journal      = {Retrieved August},
	volume       = {15},
	number       = {2018},
	pages        = {11}
}
@inproceedings{liu2018learning,
	title        = {Learning a hierarchical latent-variable model of 3d shapes},
	author       = {Liu, Shikun and Giles, Lee and Ororbia, Alexander},
	year         = {2018},
	booktitle    = {2018 International Conference on 3D Vision (3DV)},
	pages        = {542--551},
	organization = {IEEE}
}
@article{liu2019case,
	title        = {A case study on homogeneous and heterogeneous reservoir porous media reconstruction by using generative adversarial networks},
	author       = {Liu, Siyan and Zhong, Zhi and Takbiri-Borujeni, Ali and Kazemi, Mohammad and Fu, Qinwen and Yang, Yuhao},
	year         = {2019},
	journal      = {Energy Procedia},
	publisher    = {Elsevier},
	volume       = {158},
	pages        = {6164--6169}
}
@article{liu2020hybrid,
	title        = {A hybrid strategy for the discovery and design of photonic structures},
	author       = {Liu, Zhaocheng and Raju, Lakshmi and Zhu, Dayu and Cai, Wenshan},
	year         = {2020},
	journal      = {IEEE Journal on Emerging and Selected Topics in Circuits and Systems},
	publisher    = {IEEE},
	volume       = {10},
	number       = {1},
	pages        = {126--135}
}
@article{liu2021efficient,
	title        = {Efficient Training of Visual Transformers with Small Datasets},
	author       = {Liu, Yahui and Sangineto, Enver and Bi, Wei and Sebe, Nicu and Lepri, Bruno and Nadai, Marco},
	year         = {2021},
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {34}
}
@inproceedings{liu2021swin,
	title        = {Swin transformer: Hierarchical vision transformer using shifted windows},
	author       = {Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
	year         = {2021},
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {10012--10022}
}
@inproceedings{LiWuChrysathouetal2011,
	title        = {GlobFit},
	author       = {Li, Yangyan and Wu, Xiaokun and Chrysathou, Yiorgos and Sharf, Andrei and Cohen-Or, Daniel and Mitra, Niloy J.},
	year         = {2011},
	booktitle    = {ACM SIGGRAPH 2011 papers on - SIGGRAPH '11},
	publisher    = {ACM Press},
	address      = {New York, New York, USA},
	pages        = {1},
	doi          = {10.1145/1964921.1964947},
	isbn         = {9781450309431}
}
@article{LiWuetal2011,
	title        = {GlobFit},
	author       = {Li, Yangyan and Wu, Xiaokun and Chrysathou, Yiorgos and Sharf, Andrei and Cohen-Or, Daniel and Mitra, Niloy J.},
	year         = {2011},
	month        = {7},
	journal      = {ACM Transactions on Graphics},
	volume       = {30},
	number       = {4},
	pages        = {1--12},
	doi          = {10.1145/2010324.1964947},
	issn         = {0730-0301}
}
@article{locatello2018challenging,
	title        = {Challenging common assumptions in the unsupervised learning of disentangled representations},
	author       = {Locatello, Francesco and Bauer, Stefan and Lucic, Mario and Gelly, Sylvain and Sch{\"o}lkopf, Bernhard and Bachem, Olivier},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1811.12359}
}
@inproceedings{long2015fully,
	title        = {Fully convolutional networks for semantic segmentation},
	author       = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	year         = {2015},
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {3431--3440}
}
@inproceedings{lopez2018human,
	title        = {Human validation of computer vs human generated design sketches},
	author       = {Lopez, Christian and Miller, Scarlett R and Tucker, Conrad S},
	year         = {2018},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {51845},
	pages        = {V007T06A015},
	organization = {American Society of Mechanical Engineers}
}
@article{louizos2015variational,
	title        = {The variational fair autoencoder},
	author       = {Louizos, Christos and Swersky, Kevin and Li, Yujia and Welling, Max and Zemel, Richard},
	year         = {2015},
	journal      = {arXiv preprint arXiv:1511.00830}
}
@inproceedings{lucas2018auxiliary,
	title        = {Auxiliary guided autoregressive variational autoencoders},
	author       = {Lucas, Thomas and Verbeek, Jakob},
	year         = {2018},
	booktitle    = {Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
	pages        = {443--458},
	organization = {Springer}
}
@inproceedings{luo2021diffusion,
	title        = {Diffusion probabilistic models for 3d point cloud generation},
	author       = {Luo, Shitong and Hu, Wei},
	year         = {2021},
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {2837--2845}
}
@article{Luoetal2020,
	title        = {Topology optimization using material-field series expansion and Kriging-based algorithm: An effective non-gradient method},
	author       = {Luo, Yangjun and Xing, Jian and Kang, Zhan},
	year         = {2020},
	month        = {6},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	publisher    = {Elsevier B.V.},
	volume       = {364},
	pages        = {112966},
	doi          = {10.1016/j.cma.2020.112966},
	issn         = {00457825},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0045782520301493},
	keywords     = {Kriging surrogate model, Material-field series expansion, Non-gradient, Topology optimization}
}
@article{LuoZhouetal2021,
	title        = {An Improved Data-Driven Topology Optimization Method Using Feature Pyramid Networks with Physical Constraints},
	author       = {Luo, Jiaxiang and Li, Yu and Zhou, Weien and Gong, Zhiqiang and Zhang, Zeyu and Yao, Wen},
	year         = {2021},
	journal      = {Computer Modeling in Engineering {\&} Sciences},
	publisher    = {Tech Science Press},
	volume       = {128},
	number       = {3},
	pages        = {823--848},
	doi          = {10.32604/cmes.2021.016737},
	issn         = {1526-1506},
	url          = {https://www.techscience.com/CMES/v128n3/44011},
	keywords     = {Deep learning, Feature pyramid networks, Finite element analysis, Physical constraints, Topology optimization}
}
@article{Lynchetal2019,
	title        = {Machine Learning to Aid Tuning of Numerical Parameters in Topology Optimization},
	author       = {Lynch, Matthew E. and Sarkar, Soumalya and Maute, Kurt},
	year         = {2019},
	month        = {11},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers (ASME)},
	volume       = {141},
	number       = {11},
	doi          = {10.1115/1.4044228},
	issn         = {1050-0472},
	url          = {https://asmedigitalcollection.asme.org/mechanicaldesign/article/doi/10.1115/1.4044228/955325/Machine-Learning-to-Aid-Tuning-of-Numerical},
	keywords     = {Bayesian optimization, Conceptual design, Design automation, Design optimization, Machine learning, Meta learning, Metamodeling, Topology optimization}
}
@article{ma2019probabilistic,
	title        = {Probabilistic representation and inverse design of metamaterials based on a deep generative model with semi-supervised learning strategy},
	author       = {Ma, Wei and Cheng, Feng and Xu, Yihao and Wen, Qinlong and Liu, Yongmin},
	year         = {2019},
	journal      = {Advanced Materials},
	publisher    = {Wiley Online Library},
	volume       = {31},
	number       = {35},
	pages        = {1901111}
}
@article{maaloe2019biva,
	title        = {BIVA: A Very Deep Hierarchy of Latent Variables for Generative Modeling},
	author       = {Maal{\o}e, Lars and Fraccaro, Marco and Li{\'e}vin, Valentin and Winther, Ole},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1902.02102}
}
@inproceedings{mairal2009online,
	title        = {Online dictionary learning for sparse coding},
	author       = {Mairal, Julien and Bach, Francis and Ponce, Jean and Sapiro, Guillermo},
	year         = {2009},
	booktitle    = {Proceedings of the 26th annual international conference on machine learning},
	pages        = {689--696},
	organization = {ACM}
}
@article{makhzani2015adversarial,
	title        = {Adversarial autoencoders},
	author       = {Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep and Goodfellow, Ian and Frey, Brendan},
	year         = {2015},
	journal      = {arXiv preprint arXiv:1511.05644}
}
@article{malkiel2018plasmonic,
	title        = {Plasmonic nanostructure design and characterization via deep learning},
	author       = {Malkiel, Itzik and Mrejen, Michael and Nagler, Achiya and Arieli, Uri and Wolf, Lior and Suchowski, Haim},
	year         = {2018},
	journal      = {Light: Science \& Applications},
	publisher    = {Nature Publishing Group},
	volume       = {7},
	number       = {1},
	pages        = {1--8}
}
@article{mallat2012group,
	title        = {Group invariant scattering},
	author       = {Mallat, St{\'e}phane},
	year         = {2012},
	journal      = {Communications on Pure and Applied Mathematics},
	publisher    = {Wiley Online Library},
	volume       = {65},
	number       = {10},
	pages        = {1331--1398}
}
@article{manica2022gt4sd,
	title        = {GT4SD: Generative Toolkit for Scientific Discovery},
	author       = {Manica, Matteo and Cadow, Joris and Christofidellis, Dimitrios and Dave, Ashish and Born, Jannis and Clarke, Dean and Teukam, Yves Gaetan Nana and Hoffman, Samuel C and Buchan, Matthew and Chenthamarakshan, Vijil and others},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2207.03928}
}
@techreport{Marcus2019,
	title        = {An Epidemic of AI Misinformation},
	author       = {Marcus, Gary F.},
	year         = {2019},
	url          = {https://thegradient.pub/an-epidemic-of-ai-misinformation/[04-12-2019}
}
@book{MarcusDavis2019,
	title        = {Rebooting AI: Building Artificial Intelligence We Can Trust},
	author       = {Marcus, Gary and Davis, Ernest},
	year         = {2019},
	publisher    = {Pantheon Books},
	address      = {USA},
	isbn         = {1524748250}
}
@article{marino2018iterative,
	title        = {Iterative amortized inference},
	author       = {Marino, Joseph and Yue, Yisong and Mandt, Stephan},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1807.09356}
}
@article{Markov1953-MARTTO-31,
	title        = {The Theory of Algorithms},
	author       = {A. A. Markov},
	year         = {1953},
	journal      = {Journal of Symbolic Logic},
	publisher    = {Association for Symbolic Logic},
	volume       = {18},
	number       = {4},
	pages        = {340--341},
	doi          = {10.2307/2266585}
}
@book{marr,
	title        = {Vision: a computational investigation into the human representation and processing of visual information},
	author       = {Marr, David},
	year         = {1982},
	publisher    = {W H Freeman}
}
@article{marr1978representation,
	title        = {Representation and recognition of the spatial organization of three-dimensional shapes},
	author       = {Marr, David and Nishihara, Herbert Keith},
	year         = {1978},
	journal      = {Proceedings of the Royal Society of London. Series B. Biological Sciences},
	publisher    = {The Royal Society London},
	volume       = {200},
	number       = {1140},
	pages        = {269--294}
}
@inproceedings{masci2011stacked,
	title        = {Stacked convolutional auto-encoders for hierarchical feature extraction},
	author       = {Masci, Jonathan and Meier, Ueli and Cire{\c{s}}an, Dan and Schmidhuber, J{\"u}rgen},
	year         = {2011},
	booktitle    = {International Conference on Artificial Neural Networks},
	pages        = {52--59},
	organization = {Springer}
}
@inproceedings{masrani2019thermodynamic,
	title        = {The Thermodynamic Variational Objective},
	author       = {Masrani, Vaden and Le, Tuan Anh and Wood, Frank},
	year         = {2019},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {11525--11534}
}
@article{matplotlib,
	title        = {Matplotlib: A 2D graphics environment},
	author       = {Hunter, J. D.},
	year         = {2007},
	journal      = {Computing in Science \& Engineering},
	publisher    = {IEEE COMPUTER SOC},
	volume       = {9},
	number       = {3},
	pages        = {90--95},
	doi          = {10.1109/MCSE.2007.55},
	abstract     = {Matplotlib is a 2D graphics package used for Python for application development, interactive scripting, and publication-quality image generation across user interfaces and operating systems.}
}
@inproceedings{maze2022topodiff,
	title        = {Diffusion Models Beat GANs on Topology Optimization},
	author       = {Mazé, F. and Ahmed, F.},
	year         = {2023},
	booktitle    = {Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
	address      = {Washington, DC},
	url          = {https://arxiv.org/abs/2208.09591}
}
@article{MaZeng2020,
	title        = {High-risk prediction localization: evaluating the reliability of black box models for topology optimization},
	author       = {Ma, Fulei and Zeng, Zhi},
	year         = {2020},
	month        = {12},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	volume       = {62},
	number       = {6},
	pages        = {3053--3069},
	doi          = {10.1007/s00158-020-02648-7},
	issn         = {1615-147X},
	url          = {https://link.springer.com/10.1007/s00158-020-02648-7},
	keywords     = {Error distribution, Neural network, Topology optimization}
}
@article{mccomb2018data,
	title        = {Data on the design of truss structures by teams of engineering students},
	author       = {McComb, Christopher and Cagan, Jonathan and Kotovsky, Kenneth},
	year         = {2018},
	journal      = {Data in brief},
	publisher    = {Elsevier},
	volume       = {18},
	pages        = {160--163}
}
@inproceedings{memisevic2007unsupervised,
	title        = {Unsupervised learning of image transformations},
	author       = {Memisevic, Roland and Hinton, Geoffrey},
	year         = {2007},
	booktitle    = {2007 IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {1--8},
	organization = {IEEE}
}
@article{memisevic2012multi,
	title        = {On multi-view feature learning},
	author       = {Memisevic, Roland},
	year         = {2012},
	journal      = {arXiv preprint arXiv:1206.4609}
}
@article{meng2022distillation,
	title        = {On distillation of guided diffusion models},
	author       = {Meng, Chenlin and Gao, Ruiqi and Kingma, Diederik P and Ermon, Stefano and Ho, Jonathan and Salimans, Tim},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2210.03142}
}
@book{mezard2009information,
	title        = {Information, physics, and computation},
	author       = {Mezard, Marc and Mezard, Marc and Montanari, Andrea},
	year         = {2009},
	publisher    = {Oxford University Press}
}
@inproceedings{michalski2014modeling,
	title        = {Modeling deep temporal dependencies with recurrent grammar cells""},
	author       = {Michalski, Vincent and Memisevic, Roland and Konda, Kishore},
	year         = {2014},
	booktitle    = {Advances in neural information processing systems},
	pages        = {1925--1933}
}
@article{mirza2014conditional,
	title        = {Conditional generative adversarial nets},
	author       = {Mirza, Mehdi and Osindero, Simon},
	year         = {2014},
	journal      = {arXiv preprint arXiv:1411.1784}
}
@misc{mis,
	title        = {Miscellaneous {T}itle},
	author       = {A. Misc},
	year         = {2003},
	month        = {May},
	note         = {URL \verb+http://www.abc.edu+},
	howpublished = {On the WWW}
}
@article{mlejnek1992some,
	title        = {Some aspects of the genesis of structures},
	author       = {Mlejnek, HP},
	year         = {1992},
	journal      = {Structural optimization},
	publisher    = {Springer},
	volume       = {5},
	pages        = {64--69}
}
@article{mnih2015human,
	title        = {Human-level control through deep reinforcement learning},
	author       = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
	year         = {2015},
	journal      = {nature},
	publisher    = {Nature Publishing Group},
	volume       = {518},
	number       = {7540},
	pages        = {529--533}
}
@inproceedings{mo2019partnet,
	title        = {Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding},
	author       = {Mo, Kaichun and Zhu, Shilin and Chang, Angel X and Yi, Li and Tripathi, Subarna and Guibas, Leonidas J and Su, Hao},
	year         = {2019},
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {909--918}
}
@article{mo2019structurenet,
	title        = {StructureNet: hierarchical graph networks for 3D shape generation},
	author       = {Mo, Kaichun and Guerrero, Paul and Yi, Li and Su, Hao and Wonka, Peter and Mitra, Niloy J and Guibas, Leonidas J},
	year         = {2019},
	journal      = {ACM Transactions on Graphics},
	volume       = {38},
	number       = {6},
	pages        = {1--19}
}
@article{mohamed2016learning,
	title        = {Learning in implicit generative models},
	author       = {Mohamed, Shakir and Lakshminarayanan, Balaji},
	year         = {2016},
	journal      = {arXiv preprint arXiv:1610.03483}
}
@article{molesky2018inverse,
	title        = {Inverse design in nanophotonics},
	author       = {Molesky, Sean and Lin, Zin and Piggott, Alexander Y and Jin, Weiliang and Vuckovi{\'c}, Jelena and Rodriguez, Alejandro W},
	year         = {2018},
	journal      = {Nature Photonics},
	publisher    = {Nature Publishing Group},
	volume       = {12},
	number       = {11},
	pages        = {659--670}
}
@inproceedings{monti2017geometric,
	title        = {Geometric deep learning on graphs and manifolds using mixture model cnns},
	author       = {Monti, Federico and Boscaini, Davide and Masci, Jonathan and Rodola, Emanuele and Svoboda, Jan and Bronstein, Michael M},
	year         = {2017},
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {5115--5124}
}
@article{mosser2017reconstruction,
	title        = {Reconstruction of three-dimensional porous media using generative adversarial neural networks},
	author       = {Mosser, Lukas and Dubrule, Olivier and Blunt, Martin J},
	year         = {2017},
	journal      = {Physical Review E},
	publisher    = {APS},
	volume       = {96},
	number       = {4},
	pages        = {043309}
}
@mastersthesis{mts,
	title        = {Thesis Title},
	author       = {A. Mastersthesis},
	year         = {2003},
	month        = {May},
	address      = {Cambridge, {MA}},
	note         = {See also URL \verb+http://www.abc.edu+},
	school       = {University of Higher Education},
	type         = {MS Thesis}
}
@article{Mukherjeeetal2021,
	title        = {Accelerating Large-scale Topology Optimization: State-of-the-Art and Challenges},
	author       = {Mukherjee, Sougata and Lu, Dongcheng and Raghavan, Balaji and Breitkopf, Piotr and Dutta, Subhrajit and Xiao, Manyu and Zhang, Weihong},
	year         = {2021},
	month        = {12},
	journal      = {Archives of Computational Methods in Engineering},
	publisher    = {Springer Science and Business Media B.V.},
	volume       = {28},
	number       = {7},
	pages        = {4549--4571},
	doi          = {10.1007/s11831-021-09544-3},
	issn         = {1134-3060},
	url          = {https://link.springer.com/10.1007/s11831-021-09544-3}
}
@misc{mulitdigitmnist,
	title        = {Multi-digit MNIST for Few-shot Learning},
	author       = {Sun, Shao-Hua},
	year         = {2019},
	journal      = {GitHub repository},
	url          = {https://github.com/shaohua0116/MultiDigitMNIST}
}
@article{muller1997integral,
	title        = {Integral probability metrics and their generating classes of functions},
	author       = {M{\"u}ller, Alfred},
	year         = {1997},
	journal      = {Advances in Applied Probability},
	publisher    = {Cambridge University Press},
	volume       = {29},
	number       = {2},
	pages        = {429--443}
}
@article{MunozChinesta2022,
	title        = {Allying topology and shape optimization through machine learning algorithms},
	author       = {Mu{\~{n}}oz, D. and Nadal, E. and Albelda, J. and Chinesta, F. and R{\'{o}}denas, J.J.},
	year         = {2022},
	month        = {7},
	journal      = {Finite Elements in Analysis and Design},
	volume       = {204},
	pages        = {103719},
	doi          = {10.1016/j.finel.2021.103719},
	issn         = {0168874X}
}
@article{NakamuraSuzuki2020,
	title        = {Deep learning-based topological optimization for representing a user-specified design area},
	author       = {Nakamura, Keigo and Suzuki, Yoshiro},
	year         = {2020},
	month        = {4},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/2004.05461},
	arxivid      = {2004.05461}
}
@inproceedings{nalisnick2018learning,
	title        = {Learning priors for invariance},
	author       = {Nalisnick, Eric and Smyth, Padhraic},
	year         = {2018},
	booktitle    = {International Conference on Artificial Intelligence and Statistics},
	pages        = {366--375}
}
@article{nalisnick2019hybrid,
	title        = {Hybrid models with deep and invertible features},
	author       = {Nalisnick, Eric and Matsukawa, Akihiro and Teh, Yee Whye and Gorur, Dilan and Lakshminarayanan, Balaji},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1902.02767}
}
@article{Napieretal2020,
	title        = {An Artificial Neural Network Approach for Generating High-Resolution Designs From Low-Resolution Input in Topology Optimization},
	author       = {Napier, Nicholas and Sriraman, Sai-Aksharah and Tran, Huy T. and James, Kai A.},
	year         = {2020},
	month        = {1},
	journal      = {Journal of Mechanical Design},
	publisher    = {ASME International},
	volume       = {142},
	number       = {1},
	doi          = {10.1115/1.4044332},
	issn         = {1050-0472},
	url          = {https://asmedigitalcollection.asme.org/mechanicaldesign/article/doi/10.1115/1.4044332/955332/An-Artificial-Neural-Network-Approach-for}
}
@article{nash2021generating,
	title        = {Generating images with sparse representations},
	author       = {Nash, Charlie and Menick, Jacob and Dieleman, Sander and Battaglia, Peter W},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2103.03841}
}
@article{netzer2011reading,
	title        = {Reading digits in natural images with unsupervised feature learning},
	author       = {Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
	year         = {2011}
}
@inproceedings{NEURIPS2019_d0921d44,
	title        = {Efficient Graph Generation with Graph Recurrent Attention Networks},
	author       = {Liao, Renjie and Li, Yujia and Song, Yang and Wang, Shenlong and Hamilton, Will and Duvenaud, David K and Urtasun, Raquel and Zemel, Richard},
	year         = {2019},
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = {32},
	pages        = {},
	url          = {https://proceedings.neurips.cc/paper/2019/file/d0921d442ee91b896ad95059d13df618-Paper.pdf},
	editor       = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett}
}
@article{Nguyenetal2010,
	title        = {A computational paradigm for multiresolution topology optimization (MTOP)},
	author       = {Nguyen, Tam H. and Paulino, Glaucio H. and Song, Junho and Le, Chau H.},
	year         = {2010},
	month        = {4},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {41},
	number       = {4},
	pages        = {525--539},
	doi          = {10.1007/s00158-009-0443-8},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-009-0443-8},
	keywords     = {Density mesh, Design variable, Finite element mesh, Multiresolution, Projection scheme, Topology optimization}
}
@article{Nguyenetal2012,
	title        = {Improving multiresolution topology optimization via multiple discretizations},
	author       = {Nguyen, Tam H. and Paulino, Glaucio H. and Song, Junho and Le, Chau H.},
	year         = {2012},
	month        = {11},
	journal      = {International Journal for Numerical Methods in Engineering},
	volume       = {92},
	number       = {6},
	pages        = {507--530},
	doi          = {10.1002/nme.4344},
	issn         = {00295981},
	url          = {https://onlinelibrary.wiley.com/doi/10.1002/nme.4344},
	keywords     = {Adaptive optimization, Density mesh, Design variable, Finite elements, Multiresolution, Multiresolution topology optimization (MTOP)}
}
@article{nichol2021,
	title        = {Improved Denoising Diffusion Probabilistic Models},
	author       = {Alex Nichol and Prafulla Dhariwal},
	year         = {2021},
	journal      = {CoRR}
}
@article{nichol2021glide,
	title        = {Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
	author       = {Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2112.10741}
}
@inproceedings{nichol2021improved,
	title        = {Improved denoising diffusion probabilistic models},
	author       = {Nichol, Alexander Quinn and Dhariwal, Prafulla},
	year         = {2021},
	booktitle    = {International Conference on Machine Learning},
	pages        = {8162--8171},
	organization = {PMLR}
}
@string{JAIR = {{J. Artif. Intell. Res.(JAIR)}}}
@string{AIJ = {{Artificial Intelligence}}}
@string{IEEE = {{Proc. of the IEEE}}}
@string{ECAI = {{Proc. of European Conference on Artificial Intelligence}}}
@string{IJCAI = {{Proc. of International Joint Conference on Artificial Intelligence (IJCAI)}}}
@string{KEPS = {{Proc. of the ICAPS Workshop on Knowledge Engineering for Planning and Scheduling(KEPS)}}}
@string{SPARK = {{Proc. of the ICAPS Workshop on Scheduling and Planning Applications (SPARK)}}}
@string{PRL = {{Proc. of the ICAPS Workshop on Bridging the Gap Between AI Planning and Reinforcement Learning (PRL)}}}
@string{ICAPS = {{Proc. of the International Conference on Automated Planning and Scheduling (ICAPS)}}}
@string{IPC = {{Proc. of the International Planning Competition}}}
@string{ECP = {{Proc. of European Conference on Planning}}}
@string{AIPS = {{Proc. of the International Conference on Artificial Intelligence Planning and Scheduling}}}
@string{SOCS = {{Proc. of Annual Symposium on Combinatorial Search}}}
@string{SARA = {{Proc. of Symposium on Abstraction, Reformulation, and Approximation}}}
@string{AAAI = {{Proc. of AAAI Conference on Artificial Intelligence}}}
@string{IAAI = {{Proc. of the Innovative Applications of Artificial Intelligence Conference}}}
@string{ICRA = {{Proc. of IEEE International Conference on Robotics and Automaton (ICRA)}}}
@string{IROS = {{Proc. of IEEE International Workshop on Intelligent Robots and Systems (IROS)}}}
@string{AAMAS = {{Proc. of the International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS)}}}
@string{UAI = {{Proc. of the International Conference on Uncertainty in Artificial Intelligence (UAI)}}}
@string{NIPS = {{Advances in Neural Information Processing Systems}}}
@string{ICML = {{Proc. of the International Conference on Machine Learning}}}
@string{ICLR = {{Proc. of the International Conference on Learning Representations}}}
@string{CVPR = {{Proc. of IEEE Conference on Computer Vision and Pattern Recognition}}}
@string{ICASSP = {{Proc. of IEEE Conference on Acoustics, Speech and Signal Processing}}}
@string{IJCCI = {{Proc. of International Joint Conference on Computational Intelligence (IJCCI)}}}
@string{ILP = {{Proc. of International Conference on Inductive Logic Programming ({ILP})}}}
@string{SIGMOD = {{Proc. of the International Conference on Management of Data (SIGMOD)}}}
@string{SIGKDD = {{Proc. of ACM International Conference on Knowledge Discovery and Data Mining (SIGKDD)}}}
@string{ECCV = {{Proc. of the European Conference on Computer Vision (ECCV)}}}
@string{ICPR = {{Proc. of the International Conference on Pattern Recognition (ICPR)}}}
@string{TPAMI = {{IEEE Transactions on Pattern Analysis and Machine Intelligence}}}
@string{ACL = {{Proc. of the Annual Meeting of the Association for Computational Linguistics}}}
@string{COLING = {{Proc. of the International Conference on Computational Linguistics}}}
@string{COMPINT = {Computational Intelligence}}
@string{ECML = {{Proc. of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases}}}
@string{AMAI = {{Annals of Mathematics and Artificial Intelligence}}}
@string{AISTATS = {Proc. of the International Conference on Artificial Intelligence and Statistics (AISTATS)}}
@string{ICCV = {Proc. of the IEEE International Conference on Computer Vision}}
@article{Nie2021,
	title        = {TopologyGAN: Topology Optimization Using Generative Adversarial Networks Based on Physical Fields Over the Initial Domain},
	author       = {Nie, Zhenguo and Lin, Tong and Jiang, Haoliang and Kara, Levent Burak},
	year         = {2021},
	month        = {02},
	journal      = {Journal of Mechanical Design},
	volume       = {143},
	number       = {3},
	doi          = {10.1115/1.4049533},
	issn         = {1050-0472},
	url          = {https://doi.org/10.1115/1.4049533},
	note         = {031715},
	abstract     = {In topology optimization using deep learning, the load and boundary conditions represented as vectors or sparse matrices often miss the opportunity to encode a rich view of the design problem, leading to less than ideal generalization results. We propose a new data-driven topology optimization model called TopologyGAN that takes advantage of various physical fields computed on the original, unoptimized material domain, as inputs to the generator of a conditional generative adversarial network (cGAN). Compared to a baseline cGAN, TopologyGAN achieves a nearly 3 × reduction in the mean squared error and a 2.5 × reduction in the mean absolute error on test problems involving previously unseen boundary conditions. Built on several existing network models, we also introduce a hybrid network called U-SE(Squeeze-and-Excitation)-ResNet for the generator that further increases the overall accuracy. We publicly share our full implementation and trained network.},
	eprint       = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/143/3/031715/6633125/md\_143\_3\_031715.pdf}
}
@article{nie2021topologygan,
	title        = {Topologygan: Topology optimization using generative adversarial networks based on physical fields over the initial domain},
	author       = {Nie, Zhenguo and Lin, Tong and Jiang, Haoliang and Kara, Levent Burak},
	year         = {2021},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers Digital Collection},
	volume       = {143},
	number       = {3}
}
@article{Nieetal2020,
	title        = {TopologyGAN: Topology Optimization Using Generative Adversarial Networks Based on Physical Fields Over the Initial Domain},
	author       = {Nie, Zhenguo and Lin, Tong and Jiang, Haoliang and Kara, Levent Burak},
	year         = {2020},
	month        = {3},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/2003.04685},
	arxivid      = {2003.04685}
}
@article{NieJiangKara2020,
	title        = {Stress Field Prediction in Cantilevered Structures Using Convolutional Neural Networks},
	author       = {Nie, Zhenguo and Jiang, Haoliang and Kara, Levent Burak},
	year         = {2020},
	month        = {2},
	journal      = {Journal of Computing and Information Science in Engineering},
	publisher    = {American Society of Mechanical Engineers (ASME)},
	volume       = {20},
	number       = {1},
	doi          = {10.1115/1.4044097},
	issn         = {1530-9827},
	url          = {https://asmedigitalcollection.asme.org/computingengineering/article/doi/10.1115/1.4044097/955168/Stress-Field-Prediction-in-Cantilevered-Structures},
	keywords     = {CNN, Stress fields, StressNet, deep learning}
}
@inproceedings{NIPS2017_3f5ee243,
	title        = {Attention is All you Need},
	author       = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
	year         = {2017},
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = {30},
	pages        = {},
	url          = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
	editor       = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett}
}
@inproceedings{nobari2021creativegan,
	title        = {CreativeGAN: Editing Generative Adversarial Networks for Creative Design Synthesis},
	author       = {Amin Heyrani Nobari and Muhammad Fathy Rashad and Faez Ahmed},
	year         = {2021},
	month        = {Aug},
	day          = {17-20},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, {IDETC-21}},
	address      = {Virtual, Online},
	organization = {ASME}
}
@article{nobari2021pcdgan,
	title        = {Pcdgan: A continuous conditional diverse generative adversarial network for inverse design},
	author       = {Nobari, Amin Heyrani and Chen, Wei and Ahmed, Faez},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2106.03620}
}
@article{nobari2022range,
	title        = {Range-Constrained Generative Adversarial Network: Design Synthesis Under Constraints Using Conditional Generative Adversarial Networks},
	author       = {Nobari, Amin Heyrani and Chen, Wei and Ahmed, Faez},
	year         = {2022},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers Digital Collection},
	volume       = {144},
	number       = {2}
}
@article{NoratoBendsoe2004,
	title        = {A geometry projection method for shape optimization},
	author       = {Norato, J. and Haber, R. and Tortorelli, D. and Bends{\o}e, M. P.},
	year         = {2004},
	month        = {8},
	journal      = {International Journal for Numerical Methods in Engineering},
	volume       = {60},
	number       = {14},
	pages        = {2289--2312},
	doi          = {10.1002/nme.1044},
	issn         = {0029-5981},
	url          = {https://onlinelibrary.wiley.com/doi/10.1002/nme.1044}
}
@article{numpy,
	title        = {Array programming with {NumPy}},
	author       = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J. van der Walt and Ralf Gommers and Pauli Virtanen and David Cournapeau and Eric Wieser and Julian Taylor and Sebastian Berg and Nathaniel J. Smith and Robert Kern and Matti Picus and Stephan Hoyer and Marten H. van Kerkwijk and Matthew Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and Warren Weckesser and Hameer Abbasi and Christoph Gohlke and Travis E. Oliphant},
	year         = {2020},
	month        = sep,
	journal      = {Nature},
	publisher    = {Springer Science and Business Media {LLC}},
	volume       = {585},
	number       = {7825},
	pages        = {357--362},
	doi          = {10.1038/s41586-020-2649-2},
	url          = {https://doi.org/10.1038/s41586-020-2649-2}
}
@inproceedings{odena2017conditional,
	title        = {Conditional image synthesis with auxiliary classifier gans},
	author       = {Odena, Augustus and Olah, Christopher and Shlens, Jonathon},
	year         = {2017},
	booktitle    = {International conference on machine learning},
	pages        = {2642--2651},
	organization = {PMLR}
}
@inproceedings{oh2018design,
	title        = {Design automation by integrating generative adversarial networks and topology optimization},
	author       = {Oh, Sangeun and Jung, Yongsu and Lee, Ikjin and Kang, Namwoo},
	year         = {2018},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {51753},
	pages        = {V02AT03A008},
	organization = {American Society of Mechanical Engineers}
}
@article{oh2019,
	title        = {Deep Generative Design: Integration of Topology Optimization and Generative Models},
	author       = {Oh, Sangeun and Jung, Yongsu and Kim, Seongsin and Lee, Ikjin and Kang, Namwoo},
	year         = {2019},
	month        = {09},
	journal      = {Journal of Mechanical Design},
	volume       = {141},
	number       = {11},
	doi          = {10.1115/1.4044229},
	issn         = {1050-0472},
	url          = {https://doi.org/10.1115/1.4044229},
	note         = {111405},
	abstract     = {Deep learning has recently been applied to various research areas of design optimization. This study presents the need and effectiveness of adopting deep learning for generative design (or design exploration) research area. This work proposes an artificial intelligent (AI)-based deep generative design framework that is capable of generating numerous design options which are not only aesthetic but also optimized for engineering performance. The proposed framework integrates topology optimization and generative models (e.g., generative adversarial networks (GANs)) in an iterative manner to explore new design options, thus generating a large number of designs starting from limited previous design data. In addition, anomaly detection can evaluate the novelty of generated designs, thus helping designers choose among design options. The 2D wheel design problem is applied as a case study for validation of the proposed framework. The framework manifests better aesthetics, diversity, and robustness of generated designs than previous generative design methods.},
	eprint       = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/141/11/111405/6578473/md\_141\_11\_111405.pdf}
}
@article{oh2019deep,
	title        = {Deep generative design: Integration of topology optimization and generative models},
	author       = {Oh, Sangeun and Jung, Yongsu and Kim, Seongsin and Lee, Ikjin and Kang, Namwoo},
	year         = {2019},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers Digital Collection},
	volume       = {141},
	number       = {11}
}
@article{OhJungKim2019,
	title        = {Deep Generative Design: Integration of Topology Optimization and Generative Models},
	author       = {Oh, Sangeun and Jung, Yongsu and Kim, Seongsin and Lee, Ikjin and Kang, Namwoo},
	year         = {2019},
	month        = {11},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers (ASME)},
	volume       = {141},
	number       = {11},
	doi          = {10.1115/1.4044229},
	issn         = {1050-0472},
	url          = {https://asmedigitalcollection.asme.org/mechanicaldesign/article/doi/10.1115/1.4044229/955342/Deep-Generative-Design-Integration-of-Topology},
	keywords     = {Deep learning, Design automation, Design exploration, Design methodology, Design optimization, Expert systems, Generative adversarial networks, Generative design, Generative models, Product design, Topology optimization}
}
@article{oja1989neural,
	title        = {Neural networks, principal components, and subspaces},
	author       = {Oja, Erkki},
	year         = {1989},
	journal      = {International journal of neural systems},
	publisher    = {World Scientific},
	volume       = {1},
	number       = {01},
	pages        = {61--68}
}
@article{olshausen1995multiscale,
	title        = {A multiscale dynamic routing circuit for forming size-and position-invariant object representations},
	author       = {Olshausen, Bruno A and Anderson, Charles H and Van Essen, David C},
	year         = {1995},
	journal      = {Journal of Computational Neuroscience},
	publisher    = {Springer},
	volume       = {2},
	number       = {1},
	pages        = {45--62}
}
@article{olshausen2004sparse,
	title        = {Sparse coding of sensory inputs},
	author       = {Olshausen, Bruno A and Field, David J},
	year         = {2004},
	journal      = {Current opinion in neurobiology},
	publisher    = {Elsevier},
	volume       = {14},
	number       = {4},
	pages        = {481--487}
}
@article{oord2016pixel,
	title        = {Pixel recurrent neural networks},
	author       = {Oord, Aaron van den and Kalchbrenner, Nal and Kavukcuoglu, Koray},
	year         = {2016},
	journal      = {arXiv preprint arXiv:1601.06759}
}
@article{oord2016wavenet,
	title        = {Wavenet: A generative model for raw audio},
	author       = {Oord, Aaron van den and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
	year         = {2016},
	journal      = {arXiv preprint arXiv:1609.03499}
}
@article{oord2018representation,
	title        = {Representation learning with contrastive predictive coding},
	author       = {Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1807.03748}
}
@article{orbanz2014bayesian,
	title        = {Bayesian models of graphs, arrays and other exchangeable random structures},
	author       = {Orbanz, Peter and Roy, Daniel M},
	year         = {2014},
	journal      = {IEEE transactions on pattern analysis and machine intelligence},
	publisher    = {IEEE},
	volume       = {37},
	number       = {2},
	pages        = {437--461}
}
@article{oreshkin2018tadam,
	title        = {Tadam: Task dependent adaptive metric for improved few-shot learning},
	author       = {Oreshkin, Boris and Rodr{\'\i}guez L{\'o}pez, Pau and Lacoste, Alexandre},
	year         = {2018},
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {31},
	pages        = {721--731}
}
@article{pandey2022diffusevae,
	title        = {DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents},
	author       = {Pandey, Kushagra and Mukherjee, Avideep and Rai, Piyush and Kumar, Abhishek},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2201.00308}
}
@article{PantzTrabelsi2008,
	title        = {A Post-Treatment of the Homogenization Method for Shape Optimization},
	author       = {Pantz, O. and Trabelsi, K.},
	year         = {2008},
	month        = {1},
	journal      = {SIAM Journal on Control and Optimization},
	volume       = {47},
	number       = {3},
	pages        = {1380--1398},
	doi          = {10.1137/070688900},
	issn         = {0363-0129},
	url          = {http://epubs.siam.org/doi/10.1137/070688900}
}
@inproceedings{PantzTrabelsi2010,
	title        = {Construction of minimization sequences for shape optimization},
	author       = {Pantz, Olivier and Trabelsi, Karim},
	year         = {2010},
	month        = {8},
	booktitle    = {2010 15th International Conference on Methods and Models in Automation and Robotics},
	publisher    = {IEEE},
	pages        = {278--283},
	doi          = {10.1109/MMAR.2010.5587222},
	isbn         = {978-1-4244-7828-6},
	url          = {http://ieeexplore.ieee.org/document/5587222/}
}
@article{PanYuYietal2019,
	title        = {Recent Progress on Generative Adversarial Networks (GANs): A Survey},
	author       = {Pan, Zhaoqing and Yu, Weijie and Yi, Xiaokai and Khan, Asifullah and Yuan, Feng and Zheng, Yuhui},
	year         = {2019},
	journal      = {IEEE Access},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	volume       = {7},
	pages        = {36322--36333},
	doi          = {10.1109/ACCESS.2019.2905015},
	issn         = {2169-3536},
	url          = {https://ieeexplore.ieee.org/document/8667290/},
	keywords     = {Deep learning, generative adversarial networks, machine learning, unsupervised learning}
}
@techreport{Papadrakakis1998,
	title        = {Structural optimization using evolution strategies and neural networks},
	author       = {Papadrakakis, Manolis and Lagaros, Nikos D and Tsompanakis, Yiannis},
	year         = {1998},
	booktitle    = {Comput. Methods Appl. Mech. Engrg},
	volume       = {156},
	pages        = {309--333},
	isbn         = {00457825/98}
}
@article{PapaLaga2002,
	title        = {Reliability-based structural optimization using neural networks and Monte Carlo simulation},
	author       = {Papadrakakis, Manolis and Lagaros, Nikos D},
	year         = {2002},
	month        = {6},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	volume       = {191},
	number       = {32},
	pages        = {3491--3507},
	doi          = {10.1016/S0045-7825(02)00287-6},
	issn         = {00457825},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0045782502002876},
	keywords     = {Evolution strategies, Monte Carlo simulation, Neural networks, Parallel computations, Reliability analysis, Structural optimization}
}
@article{papamakarios2018sequential,
	title        = {Sequential neural likelihood: Fast likelihood-free inference with autoregressive flows},
	author       = {Papamakarios, George and Sterratt, David C and Murray, Iain},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1805.07226}
}
@article{papamakarios2019neural,
	title        = {Neural density estimation and likelihood-free inference},
	author       = {Papamakarios, George},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1910.13233}
}
@article{papamakarios2021normalizing,
	title        = {Normalizing flows for probabilistic modeling and inference},
	author       = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
	year         = {2021},
	journal      = {Journal of Machine Learning Research},
	volume       = {22},
	number       = {57},
	pages        = {1--64}
}
@article{parascandolo2017learning,
	title        = {Learning independent causal mechanisms},
	author       = {Parascandolo, Giambattista and Kilbertus, Niki and Rojas-Carulla, Mateo and Sch{\"o}lkopf, Bernhard},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1712.00961}
}
@inproceedings{park2019deepsdf,
	title        = {Deepsdf: Learning continuous signed distance functions for shape representation},
	author       = {Park, Jeong Joon and Florence, Peter and Straub, Julian and Newcombe, Richard and Lovegrove, Steven},
	year         = {2019},
	booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages        = {165--174}
}
@techreport{ParkAdeli1995,
	title        = {A NEURAL DYNAMICS MODEL FOR STRUCTURAL OPTIMIZATION-APPLICATION TO PLASTIC DESIGN OF STRUCTURES},
	author       = {Park, Hyo Seon and Adeli, H},
	year         = {1995},
	booktitle    = {Compurers {\&} Smrrures},
	volume       = {57},
	number       = {3},
	pages        = {391--399},
	isbn         = {00457949/95}
}
@inproceedings{parrott2022multi,
	title        = {Multi-Head Self-Attention GANs for Multiphysics Topology Optimization},
	author       = {Parrott, Corey and Abueidda, Diab and James, Kai A},
	year         = {2022},
	booktitle    = {AIAA AVIATION 2022 Forum},
	pages        = {3726}
}
@inproceedings{Patalano2013AGS,
	title        = {A Graph-based Software Tool for the CAD Modeling of Mechanical Assemblies},
	author       = {S. Patalano and F. Vitolo and A. Lanzotti},
	year         = {2013},
	booktitle    = {GRAPP/IVAPP}
}
@inproceedings{paysan20093d,
	title        = {A 3D face model for pose and illumination invariant face recognition},
	author       = {Paysan, Pascal and Knothe, Reinhard and Amberg, Brian and Romdhani, Sami and Vetter, Thomas},
	year         = {2009},
	booktitle    = {Advanced video and signal based surveillance, 2009. AVSS'09. Sixth IEEE International Conference on},
	pages        = {296--301},
	organization = {Ieee}
}
@inproceedings{pcdgan,
	title        = {PcDGAN: A Continuous Conditional Diverse Generative Adversarial Network For Inverse Design},
	author       = {Heyrani Nobari, Amin and Chen, Wei and Ahmed, Faez},
	year         = {2021},
	month        = {Aug},
	journal      = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
	publisher    = {ACM},
	doi          = {10.1145/3447548.3467414},
	isbn         = {9781450383325},
	url          = {http://dx.doi.org/10.1145/3447548.3467414}
}
@book{pearl2009causality,
	title        = {Causality},
	author       = {Pearl, Judea},
	year         = {2009},
	publisher    = {Cambridge university press}
}
@article{perez2017film,
	title        = {Film: Visual reasoning with a general conditioning layer},
	author       = {Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1709.07871}
}
@article{PerKesWhi2020,
	title        = {Visualization of topology optimization designs with representative subset selection},
	author       = {Perry, Daniel J and Keshavarzzadeh, Vahid and Elhabian, Shireen Y and Kirby, Robert M and Gleicher, Michael and Whitaker, Ross T},
	year         = {2020},
	month        = {12},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/2012.14901},
	arxivid      = {2012.14901}
}
@book{peters2017elements,
	title        = {Elements of causal inference: foundations and learning algorithms},
	author       = {Peters, Jonas and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
	year         = {2017},
	publisher    = {MIT press}
}
% structure____________________________________________________________________
% relaxations_____________________________________________________
@inproceedings{plotz2018neural,
	title        = {Neural nearest neighbors networks},
	author       = {Pl{\"o}tz, Tobias and Roth, Stefan},
	year         = {2018},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {1095--1106}
}
@inproceedings{pmlr-v119-chen20s,
	title        = {Generative Pretraining From Pixels},
	author       = {Chen, Mark and Radford, Alec and Child, Rewon and Wu, Jeffrey and Jun, Heewoo and Luan, David and Sutskever, Ilya},
	year         = {2020},
	month        = {13--18 Jul},
	booktitle    = {Proceedings of the 37th International Conference on Machine Learning},
	publisher    = {PMLR},
	series       = {Proceedings of Machine Learning Research},
	volume       = {119},
	pages        = {1691--1703},
	url          = {https://proceedings.mlr.press/v119/chen20s.html},
	editor       = {III, Hal Daumé and Singh, Aarti},
	pdf          = {http://proceedings.mlr.press/v119/chen20s/chen20s.pdf},
	abstract     = {Inspired by progress in unsupervised representation learning for natural language, we examine whether similar models can learn useful representations for images. We train a sequence Transformer to auto-regressively predict pixels, without incorporating knowledge of the 2D input structure. Despite training on low-resolution ImageNet without labels, we find that a GPT-2 scale model learns strong image representations as measured by linear probing, fine-tuning, and low-data classification. On CIFAR-10, we achieve 96.3\% accuracy with a linear probe, outperforming a supervised Wide ResNet, and 99.0\% accuracy with full fine-tuning, matching the top supervised pre-trained models. We are also competitive with self-supervised benchmarks on ImageNet when substituting pixels for a VQVAE encoding, achieving 69.0\% top-1 accuracy on a linear probe of our features.}
}
@article{Poggio:2013,
	title        = {{M}odels of visual cortex},
	author       = {Poggio, T.  and Serre, T.},
	year         = {2013},
	journal      = {Scholarpedia},
	volume       = {8},
	number       = {4},
	pages        = {3516},
	doi          = {10.4249/scholarpedia.3516},
	note         = {revision \#149958}
}
@techreport{poggio2015theory,
	title        = {I-theory on depth vs width: hierarchical function composition},
	author       = {Poggio, Tomaso and Anselmi, Fabio and Rosasco, Lorenzo},
	year         = {2015},
	institution  = {Center for Brains, Minds and Machines (CBMM)}
}
@article{Pouyanfaretal2018,
	title        = {A Survey on Deep Learning},
	author       = {Pouyanfar, Samira and Sadiq, Saad and Yan, Yilin and Tian, Haiman and Tao, Yudong and Reyes, Maria Presa and Shyu, Mei-Ling and Chen, Shu-Ching and Iyengar, S. S.},
	year         = {2019},
	month        = {9},
	journal      = {ACM Computing Surveys},
	publisher    = {Association for Computing Machinery},
	volume       = {51},
	number       = {5},
	pages        = {1--36},
	doi          = {10.1145/3234150},
	issn         = {0360-0300},
	url          = {https://dl.acm.org/doi/10.1145/3234150},
	keywords     = {Big data, Deep learning, Distributed processing, Machine learning, Neural networks, Survey}
}
@article{praveen2009low,
	title        = {Low cost PSO using metamodels and inexact pre-evaluation: Application to aerodynamic shape design},
	author       = {Praveen, C and Duvigneau, Regis},
	year         = {2009},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	publisher    = {Elsevier},
	volume       = {198},
	number       = {9-12},
	pages        = {1087--1096}
}
@article{preechakul2021diffusion,
	title        = {Diffusion Autoencoders: Toward a Meaningful and Decodable Representation},
	author       = {Preechakul, Konpat and Chatthee, Nattanat and Wizadwongsa, Suttisak and Suwajanakorn, Supasorn},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2111.15640}
}
@inproceedings{pro,
	title        = {Volume {T}itle},
	year         = {1991},
	month        = {May},
	publisher    = {Publisher {N}ame},
	address      = {Publisher address},
	series       = {Proceedings {S}eries},
	volume       = {1},
	note         = {See also URL \verb+http://www.abc.edu+},
	editor       = {A. Proceedings},
	organization = {Organization {N}ame}
}
@phdthesis{pts,
	title        = {Thesis Title},
	author       = {A. Phdthesis},
	year         = {2003},
	month        = {May},
	address      = {Cambridge, {MA}},
	note         = {See also URL \verb+http://www.abc.edu+},
	school       = {University of Higher Education},
	type         = {PhD Thesis}
}
@inproceedings{puentes2020modeling,
	title        = {Modeling A Strategic Human Engineering Design Process: Human-Inspired Heuristic Guidance Through Learned Visual Design Agents},
	author       = {Puentes, L and Raina, A and Cagan, J and McComb, C},
	year         = {2020},
	booktitle    = {Proceedings of the Design Society: DESIGN Conference},
	volume       = {1},
	pages        = {355--364},
	organization = {Cambridge University Press}
}
@inproceedings{Pumarola2020,
	title        = {C-Flow: Conditional Generative Flow Models for Images and 3D Point Clouds},
	author       = {Pumarola, Albert and Popov, Stefan and Moreno-Noguer, Francesc and Ferrari, Vittorio},
	year         = {2020},
	month        = {6},
	booktitle    = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	publisher    = {IEEE},
	pages        = {7946--7955},
	doi          = {10.1109/CVPR42600.2020.00797},
	isbn         = {978-1-7281-7168-5}
}
@article{PyTorch,
	title        = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
	author       = {Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas K{\"{o}}pf and Edward Z. Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
	year         = {2019},
	journal      = {CoRR},
	volume       = {abs/1912.01703},
	url          = {http://arxiv.org/abs/1912.01703},
	eprinttype   = {arXiv},
	eprint       = {1912.01703},
	timestamp    = {Tue, 02 Nov 2021 15:18:32 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1912-01703.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{qi2017pointnet,
	title        = {Pointnet: Deep learning on point sets for 3d classification and segmentation},
	author       = {Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
	year         = {2017},
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {652--660}
}
@article{qi2017pointnet++,
	title        = {Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
	author       = {Qi, Charles R and Yi, Li and Su, Hao and Guibas, Leonidas J},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1706.02413}
}
@article{QianYe2020,
	title        = {Accelerating gradient-based topology optimization design with dual-model artificial neural networks},
	author       = {Qian, Chao and Ye, Wenjing},
	year         = {2021},
	month        = {4},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	volume       = {63},
	number       = {4},
	pages        = {1687--1707},
	doi          = {10.1007/s00158-020-02770-6},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-020-02770-6},
	keywords     = {Artificial neural network, Deep learning, SIMP, Structural and metamaterial design, Topology optimization}
}
@article{QiuDuYang2021,
	title        = {A deep learning approach for efficient topology optimization based on the element removal strategy},
	author       = {Qiu, Cheng and Du, Shanyi and Yang, Jinglei},
	year         = {2021},
	month        = {12},
	journal      = {Materials {\&} Design},
	publisher    = {Elsevier BV},
	volume       = {212},
	pages        = {110179},
	doi          = {10.1016/j.matdes.2021.110179},
	issn         = {02641275},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0264127521007346}
}
@inproceedings{QRL,
	title        = {Q-Learning with Linear Function Approximation},
	author       = {Melo, Francisco S. and Ribeiro, M. Isabel},
	year         = {2007},
	booktitle    = {Learning Theory},
	publisher    = {Springer Berlin Heidelberg},
	address      = {Berlin, Heidelberg},
	pages        = {308--322},
	isbn         = {978-3-540-72927-3},
	editor       = {Bshouty, Nader H. and Gentile, Claudio},
	abstract     = {In this paper, we analyze the convergence of Q-learning with linear function approximation. We identify a set of conditions that implies the convergence of this method with probability 1, when a fixed learning policy is used. We discuss the differences and similarities between our results and those obtained in several related works. We also discuss the applicability of this method when a changing policy is used. Finally, we describe the applicability of this approximate method in partially observable scenarios.}
}
@article{Radeetat2020,
	title        = {Algorithmically-consistent deep learning frameworks for structural topology optimization},
	author       = {Rade, Jaydeep and Balu, Aditya and Herron, Ethan and Pathak, Jay and Ranade, Rishikesh and Sarkar, Soumik and Krishnamurthy, Adarsh},
	year         = {2021},
	month        = {11},
	journal      = {Engineering Applications of Artificial Intelligence},
	volume       = {106},
	pages        = {104483},
	doi          = {10.1016/j.engappai.2021.104483},
	issn         = {09521976},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0952197621003316}
}
@inproceedings{radford2021learning,
	title        = {Learning transferable visual models from natural language supervision},
	author       = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
	year         = {2021},
	booktitle    = {International Conference on Machine Learning},
	pages        = {8748--8763},
	organization = {PMLR}
}
@article{raffel2020exploring,
	title        = {Exploring the limits of transfer learning with a unified text-to-text transformer},
	author       = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
	year         = {2020},
	journal      = {The Journal of Machine Learning Research},
	publisher    = {JMLRORG},
	volume       = {21},
	number       = {1},
	pages        = {5485--5551}
}
@article{raina2019learning,
	title        = {Learning to design from humans: Imitating human designers through deep learning},
	author       = {Raina, Ayush and McComb, Christopher and Cagan, Jonathan},
	year         = {2019},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers Digital Collection},
	volume       = {141},
	number       = {11}
}
@article{raina2021goal,
	title        = {Goal-Directed Design Agents: Integrating Visual Imitation With One-Step Lookahead Optimization for Generative Design},
	author       = {Raina, Ayush and Puentes, Lucas and Cagan, Jonathan and McComb, Christopher},
	year         = {2021},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers},
	volume       = {143},
	number       = {12},
	pages        = {124501}
}
@article{Raissi2018,
	title        = {Deep Hidden Physics Models: Deep Learning of Nonlinear Partial Differential Equations},
	author       = {Raissi, Maziar},
	year         = {2018},
	month        = {1},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/1801.06637},
	arxivid      = {1801.06637}
}
@article{Raissietal2019,
	title        = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
	author       = {Raissi, M. and Perdikaris, P. and Karniadakis, G.E.},
	year         = {2019},
	month        = {2},
	journal      = {Journal of Computational Physics},
	publisher    = {Academic Press Inc.},
	volume       = {378},
	pages        = {686--707},
	doi          = {10.1016/j.jcp.2018.10.045},
	issn         = {00219991},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0021999118307125},
	keywords     = {Data-driven scientific computing, Machine learning, Nonlinear dynamics, Predictive modeling, Runge–Kutta methods}
}
@inproceedings{ramesh2021zero,
	title        = {Zero-shot text-to-image generation},
	author       = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
	year         = {2021},
	booktitle    = {International Conference on Machine Learning},
	pages        = {8821--8831},
	organization = {PMLR}
}
@misc{ramesh2021zeroshot,
	title        = {Zero-Shot Text-to-Image Generation},
	author       = {Aditya Ramesh and Mikhail Pavlov and Gabriel Goh and Scott Gray and Chelsea Voss and Alec Radford and Mark Chen and Ilya Sutskever},
	year         = {2021},
	eprint       = {2102.12092},
	archiveprefix = {arXiv},
	primaryclass = {cs.CV}
}
@article{ramesh2022hierarchical,
	title        = {Hierarchical text-conditional image generation with clip latents},
	author       = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2204.06125}
}
@inproceedings{ranganath2014black,
	title        = {Black box variational inference},
	author       = {Ranganath, Rajesh and Gerrish, Sean and Blei, David},
	year         = {2014},
	booktitle    = {Artificial Intelligence and Statistics},
	pages        = {814--822}
}
@article{rangegan,
	title        = {RANGE-GAN: Design Synthesis Under Constraints Using Conditional Generative Adversarial Networks},
	author       = {Heyrani Nobari, Amin and Chen, Wei (Wayne) and Ahmed, Faez},
	year         = {2021},
	month        = {09},
	journal      = {Journal of Mechanical Design},
	pages        = {1--16},
	doi          = {10.1115/1.4052442},
	issn         = {1050-0472},
	url          = {https://doi.org/10.1115/1.4052442},
	abstract     = {Typical engineering design tasks require the effort to modify designs iteratively until they meet certain constraints, i.e., performance or attribute requirements. Past work has proposed ways to solve the inverse design problem, where desired designs are directly generated from specified requirements, thus avoid the trial and error process. Among those approaches, the conditional deep generative model shows great potential since 1) it works for complex high-dimensional designs and 2) it can generate multiple alternative designs given any condition. In this work, we propose a conditional deep generative model, Range-GAN, to achieve automatic design synthesis subject to range constraints. The proposed model addresses the sparse conditioning issue in data-driven inverse design problems by introducing a label-aware self-augmentation approach. We also propose a new uniformity loss to ensure generated designs evenly cover the given requirement range. Through a real-world example of constrained 3D shape generation, we show that the label-aware self-augmentation leads to an average improvement of14\\% on the constraint satisfaction for generated 3D shapes, and the uniformity loss leads to a 125\\% average increase on the uniformity of generated shapes' attributes. This work laid the foundation for data-driven inverse design problems where we consider range constraints and there are sparse regions in the condition space.},
	eprint       = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/doi/10.1115/1.4052442/6756741/md-21-1243.pdf}
}
@inproceedings{ranjan2018generating,
	title        = {Generating 3D faces using convolutional mesh autoencoders},
	author       = {Ranjan, Anurag and Bolkart, Timo and Sanyal, Soubhik and Black, Michael J},
	year         = {2018},
	booktitle    = {Proceedings of the European Conference on Computer Vision (ECCV)},
	pages        = {704--720}
}
@inproceedings{rasul2021autoregressive,
	title        = {Autoregressive denoising diffusion models for multivariate probabilistic time series forecasting},
	author       = {Rasul, Kashif and Seward, Calvin and Schuster, Ingmar and Vollgraf, Roland},
	year         = {2021},
	booktitle    = {International Conference on Machine Learning},
	pages        = {8857--8868},
	organization = {PMLR}
}
@article{ravi2016optimization,
	title        = {Optimization as a model for few-shot learning},
	author       = {Ravi, Sachin and Larochelle, Hugo},
	year         = {2016}
}
@inproceedings{ravi2018amortized,
	title        = {Amortized bayesian meta-learning},
	author       = {Ravi, Sachin and Beatson, Alex},
	year         = {2018},
	booktitle    = {International Conference on Learning Representations}
}
@article{Rawat2019,
	title        = {A Novel Topology Optimization Approach using Conditional Deep Learning},
	author       = {Sharad Rawat and M.{-}H. Herman Shen},
	year         = {2019},
	journal      = {CoRR},
	volume       = {abs/1901.04859},
	url          = {http://arxiv.org/abs/1901.04859},
	eprinttype   = {arXiv},
	eprint       = {1901.04859},
	timestamp    = {Fri, 01 Feb 2019 13:39:59 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1901-04859.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@techreport{rawat2019application,
	title        = {Application of adversarial networks for 3d structural topology optimization},
	author       = {Rawat, Sharad and Shen, MH Herman},
	year         = {2019},
	institution  = {SAE Technical Paper}
}
@article{RawatShen2018,
	title        = {A novel topology design approach using an integrated deep learning network architecture},
	author       = {Rawat, Sharad and Shen, M. H. Herman},
	year         = {2018},
	month        = {8},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/1808.02334},
	arxivid      = {1808.02334},
	keywords     = {()}
}
@article{RawatShen2019,
	title        = {A Novel Topology Optimization Approach using Conditional Deep Learning},
	author       = {Rawat, Sharad and Shen, M. -H. Herman},
	year         = {2019},
	month        = {1},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/1901.04859},
	arxivid      = {1901.04859}
}
@inproceedings{RawShe2019,
	title        = {Application of Adversarial Networks for 3D Structural Topology Optimization},
	author       = {Rawat, Sharad and Shen, MH Herman},
	year         = {2019},
	month        = {4},
	booktitle    = {SAE Technical Papers},
	publisher    = {SAE International},
	volume       = {2019-April},
	number       = {April},
	doi          = {10.4271/2019-01-0829},
	url          = {https://www.sae.org/content/2019-01-0829/}
}
@article{razavi2019generating,
	title        = {Generating diverse high-fidelity images with vq-vae-2},
	author       = {Razavi, Ali and Van den Oord, Aaron and Vinyals, Oriol},
	year         = {2019},
	journal      = {Advances in neural information processing systems},
	volume       = {32}
}
@article{razavi2019preventing,
	title        = {Preventing Posterior Collapse with delta-VAEs},
	author       = {Razavi, Ali and Oord, A{\"a}ron van den and Poole, Ben and Vinyals, Oriol},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1901.03416}
}
@article{reed2017few,
	title        = {Few-shot autoregressive density estimation: Towards learning to learn distributions},
	author       = {Reed, Scott and Chen, Yutian and Paine, Thomas and Oord, A{\"a}ron van den and Eslami, SM and Rezende, Danilo and Vinyals, Oriol and de Freitas, Nando},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1710.10304}
}
@inproceedings{regenwetter2021biked,
	title        = {{BIKED}: A Dataset and Machine Learning Benchmarks for Data-Driven Bicycle Design},
	author       = {Regenwetter, Lyle and Curry, Brent and Ahmed, Faez},
	year         = {2021},
	month        = {Aug},
	day          = {17-20},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, {IDETC-21}},
	address      = {Virtual, Online},
	organization = {ASME}
}
@article{regenwetter2022biked,
	title        = {BIKED: A Dataset for Computational Bicycle Design With Machine Learning Benchmarks},
	author       = {Regenwetter, Lyle and Curry, Brent and Ahmed, Faez},
	year         = {2022},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers Digital Collection},
	volume       = {144},
	number       = {3}
}
@article{regenwetter2022deep,
	title        = {Deep generative models in engineering design: A review},
	author       = {Regenwetter, Lyle and Nobari, Amin Heyrani and Ahmed, Faez},
	year         = {2022},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers},
	volume       = {144},
	number       = {7},
	pages        = {071704}
}
@misc{regenwetter2022framed,
	title        = {FRAMED: Data-Driven Structural Performance Analysis of Community-Designed Bicycle Frames},
	author       = {Lyle Regenwetter and Colin Weaver and Faez Ahmed},
	year         = {2022},
	eprint       = {2201.10459},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@article{remondino2003point,
	title        = {From point cloud to surface: the modeling and visualization problem},
	author       = {Remondino, Fabio},
	year         = {2003},
	journal      = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
	publisher    = {ISPRS},
	volume       = {34}
}
@article{requeima2019fast,
	title        = {Fast and flexible multi-task classification using conditional neural adaptive processes},
	author       = {Requeima, James and Gordon, Jonathan and Bronskill, John and Nowozin, Sebastian and Turner, Richard E},
	year         = {2019},
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {32}
}
@article{rezende2014stochastic,
	title        = {Stochastic backpropagation and approximate inference in deep generative models},
	author       = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
	year         = {2014},
	journal      = {arXiv preprint arXiv:1401.4082}
}
@article{rezende2015variational,
	title        = {Variational inference with normalizing flows},
	author       = {Rezende, Danilo Jimenez and Mohamed, Shakir},
	year         = {2015},
	journal      = {arXiv preprint arXiv:1505.05770}
}
@article{rezende2016one,
	title        = {One-shot generalization in deep generative models},
	author       = {Rezende, Danilo Jimenez and Mohamed, Shakir and Danihelka, Ivo and Gregor, Karol and Wierstra, Daan},
	year         = {2016},
	journal      = {arXiv preprint arXiv:1603.05106}
}
@book{robinson2012course,
	title        = {A Course in the Theory of Groups},
	author       = {Robinson, Derek JS},
	year         = {2012},
	publisher    = {Springer},
	volume       = {80}
}
@article{rombach2021high,
	title        = {High-Resolution Image Synthesis with Latent Diffusion Models},
	author       = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2112.10752}
}
@inproceedings{ronneberger2015u,
	title        = {U-net: Convolutional networks for biomedical image segmentation},
	author       = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	year         = {2015},
	booktitle    = {International Conference on Medical image computing and computer-assisted intervention},
	pages        = {234--241},
	organization = {Springer}
}
@article{rozvany1992generalized,
	title        = {Generalized shape optimization without homogenization},
	author       = {Rozvany, George IN and Zhou, Ming and Birker, Torben},
	year         = {1992},
	journal      = {Structural optimization},
	publisher    = {Springer},
	volume       = {4},
	pages        = {250--252}
}
@article{rusu2018meta,
	title        = {Meta-learning with latent embedding optimization},
	author       = {Rusu, Andrei A and Rao, Dushyant and Sygnowski, Jakub and Vinyals, Oriol and Pascanu, Razvan and Osindero, Simon and Hadsell, Raia},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1807.05960}
}
@article{sabiston20203d,
	title        = {3D topology optimization for cost and time minimization in additive manufacturing},
	author       = {Sabiston, Graeme and Kim, Il Yong},
	year         = {2020},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer},
	volume       = {61},
	number       = {2},
	pages        = {731--748}
}
@inproceedings{sabour2017dynamic,
	title        = {Dynamic routing between capsules},
	author       = {Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E},
	year         = {2017},
	booktitle    = {Advances in neural information processing systems},
	pages        = {3856--3866}
}
@article{saharia2022photorealistic,
	title        = {Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
	author       = {Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S Sara and Lopes, Rapha Gontijo and others},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2205.11487}
}
@inproceedings{salimans2016improved,
	title        = {Improved Techniques for Training GANs},
	author       = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
	year         = {2016},
	booktitle    = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
	location     = {Barcelona, Spain},
	publisher    = {Curran Associates Inc.},
	address      = {Red Hook, NY, USA},
	series       = {NIPS'16},
	pages        = {2234–2242},
	isbn         = {9781510838819},
	abstract     = {We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3\%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.},
	numpages     = {9}
}
@article{salimans2017pixelcnn++,
	title        = {Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modifications},
	author       = {Salimans, Tim and Karpathy, Andrej and Chen, Xi and Kingma, Diederik P},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1701.05517}
}
@article{salimans2022progressive,
	title        = {Progressive distillation for fast sampling of diffusion models},
	author       = {Salimans, Tim and Ho, Jonathan},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2202.00512}
}
@article{Sanchezetal2020,
	title        = {Machine learning in structural engineering},
	author       = {Amezquita-Sanchez, J P and Valtierra-Rodriguez, M and Adeli, H},
	year         = {2020},
	journal      = {Scientia Iranica A},
	number       = {6},
	pages        = {2645--2656},
	doi          = {10.24200/sci.2020.22091},
	url          = {http://scientiairanica.sharif.edu},
	keywords     = {Civil structures, Deep learning, Machine learning, Prediction, Structural design, Structural engineering, Structural health monitoring, System identiication, Vibration control}
}
@inproceedings{sangpil2020large,
	title        = {A Large-scale Annotated Mechanical Components Benchmark for Classification and Retrieval Tasks with Deep Neural Networks},
	author       = {Kim, Sangpil and Chi, Hyung-gun and Hu, Xiao and Huang, Qixing and Ramani, Karthik},
	year         = {2020},
	booktitle    = {Proceedings of 16th European Conference on Computer Vision (ECCV)}
}
@article{SARKAR2011348,
	title        = {Assessing design creativity},
	author       = {Prabir Sarkar and Amaresh Chakrabarti},
	year         = {2011},
	journal      = {Design Studies},
	volume       = {32},
	number       = {4},
	pages        = {348--383},
	doi          = {https://doi.org/10.1016/j.destud.2011.01.002},
	issn         = {0142-694X},
	url          = {https://www.sciencedirect.com/science/article/pii/S0142694X11000111},
	keywords     = {creativity, engineering design, measure creativity},
	abstract     = {Creativity is crucial for designing products and enabling innovation. Assessing creativity can help identify innovative designers and products, and support improvement of both. The literature variously defines creativity as a function of degree of novelty, usefulness, or both. Most methods for assessing creativity, however, focus only on assessing novelty of products. This research proposes a new method for assessing the creativity of products as a function of their novelty and usefulness. We develop individual methods for assessing novelty and usefulness of products, and then combine these into a method for assessing creativity of products. The proposed methods have been evaluated by benchmarking them, and other methods available from literature, against the collective, intuitive assessment of product creativity of experienced designers.}
}
@article{Sasaki2019,
	title        = {Topology Optimization Accelerated by Deep Learning},
	author       = {Sasaki, Hidenori and Igarashi, Hajime},
	year         = {2019},
	month        = {6},
	journal      = {IEEE Transactions on Magnetics},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	volume       = {55},
	number       = {6},
	pages        = {1--5},
	doi          = {10.1109/TMAG.2019.2901906},
	issn         = {0018-9464},
	url          = {https://ieeexplore.ieee.org/document/8673771/},
	keywords     = {Approximate computing, convolutional neural network (CNN), deep learning (DL), interior permanent magnet (IPM) motor, topology optimization}
}
@article{Satoetal2019,
	title        = {Data mining based on clustering and association rule analysis for knowledge discovery in multiobjective topology optimization},
	author       = {Sato, Yuki and Izui, Kazuhiro and Yamada, Takayuki and Nishiwaki, Shinji},
	year         = {2019},
	month        = {4},
	journal      = {Expert Systems with Applications},
	publisher    = {Elsevier Ltd},
	volume       = {119},
	pages        = {247--261},
	doi          = {10.1016/j.eswa.2018.10.047},
	issn         = {09574174},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S095741741830705X},
	keywords     = {Association analysis, Clustering, Data mining, Optimum design, Topology optimization}
}
@article{satorras2019combining,
	title        = {Combining Generative and Discriminative Models for Hybrid Inference},
	author       = {Satorras, Victor Garcia and Akata, Zeynep and Welling, Max},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1906.02547}
}
@article{schaul2010metalearning,
	title        = {Metalearning},
	author       = {Schaul, Tom and Schmidhuber, J{\"u}rgen},
	year         = {2010},
	journal      = {Scholarpedia},
	volume       = {5},
	number       = {6},
	pages        = {4650}
}
@inproceedings{schlag2018learning,
	title        = {Learning to reason with third order tensor products},
	author       = {Schlag, Imanol and Schmidhuber, J{\"u}rgen},
	year         = {2018},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {9981--9993}
}
@phdthesis{schmidhuber1987evolutionary,
	title        = {Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook},
	author       = {Schmidhuber, J{\"u}rgen},
	year         = {1987},
	school       = {Technische Universit{\"a}t M{\"u}nchen}
}
% compression__________________________________________________________________
@article{schmidhuber1992learning,
	title        = {Learning factorial codes by predictability minimization},
	author       = {Schmidhuber, J{\"u}rgen},
	year         = {1992},
	journal      = {Neural Computation},
	publisher    = {MIT Press},
	volume       = {4},
	number       = {6},
	pages        = {863--879}
}
% compression__________________________________________________________________
@article{schmidhuber1996semilinear,
	title        = {Semilinear predictability minimization produces well-known feature detectors},
	author       = {Schmidhuber, J{\"u}rgen and Eldracher, Martin and Foltin, Bernhard},
	year         = {1996},
	journal      = {Neural Computation},
	publisher    = {MIT Press},
	volume       = {8},
	number       = {4},
	pages        = {773--786}
}
@article{schmidhuber2015deep,
	title        = {Deep learning in neural networks: An overview},
	author       = {Schmidhuber, J{\"u}rgen},
	year         = {2015},
	journal      = {Neural networks},
	publisher    = {Elsevier},
	volume       = {61},
	pages        = {85--117}
}
@article{schmidt_cagan_1997,
	title        = {GGREADA: A graph grammar-based machine design algorithm},
	author       = {Schmidt, Linda C. and Cagan, Jonathan},
	year         = {1997},
	journal      = {Research in Engineering Design},
	volume       = {9},
	number       = {4},
	pages        = {195–213},
	doi          = {10.1007/bf01589682}
}
@article{scholkopf2012causal,
	title        = {On causal and anticausal learning},
	author       = {Sch{\"o}lkopf, Bernhard and Janzing, Dominik and Peters, Jonas and Sgouritsa, Eleni and Zhang, Kun and Mooij, Joris},
	year         = {2012},
	journal      = {arXiv preprint arXiv:1206.6471}
}
@article{scholkopf2019causality,
	title        = {Causality for Machine Learning},
	author       = {Sch{\"o}lkopf, Bernhard},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1911.10500}
}
@inproceedings{schulman2015gradient,
	title        = {Gradient estimation using stochastic computation graphs},
	author       = {Schulman, John and Heess, Nicolas and Weber, Theophane and Abbeel, Pieter},
	year         = {2015},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {3528--3536}
}
@article{schulman2017proximal,
	title        = {Proximal policy optimization algorithms},
	author       = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1707.06347}
}
@book{schweizer2011probabilistic,
	title        = {Probabilistic metric spaces},
	author       = {Schweizer, Berthold and Sklar, Abe},
	year         = {2011},
	publisher    = {Courier Corporation}
}
%NO BETTER BIBTEX
@article{sdesong,
	title        = {Score-Based Generative Modeling through Stochastic Differential Equations},
	author       = {Yang Song and Jascha Sohl{-}Dickstein and Diederik P. Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
	year         = {2020},
	journal      = {CoRR},
	volume       = {abs/2011.13456},
	url          = {https://arxiv.org/abs/2011.13456},
	eprinttype   = {arXiv},
	eprint       = {2011.13456},
	timestamp    = {Wed, 02 Dec 2020 10:10:16 +0100},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2011-13456.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{sehwag2022generating,
	title        = {Generating High Fidelity Data from Low-density Regions using Diffusion Models},
	author       = {Sehwag, Vikash and Hazirbas, Caner and Gordo, Albert and Ozgenel, Firat and Ferrer, Cristian Canton},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2203.17260}
}
@inproceedings{sermanet2018time,
	title        = {Time-contrastive networks: Self-supervised learning from video},
	author       = {Sermanet, Pierre and Lynch, Corey and Chebotar, Yevgen and Hsu, Jasmine and Jang, Eric and Schaal, Stefan and Levine, Sergey and Brain, Google},
	year         = {2018},
	booktitle    = {2018 IEEE International Conference on Robotics and Automation (ICRA)},
	pages        = {1134--1141},
	organization = {IEEE}
}
@article{sharma2019dynamics,
	title        = {Dynamics-Aware Unsupervised Discovery of Skills},
	author       = {Sharma, Archit and Gu, Shixiang and Levine, Sergey and Kumar, Vikash and Hausman, Karol},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1907.01657}
}
@inproceedings{sharma2020path,
	title        = {Path Synthesis of Defect-Free Spatial 5-SS Mechanisms Using Machine Learning},
	author       = {Sharma, Shashank and Purwar, Anurag},
	year         = {2020},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {83990},
	pages        = {V010T10A034},
	organization = {American Society of Mechanical Engineers}
}
@article{Sharpe2019,
	title        = {Topology Design With Conditional Generative Adversarial Networks},
	author       = {Sharpe, Conner and Seepersad, Carolyn Conner},
	year         = {2019},
	month        = {08},
	series       = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {Volume 2A: 45th Design Automation Conference},
	doi          = {10.1115/DETC2019-97833},
	url          = {https://doi.org/10.1115/DETC2019-97833},
	note         = {V02AT03A062},
	abstract     = {Deep convolutional neural networks have gained significant traction as effective approaches for developing detailed but compact representations of complex structured data. Generative networks in particular have become popular for their ability to mimic data distributions and allow further exploration of them. This attribute can be utilized in engineering design domains, in which the data structures of finite element meshes for analyzing potential designs are well suited to the deep convolutional network approaches that are being developed at a rapid pace in the field of image processing. This paper explores the use of conditional generative adversarial networks (cGANs) as a means of generating a compact latent representation of structures resulting from classical topology optimization techniques. The constraints and contextual factors of a design problem, such as mass fraction, material type, and load location, can then be specified as input conditions to generate potential topologies in a directed fashion. The trained network can be used to aid concept generation, such that engineers can explore a variety of designs relevant to the problem at hand with ease. The latent variables of the generator can also be used as design parameters, and the low dimensionality enables tractable computational design without analytical sensitivities. This paper demonstrates these capabilities and discusses avenues for further developments that would enable the engineering design community to further leverage generative machine learning techniques to their full potential.},
	eprint       = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-pdf/IDETC-CIE2019/59186/V02AT03A062/6453126/v02at03a062-detc2019-97833.pdf}
}
@inproceedings{sharpe2019topology,
	title        = {Topology design with conditional generative adversarial networks},
	author       = {Sharpe, Conner and Seepersad, Carolyn Conner},
	year         = {2019},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {59186},
	pages        = {V02AT03A062},
	organization = {American Society of Mechanical Engineers}
}
@article{ShenChen2019,
	title        = {A New CGAN Technique for Constrained Topology Design Optimization},
	author       = {Shen, M. -H. Herman and Chen, Liang},
	year         = {2019},
	month        = {1},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/1901.07675},
	arxivid      = {1901.07675}
}
@inproceedings{sheynin2021hierarchical,
	title        = {A hierarchical transformation-discriminating generative model for few shot anomaly detection},
	author       = {Sheynin, Shelly and Benaim, Sagie and Wolf, Lior},
	year         = {2021},
	booktitle    = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages        = {8495--8504}
}
@article{shigley1985mechanical,
	title        = {Mechanical engineering design},
	author       = {Shigley, Joseph Edward and Mitchell, Larry D and Saunders, H},
	year         = {1985}
}
@article{shu2019weakly,
	title        = {Weakly Supervised Disentanglement with Guarantees},
	author       = {Shu, Rui and Chen, Yining and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1910.09772}
}
@article{shu20203d,
	title        = {3d design using generative adversarial networks and physics-based validation},
	author       = {Shu, Dule and Cunningham, James and Stump, Gary and Miller, Simon W and Yukish, Michael A and Simpson, Timothy W and Tucker, Conrad S},
	year         = {2020},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers},
	volume       = {142},
	number       = {7},
	pages        = {071701}
}
@inproceedings{shyam2017attentive,
	title        = {Attentive recurrent comparators},
	author       = {Shyam, Pranav and Gupta, Shubham and Dukkipati, Ambedkar},
	year         = {2017},
	booktitle    = {International Conference on Machine Learning},
	pages        = {3173--3181},
	organization = {PMLR}
}
%NO BETTER BIBTEX
@article{sigmund_review,
	title        = {Topology optimization approaches: A comparative review},
	author       = {Ole Sigmund and Kurt Maute},
	year         = {2013},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer},
	volume       = {48},
	number       = {6},
	pages        = {1031--1055},
	doi          = {10.1007/s00158-013-0978-6},
	issn         = {1615-147X},
	abstract     = {Topology optimization has undergone a tremendous development since its introduction in the seminal paper by Bends{\o}e and Kikuchi in 1988. By now, the concept is developing in many different directions, including “density”, “level set”, “topological derivative”, “phase field”, “evolutionary” and several others. The paper gives an overview, comparison and critical review of the different approaches, their strengths, weaknesses, similarities and dissimilarities and suggests guidelines for future research.},
	keywords     = {Structural optimization, Topology optimization, Density methods, Level set methods, Phase field methods, Topological derivatives},
	language     = {English}
}
@phdthesis{Sigmund1994,
	title        = {Design of Material Structures Using Topology Optimization},
	author       = {Sigmund, Ole},
	year         = {1994},
	month        = {12},
	address      = {Kongens Lyngby, Denmark},
	url          = {https://www.researchgate.net/publication/261173987_Design_of_Material_Structures_Using_Topology_Optimization},
	school       = {Technical University of Denmark}
}
@article{sigmund200199,
	title        = {A 99 line topology optimization code written in Matlab},
	author       = {Sigmund, Ole},
	year         = {2001},
	journal      = {Structural and multidisciplinary optimization},
	publisher    = {Springer},
	volume       = {21},
	pages        = {120--127}
}
@article{sigmund2007morphology,
	title        = {Morphology-based black and white filters for topology optimization},
	author       = {Sigmund, Ole},
	year         = {2007},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer},
	volume       = {33},
	pages        = {401--424}
}
@article{sigmund2013topology,
	title        = {Topology optimization approaches: A comparative review},
	author       = {Sigmund, Ole and Maute, Kurt},
	year         = {2013},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer},
	volume       = {48},
	number       = {6},
	pages        = {1031--1055}
}
@article{SigmundGA2011,
	title        = {On the usefulness of non-gradient approaches in topology optimization},
	author       = {Sigmund, Ole},
	year         = {2011},
	month        = {5},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {43},
	number       = {5},
	pages        = {589--596},
	doi          = {10.1007/s00158-011-0638-7},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-011-0638-7}
}
@article{SigmundMaute2013,
	title        = {Topology optimization approaches},
	author       = {Sigmund, Ole and Maute, Kurt},
	year         = {2013},
	month        = {12},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {48},
	number       = {6},
	pages        = {1031--1055},
	doi          = {10.1007/s00158-013-0978-6},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-013-0978-6}
}
@article{SIMP1988,
	title        = {Generating optimal topologies in structural design using a homogenization method},
	author       = {Martin Philip Bendsøe and Noboru Kikuchi},
	year         = {1988},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	volume       = {71},
	number       = {2},
	pages        = {197--224},
	doi          = {https://doi.org/10.1016/0045-7825(88)90086-2},
	issn         = {0045-7825},
	url          = {https://www.sciencedirect.com/science/article/pii/0045782588900862},
	abstract     = {Optimal shape design of structural elements based on boundary variations results in final designs that are topologically equivalent to the initial choice of design, and general, stable computational schemes for this approach often require some kind of remeshing of the finite element approximation of the analysis problem. This paper presents a methodology for optimal shape design where both these drawbacks can be avoided. The method is related to modern production techniques and consists of computing the optimal distribution in space of an anisotropic material that is constructed by introducing an infimum of periodically distributed small holes in a given homogeneous, isotropic material, with the requirement that the resulting structure can carry the given loads as well as satisfy other design requirements. The computation of effective material properties for the anisotropic material is carried out using the method of homogenization. Computational results are presented and compared with results obtained by boundary variations.}
}
%NO BETTER BIBTEX
@article{SIMP1992,
	title        = {Generalized shape optimization without homogenization},
	author       = {G. I. N. Rozvany and M. Zhou and Torben Birker},
	year         = {1992},
	journal      = {Structural optimization},
	volume       = {4},
	pages        = {250--252}
}
@article{sinha2021consistency,
	title        = {Consistency regularization for variational auto-encoders},
	author       = {Sinha, Samarth and Dieng, Adji Bousso},
	year         = {2021},
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {34},
	pages        = {12943--12954}
}
@article{sinha2021d2c,
	title        = {D2C: Diffusion-Decoding Models for Few-Shot Conditional Generation},
	author       = {Sinha, Abhishek and Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
	year         = {2021},
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {34}
}
@inproceedings{snell2017prototypical,
	title        = {Prototypical networks for few-shot learning},
	author       = {Snell, Jake and Swersky, Kevin and Zemel, Richard},
	year         = {2017},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {4077--4087}
}
@inproceedings{sohl2015deep,
	title        = {Deep unsupervised learning using nonequilibrium thermodynamics},
	author       = {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
	year         = {2015},
	booktitle    = {International Conference on Machine Learning},
	pages        = {2256--2265},
	organization = {PMLR}
}
@inproceedings{sohn2015learning,
	title        = {Learning Structured Output Representation Using Deep Conditional Generative Models},
	author       = {Sohn, Kihyuk and Yan, Xinchen and Lee, Honglak},
	year         = {2015},
	booktitle    = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2},
	location     = {Montreal, Canada},
	publisher    = {MIT Press},
	address      = {Cambridge, MA, USA},
	series       = {NIPS'15},
	pages        = {3483–3491},
	abstract     = {Supervised deep learning has been successfully applied to many recognition problems. Although it can approximate a complex many-to-one function well when a large amount of training data is provided, it is still challenging to model complex structured output representations that effectively perform probabilistic inference and make diverse predictions. In this work, we develop a deep conditional generative model for structured output prediction using Gaussian latent variables. The model is trained efficiently in the framework of stochastic gradient variational Bayes, and allows for fast prediction using stochastic feed-forward inference. In addition, we provide novel strategies to build robust structured prediction algorithms, such as input noise-injection and multi-scale prediction objective at training. In experiments, we demonstrate the effectiveness of our proposed algorithm in comparison to the deterministic deep neural network counterparts in generating diverse but realistic structured output predictions using stochastic inference. Furthermore, the proposed training methods are complimentary, which leads to strong pixel-level object segmentation and semantic labeling performance on Caltech-UCSD Birds 200 and the subset of Labeled Faces in the Wild dataset.},
	numpages     = {9}
}
@article{sokolowski1999topological,
	title        = {On the topological derivative in shape optimization},
	author       = {Sokolowski, Jan and Zochowski, Antoni},
	year         = {1999},
	journal      = {SIAM journal on control and optimization},
	publisher    = {SIAM},
	volume       = {37},
	number       = {4},
	pages        = {1251--1272}
}
@software{solidspy,
	title        = {SolidsPy: 2D-Finite Element Analysis with Python},
	author       = {Guarín-Zapata, Nicolás and Gómez, Juan},
	year         = {2020},
	doi          = {http://doi.org/10.5281/zenodo.4029270},
	url          = {https://github.com/AppliedMechanics-EAFIT/SolidsPy},
	version      = {1.0.16},
	keywords     = {Python, Finite elements, Scientific computing, Computational mechanics},
	abstract     = {SolidsPy is a simple finite element analysis code for 2D elasticity problems. The code uses as input simple-to-create text files defining a model in terms of nodal, element, material and load data.}
}
@inproceedings{sonderby2016ladder,
	title        = {Ladder variational autoencoders},
	author       = {S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
	year         = {2016},
	booktitle    = {Advances in neural information processing systems},
	pages        = {3738--3746}
}
@inproceedings{song2019,
	title        = {Generative Modeling by Estimating Gradients of the Data Distribution},
	author       = {Yang Song and Stefano Ermon},
	year         = {2019},
	booktitle    = {Advances in Neural Information Processing Systems 32}
}
@article{song2020denoising,
	title        = {Denoising diffusion implicit models},
	author       = {Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
	year         = {2020},
	journal      = {arXiv preprint arXiv:2010.02502}
}
@article{song2020improved,
	title        = {Improved techniques for training score-based generative models},
	author       = {Song, Yang and Ermon, Stefano},
	year         = {2020},
	journal      = {Advances in neural information processing systems},
	volume       = {33},
	pages        = {12438--12448}
}
@article{song2020score,
	title        = {Score-based generative modeling through stochastic differential equations},
	author       = {Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
	year         = {2020},
	journal      = {arXiv preprint arXiv:2011.13456}
}
@inproceedings{song2021denoising,
	title        = {Denoising Diffusion Implicit Models},
	author       = {Jiaming Song and Chenlin Meng and Stefano Ermon},
	year         = {2021},
	booktitle    = {International Conference on Learning Representations},
	url          = {https://openreview.net/forum?id=St1giarCHLP}
}
@article{song2023consistency,
	title        = {Consistency models},
	author       = {Song, Yang and Dhariwal, Prafulla and Chen, Mark and Sutskever, Ilya},
	year         = {2023},
	journal      = {arXiv preprint arXiv:2303.01469}
}
@article{song2023multi,
	title        = {Multi-modal Machine Learning in Engineering Design: A Review and Future Directions},
	author       = {Song, Binyang and Zhou, Rui and Ahmed, Faez},
	year         = {2023},
	journal      = {arXiv preprint arXiv:2302.10909}
}
%NO BETTER BIBTEX
@article{Sosnovik2019,
	title        = {Neural networks for topology optimization},
	author       = {Ivan Sosnovik and Ivan Oseledets},
	year         = {2019},
	journal      = {Russian Journal of Numerical Analysis and Mathematical Modelling},
	volume       = {34},
	number       = {4},
	pages        = {215--223},
	doi          = {doi:10.1515/rnam-2019-0018},
	url          = {https://doi.org/10.1515/rnam-2019-0018},
	lastchecked  = {2022-08-02}
}
@article{sosnovik2019neural,
	title        = {Neural networks for topology optimization},
	author       = {Sosnovik, Ivan and Oseledets, Ivan},
	year         = {2019},
	journal      = {Russian Journal of Numerical Analysis and Mathematical Modelling},
	publisher    = {De Gruyter},
	volume       = {34},
	number       = {4},
	pages        = {215--223}
}
@article{SosnovikOseledets2017,
	title        = {Neural networks for topology optimization},
	author       = {Sosnovik, Ivan and Oseledets, Ivan},
	year         = {2017},
	month        = {9},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/1709.09578},
	arxivid      = {1709.09578}
}
@inproceedings{speed_DM1,
	title        = {Accelerating Score-Based Generative Models with Preconditioned Diffusion Sampling},
	author       = {Ma, Hengyuan and Zhang, Li and Zhu, Xiatian and Feng, Jianfeng},
	year         = {2022},
	booktitle    = {Computer Vision – ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part XXIII},
	location     = {Tel Aviv, Israel},
	publisher    = {Springer-Verlag},
	address      = {Berlin, Heidelberg},
	pages        = {1–16},
	doi          = {10.1007/978-3-031-20050-2_1},
	isbn         = {978-3-031-20049-6},
	url          = {https://doi.org/10.1007/978-3-031-20050-2_1},
	abstract     = {Score-based generative models (SGMs) have recently emerged as a promising class of generative models. However, a fundamental limitation is that their inference is very slow due to a need for many (e.g., 2000) iterations of sequential computations. An intuitive acceleration method is to reduce the sampling iterations which however causes severe performance degradation. We investigate this problem by viewing the diffusion sampling process as a Metropolis adjusted Langevin algorithm, which helps reveal the underlying cause to be ill-conditioned curvature. Under this insight, we propose a model-agnostic preconditioned diffusion sampling (PDS) method that leverages matrix preconditioning to alleviate the aforementioned problem. Crucially, PDS is proven theoretically to converge to the original target distribution of a SGM, no need for retraining. Extensive experiments on three image datasets with a variety of resolutions and diversity validate that PDS consistently accelerates off-the-shelf SGMs whilst maintaining the synthesis quality. In particular, PDS can accelerate by up to 29\texttimes{} on more challenging high resolution (1024\texttimes{}1024) image generation.},
	numpages     = {16},
	keywords     = {Ill-conditioned curvature, Matrix preconditioning, Score-based generative model, Image synthesis}
}
@misc{speed_DM2,
	title        = {How Much is Enough? A Study on Diffusion Times in Score-based Generative Models},
	author       = {Franzese, Giulio and Rossi, Simone and Yang, Lixuan and Finamore, Alessandro and Rossi, Dario and Filippone, Maurizio and Michiardi, Pietro},
	year         = {2022},
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2206.05173},
	url          = {https://arxiv.org/abs/2206.05173},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@misc{speed_DM3,
	title        = {Accelerating Score-based Generative Models for High-Resolution Image Synthesis},
	author       = {Ma, Hengyuan and Zhang, Li and Zhu, Xiatian and Zhang, Jingfeng and Feng, Jianfeng},
	year         = {2022},
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2206.04029},
	url          = {https://arxiv.org/abs/2206.04029},
	copyright    = {Creative Commons Attribution 4.0 International},
	keywords     = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@misc{speed_DM4,
	title        = {Few-Shot Diffusion Models},
	author       = {Giannone, Giorgio and Nielsen, Didrik and Winther, Ole},
	year         = {2022},
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2205.15463},
	url          = {https://arxiv.org/abs/2205.15463},
	copyright    = {arXiv.org perpetual, non-exclusive license},
	keywords     = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@misc{speed_DM5,
	title        = {Accelerating Diffusion Models via Early Stop of the Diffusion Process},
	author       = {Lyu, Zhaoyang and XU, Xudong and Yang, Ceyuan and Lin, Dahua and Dai, Bo},
	year         = {2022},
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.2205.12524},
	url          = {https://arxiv.org/abs/2205.12524},
	copyright    = {Creative Commons Attribution 4.0 International},
	keywords     = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@article{sriperumbudur2012empirical,
	title        = {On the empirical estimation of integral probability metrics},
	author       = {Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG and others},
	year         = {2012},
	journal      = {Electronic Journal of Statistics},
	publisher    = {The Institute of Mathematical Statistics and the Bernoulli Society},
	volume       = {6},
	pages        = {1550--1599}
}
@inproceedings{srivastava2015unsupervised,
	title        = {Unsupervised learning of video representations using lstms},
	author       = {Srivastava, Nitish and Mansimov, Elman and Salakhudinov, Ruslan},
	year         = {2015},
	booktitle    = {International conference on machine learning},
	pages        = {843--852}
}
@article{srivastava2017veegan,
	title        = {Veegan: Reducing mode collapse in gans using implicit variational learning},
	author       = {Srivastava, Akash and Valkov, Lazar and Russell, Chris and Gutmann, Michael U and Sutton, Charles},
	year         = {2017},
	journal      = {Advances in neural information processing systems},
	volume       = {30}
}
@article{stump2019spatial,
	title        = {Spatial Grammar-Based Recurrent Neural Network for Design Form and Behavior Optimization},
	author       = {Stump, Gary M and Miller, Simon W and Yukish, Michael A and Simpson, Timothy W and Tucker, Conrad},
	year         = {2019},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers Digital Collection},
	volume       = {141},
	number       = {12}
}
@article{SuiGuoetal2021,
	title        = {Deep Reinforcement Learning for Digital Materials Design},
	author       = {Sui, Fanping and Guo, Ruiqi and Zhang, Zhizhou and Gu, Grace X. and Lin, Liwei},
	year         = {2021},
	month        = {10},
	journal      = {ACS Materials Letters},
	volume       = {3},
	number       = {10},
	pages        = {1433--1439},
	doi          = {10.1021/acsmaterialslett.1c00390},
	issn         = {2639-4979},
	url          = {https://pubs.acs.org/doi/10.1021/acsmaterialslett.1c00390}
}
@inproceedings{sung2018learning,
	title        = {Learning to compare: Relation network for few-shot learning},
	author       = {Sung, Flood and Yang, Yongxin and Zhang, Li and Xiang, Tao and Torr, Philip HS and Hospedales, Timothy M},
	year         = {2018},
	booktitle    = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages        = {1199--1208}
}
@article{SunMa2020,
	title        = {Generative Design by Using Exploration Approaches of Reinforcement Learning in Density-Based Structural Topology Optimization},
	author       = {Sun, Hongbo and Ma, Ling},
	year         = {2020},
	month        = {5},
	journal      = {Designs},
	publisher    = {MDPI AG},
	volume       = {4},
	number       = {2},
	pages        = {10},
	doi          = {10.3390/designs4020010},
	issn         = {2411-9660},
	url          = {https://www.mdpi.com/2411-9660/4/2/10},
	keywords     = {Bi-directional evolutionary optimization, Exploration, Generative design, Reinforcement learning, Solid isotropic microstructure with penalization, Structural topology optimization}
}
@article{suter2018robustly,
	title        = {Robustly disentangled causal mechanisms: Validating deep representations for interventional robustness},
	author       = {Suter, Raphael and Miladinovi{\'c}, {\DJ}or{\dj}e and Sch{\"o}lkopf, Bernhard and Bauer, Stefan},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1811.00007}
}
@inproceedings{sutskever2009using,
	title        = {Using matrices to model symbolic relationship},
	author       = {Sutskever, Ilya and Hinton, Geoffrey E},
	year         = {2009},
	booktitle    = {Advances in neural information processing systems},
	pages        = {1593--1600}
}
@book{sutton_barto_2012,
	title        = {Reinforcement learning: an introduction},
	author       = {Sutton, Richard S. and Barto, Andrew G.},
	year         = {2012},
	publisher    = {The MIT Press},
	place        = {Cambridge, MA}
}
@article{Svanberg1987,
	title        = {The method of moving asymptotes—a new method for structural optimization},
	author       = {Svanberg, Krister},
	year         = {1987},
	month        = {2},
	journal      = {International Journal for Numerical Methods in Engineering},
	volume       = {24},
	number       = {2},
	pages        = {359--373},
	doi          = {10.1002/nme.1620240207},
	issn         = {0029-5981}
}
@article{tan2020deep,
	title        = {A deep learning--based method for the design of microstructural materials},
	author       = {Tan, Ren Kai and Zhang, Nevin L and Ye, Wenjing},
	year         = {2020},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer},
	volume       = {61},
	number       = {4},
	pages        = {1417--1438}
}
@inproceedings{tang2020generative,
	title        = {Generative deep learning model for a multi-level nano-optic broadband power splitter},
	author       = {Tang, Yingheng and Kojima, Keisuke and Koike-Akino, Toshiaki and Wang, Ye and Wu, Pengxiang and Tahersima, Mohammad and Jha, Devesh and Parsons, Kieran and Qi, Minghao},
	year         = {2020},
	booktitle    = {2020 Optical Fiber Communications Conference and Exhibition (OFC)},
	pages        = {1--3},
	organization = {IEEE}
}
@article{TanZhangYe2020,
	title        = {A deep learning–based method for the design of microstructural materials},
	author       = {Tan, Ren Kai and Zhang, Nevin L. and Ye, Wenjing},
	year         = {2020},
	month        = {4},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer},
	volume       = {61},
	number       = {4},
	pages        = {1417--1438},
	doi          = {10.1007/s00158-019-02424-2},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-019-02424-2},
	keywords     = {Convolutional neural network, Deep learning, Generative adversarial network, Material design, Microstructural materials}
}
@phdthesis{tenenbaum1999bayesian,
	title        = {A Bayesian framework for concept learning},
	author       = {Tenenbaum, Joshua Brett},
	year         = {1999},
	school       = {Massachusetts Institute of Technology}
}
@article{tenenbaum2011grow,
	title        = {How to grow a mind: Statistics, structure, and abstraction},
	author       = {Tenenbaum, Joshua B and Kemp, Charles and Griffiths, Thomas L and Goodman, Noah D},
	year         = {2011},
	journal      = {science},
	publisher    = {American Association for the Advancement of Science},
	volume       = {331},
	number       = {6022},
	pages        = {1279--1285}
}
@misc{tensorflow,
	title        = {{TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
	author       = {Mart\'{i}n~Abadi and Ashish~Agarwal and Paul~Barham and Eugene~Brevdo and Zhifeng~Chen and Craig~Citro and Greg~S.~Corrado and Andy~Davis and Jeffrey~Dean and Matthieu~Devin and Sanjay~Ghemawat and Ian~Goodfellow and Andrew~Harp and Geoffrey~Irving and Michael~Isard and Yangqing Jia and Rafal~Jozefowicz and Lukasz~Kaiser and Manjunath~Kudlur and Josh~Levenberg and Dandelion~Man\'{e} and Rajat~Monga and Sherry~Moore and Derek~Murray and Chris~Olah and Mike~Schuster and Jonathon~Shlens and Benoit~Steiner and Ilya~Sutskever and Kunal~Talwar and Paul~Tucker and Vincent~Vanhoucke and Vijay~Vasudevan and Fernanda~Vi\'{e}gas and Oriol~Vinyals and Pete~Warden and Martin~Wattenberg and Martin~Wicke and Yuan~Yu and Xiaoqiang~Zheng},
	year         = {2015},
	url          = {https://www.tensorflow.org/},
	note         = {Software available from tensorflow.org}
}
@inproceedings{text_to_image1,
	title        = {{GLIDE:} Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models},
	author       = {Alexander Quinn Nichol and Prafulla Dhariwal and Aditya Ramesh and Pranav Shyam and Pamela Mishkin and Bob McGrew and Ilya Sutskever and Mark Chen},
	year         = {2022},
	booktitle    = {International Conference on Machine Learning, {ICML} 2022, 17-23 July 2022, Baltimore, Maryland, {USA}},
	publisher    = {PMLR},
	series       = {Proceedings of Machine Learning Research},
	volume       = {162},
	pages        = {16784--16804},
	url          = {https://proceedings.mlr.press/v162/nichol22a.html},
	editor       = {Kamalika Chaudhuri and Stefanie Jegelka and Le Song and Csaba Szepesv{\'{a}}ri and Gang Niu and Sivan Sabato},
	timestamp    = {Tue, 12 Jul 2022 17:36:52 +0200},
	biburl       = {https://dblp.org/rec/conf/icml/NicholDRSMMSC22.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{text_to_image2,
	title        = {DiffusionCLIP: Text-guided Image Manipulation Using Diffusion Models},
	author       = {Gwanghyun Kim and Jong Chul Ye},
	year         = {2021},
	journal      = {CoRR},
	volume       = {abs/2110.02711},
	url          = {https://arxiv.org/abs/2110.02711},
	eprinttype   = {arXiv},
	eprint       = {2110.02711},
	timestamp    = {Thu, 21 Oct 2021 16:20:08 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2110-02711.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{thomas2017independently,
	title        = {Independently Controllable Features},
	author       = {Thomas, Valentin and Pondard, Jules and Bengio, Emmanuel and Sarfati, Marc and Beaudoin, Philippe and Meurs, Marie-Jean and Pineau, Joelle and Precup, Doina and Bengio, Yoshua},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1708.01289}
}
@article{Thompsonetal2020,
	title        = {The Computational Limits of Deep Learning},
	author       = {Thompson, Neil C. and Greenewald, Kristjan and Lee, Keeheon and Manso, Gabriel F.},
	year         = {2020},
	month        = {7},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/2007.05558},
	arxivid      = {2007.05558}
}
@inproceedings{thrun1996learning,
	title        = {Is learning the n-th thing any easier than learning the first?},
	author       = {Thrun, Sebastian},
	year         = {1996},
	booktitle    = {Advances in neural information processing systems},
	pages        = {640--646}
}
@book{thrun2012learning,
	title        = {Learning to learn},
	author       = {Thrun, Sebastian and Pratt, Lorien},
	year         = {2012},
	publisher    = {Springer Science \& Business Media}
}
@techreport{Tiwarietal2018,
	title        = {How Artificial Intelligence, Machine Learning and Deep Learning are Radically Different?},
	author       = {Tiwari, Tanya and Tiwari, Tanuj and Tiwari, Sanjay},
	year         = {2018},
	booktitle    = {International Journals of Advanced Research in Computer Science and Software Engineering},
	number       = {2},
	pages        = {2277--128},
	url          = {www.ijarcsse.com,},
	keywords     = {Artificial Intelligence, Deep Learning, Machine Learning}
}
@inproceedings{toh2013exploring,
	title        = {Exploring the utility of product dissection for early-phase idea generation},
	author       = {Toh, Christine A and Miller, Scarlett R},
	year         = {2013},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {55928},
	pages        = {V005T06A034},
	organization = {American Society of Mechanical Engineers}
}
@article{tolstikhin2017wasserstein,
	title        = {Wasserstein auto-encoders},
	author       = {Tolstikhin, Ilya and Bousquet, Olivier and Gelly, Sylvain and Schoelkopf, Bernhard},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1711.01558}
}
@article{tomczak2017vae,
	title        = {VAE with a VampPrior},
	author       = {Tomczak, Jakub M and Welling, Max},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1705.07120}
}
@inproceedings{touvron2021training,
	title        = {Training data-efficient image transformers \& distillation through attention},
	author       = {Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
	year         = {2021},
	booktitle    = {International Conference on Machine Learning},
	pages        = {10347--10357},
	organization = {PMLR}
}
@article{Traffetal2019,
	title        = {Simple single-scale microstructures based on optimal rank-3 laminates},
	author       = {Tr{\"{a}}ff, E. and Sigmund, O. and Groen, J. P.},
	year         = {2019},
	month        = {4},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {59},
	number       = {4},
	pages        = {1021--1031},
	doi          = {10.1007/s00158-018-2180-3},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-018-2180-3}
}
@inproceedings{tran2017hierarchical,
	title        = {Hierarchical implicit models and likelihood-free variational inference},
	author       = {Tran, Dustin and Ranganath, Rajesh and Blei, David},
	year         = {2017},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {5523--5533}
}
@techreport{trt,
	title        = {Techreport title},
	author       = {A. Techreport},
	year         = {2003},
	month        = {May},
	address      = {Cambridge, {MA}},
	number       = {1},
	note         = {See also URL \verb+http://www.abc.edu+},
	institution  = {University of Higher Education},
	type         = {Progress report}
}
@techreport{Tyflopoulosetal2018,
	title        = {State of the art of generative design and topology optimization and potential research needs},
	author       = {Tyflopoulos, Evangelos and Flem, David Tollnes and Steinert, Martin and Olsen, Anna},
	year         = {2018},
	booktitle    = {NordDesign},
	isbn         = {9789176851852},
	url          = {https://www.researchgate.net/publication/334974685_State_of_the_art_of_generative_design_and_topology_optimization_and_potential_research_needs},
	keywords     = {design, finite element analysis 2, product development, topology optimization}
}
@article{ullman2020bayesian,
	title        = {Bayesian models of conceptual development: Learning as building models of the world},
	author       = {Ullman, Tomer D and Tenenbaum, Joshua B},
	year         = {2020},
	journal      = {Annual Review of Developmental Psychology},
	publisher    = {Annual Reviews},
	volume       = {2},
	pages        = {533--558}
}
@article{UluZhangKara2016,
	title        = {A data-driven investigation and estimation of optimal topologies under variable loading configurations},
	author       = {Ulu, Erva and Zhang, Rusheng and Kara, Levent Burak},
	year         = {2016},
	month        = {3},
	journal      = {Computer Methods in Biomechanics and Biomedical Engineering: Imaging {\&} Visualization},
	publisher    = {Taylor and Francis Ltd.},
	volume       = {4},
	number       = {2},
	pages        = {61--72},
	doi          = {10.1080/21681163.2015.1030775},
	issn         = {2168-1163},
	url          = {http://www.tandfonline.com/doi/full/10.1080/21681163.2015.1030775},
	keywords     = {data-driven design, dimensionality reduction, topology optimisation}
}
@inproceedings{UNet,
	title        = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	author       = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	year         = {2015},
	booktitle    = {Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	pages        = {234--241},
	isbn         = {978-3-319-24574-4},
	editor       = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	abstract     = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.}
}
@unpublished{upd,
	title        = {Unpublished document title},
	author       = {A. Unpublished},
	year         = {2003},
	month        = {May},
	note         = {See also URL \verb+http://www.abc.edu+}
}
@inproceedings{vahdat2020NVAE,
	title        = {{NVAE}: A Deep Hierarchical Variational Autoencoder},
	author       = {Vahdat, Arash and Kautz, Jan},
	year         = {2020},
	booktitle    = {Neural Information Processing Systems (NeurIPS)}
}
@article{vahdat2021score,
	title        = {Score-based generative modeling in latent space},
	author       = {Vahdat, Arash and Kreis, Karsten and Kautz, Jan},
	year         = {2021},
	journal      = {Advances in Neural Information Processing Systems},
	volume       = {34}
}
@inproceedings{Valdez2021framework,
	title        = {A FRAMEWORK FOR INTERACTIVE STRUCTURAL DESIGN EXPLORATION},
	author       = {Valdez, Sofia and Seepersad, Carolyn and Kambampati, Sandilya},
	year         = {2021},
	month        = {Aug},
	day          = {17-20},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, {IDETC-21}},
	address      = {Virtual, Online},
	organization = {ASME}
}
@inproceedings{van2016conditional,
	title        = {Conditional image generation with pixelcnn decoders},
	author       = {Van den Oord, Aaron and Kalchbrenner, Nal and Espeholt, Lasse and Vinyals, Oriol and Graves, Alex and others},
	year         = {2016},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {4790--4798}
}
@article{van2016deep,
	title        = {Deep Reinforcement Learning with Double Q-Learning},
	author       = {van Hasselt, Hado and Guez, Arthur and Silver, David},
	year         = {2016},
	month        = {Mar.},
	journal      = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume       = {30},
	number       = {1},
	url          = {https://ojs.aaai.org/index.php/AAAI/article/view/10295},
	abstractnote = {&lt;p&gt; The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games. &lt;/p&gt;}
}
@inproceedings{van2017neural,
	title        = {Neural discrete representation learning},
	author       = {Van Den Oord, Aaron and Vinyals, Oriol and others},
	year         = {2017},
	journal      = {Advances in neural information processing systems},
	volume       = {30}
}
@article{van2018relational,
	title        = {Relational neural expectation maximization: Unsupervised discovery of objects and their interactions},
	author       = {van Steenkiste, Sjoerd and Chang, Michael and Greff, Klaus and Schmidhuber, J{\"u}rgen},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1802.10353}
}
@inproceedings{vashishth2019composition,
	title        = {Composition-based Multi-Relational Graph Convolutional Networks},
	author       = {Vashishth, Shikhar and Sanyal, Soumya and Nitin, Vikram and Talukdar, Partha},
	year         = {2019},
	booktitle    = {International Conference on Learning Representations}
}
@inproceedings{vaswani2017attention,
	title        = {Attention is all you need},
	author       = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	year         = {2017},
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {5998--6008}
}
@inproceedings{VeeGAN,
	title        = {VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning},
	author       = {Srivastava, Akash and Valkov, Lazar and Russell, Chris and Gutmann, Michael U. and Sutton, Charles},
	year         = {2017},
	booktitle    = {Advances in Neural Information Processing Systems},
	publisher    = {Curran Associates, Inc.},
	volume       = {30},
	pages        = {3308--3318},
	url          = {https://proceedings.neurips.cc/paper/2017/file/44a2e0804995faf8d2e3b084a1e2db1d-Paper.pdf},
	editor       = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett}
}
@article{velickovic2017graph,
	title        = {Graph attention networks},
	author       = {Velickovic, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio, Pietro and Bengio, Yoshua},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1710.10903},
	volume       = {1},
	number       = {2}
}
@inproceedings{vinyals2016matching,
	title        = {Matching networks for one shot learning},
	author       = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Wierstra, Daan and others},
	year         = {2016},
	booktitle    = {Advances in neural information processing systems},
	pages        = {3630--3638}
}
@article{volkhonskiy2019reconstruction,
	title        = {Reconstruction of 3d porous media from 2d slices},
	author       = {Volkhonskiy, Denis and Muravleva, Ekaterina and Sudakov, Oleg and Orlov, Denis and Belozerov, Boris and Burnaev, Evgeny and Koroteev, Dmitry},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1901.10233}
}
@article{Vulimirietal2021,
	title        = {Integrating Geometric Data into Topology Optimization via Neural Style Transfer},
	author       = {Vulimiri, Praveen S. and Deng, Hao and Dugast, Florian and Zhang, Xiaoli and To, Albert C.},
	year         = {2021},
	month        = {8},
	journal      = {Materials},
	publisher    = {MDPI AG},
	volume       = {14},
	number       = {16},
	pages        = {4551},
	doi          = {10.3390/ma14164551},
	issn         = {1996-1944},
	url          = {https://www.mdpi.com/1996-1944/14/16/4551},
	keywords     = {Additive manufacturing, Neural network, Neural style transfer, Topology optimization}
}
% Variational Inference
@article{wainwright2008graphical,
	title        = {Graphical models, exponential families, and variational inference},
	author       = {Wainwright, Martin J and Jordan, Michael},
	year         = {2008},
	journal      = {Foundations and Trends{\textregistered} in Machine Learning},
	publisher    = {Now Publishers, Inc.},
	volume       = {1},
	number       = {1--2},
	pages        = {1--305}
}
@article{wang_peng_li_chen_wu_wang_childs_guo_2019,
	title        = {Human-in-the-Loop Design with Machine Learning},
	author       = {Wang, Pan and Peng, Danlin and Li, Ling and Chen, Liuqing and Wu, Chao and Wang, Xiaoyi and Childs, Peter and Guo, Yike},
	year         = {2019},
	journal      = {Proceedings of the Design Society: International Conference on Engineering Design},
	publisher    = {Cambridge University Press},
	volume       = {1},
	number       = {1},
	pages        = {2577–2586},
	doi          = {10.1017/dsi.2019.264}
}
@article{wang2011projection,
	title        = {On projection methods, convergence and robust formulations in topology optimization},
	author       = {Wang, Fengwen and Lazarov, Boyan Stefanov and Sigmund, Ole},
	year         = {2011},
	journal      = {Structural and multidisciplinary optimization},
	publisher    = {Springer},
	volume       = {43},
	pages        = {767--784}
}
@article{wang2018dataset,
	title        = {Dataset Distillation},
	author       = {Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio and Efros, Alexei A},
	year         = {2018},
	journal      = {arXiv preprint arXiv:1811.10959}
}
@article{wang2020deep,
	title        = {Deep generative modeling for mechanistic-based learning and design of metamaterial systems},
	author       = {Wang, Liwei and Chan, Yu-Chin and Ahmed, Faez and Liu, Zhao and Zhu, Ping and Chen, Wei},
	year         = {2020},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	publisher    = {Elsevier},
	volume       = {372},
	pages        = {113377}
}
@article{wang2021data,
	title        = {Data-Driven Multiscale Design of Cellular Composites with Multiclass Microstructures for Natural Frequency Maximization},
	author       = {Wang, Liwei and van Beek, Anton and Da, Daicong and Chan, Yu-Chin and Zhu, Ping and Chen, Wei},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2106.06478}
}
@inproceedings{Wang2021gaussian,
	title        = {A GAUSSIAN MIXTURE VARIATIONAL AUTOENCODER-BASED APPROACH FOR DESIGNING PHONONIC BANDGAP METAMATERIALS},
	author       = {Wang, Zihan and Xian, Weikang and Baccouche, M. Ridha and Lanzerath, Horst and Li, Ying and Xu, Hongyi},
	year         = {2021},
	month        = {Aug},
	day          = {17-20},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, {IDETC-21}},
	address      = {Virtual, Online},
	organization = {ASME}
}
@article{WANG2022115060,
	title        = {IH-GAN: A conditional generative model for implicit surface-based inverse design of cellular structures},
	author       = {Jun Wang and Wei (Wayne) Chen and Daicong Da and Mark Fuge and Rahul Rai},
	year         = {2022},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	volume       = {396},
	pages        = {115060},
	doi          = {https://doi.org/10.1016/j.cma.2022.115060},
	issn         = {0045-7825},
	url          = {https://www.sciencedirect.com/science/article/pii/S0045782522002699},
	keywords     = {Inverse design, Cellular structure design, Homogenization, Generative adversarial network, Topology optimization},
	abstract     = {Variable-density cellular structures can overcome connectivity and manufacturability issues of topologically optimized structures, particularly those represented as discrete density maps. However, the optimization of such cellular structures is challenging due to the multiscale design problem. Past work addressing this problem generally either only optimizes the volume fraction of single-type unit cells but ignoring the effects of unit cell geometry on properties, or considers the geometry–property relation but builds this relation via heuristics. In contrast, we propose a simple yet more principled way to accurately model the property to geometry mapping using a conditional deep generative model, named Inverse Homogenization Generative Adversarial Network (IH-GAN). It learns the conditional distribution of unit cell geometries given properties and can realize the one-to-many mapping from properties to geometries. We further reduce the complexity of IH-GAN by using the implicit function parameterization to represent unit cell geometries. Results show that our method can 1) generate various unit cells that satisfy given material properties with high accuracy (R2-scores between target properties and properties of generated unit cells >98%) and 2) improve the optimized structural performance over the conventional variable-density single-type structure. In the minimum compliance example, our IH-GAN generated structure achieves a 79.7% reduction in concentrated stress and an extra 3.03% reduction in displacement. In the target deformation examples, our IH-GAN generated structure reduces the target matching error by 86.4% and 79.6% for two test cases, respectively. We also demonstrated that the connectivity issue for multi-type unit cells can be solved by transition layer blending.}
}
@article{WangBeckDa2021,
	title        = {Data-driven multiscale design of cellular composites with multiclass microstructures for natural frequency maximization},
	author       = {Wang, Liwei and van Beek, Anton and Da, Daicong and Chan, Yu-Chin and Zhu, Ping and Chen, Wei},
	year         = {2022},
	month        = {1},
	journal      = {Composite Structures},
	volume       = {280},
	pages        = {114949},
	doi          = {10.1016/j.compstruct.2021.114949},
	issn         = {02638223},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0263822321013805}
}
@article{WangChanAhmedetal2020,
	title        = {Deep generative modeling for mechanistic-based learning and design of metamaterial systems},
	author       = {Wang, Liwei and Chan, Yu-Chin and Ahmed, Faez and Liu, Zhao and Zhu, Ping and Chen, Wei},
	year         = {2020},
	month        = {12},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	volume       = {372},
	pages        = {113377},
	doi          = {10.1016/j.cma.2020.113377},
	issn         = {00457825},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0045782520305624}
}
@article{Wangetal2003,
	title        = {A level set method for structural topology optimization},
	author       = {Wang, Michael Yu and Wang, Xiaoming and Guo, Dongming},
	year         = {2003},
	month        = {1},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	volume       = {192},
	number       = {1-2},
	pages        = {227--246},
	doi          = {10.1016/S0045-7825(02)00559-5},
	issn         = {00457825},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0045782502005595}
}
@article{Wangetal2020,
	title        = {Deep super-resolution neural network for structural topology optimization},
	author       = {Wang, Chunpeng and Yao, Song and Wang, Zhangjun and Hu, Jie},
	year         = {2021},
	month        = {12},
	journal      = {Engineering Optimization},
	publisher    = {Taylor and Francis Ltd.},
	volume       = {53},
	number       = {12},
	pages        = {2108--2121},
	doi          = {10.1080/0305215X.2020.1846031},
	issn         = {0305-215X},
	url          = {https://www.tandfonline.com/doi/full/10.1080/0305215X.2020.1846031},
	keywords     = {Deep learning, super-resolution network, topology optimization}
}
@article{WangLazSig11,
	title        = {On projection methods, convergence and robust formulations in topology optimization},
	author       = {Wang, Fengwen and Lazarov, Boyan Stefanov and Sigmund, Ole},
	year         = {2011},
	month        = {6},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {43},
	number       = {6},
	pages        = {767--784},
	doi          = {10.1007/s00158-010-0602-y},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-010-0602-y},
	keywords     = {Compliant mechanisms, Manufacturing constraints, Robust design, Topology optimization}
}
@article{WangLiuDaChanChenZhu2021,
	title        = {Enhancing Data-driven Multiscale Topology Optimization with Generalized De-homogenization},
	author       = {Wang, Liwei and Liu, Zhao and Da, Daicong and Chan, Yu-Chin and Chen, Wei and Zhu, Ping},
	year         = {2021},
	month        = {12},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/2112.02506},
	arxivid      = {2112.02506}
}
@article{WangXiangetal2021,
	title        = {A deep convolutional neural network for topology optimization with perceptible generalization ability},
	author       = {Wang, Dalei and Xiang, Cheng and Pan, Yue and Chen, Airong and Zhou, Xiaoyi and Zhang, Yiquan},
	year         = {2021},
	month        = {3},
	journal      = {Engineering Optimization},
	publisher    = {Taylor and Francis Ltd.},
	pages        = {1--16},
	doi          = {10.1080/0305215X.2021.1902998},
	issn         = {0305-215X},
	url          = {https://www.tandfonline.com/doi/full/10.1080/0305215X.2021.1902998},
	keywords     = {Convolutional neural network, deep learning, generalization ability, machine learning, topology optimization}
}
@article{WangZhaoZhou2021,
	title        = {A comprehensive review of educational articles on structural and multidisciplinary optimization},
	author       = {Wang, Chao and Zhao, Zhi and Zhou, Ming and Sigmund, Ole and Zhang, Xiaojia Shelly},
	year         = {2021},
	month        = {11},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {64},
	number       = {5},
	pages        = {2827--2880},
	doi          = {10.1007/s00158-021-03050-7},
	issn         = {1615-147X}
}
@article{watanabe1960information,
	title        = {Information theoretical analysis of multivariate correlation},
	author       = {Watanabe, Satosi},
	year         = {1960},
	journal      = {IBM Journal of research and development},
	publisher    = {IBM},
	volume       = {4},
	number       = {1},
	pages        = {66--82}
}
@article{watson2021learning,
	title        = {Learning to efficiently sample from diffusion probabilistic models},
	author       = {Watson, Daniel and Ho, Jonathan and Norouzi, Mohammad and Chan, William},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2106.03802}
}
@inproceedings{watter2015embed,
	title        = {Embed to control: A locally linear latent dynamics model for control from raw images},
	author       = {Watter, Manuel and Springenberg, Jost and Boedecker, Joschka and Riedmiller, Martin},
	year         = {2015},
	booktitle    = {Advances in neural information processing systems},
	pages        = {2746--2754}
}
@article{watters2019spatial,
	title        = {Spatial Broadcast Decoder: A Simple Architecture for Learning Disentangled Representations in VAEs},
	author       = {Watters, Nicholas and Matthey, Loic and Burgess, Christopher P and Lerchner, Alexander},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1901.07017}
}
@article{WeinDunningNorato2020,
	title        = {A review on feature-mapping methods for structural optimization},
	author       = {Wein, Fabian and Dunning, Peter D. and Norato, Julián A.},
	year         = {2020},
	month        = {10},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {62},
	number       = {4},
	pages        = {1597--1638},
	doi          = {10.1007/s00158-020-02649-6},
	issn         = {1615-147X}
}
@article{weyl1927quantenmechanik,
	title        = {Quantenmechanik und gruppentheorie},
	author       = {Weyl, Hermann},
	year         = {1927},
	journal      = {Zeitschrift f{\"u}r Physik},
	publisher    = {Springer},
	volume       = {46},
	number       = {1-2},
	pages        = {1--46}
}
@article{Whiteetal2018,
	title        = {Multiscale topology optimization using neural network surrogate models},
	author       = {White, Daniel A. and Arrighi, William J. and Kudo, Jun and Watts, Seth E.},
	year         = {2019},
	month        = {4},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	publisher    = {Elsevier B.V.},
	volume       = {346},
	pages        = {1118--1135},
	doi          = {10.1016/j.cma.2018.09.007},
	issn         = {00457825},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S004578251830450X},
	keywords     = {Material models, Multiscale analysis, Neural networks, Topology optimization}
}
@book{wigner1931gruppentheorie,
	title        = {Gruppentheorie und ihre Anwendung auf die Quantenmechanik der Atomspektren},
	author       = {Wigner, Eugene Paul},
	year         = {1931},
	publisher    = {Springer}
}
@article{willis2021fusion,
	title        = {Fusion 360 gallery: A dataset and environment for programmatic cad construction from human design sequences},
	author       = {Willis, Karl DD and Pu, Yewen and Luo, Jieliang and Chu, Hang and Du, Tao and Lambourne, Joseph G and Solar-Lezama, Armando and Matusik, Wojciech},
	year         = {2021},
	journal      = {ACM Transactions on Graphics (TOG)},
	publisher    = {ACM New York, NY, USA},
	volume       = {40},
	number       = {4},
	pages        = {1--24}
}
@article{woldseth2022use,
	title        = {On the use of artificial neural networks in topology optimisation},
	author       = {Woldseth, Rebekka V and Aage, Niels and B{\ae}rentzen, J Andreas and Sigmund, Ole},
	year         = {2022},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer},
	volume       = {65},
	number       = {10},
	pages        = {294}
}
@article{wood1996representation,
	title        = {Representation theory and invariant neural networks},
	author       = {Wood, Jeffrey and Shawe-Taylor, John},
	year         = {1996},
	journal      = {Discrete applied mathematics},
	publisher    = {Elsevier},
	volume       = {69},
	number       = {1-2},
	pages        = {33--60}
}
@inproceedings{wu20153d,
	title        = {3d shapenets: A deep representation for volumetric shapes},
	author       = {Wu, Zhirong and Song, Shuran and Khosla, Aditya and Yu, Fisher and Zhang, Linguang and Tang, Xiaoou and Xiao, Jianxiong},
	year         = {2015},
	booktitle    = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages        = {1912--1920}
}
@inproceedings{wu2020meta,
	title        = {Meta-Amortized Variational Inference and Learning.},
	author       = {Wu, Mike and Choi, Kristy and Goodman, Noah D and Ermon, Stefano},
	year         = {2020},
	booktitle    = {AAAI},
	pages        = {6404--6412}
}
@article{wu2023difformer,
	title        = {Difformer: Scalable (graph) transformers induced by energy constrained diffusion},
	author       = {Wu, Qitian and Yang, Chenxiao and Zhao, Wentao and He, Yixuan and Wipf, David and Yan, Junchi},
	year         = {2023},
	journal      = {arXiv preprint arXiv:2301.09474}
}
@article{WuAageetal2018,
	title        = {Infill Optimization for Additive Manufacturing—Approaching Bone-Like Porous Structures},
	author       = {Wu, Jun and Aage, Niels and Westermann, Rudiger and Sigmund, Ole},
	year         = {2018},
	month        = {2},
	journal      = {IEEE Transactions on Visualization and Computer Graphics},
	volume       = {24},
	number       = {2},
	pages        = {1127--1140},
	doi          = {10.1109/TVCG.2017.2655523},
	issn         = {1077-2626}
}
@article{WuSigGro21,
	title        = {Topology optimization of multi-scale structures: a review},
	author       = {Wu, Jun and Sigmund, Ole and Groen, Jeroen P.},
	year         = {2021},
	month        = {3},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {63},
	number       = {3},
	pages        = {1455--1480},
	doi          = {10.1007/s00158-021-02881-8},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-021-02881-8}
}
@article{xia2017recent,
	title        = {Recent advances on topology optimization of multiscale nonlinear structures},
	author       = {Xia, Liang and Breitkopf, Piotr},
	year         = {2017},
	journal      = {Archives of Computational Methods in Engineering},
	publisher    = {Springer},
	volume       = {24},
	number       = {2},
	pages        = {227--249}
}
@article{xiang2022accelerated,
	title        = {Accelerated topology optimization design of 3D structures based on deep learning},
	author       = {Xiang, Cheng and Wang, Dalei and Pan, Yue and Chen, Airong and Zhou, Xiaoyi and Zhang, Yiquan},
	year         = {2022},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer},
	volume       = {65},
	number       = {3},
	pages        = {99}
}
@article{xiao2017fashion,
	title        = {Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
	author       = {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1708.07747}
}
@book{xie1997basic,
	title        = {Basic evolutionary structural optimization},
	author       = {Xie, Y Mike and Steven, Grant P and Xie, YM and Steven, GP},
	year         = {1997},
	publisher    = {Springer}
}
@article{xie2021crystal,
	title        = {Crystal Diffusion Variational Autoencoder for Periodic Material Generation},
	author       = {Xie, Tian and Fu, Xiang and Ganea, Octavian-Eugen and Barzilay, Regina and Jaakkola, Tommi},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2110.06197}
}
@book{XieSteven1997,
	title        = {Evolutionary Structural Optimization},
	author       = {Xie, Y. M. and Steven, G. P.},
	year         = {1997},
	publisher    = {Springer London},
	address      = {London},
	doi          = {10.1007/978-1-4471-0985-3},
	isbn         = {978-1-4471-1250-1},
	url          = {http://link.springer.com/10.1007/978-1-4471-0985-3}
}
@article{xu2010volume,
	title        = {Volume preserving nonlinear density filter based on heaviside functions},
	author       = {Xu, Shengli and Cai, Yuanwu and Cheng, Gengdong},
	year         = {2010},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer},
	volume       = {41},
	pages        = {495--505}
}
@article{xu2019metafun,
	title        = {MetaFun: Meta-Learning with Iterative Functional Updates},
	author       = {Xu, Jin and Ton, Jean-Francois and Kim, Hyunjik and Kosiorek, Adam R and Teh, Yee Whye},
	year         = {2019},
	journal      = {arXiv preprint arXiv:1912.02738}
}
@inproceedings{xu2021a,
	title        = {A Bayesian-Symbolic Approach to Learning and Reasoning for Intuitive Physics},
	author       = {Kai {Xu} and Akash {Srivastava} and Dan {Gutfreund} and Felix {Sosa} and Tomer {Ullman} and Joshua B. {Tenenbaum} and Charles {Sutton}},
	year         = {2021},
	booktitle    = {},
	notes        = {Sourced from Microsoft Academic - https://academic.microsoft.com/paper/3130844156}
}
@article{xu2022geodiff,
	title        = {Geodiff: A geometric diffusion model for molecular conformation generation},
	author       = {Xu, Minkai and Yu, Lantao and Song, Yang and Shi, Chence and Ermon, Stefano and Tang, Jian},
	year         = {2022},
	journal      = {arXiv preprint arXiv:2203.02923}
}
@article{XuDarve2020,
	title        = {ADCME: Learning Spatially-varying Physical Fields using Deep Neural Networks},
	author       = {Xu, Kailai and Darve, Eric},
	year         = {2020},
	month        = {11},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/2011.11955},
	arxivid      = {2011.11955}
}
@article{xue2020machine,
	title        = {Machine learning generative models for automatic design of multi-material 3D printed composite solids},
	author       = {Xue, Tianju and Wallin, Thomas J and Menguc, Yigit and Adriaenssens, Sigrid and Chiaramonte, Maurizio},
	year         = {2020},
	journal      = {Extreme Mechanics Letters},
	publisher    = {Elsevier},
	volume       = {41},
	pages        = {100992}
}
@article{Xueetal2021,
	title        = {Efficient, high-resolution topology optimization method based on convolutional neural networks},
	author       = {Xue, Liang and Liu, Jie and Wen, Guilin and Wang, Hongxin},
	year         = {2021},
	month        = {3},
	journal      = {Frontiers of Mechanical Engineering},
	publisher    = {Higher Education Press Limited Company},
	volume       = {16},
	number       = {1},
	pages        = {80--96},
	doi          = {10.1007/s11465-020-0614-2},
	issn         = {2095-0233},
	url          = {http://link.springer.com/10.1007/s11465-020-0614-2},
	keywords     = {convolutional neural network, density-based, high resolution, topology optimization}
}
@article{XuGaoSteven2021,
	title        = {Machine learning based topology optimization of fiber orientation for variable stiffness composite structures},
	author       = {Xu, Yanan and Gao, Yunkai and Wu, Chi and Fang, Jianguang and Sun, Guangyong and Steven, Grant P. and Li, Qing},
	year         = {2021},
	month        = {11},
	journal      = {International Journal for Numerical Methods in Engineering},
	volume       = {122},
	number       = {22},
	pages        = {6736--6755},
	doi          = {10.1002/nme.6809},
	issn         = {0029-5981},
	url          = {https://onlinelibrary.wiley.com/doi/10.1002/nme.6809}
}
@article{Yamasakietal2021,
	title        = {Data-driven topology design using a deep generative model},
	author       = {Yamasaki, Shintaro and Yaji, Kentaro and Fujita, Kikuo},
	year         = {2021},
	month        = {9},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	volume       = {64},
	number       = {3},
	pages        = {1401--1420},
	doi          = {10.1007/s00158-021-02926-y},
	issn         = {1615-147X},
	url          = {https://link.springer.com/10.1007/s00158-021-02926-y},
	keywords     = {Data-driven design, Deep generative model, Estimation of distribution algorithm, Multi-objective methodology, Sensitivity-free methodology, Topology optimization}
}
@article{yan2022deep,
	title        = {Deep learning driven real time topology optimisation based on initial stress learning},
	author       = {Yan, Jun and Zhang, Qi and Xu, Qi and Fan, Zhirui and Li, Haijiang and Sun, Wei and Wang, Guangyuan},
	year         = {2022},
	journal      = {Advanced Engineering Informatics},
	publisher    = {Elsevier},
	volume       = {51},
	pages        = {101472}
}
@article{yang2018microstructural,
	title        = {Microstructural materials design via deep adversarial learning methodology},
	author       = {Yang, Zijiang and Li, Xiaolin and Catherine Brinson, L and Choudhary, Alok N and Chen, Wei and Agrawal, Ankit},
	year         = {2018},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers Digital Collection},
	volume       = {140},
	number       = {11}
}
@article{YangHuangHao2019,
	title        = {PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows},
	author       = {Yang, Guandao and Huang, Xun and Hao, Zekun and Liu, Ming-Yu and Belongie, Serge and Hariharan, Bharath},
	year         = {2019},
	month        = {6},
	arxivid      = {1906.12320}
}
@article{YanZhangXuetal2022,
	title        = {Deep learning driven real time topology optimisation based on initial stress learning},
	author       = {Yan, Jun and Zhang, Qi and Xu, Qi and Fan, Zhirui and Li, Haijiang and Sun, Wei and Wang, Guangyuan},
	year         = {2022},
	month        = {1},
	journal      = {Advanced Engineering Informatics},
	volume       = {51},
	pages        = {101472},
	doi          = {10.1016/j.aei.2021.101472},
	issn         = {14740346},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S1474034621002226}
}
@article{YeLietal2021,
	title        = {Acceleration Design for Continuum Topology Optimization by Using Pix2pix Neural Network},
	author       = {Ye, Hong-Ling and Li, Ji-Cheng and Yuan, Bo-Shuai and Wei, Nan and Sui, Yun-Kang},
	year         = {2021},
	month        = {5},
	journal      = {International Journal of Applied Mechanics},
	volume       = {13},
	number       = {04},
	pages        = {2150042},
	doi          = {10.1142/S1758825121500423},
	issn         = {1758-8251},
	url          = {https://www.worldscientific.com/doi/abs/10.1142/S1758825121500423}
}
@article{Yildizetal2003,
	title        = {Integrated optimal topology design and shape optimization using neural networks},
	author       = {Yildiz, A.R. and {\"{O}}zt{\"{u}}rk, N. and Kaya, N. and {\"{O}}zt{\"{u}}rk, F.},
	year         = {2003},
	month        = {10},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {25},
	number       = {4},
	pages        = {251--260},
	doi          = {10.1007/s00158-003-0300-0},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-003-0300-0},
	keywords     = {Feature recognition, Neural networks, Shape optimization, Topology optimization}
}
@article{Yilinetal2021,
	title        = {Multiscale topology optimisation with nonparametric microstructures using three-dimensional convolutional neural network (3D-CNN) models},
	author       = {Yilin, Guo and Fuh Ying Hsi, Jerry and Wen Feng, Lu},
	year         = {2021},
	month        = {5},
	journal      = {Virtual and Physical Prototyping},
	volume       = {16},
	number       = {3},
	pages        = {306--317},
	doi          = {10.1080/17452759.2021.1913783},
	issn         = {1745-2759},
	url          = {https://www.tandfonline.com/doi/full/10.1080/17452759.2021.1913783}
}
@inproceedings{yilmaz2020conditional,
	title        = {Conditional generative adversarial network framework for airfoil inverse design},
	author       = {Yilmaz, Emre and German, Brian},
	year         = {2020},
	booktitle    = {AIAA aviation 2020 forum},
	pages        = {3185}
}
@article{YimLeeKim2021,
	title        = {Big data approach for the simultaneous determination of the topology and end-effector location of a planar linkage mechanism},
	author       = {Yim, Neung Hwan and Lee, Jongjun and Kim, Jungho and Kim, Yoon Young},
	year         = {2021},
	month        = {9},
	journal      = {Mechanism and Machine Theory},
	publisher    = {Elsevier Ltd},
	volume       = {163},
	pages        = {104375},
	doi          = {10.1016/j.mechmachtheory.2021.104375},
	issn         = {0094114X},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0094114X21001336},
	keywords     = {Big data approach, End-effector location, Mechanism synthesis, Planar linkages, Shape optimization, Topology}
}
@article{Yooetal2021,
	title        = {Integrating deep learning into CAD/CAE system: generative design and evaluation of 3D conceptual wheel},
	author       = {Yoo, Soyoung and Lee, Sunghee and Kim, Seongsin and Hwang, Kwang Hyeon and Park, Jong Ho and Kang, Namwoo},
	year         = {2021},
	month        = {10},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer Science and Business Media Deutschland GmbH},
	volume       = {64},
	number       = {4},
	pages        = {2725--2747},
	doi          = {10.1007/s00158-021-02953-9},
	issn         = {1615-147X},
	url          = {https://link.springer.com/10.1007/s00158-021-02953-9},
	keywords     = {Artificial intelligence, CAD, CAE, Deep learning, Generative design, Topology optimization}
}
@inproceedings{you2018graph,
	title        = {Graph convolutional policy network for goal-directed molecular graph generation},
	author       = {You, Jiaxuan and Liu, Bowen and Ying, Rex and Pande, Vijay and Leskovec, Jure},
	year         = {2018},
	booktitle    = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
	pages        = {6412--6422}
}
@inproceedings{you2018graphrnn,
	title        = {Graphrnn: Generating realistic graphs with deep auto-regressive models},
	author       = {You, Jiaxuan and Ying, Rex and Ren, Xiang and Hamilton, William and Leskovec, Jure},
	year         = {2018},
	booktitle    = {International conference on machine learning},
	pages        = {5708--5717},
	organization = {PMLR}
}
@article{yu2017characterization,
	title        = {Characterization and design of functional quasi-random nanostructured materials using spectral density function},
	author       = {Yu, Shuangcheng and Zhang, Yichi and Wang, Chen and Lee, Won-kyu and Dong, Biqin and Odom, Teri W and Sun, Cheng and Chen, Wei},
	year         = {2017},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers},
	volume       = {139},
	number       = {7},
	pages        = {071401}
}
@article{Yu2018,
	title        = {Deep learning for determining a near-optimal topological design without any iteration},
	author       = {Yonggyun Yu and Taeil Hur and Jaeho Jung and In Gwun Jang},
	year         = {2018},
	month        = {oct},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer Science and Business Media {LLC}},
	volume       = {59},
	number       = {3},
	pages        = {787--799},
	doi          = {10.1007/s00158-018-2101-5},
	url          = {https://doi.org/10.1007%2Fs00158-018-2101-5}
}
@article{yu2019deep,
	title        = {Deep learning for determining a near-optimal topological design without any iteration},
	author       = {Yu, Yonggyun and Hur, Taeil and Jung, Jaeho and Jang, In Gwun},
	year         = {2019},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer},
	volume       = {59},
	number       = {3},
	pages        = {787--799}
}
@article{YueYangDuetal2021,
	title        = {A mechanistic-based data-driven approach to accelerate structural topology optimization through finite element convolutional neural network (FE-CNN)},
	author       = {Yue, Tianle and Yang, Hang and Du, Zongliang and Liu, Chang and Elkhodary, Khalil I. and Tang, Shan and Guo, Xu},
	year         = {2021},
	month        = {6},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/2106.13652},
	arxivid      = {2106.13652}
}
@article{YuHurJungJang2019,
	title        = {Deep learning for determining a near-optimal topological design without any iteration},
	author       = {Yu, Yonggyun and Hur, Taeil and Jung, Jaeho and Jang, In Gwun},
	year         = {2019},
	month        = {3},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer Verlag},
	volume       = {59},
	number       = {3},
	pages        = {787--799},
	doi          = {10.1007/s00158-018-2101-5},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-018-2101-5},
	keywords     = {Convolutional neural network, Deep learning, Generative adversarial network, Generative model, Machine learning, Topology optimization}
}
@article{yukish2020using,
	title        = {Using Recurrent Neural Networks to Model Spatial Grammars for Design Creation},
	author       = {Yukish, Michael A and Stump, Gary M and Miller, Simon W},
	year         = {2020},
	journal      = {Journal of Mechanical Design},
	publisher    = {American Society of Mechanical Engineers},
	volume       = {142},
	number       = {10},
	pages        = {104501}
}
@inproceedings{zaheer2017deep,
	title        = {Deep sets},
	author       = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan R and Smola, Alexander J},
	year         = {2017},
	booktitle    = {Advances in neural information processing systems},
	pages        = {3391--3401}
}
@book{zee2016group,
	title        = {Group theory in a nutshell for physicists},
	author       = {Zee, Anthony},
	year         = {2016},
	publisher    = {Princeton University Press}
}
@article{zegard2016bridging,
	title        = {Bridging topology optimization and additive manufacturing},
	author       = {Zegard, Tom{\'a}s and Paulino, Glaucio H},
	year         = {2016},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer},
	volume       = {53},
	number       = {1},
	pages        = {175--192}
}
@article{Zehnderetal2021,
	title        = {NTopo: Mesh-free Topology Optimization using Implicit Neural Representations},
	author       = {Zehnder, Jonas and Li, Yue and Coros, Stelian and Thomaszewski, Bernhard},
	year         = {2021},
	month        = {2},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/2102.10782},
	arxivid      = {2102.10782}
}
@article{zellinger2017central,
	title        = {Central moment discrepancy (cmd) for domain-invariant representation learning},
	author       = {Zellinger, Werner and Grubinger, Thomas and Lughofer, Edwin and Natschl{\"a}ger, Thomas and Saminger-Platz, Susanne},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1702.08811}
}
@inproceedings{zhang20193d,
	title        = {3D shape synthesis for conceptual design and optimization using variational autoencoders},
	author       = {Zhang, Wentai and Yang, Zhangsihao and Jiang, Haoliang and Nigam, Suyash and Yamakawa, Soji and Furuhata, Tomotake and Shimada, Kenji and Kara, Levent Burak},
	year         = {2019},
	booktitle    = {International Design Engineering Technical Conferences and Computers and Information in Engineering Conference},
	volume       = {59186},
	pages        = {V02AT03A017},
	organization = {American Society of Mechanical Engineers}
}
@inproceedings{zhang2020meshingnet,
	title        = {MeshingNet: a new mesh generation method based on deep learning},
	author       = {Zhang, Zheyan and Wang, Yongxing and Jimack, Peter K and Wang, He},
	year         = {2020},
	booktitle    = {International Conference on Computational Science},
	pages        = {186--198},
	organization = {Springer}
}
@article{ZHANG2021103041,
	title        = {ScaffoldGAN: Synthesis of Scaffold Materials based on Generative Adversarial Networks},
	author       = {Hui Zhang and Lei Yang and Changjian Li and Bojian Wu and Wenping Wang},
	year         = {2021},
	journal      = {Computer-Aided Design},
	volume       = {138},
	pages        = {103041},
	doi          = {https://doi.org/10.1016/j.cad.2021.103041},
	issn         = {0010-4485},
	url          = {https://www.sciencedirect.com/science/article/pii/S001044852100052X},
	keywords     = {3D shape synthesis, Generative adversarial networks, Deep learning, Scaffold material, Complex structure},
	abstract     = {Digitally synthesizing scaffold-like materials with complex structures, e.g., bones or metal foam, is a fundamental yet challenging task in tissue engineering and other biomedical applications, because it is difficult to generate synthesized results with equal visual complexity, strong spatial coherence, and similar statistical metrics. To handle these challenges, we present ScaffoldGAN, an efficient end-to-end framework based on generative adversarial networks (GANs) for synthesizing three-dimensional (3D) materials with complex internal structures resembling the given exemplar. Specifically, we propose a novel structural loss to enforce strong spatial coherence in the synthesized results by leveraging the deep features learned by our networks. To demonstrate the effectiveness of our model and the proposed structural loss term, we collected example data containing various structural complexities, covering two categories of materials, i.e., bones and metal foams. Extensive comparative experiments on these collected data showed that our method outperforms state-of-the-art methods, producing synthesized results with better visual quality and desirable statistical metrics. The ablation study proves the structural loss is the main contributor to the performance gain, validating our design choice.}
}
@article{Zhang2022,
	title        = {A deep convolutional neural network for topology optimization with perceptible generalization ability},
	author       = {Dalei Wang and Cheng Xiang and Yue Pan and Airong Chen and Xiaoyi Zhou and Yiquan Zhang},
	year         = {2021},
	journal      = {Engineering Optimization},
	publisher    = {Taylor & Francis},
	volume       = {54},
	number       = {6},
	pages        = {973--988},
	doi          = {10.1080/0305215X.2021.1902998},
	url          = {https://doi.org/10.1080/0305215X.2021.1902998},
	eprint       = {https://doi.org/10.1080/0305215X.2021.1902998}
}
@article{ZhangChiPaulinoetal2021,
	title        = {Speeding up Computational Morphogenesis with Online Neural Synthetic Gradients},
	author       = {Zhang, Yuyu and Chi, Heng and Chen, Binghong and Tang, Tsz Ling Elaine and Mirabella, Lucia and Song, Le and Paulino, Glaucio H.},
	year         = {2021},
	month        = {4},
	journal      = {Preprint},
	url          = {http://arxiv.org/abs/2104.12282},
	arxivid      = {2104.12282}
}
@article{Zhangetal2019,
	title        = {A deep convolutional neural network for topology optimization with perceptible generalization ability},
	author       = {Wang, Dalei and Xiang, Cheng and Pan, Yue and Chen, Airong and Zhou, Xiaoyi and Zhang, Yiquan},
	year         = {2021},
	month        = {3},
	journal      = {Engineering Optimization},
	pages        = {1--16},
	doi          = {10.1080/0305215X.2021.1902998},
	issn         = {0305-215X},
	url          = {https://www.tandfonline.com/doi/full/10.1080/0305215X.2021.1902998}
}
@article{ZhangYe2019,
	title        = {Deep learning–based inverse method for layout design},
	author       = {Zhang, Yujie and Ye, Wenjing},
	year         = {2019},
	month        = {8},
	journal      = {Structural and Multidisciplinary Optimization},
	publisher    = {Springer Verlag},
	volume       = {60},
	number       = {2},
	pages        = {527--536},
	doi          = {10.1007/s00158-019-02222-w},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-019-02222-w},
	keywords     = {Artificial neural network, Deep learning, Inverse method, Layout design, Variational autoencoder}
}
@article{ZhangYe2019b,
	title        = {Deep learning–based inverse method for layout design},
	author       = {Zhang, Yujie and Ye, Wenjing},
	year         = {2019},
	month        = {8},
	journal      = {Structural and Multidisciplinary Optimization},
	volume       = {60},
	number       = {2},
	pages        = {527--536},
	doi          = {10.1007/s00158-019-02222-w},
	issn         = {1615-147X},
	url          = {http://link.springer.com/10.1007/s00158-019-02222-w}
}
@article{ZhangZhao2021,
	title        = {TONR: An exploration for a novel way combining neural network with topology optimization},
	author       = {Zhang, Zeyu and Li, Yu and Zhou, Weien and Chen, Xiaoqian and Yao, Wen and Zhao, Yong},
	year         = {2021},
	month        = {12},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	volume       = {386},
	pages        = {114083},
	doi          = {10.1016/j.cma.2021.114083},
	issn         = {00457825},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S004578252100414X}
}
@article{zhao2017infovae,
	title        = {Infovae: Information maximizing variational autoencoders},
	author       = {Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1706.02262}
}
@article{zhao2017towards,
	title        = {Towards deeper understanding of variational autoencoding models},
	author       = {Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
	year         = {2017},
	journal      = {arXiv preprint arXiv:1702.08658}
}
@article{zhao2018nanomine,
	title        = {NanoMine schema: An extensible data representation for polymer nanocomposites},
	author       = {Zhao, He and Wang, Yixing and Lin, Anqi and Hu, Bingyin and Yan, Rui and McCusker, James and Chen, Wei and McGuinness, Deborah L and Schadler, Linda and Brinson, L Catherine},
	year         = {2018},
	journal      = {APL Materials},
	publisher    = {AIP Publishing LLC},
	volume       = {6},
	number       = {11},
	pages        = {111108}
}
@article{ZheKumKoch2021,
	title        = {Data-driven topology optimization of spinodoid metamaterials with seamlessly tunable anisotropy},
	author       = {Zheng, Li and Kumar, Siddhant and Kochmann, Dennis M.},
	year         = {2021},
	month        = {9},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	volume       = {383},
	pages        = {113894},
	doi          = {10.1016/j.cma.2021.113894},
	issn         = {00457825},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0045782521002310}
}
@article{ZhengFanetal2021,
	title        = {Accurate and real-time structural topology prediction driven by deep learning under moving morphable component-based framework},
	author       = {Zheng, Shuai and Fan, Haojie and Zhang, Ziyu and Tian, Zhiqiang and Jia, Kang},
	year         = {2021},
	month        = {9},
	journal      = {Applied Mathematical Modelling},
	publisher    = {Elsevier Inc.},
	volume       = {97},
	pages        = {522--535},
	doi          = {10.1016/j.apm.2021.04.009},
	issn         = {0307904X},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0307904X21002092},
	keywords     = {Attention-Res-U-Net, Deep learning, Moving morphable component (MMC), Real-time optimization, Topology optimization}
}
@article{ZhengHeLiu2021,
	title        = {Generating three-dimensional structural topologies via a U-Net convolutional neural network},
	author       = {Zheng, Shuai and He, Zhenzhen and Liu, Honglei},
	year         = {2021},
	month        = {2},
	journal      = {Thin-Walled Structures},
	publisher    = {Elsevier Ltd},
	volume       = {159},
	pages        = {107263},
	doi          = {10.1016/j.tws.2020.107263},
	issn         = {02638231},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0263823120311319},
	keywords     = {Computational efficiency, Convolutional neural network, Three dimensions, Topology optimization, Variable design domain}
}
@article{zhou2008variational,
	title        = {A variational level set method for the topology optimization of steady-state Navier--Stokes flow},
	author       = {Zhou, Shiwei and Li, Qing},
	year         = {2008},
	journal      = {Journal of Computational Physics},
	publisher    = {Elsevier},
	volume       = {227},
	number       = {24},
	pages        = {10178--10195}
}
@article{zhou2021deepvit,
	title        = {Deepvit: Towards deeper vision transformer},
	author       = {Zhou, Daquan and Kang, Bingyi and Jin, Xiaojie and Yang, Linjie and Lian, Xiaochen and Jiang, Zihang and Hou, Qibin and Feng, Jiashi},
	year         = {2021},
	journal      = {arXiv preprint arXiv:2103.11886}
}
@article{Zhouetal2020,
	title        = {A new data-driven topology optimization framework for structural optimization},
	author       = {Zhou, Ying and Zhan, Haifei and Zhang, Weihong and Zhu, Jihong and Bai, Jinshuai and Wang, Qingxia and Gu, Yuantong},
	year         = {2020},
	month        = {10},
	journal      = {Computers {\&} Structures},
	publisher    = {Elsevier Ltd},
	volume       = {239},
	pages        = {106310},
	doi          = {10.1016/j.compstruc.2020.106310},
	issn         = {00457949},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0045794920301139},
	keywords     = {Constitutive model, Data-driven computational mechanics, Material data set, Moving least square, Topology optimization}
}
@article{ZhouRozvany1991,
	title        = {The COC algorithm, Part II: Topological, geometrical and generalized shape optimization},
	author       = {Zhou, M. and Rozvany, G.I.N.},
	year         = {1991},
	month        = {8},
	journal      = {Computer Methods in Applied Mechanics and Engineering},
	volume       = {89},
	number       = {1-3},
	pages        = {309--336},
	doi          = {10.1016/0045-7825(91)90046-9},
	issn         = {00457825},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/0045782591900469}
}
@article{zhu2016topology,
	title        = {Topology optimization in aircraft and aerospace structures design},
	author       = {Zhu, Ji-Hong and Zhang, Wei-Hong and Xia, Liang},
	year         = {2016},
	journal      = {Archives of Computational Methods in Engineering},
	publisher    = {Springer},
	volume       = {23},
	number       = {4},
	pages        = {595--622}
}
@inproceedings{zhu2017unpaired,
	title        = {Unpaired image-to-image translation using cycle-consistent adversarial networks},
	author       = {Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
	year         = {2017},
	booktitle    = {Proceedings of the IEEE international conference on computer vision},
	pages        = {2223--2232}
}
@article{ZhuGuoetal2021,
	title        = {Machine-specified ground structures for topology optimization of binary trusses using graph embedding policy network},
	author       = {Zhu, Shaojun and Ohsaki, Makoto and Hayashi, Kazuki and Guo, Xiaonong},
	year         = {2021},
	month        = {9},
	journal      = {Advances in Engineering Software},
	publisher    = {Elsevier Ltd},
	volume       = {159},
	pages        = {103032},
	doi          = {10.1016/j.advengsoft.2021.103032},
	issn         = {09659978},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0965997821000612},
	keywords     = {Binary trusses, Graph embedding, Machine-specified ground structures, Reinforcement learning, Topology optimization}
}
@inproceedings{zou20173d,
	title        = {3d-prnn: Generating shape primitives with recurrent neural networks},
	author       = {Zou, Chuhang and Yumer, Ersin and Yang, Jimei and Ceylan, Duygu and Hoiem, Derek},
	year         = {2017},
	booktitle    = {Proceedings of the IEEE International Conference on Computer Vision},
	pages        = {900--909}
}
