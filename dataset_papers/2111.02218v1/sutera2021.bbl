\begin{thebibliography}{28}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Archer and Kimes(2008)]{archer2008empirical}
Kellie~J Archer and Ryan~V Kimes.
\newblock Empirical characterization of random forest variable importance
  measures.
\newblock \emph{Computational statistics \& data analysis}, 52\penalty0
  (4):\penalty0 2249--2260, 2008.

\bibitem[Auret and Aldrich(2011)]{auret2011empirical}
Lidia Auret and Chris Aldrich.
\newblock Empirical comparison of tree ensemble variable importance measures.
\newblock \emph{Chemometrics and Intelligent Laboratory Systems}, 105\penalty0
  (2):\penalty0 157--170, 2011.

\bibitem[Besner(2019)]{besner2019axiomatizations}
Manfred Besner.
\newblock Axiomatizations of the proportional shapley value.
\newblock \emph{Theory and Decision}, 86\penalty0 (2):\penalty0 161--183, 2019.

\bibitem[Breiman(2001)]{breiman2001random}
Leo Breiman.
\newblock Random forests.
\newblock \emph{Machine learning}, 45\penalty0 (1):\penalty0 5--32, 2001.

\bibitem[Breiman et~al.(1984)Breiman, Friedman, Stone, and
  Olshen]{breiman1984classification}
Leo Breiman, Jerome Friedman, Charles~J Stone, and Richard~A Olshen.
\newblock \emph{Classification and regression trees}.
\newblock CRC press, 1984.

\bibitem[Cover and Thomas(2012)]{cover2012elements}
Thomas~M Cover and Joy~A Thomas.
\newblock \emph{Elements of Information Theory}.
\newblock John Wiley \& Sons, 2012.

\bibitem[Covert et~al.(2020)Covert, Lundberg, and Lee]{covert2020understanding}
Ian Covert, Scott Lundberg, and Su-In Lee.
\newblock Understanding global feature contributions with additive importance
  measures.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Genuer et~al.(2010)Genuer, Poggi, and
  Tuleau-Malot]{genuer2010variable}
Robin Genuer, Jean-Michel Poggi, and Christine Tuleau-Malot.
\newblock Variable selection using random forests.
\newblock \emph{Pattern recognition letters}, 31\penalty0 (14):\penalty0
  2225--2236, 2010.

\bibitem[Geurts et~al.(2006)Geurts, Ernst, and Wehenkel]{geurts2006extremely}
Pierre Geurts, Damien Ernst, and Louis Wehenkel.
\newblock Extremely randomized trees.
\newblock \emph{Machine learning}, 63\penalty0 (1):\penalty0 3--42, 2006.

\bibitem[Ishwaran et~al.(2007)]{ishwaran2007variable}
Hemant Ishwaran et~al.
\newblock Variable importance in binary regression trees and forests.
\newblock \emph{Electronic Journal of Statistics}, 1:\penalty0 519--537, 2007.

\bibitem[Izza et~al.(2020)Izza, Ignatiev, and
  Marques-Silva]{izza2020explaining}
Yacine Izza, Alexey Ignatiev, and Joao Marques-Silva.
\newblock On explaining decision trees.
\newblock \emph{arXiv preprint arXiv:2010.11034}, 2020.

\bibitem[Kohavi et~al.(1997)Kohavi, John, et~al.]{kohavi1997wrappers}
Ron Kohavi, George~H John, et~al.
\newblock Wrappers for feature subset selection.
\newblock \emph{Artificial intelligence}, 97\penalty0 (1-2):\penalty0 273--324,
  1997.

\bibitem[Li et~al.(2019)Li, Wang, Basu, Kumbier, and Yu]{li2019debiased}
Xiao Li, Yu~Wang, Sumanta Basu, Karl Kumbier, and Bin Yu.
\newblock A debiased mdi feature importance measure for random forests.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  8047--8057, 2019.

\bibitem[Louppe et~al.(2013)Louppe, Wehenkel, Sutera, and
  Geurts]{louppe2013understanding}
G.~Louppe, L.~Wehenkel, A.~Sutera, and P.~Geurts.
\newblock Understanding variable importances in forests of randomized trees.
\newblock In \emph{Advances in Neural Information Processing Systems 26}, pages
  431--439, 2013.

\bibitem[Louppe(2014)]{louppe2014understanding}
Gilles Louppe.
\newblock \emph{Understanding random forests: from theory to practice}.
\newblock PhD thesis, Universit{\'e} de Li{\`e}ge, Li{\`e}ge, Belgique, 2014.

\bibitem[Lundberg and Lee(2017)]{lundberg2017unified}
Scott~M Lundberg and Su-In Lee.
\newblock A unified approach to interpreting model predictions.
\newblock In \emph{Advances in neural information processing systems}, pages
  4765--4774, 2017.

\bibitem[Lundberg et~al.(2020)Lundberg, Erion, Chen, DeGrave, Prutkin, Nair,
  Katz, Himmelfarb, Bansal, and Lee]{lundberg2020local}
Scott~M Lundberg, Gabriel Erion, Hugh Chen, Alex DeGrave, Jordan~M Prutkin,
  Bala Nair, Ronit Katz, Jonathan Himmelfarb, Nisha Bansal, and Su-In Lee.
\newblock From local explanations to global understanding with explainable ai
  for trees.
\newblock \emph{Nature machine intelligence}, 2\penalty0 (1):\penalty0
  2522--5839, 2020.

\bibitem[Neto and Paulovich(2020)]{neto2020explainable}
M{\'a}rio~Popolin Neto and Fernando~V Paulovich.
\newblock Explainable matrix--visualization for global and local
  interpretability of random forest classification ensembles.
\newblock \emph{arXiv preprint arXiv:2005.04289}, 2020.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, et~al.]{pedregosa2011scikit}
Fabian Pedregosa, Ga{\"e}l Varoquaux, Alexandre Gramfort, Vincent Michel,
  Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
  Weiss, Vincent Dubourg, et~al.
\newblock Scikit-learn: Machine learning in python.
\newblock \emph{the Journal of machine Learning research}, 12:\penalty0
  2825--2830, 2011.

\bibitem[Saabas(2014)]{saabas2014interpreting}
Ando Saabas.
\newblock Interpreting random forests.
\newblock 2014.
\newblock URL \url{http://blog.datadive.net/interpreting-random-forests/}.
\newblock Last access: February 2021.

\bibitem[Scornet(2020)]{scornet2020trees}
Erwan Scornet.
\newblock Trees, forests, and impurity-based variable importance.
\newblock \emph{arXiv preprint arXiv:2001.04295}, 2020.

\bibitem[Shapley(1953)]{shapley1953value}
Lloyd~S Shapley.
\newblock A value for n-person games.
\newblock \emph{Contributions to the Theory of Games}, 2\penalty0
  (28):\penalty0 307--317, 1953.

\bibitem[Strobl et~al.(2007)Strobl, Boulesteix, Zeileis, and
  Hothorn]{strobl2007bias}
Carolin Strobl, Anne-Laure Boulesteix, Achim Zeileis, and Torsten Hothorn.
\newblock Bias in random forest variable importance measures: Illustrations,
  sources and a solution.
\newblock \emph{BMC bioinformatics}, 8\penalty0 (1):\penalty0 25, 2007.

\bibitem[Strumbelj and Kononenko(2010)]{strumbelj2010}
Erik Strumbelj and Igor Kononenko.
\newblock An efficient explanation of individual classifications using game
  theory.
\newblock \emph{J. Mach. Learn. Res.}, 11:\penalty0 1â€“18, March 2010.
\newblock ISSN 1532-4435.

\bibitem[Sutera(2019)]{sutera2019importance}
Antonio Sutera.
\newblock \emph{Importance measures derived from random forests:
  characterisation and extension}.
\newblock PhD thesis, Universit{\'e} de Li{\`e}ge, Li{\`e}ge, Belgique, 2019.

\bibitem[Sutera et~al.(2018)Sutera, Ch{\^a}tel, Louppe, Wehenkel, and
  Geurts]{sutera2018random}
Antonio Sutera, C{\'e}lia Ch{\^a}tel, Gilles Louppe, Louis Wehenkel, and Pierre
  Geurts.
\newblock Random subspace with trees for feature selection under memory
  constraints.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 929--937, 2018.

\bibitem[van~den Brink et~al.(2015)van~den Brink, Lev{\'\i}nsk{\`y}, and
  Zelen{\`y}]{van2015proper}
Ren{\'e} van~den Brink, Ren{\'e} Lev{\'\i}nsk{\`y}, and Miroslav Zelen{\`y}.
\newblock On proper shapley values for monotone tu-games.
\newblock \emph{International Journal of Game Theory}, 44\penalty0
  (2):\penalty0 449--471, 2015.

\bibitem[Young(1985)]{young1985monotonic}
H~Peyton Young.
\newblock Monotonic solutions of cooperative games.
\newblock \emph{International Journal of Game Theory}, 14\penalty0
  (2):\penalty0 65--72, 1985.

\end{thebibliography}
