\begin{thebibliography}{38}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aubry et~al.(2014)Aubry, Maturana, Efros, Russell, and Sivic]{Aubry14}
Mathieu Aubry, Daniel Maturana, Alexei Efros, Bryan Russell, and Josef Sivic.
\newblock Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large
  dataset of cad models.
\newblock In \emph{CVPR}, 2014.

\bibitem[Balasubramanian et~al.(2020)Balasubramanian, Kobyzev, Bahuleyan,
  Shapiro, and Vechtomova]{balasubramanian2020polarized}
Vikash Balasubramanian, Ivan Kobyzev, Hareesh Bahuleyan, Ilya Shapiro, and Olga
  Vechtomova.
\newblock Polarized-vae: Proximity based disentangled representation learning
  for text generation.
\newblock \emph{arXiv preprint arXiv:2004.10809}, 2020.

\bibitem[Bishop(2006)]{bishop2006pattern}
Christopher~M Bishop.
\newblock \emph{Pattern recognition and machine learning}.
\newblock Springer, 2006.

\bibitem[Blei et~al.(2017)Blei, Kucukelbir, and McAuliffe]{Blei2017VI}
David~M. Blei, Alp Kucukelbir, and Jon~D. McAuliffe.
\newblock Variational inference: A review for statisticians.
\newblock \emph{Journal of the American Statistical Association}, 112\penalty0
  (518):\penalty0 859--877, 2017.

\bibitem[Burgess et~al.(2018)Burgess, Higgins, Pal, Matthey, Watters,
  Desjardins, and Lerchner]{burgess2018understanding}
Christopher~P Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick Watters,
  Guillaume Desjardins, and Alexander Lerchner.
\newblock Understanding disentangling in $\beta $-vae.
\newblock \emph{arXiv preprint arXiv:1804.03599}, 2018.

\bibitem[Chen et~al.(2018)Chen, Li, Grosse, and Duvenaud]{chen2018isolating}
Tian~Qi Chen, Xuechen Li, Roger~B Grosse, and David~K Duvenaud.
\newblock Isolating sources of disentanglement in variational autoencoders.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2610--2620, 2018.

\bibitem[Dai and Wipf(2019)]{dai2019diagnosing}
Bin Dai and David Wipf.
\newblock Diagnosing and enhancing vae models.
\newblock \emph{arXiv preprint arXiv:1903.05789}, 2019.

\bibitem[Dieng et~al.(2017)Dieng, Tran, Ranganath, Paisley, and
  Blei]{dieng2017variational}
Adji~Bousso Dieng, Dustin Tran, Rajesh Ranganath, John Paisley, and David Blei.
\newblock Variational inference via $\chi$ upper bound minimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2732--2741, 2017.

\bibitem[Germain et~al.(2015)Germain, Gregor, Murray, and
  Larochelle]{germain2015made}
Mathieu Germain, Karol Gregor, Iain Murray, and Hugo Larochelle.
\newblock Made: Masked autoencoder for distribution estimation.
\newblock In \emph{International Conference on Machine Learning}, pages
  881--889, 2015.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pages
  2672--2680, 2014.

\bibitem[Gretton et~al.(2012)Gretton, Borgwardt, Rasch, Sch{\"o}lkopf, and
  Smola]{gretton2012kernel}
Arthur Gretton, Karsten~M Borgwardt, Malte~J Rasch, Bernhard Sch{\"o}lkopf, and
  Alexander Smola.
\newblock A kernel two-sample test.
\newblock \emph{Journal of Machine Learning Research}, 13\penalty0
  (Mar):\penalty0 723--773, 2012.

\bibitem[Hensman et~al.(2014)Hensman, Zwie{\ss}ele, and
  Lawrence]{hensman2014tilted}
James Hensman, Max Zwie{\ss}ele, and Neil Lawrence.
\newblock Tilted variational bayes.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 356--364,
  2014.

\bibitem[Higgins et~al.(2017)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{higgins2017beta}
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot,
  Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock \emph{Iclr}, 2\penalty0 (5):\penalty0 6, 2017.

\bibitem[Huang et~al.(2018)Huang, Tan, Lacoste, and
  Courville]{Huang2018Anneling}
Chin-Wei Huang, Shawn Tan, Alexandre Lacoste, and Aaron~C Courville.
\newblock Improving explorability in variational inference with annealed
  variational objectives.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, \emph{Advances in Neural Information Processing
  Systems 31}, pages 9701--9711. Curran Associates, Inc., 2018.

\bibitem[Karush(1939)]{karush1939minima}
William Karush.
\newblock Minima of functions of several variables with inequalities as side
  constraints.
\newblock \emph{M. Sc. Dissertation. Dept. of Mathematics, Univ. of Chicago},
  1939.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma and Welling(2014)]{kingma2013auto}
Diederik~P. Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock In \emph{ICLR 2014}, 2014.
\newblock URL \url{abs/1312.6114}.

\bibitem[Kuhn and Tucker(2014)]{kuhn2014nonlinear}
Harold~W Kuhn and Albert~W Tucker.
\newblock Nonlinear programming.
\newblock In \emph{Traces and emergence of nonlinear programming}, pages
  247--258. Springer, 2014.

\bibitem[Kullback and Leibler(1951)]{kullback1951information}
Solomon Kullback and Richard~A Leibler.
\newblock On information and sufficiency.
\newblock \emph{The annals of mathematical statistics}, 22\penalty0
  (1):\penalty0 79--86, 1951.

\bibitem[Larochelle and Murray(2011)]{larochelle2011neural}
Hugo Larochelle and Iain Murray.
\newblock The neural autoregressive distribution estimator.
\newblock In \emph{Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics}, pages 29--37, 2011.

\bibitem[LeCun et~al.(2010)LeCun, Cortes, and Burges]{mnist}
Yann LeCun, Corinna Cortes, and CJ~Burges.
\newblock Mnist handwritten digit database.
\newblock \emph{ATT Labs [Online]. Available:
  http://yann.lecun.com/exdb/mnist}, 2, 2010.

\bibitem[Li and Turner(2016)]{Li2016Renyi}
Yingzhen Li and Richard~E Turner.
\newblock R\'{e}nyi divergence variational inference.
\newblock In D.~D. Lee, M.~Sugiyama, U.~V. Luxburg, I.~Guyon, and R.~Garnett,
  editors, \emph{Advances in Neural Information Processing Systems 29}, pages
  1073--1081. Curran Associates, Inc., 2016.

\bibitem[Lin(1991)]{lin1991divergence}
Jianhua Lin.
\newblock Divergence measures based on the shannon entropy.
\newblock \emph{IEEE Transactions on Information theory}, 37\penalty0
  (1):\penalty0 145--151, 1991.

\bibitem[Lucas et~al.(2019)Lucas, Tucker, Grosse, and
  Norouzi]{Lucas2019UnderstandingPC}
James Lucas, George Tucker, Roger~Baker Grosse, and Mohammad Norouzi.
\newblock Understanding posterior collapse in generative latent variable
  models.
\newblock In \emph{DGS@ICLR}, 2019.

\bibitem[Matthey et~al.(2017)Matthey, Higgins, Hassabis, and
  Lerchner]{dsprites17}
Loic Matthey, Irina Higgins, Demis Hassabis, and Alexander Lerchner.
\newblock dsprites: Disentanglement testing sprites dataset.
\newblock https://github.com/deepmind/dsprites-dataset/, 2017.

\bibitem[Murphy(2012)]{murphy2012machine}
Kevin~P Murphy.
\newblock \emph{Machine learning: a probabilistic perspective}.
\newblock MIT press, 2012.

\bibitem[Neal(2012)]{neal2012bayesian}
Radford~M Neal.
\newblock \emph{Bayesian learning for neural networks}, volume 118.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Niculescu and Persson(2006)]{niculescu2006convex}
Constantin Niculescu and Lars-Erik Persson.
\newblock \emph{Convex functions and their applications}.
\newblock Springer, 2006.

\bibitem[Nielsen(2010)]{nielsen2010family}
Frank Nielsen.
\newblock A family of statistical symmetric divergences based on jensen's
  inequality.
\newblock \emph{arXiv preprint arXiv:1009.4004}, 2010.

\bibitem[Nielsen(2019)]{nielsen2019jensen}
Frank Nielsen.
\newblock On the jensen--shannon symmetrization of distances relying on
  abstract means.
\newblock \emph{Entropy}, 21\penalty0 (5):\penalty0 485, 2019.

\bibitem[Nielsen and Garcia(2009)]{nielsen2009statistical}
Frank Nielsen and Vincent Garcia.
\newblock Statistical exponential families: A digest with flash cards.
\newblock \emph{arXiv preprint arXiv:0911.4863}, 2009.

\bibitem[Nishiyama(2018)]{nishiyama2018generalized}
Tomohiro Nishiyama.
\newblock Generalized bregman and jensen divergences which include some
  f-divergences.
\newblock \emph{arXiv preprint arXiv:1808.06148}, 2018.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pages
  8024--8035. Curran Associates, Inc., 2019.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In \emph{Proceedings of the 31st International Conference on Machine
  Learning}, volume~32 of \emph{Proceedings of Machine Learning Research},
  pages 1278--1286. PMLR, 2014.

\bibitem[Sutter et~al.(2019)Sutter, Daunhawer, and Vogt]{sutter2019multimodal}
Thomas Sutter, Imant Daunhawer, and Julia~E Vogt.
\newblock Multimodal generative learning utilizing jensen-shannon divergence.
\newblock In \emph{Workshop on Visually Grounded Interaction and Language at
  the 33rd Conference on Neural Information Processing Systems (NeurIPS 2019)},
  2019.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017Online}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms, 2017.

\bibitem[Zhang et~al.(2019)Zhang, Bird, Habib, Xu, and
  Barber]{zhang2019variational}
Mingtian Zhang, Thomas Bird, Raza Habib, Tianlin Xu, and David Barber.
\newblock Variational f-divergence minimization.
\newblock \emph{arXiv preprint arXiv:1907.11891}, 2019.

\bibitem[Zhao et~al.(2019)Zhao, Song, and Ermon]{zhao2017infovae}
Shengjia Zhao, Jiaming Song, and Stefano Ermon.
\newblock Infovae: Balancing learning and inference in variational
  autoencoders.
\newblock In \emph{The Thirty-Third {AAAI} Conference on Artificial
  Intelligence, {AAAI} 2019, Honolulu, Hawaii, USA}, pages 5885--5892. {AAAI}
  Press, Palo Alto, CA, USA, 2019.

\end{thebibliography}
