@inproceedings{dai2023refined,
  title={Refined regret for adversarial mdps with linear function approximation},
  author={Dai, Yan and Luo, Haipeng and Wei, Chen-Yu and Zimmert, Julian},
  booktitle={International Conference on Machine Learning},
  pages={6726--6759},
  year={2023},
  organization={PMLR}
}

@article{mhammedi2024power,
  title={The Power of Resets in Online Reinforcement Learning},
  author={Mhammedi, Zakaria and Foster, Dylan J and Rakhlin, Alexander},
  journal={arXiv preprint arXiv:2404.15417},
  year={2024}
}

@article{mhammedi2023efficient,
  title={Efficient Model-Free Exploration in Low-Rank MDPs},
  author={Mhammedi, Zakaria and Block, Adam and Foster, Dylan J and Rakhlin, Alexander},
  journal={arXiv preprint arXiv:2307.03997},
  year={2023}
}

@article{luo2021policy,
  title={Policy optimization in adversarial mdps: Improved exploration via dilated bonuses},
  author={Luo, Haipeng and Wei, Chen-Yu and Lee, Chung-Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={22931--22942},
  year={2021}
}

@inproceedings{ayoub2020model,
  title={Model-based reinforcement learning with value-targeted regression},
  author={Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin},
  booktitle={International Conference on Machine Learning},
  pages={463--474},
  year={2020},
  organization={PMLR}
}


@article{zhao2024learning,
  title={Learning adversarial low-rank markov decision processes with unknown transition and full-information feedback},
  author={Zhao, Canzhe and Yang, Ruofeng and Wang, Baoxiang and Zhang, Xuezhou and Li, Shuai},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}


@inproceedings{sun2019model,
  title={Model-based rl in contextual decision processes: Pac bounds and exponential improvements over model-free approaches},
  author={Sun, Wen and Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  booktitle={Conference on learning theory},
  pages={2898--2933},
  year={2019},
  organization={PMLR}
}

@article{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{pathak2017curiosity,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={International conference on machine learning},
  pages={2778--2787},
  year={2017},
  organization={PMLR}
}

@article{tang2017exploration,
  title={\# exploration: A study of count-based exploration for deep reinforcement learning},
  author={Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Xi Chen, OpenAI and Duan, Yan and Schulman, John and DeTurck, Filip and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@inproceedings{laskin2020curl,
  title={Curl: Contrastive unsupervised representations for reinforcement learning},
  author={Laskin, Michael and Srinivas, Aravind and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={5639--5650},
  year={2020},
  organization={PMLR}
}

@article{silver2018general,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}


@inproceedings{stooke2021decoupling,
  title={Decoupling representation learning from reinforcement learning},
  author={Stooke, Adam and Lee, Kimin and Abbeel, Pieter and Laskin, Michael},
  booktitle={International Conference on Machine Learning},
  pages={9870--9879},
  year={2021},
  organization={PMLR}
}

@inproceedings{yang2021representation,
  title={Representation matters: Offline pretraining for sequential decision making},
  author={Yang, Mengjiao and Nachum, Ofir},
  booktitle={International Conference on Machine Learning},
  pages={11784--11794},
  year={2021},
  organization={PMLR}
}

@article{foster2024model,
  title={Model-free reinforcement learning with the decision-estimation coefficient},
  author={Foster, Dylan J and Golowich, Noah and Qian, Jian and Rakhlin, Alexander and Sekhari, Ayush},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{abbeel2005exploration,
  title={Exploration and apprenticeship learning in reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={1--8},
  year={2005}
}s


@article{padakandla2020reinforcement,
  title={Reinforcement learning algorithm for non-stationary environments},
  author={Padakandla, Sindhu and KJ, Prabuchandran and Bhatnagar, Shalabh},
  journal={Applied Intelligence},
  volume={50},
  number={11},
  pages={3590--3606},
  year={2020},
  publisher={Springer}
}

@inproceedings{kalashnikov2018scalable,
  title={Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on robot learning},
  pages={651--673},
  year={2018},
  organization={PMLR}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{foster2023tight,
  title={Tight guarantees for interactive decision making with the decision-estimation coefficient},
  author={Foster, Dylan J and Golowich, Noah and Han, Yanjun},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={3969--4043},
  year={2023},
  organization={PMLR}
}

@inproceedings{bubeck2012towards,
  title={Towards minimax policies for online linear optimization with bandit feedback},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and Kakade, Sham M},
  booktitle={Conference on Learning Theory},
  pages={41--1},
  year={2012},
  organization={JMLR Workshop and Conference Proceedings}
}


@article{kong2023improved,
  title={Improved Regret Bounds for Linear Adversarial MDPs via Linear Optimization},
  author={Kong, Fang and Zhang, Xiangcheng and Wang, Baoxiang and Li, Shuai},
  journal={arXiv preprint arXiv:2302.06834},
  year={2023}
}


@inproceedings{jin2020learning,
  title={Learning adversarial markov decision processes with bandit feedback and unknown transition},
  author={Jin, Chi and Jin, Tiancheng and Luo, Haipeng and Sra, Suvrit and Yu, Tiancheng},
  booktitle={International Conference on Machine Learning},
  pages={4860--4869},
  year={2020},
  organization={PMLR}
}

@article{olkhovskaya2023first,
  title={First-and Second-Order Bounds for Adversarial Linear Contextual Bandits},
  author={Olkhovskaya, Julia and Mayo, Jack and van Erven, Tim and Neu, Gergely and Wei, Chen-Yu},
  journal={arXiv preprint arXiv:2305.00832},
  year={2023}
}

@article{neu2014online,
  title={Online combinatorial optimization with stochastic decision sets and adversarial losses},
  author={Neu, Gergely and Valko, Michal},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  year={2014}
}

@techreport{khachiyan1990complexity,
  title={On the complexity of approximating the maximal inscribed ellipsoid for a polytope},
  author={Khachiyan, Leonid G and Todd, Michael J},
  year={1990},
  institution={Cornell University Operations Research and Industrial Engineering}
}

@inproceedings{saha2020improved,
  title={Improved sleeping bandits with stochastic action sets and adversarial rewards},
  author={Saha, Aadirupa and Gaillard, Pierre and Valko, Michal},
  booktitle={International Conference on Machine Learning},
  pages={8357--8366},
  year={2020},
  organization={PMLR}
}

@article{foster2022note,
  title={Model-Free Reinforcement Learning with the Decision-Estimation Coefficient},
  author={Foster, Dylan J and Golowich, Noah and Qian, Jian and Rakhlin, Alexander and Sekhari, Ayush},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}

@inproceedings{kanade2009sleeping,
  title={Sleeping experts and bandits with stochastic action availability and adversarial rewards},
  author={Kanade, Varun and McMahan, H Brendan and Bryan, Brent},
  booktitle={Artificial Intelligence and Statistics},
  pages={272--279},
  year={2009},
  organization={PMLR}
}

@article{kleinberg2010regret,
  title={Regret bounds for sleeping experts and bandits},
  author={Kleinberg, Robert and Niculescu-Mizil, Alexandru and Sharma, Yogeshwer},
  journal={Machine learning},
  volume={80},
  number={2-3},
  pages={245--272},
  year={2010},
  publisher={Springer}
}

@article{auer2002nonstochastic,
  title={The nonstochastic multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  journal={SIAM journal on computing},
  volume={32},
  number={1},
  pages={48--77},
  year={2002},
  publisher={SIAM}
}

@inproceedings{sherman2023improved,
  title={Improved Regret for Efficient Online Reinforcement Learning with Linear Function Approximation},
  author={Sherman, Uri and Koren, Tomer and Mansour, Yishay},
  booktitle={International Conference on Machine Learning},
  year={2023}
}

@inproceedings{abernethy2009competing,
  title={Competing in the dark: An efficient algorithm for bandit linear optimization},
  author={Abernethy, Jacob D and Hazan, Elad and Rakhlin, Alexander},
booktitle={Conference on Learning Theory},
  year={2009}
}

@inproceedings{hazan2016computational,
  title={The computational power of optimization in online learning},
  author={Hazan, Elad and Koren, Tomer},
  booktitle={Proceedings of the forty-eighth annual ACM symposium on Theory of Computing},
  pages={128--141},
  year={2016}
}

@inproceedings{emamjomeh2021adversarial,
  title={Adversarial online learning with changing action sets: Efficient algorithms with approximate regret bounds},
  author={Emamjomeh-Zadeh, Ehsan and Wei, Chen-Yu and Luo, Haipeng and Kempe, David},
  booktitle={Algorithmic Learning Theory},
  pages={599--618},
  year={2021},
  organization={PMLR}
}

@inproceedings{chen2019new,
  title={A new algorithm for non-stationary contextual bandits: Efficient, optimal and parameter-free},
  author={Chen, Yifang and Lee, Chung-Wei and Luo, Haipeng and Wei, Chen-Yu},
  booktitle={Conference on Learning Theory},
  pages={696--726},
  year={2019},
  organization={PMLR}
}

@inproceedings{luo2018efficient,
  title={Efficient contextual bandits in non-stationary worlds},
  author={Luo, Haipeng and Wei, Chen-Yu and Agarwal, Alekh and Langford, John},
  booktitle={Conference On Learning Theory},
  pages={1739--1776},
  year={2018},
  organization={PMLR}
}

@article{kanade2014learning,
  title={Learning hurdles for sleeping experts},
  author={Kanade, Varun and Steinke, Thomas},
  journal={ACM Transactions on Computation Theory (TOCT)},
  volume={6},
  number={3},
  pages={1--16},
  year={2014},
  publisher={ACM New York, NY, USA}
}

@misc{linearalgebra,
  title = {Stack Exchange: If the matrix such $B-A$, $A$ is positive-semidefinite, then $\sqrt{B}-\sqrt{A}$ is positive-semidefinite},
 author = {Auld, Eric and Math110},
  howpublished = {\url{https://math.stackexchange.com/questions/585772/if-the-matrix-such-b-a-a-is-positive-semidefinite-then-sqrtb-sqrta-is?noredirect=1&lq=1}}, 
  year = {2013}
}



@inproceedings{rakhlin2013online,
  title={Online learning with predictable sequences},
  author={Rakhlin, Alexander and Sridharan, Karthik},
  booktitle={Conference on Learning Theory},
  pages={993--1019},
  year={2013},
  organization={PMLR}
}

@inproceedings{wei2022model,
  title={A model selection approach for corruption robust reinforcement learning},
  author={Wei, Chen-Yu and Dann, Christoph and Zimmert, Julian},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={1043--1096},
  year={2022},
  organization={PMLR}
}

@inproceedings{bubeck2019improved,
  title={Improved path-length regret bounds for bandits},
  author={Bubeck, S{\'e}bastien and Li, Yuanzhi and Luo, Haipeng and Wei, Chen-Yu},
  booktitle={Conference On Learning Theory},
  pages={508--528},
  year={2019},
  organization={PMLR}
}

@inproceedings{lee2020bias,
  title={Bias no more: high-probability data-dependent regret bounds for adversarial bandits and MDPs},
  author={Lee, Chung-Wei and Luo, Haipeng and Wei, Chen-Yu and Zhang, Mengxiao},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@article{ito2020tight,
  title={Tight first-and second-order regret bounds for adversarial linear bandits},
  author={Ito, Shinji and Hirahara, Shuichi and Soma, Tasuku and Yoshida, Yuichi},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2028--2038},
  year={2020}
}

@article{foster2020adapting,
  title={Adapting to misspecification in contextual bandits},
  author={Foster, Dylan J and Gentile, Claudio and Mohri, Mehryar and Zimmert, Julian},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11478--11489},
  year={2020}
}

@inproceedings{neu2020efficient,
  title={Efficient and robust algorithms for adversarial linear contextual bandits},
  author={Neu, Gergely and Olkhovskaya, Julia},
  booktitle={Conference on Learning Theory},
  pages={3049--3068},
  year={2020},
  organization={PMLR}
}

@article{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  journal={Advances in neural information processing systems},
  volume={24},
  pages={2312--2320},
  year={2011}
}

@inproceedings{li2019nearly,
  title={Nearly minimax-optimal regret for linearly parameterized bandits},
  author={Li, Yingkai and Wang, Yining and Zhou, Yuan},
  booktitle={Conference on Learning Theory},
  pages={2173--2174},
  year={2019},
  organization={PMLR}
}

@inproceedings{li2021tight,
  title={Tight regret bounds for infinite-armed linear contextual bandits},
  author={Li, Yingkai and Wang, Yining and Chen, Xi and Zhou, Yuan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={370--378},
  year={2021},
  organization={PMLR}
}

@article{zhang2021variance,
  title={Variance-Aware Confidence Set: Variance-Dependent Bound for Linear Bandits and Horizon-Free Bound for Linear Mixture MDP},
  author={Zhang, Zihan and Yang, Jiaqi and Ji, Xiangyang and Du, Simon S},
  journal={arXiv preprint arXiv:2101.12745},
  year={2021}
}

@inproceedings{allen2018make,
  title={Make the minority great again: First-order regret bound for contextual bandits},
  author={Allen-Zhu, Zeyuan and Bubeck, S{\'e}bastien and Li, Yuanzhi},
  booktitle={International Conference on Machine Learning},
  pages={186--194},
  year={2018},
  organization={PMLR}
}
@inproceedings{wei2020taking,
  title={Taking a hint: How to leverage loss predictors in contextual bandits?},
  author={Wei, Chen-Yu and Luo, Haipeng and Agarwal, Alekh},
  booktitle={Conference on Learning Theory},
  pages={3583--3634},
  year={2020},
  organization={PMLR}
}

@inproceedings{foster2021efficient,
  title={Efficient First-Order Contextual Bandits: Prediction, Allocation, and Triangular Discrimination},
  author={Foster, Dylan J and Krishnamurthy, Akshay},
  booktitle={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{hanna2022contexts,
  title={Contexts can be Cheap: Solving Stochastic Contextual Bandits with Linear Bandit Algorithms},
  author={Hanna, Osama A and Yang, Lin F and Fragouli, Christina},
  journal={arXiv preprint arXiv:2211.05632},
  year={2022}
}

@inproceedings{zimmert2022return,
  title={Return of the bias: Almost minimax optimal high probability bounds for adversarial linear bandits},
  author={Zimmert, Julian and Lattimore, Tor},
  booktitle={Conference on Learning Theory},
  pages={3285--3312},
  year={2022},
  organization={PMLR}
}

@inproceedings{dann2023blackbox,
  title={A Blackbox Approach to Best of Both Worlds in Bandits and Beyond},
  author={Dann, Christoph and Wei, Chen-Yu and Zimmert, Julian},
  booktitle={Conference on Learning Theory},
  year={2023}
}


@misc{Matrix_Jensen_inequality,
  title = {Stack exchange: Jensen's inequality over definite positive matrices.},
  howpublished = {\url{https://math.stackexchange.com/questions/3322556/jensens-inequality-over-definite-positive-matrices}}
}

@misc{Anonymous_corruption,
  title = {Anonymous},
  year = {2023}
}



@inproceedings{wei2018more,
  title={More adaptive algorithms for adversarial bandits},
  author={Wei, Chen-Yu and Luo, Haipeng},
  booktitle={Conference on Learning Theory},
  pages={1263--1291},
  year={2018},
  organization={PMLR}
}

@article{sherman2023rate,
  title={Rate-Optimal Policy Optimization for Linear Markov Decision Processes},
  author={Sherman, Uri and Cohen, Alon and Koren, Tomer and Mansour, Yishay},
  journal={arXiv preprint arXiv:2308.14642},
  year={2023}
}

@inproceedings{wagenmaker2022reward,
  title={Reward-free rl is no harder than reward-aware rl in linear markov decision processes},
  author={Wagenmaker, Andrew J and Chen, Yifang and Simchowitz, Max and Du, Simon and Jamieson, Kevin},
  booktitle={International Conference on Machine Learning},
  pages={22430--22456},
  year={2022},
  organization={PMLR}
}

@article{nemirovski2004interior,
  title={Interior point polynomial time methods in convex programming},
  author={Nemirovski, Arkadi},
  journal={Lecture notes},
  volume={42},
  number={16},
  pages={3215--3224},
  year={2004},
  publisher={Citeseer}
}

@inproceedings{agrawal2013thompson,
  title={Thompson sampling for contextual bandits with linear payoffs},
  author={Agrawal, Shipra and Goyal, Navin},
  booktitle={International conference on machine learning},
  pages={127--135},
  year={2013},
  organization={PMLR}
}

@inproceedings{luo2022corralling,
  title={Corralling a larger band of bandits: A case study on switching regret for linear bandits},
  author={Luo, Haipeng and Zhang, Mengxiao and Zhao, Peng and Zhou, Zhi-Hua},
  booktitle={Conference on Learning Theory},
  pages={3635--3684},
  year={2022},
  organization={PMLR}
}

@inproceedings{chen2022policy,
  title={Policy optimization for stochastic shortest path},
  author={Chen, Liyu and Luo, Haipeng and Rosenberg, Aviv},
  booktitle={Conference on Learning Theory},
  pages={982--1046},
  year={2022},
  organization={PMLR}
}

@inproceedings{dann2023best,
  title={Best of Both Worlds Policy Optimization},
  author={Dann, Christoph and Wei, Chen-Yu and Zimmert, Julian},
  booktitle={International Conference on Machine Learning},
  year={2023}
}

@inproceedings{zhu2022contextual,
  title={Contextual bandits with large action spaces: Made practical},
  author={Zhu, Yinglun and Foster, Dylan J and Langford, John and Mineiro, Paul},
  booktitle={International Conference on Machine Learning},
  pages={27428--27453},
  year={2022},
  organization={PMLR}
}

@article{rosenberg2019online,
  title={Online stochastic shortest path with bandit feedback and unknown transition function},
  author={Rosenberg, Aviv and Mansour, Yishay},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{dai2022follow,
  title={Follow-the-perturbed-leader for adversarial markov decision processes with bandit feedback},
  author={Dai, Yan and Luo, Haipeng and Chen, Liyu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={11437--11449},
  year={2022}
}

@inproceedings{he2022near,
  title={Near-optimal policy optimization algorithms for learning adversarial linear mixture mdps},
  author={He, Jiafan and Zhou, Dongruo and Gu, Quanquan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4259--4280},
  year={2022},
  organization={PMLR}
}

@inproceedings{chen2021finding,
  title={Finding the stochastic shortest path with low regret: The adversarial cost and unknown transition case},
  author={Chen, Liyu and Luo, Haipeng},
  booktitle={International Conference on Machine Learning},
  pages={1651--1660},
  year={2021},
  organization={PMLR}
}

@article{jin2021best,
  title={The best of both worlds: stochastic and adversarial episodic mdps with unknown transition},
  author={Jin, Tiancheng and Huang, Longbo and Luo, Haipeng},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={20491--20502},
  year={2021}
}

@article{jin2023no,
  title={No-Regret Online Reinforcement Learning with Adversarial Losses and Transitions},
  author={Jin, Tiancheng and Liu, Junyan and Rouyer, Chlo{\'e} and Chang, William and Wei, Chen-Yu and Luo, Haipeng},
  journal={arXiv preprint arXiv:2305.17380},
  year={2023}
}

@inproceedings{cai2020provably,
  title={Provably efficient exploration in policy optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={1283--1294},
  year={2020},
  organization={PMLR}
}

@article{foster2022complexity,
  title={On the complexity of adversarial decision making},
  author={Foster, Dylan J and Rakhlin, Alexander and Sekhari, Ayush and Sridharan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={35404--35417},
  year={2022}
}

@inproceedings{zhao2022mixture,
  title={Learning Adversarial Linear Mixture Markov Decision Processes with Bandit Feedback and Unknown Transition},
  author={Zhao, Canzhe and Yang, Ruofeng and Wang, Baoxiang and Li, Shuai},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@inproceedings{agarwal2017corralling,
  title={Corralling a band of bandit algorithms},
  author={Agarwal, Alekh and Luo, Haipeng and Neyshabur, Behnam and Schapire, Robert E},
  booktitle={Conference on Learning Theory},
  pages={12--38},
  year={2017},
  organization={PMLR}
}
@inproceedings{chu2011contextual,
  title={Contextual bandits with linear payoff functions},
  author={Chu, Wei and Li, Lihong and Reyzin, Lev and Schapire, Robert},
  booktitle={Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages={208--214},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{foster2021statistical,
  title={The statistical complexity of interactive decision making},
  author={Foster, Dylan J and Kakade, Sham M and Qian, Jian and Rakhlin, Alexander},
  journal={arXiv preprint arXiv:2112.13487},
  year={2021}
}

@article{zhong2022gec,
  title={Gec: A unified framework for interactive decision making in mdp, pomdp, and beyond},
  author={Zhong, Han and Xiong, Wei and Zheng, Sirui and Wang, Liwei and Wang, Zhaoran and Yang, Zhuoran and Zhang, Tong},
  journal={arXiv preprint arXiv:2211.01962},
  year={2022}
}

@inproceedings{zhang2022making,
  title={Making linear mdps practical via contrastive representation learning},
  author={Zhang, Tianjun and Ren, Tongzheng and Yang, Mengjiao and Gonzalez, Joseph and Schuurmans, Dale and Dai, Bo},
  booktitle={International Conference on Machine Learning},
  pages={26447--26466},
  year={2022},
  organization={PMLR}
}

@inproceedings{foster2021instance,
  title={Instance-Dependent Complexity of Contextual Bandits and Reinforcement Learning: A Disagreement-Based Perspective},
  author={Foster, Dylan and Rakhlin, Alexander and Simchi-Levi, David and Xu, Yunzong},
  booktitle={Conference on Learning Theory},
  pages={2059--2059},
  year={2021},
  organization={PMLR}
}

@inproceedings{rakhlin2016bistro,
  title={Bistro: An efficient relaxation-based method for contextual bandits},
  author={Rakhlin, Alexander and Sridharan, Karthik},
  booktitle={International Conference on Machine Learning},
  pages={1977--1985},
  year={2016},
  organization={PMLR}
}

@article{syrgkanis2016improved,
  title={Improved regret bounds for oracle-based adversarial contextual bandits},
  author={Syrgkanis, Vasilis and Luo, Haipeng and Krishnamurthy, Akshay and Schapire, Robert E},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}

@article{neu2021online,
  title={Online learning in MDPs with linear function approximation and bandit feedback.},
  author={Neu, Gergely and Olkhovskaya, Julia},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={10407--10417},
  year={2021}
}

@inproceedings{syrgkanis2016efficient,
  title={Efficient algorithms for adversarial contextual learning},
  author={Syrgkanis, Vasilis and Krishnamurthy, Akshay and Schapire, Robert},
  booktitle={International Conference on Machine Learning},
  pages={2159--2168},
  year={2016},
  organization={PMLR}
}

@inproceedings{foster2020beyond,
  title={Beyond ucb: Optimal and efficient contextual bandits with regression oracles},
  author={Foster, Dylan and Rakhlin, Alexander},
  booktitle={International Conference on Machine Learning},
  pages={3199--3210},
  year={2020},
  organization={PMLR}
}

@inproceedings{foster2018practical,
  title={Practical contextual bandits with regression oracles},
  author={Foster, Dylan and Agarwal, Alekh and Dud{\'\i}k, Miroslav and Luo, Haipeng and Schapire, Robert},
  booktitle={International Conference on Machine Learning},
  pages={1539--1548},
  year={2018},
  organization={PMLR}
}

@article{li2022understanding,
  title={Understanding the Eluder Dimension},
  author={Li, Gene and Kamath, Pritish and Foster, Dylan J and Srebro, Nati},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23737--23750},
  year={2022}
}


@article{jin2021bellman,
  title={Bellman eluder dimension: New rich classes of rl problems, and sample-efficient algorithms},
  author={Jin, Chi and Liu, Qinghua and Miryoosefi, Sobhan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13406--13418},
  year={2021}
}

@article{russo2013eluder,
  title={Eluder dimension and the sample complexity of optimistic exploration},
  author={Russo, Daniel and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  year={2013}
}

@inproceedings{zhao2023variance,
  title={Variance-Dependent Regret Bounds for Linear Bandits and Reinforcement Learning: Adaptivity and Computational Efficiency},
  author={Zhao, Heyang and He, Jiafan and Zhou, Dongruo and Zhang, Tong and Gu, Quanquan},
  booktitle={Conference on Learning Theory},
  year={2023}
}

@article{xu2020upper,
  title={Upper counterfactual confidence bounds: a new optimism principle for contextual bandits},
  author={Xu, Yunbei and Zeevi, Assaf},
  journal={arXiv preprint arXiv:2007.07876},
  year={2020}
}

@article{simchi2022bypassing,
  title={Bypassing the monster: A faster and simpler optimal algorithm for contextual bandits under realizability},
  author={Simchi-Levi, David and Xu, Yunzong},
  journal={Mathematics of Operations Research},
  volume={47},
  number={3},
  pages={1904--1931},
  year={2022},
  publisher={INFORMS}
}

@inproceedings{du2021bilinear,
  title={Bilinear classes: A structural framework for provable generalization in rl},
  author={Du, Simon and Kakade, Sham and Lee, Jason and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={2826--2836},
  year={2021},
  organization={PMLR}
}

@inproceedings{agarwal2012contextual,
  title={Contextual bandit learning with predictable rewards},
  author={Agarwal, Alekh and Dud{\'\i}k, Miroslav and Kale, Satyen and Langford, John and Schapire, Robert},
  booktitle={Artificial Intelligence and Statistics},
  pages={19--26},
  year={2012},
  organization={PMLR}
}

@inproceedings{agarwal2014taming,
  title={Taming the monster: A fast and simple algorithm for contextual bandits},
  author={Agarwal, Alekh and Hsu, Daniel and Kale, Satyen and Langford, John and Li, Lihong and Schapire, Robert},
  booktitle={International Conference on Machine Learning},
  pages={1638--1646},
  year={2014},
  organization={PMLR}
}

@inproceedings{dudik2011efficient,
  title={Efficient optimal learning for contextual bandits},
  author={Dudik, M and Hsu, D and Kale, S and Karampatziakis, N and Langford, J and Reyzin, L and Zhang, T},
  booktitle={Proceedings of the 27th Conference on Uncertainty in Artificial Intelligence, UAI 2011},
  pages={169},
  year={2011}
}

@article{langford2007epoch,
  title={The epoch-greedy algorithm for contextual multi-armed bandits},
  author={Langford, John and Zhang, Tong},
  journal={Advances in neural information processing systems},
  volume={20},
  number={1},
  pages={96--1},
  year={2007},
  publisher={Citeseer}
}

@inproceedings{abernethy2009beating,
  title={Beating the adaptive bandit with high probability},
  author={Abernethy, Jacob and Rakhlin, Alexander},
  booktitle={2009 Information Theory and Applications Workshop},
  pages={280--289},
  year={2009},
  organization={IEEE}
}

@inproceedings{bartlett2008high,
  title={High-Probability Regret Bounds for Bandit Online Linear Optimization.},
  author={Bartlett, Peter L and Dani, Varsha and Hayes, Thomas P and Kakade, Sham M and Rakhlin, Alexander and Tewari, Ambuj},
  booktitle={COLT},
  pages={335--342},
  year={2008}
}

@inproceedings{beygelzimer2011contextual,
  title={Contextual bandit algorithms with supervised learning guarantees},
  author={Beygelzimer, Alina and Langford, John and Li, Lihong and Reyzin, Lev and Schapire, Robert},
  booktitle={Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages={19--26},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{tewari2017ads,
  title={From ads to interventions: Contextual bandits in mobile health},
  author={Tewari, Ambuj and Murphy, Susan A},
  journal={Mobile Health: Sensors, Analytic Methods, and Applications},
  pages={495--517},
  year={2017},
  publisher={Springer}
}

@article{zhang2022feel,
  title={Feel-good thompson sampling for contextual bandits and reinforcement learning},
  author={Zhang, Tong},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={4},
  number={2},
  pages={834--857},
  year={2022},
  publisher={SIAM}
}

@book{todd2016minimum,
  title={Minimum-volume ellipsoids: Theory and algorithms},
  author={Todd, Michael J},
  year={2016},
  publisher={SIAM}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@inproceedings{zimmert2022pushing,
  title={Pushing the efficiency-regret Pareto frontier for online learning of portfolios and quantum states},
  author={Zimmert, Julian and Agarwal, Naman and Kale, Satyen},
  booktitle={Conference on Learning Theory},
  pages={182--226},
  year={2022},
  organization={PMLR}
}

@article{lu2002inverses,
  title={Inverses of 2$\times$ 2 block matrices},
  author={Lu, Tzon-Tzer and Shiou, Sheng-Hua},
  journal={Computers \& Mathematics with Applications},
  volume={43},
  number={1-2},
  pages={119--129},
  year={2002},
  publisher={Elsevier}
}


@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}

@article{agarwal2019reinforcement,
  title={Reinforcement learning: Theory and algorithms},
  author={Agarwal, Alekh and Jiang, Nan and Kakade, Sham M and Sun, Wen},
  journal={CS Dept., UW Seattle, Seattle, WA, USA, Tech. Rep},
  volume={32},
  year={2019}
}



@inproceedings{wagenmaker2022first,
  title={First-order regret in reinforcement learning with linear function approximation: A robust estimation approach},
  author={Wagenmaker, Andrew J and Chen, Yifang and Simchowitz, Max and Du, Simon and Jamieson, Kevin},
  booktitle={International Conference on Machine Learning},
  pages={22384--22429},
  year={2022},
  organization={PMLR}
}





@inproceedings{jaggi2013revisiting,
  title={Revisiting Frank-Wolfe: Projection-free sparse convex optimization},
  author={Jaggi, Martin},
  booktitle={International conference on machine learning},
  pages={427--435},
  year={2013},
  organization={PMLR}
}




@article{liu2023bypassing,
  title={Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual Bandits},
  author={Liu, Haolin and Wei, Chen-Yu and Zimmert, Julian},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}


@article{agarwal2020pc,
  title={Pc-pg: Policy cover directed exploration for provable policy gradient learning},
  author={Agarwal, Alekh and Henaff, Mikael and Kakade, Sham and Sun, Wen},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={13399--13412},
  year={2020}
}

@inproceedings{zanette2021cautiously,
  title={Cautiously optimistic policy optimization and exploration with linear function approximation},
  author={Zanette, Andrea and Cheng, Ching-An and Agarwal, Alekh},
  booktitle={Conference on Learning Theory},
  pages={4473--4525},
  year={2021},
  organization={PMLR}
}


@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={Proceedings of the Nineteenth International Conference on Machine Learning},
  pages={267--274},
  year={2002}
}

@inproceedings{agarwal2020optimality,
  title={Optimality and approximation with policy gradient methods in markov decision processes},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  booktitle={Conference on Learning Theory},
  pages={64--66},
  year={2020},
  organization={PMLR}
}


@inproceedings{wei2020model,
  title={Model-free reinforcement learning in infinite-horizon average-reward markov decision processes},
  author={Wei, Chen-Yu and Jahromi, Mehdi Jafarnia and Luo, Haipeng and Sharma, Hiteshi and Jain, Rahul},
  booktitle={International conference on machine learning},
  pages={10170--10180},
  year={2020},
  organization={PMLR}
}

@inproceedings{shani2020optimistic,
  title={Optimistic policy optimization with bandit feedback},
  author={Shani, Lior and Efroni, Yonathan and Rosenberg, Aviv and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={8604--8613},
  year={2020},
  organization={PMLR}
}

@article{zhong2023theoretical,
  title={A theoretical analysis of optimistic proximal policy optimization in linear markov decision processes},
  author={Zhong, Han and Zhang, Tong},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}

@article{liu2023optimistic,
  title={Optimistic Natural Policy Gradient: a Simple Efficient Policy Optimization Framework for Online RL},
  author={Liu, Qinghua and Weisz, Gell{\'e}rt and Gy{\"o}rgy, Andr{\'a}s and Jin, Chi and Szepesv{\'a}ri, Csaba},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}
@inproceedings{pan2019policy,
  title={Policy optimization with model-based explorations},
  author={Pan, Feiyang and Cai, Qingpeng and Zeng, An-Xiang and Pan, Chun-Xiang and Da, Qing and He, Hualin and He, Qing and Tang, Pingzhong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={4675--4682},
  year={2019}
}


@inproceedings{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  booktitle={International Conference on Learning Representations},
  year={2018}
}



@article{agarwal2020flambe,
  title={Flambe: Structural complexity and representation learning of low rank mdps},
  author={Agarwal, Alekh and Kakade, Sham and Krishnamurthy, Akshay and Sun, Wen},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={20095--20107},
  year={2020}
}


@article{cheng2023improved,
  title={Improved Sample Complexity for Reward-free Reinforcement Learning under Low-rank MDPs},
  author={Cheng, Yuan and Huang, Ruiquan and Yang, Jing and Liang, Yingbin},
  journal={arXiv preprint arXiv:2303.10859},
  year={2023}
}

@article{chen2022unified,
  title={Unified algorithms for rl with decision-estimation coefficients: No-regret, pac, and reward-free learning},
  author={Chen, Fan and Mei, Song and Bai, Yu},
  journal={arXiv preprint arXiv:2209.11745},
  year={2022}
}

@article{liu2023towards,
  title={Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback},
  author={Liu, Haolin and Wei, Chen-Yu and Zimmert, Julian},
  journal={arXiv preprint arXiv:2310.11550},
  year={2023}
}

@inproceedings{dong2020root,
  title={Root-n-regret for learning in markov decision processes with function approximation and low bellman rank},
  author={Dong, Kefan and Peng, Jian and Wang, Yining and Zhou, Yuan},
  booktitle={Conference on Learning Theory},
  pages={1554--1557},
  year={2020},
  organization={PMLR}
}

@inproceedings{jiang2017contextual,
  title={Contextual decision processes with low bellman rank are pac-learnable},
  author={Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
  booktitle={International Conference on Machine Learning},
  pages={1704--1713},
  year={2017},
  organization={PMLR}
}

@inproceedings{huang2023reinforcement,
  title={Reinforcement learning in low-rank mdps with density features},
  author={Huang, Audrey and Chen, Jinglin and Jiang, Nan},
  booktitle={International Conference on Machine Learning},
  pages={13710--13752},
  year={2023},
  organization={PMLR}
}

@article{uehara2021pessimistic,
  title={Pessimistic model-based offline reinforcement learning under partial coverage},
  author={Uehara, Masatoshi and Sun, Wen},
  journal={arXiv preprint arXiv:2107.06226},
  year={2021}
}

@article{xie2022role,
  title={The role of coverage in online reinforcement learning},
  author={Xie, Tengyang and Foster, Dylan J and Bai, Yu and Jiang, Nan and Kakade, Sham M},
  journal={arXiv preprint arXiv:2210.04157},
  year={2022}
}


@inproceedings{ren2022free,
  title={A free lunch from the noise: Provable and practical exploration for representation learning},
  author={Ren, Tongzheng and Zhang, Tianjun and Szepesv{\'a}ri, Csaba and Dai, Bo},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1686--1696},
  year={2022},
  organization={PMLR}
}

@article{uehara2021representation,
  title={Representation learning for online and offline rl in low-rank mdps},
  author={Uehara, Masatoshi and Zhang, Xuezhou and Sun, Wen},
  journal={arXiv preprint arXiv:2110.04652},
  year={2021}
}

@article{modi2024model,
  title={Model-free representation learning and exploration in low-rank mdps},
  author={Modi, Aditya and Chen, Jinglin and Krishnamurthy, Akshay and Jiang, Nan and Agarwal, Alekh},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={6},
  pages={1--76},
  year={2024}
}

@inproceedings{zhang2022efficient,
  title={Efficient reinforcement learning in block mdps: A model-free representation learning approach},
  author={Zhang, Xuezhou and Song, Yuda and Uehara, Masatoshi and Wang, Mengdi and Agarwal, Alekh and Sun, Wen},
  booktitle={International Conference on Machine Learning},
  pages={26517--26547},
  year={2022},
  organization={PMLR}
}


@article{mhammedi2024efficient,
  title={Efficient model-free exploration in low-rank mdps},
  author={Mhammedi, Zak and Block, Adam and Foster, Dylan J and Rakhlin, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{chen2022statistical,
  title={On the statistical efficiency of reward-free exploration in non-linear rl},
  author={Chen, Jinglin and Modi, Aditya and Krishnamurthy, Akshay and Jiang, Nan and Agarwal, Alekh},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={20960--20973},
  year={2022}
}

