\begin{thebibliography}{10}

\bibitem{altman1999constrained}
Eitan Altman.
\newblock {\em Constrained Markov decision processes}, volume~7.
\newblock CRC Press, 1999.

\bibitem{artzner1999coherent}
Philippe Artzner, Freddy Delbaen, Jean-Marc Eber, and David Heath.
\newblock Coherent measures of risk.
\newblock {\em Mathematical finance}, 9(3):203--228, 1999.

\bibitem{bauerle2011markov}
Nicole B{\"a}uerle and Jonathan Ott.
\newblock Markov decision processes with average-value-at-risk criteria.
\newblock {\em Mathematical Methods of Operations Research}, 74(3):361--379,
  2011.

\bibitem{borkar2010risk}
Vivek Borkar and Rahul Jain.
\newblock Risk-constrained {Markov} decision processes.
\newblock In {\em 49th IEEE Conference on Decision and Control (CDC)}, pages
  2664--2669. IEEE, 2010.

\bibitem{chen2012tractable}
Katherine Chen and Michael Bowling.
\newblock Tractable objectives for robust policy optimization.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2069--2077, 2012.

\bibitem{chow2014algorithms}
Yinlam Chow and Mohammad Ghavamzadeh.
\newblock Algorithms for {CVaR} optimization in mdps.
\newblock In {\em Advances in neural information processing systems}, pages
  3509--3517, 2014.

\bibitem{chow2017risk}
Yinlam Chow, Mohammad Ghavamzadeh, Lucas Janson, and Marco Pavone.
\newblock Risk-constrained reinforcement learning with percentile risk
  criteria.
\newblock {\em The Journal of Machine Learning Research}, 18(1):6070--6120,
  2017.

\bibitem{chow2015risk}
Yinlam Chow, Aviv Tamar, Shie Mannor, and Marco Pavone.
\newblock Risk-sensitive and robust decision-making: a {CVaR} optimization
  approach.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1522--1530, 2015.

\bibitem{clements2019estimating}
William~R Clements, Bastien Van~Delft, Beno{\^\i}t-Marie Robaglia, Reda~Bahi
  Slaoui, and S{\'e}bastien Toth.
\newblock Estimating risk and uncertainty in deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1905.09638}, 2019.

\bibitem{couetoux2011continuous}
Adrien Cou{\"e}toux, Jean-Baptiste Hoock, Nataliya Sokolovska, Olivier Teytaud,
  and Nicolas Bonnard.
\newblock Continuous upper confidence trees.
\newblock In {\em International Conference on Learning and Intelligent
  Optimization}, pages 433--445. Springer, 2011.

\bibitem{delage2010percentile}
Erick Delage and Shie Mannor.
\newblock Percentile optimization for {Markov} decision processes with
  parameter uncertainty.
\newblock {\em Operations research}, 58(1):203--213, 2010.

\bibitem{duff2003optimal}
Michael~O Duff.
\newblock Optimal learning: Computational procedures for {Bayes-adaptive
  Markov} decision processes.
\newblock 2003.

\bibitem{eriksson2021sentinel}
Hannes Eriksson, Debabrota Basu, Mina Alibeigi, and Christos Dimitrakakis.
\newblock Sentinel: Taming uncertainty with ensemble-based distributional
  reinforcement learning.
\newblock {\em arXiv preprint arXiv:2102.11075}, 2021.

\bibitem{gelly2011monte}
Sylvain Gelly and David Silver.
\newblock {Monte-Carlo} tree search and rapid action value estimation in
  computer {Go}.
\newblock {\em Artificial Intelligence}, 175(11):1856--1875, 2011.

\bibitem{guez2014bayes}
Arthur Guez, Nicolas Heess, David Silver, and Peter Dayan.
\newblock Bayes-adaptive simulation-based search with value function
  approximation.
\newblock In {\em NIPS}, volume~27, pages 451--459, 2014.

\bibitem{guez2012efficient}
Arthur Guez, David Silver, and Peter Dayan.
\newblock Efficient {Bayes}-adaptive reinforcement learning using sample-based
  search.
\newblock {\em Advances in neural information processing systems},
  25:1025--1033, 2012.

\bibitem{iyengar2005robust}
Garud~N Iyengar.
\newblock Robust dynamic programming.
\newblock {\em Mathematics of Operations Research}, 30(2):257--280, 2005.

\bibitem{lee2017constrained}
Jongmin Lee, Youngsoo Jang, Pascal Poupart, and Kee-Eung Kim.
\newblock Constrained {Bayesian} reinforcement learning via approximate linear
  programming.
\newblock In {\em IJCAI}, pages 2088--2095, 2017.

\bibitem{lee2018monte}
Jongmin Lee, Geon-Hyeong Kim, Pascal Poupart, and Kee-Eung Kim.
\newblock Monte-carlo tree search for constrained pomdps.
\newblock In {\em NeurIPS}, pages 7934--7943, 2018.

\bibitem{mannor2004bias}
Shie Mannor, Duncan Simester, Peng Sun, and John~N Tsitsiklis.
\newblock Bias and variance in value function estimation.
\newblock In {\em Proceedings of the twenty-first international conference on
  Machine learning}, page~72, 2004.

\bibitem{martin1967bayesian}
James~John Martin.
\newblock {\em Bayesian decision problems and {Markov} chains}.
\newblock Wiley, 1967.

\bibitem{mern2020bayesian}
John Mern, Anil Yildiz, Zachary Sunberg, Tapan Mukerji, and Mykel~J
  Kochenderfer.
\newblock Bayesian optimized {Monte Carlo} planning.
\newblock {\em arXiv preprint arXiv:2010.03597}, 2020.

\bibitem{micchelli2006universal}
Charles~A Micchelli, Yuesheng Xu, and Haizhang Zhang.
\newblock Universal kernels.
\newblock {\em Journal of Machine Learning Research}, 7(12), 2006.

\bibitem{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.

\bibitem{morere2016bayesian}
Philippe Morere, Roman Marchant, and Fabio Ramos.
\newblock Bayesian optimisation for solving continuous state-action-observation
  pomdps.
\newblock {\em Advances in Neural Information Processing Systems (NIPS)}, 2016.

\bibitem{nilim2005robust}
Arnab Nilim and Laurent El~Ghaoui.
\newblock Robust control of {Markov} decision processes with uncertain
  transition matrices.
\newblock {\em Operations Research}, 53(5):780--798, 2005.

\bibitem{osogami2012robustness}
Takayuki Osogami.
\newblock Robustness and risk-sensitivity in {Markov} decision processes.
\newblock {\em Advances in Neural Information Processing Systems}, 25:233--241,
  2012.

\bibitem{pan2019risk}
Xinlei Pan, Daniel Seita, Yang Gao, and John Canny.
\newblock Risk averse robust adversarial reinforcement learning.
\newblock In {\em 2019 International Conference on Robotics and Automation
  (ICRA)}, pages 8522--8528. IEEE, 2019.

\bibitem{pflug2016time}
Georg~Ch Pflug and Alois Pichler.
\newblock Time-consistent decisions and temporal decomposition of coherent risk
  functionals.
\newblock {\em Mathematics of Operations Research}, 41(2):682--699, 2016.

\bibitem{pinto17robust}
Lerrel Pinto, James Davidson, Rahul Sukthankar, and Abhinav Gupta.
\newblock Robust adversarial reinforcement learning.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning}, volume~70, pages 2817--2826, 2017.

\bibitem{prashanth2014policy}
LA~Prashanth.
\newblock Policy gradients for {CVaR-constrained MDPs}.
\newblock In {\em International Conference on Algorithmic Learning Theory},
  pages 155--169. Springer, 2014.

\bibitem{rigter2021lexicographic}
Marc Rigter, Paul Duckworth, Bruno Lacerda, and Nick Hawes.
\newblock Lexicographic optimisation of conditional value at risk and expected
  value for risk-averse planning in {MDPs}.
\newblock {\em arXiv preprint arXiv:2110.12746}, 2021.

\bibitem{rigter2020minimax}
Marc Rigter, Bruno Lacerda, and Nick Hawes.
\newblock Minimax regret optimisation for robust planning in uncertain {Markov}
  decision processes.
\newblock {\em Proceedings of the AAAI Conference on Artificial Intelligence},
  35(13):11930--11938, May 2021.

\bibitem{rockafellar2000optimization}
R~Tyrrell Rockafellar, Stanislav Uryasev, et~al.
\newblock Optimization of conditional value-at-risk.
\newblock {\em Journal of risk}, 2:21--42, 2000.

\bibitem{ruszczynski2010risk}
Andrzej Ruszczy{\'n}ski.
\newblock Risk-averse dynamic programming for {Markov} decision processes.
\newblock {\em Mathematical programming}, 125(2):235--261, 2010.

\bibitem{santana2016rao}
Pedro Santana, Sylvie Thi{\'e}baux, and Brian Williams.
\newblock {RAO*}: An algorithm for chance-constrained {POMDP’s}.
\newblock 2016.

\bibitem{shapiro2014lectures}
Alexander Shapiro, Darinka Dentcheva, and Andrzej Ruszczy{\'n}ski.
\newblock {\em Lectures on stochastic programming: modeling and theory}.
\newblock SIAM, 2014.

\bibitem{sharma2019robust}
Apoorva Sharma, James Harrison, Matthew Tsao, and Marco Pavone.
\newblock Robust and adaptive planning under model uncertainty.
\newblock In {\em Proceedings of the International Conference on Automated
  Planning and Scheduling}, volume~29, pages 410--418, 2019.

\bibitem{silver2016mastering}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George
  Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, et~al.
\newblock Mastering the game of {Go} with deep neural networks and tree search.
\newblock {\em nature}, 529(7587):484--489, 2016.

\bibitem{sonnenburg2010shogun}
S{\"o}ren Sonnenburg, Gunnar R{\"a}tsch, Sebastian Henschel, Christian Widmer,
  Jonas Behr, Alexander Zien, Fabio~de Bona, Alexander Binder, Christian Gehl,
  and Vojt{\v{e}}ch Franc.
\newblock The {SHOGUN} machine learning toolbox.
\newblock {\em The Journal of Machine Learning Research}, 11:1799--1802, 2010.

\bibitem{srinivas2010gaussian}
Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger.
\newblock Gaussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock In {\em Proceedings of the 27th International Conference on
  International Conference on Machine Learning}, ICML'10, page 1015–1022,
  Madison, WI, USA, 2010. Omnipress.

\bibitem{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem{tamar2015policy}
Aviv Tamar, Yinlam Chow, Mohammad Ghavamzadeh, and Shie Mannor.
\newblock Policy gradient for coherent risk measures.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1468--1476, 2015.

\bibitem{tamar2016sequential}
Aviv Tamar, Yinlam Chow, Mohammad Ghavamzadeh, and Shie Mannor.
\newblock Sequential decision making with coherent risk.
\newblock {\em IEEE Transactions on Automatic Control}, 62(7):3323--3338, 2016.

\bibitem{tamar2014optimizing}
Aviv Tamar, Yonatan Glassner, and Shie Mannor.
\newblock Optimizing the {CVaR} via sampling.
\newblock In {\em Proceedings of the Twenty-Ninth AAAI Conference on Artificial
  Intelligence}, AAAI'15, page 2993–2999. AAAI Press, 2015.

\bibitem{tang2019worst}
Yichuan~Charlie Tang, Jian Zhang, and Ruslan Salakhutdinov.
\newblock Worst cases policy gradients.
\newblock {\em arXiv preprint arXiv:1911.03618}, 2019.

\bibitem{wolff2012robust}
Eric~M Wolff, Ufuk Topcu, and Richard~M Murray.
\newblock Robust control of uncertain {Markov} decision processes with temporal
  logic specifications.
\newblock In {\em 2012 IEEE 51st IEEE Conference on Decision and Control
  (CDC)}, pages 3372--3379. IEEE, 2012.

\end{thebibliography}
