\begin{thebibliography}{36}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[McClelland et~al.(1995)McClelland, McNaughton, and
  O'Reilly]{mcclelland1995there}
James~L McClelland, Bruce~L McNaughton, and Randall~C O'Reilly.
\newblock Why there are complementary learning systems in the hippocampus and
  neocortex: insights from the successes and failures of connectionist models
  of learning and memory.
\newblock \emph{Psychological review}, 102\penalty0 (3):\penalty0 419, 1995.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529, 2015.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van
  Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot,
  et~al.]{silver2016mastering}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George
  Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{nature}, 529\penalty0 (7587):\penalty0 484--489, 2016.

\bibitem[Morav{\v{c}}{\'\i}k et~al.(2017)Morav{\v{c}}{\'\i}k, Schmid, Burch,
  Lis{\`y}, Morrill, Bard, Davis, Waugh, Johanson, and
  Bowling]{moravvcik2017deepstack}
Matej Morav{\v{c}}{\'\i}k, Martin Schmid, Neil Burch, Viliam Lis{\`y}, Dustin
  Morrill, Nolan Bard, Trevor Davis, Kevin Waugh, Michael Johanson, and Michael
  Bowling.
\newblock Deepstack: Expert-level artificial intelligence in heads-up no-limit
  poker.
\newblock \emph{Science}, 356\penalty0 (6337):\penalty0 508--513, 2017.

\bibitem[Sutton and Barto(1998)]{sutton_barto}
Richard~S Sutton and Andrew~G Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 1998.

\bibitem[Blundell et~al.(2016{\natexlab{a}})Blundell, Uria, Pritzel, Li,
  Ruderman, Leibo, Rae, Wierstra, and Hassabis]{blundell2016model}
Charles Blundell, Benigno Uria, Alexander Pritzel, Yazhe Li, Avraham Ruderman,
  Joel~Z Leibo, Jack Rae, Daan Wierstra, and Demis Hassabis.
\newblock Model-free episodic control.
\newblock \emph{arXiv preprint arXiv:1606.04460}, 2016{\natexlab{a}}.

\bibitem[Pritzel et~al.(2017)Pritzel, Uria, Srinivasan, Puigdom{\`e}nech,
  Vinyals, Hassabis, Wierstra, and Blundell]{pritzel2017neural}
Alexander Pritzel, Benigno Uria, Sriram Srinivasan, Adri{\`a} Puigdom{\`e}nech,
  Oriol Vinyals, Demis Hassabis, Daan Wierstra, and Charles Blundell.
\newblock Neural episodic control.
\newblock \emph{ICML}, 2017.

\bibitem[Dayan and Daw(2008)]{dayan2008decision}
Peter Dayan and Nathaniel~D Daw.
\newblock Decision theory, reinforcement learning, and the brain.
\newblock \emph{Cognitive, Affective, \& Behavioral Neuroscience}, 8\penalty0
  (4):\penalty0 429--453, 2008.

\bibitem[Gershman and Daw(2017)]{gershman2017reinforcement}
Samuel~J Gershman and Nathaniel~D Daw.
\newblock Reinforcement learning and episodic memory in humans and animals: an
  integrative framework.
\newblock \emph{Annual review of psychology}, 68:\penalty0 101--128, 2017.

\bibitem[Silver et~al.(2008)Silver, Sutton, and M{\"u}ller]{silver2008sample}
David Silver, Richard~S Sutton, and Martin M{\"u}ller.
\newblock Sample-based learning and search with permanent and transient
  memories.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, pages 968--975. ACM, 2008.

\bibitem[Espeholt et~al.(2018)Espeholt, Soyer, Munos, Simonyan, Mnih, Ward,
  Doron, Firoiu, Harley, Dunning, et~al.]{espeholt2018impala}
Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Volodymir Mnih, Tom
  Ward, Yotam Doron, Vlad Firoiu, Tim Harley, Iain Dunning, et~al.
\newblock Impala: Scalable distributed deep-rl with importance weighted
  actor-learner architectures.
\newblock \emph{arXiv preprint arXiv:1802.01561}, 2018.

\bibitem[Barth-Maron et~al.(2018)Barth-Maron, Hoffman, Budden, Dabney, Horgan,
  Muldal, Heess, and Lillicrap]{barth2018distributed}
Gabriel Barth-Maron, Matthew~W Hoffman, David Budden, Will Dabney, Dan Horgan,
  Alistair Muldal, Nicolas Heess, and Timothy Lillicrap.
\newblock Distributed distributional deterministic policy gradients.
\newblock \emph{arXiv preprint arXiv:1804.08617}, 2018.

\bibitem[Watkins and Dayan(1992)]{watkins1992q}
Christopher~JCH Watkins and Peter Dayan.
\newblock Q-learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 279--292, 1992.

\bibitem[Ormoneit and Sen(2002)]{ormoneit2002kernel}
Dirk Ormoneit and {\'S}aunak Sen.
\newblock Kernel-based reinforcement learning.
\newblock \emph{Machine learning}, 49\penalty0 (2-3):\penalty0 161--178, 2002.

\bibitem[Bakker et~al.(2003)Bakker, Zhumatiy, Gruener, and
  Schmidhuber]{bakker2003robot}
Bram Bakker, Viktor Zhumatiy, Gabriel Gruener, and J{\"u}rgen Schmidhuber.
\newblock A robot that reinforcement-learns to identify and memorize important
  previous observations.
\newblock In \emph{Intelligent Robots and Systems, 2003.(IROS 2003).
  Proceedings. 2003 IEEE/RSJ International Conference on}, volume~1, pages
  430--435. IEEE, 2003.

\bibitem[Hausknecht and Stone(2015)]{hausknecht2015deep}
Matthew Hausknecht and Peter Stone.
\newblock Deep recurrent q-learning for partially observable mdps.
\newblock \emph{arXiv preprint arXiv:1507.06527}, 2015.

\bibitem[Graves et~al.(2016)Graves, Wayne, Reynolds, Harley, Danihelka,
  Grabska-Barwi{\'n}ska, Colmenarejo, Grefenstette, Ramalho, Agapiou,
  et~al.]{graves2016hybrid}
Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka
  Grabska-Barwi{\'n}ska, Sergio~G{\'o}mez Colmenarejo, Edward Grefenstette,
  Tiago Ramalho, John Agapiou, et~al.
\newblock Hybrid computing using a neural network with dynamic external memory.
\newblock \emph{Nature}, 538\penalty0 (7626):\penalty0 471--476, 2016.

\bibitem[Oh et~al.(2016)Oh, Chockalingam, Lee, et~al.]{oh2016control}
Junhyuk Oh, Valliappa Chockalingam, Honglak Lee, et~al.
\newblock Control of memory, active perception, and action in minecraft.
\newblock In \emph{Proceedings of The 33rd International Conference on Machine
  Learning}, pages 2790--2799, 2016.

\bibitem[Wayne et~al.(2018)Wayne, Hung, Amos, Mirza, Ahuja, Grabska-Barwinska,
  Rae, Mirowski, Leibo, Santoro, et~al.]{wayne2018merlin}
Greg Wayne, Chia-Chun Hung, David Amos, Mehdi Mirza, Arun Ahuja, Agnieszka
  Grabska-Barwinska, Jack Rae, Piotr Mirowski, Joel~Z Leibo, Adam Santoro,
  et~al.
\newblock Unsupervised predictive memory in a goal-directed agent.
\newblock \emph{arXiv preprint arXiv:1803.10760}, 2018.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{mnih2016asynchronous}
Volodymyr Mnih, Adria~Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy~P
  Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2016.

\bibitem[Schaul et~al.(2015)Schaul, Quan, Antonoglou, and
  Silver]{PrioritizedReplay}
Tom Schaul, John Quan, Ioannis Antonoglou, and David Silver.
\newblock Prioritized experience replay.
\newblock \emph{CoRR}, abs/1511.05952, 2015.

\bibitem[Santamar{\'\i}a et~al.(1997)Santamar{\'\i}a, Sutton, and
  Ram]{santamaria}
Juan~C Santamar{\'\i}a, Richard~S Sutton, and Ashwin Ram.
\newblock Experiments with reinforcement learning in problems with continuous
  state and action spaces.
\newblock \emph{Adaptive behavior}, 6\penalty0 (2):\penalty0 163--217, 1997.

\bibitem[Munos and Moore(1998)]{barycentric}
Remi Munos and Andrew~W Moore.
\newblock Barycentric interpolators for continuous space and time reinforcement
  learning.
\newblock In \emph{NIPS}, pages 1024--1030, 1998.

\bibitem[Gabel and Riedmiller(2005)]{riedmiller2005}
Thomas Gabel and Martin Riedmiller.
\newblock Cbr for state value function approximation in reinforcement learning.
\newblock In \emph{International Conference on Case-Based Reasoning}, pages
  206--221. Springer, 2005.

\bibitem[Blundell et~al.(2016{\natexlab{b}})Blundell, Uria, Pritzel, Li,
  Ruderman, Leibo, Rae, Wierstra, and Hassabis]{mfec}
Charles Blundell, Benigno Uria, Alexander Pritzel, Yazhe Li, Avraham Ruderman,
  Joel~Z Leibo, Jack Rae, Daan Wierstra, and Demis Hassabis.
\newblock Model-free episodic control.
\newblock \emph{arXiv preprint arXiv:1606.04460}, 2016{\natexlab{b}}.

\bibitem[Nishio and Yamane(2018)]{nishio2018faster}
Daichi Nishio and Satoshi Yamane.
\newblock Faster deep q-learning using neural episodic control.
\newblock \emph{arXiv preprint arXiv:1801.01968}, 2018.

\bibitem[Jain and Lindsey(2018)]{jain2018semiparametric}
Mika~Sarkin Jain and Jack Lindsey.
\newblock Semiparametric reinforcement learning.
\newblock \emph{ICLR 2018 Workshop}, 2018.

\bibitem[Brea(2017)]{brea2017prioritized}
Johanni Brea.
\newblock Is prioritized sweeping the better episodic control?
\newblock \emph{arXiv preprint arXiv:1711.06677}, 2017.

\bibitem[Savinov et~al.(2018)Savinov, Dosovitskiy, and Koltun]{savinov2018semi}
Nikolay Savinov, Alexey Dosovitskiy, and Vladlen Koltun.
\newblock Semi-parametric topological memory for navigation.
\newblock \emph{arXiv preprint arXiv:1803.00653}, 2018.

\bibitem[Xiao et~al.(2018)Xiao, Mei, and M{\"u}ller]{xiao2018memory}
Chenjun Xiao, Jincheng Mei, and Martin M{\"u}ller.
\newblock Memory-augmented monte carlo tree search.
\newblock \emph{AAAI}, 2018.

\bibitem[Kaiser et~al.(2016)Kaiser, Nachum, Roy, and
  Bengio]{kaiser2016learning}
Lukasz Kaiser, Ofir Nachum, Aurko Roy, and Samy Bengio.
\newblock Learning to remember rare events.
\newblock 2016.

\bibitem[Grave et~al.(2016)Grave, Joulin, and Usunier]{grave2016improving}
Edouard Grave, Armand Joulin, and Nicolas Usunier.
\newblock Improving neural language models with a continuous cache.
\newblock \emph{arXiv preprint arXiv:1612.04426}, 2016.

\bibitem[Merity et~al.(2016)Merity, Xiong, Bradbury, and
  Socher]{merity2016pointer}
Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher.
\newblock Pointer sentinel mixture models.
\newblock \emph{arXiv preprint arXiv:1609.07843}, 2016.

\bibitem[Sprechmann et~al.(2018)Sprechmann, Jayakumar, Rae, Pritzel, Badia,
  Uria, Vinyals, Hassabis, Pascanu, and Blundell]{sprechmann2018memory}
Pablo Sprechmann, Siddhant~M Jayakumar, Jack~W Rae, Alexander Pritzel,
  Adri{\`a}~Puigdom{\`e}nech Badia, Benigno Uria, Oriol Vinyals, Demis
  Hassabis, Razvan Pascanu, and Charles Blundell.
\newblock Memory-based parameter adaptation.
\newblock \emph{ICLR}, 2018.

\bibitem[Stepleton(2017)]{pycolab}
Tom Stepleton.
\newblock The pycolab game engine.
\newblock \url{https://github.com/deepmind/pycolab/ tree/master/pycolab}, 2017.

\bibitem[Bellemare et~al.(2013)Bellemare, Naddaf, Veness, and Bowling]{atari}
Marc~G Bellemare, Yavar Naddaf, Joel Veness, and Michael Bowling.
\newblock The arcade learning environment: An evaluation platform for general
  agents.
\newblock \emph{J. Artif. Intell. Res.(JAIR)}, 47:\penalty0 253--279, 2013.

\end{thebibliography}
