\begin{thebibliography}{62}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alaoui et~al.(2016)Alaoui, Cheng, Ramdas, Wainwright, and
  Jordan]{Alaoui2016}
Ahmed~El Alaoui, Xiang Cheng, Aaditya Ramdas, Martin Wainwright, and Michael
  Jordan.
\newblock Asymptotic behavior of \(\ell_p\)-based {L}aplacian regularization in
  semi-supervised learning.
\newblock In \emph{Conference on Learning Theory}, 2016.

\bibitem[Alayrac et~al.(2016)Alayrac, Bojanowski, Agrawal, Sivic, Laptev, and
  Lacoste{-}Julien]{Alayrac2016}
Jean{-}Baptiste Alayrac, Piotr Bojanowski, Nishant Agrawal, Josef Sivic, Ivan
  Laptev, and Simon Lacoste{-}Julien.
\newblock Unsupervised learning from narrated instruction videos.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition},
  2016.

\bibitem[Aronszajn(1950)]{Aronszajn1950}
Nachman Aronszajn.
\newblock Theory of reproducing kernels.
\newblock \emph{Transactions of the American Mathematical Society}, 1950.

\bibitem[Belkin and Niyogi(2003)]{Belkin2003}
Mikhail Belkin and Partha Niyogi.
\newblock Laplacian eigenmaps for dimensionality reduction and data
  representation.
\newblock \emph{Neural Computation}, 2003.

\bibitem[Bengio et~al.(2006)Bengio, Delalleau, and Roux]{Bengio2006}
Yoshua Bengio, Olivier Delalleau, and Nicolas~Le Roux.
\newblock Label propagation and quadratic criterion.
\newblock In \emph{Semi-Supervised Learning}. MIT Press, 2006.

\bibitem[Berthelot et~al.(2019)Berthelot, Carlini, Goodfellow, Papernot,
  Oliver, and Raffel]{Berthelot2019}
David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital
  Oliver, and Colin Raffel.
\newblock Mixmatch: {A} holistic approach to semi-supervised learning.
\newblock In \emph{Neural Information Processing Systems}, 2019.

\bibitem[Cabannes et~al.(2020)Cabannes, Rudi, and Bach]{Cabannes2020}
Vivien Cabannes, Alessandro Rudi, and Francis Bach.
\newblock Structured prediction with partial labelling through the infimum
  loss.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Cabannes et~al.(2021{\natexlab{a}})Cabannes, Rudi, and
  Bach]{Cabannes2021}
Vivien Cabannes, Alessandro Rudi, and Francis Bach.
\newblock Disambiguation of weak supervision with exponential convergence
  rates.
\newblock In \emph{International Conference on Machine Learning},
  2021{\natexlab{a}}.

\bibitem[Cabannes et~al.(2021{\natexlab{b}})Cabannes, Rudi, and
  Bach]{Cabannes2021b}
Vivien Cabannes, Alessandro Rudi, and Francis Bach.
\newblock Fast rates in structured prediction.
\newblock In \emph{Conference on Learning Theory}, 2021{\natexlab{b}}.

\bibitem[Caponnetto and De~Vito(2006)]{Caponnetto2007}
Andrea Caponnetto and Ernesto De~Vito.
\newblock Optimal rates for the regularized least-squares algorithm.
\newblock \emph{Foundations of Computational Mathematics}, 2006.

\bibitem[Castelli and Cover(1995)]{Castelli1995}
Vittorio Castelli and Thomas Cover.
\newblock On the exponential value of labeled samples.
\newblock \emph{Pattern Recognition Letters}, 1995.

\bibitem[Chen and Xu(2021)]{Chen2021}
Lin Chen and Sheng Xu.
\newblock Deep neural tangent kernel and {L}aplace kernel have the same {RKHS}.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Ciliberto et~al.(2020)Ciliberto, Rosasco, and Rudi]{Ciliberto2020}
Carlo Ciliberto, Lorenzo Rosasco, and Alessandro Rudi.
\newblock A general framework for consistent structured prediction with
  implicit loss embeddings.
\newblock \emph{Journal of Machine Learning Research}, 2020.

\bibitem[Coifman and Lafon(2006)]{Coifman2006}
Ronald Coifman and St\'ephane Lafon.
\newblock Diffusion maps.
\newblock \emph{Applied and Computational Harmonic Analysis}, 2006.

\bibitem[Cour et~al.(2011)Cour, Sapp, and Taskar]{Cour2011}
Timoth{\'{e}}e Cour, Benjamin Sapp, and Ben Taskar.
\newblock Learning from partial labels.
\newblock \emph{Journal of Machine Learning Research}, 2011.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Li]{ImageNet}
Jia Deng, Wei Dong, Richard Socher, Li{-}Jia Li, Kai Li, and Fei{-}Fei Li.
\newblock Imagenet: {A} large-scale hierarchical image database.
\newblock In \emph{Computer Vision and Pattern Recognition}, 2009.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{Devlin2019}
Jacob Devlin, Ming{-}Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT:} pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{North American Chapter of the Association for Computational
  Linguistics: Human Language Technologies}, 2019.

\bibitem[Edelman and Wang(2020)]{Edelman2020}
Alan Edelman and Yuyang Wang.
\newblock The {GSVD:} where are the ellipses?, matrix trigonometry, and more.
\newblock \emph{Journal on Matrix Analysis and Applications}, 2020.

\bibitem[Eriksson et~al.(2018)Eriksson, Dong, Lee, Bindel, and
  Wilson]{Eriksson2018}
David Eriksson, Kun Dong, Eric~Hans Lee, David Bindel, and Andrew~Gordon
  Wilson.
\newblock Scaling {G}aussian process regression with derivatives.
\newblock In \emph{Neural Information Processing Systems}, 2018.

\bibitem[Fix and Hodges(1951)]{Fix1951}
Evelyn Fix and Joseph Hodges.
\newblock Discriminatory analysis. nonparametric discrimination: Consistency
  properties.
\newblock Technical report, SAF School of Aviation Medicine, Randolph Field,
  Texas, 1951.

\bibitem[Garc{\'i}a~Trillos et~al.(2019)Garc{\'i}a~Trillos, Gerlach, Hein, and
  Slep{\v c}ev]{GarciaTrillos2019}
Nicol{\'a}s Garc{\'i}a~Trillos, Moritz Gerlach, Matthias Hein, and Dejan
  Slep{\v c}ev.
\newblock Error estimates for spectral convergence of the graph {L}aplacian on
  random geometric graphs toward the {L}aplace–{B}eltrami operator.
\newblock \emph{Foundations of Computational Mathematics}, 2019.

\bibitem[Golub and Loan(2013)]{Golub2013}
Gene Golub and Charles~Van Loan.
\newblock \emph{Matrix computations {(4th} editions)}.
\newblock Johns Hopkins University Press, 2013.

\bibitem[Grandvalet(2002)]{Grandvalet2002}
Yves Grandvalet.
\newblock Logistic regression for partial labels.
\newblock In \emph{9th Information Processing and Management of Uncertainty},
  2002.

\bibitem[Hein et~al.(2007)Hein, Audibert, and von Luxburg]{Hein2007}
Matthias Hein, Jean{-}Yves Audibert, and Ulrike von Luxburg.
\newblock Graph {L}aplacians and their convergence on random neighborhood
  graphs.
\newblock \emph{Journal of Machine Learning Research}, 2007.

\bibitem[H{\"{u}}llermeier et~al.(2008)H{\"{u}}llermeier, F{\"{u}}rnkranz,
  Cheng, and Brinker]{Hullermeier2008}
Eyke H{\"{u}}llermeier, Johannes F{\"{u}}rnkranz, Weiwei Cheng, and Klaus
  Brinker.
\newblock Label ranking by learning pairwise preferences.
\newblock \emph{Artificial Intelligence}, 2008.

\bibitem[Jin and Ghahramani(2002)]{Jin2002}
Rong Jin and Zoubin Ghahramani.
\newblock Learning with multiple labels.
\newblock In \emph{Neural Information Processing Systems}, 2002.

\bibitem[Karzand and Nowak(2020)]{Karzand2020}
Mina Karzand and Robert Nowak.
\newblock Maximin active learning in overparameterized model classes.
\newblock \emph{IEEE Journal on Selected Areas in Information Theory}, 2020.

\bibitem[Kolmogorov and Tikhomirov(1959)]{Kolmogorov1959}
Andrey Kolmogorov and Vladimir Tikhomirov.
\newblock $\epsilon$-entropy and $\epsilon$-capacity of sets in functional
  spaces.
\newblock \emph{Uspekhi Matematicheskikh Nauk}, 1959.

\bibitem[Lelarge and Miolane(2019)]{Lelarge2019}
Marc Lelarge and L{\'{e}}o Miolane.
\newblock Asymptotic {B}ayes risk for {G}aussian mixture in a semi-supervised
  setting.
\newblock In \emph{International Workshop on Computational Advances in
  Multi-Sensor Adaptive Processing}, 2019.

\bibitem[Lin et~al.(2020)Lin, Rudi, Rosasco, and Cevher]{Lin2020}
Junhong Lin, Alessandro Rudi, Lorenzo Rosasco, and Volkan Cevher.
\newblock Optimal rates for spectral algorithms with least-squares regression
  over {Hilbert} spaces.
\newblock \emph{Applied and Computational Harmonic Analysis}, 2020.

\bibitem[Liu and Dietterich(2014)]{Liu2014}
Li-Ping Liu and Thomas Dietterich.
\newblock Learnability of the superset label learning problem.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Lou and Hamprecht(2012)]{Lou2012}
Xinghua Lou and Fred Hamprecht.
\newblock Structured learning from partial annotations.
\newblock In \emph{International Conference on Machine Learning}, 2012.

\bibitem[Luo and Orabona(2010)]{Luo2010}
Jie Luo and Francesco Orabona.
\newblock Learning from candidate labeling sets.
\newblock In \emph{Neural Information Processing Systems}, 2010.

\bibitem[Micchelli et~al.(2006)Micchelli, Xu, and Zhang]{Micchelli2006}
Charles Micchelli, Yuesheng Xu, and Haizhang Zhang.
\newblock Universal kernels.
\newblock \emph{Journal of Machine Learning Research}, 2006.

\bibitem[Miech et~al.(2019)Miech, Zhukov, Alayrac, Tapaswi, Laptev, and
  Sivic]{Miech2019}
Antoine Miech, Dimitri Zhukov, Jean-Baptiste Alayrac, Makarand Tapaswi, Ivan
  Laptev, and Josef Sivic.
\newblock Howto100m: Learning a text-video embedding by watching hundred
  million narrated video clips.
\newblock In \emph{International Conference on Computer Vision}, 2019.

\bibitem[Minsker(2017)]{Minsker2017}
Stanislav Minsker.
\newblock On some extensions of {B}ernstein’s inequality for self-adjoint
  operators.
\newblock \emph{Statistics \& Probability Letters}, 2017.

\bibitem[Nadler et~al.(2009)Nadler, Srebro, and Zhou]{Nadler2009}
Boaz Nadler, Nathan Srebro, and Xueyuan Zhou.
\newblock Statistical analysis of semi-supervised learning: The limit of
  infinite unlabelled data.
\newblock In \emph{Neural Information Processing Systems}, 2009.

\bibitem[Nguyen and Caruana(2008)]{Nguyen2008}
Nam Nguyen and Rich Caruana.
\newblock Classification with partial labels.
\newblock In \emph{14th International Conference on Knowledge Discovery and
  Data Mining}, 2008.

\bibitem[Papandreou et~al.(2015)Papandreou, Chen, Murphy, and
  Yuille]{Papandreou2015}
George Papandreou, Liang{-}Chieh Chen, Kevin Murphy, and Alan Yuille.
\newblock Weakly-and semi-supervised learning of a deep convolutional network
  for semantic image segmentation.
\newblock In \emph{International Conference on Computer Vision}, 2015.

\bibitem[Pillaud{-}Vivien(2020{\natexlab{a}})]{PillaudVivien2020}
Loucas Pillaud{-}Vivien.
\newblock Statistical estimation of the poincar{\'{e}} constant and application
  to sampling multimodal distributions.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2020{\natexlab{a}}.

\bibitem[Pillaud{-}Vivien(2020{\natexlab{b}})]{PillaudVivien2020b}
Loucas Pillaud{-}Vivien.
\newblock \emph{{Learning with Reproducing Kernel Hilbert Spaces: Stochastic
  Gradient Descent and Laplacian Estimation}}.
\newblock Phd thesis, {Ecole normale sup{\'e}rieure}, 2020{\natexlab{b}}.

\bibitem[Rahimi and Recht(2007)]{Rahimi2007}
Ali Rahimi and Benjamin Recht.
\newblock Random features for large-scale kernel machines.
\newblock In \emph{Neural Information Processing Systems}, 2007.

\bibitem[Rigollet(2007)]{Rigollet2007}
Philippe Rigollet.
\newblock Generalization error bounds in semi-supervised classification under
  the cluster assumption.
\newblock \emph{Journal of Machine Learning Research}, 2007.

\bibitem[Rosasco et~al.(2013)Rosasco, Villa, Mosci, Santoro, and
  verri]{Rosasco2013}
Lorenzo Rosasco, Silvia Villa, Sofia Mosci, Matteo Santoro, and Alessandro
  verri.
\newblock {Nonparametric sparsity and regularization}.
\newblock \emph{Journal of Machine Learning Research}, 2013.

\bibitem[Rudi et~al.(2015)Rudi, Camoriano, and Rosasco]{Rudi2015}
Alessandro Rudi, Raffaello Camoriano, and Lorenzo Rosasco.
\newblock Less is more: {N}ystr{\"{o}}m computational regularization.
\newblock In \emph{Neural Information Processing Systems}, 2015.

\bibitem[Scholkopf and Smola(2001)]{Scholkopf2001}
Bernhard Scholkopf and Alex Smola.
\newblock \emph{Learning with kernels: support vector machines, regularization,
  optimization, and beyond}.
\newblock MIT press, 2001.

\bibitem[Smola and Kondor(2003)]{Smola2003}
Alexander Smola and Risi Kondor.
\newblock Kernels and regularization on graphs.
\newblock In \emph{Conference on Computational Learning Theory}, 2003.

\bibitem[Stefan~Klus(2020)]{Klus2020}
Boumediene~Hamzi Stefan~Klus, Feliks~N\"uske.
\newblock Kernel-based approximation of the koopman generator and schrödinger
  operator.
\newblock \emph{Entropy}, 2020.

\bibitem[Steinwart and Christmann(2008)]{Steinwart2008}
Ingo Steinwart and Andreas Christmann.
\newblock \emph{Support Vector Machines}.
\newblock Springer, 2008.

\bibitem[Tobin(1958)]{Tobin1958}
James Tobin.
\newblock Estimation of relationships for limited dependent variables.
\newblock \emph{Econometrica}, 1958.

\bibitem[Turing(1950)]{Turing1950}
Alan Turing.
\newblock Computing machinery and intelligence.
\newblock \emph{Mind}, 1950.

\bibitem[van Engelen and Hoos(2020)]{Engelen2020}
Jesper van Engelen and Holger Hoos.
\newblock A survey on semi-supervised learning.
\newblock \emph{Machine Learning Journal}, 2020.

\bibitem[Verbeek and Triggs(2008)]{Verbeek2007}
Jakob Verbeek and William Triggs.
\newblock {Scene Segmentation with {CRF}s Learned from Partially Labeled
  Images}.
\newblock In \emph{Neural Information Processing Systems}, 2008.

\bibitem[Verma et~al.(2019)Verma, Lamb, Kannala, Bengio, and
  Lopez{-}Paz]{Verma2019}
Vikas Verma, Alex Lamb, Juho Kannala, Yoshua Bengio, and David Lopez{-}Paz.
\newblock Interpolation consistency training for semi-supervised learning.
\newblock In \emph{International Joint Conference on Artificial Intelligence},
  2019.

\bibitem[Williams and Seeger(2000)]{Williams2000}
Christopher Williams and Matthias Seeger.
\newblock Using the {N}ystr{\"{o}}m method to speed up kernel machines.
\newblock In \emph{Neural Information Processing Systems}, 2000.

\bibitem[Yang(1999)]{Yang1999}
Yuhong Yang.
\newblock Minimax nonparametric classification. {I}. {R}ates of convergence.
\newblock \emph{{IEEE} Transactions on Information Theory}, 1999.

\bibitem[Yu et~al.(2014)Yu, Jain, Kar, and Dhillon]{Yu2014}
Hsiang{-}Fu Yu, Prateek Jain, Purushottam Kar, and Inderjit Dhillon.
\newblock Large-scale multi-label learning with missing labels.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Yurinskii(1970)]{Yurinskii1970}
Vadim~Vladimirovich Yurinskii.
\newblock On an infinite-dimensional version of {S. N. B}ernstein's
  inequalities.
\newblock \emph{Theory of Probability and Its Applications}, 1970.

\bibitem[Zhang and Agarwal(2020)]{Zhang2020}
Mingyuan Zhang and Shivani Agarwal.
\newblock Bayes consistency vs. $\cal {H}$-consistency: The interplay between
  surrogate loss functions and the scoring function class.
\newblock In \emph{Neural Information Processing Systems}, 2020.

\bibitem[Zhou et~al.(2003)Zhou, Bousquet, Lal, Weston, and
  Sch{\"{o}}lkopf]{Zhou2003}
Dengyong Zhou, Olivier Bousquet, Thomas~Navin Lal, Jason Weston, and Bernhard
  Sch{\"{o}}lkopf.
\newblock Learning with local and global consistency.
\newblock In \emph{Neural Information Processing Systems}, 2003.

\bibitem[Zhou(2008)]{Zhou2008}
Ding-Xuan Zhou.
\newblock Derivative reproducing properties for kernel methods in learning
  theory.
\newblock \emph{Journal of Computational and Applied Mathematics}, 2008.

\bibitem[Zhu et~al.(2003)Zhu, Ghahramani, and Lafferty]{Zhu2003}
Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty.
\newblock Semi-supervised learning using {G}aussian fields and harmonic
  functions.
\newblock In \emph{International Conference of Machine Learning}, 2003.

\end{thebibliography}
