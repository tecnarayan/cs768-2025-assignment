\begin{thebibliography}{10}

\bibitem{arik2019tabnet}
S.~O. Arik and T.~Pfister.
\newblock Tabnet: Attentive interpretable tabular learning.
\newblock {\em arXiv preprint arXiv:1908.07442}, 2019.

\bibitem{arya2019explanation}
V.~Arya, R.~K.~E. Bellamy, P.-Y. Chen, A.~Dhurandhar, M.~Hind, S.~C. Hoffman,
  S.~Houde, Q.~V. Liao, R.~Luss, A.~Mojsilović, S.~Mourad, P.~Pedemonte,
  R.~Raghavendra, J.~Richards, P.~Sattigeri, K.~Shanmugam, M.~Singh, K.~R.
  Varshney, D.~Wei, and Y.~Zhang.
\newblock One explanation does not fit all: A toolkit and taxonomy of {AI}
  explainability techniques.
\newblock arXiv:1909.03012, 2019.

\bibitem{bach2015pixel}
S.~Bach, A.~Binder, G.~Montavon, F.~Klauschen, K.-R. M{\"u}ller, and W.~Samek.
\newblock On pixel-wise explanations for non-linear classifier decisions by
  layer-wise relevance propagation.
\newblock {\em PloS one}, 10(7):e0130140, 2015.

\bibitem{bastani2017interpreting}
O.~Bastani, C.~Kim, and H.~Bastani.
\newblock Interpreting blackbox models via model extraction.
\newblock {\em arXiv preprint arXiv:1705.08504}, 2017.

\bibitem{modelcompr}
C.~Bucilu\v{a}, R.~Caruana, and A.~Niculescu-Mizil.
\newblock Model compression.
\newblock In {\em Proceedings of the 12th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, 2006.

\bibitem{Caruana:2015}
R.~Caruana, Y.~Lou, J.~Gehrke, P.~Koch, M.~Sturm, and N.~Elhadad.
\newblock Intelligible models for healthcare: Predicting pneumonia risk and
  hospital 30-day readmission.
\newblock In {\em Proceedings of the 21th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, KDD '15, pages 1721--1730, New York,
  NY, USA, 2015. ACM.

\bibitem{boolcolumn}
S.~Dash, O.~G{\"{u}}nl{\"{u}}k, and D.~Wei.
\newblock Boolean decision rules via column generation.
\newblock {\em Advances in Neural Information Processing Systems}, 2018.

\bibitem{cem}
A.~Dhurandhar, P.-Y. Chen, R.~Luss, C.-C. Tu, P.~Ting, K.~Shanmugam, and
  P.~Das.
\newblock Explanations based on the missing: Towards contrastive explanations
  with pertinent negatives.
\newblock In {\em Advances in Neural Information Processing Systems 31}. 2018.

\bibitem{macem}
A.~Dhurandhar, T.~Pedapati, A.~Balakrishnan, P.-Y. Chen, K.~Shanmugam, and
  R.~Puri.
\newblock Model agnostic contrastive explanations for structured data.
\newblock {\em arxiv}, 2019.

\bibitem{profweight}
A.~Dhurandhar, K.~Shanmugam, R.~Luss, and P.~Olsen.
\newblock Improving simple models with confidence profiles.
\newblock {\em Advances of Neural Inf. Processing Systems (NeurIPS)}, 2018.

\bibitem{distill}
J.~D. Geoffrey~Hinton, Oriol~Vinyals.
\newblock Distilling the knowledge in a neural network.
\newblock In {\em https://arxiv.org/abs/1503.02531}, 2015.

\bibitem{gan}
I.~Goodfellow, Y.~Bengio, and A.~Courville.
\newblock {\em Deep Learning.}
\newblock MIT Press, 2016.

\bibitem{hendricks-2016}
L.~A. Hendricks, Z.~Akata, M.~Rohrbach, J.~Donahue, B.~Schiele, and T.~Darrell.
\newblock Generating visual explanations.
\newblock In {\em European Conference on Computer Vision}, 2016.

\bibitem{irt}
T.~Idé and A.~Dhurandhar.
\newblock Supervised item response models for informative prediction.
\newblock {\em Knowl. Inf. Syst.}, 51(1):235--257, Apr. 2017.

\bibitem{augcounter}
D.~Kaushik, E.~Hovy, and Z.~C. Lipton.
\newblock Learning the difference that makes a difference with
  counterfactually-augmented data.
\newblock In {\em Intl. Conference on Learning Representations}, 2020.

\bibitem{lundberg2017unified}
S.~M. Lundberg and S.-I. Lee.
\newblock A unified approach to interpreting model predictions.
\newblock In {\em Advances in neural information processing systems}, pages
  4765--4774, 2017.

\bibitem{cemmaf}
R.~Luss, P.-Y. Chen, A.~Dhurandhar, P.~Sattigeri, Z.~Yunfeng, K.~Shanmugam, and
  C.-C. Tu.
\newblock Generating contrastive explanations using monotonic attribute
  functions.
\newblock In {\em arXiv:1905.12698}. 2019.

\bibitem{miller2018explanation}
T.~Miller.
\newblock Explanation in artificial intelligence: Insights from the social
  sciences.
\newblock {\em Artificial Intelligence}, 2018.

\bibitem{molnarbook}
C.~Molnar.
\newblock Interpretable machine learning, 2019.

\bibitem{mothilal2019explaining}
R.~K. Mothilal, A.~Sharma, and C.~Tan.
\newblock Explaining machine learning classifiers through diverse
  counterfactual explanations.
\newblock {\em arXiv preprint arXiv:1905.07697}, 2019.

\bibitem{popov2019neural}
S.~Popov, S.~Morozov, and A.~Babenko.
\newblock Neural oblivious decision ensembles for deep learning on tabular
  data.
\newblock {\em arXiv preprint arXiv:1909.06312}, 2019.

\bibitem{lime}
M.~Ribeiro, S.~Singh, and C.~Guestrin.
\newblock "why should i trust you?” explaining the predictions of any
  classifier.
\newblock In {\em ACM SIGKDD Intl. Conference on Knowledge Discovery and Data
  Mining}, 2016.

\bibitem{rudin2019stop}
C.~Rudin.
\newblock Stop explaining black box machine learning models for high stakes
  decisions and use interpretable models instead.
\newblock {\em Nature Machine Intelligence}, 1(5):206--215, 2019.

\bibitem{unifiedPI}
S.-I.~L. Scott~Lundberg.
\newblock Unified framework for interpretable methods.
\newblock In {\em In Advances of Neural Inf. Proc. Systems}, 2017.

\bibitem{selvaraju2017grad}
R.~R. Selvaraju, M.~Cogswell, A.~Das, R.~Vedantam, D.~Parikh, and D.~Batra.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based
  localization.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 618--626, 2017.

\bibitem{saliency}
K.~Simonyan, A.~Vedaldi, and A.~Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock {\em CoRR}, abs/1312.6034, 2013.

\bibitem{toc}
M.~Sipser.
\newblock {\em Introduction to the Theory of Computation 3rd.}
\newblock Cengage Learning, 2013.

\bibitem{twl}
G.~Su, D.~Wei, K.~Varshney, and D.~Malioutov.
\newblock Interpretable two-level boolean rule learning for classification.
\newblock In {\em https://arxiv.org/abs/1606.05798}, 2016.

\bibitem{wachter2017counterfactual}
S.~Wachter, B.~Mittelstadt, and C.~Russell.
\newblock Counterfactual explanations without opening the black box: Automated
  decisions and the gdpr.
\newblock {\em Harv. JL \& Tech.}, 31:841, 2017.

\bibitem{gdpr}
P.~N. Yannella and O.~Kagan.
\newblock Analysis: Article 29 working party guidelines on automated decision
  making under gdpr.
\newblock 2018.
\newblock
  https://www.cyberadviserblog.com/2018/01/analysis-article-29-working-party-guidelines-on-automated-decision-making-under-gdpr/.

\end{thebibliography}
