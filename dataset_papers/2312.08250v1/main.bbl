\begin{thebibliography}{10}

\bibitem{austin2021program}
Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski,
  David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et~al.
\newblock Program synthesis with large language models.
\newblock {\em arXiv preprint arXiv:2108.07732}, 2021.

\bibitem{vizdoom_RL2021}
Maria Bakhanova and Ilya Makarov.
\newblock Deep reinforcement learning in vizdoom via dqn and actor-critic
  agents.
\newblock In {\em Proceedings of IWANN}, 2021.

\bibitem{deep_coder_2017}
Matej Balog, Alexander~L Gaunt, Marc Brockschmidt, Sebastian Nowozin, and
  Daniel Tarlow.
\newblock Deepcoder: Learning to write programs.
\newblock In {\em Proceedings of ICLR}, 2017.

\bibitem{berabi2021tfix}
Berkay Berabi, Jingxuan He, Veselin Raychev, and Martin Vechev.
\newblock Tfix: Learning to fix coding errors with a text-to-text transformer.
\newblock In {\em Proceedings of ICML}, 2021.

\bibitem{bovsnjak2017programming}
Matko Bo{\v{s}}njak, Tim Rockt{\"a}schel, Jason Naradowsky, and Sebastian
  Riedel.
\newblock Programming with a differentiable forth interpreter.
\newblock In {\em Proceedings of ICML}, 2017.

\bibitem{brody2022attentive}
Shaked Brody, Uri Alon, and Eran Yahav.
\newblock How attentive are graph attention networks?
\newblock In {\em Proceedings of ICLR}, 2022.

\bibitem{bunel2018leveraging}
Rudy Bunel, Matthew Hausknecht, Jacob Devlin, Rishabh Singh, and Pushmeet
  Kohli.
\newblock Leveraging grammar and reinforcement learning for neural program
  synthesis.
\newblock In {\em Proceedings of ICLR}, 2018.

\bibitem{bunel2016adaptive}
Rudy~R Bunel, Alban Desmaison, Pawan~K Mudigonda, Pushmeet Kohli, and Philip
  Torr.
\newblock Adaptive neural compilation.
\newblock In {\em Proceedings of NeurIPS}, 2016.

\bibitem{chen2019execution}
Xinyun Chen, Chang Liu, and Dawn Song.
\newblock Execution-guided neural program synthesis.
\newblock In {\em Proceedings of ICLR}, 2019.

\bibitem{chen2021latent}
Xinyun Chen, Dawn Song, and Yuandong Tian.
\newblock Latent execution for neural program synthesis beyond domain-specific
  languages.
\newblock In {\em Proceedings of NeurIPS}, 2021.

\bibitem{dang2020plans}
Rapha{\"e}l Dang-Nhu.
\newblock Plans: Neuro-symbolic program learning from videos.
\newblock In {\em Proceedings of NeurIPS}, 2020.

\bibitem{devlin2017neural}
Jacob Devlin, Rudy~R Bunel, Rishabh Singh, Matthew Hausknecht, and Pushmeet
  Kohli.
\newblock Neural program meta-induction.
\newblock In {\em Proceedings of NeurIPS}, 2017.

\bibitem{devlin2017robustfill}
Jacob Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh, Abdel-rahman
  Mohamed, and Pushmeet Kohli.
\newblock Robustfill: Neural program learning under noisy i/o.
\newblock In {\em Proceedings of ICML}, 2017.

\bibitem{duan2019watch}
Xuguang Duan, Qi~Wu, Chuang Gan, Yiwei Zhang, Wenbing Huang, Anton Van
  Den~Hengel, and Wenwu Zhu.
\newblock Watch, reason and code: Learning to represent videos using program.
\newblock In {\em Proceedings of ACM MM}, 2019.

\bibitem{el2020blind}
Majed El~Helou and Sabine S{\"u}sstrunk.
\newblock Blind universal bayesian image denoising with gaussian noise level
  learning.
\newblock {\em IEEE Transactions on Image Processing}, 2020.

\bibitem{ellis2019write}
Kevin Ellis, Maxwell Nye, Yewen Pu, Felix Sosa, Josh Tenenbaum, and Armando
  Solar-Lezama.
\newblock Write, execute, assess: Program synthesis with a repl.
\newblock In {\em Proceedings of NeurIPS}, 2019.

\bibitem{ellis2018learning}
Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, and Josh Tenenbaum.
\newblock Learning to infer graphics programs from hand-drawn images.
\newblock In {\em Proceedings of NeurIPS}, 2018.

\bibitem{garg2021transformers}
Abhay Garg, Anand Sriraman, Kunal Pagarey, and Shirish Karande.
\newblock Are transformers all that karel needs?
\newblock In {\em Proceedings of NeurIPS Workshop}, 2021.

\bibitem{gupta2020synthesize}
Kavi Gupta, Peter~Ebert Christensen, Xinyun Chen, and Dawn Song.
\newblock Synthesize, execute and debug: Learning to repair for neural program
  synthesis.
\newblock In {\em Proceedings of NeurIPS}, 2020.

\bibitem{hua2018towards}
Jinru Hua, Mengshi Zhang, Kaiyuan Wang, and Sarfraz Khurshid.
\newblock Towards practical program repair with on-demand candidate generation.
\newblock In {\em Proceedings of ICSE}, 2018.

\bibitem{huang2019synthesizing}
Justin Huang, Dieter Fox, and Maya Cakmak.
\newblock Synthesizing robot manipulation programs from a single observed human
  demonstration.
\newblock In {\em Proceedings of IROS}, 2019.

\bibitem{inala2022fault}
Jeevana~Priya Inala, Chenglong Wang, Mei Yang, Andres Codas, Mark
  Encarnaci{\'o}n, Shuvendu Lahiri, Madanlal Musuvathi, and Jianfeng Gao.
\newblock Fault-aware neural code rankers.
\newblock In {\em Proceedings of NeurIPS}, 2022.

\bibitem{jain2022jigsaw}
Naman Jain, Skanda Vaidyanath, Arun Iyer, Nagarajan Natarajan, Suresh
  Parthasarathy, Sriram Rajamani, and Rahul Sharma.
\newblock Jigsaw: Large language models meet program synthesis.
\newblock In {\em Proceedings of ICSE}, 2022.

\bibitem{vizdoom2016}
Michał Kempka, Marek Wydmuch, Grzegorz Runc, Jakub Toczek, and Wojciech
  Jaśkowski.
\newblock Vizdoom: A doom-based ai research platform for visual reinforcement
  learning.
\newblock In {\em Proceedings of CIG}, 2016.

\bibitem{KHAN2020100357}
Adil Khan, Muhammad Naeem, Muhammad~Zubair Asghar, Aziz~Ud Din, and Atif Khan.
\newblock Playing first-person shooter games with machine learning techniques
  and methods using the vizdoom game-ai research platform.
\newblock {\em Entertainment Computing}, 2020.

\bibitem{kulal2019spoc}
Sumith Kulal, Panupong Pasupat, Kartik Chandra, Mina Lee, Oded Padon, Alex
  Aiken, and Percy~S Liang.
\newblock Spoc: Search-based pseudocode to code.
\newblock In {\em Proceedings of NeurIPS}, 2019.

\bibitem{lazaro2019beyond}
Miguel L{\'a}zaro-Gredilla, Dianhuan Lin, J~Swaroop Guntupalli, and Dileep
  George.
\newblock Beyond imitation: Zero-shot task transfer on robots by learning
  concepts as cognitive programs.
\newblock {\em Science Robotics}, 2019.

\bibitem{le2022coderl}
Hung Le, Yue Wang, Akhilesh~Deepak Gotmare, Silvio Savarese, and Steven
  Chu~Hong Hoi.
\newblock Coderl: Mastering code generation through pretrained models and deep
  reinforcement learning.
\newblock In {\em Proceedings of NeurIPS}, 2022.

\bibitem{le2017s3}
Xuan-Bach~D Le, Duc-Hiep Chu, David Lo, Claire Le~Goues, and Willem Visser.
\newblock S3: syntax-and semantic-guided repair synthesis via programming by
  examples.
\newblock In {\em Proceedings of ESEC}, 2017.

\bibitem{6227211}
Claire Le~Goues, Michael Dewey-Vogt, Stephanie Forrest, and Westley Weimer.
\newblock A systematic study of automated program repair: Fixing 55 out of 105
  bugs for \$8 each.
\newblock In {\em Proceedings of ICSE}, 2012.

\bibitem{le2011genprog}
Claire Le~Goues, ThanhVu Nguyen, Stephanie Forrest, and Westley Weimer.
\newblock Genprog: A generic method for automatic software repair.
\newblock {\em Ieee transactions on software engineering}, 2011.

\bibitem{ling2016latent}
Wang Ling, Edward Grefenstette, Karl~Moritz Hermann, Tom{\'a}{\v{s}}
  Ko{\v{c}}isk{\`y}, Andrew Senior, Fumin Wang, and Phil Blunsom.
\newblock Latent predictor networks for code generation.
\newblock In {\em Proceedings of ACL}, 2016.

\bibitem{long2016automatic}
Fan Long and Martin Rinard.
\newblock Automatic patch generation by learning correct code.
\newblock In {\em Proceedings of POPL}, 2016.

\bibitem{manna1971toward}
Zohar Manna and Richard~J Waldinger.
\newblock Toward automatic program synthesis.
\newblock {\em Communications of the ACM}, 1971.

\bibitem{nguyen2013semfix}
Hoang Duong~Thien Nguyen, Dawei Qi, Abhik Roychoudhury, and Satish Chandra.
\newblock Semfix: Program repair via semantic analysis.
\newblock In {\em Proceedings of ICSE}, 2013.

\bibitem{pmlr-v97-nye19a}
Maxwell Nye, Luke Hewitt, Joshua Tenenbaum, and Armando Solar-Lezama.
\newblock Learning to infer program sketches.
\newblock In {\em Proceedings of ICML}, 2019.

\bibitem{parisotto2017neurosymbolic}
Emilio Parisotto, Abdel-rahman Mohamed, Rishabh Singh, Lihong Li, Dengyong
  Zhou, and Pushmeet Kohli.
\newblock Neuro-symbolic program synthesis.
\newblock In {\em Proceedings of ICLR}, 2017.

\bibitem{polozov2015flashmeta}
Oleksandr Polozov and Sumit Gulwani.
\newblock Flashmeta: A framework for inductive program synthesis.
\newblock In {\em Proceedings of OOPSLA}, 2015.

\bibitem{rolim2018learning}
Reudismam Rolim, Gustavo Soares, Rohit Gheyi, Titus Barik, and Loris D'Antoni.
\newblock Learning quick fixes from code repositories.
\newblock {\em arXiv preprint arXiv:1803.03806}, 2018.

\bibitem{schkufza2013stochastic}
Eric Schkufza, Rahul Sharma, and Alex Aiken.
\newblock Stochastic superoptimization.
\newblock {\em ACM SIGARCH Computer Architecture News}, 2013.

\bibitem{vizdoom_battles2018}
Kun Shao, Dongbin Zhao, Nannan Li, and Yuanheng Zhu.
\newblock Learning battles in vizdoom via deep reinforcement learning.
\newblock In {\em CIG}, 2018.

\bibitem{shao2021concept2robot}
Lin Shao, Toki Migimatsu, Qiang Zhang, Karen Yang, and Jeannette Bohg.
\newblock Concept2robot: Learning manipulation concepts from instructions and
  human demonstrations.
\newblock {\em The International Journal of Robotics Research}, 2021.

\bibitem{shin2018improving}
Eui~Chul Shin, Illia Polosukhin, and Dawn Song.
\newblock Improving neural program synthesis with inferred execution traces.
\newblock In {\em Proceedings of NeurIPS}, 2018.

\bibitem{shin2019synthetic}
Richard Shin, Neel Kant, Kavi Gupta, Chris Bender, Brandon Trabucco, Rishabh
  Singh, and Dawn Song.
\newblock Synthetic datasets for neural program synthesis.
\newblock In {\em Proceedings of ICLR}, 2019.

\bibitem{shin2018towards}
Richard Shin, Illia Polosukhin, and Dawn Song.
\newblock Towards specification-directed program repair.
\newblock In {\em Proceedings of ICLR Workshop}, 2018.

\bibitem{shrivastava2021learning}
Disha Shrivastava, Hugo Larochelle, and Daniel Tarlow.
\newblock Learning to combine per-example solutions for neural program
  synthesis.
\newblock In {\em Proceedings of NeurIPS}, 2021.

\bibitem{sun2018neural}
Shao-Hua Sun, Hyeonwoo Noh, Sriram Somasundaram, and Joseph Lim.
\newblock Neural program synthesis from diverse demonstration videos.
\newblock In {\em Proceedings of ICML}, 2018.

\bibitem{trivedi2021learning}
Dweep Trivedi, Jesse Zhang, Shao-Hua Sun, and Joseph~J Lim.
\newblock Learning to synthesize programs as interpretable and generalizable
  policies.
\newblock In {\em Proceedings of NeurIPS}, 2021.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em Proceedings of NeurIPS}, 2017.

\bibitem{velivckovic2018graph}
Petar Veli{\v{c}}kovi{\'c}, Guillem Cucurull, Arantxa Casanova, Adriana Romero,
  Pietro Li{\`o}, and Yoshua Bengio.
\newblock Graph attention networks.
\newblock In {\em Proceedings of ICLR}, 2018.

\bibitem{wang2017synthesizing}
Chenglong Wang, Alvin Cheung, and Rastislav Bodik.
\newblock Synthesizing highly expressive sql queries from input-output
  examples.
\newblock In {\em Proceedings of PLDI}, 2017.

\bibitem{wang2018dynamic}
Ke~Wang, Rishabh Singh, and Zhendong Su.
\newblock Dynamic neural program embeddings for program repair.
\newblock In {\em Proceedings of ICLR}, 2018.

\bibitem{vizdoom_comp2019}
Marek Wydmuch, Michał Kempka, and Wojciech Jaśkowski.
\newblock Vizdoom competitions: Playing doom from pixels.
\newblock {\em IEEE Transactions on Games}, 2019.

\bibitem{ye2022neural}
He~Ye, Matias Martinez, and Martin Monperrus.
\newblock Neural program repair with execution-based backpropagation.
\newblock In {\em Proceedings of ICSE}, 2022.

\bibitem{yin2021sequential}
Haiyan Yin, Jianda Chen, Sinno~Jialin Pan, and Sebastian Tschiatschek.
\newblock Sequential generative exploration model for partially observable
  reinforcement learning.
\newblock In {\em Proceedings of AAAI}, 2021.

\bibitem{zohar2018automatic}
Amit Zohar and Lior Wolf.
\newblock Automatic program synthesis of long programs with a learned garbage
  collector.
\newblock In {\em Proceedings of NeurIPS}, 2018.

\end{thebibliography}
