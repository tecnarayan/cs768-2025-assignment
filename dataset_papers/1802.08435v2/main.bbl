\begin{thebibliography}{26}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Chung et~al.(2014)Chung, G{\"{u}}l{\c{c}}ehre, Cho, and Bengio]{gru}
Chung, J., G{\"{u}}l{\c{c}}ehre, {\c{C}}., Cho, K., and Bengio, Y.
\newblock Empirical evaluation of gated recurrent neural networks on sequence
  modeling.
\newblock \emph{CoRR}, abs/1412.3555, 2014.

\bibitem[Diamos et~al.(2016)Diamos, Sengupta, Catanzaro, Chrzanowski, Coates,
  Elsen, Engel, Hannun, and Satheesh]{persistentrnns}
Diamos, G., Sengupta, S., Catanzaro, B., Chrzanowski, M., Coates, A., Elsen,
  E., Engel, J., Hannun, A., and Satheesh, S.
\newblock Persistent {RNNs}: Stashing recurrent weights on-chip.
\newblock In \emph{ICML}, pp.\  2024--2033, 2016.

\bibitem[Engel(2016)]{baidu_diffgraph}
Engel, J.
\newblock Optimizing {RNNs} with differentiable graphs, June 2016.
\newblock URL \url{https://svail.github.io/diff_graphs/}.

\bibitem[Engel et~al.(2017)Engel, Resnick, Roberts, Dieleman, Eck, Simonyan,
  and Norouzi]{nsynth}
Engel, J., Resnick, C., Roberts, A., Dieleman, S., Eck, D., Simonyan, K., and
  Norouzi, M.
\newblock Neural audio synthesis of musical notes with wavenet autoencoders.
\newblock \emph{CoRR}, abs/1704.01279, 2017.

\bibitem[geekbench({\natexlab{a}})]{nexus5xgeekbench}
geekbench, 2018{\natexlab{a}}.
\newblock URL \url{https://browser.geekbench.com/v4/cpu/6960655}.

\bibitem[geekbench({\natexlab{b}})]{pixel2geekbench}
geekbench, 2018{\natexlab{b}}.
\newblock URL \url{https://browser.geekbench.com/v4/cpu/6473830}.

\bibitem[{Gordon} et~al.(2017){Gordon}, {Eban}, {Nachum}, {Chen}, {Wu}, {Yang},
  and {Choi}]{morphnet}
{Gordon}, A., {Eban}, E., {Nachum}, O., {Chen}, B., {Wu}, H., {Yang}, T.-J.,
  and {Choi}, E.
\newblock {MorphNet: Fast \& Simple Resource-Constrained Structure Learning of
  Deep Networks}.
\newblock \emph{ArXiv e-prints}, November 2017.

\bibitem[Gray et~al.(2017)Gray, Radford, and Kingma]{openai_sparse}
Gray, S., Radford, A., and Kingma, D.
\newblock Block-sparse gpu kernels, Dec 2017.
\newblock URL \url{https://blog.openai.com/block-sparse-gpu-kernels/}.

\bibitem[Gu et~al.(2017)Gu, Bradbury, Xiong, Li, and
  Socher]{DBLP:journals/corr/abs-1711-02281}
Gu, J., Bradbury, J., Xiong, C., Li, V. O.~K., and Socher, R.
\newblock Non-autoregressive neural machine translation.
\newblock \emph{CoRR}, abs/1711.02281, 2017.

\bibitem[Kalchbrenner et~al.(2016)Kalchbrenner, Espeholt, Simonyan, van~den
  Oord, Graves, and Kavukcuoglu]{bytenet}
Kalchbrenner, N., Espeholt, L., Simonyan, K., van~den Oord, A., Graves, A., and
  Kavukcuoglu, K.
\newblock Neural machine translation in linear time.
\newblock \emph{CoRR}, abs/1610.10099, 2016.

\bibitem[Kalchbrenner et~al.(2017)Kalchbrenner, van~den Oord, Simonyan,
  Danihelka, Vinyals, Graves, and
  Kavukcuoglu]{DBLP:conf/icml/KalchbrennerOSD17}
Kalchbrenner, N., van~den Oord, A., Simonyan, K., Danihelka, I., Vinyals, O.,
  Graves, A., and Kavukcuoglu, K.
\newblock Video pixel networks.
\newblock In \emph{{ICML}}, volume~70, pp.\  1771--1779, 2017.

\bibitem[Lee et~al.(2018)Lee, Ahn, Kim, Chuang, and Kim]{viterbi-based}
Lee, D., Ahn, D., Kim, T., Chuang, P.~I., and Kim, J.-J.
\newblock Viterbi-based pruning for sparse matrix with fixed and high index
  compression ratio.
\newblock \emph{ICLR}, 2018.
\newblock URL \url{https://openreview.net/forum?id=S1D8MPxA-}.

\bibitem[Mehri et~al.(2016)Mehri, Kumar, Gulrajani, Kumar, Jain, Sotelo,
  Courville, and Bengio]{samplernn}
Mehri, S., Kumar, K., Gulrajani, I., Kumar, R., Jain, S., Sotelo, J.,
  Courville, A.~C., and Bengio, Y.
\newblock {SampleRNN:} an unconditional end-to-end neural audio generation
  model.
\newblock \emph{CoRR}, abs/1612.07837, 2016.

\bibitem[Narang et~al.(2017{\natexlab{a}})Narang, Diamos, and
  Sengupta]{exploringsparsity}
Narang, S., Diamos, E. E. G.~F., and Sengupta, S.
\newblock Exploring sparsity in recurrent neural networks.
\newblock \emph{CoRR}, abs/1704.05119, 2017{\natexlab{a}}.

\bibitem[Narang et~al.(2017{\natexlab{b}})Narang, Undersander, and
  Diamos]{blocksparse}
Narang, S., Undersander, E., and Diamos, G.~F.
\newblock Block-sparse recurrent neural networks.
\newblock \emph{CoRR}, abs/1711.02782, 2017{\natexlab{b}}.

\bibitem[Reed et~al.(2017)Reed, van~den Oord, Kalchbrenner, Colmenarejo, Wang,
  Chen, Belov, and de~Freitas]{DBLP:conf/icml/ReedOKCWCBF17}
Reed, S.~E., van~den Oord, A., Kalchbrenner, N., Colmenarejo, S.~G., Wang, Z.,
  Chen, Y., Belov, D., and de~Freitas, N.
\newblock Parallel multiscale autoregressive density estimation.
\newblock In \emph{{ICML}}, volume~70, pp.\  2912--2921, 2017.

\bibitem[Salimans et~al.(2017)Salimans, Karpathy, Chen, and Kingma]{salimans}
Salimans, T., Karpathy, A., Chen, X., and Kingma, D.~P.
\newblock {PixelCNN++}: Improving the pixelcnn with discretized logistic
  mixture likelihood and other modifications.
\newblock \emph{CoRR}, abs/1701.05517, 2017.

\bibitem[Simon \& Oore(2017)Simon and Oore]{performance-rnn-2017}
Simon, I. and Oore, S.
\newblock Performance {RNN}: Generating music with expressive timing and
  dynamics.
\newblock \url{https://magenta.tensorflow.org/performance-rnn}, 2017.

\bibitem[van~den Oord et~al.(2016{\natexlab{a}})van~den Oord, Dieleman, Zen,
  Simonyan, Vinyals, Graves, Kalchbrenner, Senior, and Kavukcuoglu]{wavenet}
van~den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A.,
  Kalchbrenner, N., Senior, A., and Kavukcuoglu, K.
\newblock {WaveNet}: A generative model for raw audio.
\newblock \emph{CoRR}, abs/1609.03499, 2016{\natexlab{a}}.

\bibitem[van~den Oord et~al.(2016{\natexlab{b}})van~den Oord, Kalchbrenner, and
  Kavukcuoglu]{van2016pixel}
van~den Oord, A., Kalchbrenner, N., and Kavukcuoglu, K.
\newblock Pixel recurrent neural networks.
\newblock In \emph{{ICML}}, volume~48, pp.\  1747--1756, 2016{\natexlab{b}}.

\bibitem[van~den Oord et~al.(2017)van~den Oord, Li, Babuschkin, Simonyan,
  Vinyals, Kavukcuoglu, van~den Driessche, Lockhart, Cobo, Stimberg,
  Casagrande, Grewe, Noury, Dieleman, Elsen, Kalchbrenner, Zen, Graves, King,
  Walters, Belov, and Hassabis]{parallel_wavenet}
van~den Oord, A., Li, Y., Babuschkin, I., Simonyan, K., Vinyals, O.,
  Kavukcuoglu, K., van~den Driessche, G., Lockhart, E., Cobo, L.~C., Stimberg,
  F., Casagrande, N., Grewe, D., Noury, S., Dieleman, S., Elsen, E.,
  Kalchbrenner, N., Zen, H., Graves, A., King, H., Walters, T., Belov, D., and
  Hassabis, D.
\newblock Parallel {WaveNet}: Fast high-fidelity speech synthesis.
\newblock \emph{CoRR}, abs/1711.10433, 2017.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{transformer}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, L., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{CoRR}, abs/1706.03762, 2017.

\bibitem[Wang et~al.(2017)Wang, Skerry{-}Ryan, Stanton, Wu, Weiss, Jaitly,
  Yang, Xiao, Chen, Bengio, Le, Agiomyrgiannakis, Clark, and Saurous]{tacotron}
Wang, Y., Skerry{-}Ryan, R.~J., Stanton, D., Wu, Y., Weiss, R.~J., Jaitly, N.,
  Yang, Z., Xiao, Y., Chen, Z., Bengio, S., Le, Q.~V., Agiomyrgiannakis, Y.,
  Clark, R., and Saurous, R.~A.
\newblock Tacotron: {A} fully end-to-end text-to-speech synthesis model.
\newblock \emph{CoRR}, abs/1703.10135, 2017.

\bibitem[Wu et~al.(2016)Wu, Schuster, Chen, Le, Norouzi, Macherey, Krikun, Cao,
  and al.]{wu}
Wu, Y., Schuster, M., Chen, Z., Le, Q.~V., Norouzi, M., Macherey, W., Krikun,
  M., Cao, Y., and al.
\newblock Google's neural machine translation system: Bridging the gap between
  human and machine translation.
\newblock \emph{CoRR}, abs/1609.08144, 2016.

\bibitem[Xiao \& c.~Feng(2010)Xiao and c.~Feng]{gpubarriers}
Xiao, S. and c.~Feng, W.
\newblock Inter-block {GPU} communication via fast barrier synchronization.
\newblock In \emph{2010 IEEE International Symposium on Parallel Distributed
  Processing (IPDPS)}, pp.\  1--12, 2010.

\bibitem[{Zhu} \& {Gupta}(2017){Zhu} and {Gupta}]{topruneornot}
{Zhu}, M. and {Gupta}, S.
\newblock {To prune, or not to prune: exploring the efficacy of pruning for
  model compression}.
\newblock \emph{CoRR}, abs/1710.01878, 2017.

\end{thebibliography}
