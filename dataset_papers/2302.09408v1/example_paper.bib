@article{jin2021best,
  title={The best of both worlds: stochastic and adversarial episodic mdps with unknown transition},
  author={Jin, Tiancheng and Huang, Longbo and Luo, Haipeng},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={20491--20502},
  year={2021}
}

@article{lai1985asymptotically,
  title={Asymptotically efficient adaptive allocation rules},
  author={Lai, Tze Leung and Robbins, Herbert and others},
  journal={Advances in applied mathematics},
  volume={6},
  number={1},
  pages={4--22},
  year={1985}
}

@article{chen2022policy,
  title={Policy Optimization for Stochastic Shortest Path},
  author={Chen, Liyu and Luo, Haipeng and Rosenberg, Aviv},
  journal={arXiv preprint arXiv:2202.03334},
  year={2022}
}

@article{luo2021policy,
  title={Policy optimization in adversarial mdps: Improved exploration via dilated bonuses},
  author={Luo, Haipeng and Wei, Chen-Yu and Lee, Chung-Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={22931--22942},
  year={2021}
}

@article{neu2020online,
  title={Online learning in MDPs with linear function approximation and bandit feedback},
  author={Neu, Gergely and Olkhovskaya, Julia},
  journal={arXiv preprint arXiv:2007.01612v1},
  year={2020}
}

@article{neu2021online,
  title={Online learning in MDPs with linear function approximation and bandit feedback},
  author={Neu, Gergely and Olkhovskaya, Julia},
  journal={arXiv preprint arXiv:2007.01612v2},
  year={2021}
}

@article{meng2010optimal,
  title={The optimal perturbation bounds of the Moore--Penrose inverse under the Frobenius norm},
  author={Meng, Lingsheng and Zheng, Bing},
  journal={Linear algebra and its applications},
  volume={432},
  number={4},
  pages={956--963},
  year={2010},
  publisher={Elsevier}
}

@article{agarwal2020pc,
  title={PC-PG: Policy cover directed exploration for provable policy gradient learning},
  author={Agarwal, Alekh and Henaff, Mikael and Kakade, Sham and Sun, Wen},
  journal={arXiv preprint arXiv:2007.08459},
  year={2020}
}

@article{du2019good,
  title={Is a good representation sufficient for sample efficient reinforcement learning?},
  author={Du, Simon S and Kakade, Sham M and Wang, Ruosong and Yang, Lin F},
  journal={arXiv preprint arXiv:1910.03016},
  year={2019}
}

@inproceedings{seldin2017improved,
  title={An improved parametrization and analysis of the EXP3++ algorithm for stochastic and adversarial bandits},
  author={Seldin, Yevgeny and Lugosi, G{\'a}bor},
  booktitle={Conference on Learning Theory},
  pages={1743--1759},
  year={2017},
  organization={PMLR}
}

@article{erez2021best,
  title={Best-of-all-worlds bounds for online learning with feedback graphs},
  author={Erez, Liad and Koren, Tomer},
  journal={arXiv preprint arXiv:2107.09572},
  year={2021}
}

@article{tsuchiya2022best,
  title={Best-of-Both-Worlds Algorithms for Partial Monitoring},
  author={Tsuchiya, Taira and Ito, Shinji and Honda, Junya},
  journal={arXiv preprint arXiv:2207.14550},
  year={2022}
}

@inproceedings{rouyer2021algorithm,
  title={An algorithm for stochastic and adversarial bandits with switching costs},
  author={Rouyer, Chlo{\'e} and Seldin, Yevgeny and Cesa-Bianchi, Nicol{\`o}},
  booktitle={International Conference on Machine Learning},
  pages={9127--9135},
  year={2021},
  organization={PMLR}
} 

@misc{luo2022homework3,
  author        = {Luo, Haipeng},
  title         = {Homework 3 Solution, Introduction to Online Optimization/Learning},
  month         = {November},
  year          = {2022},
  howpublished = "\url{http://haipeng-luo.net/courses/CSCI659/2022_fall/homework/HW3_solutions.pdf}",
}

@inproceedings{chen2021impossible,
  title={Impossible tuning made possible: A new expert algorithm and its applications},
  author={Chen, Liyu and Luo, Haipeng and Wei, Chen-Yu},
  booktitle={Conference on Learning Theory},
  pages={1216--1259},
  year={2021},
  organization={PMLR}
}

@inproceedings{he2022near,
  title={Near-optimal Policy Optimization Algorithms for Learning Adversarial Linear Mixture MDPs},
  author={He, Jiafan and Zhou, Dongruo and Gu, Quanquan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4259--4280},
  year={2022},
  organization={PMLR}
}

@article{amir2022better,
  title={Better Best of Both Worlds Bounds for Bandits with Switching Costs},
  author={Amir, Idan and Azov, Guy and Koren, Tomer and Livni, Roi},
  journal={arXiv preprint arXiv:2206.03098},
  year={2022}
}

@inproceedings{zimmert2019beating,
  title={Beating stochastic and adversarial semi-bandits optimally and simultaneously},
  author={Zimmert, Julian and Luo, Haipeng and Wei, Chen-Yu},
  booktitle={International Conference on Machine Learning},
  pages={7683--7692},
  year={2019},
  organization={PMLR}
}

@inproceedings{auer2016algorithm,
  title={An algorithm with nearly optimal pseudo-regret for both stochastic and adversarial bandits},
  author={Auer, Peter and Chiang, Chao-Kai},
  booktitle={Conference on Learning Theory},
  pages={116--120},
  year={2016},
  organization={PMLR}
}



@inproceedings{seldin2014one,
  title={One practical algorithm for both stochastic and adversarial bandits},
  author={Seldin, Yevgeny and Slivkins, Aleksandrs},
  booktitle={International Conference on Machine Learning},
  pages={1287--1295},
  year={2014},
  organization={PMLR}
}



@inproceedings{bubeck2012best,
  title={The best of both worlds: Stochastic and adversarial bandits},
  author={Bubeck, S{\'e}bastien and Slivkins, Aleksandrs},
  booktitle={Conference on Learning Theory},
  pages={42--1},
  year={2012},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{jin2020simultaneously,
  title={Simultaneously learning stochastic and adversarial episodic mdps with known transition},
  author={Jin, Tiancheng and Luo, Haipeng},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={16557--16566},
  year={2020}
}

@article{wang2020reward,
  title={On reward-free reinforcement learning with linear function approximation},
  author={Wang, Ruosong and Du, Simon S and Yang, Lin F and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2006.11274},
  year={2020}
}

@article{tropp2012user,
  title={User-friendly tail bounds for sums of random matrices},
  author={Tropp, Joel A},
  journal={Foundations of computational mathematics},
  volume={12},
  number={4},
  pages={389--434},
  year={2012},
  publisher={Springer}
}




@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={In Proc. 19th International Conference on Machine Learning},
  year={2002},
  organization={Citeseer}
}

@inproceedings{yang2020reinforcement,
  title={Reinforcement learning in feature space: Matrix bandit, kernels, and regret bound},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={10746--10756},
  year={2020},
  organization={PMLR}
}

@inproceedings{zanette2020frequentist,
  title={Frequentist regret bounds for randomized least-squares value iteration},
  author={Zanette, Andrea and Brandfonbrener, David and Brunskill, Emma and Pirotta, Matteo and Lazaric, Alessandro},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1954--1964},
  year={2020},
  organization={PMLR}
}

@inproceedings{zanette2019tighter,
  title={Tighter problem-dependent regret bounds in reinforcement learning without domain knowledge using value function bounds},
  author={Zanette, Andrea and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={7304--7312},
  year={2019},
  organization={PMLR}
}

@article{dann2015sample,
  title={Sample complexity of episodic fixed-horizon reinforcement learning},
  author={Dann, Christoph and Brunskill, Emma},
  journal={arXiv preprint arXiv:1510.08906},
  year={2015}
}

@article{dong2019q,
  title={Q-learning with ucb exploration is sample efficient for infinite-horizon mdp},
  author={Dong, Kefan and Wang, Yuanhao and Chen, Xiaoyu and Wang, Liwei},
  journal={arXiv preprint arXiv:1901.09311},
  year={2019}
}

@inproceedings{fruit2018efficient,
  title={Efficient bias-span-constrained exploration-exploitation in reinforcement learning},
  author={Fruit, Ronan and Pirotta, Matteo and Lazaric, Alessandro and Ortner, Ronald},
  booktitle={International Conference on Machine Learning},
  pages={1578--1586},
  year={2018},
  organization={PMLR}
}

@article{lazic2021improved,
  title={Improved Regret Bound and Experience Replay in Regularized Policy Iteration},
  author={Lazic, Nevena and Yin, Dong and Abbasi-Yadkori, Yasin and Szepesvari, Csaba},
  journal={arXiv preprint arXiv:2102.12611},
  year={2021}
}

@article{zhang2020reinforcement,
  title={Is reinforcement learning more difficult than bandits? a near-optimal algorithm escaping the curse of horizon},
  author={Zhang, Zihan and Ji, Xiangyang and Du, Simon S},
  journal={arXiv preprint arXiv:2009.13503},
  year={2020}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International conference on machine learning},
  pages={1--9},
  year={2013},
  organization={PMLR}
}

@inproceedings{cai2020provably,
  title={Provably efficient exploration in policy optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={1283--1294},
  year={2020},
  organization={PMLR}
}

@article{zanette2021cautiously,
    title={Cautiously Optimistic Policy Optimization and Exploration with Linear Function Approximation},
    author={Andrea Zanette and Ching-An Cheng and Alekh Agarwal},
      journal={arXiv preprint arXiv:2103.12923},
    year={2021},
}

@inproceedings{wei2021learning,
  title={Learning infinite-horizon average-reward mdps with linear function approximation},
  author={Wei, Chen-Yu and Jahromi, Mehdi Jafarnia and Luo, Haipeng and Jain, Rahul},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3007--3015},
  year={2021},
  organization={PMLR}
}

@inproceedings{zanette2020learning,
  title={Learning near optimal policies with low inherent bellman error},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={10978--10989},
  year={2020},
  organization={PMLR}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}

@inproceedings{abbasi2019politex,
  title={Politex: Regret bounds for policy iteration using expert prediction},
  author={Abbasi-Yadkori, Yasin and Bartlett, Peter and Bhatia, Kush and Lazic, Nevena and Szepesvari, Csaba and Weisz, Gell{\'e}rt},
  booktitle={International Conference on Machine Learning},
  pages={3692--3702},
  year={2019},
  organization={PMLR}
}

@inproceedings{agarwal2020optimality,
  title={Optimality and approximation with policy gradient methods in markov decision processes},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  booktitle={Conference on Learning Theory},
  pages={64--66},
  year={2020},
  organization={PMLR}
}

@article{jaksch2010near,
  title={Near-optimal Regret Bounds for Reinforcement Learning.},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={4},
  year={2010}
}

@inproceedings{wei2020model,
  title={Model-free reinforcement learning in infinite-horizon average-reward markov decision processes},
  author={Wei, Chen-Yu and Jahromi, Mehdi Jafarnia and Luo, Haipeng and Sharma, Hiteshi and Jain, Rahul},
  booktitle={International Conference on Machine Learning},
  pages={10170--10180},
  year={2020},
  organization={PMLR}
}

@inproceedings{shani2020optimistic,
  title={Optimistic policy optimization with bandit feedback},
  author={Shani, Lior and Efroni, Yonathan and Rosenberg, Aviv and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={8604--8613},
  year={2020},
  organization={PMLR}
}

@inproceedings{rosenberg2019online,
	title={Online Stochastic Shortest Path with Bandit Feedback and Unknown Transition Function},
	author={Rosenberg, Aviv and Mansour, Yishay},
	booktitle={Advances in Neural Information Processing Systems},
	year={2019}
}

@inproceedings{zimmert2019optimal,
  title={An optimal algorithm for stochastic and adversarial bandits},
  author={Zimmert, Julian and Seldin, Yevgeny},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={467--475},
  year={2019},
  organization={PMLR}
}

@article{ito2022nearly,
  title={Nearly Optimal Best-of-Both-Worlds Algorithms for Online Learning with Feedback Graphs},
  author={Ito, Shinji and Tsuchiya, Taira and Honda, Junya},
  journal={arXiv preprint arXiv:2206.00873},
  year={2022}
}

@inproceedings{ito2021parameter,
  title={Parameter-free multi-armed bandit algorithms with hybrid data-dependent regret bounds},
  author={Ito, Shinji},
  booktitle={Conference on Learning Theory},
  pages={2552--2583},
  year={2021},
  organization={PMLR}
}

@inproceedings{zimin2013,
	author = {Zimin, Alexander and Neu, Gergely},
	title = {Online Learning in Episodic Markovian Decision Processes by Relative Entropy Policy Search},
	booktitle = {Advances in Neural Information Processing Systems},
	year={2013}
} 

@inproceedings{LLZ20,
  title={A Closer Look at Small-loss Bounds for Bandits with Graph Feedback},
  author={Lee, Chung-Wei and Luo, Haipeng and Zhang, Mengxiao},
  booktitle={Conference on Learning Theory},
  year={2020}
}
@inproceedings{abernethy2009beating,
  title={Beating the adaptive bandit with high probability},
  author={Abernethy, Jacob and Rakhlin, Alexander},
  booktitle={Conference on Learning Theory},
  year={2009}
}
@inproceedings{abernethy2008competing,
	title={Competing in the Dark: An Efficient Algorithm for Bandit Linear Optimization},
	author={Abernethy, Jacob D and Hazan, Elad and Rakhlin, Alexander},
	booktitle={Conference on Learning Theory},
	year={2008}
}
@inproceedings{beygelzimer2011contextual,
	title={Contextual bandit algorithms with supervised learning guarantees},
	author={Beygelzimer, Alina and Langford, John and Li, Lihong and Reyzin, Lev and Schapire, Robert},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	year={2011}
}
@inproceedings{neu2015explore,
	title={Explore no more: Improved high-probability regret bounds for non-stochastic bandits},
	author={Neu, Gergely},
	booktitle={Advances in Neural Information Processing Systems},
	year={2015}
}
@inproceedings{AllenbergAuGyOt06,
	title={Hannan consistency in on-line learning in case of unbounded losses under partial monitoring},
	author={Allenberg, Chamy and Auer, Peter and Gy{\"o}rfi, L{\'a}szl{\'o} and Ottucs{\'a}k, Gy{\"o}rgy},
	booktitle={International conference on Algorithmic Learning Theory},
	year={2006}
}
@article{auer2002nonstochastic,
	title={The nonstochastic multiarmed bandit problem},
	author={Auer, Peter and Cesa-Bianchi, Nicol{\`o} and Freund, Yoav and Schapire, Robert E},
	journal={SIAM Journal on Computing},
	volume={32},
	number={1},
	year={2002}
}
@inproceedings{audibert2009minimax,
	title={Minimax policies for adversarial and stochastic bandits},
	author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien},
	booktitle={Conference on Learning Theory},
	year={2009}
}
@inproceedings{wei2018more,
	title={More Adaptive Algorithms for Adversarial Bandits},
	author={Wei, Chen-Yu and Luo, Haipeng},
	booktitle={Conference On Learning Theory},
	year={2018}
}
@book{lattimore2018bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  publisher={Cambridge University Press (preprint)},
  year={2018}
}
@inproceedings{bartlett2008high,
  title={High-probability regret bounds for bandit online linear optimization},
  author={Bartlett, Peter L and Dani, Varsha and Hayes, Thomas and Kakade, Sham and Rakhlin, Alexander and Tewari, Ambuj},
  booktitle={Conference On Learning Theory},
  year={2008}
}
@inproceedings{jin2019learning,
  title={Learning Adversarial Markov Decision Processes with Bandit Feedback and Unknown Transition},
  author={Chi Jin and Tiancheng Jin and Haipeng Luo and Suvrit Sra and Tiancheng Yu},
  booktitle={International Conference on Machine Learning},
  year={2020}
}
@inproceedings{bubeck2017kernel,
  title={Kernel-based methods for bandit convex optimization},
  author={Bubeck, S{\'e}bastien and Lee, Yin Tat and Eldan, Ronen},
  booktitle={Symposium on Theory of Computing},
  year={2017}
}
@inproceedings{agarwal2017corralling,
  title={Corralling a Band of Bandit Algorithms},
  author={Agarwal, Alekh and Luo, Haipeng and Neyshabur, Behnam and Schapire, Robert E},
  booktitle={Conference on Learning Theory},
  year={2017}
}
@inproceedings{FosterLiLySrTa16,
 title={Learning in Games: Robustness of Fast Convergence},
  author={Foster, Dylan J and Li, Zhiyuan and Lykouris, Thodoris and Sridharan, Karthik and Tardos, Eva},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
} 
@inproceedings{allen2018make,
  title={Make the minority great again: First-order regret bound for contextual bandits},
  author={Allen-Zhu, Zeyuan and Bubeck, S{\'e}bastien and Li, Yuanzhi},
  booktitle={International Conference on Machine Learning},
  year={2018}
}
@article{braun2016efficient,
  title={An efficient high-probability algorithm for linear bandits},
  author={Braun, G{\'a}bor and Pokutta, Sebastian},
  journal={arXiv preprint arXiv:1610.02072},
  year={2016}
}
@article{abernethy2012interior,
  title={Interior-point methods for full-information and bandit online learning},
  author={Abernethy, Jacob D and Hazan, Elad and Rakhlin, Alexander},
  journal={IEEE Transactions on Information Theory},
  volume={58},
  number={7},
  pages={4164--4175},
  year={2012},
  publisher={IEEE}
}

@misc{luo2017,
  title={Lecture 2, Introduction to Online Learning},
  author={Luo, Haipeng},
  note = {Available at \url{https://haipeng-luo.net/courses/CSCI699/lecture2.pdf}},
  year={2017}
} 
@inproceedings{lykouris2018small,
  title={Small-loss bounds for online learning with partial information},
  author={Lykouris, Thodoris and Sridharan, Karthik and Tardos, {\'E}va},
  booktitle={Conference on Learning Theory},
  year={2018}
}
@inproceedings{luo2018efficient,
  title={Efficient online portfolio with logarithmic regret},
  author={Luo, Haipeng and Wei, Chen-Yu and Zheng, Kai},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}
@inproceedings{neu2015first,
  title={First-order regret bounds for combinatorial semi-bandits},
  author={Neu, Gergely},
  booktitle={Conference on Learning Theory},
  year={2015}
}
@inproceedings{abernethy2019online,
  title={Online Learning via the Differential Privacy Lens},
  author={Abernethy, Jacob D and Jung, Young Hun and Lee, Chansoo and McMillan, Audra and Tewari, Ambuj},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}
@book{nesterov1994interior,
  title={Interior-point polynomial algorithms in convex programming},
  author={Nesterov, Yurii and Nemirovskii, Arkadii},
  volume={13},
  year={1994},
  publisher={Siam}
}
@inproceedings{bubeck2018sparsity,
  title={Sparsity, variance and curvature in multi-armed bandits},
  author={Bubeck, S{\'e}bastien and Cohen, Michael and Li, Yuanzhi},
  booktitle={Algorithmic Learning Theory},
  year={2018}
}
@inproceedings{bubeck2019improved,
  title={Improved Path-length Regret Bounds for Bandits},
  author={Bubeck, S{\'e}bastien and Li, Yuanzhi and Luo, Haipeng and Wei, Chen-Yu},
  booktitle={Conference On Learning Theory},
  year={2019}
}
@article{freedman1975tail,
  title={On tail probabilities for martingales},
  author={Freedman, David A},
  journal={the Annals of Probability},
  pages={100--118},
  year={1975},
  publisher={JSTOR}
}
@inproceedings{audibert2011minimax,
  title={Minimax policies for combinatorial prediction games},
  author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien and Lugosi, G{\'a}bor},
  booktitle={Proceedings of the 24th Annual Conference on Learning Theory},
  year={2011}
}
@article{cesa2012combinatorial,
  title={Combinatorial bandits},
  author={Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  journal={Journal of Computer and System Sciences},
  volume={78},
  number={5},
  pages={1404--1422},
  year={2012},
  publisher={Elsevier}
}
@inproceedings{dani2008price,
  title={The price of bandit information for online optimization},
  author={Dani, Varsha and Kakade, Sham M and Hayes, Thomas P},
  booktitle={Advances in Neural Information Processing Systems},
  year={2008}
}
@inproceedings{bubeck2012towards,
  title={Towards minimax policies for online linear optimization with bandit feedback},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and Kakade, Sham M},
  booktitle={Conference on Learning Theory},
  year={2012}
}
@article{hazan2016volumetric,
  title={Volumetric spanners: an efficient exploration basis for learning},
  author={Hazan, Elad and Karnin, Zohar},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={4062--4095},
  year={2016},
  publisher={JMLR. org}
}
@inproceedings{awerbuch2004adaptive,
  title={Adaptive routing with end-to-end feedback: Distributed learning and geometric approaches},
  author={Awerbuch, Baruch and Kleinberg, Robert D},
  booktitle={Symposium on Theory of Computing},
  year={2004}
}
@article{gyorgy2007line,
  title={The on-line shortest path problem under partial monitoring},
  author={Gy{\"o}rgy, Andr{\'a}s and Linder, Tam{\'a}s and Lugosi, G{\'a}bor and Ottucs{\'a}k, Gy{\"o}rgy},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={Oct},
  pages={2369--2403},
  year={2007}
}
@inproceedings{saha2011improved,
  title={Improved regret guarantees for online smooth convex optimization with bandit feedback},
  author={Saha, Ankan and Tewari, Ambuj},
  booktitle={ International Conference on Artificial Intelligence and Statistics},
  year={2011}
}
@book{shalev2014understanding,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}
@article{hazan2011better,
  title={Better algorithms for benign bandits},
  author={Hazan, Elad and Kale, Satyen},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Apr},
  pages={1287--1311},
  year={2011}
}
@inproceedings{rakhlin2013online,
  title={Online learning with predictable sequences},
  author={Rakhlin, Alexander and Sridharan, Karthik},
  booktitle={Conference on Learning Theory},
  year={2013}
}
@InProceedings{pmlr-v97-rosenberg19a,
  title = 	 {Online Convex Optimization in Adversarial {M}arkov Decision Processes},
  author = 	 {Rosenberg, Aviv and Mansour, Yishay},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  year = {2019}
}

@article{lee2020bias,
	title={Bias no more: high-probability data-dependent regret bounds for adversarial bandits and MDPs},
	author={Lee, Chung-Wei and Luo, Haipeng and Wei, Chen-Yu and Zhang, Mengxiao},
	journal={Advances in Neural Information Processing Systems},
	year={2020}
}

@inproceedings{chen2021finding,
  title={Finding the stochastic shortest path with low regret: The adversarial cost and unknown transition case},
  author={Chen, Liyu and Luo, Haipeng},
  booktitle={International Conference on Machine Learning},
  year={2021},
}

@inproceedings{chen2020minimax,
  title={Minimax Regret for Stochastic Shortest Path with Adversarial Costs and Known Transition},
  author={Chen, Liyu and Luo, Haipeng and Wei, Chen-Yu},
  booktitle={Conference On Learning Theory},
  year={2021},
}

@inproceedings{jin2018q,
  title={Is {Q}-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  booktitle={Advances in neural information processing systems},
  pages={4863--4873},
  year={2018}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@article{kakade2001natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  journal={Advances in neural information processing systems},
  volume={14},
  year={2001}
}

@inproceedings{sidford2018near,
  title={Near-optimal time and sample complexities for solving Markov decision processes with a generative model},
  author={Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin F and Ye, Yinyu},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5192--5202},
  year={2018}
}

@inproceedings{azar2012sample,
  title={On the sample complexity of reinforcement learning with a generative model},
  author={Azar, Mohammad Gheshlaghi and Munos, R{\'e}mi and Kappen, Bert},
  booktitle={International Conference on Machine Learning},
  year={2012}
}

@inproceedings{xu2021fine,
  title={Fine-grained gap-dependent bounds for tabular mdps via adaptive multi-step bootstrap},
  author={Xu, Haike and Ma, Tengyu and Du, Simon},
  booktitle={Conference on Learning Theory},
  pages={4438--4472},
  year={2021},
  organization={PMLR}
}