\begin{thebibliography}{28}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi-Yadkori et~al.(2011)Abbasi-Yadkori, P{\'a}l, and Szepesv{\'a}ri]{abbasi2011improved}
Yasin Abbasi-Yadkori, D{\'a}vid P{\'a}l, and Csaba Szepesv{\'a}ri.
\newblock Improved algorithms for linear stochastic bandits.
\newblock \emph{Advances in neural information processing systems}, 24, 2011.

\bibitem[Abeille et~al.(2021)Abeille, Faury, and Calauz{\`e}nes]{abeille2021instance}
Marc Abeille, Louis Faury, and Cl{\'e}ment Calauz{\`e}nes.
\newblock Instance-wise minimax-optimal algorithms for logistic bandits.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 3691--3699. PMLR, 2021.

\bibitem[Auer(2002)]{auer2002using}
Peter Auer.
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0 (Nov):\penalty0 397--422, 2002.

\bibitem[Chu et~al.(2011)Chu, Li, Reyzin, and Schapire]{pmlr-v15-chu11a}
Wei Chu, Lihong Li, Lev Reyzin, and Robert Schapire.
\newblock Contextual bandits with linear payoff functions.
\newblock In Geoffrey Gordon, David Dunson, and Miroslav Dudík, editors, \emph{Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics}, volume~15 of \emph{Proceedings of Machine Learning Research}, pages 208--214, Fort Lauderdale, FL, USA, 11--13 Apr 2011. PMLR.
\newblock URL \url{https://proceedings.mlr.press/v15/chu11a.html}.

\bibitem[Faury(2021)]{faurythesis}
Louis Faury.
\newblock \emph{{Variance-sensitive confidence intervals for parametric and offline bandits}}.
\newblock Theses, {Institut Polytechnique de Paris}, Oct 2021.
\newblock URL \url{https://tel.archives-ouvertes.fr/tel-03485328}.

\bibitem[Faury et~al.(2020)Faury, Abeille, Calauz{\`e}nes, and Fercoq]{faury_improved_2020}
Louis Faury, Marc Abeille, Cl{\'e}ment Calauz{\`e}nes, and Olivier Fercoq.
\newblock Improved optimistic algorithms for logistic bandits.
\newblock In \emph{International Conference on Machine Learning}, pages 3052--3060. PMLR, 2020.

\bibitem[Faury et~al.(2022)Faury, Abeille, Jun, and Calauz{\`e}nes]{faury2022jointly}
Louis Faury, Marc Abeille, Kwang-Sung Jun, and Cl{\'e}ment Calauz{\`e}nes.
\newblock Jointly efficient and optimal algorithms for logistic bandits.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 546--580. PMLR, 2022.

\bibitem[Filippi et~al.(2010)Filippi, Cappe, Garivier, and Szepesv{\'a}ri]{filippi2010parametric}
Sarah Filippi, Olivier Cappe, Aur{\'e}lien Garivier, and Csaba Szepesv{\'a}ri.
\newblock Parametric bandits: The generalized linear case.
\newblock \emph{Advances in neural information processing systems}, 23, 2010.

\bibitem[Gao et~al.(2019)Gao, Han, Ren, and Zhou]{gao2019batched}
Zijun Gao, Yanjun Han, Zhimei Ren, and Zhengqing Zhou.
\newblock Batched multi-armed bandits problem.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Group et~al.(1997)]{international1997international}
International Stroke Trial~Collaborative Group et~al.
\newblock The international stroke trial (ist): a randomised trial of aspirin, subcutaneous heparin, both, or neither among 19 435 patients with acute ischaemic stroke.
\newblock \emph{The Lancet}, 349\penalty0 (9065):\penalty0 1569--1581, 1997.

\bibitem[Han et~al.(2020)Han, Zhou, Zhou, Blanchet, Glynn, and Ye]{han2020sequential}
Yanjun Han, Zhengqing Zhou, Zhengyuan Zhou, Jose Blanchet, Peter~W Glynn, and Yinyu Ye.
\newblock Sequential batch learning in finite-action linear contextual bandits.
\newblock \emph{arXiv preprint arXiv:2004.06321}, 2020.

\bibitem[Hanna et~al.(2022)Hanna, Yang, and Fragouli]{hanna2022learning}
Osama Hanna, Lin Yang, and Christina Fragouli.
\newblock Learning from distributed users in contextual linear bandits without sharing the context.
\newblock In Alice~H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=RIArO3o_74Z}.

\bibitem[Hanna et~al.(2023)Hanna, Yang, and Fragouli]{hanna2023efficient}
Osama Hanna, Lin Yang, and Christina Fragouli.
\newblock Efficient batched algorithm for contextual linear bandits with large action space via soft elimination.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=L7Whl9pXd0}.

\bibitem[Jun et~al.(2017)Jun, Bhargava, Nowak, and Willett]{jun2017scalable}
Kwang-Sung Jun, Aniruddha Bhargava, Robert Nowak, and Rebecca Willett.
\newblock Scalable generalized linear bandits: Online computation and hashing.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Kiefer and Wolfowitz(1960)]{kiefer1960equivalence}
Jack Kiefer and Jacob Wolfowitz.
\newblock The equivalence of two extremum problems.
\newblock \emph{Canadian Journal of Mathematics}, 12:\penalty0 363--366, 1960.

\bibitem[Lattimore and Szepesvári(2020)]{Lattimore_Szepesvári_2020}
Tor Lattimore and Csaba Szepesvári.
\newblock \emph{Bandit Algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem[Lee et~al.(2024)Lee, Yun, and Jun]{lee2023improved}
Junghyun Lee, Se-Young Yun, and Kwang-Sung Jun.
\newblock Improved regret bounds of (multinomial) logistic bandits via regret-to-confidence-set conversion.
\newblock In \emph{Proceedings of The 27th International Conference on Artificial Intelligence and Statistics}, pages 4474--4482. PMLR, 02--04 May 2024.
\newblock URL \url{https://proceedings.mlr.press/v238/lee24d.html}.

\bibitem[Li et~al.(2010)Li, Chu, Langford, and Schapire]{li2010contextual}
Lihong Li, Wei Chu, John Langford, and Robert~E Schapire.
\newblock A contextual-bandit approach to personalized news article recommendation.
\newblock In \emph{Proceedings of the 19th international conference on World wide web}, pages 661--670, 2010.

\bibitem[Li et~al.(2017)Li, Lu, and Zhou]{li2017provably}
Lihong Li, Yu~Lu, and Dengyong Zhou.
\newblock Provably optimal algorithms for generalized linear contextual bandits.
\newblock In \emph{International Conference on Machine Learning}, pages 2071--2080. PMLR, 2017.

\bibitem[Mason et~al.(2022)Mason, Jun, and Jain]{mason2022experimental}
Blake Mason, Kwang-Sung Jun, and Lalit Jain.
\newblock An experimental design approach for regret minimization in logistic bandits.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~36, pages 7736--7743, 2022.

\bibitem[Perchet et~al.(2015)Perchet, Rigollet, Chassang, and Snowberg]{perchet2016batched}
Vianney Perchet, Philippe Rigollet, Sylvain Chassang, and Erik Snowberg.
\newblock Batched bandit problems.
\newblock In Peter Grünwald, Elad Hazan, and Satyen Kale, editors, \emph{Proceedings of The 28th Conference on Learning Theory}, volume~40 of \emph{Proceedings of Machine Learning Research}, pages 1456--1456, Paris, France, 03--06 Jul 2015. PMLR.
\newblock URL \url{https://proceedings.mlr.press/v40/Perchet15.html}.

\bibitem[Ren and Zhou(2024)]{ren2024dynamic}
Zhimei Ren and Zhengyuan Zhou.
\newblock Dynamic batch learning in high-dimensional sparse linear contextual bandits.
\newblock \emph{Management Science}, 70\penalty0 (2):\penalty0 1315--1342, 2024.

\bibitem[Ruan et~al.(2021)Ruan, Yang, and Zhou]{ruan2021linear}
Yufei Ruan, Jiaqi Yang, and Yuan Zhou.
\newblock Linear bandits with limited adaptivity and learning distributional optimal design.
\newblock In \emph{Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing}, pages 74--87, 2021.

\bibitem[Russac et~al.(2020)Russac, Capp'e, and Garivier]{Russac2020AlgorithmsFN}
Yoan Russac, Olivier Capp'e, and Aur{\'e}lien Garivier.
\newblock Algorithms for non-stationary generalized linear bandits.
\newblock \emph{ArXiv}, abs/2003.10113, 2020.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:214611704}.

\bibitem[Schwartz et~al.(2017)Schwartz, Bradlow, and Fader]{schwartz2017customer}
Eric~M Schwartz, Eric~T Bradlow, and Peter~S Fader.
\newblock Customer acquisition via display advertising using multi-armed bandit experiments.
\newblock \emph{Marketing Science}, 36\penalty0 (4):\penalty0 500--522, 2017.

\bibitem[Simchi-Levi and Xu(2022)]{simchi2022bypassing}
David Simchi-Levi and Yunzong Xu.
\newblock Bypassing the monster: A faster and simpler optimal algorithm for contextual bandits under realizability.
\newblock \emph{Mathematics of Operations Research}, 47\penalty0 (3):\penalty0 1904--1931, 2022.

\bibitem[Tropp et~al.(2015)]{tropp2015introduction}
Joel~A Tropp et~al.
\newblock An introduction to matrix concentration inequalities.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning}, 8\penalty0 (1-2):\penalty0 1--230, 2015.

\bibitem[Zhang and Sugiyama(2023)]{zhang2023online}
Yu-Jie Zhang and Masashi Sugiyama.
\newblock Online (multinomial) logistic bandit: Improved regret and constant computation cost.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=ofa1U5BJVJ}.

\end{thebibliography}
