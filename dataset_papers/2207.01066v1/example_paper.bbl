\begin{thebibliography}{65}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bachman et~al.(2014)Bachman, Alsharif, and
  Precup]{bachman2014learning}
Bachman, P., Alsharif, O., and Precup, D.
\newblock Learning with pseudo-ensembles.
\newblock \emph{Advances in Neural Information Processing Systems},
  27:\penalty0 3365--3373, 2014.

\bibitem[Berthelot et~al.(2019)Berthelot, Carlini, Goodfellow, Papernot,
  Oliver, and Raffel]{berthelot2019mixmatch}
Berthelot, D., Carlini, N., Goodfellow, I., Papernot, N., Oliver, A., and
  Raffel, C.
\newblock {MixMatch}: A holistic approach to semi-supervised learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Berthelot et~al.(2020)Berthelot, Carlini, Cubuk, Kurakin, Sohn, Zhang,
  and Raffel]{berthelot2019remixmatch}
Berthelot, D., Carlini, N., Cubuk, E.~D., Kurakin, A., Sohn, K., Zhang, H., and
  Raffel, C.
\newblock {ReMixMatch}: Semi-supervised learning with distribution alignment
  and augmentation anchoring.
\newblock \emph{International Conference on Learning Representations}, 2020.

\bibitem[Bruinsma et~al.(2021)Bruinsma, Requeima, Foong, Gordon, and
  Turner]{bruinsma2021gaussian}
Bruinsma, W.~P., Requeima, J., Foong, A.~Y., Gordon, J., and Turner, R.~E.
\newblock The {G}aussian neural process.
\newblock \emph{Advances in Approximate Bayesian Inference}, 2021.

\bibitem[Chen et~al.(2018)Chen, Wang, Gao, and Zhou]{dong2018tri}
Chen, D.-D., Wang, W., Gao, W., and Zhou, Z.-H.
\newblock Tri-net for semi-supervised deep learning.
\newblock In \emph{Proceedings of 27th International Joint Conference on
  Artificial Intelligence}, pp.\  2014--2020, 2018.

\bibitem[Coates et~al.(2011)Coates, Ng, and Lee]{coates2011analysis}
Coates, A., Ng, A., and Lee, H.
\newblock An analysis of single-layer networks in unsupervised feature
  learning.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  215--223. JMLR Workshop and Conference Proceedings, 2011.

\bibitem[Cubuk et~al.(2020)Cubuk, Zoph, Shlens, and Le]{cubuk2020randaugment}
Cubuk, E.~D., Zoph, B., Shlens, J., and Le, Q.~V.
\newblock {RandAugment}: Practical automated data augmentation with a reduced
  search space.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition Workshops}, pp.\  702--703, 2020.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Image{N}et: {A} large-scale hierarchical image database.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  248--255, 2009.

\bibitem[Gal \& Ghahramani(2016)Gal and Ghahramani]{gal2016dropout}
Gal, Y. and Ghahramani, Z.
\newblock Dropout as a {B}ayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1050--1059. PMLR, 2016.

\bibitem[Garnelo et~al.(2018{\natexlab{a}})Garnelo, Rosenbaum, Maddison,
  Ramalho, Saxton, Shanahan, Teh, Rezende, and Eslami]{garnelo2018conditional}
Garnelo, M., Rosenbaum, D., Maddison, C., Ramalho, T., Saxton, D., Shanahan,
  M., Teh, Y.~W., Rezende, D., and Eslami, S.~A.
\newblock Conditional neural processes.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1704--1713. PMLR, 2018{\natexlab{a}}.

\bibitem[Garnelo et~al.(2018{\natexlab{b}})Garnelo, Schwarz, Rosenbaum, Viola,
  Rezende, Eslami, and Teh]{garnelo2018neural}
Garnelo, M., Schwarz, J., Rosenbaum, D., Viola, F., Rezende, D.~J., Eslami, S.,
  and Teh, Y.~W.
\newblock Neural processes.
\newblock \emph{arXiv:1807.01622}, 2018{\natexlab{b}}.

\bibitem[Gordon et~al.(2020)Gordon, Bruinsma, Foong, Requeima, Dubois, and
  Turner]{gordon2019convolutional}
Gordon, J., Bruinsma, W.~P., Foong, A.~Y., Requeima, J., Dubois, Y., and
  Turner, R.~E.
\newblock Convolutional conditional neural processes.
\newblock \emph{International Conference on Learning Representations}, 2020.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Guo, C., Pleiss, G., Sun, Y., and Weinberger, K.~Q.
\newblock On calibration of modern neural networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1321--1330. PMLR, 2017.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  770--778, 2016.

\bibitem[Hu et~al.(2021)Hu, Yang, Hu, and Nevatia]{hu2021simple}
Hu, Z., Yang, Z., Hu, X., and Nevatia, R.
\newblock {SimPLE}: Similar pseudo label exploitation for semi-supervised
  classification.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  15099--15108, 2021.

\bibitem[Jean et~al.(2018)Jean, Xie, and Ermon]{jean2018semi}
Jean, N., Xie, S.~M., and Ermon, S.
\newblock Semi-supervised deep kernel learning: Regression with unlabeled data
  by minimizing predictive variance.
\newblock \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Kendall \& Gal(2017)Kendall and Gal]{kendall2017uncertainties}
Kendall, A. and Gal, Y.
\newblock What uncertainties do we need in bayesian deep learning for computer
  vision?
\newblock \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Kim et~al.(2019)Kim, Mnih, Schwarz, Garnelo, Eslami, Rosenbaum,
  Vinyals, and Teh]{kim2019attentive}
Kim, H., Mnih, A., Schwarz, J., Garnelo, M., Eslami, A., Rosenbaum, D.,
  Vinyals, O., and Teh, Y.~W.
\newblock Attentive neural processes.
\newblock \emph{International Conference on Learning Representations}, 2019.

\bibitem[Krishnan \& Tickoo(2020)Krishnan and Tickoo]{krishnan2020improving}
Krishnan, R. and Tickoo, O.
\newblock Improving model calibration with accuracy versus uncertainty
  optimization.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Image{N}et classification with deep convolutional neural networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  25:\penalty0 1097--1105, 2012.

\bibitem[Laine \& Aila(2017)Laine and Aila]{laine2016temporal}
Laine, S. and Aila, T.
\newblock Temporal ensembling for semi-supervised learning.
\newblock \emph{International Conference on Learning Representations}, 2017.

\bibitem[Laves et~al.(2020)Laves, Ihler, Kortmann, and
  Ortmaier]{laves2020calibration}
Laves, M.-H., Ihler, S., Kortmann, K.-P., and Ortmaier, T.
\newblock Calibration of model uncertainty for dropout variational inference.
\newblock \emph{arXiv:2006.11584}, 2020.

\bibitem[Lee(2013)]{lee2013pseudo}
Lee, D.-H.
\newblock Pseudo-label: The simple and efficient semi-supervised learning
  method for deep neural networks.
\newblock In \emph{Workshop on Challenges in Representation Learning,
  International Conference on Machine Learning}, volume~3, pp.\  896, 2013.

\bibitem[Lee et~al.(2020)Lee, Lee, Kim, Yang, Hwang, and
  Teh]{lee2020bootstrapping}
Lee, J., Lee, Y., Kim, J., Yang, E., Hwang, S.~J., and Teh, Y.~W.
\newblock Bootstrapping neural processes.
\newblock \emph{Advances in Neural Information Processing Systems}, pp.\
  6606--6615, 2020.

\bibitem[Li et~al.(2021)Li, Xiong, and Hoi]{li2021comatch}
Li, J., Xiong, C., and Hoi, S.~C.
\newblock {CoMatch}: Semi-supervised learning with contrastive graph
  regularization.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  9475--9484, 2021.

\bibitem[Li \& Zhou(2014)Li and Zhou]{li2014towards}
Li, Y.-F. and Zhou, Z.-H.
\newblock Towards making unlabeled data never hurt.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 37\penalty0 (1):\penalty0 175--188, 2014.

\bibitem[Liu et~al.(2010)Liu, He, and Chang]{liu2010large}
Liu, W., He, J., and Chang, S.-F.
\newblock Large graph construction for scalable semi-supervised learning.
\newblock In \emph{International Conference on Machine Learning}, 2010.

\bibitem[Liu et~al.(2020)Liu, Li, Chen, Hu, and Huang]{liu2020uncertainty}
Liu, Z.-Y., Li, S.-Y., Chen, S., Hu, Y., and Huang, S.-J.
\newblock Uncertainty aware graph {G}aussian process for semi-supervised
  learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pp.\  4957--4964, 2020.

\bibitem[Loshchilov \& Hutter(2016)Loshchilov and Hutter]{loshchilov2016sgdr}
Loshchilov, I. and Hutter, F.
\newblock {SGDR: S}tochastic gradient descent with warm restarts.
\newblock \emph{arXiv:1608.03983}, 2016.

\bibitem[Louizos et~al.(2019)Louizos, Shi, Schutte, and
  Welling]{louizos2019functional}
Louizos, C., Shi, X., Schutte, K., and Welling, M.
\newblock The functional neural process.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Naeini et~al.(2015)Naeini, Cooper, and
  Hauskrecht]{naeini2015obtaining}
Naeini, M.~P., Cooper, G., and Hauskrecht, M.
\newblock Obtaining well calibrated probabilities using bayesian binning.
\newblock In \emph{29th AAAI Conference on Artificial Intelligence}, 2015.

\bibitem[Nassar et~al.(2021)Nassar, Herath, Abbasnejad, Buntine, and
  Haffari]{nassar2021all}
Nassar, I., Herath, S., Abbasnejad, E., Buntine, W., and Haffari, G.
\newblock All labels are not created equal: Enhancing semi-supervision via
  label grouping and co-training.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  7241--7250, 2021.

\bibitem[Ng et~al.(2018)Ng, Colombo, and Silva]{ng2018bayesian}
Ng, Y.~C., Colombo, N., and Silva, R.
\newblock Bayesian semi-supervised learning with graph {G}aussian processes.
\newblock \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Niculescu \& Persson(2006)Niculescu and Persson]{niculescu2006convex}
Niculescu, C. and Persson, L.-E.
\newblock \emph{Convex functions and their applications}.
\newblock Springer, 2006.

\bibitem[Nielsen(2020)]{nielsen2020generalization}
Nielsen, F.
\newblock On a generalization of the {Jensen-Shannon divergence and the
  Jensen-Shannon} centroid.
\newblock \emph{Entropy}, 22\penalty0 (2):\penalty0 221, 2020.

\bibitem[Nielsen \& Garcia(2009)Nielsen and Garcia]{nielsen2009statistical}
Nielsen, F. and Garcia, V.
\newblock Statistical exponential families: A digest with flash cards.
\newblock \emph{arXiv:0911.4863}, 2009.

\bibitem[{\O}ksendal(2003)]{oksendal2003stochastic}
{\O}ksendal, B.
\newblock Stochastic differential equations.
\newblock In \emph{Stochastic Differential Equations}, pp.\  65--84. Springer,
  2003.

\bibitem[Pham et~al.(2021)Pham, Dai, Xie, and Le]{pham2021meta}
Pham, H., Dai, Z., Xie, Q., and Le, Q.~V.
\newblock Meta pseudo labels.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  11557--11568, 2021.

\bibitem[Qiao et~al.(2018)Qiao, Shen, Zhang, Wang, and Yuille]{qiao2018deep}
Qiao, S., Shen, W., Zhang, Z., Wang, B., and Yuille, A.
\newblock Deep co-training for semi-supervised image recognition.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  135--152, 2018.

\bibitem[Qin et~al.(2019)Qin, Zhu, Qin, Wang, and Zhao]{qin2019recurrent}
Qin, S., Zhu, J., Qin, J., Wang, W., and Zhao, D.
\newblock Recurrent attentive neural process for sequential data.
\newblock \emph{LIRE Workshop NeurIPS}, 2019.

\bibitem[Requeima et~al.(2019)Requeima, Gordon, Bronskill, Nowozin, and
  Turner]{requeima2019fast}
Requeima, J., Gordon, J., Bronskill, J., Nowozin, S., and Turner, R.~E.
\newblock Fast and flexible multi-task classification using conditional neural
  adaptive processes.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 7959--7970, 2019.

\bibitem[Rizve et~al.(2021)Rizve, Duarte, Rawat, and Shah]{rizve2021defense}
Rizve, M.~N., Duarte, K., Rawat, Y.~S., and Shah, M.
\newblock In defense of pseudo-labeling: An uncertainty-aware pseudo-label
  selection framework for semi-supervised learning.
\newblock \emph{International Conference on Learning Representations}, 2021.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and
  Brox]{ronneberger2015u}
Ronneberger, O., Fischer, P., and Brox, T.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{International Conference on Medical Image Computing and
  Computer-Assisted Intervention}, pp.\  234--241. Springer, 2015.

\bibitem[Sajjadi et~al.(2016)Sajjadi, Javanmardi, and
  Tasdizen]{sajjadi2016regularization}
Sajjadi, M., Javanmardi, M., and Tasdizen, T.
\newblock Regularization with stochastic transformations and perturbations for
  deep semi-supervised learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  29:\penalty0 1163--1171, 2016.

\bibitem[Sedai et~al.(2019)Sedai, Antony, Rai, Jones, Ishikawa, Schuman, Gadi,
  and Garnavi]{sedai2019uncertainty}
Sedai, S., Antony, B., Rai, R., Jones, K., Ishikawa, H., Schuman, J., Gadi, W.,
  and Garnavi, R.
\newblock Uncertainty guided semi-supervised segmentation of retinal layers in
  {OCT} images.
\newblock In \emph{International Conference on Medical Image Computing and
  Computer-Assisted Intervention}, pp.\  282--290. Springer, 2019.

\bibitem[Shi et~al.(2021)Shi, Zhang, Ling, Lu, Zheng, Yu, Qi, and
  Gao]{shi2021inconsistency}
Shi, Y., Zhang, J., Ling, T., Lu, J., Zheng, Y., Yu, Q., Qi, L., and Gao, Y.
\newblock Inconsistency-aware uncertainty estimation for semi-supervised
  medical image segmentation.
\newblock \emph{IEEE Transactions on Medical Imaging}, 2021.

\bibitem[Simonyan \& Zisserman(2014)Simonyan and Zisserman]{simonyan2014very}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{International Conference on Learning Representations}, 2014.

\bibitem[Sindhwani et~al.(2007)Sindhwani, Chu, and Keerthi]{sindhwani2007semi}
Sindhwani, V., Chu, W., and Keerthi, S.~S.
\newblock Semi-supervised {G}aussian process classifiers.
\newblock In \emph{International Joint Conference on Artificial Intelligence},
  pp.\  1059--1064, 2007.

\bibitem[Singh et~al.(2019)Singh, Yoon, Son, and Ahn]{singh2019sequential}
Singh, G., Yoon, J., Son, Y., and Ahn, S.
\newblock Sequential neural processes.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Sohn et~al.(2020)Sohn, Berthelot, Li, Zhang, Carlini, Cubuk, Kurakin,
  Zhang, and Raffel]{sohn2020fixmatch}
Sohn, K., Berthelot, D., Li, C.-L., Zhang, Z., Carlini, N., Cubuk, E.~D.,
  Kurakin, A., Zhang, H., and Raffel, C.
\newblock {FixMatch}: Simplifying semi-supervised learning with consistency and
  confidence.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{szegedy2015going}
Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D.,
  Vanhoucke, V., and Rabinovich, A.
\newblock Going deeper with convolutions.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  1--9, 2015.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy2016rethinking}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  2818--2826, 2016.

\bibitem[Walker \& Glocker(2019)Walker and Glocker]{walker2019graph}
Walker, I. and Glocker, B.
\newblock Graph convolutional {G}aussian processes.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  6495--6504. PMLR, 2019.

\bibitem[Wang et~al.(2021)Wang, Zhan, Zu, Wu, Zhou, Zhou, and
  Wang]{wang2021tripled}
Wang, K., Zhan, B., Zu, C., Wu, X., Zhou, J., Zhou, L., and Wang, Y.
\newblock Tripled-uncertainty guided mean teacher model for semi-supervised
  medical image segmentation.
\newblock In \emph{International Conference on Medical Image Computing and
  Computer-Assisted Intervention}, pp.\  450--460. Springer, 2021.

\bibitem[Wang et~al.(2020)Wang, Kihara, Luo, and Qi]{wang2020enaet}
Wang, X., Kihara, D., Luo, J., and Qi, G.-J.
\newblock Enaet: A self-trained framework for semi-supervised and supervised
  learning with ensemble transformations.
\newblock \emph{IEEE Transactions on Image Processing}, 30:\penalty0
  1639--1647, 2020.

\bibitem[Wilson et~al.(2016)Wilson, Hu, Salakhutdinov, and
  Xing]{wilson2016deep}
Wilson, A.~G., Hu, Z., Salakhutdinov, R., and Xing, E.~P.
\newblock Deep kernel learning.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  370--378.
  PMLR, 2016.

\bibitem[Xie et~al.(2020)Xie, Dai, Hovy, Luong, and Le]{xie2019unsupervised}
Xie, Q., Dai, Z., Hovy, E., Luong, M.-T., and Le, Q.~V.
\newblock Unsupervised data augmentation for consistency training.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Yasarla et~al.(2020)Yasarla, Sindagi, and Patel]{yasarla2020syn2real}
Yasarla, R., Sindagi, V.~A., and Patel, V.~M.
\newblock {Syn2Real} transfer learning for image deraining using {G}aussian
  processes.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  2726--2736, 2020.

\bibitem[Yoon et~al.(2020)Yoon, Singh, and Ahn]{yoon2020robustifying}
Yoon, J., Singh, G., and Ahn, S.
\newblock Robustifying sequential neural processes.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  10861--10870. PMLR, 2020.

\bibitem[Yu et~al.(2019)Yu, Wang, Li, Fu, and Heng]{yu2019uncertainty}
Yu, L., Wang, S., Li, X., Fu, C.-W., and Heng, P.-A.
\newblock Uncertainty-aware self-ensembling model for semi-supervised {3D} left
  atrium segmentation.
\newblock In \emph{International Conference on Medical Image Computing and
  Computer-Assisted Intervention}, pp.\  605--613. Springer, 2019.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and
  Komodakis]{zagoruyko2016wide}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock \emph{British Machine Vision Conference}, 2016.

\bibitem[Zhai et~al.(2019)Zhai, Oliver, Kolesnikov, and Beyer]{zhai2019s4l}
Zhai, X., Oliver, A., Kolesnikov, A., and Beyer, L.
\newblock S4l: Self-supervised semi-supervised learning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  1476--1485, 2019.

\bibitem[Zhang et~al.(2021)Zhang, Wang, Hou, Wu, Wang, Okumura, and
  Shinozaki]{zhang2021flexmatch}
Zhang, B., Wang, Y., Hou, W., Wu, H., Wang, J., Okumura, M., and Shinozaki, T.
\newblock {FlexMatch}: Boosting semi-supervised learning with curriculum pseudo
  labeling.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Zhu et~al.(2020)Zhu, Li, Bai, Chen, Li, Ma, Teo, Tao, and
  Lin]{zhu2020grasping}
Zhu, H., Li, Y., Bai, F., Chen, W., Li, X., Ma, J., Teo, C.~S., Tao, P.~Y., and
  Lin, W.
\newblock Grasping detection network with uncertainty estimation for
  confidence-driven semi-supervised domain adaptation.
\newblock In \emph{2020 IEEE/RSJ International Conference on Intelligent Robots
  and Systems}, pp.\  9608--9613. IEEE, 2020.

\end{thebibliography}
