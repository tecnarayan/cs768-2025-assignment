\begin{thebibliography}{45}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Baldi et~al.(2014)Baldi, Sadowski, and Whiteson]{baldi2014searching}
P.~Baldi, P.~Sadowski, and D.~Whiteson.
\newblock Searching for exotic particles in high-energy physics with deep
  learning.
\newblock \emph{Nature communications}, 5\penalty0 (1):\penalty0 1--9, 2014.

\bibitem[Cai et~al.(2020)Cai, Goggin, and Jiang]{CaiGogJia2020}
H.~Cai, B.~Goggin, and Q.~Jiang.
\newblock Two-sample test based on classification probability.
\newblock \emph{Statistical Analysis and Data Mining: The ASA Data Science
  Journal}, 13\penalty0 (1):\penalty0 5--13, 2020.

\bibitem[Cheng and Cloninger(2019)]{CheClo2019}
X.~Cheng and A.~Cloninger.
\newblock Classification logit two-sample testing by neural networks.
\newblock \emph{arXiv:1909.11298}, 2019.

\bibitem[Chwialkowski et~al.(2015)Chwialkowski, Ramdas, Sejdinovic, and
  Gretton]{ChwialkowskiRSG15}
K.~Chwialkowski, A.~Ramdas, D.~Sejdinovic, and A.~Gretton.
\newblock Fast two-sample testing with analytic representations of probability
  measures.
\newblock In \emph{NeurIPS}, 2015.

\bibitem[Dietterich(2000)]{dietterich2000ensemble}
T.~G. Dietterich.
\newblock Ensemble methods in machine learning.
\newblock In \emph{International workshop on multiple classifier systems},
  pages 1--15. Springer, 2000.

\bibitem[Duda et~al.(2001)Duda, Hart, and Stork]{DudaHS2001}
R.~O. Duda, P.~E. Hart, and D.~G. Stork.
\newblock \emph{Pattern classification, 2nd Edition}.
\newblock Wiley, 2001.

\bibitem[Erickson et~al.(2020)Erickson, Mueller, Shirkov, Zhang, Larroy, Li,
  and Smola]{autogluon2020}
N.~Erickson, J.~Mueller, A.~Shirkov, H.~Zhang, P.~Larroy, M.~Li, and A.~Smola.
\newblock Autogluon-tabular: Robust and accurate automl for structured data.
\newblock \emph{arXiv:2003.06505}, 2020.

\bibitem[Erven et~al.(2012)Erven, Gr{\"u}nwald, and
  De~Rooij]{erven2012catching}
T.~v. Erven, P.~Gr{\"u}nwald, and S.~De~Rooij.
\newblock Catching up faster by switching sooner: A predictive approach to
  adaptive estimation with an application to the aic--bic dilemma.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 74\penalty0 (3):\penalty0 361--417, 2012.

\bibitem[Feurer et~al.(2015)Feurer, Klein, Eggensperger, Blum, and
  Hutter]{feurer-neurips15a}
M.~Feurer, A.~Klein, J.~Eggensperger, Katharina~Springenberg, M.~Blum, and
  F.~Hutter.
\newblock Efficient and robust automated machine learning.
\newblock In \emph{NeurIPS}, 2015.

\bibitem[Feurer et~al.(2020)Feurer, Eggensperger, Falkner, Lindauer, and
  Hutter]{feurer2020auto}
M.~Feurer, K.~Eggensperger, S.~Falkner, M.~Lindauer, and F.~Hutter.
\newblock Auto-sklearn 2.0: Hands-free automl via meta-learning.
\newblock \emph{arXiv:2007.04074}, 2020.

\bibitem[Friedman(2003)]{Friedman03:Tests}
J.~H. Friedman.
\newblock {On multivariate goodness of fit and two sample testing}.
\newblock \emph{Stanford Linear Accelerator Center--PUB--10325}, 2003.

\bibitem[Gijsbers et~al.(2022)Gijsbers, Bueno, Coors, LeDell, Poirier, Thomas,
  Bischl, and Vanschoren]{gijsbers2022amlb}
P.~Gijsbers, M.~L. Bueno, S.~Coors, E.~LeDell, S.~Poirier, J.~Thomas,
  B.~Bischl, and J.~Vanschoren.
\newblock Amlb: an automl benchmark.
\newblock \emph{arXiv:2207.12560}, 2022.

\bibitem[Golland and Fischl(2003)]{Golland2003PermutationClassifier}
P.~Golland and B.~Fischl.
\newblock Permutation tests for classification: Towards statistical
  significance in image-based studies.
\newblock In C.~Taylor and J.~A. Noble, editors, \emph{Information Processing
  in Medical Imaging}, pages 330--341, Berlin, Heidelberg, 2003. Springer
  Berlin Heidelberg.
\newblock ISBN 978-3-540-45087-0.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2015adversarial}
I.~Goodfellow, J.~Shlens, and C.~Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{ICLR}, 2015.

\bibitem[Gretton et~al.(2005)Gretton, Bousquet, Smola, and
  Sch{\"o}lkopf]{gretton2005measuring}
A.~Gretton, O.~Bousquet, A.~Smola, and B.~Sch{\"o}lkopf.
\newblock Measuring statistical dependence with hilbert-schmidt norms.
\newblock In \emph{International conference on algorithmic learning theory},
  pages 63--77. Springer, 2005.

\bibitem[Gretton et~al.(2012{\natexlab{a}})Gretton, Borgwardt, Rasch,
  Sch{\"o}lkopf, and Smola]{gretton2012kernel}
A.~Gretton, K.~M. Borgwardt, M.~J. Rasch, B.~Sch{\"o}lkopf, and A.~Smola.
\newblock A kernel two-sample test.
\newblock \emph{Journal of Machine Learning Research}, 13:\penalty0 723--773,
  2012{\natexlab{a}}.

\bibitem[Gretton et~al.(2012{\natexlab{b}})Gretton, Sejdinovic, Strathmann,
  Balakrishnan, Pontil, Fukumizu, and Sriperumbudur]{Gretton2012optimal}
A.~Gretton, D.~Sejdinovic, H.~Strathmann, S.~Balakrishnan, M.~Pontil,
  K.~Fukumizu, and B.~K. Sriperumbudur.
\newblock Optimal kernel choice for large-scale two-sample tests.
\newblock In \emph{NeurIPS}, 2012{\natexlab{b}}.

\bibitem[He et~al.(2021)He, Zhao, and Chu]{he2021automl}
X.~He, K.~Zhao, and X.~Chu.
\newblock Automl: A survey of the state-of-the-art.
\newblock \emph{Knowledge-Based Systems}, 212:\penalty0 106622, 2021.

\bibitem[Hediger et~al.(2022)Hediger, Michel, and Näf]{HEDIGER2022}
S.~Hediger, L.~Michel, and J.~Näf.
\newblock On the use of random forest for two-sample testing.
\newblock \emph{Computational Statistics and Data Analysis}, 170:\penalty0
  107435, 2022.

\bibitem[Hutter et~al.(2019)Hutter, Kotthoff, and
  Vanschoren]{hutter2019automated}
F.~Hutter, L.~Kotthoff, and J.~Vanschoren.
\newblock \emph{Automated machine learning: methods, systems, challenges}.
\newblock Springer Nature, 2019.

\bibitem[Jitkrittum et~al.(2016)Jitkrittum, Szab\'{o}, Chwialkowski, and
  Gretton]{JitSzaChwGre2016}
W.~Jitkrittum, Z.~Szab\'{o}, K.~P. Chwialkowski, and A.~Gretton.
\newblock Interpretable distribution features with maximum testing power.
\newblock In \emph{NeurIPS}, 2016.

\bibitem[Kim et~al.(2021)Kim, Ramdas, Singh, and
  Wasserman]{kim2016classification}
I.~Kim, A.~Ramdas, A.~Singh, and L.~Wasserman.
\newblock {Classification accuracy as a proxy for two-sample testing}.
\newblock \emph{The Annals of Statistics}, 49\penalty0 (1):\penalty0 411 --
  434, 2021.

\bibitem[Kirchler et~al.(2020)Kirchler, Khorasani, Kloft, and
  Lippert]{KirchlerKKL20}
M.~Kirchler, S.~Khorasani, M.~Kloft, and C.~Lippert.
\newblock Two-sample testing using deep learning.
\newblock In \emph{AISTATS}, 2020.

\bibitem[Koch et~al.(2022)Koch, Sch\"ubach, Gretton, and
  Berens]{koch2022Hidden}
L.~Koch, C.~Sch\"ubach, A.~Gretton, and P.~Berens.
\newblock Hidden in plain sight: Subgroup shifts escape ood detection.
\newblock In \emph{Medical Imaging in Deep Learning}, 2022.

\bibitem[Krizhevsky(2009)]{cifar10}
A.~Krizhevsky.
\newblock Learning multiple layers of features from tiny images, 2009.

\bibitem[Kübler et~al.(2020)Kübler, Jitkrittum, Schölkopf, and
  Muandet]{kbler2020learning}
J.~M. Kübler, W.~Jitkrittum, B.~Schölkopf, and K.~Muandet.
\newblock Learning kernel tests without data splitting.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Kübler et~al.(2022)Kübler, Jitkrittum, Schölkopf, and
  Muandet]{kubler2022witness}
J.~M. Kübler, W.~Jitkrittum, B.~Schölkopf, and K.~Muandet.
\newblock A witness two-sample test.
\newblock In \emph{AISTATS}, 2022.

\bibitem[LeCun et~al.(2010)LeCun, Cortes, and Burges]{lecun2010mnist}
Y.~LeCun, C.~Cortes, and C.~Burges.
\newblock Mnist handwritten digit database.
\newblock \emph{ATT Labs [Online]. Available:
  http://yann.lecun.com/exdb/mnist}, 2, 2010.

\bibitem[Lhéritier and Cazals(2018)]{lheritier}
A.~Lhéritier and F.~Cazals.
\newblock A sequential non-parametric multivariate two-sample test.
\newblock \emph{IEEE Transactions on Information Theory}, 64\penalty0 (5),
  2018.

\bibitem[Lipton et~al.(2018)Lipton, Wang, and Smola]{lipton18aBlackBox}
Z.~Lipton, Y.-X. Wang, and A.~Smola.
\newblock Detecting and correcting for label shift with black box predictors.
\newblock In \emph{ICML}, 2018.

\bibitem[Liu et~al.(2020)Liu, Xu, Lu, Zhang, Gretton, and
  Sutherland]{liu2020learning}
F.~Liu, W.~Xu, J.~Lu, G.~Zhang, A.~Gretton, and D.~J. Sutherland.
\newblock Learning deep kernels for non-parametric two-sample tests.
\newblock In \emph{ICML}, 2020.

\bibitem[Liu et~al.(2021)Liu, Xu, Lu, and Sutherland]{Liu2021Meta}
F.~Liu, W.~Xu, J.~Lu, and D.~J. Sutherland.
\newblock Meta two-sample testing: Learning kernels for testing with limited
  data.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Lopez{-}Paz and Oquab(2017)]{LopOqu2017}
D.~Lopez{-}Paz and M.~Oquab.
\newblock Revisiting classifier two-sample tests.
\newblock In \emph{ICLR}, 2017.

\bibitem[Mao et~al.(2019)Mao, Li, Xie, Lau, Wang, and Smolley]{lsGAN}
X.~Mao, Q.~Li, H.~Xie, R.~K. Lau, Z.~Wang, and S.~Smolley.
\newblock On the effectiveness of least squares generative adversarial
  networks.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 41\penalty0 (12):\penalty0 2947--2960, dec 2019.

\bibitem[Mika(2003)]{Mika_PhD2003}
S.~Mika.
\newblock \emph{Kernel Fisher Discriminants}.
\newblock Doctoral thesis, Technische Universität Berlin, Berlin, 2003.

\bibitem[Phipson and Smyth(2010)]{phipson2010permutation}
B.~Phipson and G.~K. Smyth.
\newblock Permutation p-values should never be zero: calculating exact p-values
  when permutations are randomly drawn.
\newblock \emph{Statistical applications in genetics and molecular biology},
  9\penalty0 (1), 2010.

\bibitem[Rabanser et~al.(2019)Rabanser, G\"{u}nnemann, and
  Lipton]{Rabanser2019Failing}
S.~Rabanser, S.~G\"{u}nnemann, and Z.~Lipton.
\newblock Failing loudly: An empirical study of methods for detecting dataset
  shift.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Schrab et~al.(2021)Schrab, Kim, Albert, Laurent, Guedj, and
  Gretton]{schrab2021mmd}
A.~Schrab, I.~Kim, M.~Albert, B.~Laurent, B.~Guedj, and A.~Gretton.
\newblock Mmd aggregated two-sample test.
\newblock \emph{arXiv:2110.15073}, 2021.

\bibitem[Shekhar et~al.(2022)Shekhar, Kim, and Ramdas]{shekhar2022permutation}
S.~Shekhar, I.~Kim, and A.~Ramdas.
\newblock A permutation-free kernel two-sample test.
\newblock In \emph{NeurIPS}, 2022.

\bibitem[Steinruecken et~al.(2019)Steinruecken, Smith, Janz, Lloyd, and
  Ghahramani]{steinruecken2019automatic}
C.~Steinruecken, E.~Smith, D.~Janz, J.~Lloyd, and Z.~Ghahramani.
\newblock The automatic statistician.
\newblock In \emph{Automated Machine Learning}, pages 161--173. Springer, Cham,
  2019.

\bibitem[Student(1908)]{student1908probable}
Student.
\newblock The probable error of a mean.
\newblock \emph{Biometrika}, pages 1--25, 1908.

\bibitem[Sutherland et~al.(2017)Sutherland, Tung, Strathmann, De, Ramdas,
  Smola, and Gretton]{sutherland2016generative}
D.~J. Sutherland, H.-Y. Tung, H.~Strathmann, S.~De, A.~Ramdas, A.~Smola, and
  A.~Gretton.
\newblock Generative models and model criticism via optimized maximum mean
  discrepancy.
\newblock In \emph{ICLR}, 2017.

\bibitem[Vayatis et~al.(2009)Vayatis, Depecker, and
  Cl{\'e}men{\c{c}}on]{vayatis2009auc}
N.~Vayatis, M.~Depecker, and S.~Cl{\'e}men{\c{c}}on.
\newblock Auc optimization and the two-sample problem.
\newblock In \emph{NeurIPS}, 2009.

\bibitem[Welch(1947)]{welch1947generalization}
B.~L. Welch.
\newblock The generalization of ‘student's’problem when several different
  population varlances are involved.
\newblock \emph{Biometrika}, 34\penalty0 (1-2):\penalty0 28--35, 1947.

\bibitem[Zhao et~al.(2022)Zhao, Sinha, He, Perreault, Song, and
  Ermon]{zhao2021comparing}
S.~Zhao, A.~Sinha, Y.~He, A.~Perreault, J.~Song, and S.~Ermon.
\newblock Comparing distributions by measuring differences that affect decision
  making.
\newblock In \emph{ICLR}, 2022.

\end{thebibliography}
