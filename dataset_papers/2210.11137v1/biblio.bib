@article{chen2015efficient,
  title={Efficient multi-user computation offloading for mobile-edge cloud computing},
  author={Chen, Xu and Jiao, Lei and Li, Wenzhong and Fu, Xiaoming},
  journal={IEEE/ACM Transactions on Networking}, 
  volume={24},
  number={5},
  pages={2795--2808},
  year={2015},
  publisher={IEEE}
}
@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal = {Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}
@article{shalev2016safe,
  title={Safe, multi-agent, reinforcement learning for autonomous driving},
  author={Shalev-Shwartz, Shai and Shammah, Shaked and Shashua, Amnon},
  journal={arXiv preprint arXiv:1610.03295},
  year={2016}
}
@article{lanzetti2022first,
  title={First-order Conditions for Optimization in the {W}asserstein Space},
  author={Lanzetti, Nicolas and Bolognani, Saverio and D{\"o}rfler, Florian},
  journal={arXiv preprint arXiv:2209.12197},
  year={2022}
}
@article{ward2019improving,
  title={Improving exploration in soft-actor-critic with normalizing flows policies},
  author={Ward, Patrick Nadeem and Smofsky, Ariella and Bose, Avishek Joey},
  journal={arXiv preprint arXiv:1906.02771},
  year={2019}
}
@article{cai2021safe,
  title={Safe multi-agent reinforcement learning through decentralized multiple control barrier functions},
  author={Cai, Zhiyuan and Cao, Huanhui and Lu, Wenjie and Zhang, Lin and Xiong, Hao},
  journal={arXiv preprint arXiv:2103.12553},
  year={2021}
}
@inproceedings{lu2021decentralized,
  title={Decentralized policy gradient descent ascent for safe multi-agent reinforcement learning},
  author={Lu, Songtao and Zhang, Kaiqing and Chen, Tianyi and Basar, Tamer and Horesh, Lior},
  booktitle={AAAI Conference on Artificial Intelligence},
  volume={35},
  number={10},
  pages={8767--8775},
  year={2021}
}
@article{zhang2019mamps,
  title={Mamps: Safe multi-agent reinforcement learning via model predictive shielding},
  author={Zhang, Wenbo and Bastani, Osbert and Kumar, Vijay},
  journal={arXiv preprint arXiv:1910.12639},
  year={2019}
}
@article{aly2021safemarlshielding,
  author    = {Ingy Elsayed{-}Aly and
               Suda Bharadwaj and
               Christopher Amato and
               R{\"{u}}diger Ehlers and
               Ufuk Topcu and
               Lu Feng},
  title     = {Safe Multi-Agent Reinforcement Learning via Shielding},
  journal   = {CoRR},
  volume    = {abs/2101.11196},
  year      = {2021},
  url       = {https://arxiv.org/abs/2101.11196},
  eprinttype = {arXiv},
  eprint    = {2101.11196},
  timestamp = {Sun, 31 Jan 2021 17:23:50 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2101-11196.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{ yamamoto2015network,
  title={A Comprehensive Survey of Potential Game Approaches to Wireless Networks},
  author={Koji YAMAMOTO},
  journal={IEICE Transactions on Communications},
  volume={E98.B},
  number={9},
  pages={1804-1823},
  year={2015},
  doi={10.1587/transcom.E98.B.1804}
}
@article{bertrand2020routing,
  author    = {Nathalie Bertrand and
               Nicolas Markey and
               Suman Sadhukhan and
               Ocan Sankur},
  title     = {Dynamic network congestion games},
  journal   = {CoRR},
  volume    = {abs/2009.13632},
  year      = {2020},
  url       = {https://arxiv.org/abs/2009.13632},
  eprinttype = {arXiv},
  eprint    = {2009.13632},
  timestamp = {Wed, 30 Sep 2020 16:16:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2009-13632.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{garcia2015saferlreview,
  author  = {Javier Garc{{\'i}}a and Fern and o Fern{{\'a}}ndez},
  title   = {A Comprehensive Survey on Safe Reinforcement Learning},
  journal = {Journal of Machine Learning Research},
  year    = {2015},
  volume  = {16},
  number  = {42},
  pages   = {1437-1480},
  url     = {http://jmlr.org/papers/v16/garcia15a.html}
}
@inproceedings{neurips2020saferl,
 author = {Turchetta, Matteo and Kolobov, Andrey and Shah, Shital and Krause, Andreas and Agarwal, Alekh},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {12151--12162},
 publisher = {Curran Associates, Inc.},
 title = {Safe Reinforcement Learning via Curriculum Induction},
 url = {https://proceedings.neurips.cc/paper/2020/file/8df6a65941e4c9da40a4fb899de65c55-Paper.pdf},
 volume = {33},
 year = {2020}
}


@article{bangalore2020selfdrivingcars,
  author    = {Bangalore Ravi Kiran and
               Ibrahim Sobh and
               Victor Talpaert and
               Patrick Mannion and
               Ahmad A. Al Sallab and
               Senthil Kumar Yogamani and
               Patrick P{\'{e}}rez},
  title     = {Deep Reinforcement Learning for Autonomous Driving: {A} Survey},
  journal   = {CoRR},
  volume    = {abs/2002.00444},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.00444},
  eprinttype = {arXiv},
  eprint    = {2002.00444},
  timestamp = {Mon, 10 Feb 2020 15:12:57 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-00444.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{zhou2021autonomousdriving,
  title = 	 {SMARTS: An Open-Source Scalable Multi-Agent RL Training School for Autonomous Driving},
  author =       {Zhou, Ming and Luo, Jun and Villella, Julian and Yang, Yaodong and Rusu, David and Miao, Jiayu and Zhang, Weinan and Alban, Montgomery and FADAKAR, IMAN and Chen, Zheng and Huang, Chongxi and Wen, Ying and Hassanzadeh, Kimia and Graves, Daniel and Zhu, Zhengbang and Ni, Yihan and Nguyen, Nhat and Elsayed, Mohamed and Ammar, Haitham and Cowen-Rivers, Alexander and Ahilan, Sanjeevan and Tian, Zheng and Palenicek, Daniel and Rezaee, Kasra and Yadmellat, Peyman and Shao, Kun and chen, dong and Zhang, Baokuan and Zhang, Hongbo and Hao, Jianye and Liu, Wulong and Wang, Jun},
  booktitle = 	 {Conference on Robot Learning},
  pages = 	 {264--285},
  year = 	 {2021},
  editor = 	 {Kober, Jens and Ramos, Fabio and Tomlin, Claire},
  volume = 	 {155},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {16--18 Nov},
  publisher =    {PMLR}, 
  url = {https://proceedings.mlr.press/v155/zhou21a/zhou21a.pdf}
}

@article{zahng2021marlreview,
  title={Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms},
  author={Zhang K. and Yang Z. and Başar T.},
  journal = {Handbook of Reinforcement Learning and Control, Springer},
  year={2021}
}

@article{zhou2017chemical,
  title={Optimizing chemical reactions with deep reinforcement learning},
  author={Zhou, Zhenpeng and Li, Xiaocheng and Zare, Richard N},
  journal={ACS Central Science},
  volume={3},
  number={12},
  pages={1337--1344},
  year={2017},
  publisher={ACS Publications}
}

@inproceedings{Guanjie2018recommendation,
  title={{DRN}: A deep reinforcement learning framework for news recommendation},
  author={Zheng, Guanjie and Zhang, Fuzheng and Zheng, Zihan and Xiang, Yang and Yuan, Nicholas Jing and Xie, Xing and Li, Zhenhui},
  booktitle={World Wide Web Conference},
  pages={167--176},
  year={2018}
}


@inproceedings{mao2016resourcemanagement,
  title={Resource management with deep reinforcement learning},
  author={Mao, Hongzi and Alizadeh, Mohammad and Menache, Ishai and Kandula, Srikanth},
  booktitle={15th ACM workshop on hot topics in networks},
  pages={50--56},
  year={2016}
}

@inproceedings{Kaiser2020atari,
  title={Model Based Reinforcement Learning for {A}tari},
  author={Kaiser, {\L}ukasz and Babaeizadeh, Mohammad and Mi{\l}os, Piotr and Osi{\'n}ski, B{\l}a{\.z}ej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{monderer1996mpg,
title = {Potential Games},
journal = {Games and Economic Behavior},
volume = {14},
number = {1},
pages = {124-143},
year = {1996},
issn = {0899-8256},
doi = {https://doi.org/10.1006/game.1996.0044},
url = {https://www.sciencedirect.com/science/article/pii/S0899825696900445},
author = {Monderer, Dev and Shapley, Lloyd S.},
}

@article{Leonardos2021ExplorationExploitationIM,
  title={Exploration-Exploitation in Multi-Agent Competition: Convergence with Bounded Rationality},
  author={Stefanos Leonardos and Georgios Piliouras and Kelly Spendlove},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.12928}
}

@inproceedings{chasnov2020convergence,
  title={Convergence analysis of gradient-based learning in continuous games},
  author={Chasnov, Benjamin and Ratliff, Lillian and Mazumdar, Eric and Burden, Samuel},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={935--944},
  year={2020},
  organization={PMLR}
}

@inproceedings{Claus1998cooperativeconv,
  title={The Dynamics of Reinforcement Learning in Cooperative Multiagent Systems},
  author={Claus, Caroline and Boutilier, Craig},
  booktitle={AAAI/IAAI},
  year={1998}
}
@article{jumper2021alphafold,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={Jumper, J. and Evans, R. and Pritzel, A. et al.},
  journal={Nature 596, 583–589},
  year={2021}
}

@article{yue2019videogames,
  title={Reinforcement learning and video games},
  author={Zheng, Yue},
  journal={arXiv preprint arXiv:1909.04751},
  year={2019}
}

@article{mnih2013atari,
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
year = {2013},
pages = {},
journal={arXiv preprint arXiv:1312.5602},
title = {Playing Atari with Deep Reinforcement Learning}
}
@article{xenou2019boardgames,
  title={Deep Reinforcement Learning in Strategic Board Game Environments},
  author={Xenou, Konstantia and Chalkiadakis, Georgios and Afantenos, Stergos},
  journal={Springer International Publishing},
  year={2019}
}
@article{silver2016go,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, D. and Huang, A. and Maddison, C. et al.},
  journal={Nature 529, 484–489},
  year={2016}
}
@inproceedings{paternain2019dualitygap,
  title={Constrained Reinforcement Learning Has Zero
Duality Gap},
  author={Paternain, Santiago and Chamon, Luiz F. O. and Calvo-Fullana, Miguel and Ribeiro, Alejandro},
  booktitle={neurips},
  year={2019}
}
@article{rockafellar1970perturbation,
  title={Convex analysis},
  author={Rockafellar, R.T.},
  journal={Princeton University Press},
  year={1970}
}
@article{borkar1988convex,
  title={A convex analytic approach to Markov decision processes},
  author={Borkar, Vivek S.},
  journal={Probability Theory and Related Fields},
  year={1988}
}
@article{yu2019convergent,
  title={Convergent policy optimization for safe reinforcement learning},
  author={Yu, Ming and Yang, Zhuoran and Kolar, Mladen and Wang, Zhaoran},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={3127--3139},
  year={2019}
}
@article{taskesen2021semi,
  title={Semi-discrete optimal transport: Hardness, regularization and numerical solution},
  author={Taskesen, Bahar and Shafieezadeh-Abadeh, Soroosh and Kuhn, Daniel},
  journal={arXiv preprint arXiv:2103.06263},
  year={2021}
}
@article{Peyre2019,
    title = {Computational optimal transport},
    year = {2019},
    journal = {Foundations and Trends in Machine Learning},
    author = {Peyr{\'{e}}, Gabriel and Cuturi, Marco},
    number = {5-6},
    pages = {1--257},
    volume = {11},
}
@article{rahimian2019distributionally,
  title={Distributionally robust optimization: A review},
  author={Rahimian, Hamed and Mehrotra, Sanjay},
  journal={arXiv preprint arXiv:1908.05659},
  year={2019}
}
@inproceedings{koller2018learning,
  title={Learning-based model predictive control for safe exploration},
  author={Koller, Torsten and Berkenkamp, Felix and Turchetta, Matteo and Krause, Andreas},
  booktitle={2018 IEEE conference on decision and control (CDC)},
  pages={6059--6066},
  year={2018},
  organization={IEEE}
}
@article{xu2020primal,
  title={A primal approach to constrained policy optimization: Global optimality and finite-time analysis},
  author={Xu, Tengyu and Liang, Yingbin and Lan, Guanghui},
  journal={arXiv preprint arXiv:2011.05869},
  year={2020}
}
@article{turchetta2020safe,
  title={Safe Reinforcement Learning via Curriculum Induction},
  author={Turchetta, Matteo and Kolobov, Andrey and Shah, Shital and Krause, Andreas and Agarwal, Alekh},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{ding2021provably,
  title={Provably efficient safe exploration via primal-dual policy optimization},
  author={Ding, Dongsheng and Wei, Xiaohan and Yang, Zhuoran and Wang, Zhaoran and Jovanovic, Mihailo},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3304--3312},
  year={2021},
  organization={PMLR}
}
@article{wei2021provably,
  title={A Provably-Efficient Model-Free Algorithm for Constrained Markov Decision Processes},
  author={Wei, Honghao and Liu, Xin and Ying, Lei},
  journal={arXiv preprint arXiv:2106.01577},
  year={2021}
}

@article{yu2021provably,
  title={Provably Efficient Algorithms for Multi-Objective Competitive RL},
  author={Yu, Tiancheng and Tian, Yi and Zhang, Jingzhao and Sra, Suvrit},
  journal={arXiv preprint arXiv:2102.03192},
  year={2021}
}
@inproceedings{qin2021density,
  title={Density Constrained Reinforcement Learning},
  author={Qin, Zengyi and Chen, Yuxiao and Fan, Chuchu},
  booktitle={International Conference on Machine Learning},
  pages={8682--8692},
  year={2021},
  organization={PMLR}
}

@inproceedings{amani2021safe,
  title={Safe reinforcement learning with linear function approximation},
  author={Amani, Sanae and Thrampoulidis, Christos and Yang, Lin},
  booktitle={International Conference on Machine Learning},
  pages={243--253},
  year={2021},
  organization={PMLR}
}

@article{chow2017risk,
  title={Risk-constrained reinforcement learning with percentile risk criteria},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad and Janson, Lucas and Pavone, Marco},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={6070--6120},
  year={2017},
  publisher={JMLR. org}
}
@article{borkar2005actor,
  title={An actor-critic algorithm for constrained Markov decision processes},
  author={Borkar, Vivek S},
  journal={Systems \& control letters},
  volume={54},
  number={3},
  pages={207--213},
  year={2005},
  publisher={Elsevier}
}
@article{bhatnagar2012online,
  title={An online actor--critic algorithm with function approximation for constrained markov decision processes},
  author={Bhatnagar, Shalabh and Lakshmanan, K},
  journal={Journal of Optimization Theory and Applications},
  volume={153},
  number={3},
  pages={688--708},
  year={2012},
  publisher={Springer}
}
@inproceedings{yang2021wcsac,
  title={WCSAC: Worst-case soft actor critic for safety-constrained reinforcement learning},
  author={Yang, Qisong and Sim{\~a}o, Thiago D and Tindemans, Simon H and Spaan, Matthijs TJ},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2021}
}
@article{simao2021alwayssafe,
  title={AlwaysSafe: Reinforcement learning without safety constraint violations during training},
  author={Sim{\~a}o, Thiago D and Jansen, Nils and Spaan, Matthijs TJ},
  year={2021},
  publisher={[Sl: sn]}
}
@inproceedings{kalagarla2021sample,
  title={A Sample-Efficient Algorithm for Episodic Finite-Horizon MDP with Constraints},
  author={Kalagarla, Krishna C and Jain, Rahul and Nuzzo, Pierluigi},
  booktitle={AAAI Conference on Artificial Intelligence},
  volume={35},
  number={9},
  pages={8030--8037},
  year={2021}
}

@article{turchetta2016safe,
  title={Safe exploration in finite markov decision processes with gaussian processes},
  author={Turchetta, Matteo and Berkenkamp, Felix and Krause, Andreas},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  pages={4312--4320},
  year={2016}
}
@inproceedings{berkenkamp2017safe,
  title={Safe model-based reinforcement learning with stability guarantees},
  author={Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela P and Krause, Andreas},
  booktitle={International Conference on Neural Information Processing Systems},
  pages={908--919},
  year={2017}
}

@article{paternain2019constrained,
  title={Constrained reinforcement learning has zero duality gap},
  author={Paternain, Santiago and Chamon, Luiz FO and Calvo-Fullana, Miguel and Ribeiro, Alejandro},
  journal={arXiv preprint arXiv:1910.13393},
  year={2019}
}

@inproceedings{tessler2018reward,
  title={Reward Constrained Policy Optimization},
  author={Tessler, Chen and Mankowitz, Daniel J and Mannor, Shie},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@inproceedings{yang2019projection,
  title={Projection-Based Constrained Policy Optimization},
  author={Yang, Tsung-Yen and Rosca, Justinian and Narasimhan, Karthik and Ramadge, Peter J},
  booktitle={International Conference on Learning Representations},
  year={2019}
}
@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={22--31},
  year={2017},
  organization={PMLR}
}
@inproceedings{stooke2020responsive,
  title={Responsive safety in reinforcement learning by pid lagrangian methods},
  author={Stooke, Adam and Achiam, Joshua and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={9133--9143},
  year={2020},
  organization={PMLR}
}

@article{paternain2019safe,
  title={Safe policies for reinforcement learning via primal-dual methods},
  author={Paternain, Santiago and Calvo-Fullana, Miguel and Chamon, Luiz FO and Ribeiro, Alejandro},
  journal={arXiv preprint arXiv:1911.09101},
  year={2019}
}
@article{agarwal2021markov,
  title={Markov Decision Processes with Long-Term Average Constraints},
  author={Agarwal, Mridul and Bai, Qinbo and Aggarwal, Vaneet},
  journal={arXiv preprint arXiv:2106.06680},
  year={2021}
}
@article{amani2020decentralized,
  title={Decentralized Multi-Agent Linear Bandits with Safety Constraints},
  author={Amani, Sanae and Thrampoulidis, Christos},
  journal={arXiv preprint arXiv:2012.00314},
  year={2020}
}
@article{miryoosefi2021simple,
  title={A Simple Reward-free Approach to Constrained Reinforcement Learning},
  author={Miryoosefi, Sobhan and Jin, Chi},
  journal={arXiv preprint arXiv:2107.05216},
  year={2021}
}
@article{qiu2020upper,
  title={Upper confidence primal-dual optimization: Stochastically constrained Markov decision processes with adversarial losses and unknown transitions},
  author={Qiu, Shuang and Wei, Xiaohan and Yang, Zhuoran and Ye, Jieping and Wang, Zhaoran},
  year={2020}
}
@article{efroni2020exploration,
  title={Exploration-exploitation in constrained mdps},
  author={Efroni, Yonathan and Mannor, Shie and Pirotta, Matteo},
  journal={arXiv preprint arXiv:2003.02189},
  year={2020}
}
@article{maddpg,
  title={Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  author={Ryan Lowe, Yi Wu, Aviv Tamar, Jean Harb, Pieter Abbeel, Igor Mordatch},
  journal={arXiv preprint arXiv:1706.02275},
  year={2017}
}
@article{coma,
  title={Counterfactual Multi-Agent Policy Gradients},
  author={Jakob Foerster, Gregory Farquhar, Triantafyllos Afouras, Nantas Nardelli, Shimon Whiteson},
  journal={arXiv preprint 	arXiv:1705.08926},
  year={2017}
}


@inproceedings{wachi2020safe,
  title={Safe reinforcement learning in constrained markov decision processes},
  author={Wachi, Akifumi and Sui, Yanan},
  booktitle={International Conference on Machine Learning},
  pages={9797--9806},
  year={2020},
  organization={PMLR}
}

@inproceedings{zheng2020constrained,
  title={Constrained upper confidence reinforcement learning},
  author={Zheng, Liyuan and Ratliff, Lillian},
  booktitle={Learning for Dynamics and Control},
  pages={620--629},
  year={2020},
  organization={PMLR}
}
@article{singh2020learning,
  title={Learning in Markov decision processes under constraints},
  author={Singh, Rahul and Gupta, Abhishek and Shroff, Ness B},
  journal={arXiv preprint arXiv:2002.12435},
  year={2020}
}
@incollection{shimkin1994stochastic,
  title={Stochastic games with average cost constraints},
  author={Shimkin, Nahum},
  booktitle={Advances in Dynamic Games and Applications},
  pages={219--230},
  year={1994},
  publisher={Springer}
}

@book{altman1999constrained,
  title={Constrained Markov decision processes},
  author={Altman, Eitan},
  volume={7},
  year={1999},
  publisher={CRC Press}
}
@incollection{altman2000constrained,
  title={Constrained markov games: Nash equilibria},
  author={Altman, Eitan and Shwartz, Adam},
  booktitle={Advances in dynamic games and applications},
  pages={213--221},
  year={2000},
  publisher={Springer}
}
@inproceedings{wachi2018safe,
  title={Safe exploration and optimization of constrained mdps using gaussian processes},
  author={Wachi, Akifumi and Sui, Yanan and Yue, Yisong and Ono, Masahiro},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}
@article{hsiao1991optimal,
  title={Optimal decentralized flow control of Markovian queueing networks with multiple controllers},
  author={Hsiao, Man-Tung T and Lazar, Aurel A},
  journal={Performance evaluation},
  volume={13},
  number={3},
  pages={181--204},
  year={1991},
  publisher={Elsevier}
}
@article{lindner2021information,
  title={Information Directed Reward Learning for Reinforcement Learning},
  author={Lindner, David and Turchetta, Matteo and Tschiatschek, Sebastian and Ciosek, Kamil and Krause, Andreas},
  journal={arXiv preprint arXiv:2102.12466},
  year={2021}
}
@inproceedings{metelli2021provably,
  title={Provably Efficient Learning of Transferable Rewards},
  author={Metelli, Alberto Maria and Ramponi, Giorgia and Concetti, Alessandro and Restelli, Marcello},
  booktitle={International Conference on Machine Learning},
  pages={7665--7676},
  year={2021},
  organization={PMLR}
}
@article{flokas2021solving,
  title={Solving Min-Max Optimization with Hidden Structure via Gradient Descent Ascent},
  author={Flokas, Lampros and Vlatakis-Gkaragkounis, Emmanouil-Vasileios and Piliouras, Georgios},
  journal={arXiv e-prints},
  pages={arXiv--2101},
  year={2021}
}
@article{daskalakis2019last,
  title={Last-Iterate Convergence: Zero-Sum Games and Constrained Min-Max Optimization},
  author={Daskalakis, Constantinos and Panageas, Ioannis},
  journal={10th Innovations in Theoretical Computer Science},
  year={2019}
}
@article{metaagent,
  title={Coordinating the Crowd: Inducing Desirable Equilibria in Non-Cooperative Systems},
  author={David Mguni, Joel Jennings, Sergio Valcarcel Macua, Emilio Sison, Sofia Ceppi, Enrique Munoz de Cote},
  journal={https://arxiv.org/abs/1901.10923},
  year={2019}
}
@article{networkedsafemarl,
  title={Decentralized Policy Gradient Descent Ascent for
Safe Multi-Agent Reinforcement Learning},
  author={Songtao Lu, Kaiqing Zhang, Tianyi Chen, Tamer Ba¸sar, Lior Horesh},
  journal={AAAI Conference on Artificial Intelligence},
  year={2021}
}
@article{mpg,
  title={Global Convergence of Multi-Agent Policy Gradient in Markov Potential Games},
  author={Stefanos Leonardos, Will Overman, Ioannis Panageas, Georgios Piliouras},
  journal={arXiv:2106.01969},
  year={2021}
}

@inproceedings{bayesianOptimization,
  title={Bayesian optimization with inequality constraints},
  author={Gardner, Jacob R and Kusner, Matt J and Xu, Zhixiang and Weinberger, Kilian Q and Cunningham, John P},
  booktitle={International Conference on Machine Learning},
  pages = {II–937–II–945},
  year={2014}
}

@article{marlreview,
  title={Multi-Agent Reinforcement Learning: A Review of Challenges
and Applications},
  author={Lorenzo Canese, Gian Carlo Cardarilli, Luca Di Nunzio, Rocco Fazzolari, Daniele Giardino, Marco Re, and Sergio Spanò},
  journal={Applied Sciences},
  year={2021}
}
@article{powernetworkcontrol,
  title={Distributed value functions},
  author={Schneider, J.; Wong, W.-K.; Moore, A.; and Riedmiller, M},
  journal={Proc. Intl. Conf. Machine Learning, 371–378},
  year={1999}
}
@inproceedings{daskalakis2021complexity,
  title={The complexity of constrained min-max optimization},
  author={Daskalakis, Constantinos and Skoulakis, Stratis and Zampetakis, Manolis},
  booktitle={Annual ACM SIGACT Symposium on Theory of Computing},
  pages={1466--1478},
  year={2021}
}

@inproceedings{liu2021cmix,
  title={CMIX: Deep Multi-agent Reinforcement Learning with Peak and Average Constraints},
  author={Liu, Chenyi and Geng, Nan and Aggarwal, Vaneet and Lan, Tian and Yang, Yuan and Xu, Mingwei},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={157--173},
  year={2021},
  organization={Springer}
}

@inproceedings{xie2020learning,
  title={Learning zero-sum simultaneous-move markov games using function approximation and correlated equilibrium},
  author={Xie, Qiaomin and Chen, Yudong and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={Conference on Learning Theory},
  pages={3674--3682},
  year={2020},
  organization={PMLR}
}

@article{altman2005zero,
  title={Zero-sum constrained stochastic games with independent state processes},
  author={Altman, Eitan and Avrachenkov, Konstantin and Marquez, Richard and Miller, Gregory},
  journal={Mathematical Methods of Operations Research},
  volume={62},
  number={3},
  pages={375--386},
  year={2005},
  publisher={Springer}
}
@InProceedings{Shimkin,
author="Shimkin, Nahum",
editor="Ba{\c{s}}ar, Tamer
and Haurie, Alain",
title="Stochastic Games with Average Cost Constraints",
booktitle="Advances in Dynamic Games and Applications",
year="1994",
publisher="Birkh{\"a}user Boston",
address="Boston, MA",
pages="219--230",
isbn="978-1-4612-0245-5"
}
@inproceedings{qiu2021provably,
  title={Provably Efficient Fictitious Play Policy Optimization for Zero-Sum Markov Games with Structured Transitions},
  author={Qiu, Shuang and Wei, Xiaohan and Ye, Jieping and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={International Conference on Machine Learning},
  pages={8715--8725},
  year={2021},
  organization={PMLR}
}

@article{altman2008constrained,
  title={Constrained cost-coupled stochastic games with independent state processes},
  author={Altman, Eitan and Avrachenkov, Konstantin and Bonneau, Nicolas and Debbah, Merouane and El-Azouzi, Rachid and Menasche, Daniel Sadoc},
  journal={Operations Research Letters},
  volume={36},
  number={2},
  pages={160--164},
  year={2008},
  publisher={Elsevier}
}
@article{liu2021learning,
  title={Learning Policies with Zero or Bounded Constraint Violation for Constrained MDPs},
  author={Liu, Tao and Zhou, Ruida and Kalathil, Dileep and Kumar, PR and Tian, Chao},
  journal={arXiv preprint arXiv:2106.02684},
  year={2021}
}
@article{mpgConvergence,
  title={Independent Natural Policy Gradient Always Converges
in Markov Potential Games},
  author={Anonymus},
  journal={},
  year={2021}
}
@inproceedings{zhang2018fully,
  title={Fully decentralized multi-agent reinforcement learning with networked agents},
  author={Zhang, Kaiqing and Yang, Zhuoran and Liu, Han and Zhang, Tong and Basar, Tamer},
  booktitle={International Conference on Machine Learning},
  pages={5872--5881},
  year={2018},
  organization={PMLR}
}
@inproceedings{corke2005networked,
  title={Networked robots: Flying robot navigation using a sensor net},
  author={Corke, Peter and Peterson, Ron and Rus, Daniela},
  booktitle={Robotics research. The eleventh international symposium},
  pages={234--243},
  year={2005},
  organization={Springer}
}
@inproceedings{boyan1994packet,
  title={Packet routing in dynamically changing networks: A reinforcement learning approach},
  author={Boyan, Justin A and Littman, Michael L},
  booktitle={Advances in neural information processing systems},
  pages={671--678},
  year={1994}
}
@inproceedings{lu2021decentralized,
  title={Decentralized policy gradient descent ascent for safe multi-agent reinforcement learning},
  author={Lu, Songtao and Zhang, Kaiqing and Chen, Tianyi and Ba{\c{s}}ar, Tamer and Horesh, Lior},
  booktitle={AAAI Conference on Artificial Intelligence},
  volume={35},
  number={10},
  pages={8767--8775},
  year={2021}
}
@inproceedings{garcelon2020conservative,
  title={Conservative exploration in reinforcement learning},
  author={Garcelon, Evrard and Ghavamzadeh, Mohammad and Lazaric, Alessandro and Pirotta, Matteo},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1431--1441},
  year={2020},
  organization={PMLR}
}

@inproceedings{ding2020natural,
  title={Natural Policy Gradient Primal-Dual Method for Constrained Markov Decision Processes.},
  author={Ding, Dongsheng and Zhang, Kaiqing and Basar, Tamer and Jovanovic, Mihailo R},
  booktitle={NeurIPS},
  year={2020}
}

@book{puterman2005,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2005},
  publisher={John Wiley \& Sons}
}

@incollection{kuhn-et-al2019survey,
  title={Wasserstein distributionally robust optimization: Theory and applications in machine learning},
  author={Kuhn, Daniel and Esfahani, Peyman Mohajerin and Nguyen, Viet Anh and Shafieezadeh-Abadeh, Soroosh},
  booktitle={Operations research \& management science in the age of analytics},
  pages={130--166},
  year={2019},
  publisher={Informs}
}

@inproceedings{zhang-et-al2018,
  title={Policy optimization as wasserstein gradient flows},
  author={Zhang, Ruiyi and Chen, Changyou and Li, Chunyuan and Carin, Lawrence},
  booktitle={International Conference on Machine Learning},
  pages={5737--5746},
  year={2018},
  organization={PMLR}
}

@article{blanchet-murthy2019,
  title={Quantifying distributional model risk via optimal transport},
  author={Blanchet, Jose and Murthy, Karthyek},
  journal={Mathematics of Operations Research},
  volume={44},
  number={2},
  pages={565--600},
  year={2019},
  publisher={INFORMS}
}
@article{zhao-guan2018,
  title={Data-driven risk-averse stochastic optimization with {W}asserstein metric},
  author={Zhao, Chaoyue and Guan, Yongpei},
  journal={Operations Research Letters},
  volume={46},
  number={2},
  pages={262--267},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{Kakade2002a,
    title = {A natural policy gradient},
    year = {2002},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Kakade, Sham M},
    volume = {14}
}

@article{Peng2019,
    title = {Advantage-weighted regression: simple and scalable off-policy reinforcement learning},
    year = {2019},
    journal = {arXiv preprint arXiv:1910.00177},
    author = {Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
    arxivId = {1910.00177}
}

@inproceedings{Kakade2002b,
    title = {Approximately optimal approximate reinforcement learning},
    year = {2002},
    booktitle = {International Conference on Machine Learning},
    author = {Kakade, Sham and Langford, John},
    pages = {267--274},
    organization={PMLR},
}

@book{Rockafellar2015,
    title = {Convex Analysis},
    year = {2015},
    author = {Rockafellar, Ralph Tyrell},
    publisher = {Princeton University Press}
}

@book{Boyd2004,
    title = {Convex Optimization},
    year = {2004},
    author = {Boyd, Stephen and Vandenberghe, Lieven},
    publisher = {Cambridge University Press}
}

@article{Mohajerin2018,
    title = {Data-driven distributionally robust optimization using the {W}asserstein metric: performance guarantees and tractable reformulations},
    year = {2018},
    journal = {Mathematical Programming},
    author = {Mohajerin Esfahani, Peyman and Kuhn, Daniel},
    number = {1},
    pages = {115--166},
    volume = {171},
    publisher = {Springer Berlin Heidelberg}
}
@article{deisenroth2013survey,
  title={A survey on policy search for robotics},
  author={Deisenroth, Marc Peter and Neumann, Gerhard and Peters, Jan and others},
  journal={Foundations and trends in Robotics},
  volume={2},
  number={1-2},
  pages={388--403},
  year={2013},
  publisher={now publishers}
}

@misc{Smirnova2019,
    title = {Distributionally robust reinforcement learning},
    year = {2019},
    author = {Smirnova, Elena and Dohmatob, Elvis and Mary, Jérémie}
}

@article{Gao2016,
    title = {Distributionally robust stochastic optimization with {W}asserstein distance},
    year = {2016},
    journal = {arXiv preprint arXiv:1604.02199},
    author = {Gao, Rui and Kleywegt, Anton J.},
    url = {\url{https://faculty.mccombs.utexas.edu/rui.gao/wasserstein.pdf}},
    arxivId = {1604.02199}
}

@inproceedings{castro2020scalable,
  title={Scalable methods for computing state similarity in deterministic markov decision processes},
  author={Castro, Pablo Samuel},
  booktitle={AAAI Conference on Artificial Intelligence},
  volume={34},
  number={06},
  pages={10069--10076},
  year={2020}
}
@inproceedings{ferns2004metrics,
  title={Metrics for Finite Markov Decision Processes.},
  author={Ferns, Norm and Panangaden, Prakash and Precup, Doina},
  booktitle={UAI},
  volume={4},
  pages={162--169},
  year={2004}
}

@misc{Song2022,
title={Efficient {W}asserstein and {S}inkhorn Policy Optimization},
author={Jun Song and Chaoyue Zhao and Niao He},
year={2022},
url={\url{https://openreview.net/forum?id=Mlwe37htstv}}
}

@article{Moskovitz2020,
    title = {Efficient {W}asserstein natural gradients for reinforcement learning},
    year = {2020},
    journal = {arXiv preprint arXiv:2010.05380},
    author = {Moskovitz, Ted and Arbel, Michael and Huszar, Ferenc and Gretton, Arthur},
    number = {},
    pages = {},
    arxivId = {2010.05380}
}

@book{Ambrosio2008,
    title = {Gradient flows: In Metric Spaces and in the Space of Probability Measures},
    year = {2008},
    author = {Ambrosio, Luigi and Gigli, Nicola and Savar{\'{e}}, Giuseppe},
    publisher = {Springer}
}

@inproceedings{Schulman2016,
    title = {High-dimensional continuous control using generalized advantage estimation},
    year = {2016},
    booktitle = {International Conference on Learning Representations},
    author = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael I. and Abbeel, Pieter}
}

@book{Aliprantis2006,
    title = {Infinite Dimensional Analysis: a Hitchhiker's Guide},
    year = {2006},
    author = {Aliprantis, Charalambos D. and Border, Kim C.},
    publisher = {Springer},
    address = {Berlin; London},
    keywords = {math textbook}
}

@inproceedings{Pacchiano2020,
    title = {Learning to score behaviors for guided policy optimization},
    year = {2020},
    booktitle = {International Conference on Machine Learning},
    author = {Pacchiano, Aldo and Parker-Holder, Jack and Tang, Yunhao and Choromanska, Anna and Choromanski, Krzysztof and Jordan, Michael I.},
    pages = {7401--7410},
    organization={PMLR},
}

@article{Richemond2017,
    title = {On {W}asserstein reinforcement learning and the {F}okker-{P}lanck equation},
    year = {2017},
    journal = {arXiv preprint arXiv:1712.07185},
    author = {Richemond, Pierre H. and Maginnis, Brendan},
    number = {},
    pages = {},
    arxivId = {1712.07185}
}

@article{Brockman2016,
    title = {{OpenAI Gym}},
    year = {2016},
    journal = {arXiv preprint arXiv:1606.01540},
    author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
    arxivId = {1606.01540}
}

@book{Leuenberger1997,
    title = {{Optimization by vector space methods}},
    year = {1997},
    author = {Luenberger, David G.},
    publisher = {John Wiley \& Sons}
}

@inproceedings{Todorov2012,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@misc{Hill2018,
  author = {Hill, Ashley and Raffin, Antonin and Ernestus, Maximilian and Gleave, Adam and Kanervisto, Anssi and Traore, Rene and Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {Stable Baselines},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/hill-a/stable-baselines}},
}

@book{Villani2008,
    title = {Optimal Transport: Old and New},
    year = {2008},
    booktitle = {Media},
    author = {Villani, Cédric},
    volume = {},
    publisher = {Springer-Verlag Berlin Heidelberg}
}

@inproceedings{Sutton2000,
    title = {Policy gradient methods for reinforcement learning with function approximation},
    year = {2000},
    booktitle = {Advances in Neural Information Processing Systems},
    author = {Sutton, Richard S. and McAllester, David and Singh, Satinder and Mansour, Yishay},
    pages = {1057--1063},
    issn = {10495258}
}

@inproceedings{Peters2006,
    title = {Policy gradient methods for robotics},
    year = {2006},
    booktitle = {IEEE International Conference on Intelligent Robots and Systems},
    author = {Peters, Jan and Schaal, Stefan},
    pages = {2219--2225}
}

@book{Klenke2008,
    title = {Probability Theory: A Comprehensive Course},
    year = {2008},
    author = {Klenke, Achim},
    publisher = {Springer}
}

@article{Schulman2017,
    title = {Proximal policy optimization algorithms},
    year = {2017},
    journal = {arXiv preprint arXiv:1707.06347},
    author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
    arxivId = {1707.06347}
}

@book{Rudin1987,
    title = {Real and Complex Analysis, 3rd Ed.},
    year = {1987},
    author = {Rudin, Walter},
    publisher = {McGraw-Hill, Inc.},
    address = {USA}
}

@book{Sutton1998,
    title = {Reinforcement Learning: An Introduction},
    year = {2018},
    author = {Sutton, Richard S. and Barto, Andrew G.},
    publisher = {MIT Press}
}

@misc{Hou2020,
    title = {Robust reinforcement learning with {W}asserstein constraint},
    year = {2020},
    author = {Hou, Linfang and Pang, Liang and Hong, Xin and Lan, Yanyan and Ma, Zhiming and Yin, Dawei}
}

@book{Munkres2000,
    title = {Topology},
    year = {2000},
    author = {Munkres, James R.},
    series = {Featured Titles for Topology},
    publisher = {Prentice Hall, Incorporated}
}

@inproceedings{Schulman2015,
    title = {Trust region policy optimization},
    year = {2015},
    booktitle = {International Conference on Machine Learning},
    author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael I. and Abbeel, Pieter},
    pages = {1889--1897},
    organization={PMLR}
}

@article{Arjovsky2017,
    title = {Wasserstein {GAN}},
    year = {2017},
    journal = {arXiv preprint arXiv:1701.07875},
    author = {Arjovsky, Martin and Chintala, Soumith and Bottou, Léon},
    arxivId = {1701.07875}
}

@misc{Abdullah2019,
    title = {Wasserstein robust reinforcement learning},
    year = {2019},
    author = {Abdullah, Mohammed Amin and Ren, Hang and Ammar, Haitham Bou and Milenkovic, Vladimir and Luo, Rui and Zhang, Mingtian and Wang, Jun}
}

@article{Aolaritei2022,
  author = {Aolaritei, Liviu and Lanzetti, Nicolas and Chen, Hongruyu and Dörfler, Florian},
  title = {Uncertainty Propagation via Optimal Transport Ambiguity Sets},
  journal = {arXiv preprint arXiv:2205.00343},
  year = {2022}
}

@inproceedings{Mnih2016,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning},
  pages={1928--1937},
  year={2016},
  organization={PMLR}
}

@inproceedings{Terjek2021,
  title={Optimal transport with $f$-divergence regularization and generalized {S}inkhorn algorithm},
  author={Terj{\'e}k, D{\'a}vid and Gonz{\'a}lez-S{\'a}nchez, Diego},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={5135--5165},
  year={2022},
  organization={PMLR}
}

@inproceedings{Cuturi2013,
 author = {Cuturi, Marco},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Sinkhorn Distances: Lightspeed Computation of Optimal Transport},
 volume = {26},
 year = {2013}
}


@article{Gao2017,
  title={Wasserstein distributionally robust optimization and variation regularization},
  author={Gao, Rui and Chen, Xi and Kleywegt, Anton J.},
  journal={arXiv preprint arXiv:1712.06050},
  year={2017}
}