\begin{thebibliography}{10}

\bibitem{BarJNSV98}
C.~{Barnhart}, E.~L. {Johnson}, G.~L. {Nemhauser}, M.~W.~P. {Savelsbergh}, and
  P.~H. {Vance}.
\newblock Branch-and-price: Column generation for solving huge integer
  programs.
\newblock {\em Oper. Res.}, 46(3):316--329, 1998.

\bibitem{Berthold14}
T.~Berthold.
\newblock {\em Heuristic algorithms in global {MINLP} solvers}.
\newblock PhD thesis, TU Berlin, 2014.

\bibitem{bertsimas2017optimal}
D.~Bertsimas and J.~Dunn.
\newblock Optimal classification trees.
\newblock {\em Machine Learning}, pages 1--44, 2017.

\bibitem{bertsimas2015or}
D.~Bertsimas and A.~King.
\newblock {OR} forum---an algorithmic approach to linear regression.
\newblock {\em Operations Research}, 64(1):2--16, 2015.

\bibitem{bertsimas2016best}
D.~Bertsimas, A.~King, R.~Mazumder, et~al.
\newblock Best subset selection via a modern optimization lens.
\newblock {\em The Annals of Statistics}, 44(2):813--852, 2016.

\bibitem{bertsimas2007classification}
D.~Bertsimas and R.~Shioda.
\newblock Classification and regression via integer optimization.
\newblock {\em Operations Research}, 55(2):252--271, 2007.

\bibitem{BLRSW13}
R.~Bornd{\"o}rfer, A.~L{\"o}bel, M.~Reuther, T.~Schlechte, and S.~Weider.
\newblock Rapid branching.
\newblock {\em Public Transport}, 5(1):3--23, 2013.

\bibitem{BLW08}
R.~Bornd{\"o}rfer, A.~L{\"o}bel, and S.~Weider.
\newblock A bundle method for integrated multi-depot vehicle and duty
  scheduling in public transit.
\newblock In M.~Hickman, P.~Mirchandani, and S.~Vo{\ss}, editors, {\em
  Computer-aided Systems in Public Transport}, volume 600, pages 3--24, 2008.

\bibitem{Bre96}
L.~Breiman.
\newblock Bagging predictors.
\newblock {\em Machine Learning}, 24:123--140, 1996.

\bibitem{chang2012integer}
A.~Chang, D.~Bertsimas, and C.~Rudin.
\newblock An integer optimization approach to associative classification.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  269--277, 2012.

\bibitem{cortes2014deep}
C.~Cortes, M.~Mohri, and U.~Syed.
\newblock Deep boosting.
\newblock In {\em 31st International Conference on Machine Learning, ICML
  2014}. International Machine Learning Society (IMLS), 2014.

\bibitem{cplex}
CPLEX.
\newblock {IBM ILOG CPLEX Optimizer}.
\newblock \url{https://www.ibm.com/analytics/cplex-optimizer}, 2020.

\bibitem{dash2018boolean}
S.~Dash, O.~G{\"u}nl{\"u}k, and D.~Wei.
\newblock Boolean decision rules via column generation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4655--4665, 2018.

\bibitem{demiriz2002linear}
A.~Demiriz, K.~P. Bennett, and J.~Shawe-Taylor.
\newblock Linear programming boosting via column generation.
\newblock {\em Machine Learning}, 46(1-3):225--254, 2002.

\bibitem{desrosiers2005primer}
J.~Desrosiers and M.~E. L{\"u}bbecke.
\newblock A primer in column generation.
\newblock In {\em Column generation}, pages 1--32. Springer, 2005.

\bibitem{eckstein2012improved}
J.~Eckstein and N.~Goldberg.
\newblock An improved branch-and-bound method for maximum monomial agreement.
\newblock {\em INFORMS Journal on Computing}, 24(2):328--341, 2012.

\bibitem{fischetti2018deep}
M.~Fischetti and J.~Jo.
\newblock Deep neural networks and mixed integer linear optimization.
\newblock {\em Constraints}, 23(3):296--309, 2018.

\bibitem{freund2015new}
R.~M. Freund, P.~Grigas, and R.~Mazumder.
\newblock A new perspective on boosting in linear regression via subgradient
  optimization and relatives.
\newblock {\em arXiv preprint arXiv:1505.04243}, 2015.

\bibitem{freund1995desicion}
Y.~Freund and R.~E. Schapire.
\newblock A desicion-theoretic generalization of on-line learning and an
  application to boosting.
\newblock In {\em European Conference on Computational Learning Theory}, pages
  23--37. Springer, 1995.

\bibitem{GleixnerEtal2018OO}
A.~Gleixner, M.~Bastubbe, L.~Eifler, T.~Gally, G.~Gamrath, R.~L. Gottwald,
  G.~Hendel, C.~Hojny, T.~Koch, M.~E. L{\"u}bbecke, S.~J. Maher,
  M.~Miltenberger, B.~M{\"u}ller, M.~E. Pfetsch, C.~Puchert, D.~Rehfeldt,
  F.~Schl{\"o}sser, C.~Schubert, F.~Serrano, Y.~Shinano, J.~M. Viernickel,
  M.~Walter, F.~Wegscheider, J.~T. Witt, and J.~Witzig.
\newblock {The SCIP Optimization Suite 6.0}.
\newblock Technical report, Optimization Online, July 2018.

\bibitem{goldberg2010boosting}
N.~Goldberg and J.~Eckstein.
\newblock Boosting classifiers with tightened l0-relaxation penalties.
\newblock In {\em Proceedings of the 27th International Conference on Machine
  Learning (ICML-10)}, pages 383--390, 2010.

\bibitem{goldberg2012sparse}
N.~Goldberg and J.~Eckstein.
\newblock Sparse weighted voting classifier selection and its linear
  programming relaxations.
\newblock {\em Information Processing Letters}, 112(12):481--486, 2012.

\bibitem{gunluk2016optimal}
O.~G{\"u}nl{\"u}k, J.~Kalagnanam, M.~Menickelly, and K.~Scheinberg.
\newblock Optimal generalized decision trees via integer programming.
\newblock {\em arXiv preprint arXiv:1612.03225}, 2016.

\bibitem{gunluk2018optimal}
O.~G{\"u}nl{\"u}k, J.~Kalagnanam, M.~Menickelly, and K.~Scheinberg.
\newblock Optimal decision trees for categorical data via integer programming.
\newblock {\em arXiv preprint arXiv:1612.03225}, 2018.

\bibitem{gurobi}
Gurobi.
\newblock {Gurobi Optimizer}.
\newblock \url{http://www.gurobi.com}, 2020.

\bibitem{leskovec2003linear}
J.~Leskovec and J.~Shawe-Taylor.
\newblock Linear programming boosting for uneven datasets.
\newblock In {\em Proceedings of the Twentieth International Conference on
  Machine Learning (ICML-2003)}, pages 456--463, 2003.

\bibitem{long2008random}
P.~M. Long and R.~A. Servedio.
\newblock Random classification noise defeats all convex potential boosters.
\newblock In {\em Proceedings of the 25th international conference on Machine
  learning}, pages 608--615. ACM, 2008.

\bibitem{long2010random}
P.~M. Long and R.~A. Servedio.
\newblock Random classification noise defeats all convex potential boosters.
\newblock {\em Machine learning}, 78(3):287--304, 2010.

\bibitem{pedregosa2011scikit}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, et~al.
\newblock Scikit-learn: Machine learning in python.
\newblock {\em Journal of Machine Learning Research}, 12(Oct):2825--2830, 2011.

\bibitem{Pfetsch2008}
M.~E. Pfetsch.
\newblock Branch-and-cut for the maximum feasible subsystem problem.
\newblock {\em SIAM J. Optim.}, 19(1):21--38, 2008.

\bibitem{savicky2000optimal}
P.~Savick{\`y}, J.~Klaschka, and J.~Antoch.
\newblock Optimal classification trees.
\newblock In {\em COMPSTAT}, pages 427--432. Springer, 2000.

\bibitem{schapire2003boosting}
R.~E. Schapire.
\newblock The boosting approach to machine learning: An overview.
\newblock In {\em Nonlinear estimation and classification}, pages 149--171.
  Springer, 2003.

\bibitem{shalev2016minimizing}
S.~Shalev-Shwartz and Y.~Wexler.
\newblock Minimizing the maximal loss: How and why.
\newblock In {\em Proceedings of the 32nd International Conference on Machine
  Learning}, 2016.

\bibitem{tjeng2017evaluating}
V.~Tjeng, K.~Xiao, and R.~Tedrake.
\newblock Evaluating robustness of neural networks with mixed integer
  programming.
\newblock {\em arXiv preprint arXiv:1711.07356}, 2017.

\bibitem{verwer2019learning}
S.~Verwer and Y.~Zhang.
\newblock Learning optimal classification trees using a binary linear program
  formulation.
\newblock In {\em 33rd AAAI Conference on Artificial Intelligence}, 2019.

\bibitem{xpress}
XPRESS.
\newblock {FICO Xpress Optimizer}.
\newblock \url{https://www.fico.com/en/products/fico-xpress-optimization},
  2020.

\bibitem{zhu2009multi}
J.~Zhu, H.~Zou, S.~Rosset, and T.~Hastie.
\newblock Multi-class adaboost.
\newblock {\em Statistics and its Interface}, 2(3):349--360, 2009.

\end{thebibliography}
