\begin{thebibliography}{10}

\bibitem{AMDIM}
Philip Bachman, R~Devon Hjelm, and William Buchwalter.
\newblock Learning representations by maximizing mutual information across
  views.
\newblock {\em arXiv preprint arXiv:1906.00910}, 2019.

\bibitem{simclr}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock {\em ICML}, 2020.

\bibitem{simclrv2}
Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey
  Hinton.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock {\em arXiv preprint arXiv:2006.10029}, 2020.

\bibitem{mocov2}
Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.
\newblock Improved baselines with momentum contrastive learning.
\newblock {\em arXiv preprint arXiv:2003.04297}, 2020.

\bibitem{simsiam}
Xinlei Chen and Kaiming He.
\newblock Exploring simple siamese representation learning.
\newblock {\em arXiv preprint arXiv:2011.10566}, 2020.

\bibitem{cover1999elements}
Thomas~M Cover.
\newblock {\em Elements of information theory}.
\newblock John Wiley \& Sons, 1999.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock {\em CVPR}, 2009.

\bibitem{rel_loc_pred}
Carl Doersch, Abhinav Gupta, and Alexei~A Efros.
\newblock Unsupervised visual representation learning by context prediction.
\newblock {\em ICCV}, 2015.

\bibitem{feder1994relations}
Meir Feder and Neri Merhav.
\newblock Relations between entropy and error probability.
\newblock {\em IEEE Transactions on Information Theory}, 40(1):259--266, 1994.

\bibitem{feng2019self}
Zeyu Feng, Chang Xu, and Dacheng Tao.
\newblock Self-supervised representation learning from multi-domain data.
\newblock {\em ICCV}, 2019.

\bibitem{rotation}
Spyros Gidaris, Praveer Singh, and Nikos Komodakis.
\newblock Unsupervised representation learning by predicting image rotations.
\newblock {\em ICLR}, 2018.

\bibitem{BYOL}
Jean-Bastien Grill, Florian Strub, Florent Altch{\'e}, C.~Tallec, Pierre~H.
  Richemond, Elena Buchatskaya, C.~Doersch, Bernardo~Avila Pires,
  Zhaohan~Daniel Guo, Mohammad~Gheshlaghi Azar, B.~Piot, K.~Kavukcuoglu,
  R{\'e}mi Munos, and Michal Valko.
\newblock Bootstrap your own latent: A new approach to self-supervised
  learning.
\newblock {\em NeurIPS}, 2020.

\bibitem{moco}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock {\em CVPR}, 2020.

\bibitem{maskrcnn}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Mask {R-CNN}.
\newblock In {\em ICCV}, 2017.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock {\em CVPR}, 2016.

\bibitem{infomax}
R~Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil
  Bachman, Adam Trischler, and Yoshua Bengio.
\newblock Learning deep representations by mutual information estimation and
  maximization.
\newblock {\em ICLR}, 2019.

\bibitem{cifar}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{li2018survey}
Yingming Li, Ming Yang, and Zhongfei Zhang.
\newblock A survey of multi-view representation learning.
\newblock {\em IEEE transactions on Knowledge and Data Engineering},
  31(10):1863--1883, 2018.

\bibitem{fpn}
Tsung-Yi Lin, Piotr Doll{\'a}r, Ross Girshick, Kaiming He, Bharath Hariharan,
  and Serge Belongie.
\newblock Feature pyramid networks for object detection.
\newblock In {\em CVPR}, 2017.

\bibitem{retinanet}
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
\newblock Focal loss for dense object detection.
\newblock In {\em ICCV}, 2017.

\bibitem{coco}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em ECCV}, 2014.

\bibitem{cosine}
Ilya Loshchilov and Frank Hutter.
\newblock Sgdr: Stochastic gradient descent with warm restarts.
\newblock {\em ICLR}, 2017.

\bibitem{metzger2020evaluating}
Sean Metzger, Aravind Srinivas, Trevor Darrell, and Kurt Keutzer.
\newblock Evaluating self-supervised pretraining without using labels.
\newblock {\em arXiv preprint arXiv:2009.07724}, 2020.

\bibitem{pirl}
Ishan Misra and Laurens van~der Maaten.
\newblock Self-supervised learning of pretext-invariant representations.
\newblock {\em CVPR}, 2020.

\bibitem{jigsaw}
Mehdi Noroozi and Paolo Favaro.
\newblock Unsupervised learning of visual representations by solving {Jigsaw}
  puzzles.
\newblock {\em ECCV}, 2016.

\bibitem{InfoNCE}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock {\em arXiv preprint arXiv:1807.03748}, 2018.

\bibitem{cmc}
Yonglong Tian, Dilip Krishnan, and Phillip Isola.
\newblock Contrastive multiview coding.
\newblock {\em arXiv preprint arXiv:1906.05849}, 2019.

\bibitem{InfoMin}
Yonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan, Cordelia Schmid, and
  Phillip Isola.
\newblock What makes for good views for contrastive learning.
\newblock {\em NeurIPS}, 2020.

\bibitem{tsai2020self}
Yao-Hung~Hubert Tsai, Yue Wu, Ruslan Salakhutdinov, and Louis-Philippe Morency.
\newblock Self-supervised learning from a multi-view perspective.
\newblock {\em ICLR}, 2021.

\bibitem{van2008visualizing}
Laurens Van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-{SNE}.
\newblock {\em Journal of Machine Learning Research}, 9(11), 2008.

\bibitem{tinyImageNet}
Jiayu Wu, Qixiang Zhang, and Guoxi Xu.
\newblock Tiny {ImageNet} challenge, 2017.

\bibitem{looc}
Tete Xiao, Xiaolong Wang, Alexei~A Efros, and Trevor Darrell.
\newblock What should not be contrastive in contrastive learning.
\newblock {\em ICLR}, 2021.

\bibitem{lars}
Yang You, Igor Gitman, and Boris Ginsburg.
\newblock Scaling sgd batch size to 32k for {ImageNet} training.
\newblock {\em arXiv preprint arXiv:1708.03888}, 2017.

\bibitem{colorization}
Richard Zhang, Phillip Isola, and Alexei~A Efros.
\newblock Colorful image colorization.
\newblock {\em ECCV}, 2016.

\end{thebibliography}
