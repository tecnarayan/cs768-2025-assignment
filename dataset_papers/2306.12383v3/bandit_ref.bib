@misc{hu2021nearoptimal,
	title={Near-optimal Representation Learning for Linear Bandits and Linear RL}, 
	author={Jiachen Hu and Xiaoyu Chen and Chi Jin and Lihong Li and Liwei Wang},
	year={2021},
	eprint={2102.04132},
	archivePrefix={arXiv},
	primaryClass={cs.LG}
}

@inproceedings{katariya2017stochastic,
	title={Stochastic rank-1 bandits},
	author={Katariya, Sumeet and Kveton, Branislav and Szepesvari, Csaba and Vernade, Claire and Wen, Zheng},
	booktitle={Artificial Intelligence and Statistics},
	pages={392--401},
	year={2017},
	organization={PMLR}
}

@inproceedings{kotlowski2019bandit,
	title={Bandit principal component analysis},
	author={Kot{\l}owski, Wojciech and Neu, Gergely},
	booktitle={Conference On Learning Theory},
	pages={1994--2024},
	year={2019},
	organization={PMLR}
}

@article{agarwal2019reinforcement,
	title={Reinforcement learning: Theory and algorithms},
	author={Agarwal, Alekh and Jiang, Nan and Kakade, Sham M and Sun, Wen},
	journal={CS Dept., UW Seattle, Seattle, WA, USA, Tech. Rep},
	year={2019}
}

@article{lattimore2021bandit,
	title={Bandit Phase Retrieval},
	author={Lattimore, Tor and Hao, Botao},
	journal={arXiv preprint arXiv:2106.01660},
	year={2021}
}


@article{jlt20,
  title={Robust sub-gaussian principal component analysis and width-independent schatten packing},
  author={Jambulapati, Arun and Li, Jerry and Tian, Kevin},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={33},
  year={2020}
}

@phdthesis{li18,
  title={Principled approaches to robust machine learning and beyond},
  author={Li, Jerry Zheng},
  year={2018},
  school={Massachusetts Institute of Technology}
}

@book{fkp19,
  title={Semialgebraic Proofs and Efficient Algorithm Design.},
  author={Fleming, Noah and Kothari, Pravesh and Pitassi, Toniann },
  year={2019},
  publisher={Foundations and Trends in Theoretical Computer Science}
}

@inproceedings{cccwc20,
  title={Fast Global Convergence of Natural Policy Gradient
Methods with Entropy Regularization},
  author={Cen, Shicong and Chen, Yuxin and Cheng, Chen and Wei, Yuting and Chi, Yuejie},
  publisher={arXiv preprint arXiv:2007.06558},
  year={2020}
}

@inproceedings{aklm19,
  title={Optimality and approximation with policy gradient methods in Markov decision processes},
  author={Agarwal, Alekh and Kakade, Sham M. and Lee, Jason D. and Mahajan, Gaurav},
  publisher={arXiv preprint arXiv:1908.00261},
  year={2019}
}

@inproceedings{lan21,
  title={Policy Mirror Descent for Reinforcement Learning: Linear Convergence, New Sampling Complexity, and Generalized Problem Classes},
  author={Lan, Guanghui},
  publisher={arXiv preprint arXiv:2102.00135},
  year={2021}
}
  %pages={6067--6077},
  %booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  
@inproceedings{mxss20,
  title={On the global convergence rates of softmax
policy gradient methods},
  author={Mei, Jincheng and Xiao, Chenjun and Szepesvari, Csaba and Schuurmans, Dale},
  publisher={arXiv preprint arXiv:2005.06392},
  year={2020}
}

@inproceedings{br20,
  title={A Note on the Linear Convergence of Policy Gradient Methods},
  author={Bhandari, Jalaj and Russo, Daniel},
  publisher={arXiv preprint arXiv:2007.11120},
  year={2020}
}
@inproceedings{lcyw19,
  title={Neural Proximal/Trust Region Policy Optimization Attains Globally Optimal Policy},
  author={Liu, Boyi and Cai, Qi and Yang, Zhuoran and Wang, Zhaoran},
  publisher={arXiv preprint arXiv:1906.10306},
  year={2019}
}
@inproceedings{wcyw20,
  title={Neural policy gradient methods: Global optimality and rates of convergence},
  author={Wang, Lingxiao and Cai, Qi and Yang, Zhuoran and Wang, Zhaoran},
  publisher={arXiv preprint arXiv:1909.01150},
  year={2020}
}

@inproceedings{dym21,
  title={Provable Model-based Nonlinear Bandit and Reinforcement Learning: Shelve Optimism, Embrace Virtual Curvature},
  author={Dong, Kefan and Yang, Jiaqi and Ma, Tengyu},
  publisher={arXiv preprint arXiv:2102.04168},
  year={2021}
}

@inproceedings{acd12,
  title={On the Fundamental Limits of Adaptive Sensing},
  author={Arias-Castro, Ery and Cand{\`e}s, Emmanuel J. and Davenport, Mark A.},
  publisher={arXiv preprint arXiv:1111.4646},
  year={2012}
}

@inproceedings{chw21,
  title={Adversarial Combinatorial Bandits with General Non-linear Reward Functions},
  author={Chen, Xi and Han, Yanjun and Wang, Yining},
  publisher={arXiv preprint arXiv:2101.01301},
  year={2021}
}


@inproceedings{bjw19,
  title={Learning two layer rectified neural networks in polynomial time},
  author={Bakshi, Ainesh and Jayaram, Rajesh and Woodruff, David P},
  publisher={PMLR},
  booktitle={Conference on Learning Theory},
  pages={195–268},
  year={2019}
}

@inproceedings{lan19,
  title={First-order and Stochastic Optimization Methods for Machine Learning},
  author={Guanghui Lan},
  publisher={Springer},
  booktitle={Springer Series in the Data Sciences},
  pages={305-328},
  year={2019}
}

@inproceedings{ahr08,
  title={Competing in the Dark: An Efficient Algorithm for Bandit Linear Optimization},
  author={Jacob Abernethy and Elad Hazan and Alexander Rakhlin},
  publisher={COLT},
  booktitle={Conference on Learning Theory},
  pages={263-273},
  year={2008}
}

@inproceedings{hl14,
  title={Bandit Convex Optimization: Towards Tight Bounds},
  author={Elad Hazan and Kfir Y. Levy},
  booktitle={MIPS},
  year={2014}
}

@inproceedings{adx11,
  title={Optimal Algorithms for Online Convex Optimization with Multi-Point Bandit Feedback},
  author={Alekh Agarwal and Ofer Dekel and Lin Xiao},
  publisher={PMLR},
  booktitle={Proceedings of the 23rd Annual Conference on Learning},
  pages={2840},
  year={2011}
}

@inproceedings{fkm05,
  title={Online convex optimization in the bandit setting: gradient descent without a gradient},
  author={Abraham D. Flaxman and Adam Tauman Kalai and H. Brendan McMahan},
  booktitle={Proceedings of the 16th annualACM-SIAM symposium on Discrete Algorithms},
  pages={385–394},
  year={2005}
}

@inproceedings{jlgj18,
  title={On the Local Minima of the Empirical Risk},
  author={Chi Jin and Lydia T. Liu and Rong Ge and Michael I. Jordan},
  booktitle={32nd Conference on Neural Information Processing Systems (NIPS 2018)},
  year={2018}
}

@inproceedings{afh+13,
  title={Stochastic convex optimization with bandit feedback},
  author={Alekh Agarwal and Dean P. Foster and Daniel Hsu and Sham M. Kakade and Alexander Rakhlin},
  booktitle={SIAM Journal on Optimization},
  pages={213–240},
  year={2013}
}

@inproceedings{ns17,
  title={Random Gradient-Free Minimization of Convex Functions},
  author={Yurii Nesterov and Vladimir Spokoiny},
  booktitle={Found Comput Math (2017)},
  pages={17:527–566},
  year={2017}
}
@inproceedings{lg21,
  title={Improved Regret for Zeroth-Order Stochastic Convex Bandits},
  author={Tor Lattimore and Andr\'{a}s Gy\"{o}rgy},
  booktitle={Proceedings of Machine Learning Research},
  pages={134:1–27},
  year={2021}
}
@inproceedings{hl16,
  title={An optimal regret algorithm for bandit convex optimization},
  author={Elad Hazan and Yuanzhi Li},
  booktitle={arXiv preprint arXiv:1603.04350},
  year={2016}
}
@inproceedings{st11,
  title={Improved regret guarantees for online smooth convex optimization with bandit feedback},
  author={Ankan Saha and Ambuj Tewari},
  booktitle={Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year={2011}
}


%% applications

@article{salimans2017evolution,
	title={Evolution strategies as a scalable alternative to reinforcement learning},
	author={Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
	journal={arXiv preprint arXiv:1703.03864},
	year={2017}
}

@inproceedings{papernot2017practical,
	title={Practical black-box attacks against machine learning},
	author={Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram},
	booktitle={Proceedings of the 2017 ACM on Asia conference on computer and communications security},
	pages={506--519},
	year={2017}
}


@article{snoek2012practical,
	title={Practical bayesian optimization of machine learning algorithms},
	author={Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
	journal={Advances in neural information processing systems},
	volume={25},
	year={2012}
}

@book{lattimore2020bandit,
	title={Bandit algorithms},
	author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
	year={2020},
	publisher={Cambridge University Press}
}

@inproceedings{drucker1991double,
	title={Double backpropagation increasing generalization performance},
	author={Drucker, Harris and Le Cun, Yann},
	booktitle={IJCNN-91-Seattle International Joint Conference on Neural Networks},
	volume={2},
	pages={145--150},
	year={1991},
	organization={IEEE}
}

@book{spall2005introduction,
	title={Introduction to stochastic search and optimization: estimation, simulation, and control},
	author={Spall, James C},
	volume={65},
	year={2005},
	publisher={John Wiley \& Sons}
}

@inproceedings{malik2019derivative,
	title={Derivative-free methods for policy optimization: Guarantees for linear quadratic systems},
	author={Malik, Dhruv and Pananjady, Ashwin and Bhatia, Kush and Khamaru, Koulik and Bartlett, Peter and Wainwright, Martin},
	booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
	pages={2916--2925},
	year={2019},
	organization={PMLR}
}

@article{balasubramanian2018zeroth,
  title={Zeroth-order (non)-convex stochastic optimization via conditional gradient and gradient updates},
  author={Balasubramanian, Krishnakumar and Ghadimi, Saeed},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{arjevani2020second,
  title={Second-order information in non-convex stochastic optimization: Power and limitations},
  author={Arjevani, Yossi and Carmon, Yair and Duchi, John C and Foster, Dylan J and Sekhari, Ayush and Sridharan, Karthik},
  booktitle={Conference on Learning Theory},
  pages={242--299},
  year={2020},
  organization={PMLR}
}


@article{zhao2021optimal,
  title={Optimal Stochastic Nonconvex Optimization with Bandit Feedback},
  author={Zhao, Puning and Lai, Lifeng},
  journal={arXiv preprint arXiv:2103.16082},
  year={2021}
}

@inproceedings{zhang2015online,
  title={Online bandit learning for a special class of non-convex losses},
  author={Zhang, Lijun and Yang, Tianbao and Jin, Rong and Zhou, Zhi-Hua},
  booktitle={Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015}
}


@article{arjevani2019lower,
  title={Lower bounds for non-convex stochastic optimization},
  author={Arjevani, Yossi and Carmon, Yair and Duchi, John C and Foster, Dylan J and Srebro, Nathan and Woodworth, Blake},
  journal={arXiv preprint arXiv:1912.02365},
  year={2019}
}


@article{liu2018stochastic,
  title={Stochastic zeroth-order optimization via variance reduction method},
  author={Liu, Liu and Cheng, Minhao and Hsieh, Cho-Jui and Tao, Dacheng},
  journal={arXiv preprint arXiv:1805.11811},
  year={2018}
}


@article{hazan2014bandit,
  title={Bandit convex optimization: Towards tight bounds},
  author={Hazan, Elad and Levy, Kfir},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  year={2014}
}
@inproceedings{bubeck2017kernel,
  title={Kernel-based methods for bandit convex optimization},
  author={Bubeck, S{\'e}bastien and Lee, Yin Tat and Eldan, Ronen},
  booktitle={Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing},
  pages={72--85},
  year={2017}
}

@article{duchi2015optimal,
  title={Optimal rates for zero-order convex optimization: The power of two function evaluations},
  author={Duchi, John C and Jordan, Michael I and Wainwright, Martin J and Wibisono, Andre},
  journal={IEEE Transactions on Information Theory},
  volume={61},
  number={5},
  pages={2788--2806},
  year={2015},
  publisher={IEEE}
}

@inproceedings{ji2019improved,
  title={Improved zeroth-order variance reduced algorithms and analysis for nonconvex optimization},
  author={Ji, Kaiyi and Wang, Zhe and Zhou, Yi and Liang, Yingbin},
  booktitle={International conference on machine learning},
  pages={3100--3109},
  year={2019},
  organization={PMLR}
}
@article{liu2018zeroth,
  title={Zeroth-order stochastic variance reduction for nonconvex optimization},
  author={Liu, Sijia and Kailkhura, Bhavya and Chen, Pin-Yu and Ting, Paishun and Chang, Shiyu and Amini, Lisa},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}


@article{larson2019derivative,
  title={Derivative-free optimization methods},
  author={Larson, Jeffrey and Menickelly, Matt and Wild, Stefan M},
  journal={Acta Numerica},
  volume={28},
  pages={287--404},
  year={2019},
  publisher={Cambridge University Press}
}


@inproceedings{wang2018stochastic,
	title={Stochastic zeroth-order optimization in high dimensions},
	author={Wang, Yining and Du, Simon and Balakrishnan, Sivaraman and Singh, Aarti},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	pages={1356--1365},
	year={2018},
	organization={PMLR}
}

@inproceedings{shamir2013complexity,
	title={On the complexity of bandit and derivative-free stochastic convex optimization},
	author={Shamir, Ohad},
	booktitle={Conference on Learning Theory},
	pages={3--24},
	year={2013},
	organization={PMLR}
}

@inproceedings{schulman2015trust,
	title={Trust region policy optimization},
	author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
	booktitle={International conference on machine learning},
	pages={1889--1897},
	year={2015},
	organization={PMLR}
}

@article{rajeswaran2017towards,
	title={Towards generalization and simplicity in continuous control},
	author={Rajeswaran, Aravind and Lowrey, Kendall and Todorov, Emanuel and Kakade, Sham},
	journal={arXiv preprint arXiv:1703.02660},
	year={2017}
}

@article{agarwal2021theory,
	title={On the theory of policy gradient methods: Optimality, approximation, and distribution shift},
	author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
	journal={Journal of Machine Learning Research},
	volume={22},
	number={98},
	pages={1--76},
	year={2021}
}


@inproceedings{yang2020impact,
  title={Impact of Representation Learning in Linear Bandits},
  author={Yang, Jiaqi and Hu, Wei and Lee, Jason D and Du, Simon Shaolei},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{huang2021optimal,
  title={Optimal Gradient-based Algorithms for Non-concave Bandit Optimization},
  author={Huang, Baihe and Huang, Kaixuan and Kakade, Sham M and Lee, Jason D and Lei, Qi and Wang, Runzhe and Yang, Jiaqi},
  journal={arXiv preprint arXiv:2107.04518},
  year={2021}
}
@inproceedings{balcan2016improved,
  title={An improved gap-dependency analysis of the noisy power method},
  author={Balcan, Maria-Florina and Du, Simon Shaolei and Wang, Yining and Yu, Adams Wei},
  booktitle={Conference on Learning Theory},
  pages={284--309},
  year={2016},
  organization={PMLR}
}
@article{hardt2014noisy,
  title={The noisy power method: A meta algorithm with applications},
  author={Hardt, Moritz and Price, Eric},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  pages={2861--2869},
  year={2014}
}
@article{tropp2015introduction,
	title={An Introduction to Matrix Concentration Inequalities},
	author={Tropp, Joel A and others},
	journal={Foundations and Trends{\textregistered} in Machine Learning},
	volume={8},
	number={1-2},
	pages={1--230},
	year={2015},
	publisher={Now Publishers, Inc.}
}
@inproceedings{hu2021near,
	title={Near-optimal representation learning for linear bandits and linear rl},
	author={Hu, Jiachen and Chen, Xiaoyu and Jin, Chi and Li, Lihong and Wang, Liwei},
	booktitle={International Conference on Machine Learning},
	pages={4349--4358},
	year={2021},
	organization={PMLR}
}
@article{rusmevichientong2010linearly,
	title={Linearly parameterized bandits},
	author={Rusmevichientong, Paat and Tsitsiklis, John N},
	journal={Mathematics of Operations Research},
	volume={35},
	number={2},
	pages={395--411},
	year={2010},
	publisher={INFORMS}
}
@article{nesterov2017random,
	title={Random gradient-free minimization of convex functions},
	author={Nesterov, Yurii and Spokoiny, Vladimir},
	journal={Foundations of Computational Mathematics},
	volume={17},
	number={2},
	pages={527--566},
	year={2017},
	publisher={Springer}
}

@article{fang2018spider,
  title={Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator},
  author={Fang, Cong and Li, Chris Junchi and Lin, Zhouchen and Zhang, Tong},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}




@article{cutkosky2019momentum,
  title={Momentum-based variance reduction in non-convex sgd},
  author={Cutkosky, Ashok and Orabona, Francesco},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}


@article{wang2019spiderboost,
  title={Spiderboost and momentum: Faster variance reduction algorithms},
  author={Wang, Zhe and Ji, Kaiyi and Zhou, Yi and Liang, Yingbin and Tarokh, Vahid},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}
@article{zhou2018stochastic,
  title={Stochastic nested variance reduction for nonconvex optimization},
  author={Zhou, Dongruo and Xu, Pan and Gu, Quanquan},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}
@article{balasubramanian2022zeroth,
  title={Zeroth-order nonconvex stochastic optimization: Handling constraints, high dimensionality, and saddle points},
  author={Balasubramanian, Krishnakumar and Ghadimi, Saeed},
  journal={Foundations of Computational Mathematics},
  volume={22},
  number={1},
  pages={35--76},
  year={2022},
  publisher={Springer}
}


@article{agarwal2011stochastic,
	title={Stochastic convex optimization with bandit feedback},
	author={Agarwal, Alekh and Foster, Dean P and Hsu, Daniel J and Kakade, Sham M and Rakhlin, Alexander},
	journal={Advances in Neural Information Processing Systems},
	volume={24},
	pages={1035--1043},
	year={2011}
}

@inproceedings{kotlowski2019bandit,
	title={Bandit principal component analysis},
	author={Kot{\l}owski, Wojciech and Neu, Gergely},
	booktitle={Conference On Learning Theory},
	pages={1994--2024},
	year={2019},
	organization={PMLR}
}


@inproceedings{balcan2016improved,
	title={An improved gap-dependency analysis of the noisy power method},
	author={Balcan, Maria-Florina and Du, Simon Shaolei and Wang, Yining and Yu, Adams Wei},
	booktitle={Conference on Learning Theory},
	pages={284--309},
	year={2016},
	organization={PMLR}
}

@inproceedings{garber2015online,
	title={Online learning of eigenvectors},
	author={Garber, Dan and Hazan, Elad and Ma, Tengyu},
	booktitle={International Conference on Machine Learning},
	pages={560--568},
	year={2015},
	organization={PMLR}
}
@article{hazan2016optimal,
	title={An optimal algorithm for bandit convex optimization},
	author={Hazan, Elad and Li, Yuanzhi},
	journal={arXiv preprint arXiv:1603.04350},
	year={2016}
}



@misc{lattimore2020improved,
	title={Improved Regret for Zeroth-Order Adversarial Bandit Convex Optimisation}, 
	author={Tor Lattimore},
	year={2020},
	eprint={2006.00475},
	archivePrefix={arXiv},
	primaryClass={math.OC}
}



@article{flaxman2004online,
	title={Online convex optimization in the bandit setting: gradient descent without a gradient},
	author={Flaxman, Abraham D and Kalai, Adam Tauman and McMahan, H Brendan},
	journal={arXiv preprint cs/0408007},
	year={2004}
}

@article{kleinberg2004nearly,
	title={Nearly tight bounds for the continuum-armed bandit problem},
	author={Kleinberg, Robert},
	journal={Advances in Neural Information Processing Systems},
	volume={17},
	pages={697--704},
	year={2004}
}


@misc{riquelme2018deep,
	title={Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling}, 
	author={Carlos Riquelme and George Tucker and Jasper Snoek},
	year={2018},
	eprint={1802.09127},
	archivePrefix={arXiv},
	primaryClass={stat.ML}
}

@article{valko2013finite,
	title={Finite-time analysis of kernelised contextual bandits},
	author={Valko, Michal and Korda, Nathaniel and Munos, R{\'e}mi and Flaounas, Ilias and Cristianini, Nelo},
	journal={arXiv preprint arXiv:1309.6869},
	year={2013}
}


@article{dani2008stochastic,
	title={Stochastic linear optimization under bandit feedback},
	author={Dani, Varsha and Hayes, Thomas P and Kakade, Sham M},
	journal={The 21st Annual Conference on Learning Theory},
	year={2008}
}

@article{auer2002using,
	title={Using confidence bounds for exploitation-exploration trade-offs},
	author={Auer, Peter},
	journal={Journal of Machine Learning Research},
	volume={3},
	number={Nov},
	pages={397--422},
	year={2002}
}

@article{jin2021bellman,
	title={Bellman Eluder Dimension: New Rich Classes of RL Problems, and Sample-Efficient Algorithms},
	author={Jin, Chi and Liu, Qinghua and Miryoosefi, Sobhan},
	journal={arXiv preprint arXiv:2102.00815},
	year={2021}
}

@article{xu2020neural,
  title={Neural Contextual Bandits with Deep Representation and Shallow Exploration},
  author={Xu, Pan and Wen, Zheng and Zhao, Handong and Gu, Quanquan},
  journal={arXiv preprint arXiv:2012.01780},
  year={2020}
}

@inproceedings{jacot2018neural,
  title={Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
  author={Jacot, Arthur and Hongler, Cl{\'e}ment and Gabriel, Franck},
  booktitle={NeurIPS},
  year={2018}
}

@inproceedings{zhou2020neural,
  title={Neural contextual bandits with UCB-based exploration},
  author={Zhou, Dongruo and Li, Lihong and Gu, Quanquan},
  booktitle={International Conference on Machine Learning},
  pages={11492--11502},
  year={2020},
  organization={PMLR}
}

@inproceedings{henderson2018deep,
	title={Deep reinforcement learning that matters},
	author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={32},
	number={1},
	year={2018}
}


@article{mnih2013playing,
	title={Playing atari with deep reinforcement learning},
	author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	journal={arXiv preprint arXiv:1312.5602},
	year={2013}
}

@article{lillicrap2015continuous,
	title={Continuous control with deep reinforcement learning},
	author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	journal={arXiv preprint arXiv:1509.02971},
	year={2015}
}


@article{lecun2015deep,
	title={Deep learning},
	author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	journal={nature},
	volume={521},
	number={7553},
	pages={436--444},
	year={2015},
	publisher={Nature Publishing Group}
}


@book{goodfellow2016deep,
	title={Deep learning},
	author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
	volume={1},
	number={2},
	year={2016},
	publisher={MIT press Cambridge}
}

@inproceedings{li2010contextual,
	title={A contextual-bandit approach to personalized news article recommendation},
	author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
	booktitle={Proceedings of the 19th international conference on World wide web},
	pages={661--670},
	year={2010}
}


@article{wang2019optimism,
	title={Optimism in reinforcement learning with generalized linear function approximation},
	author={Wang, Yining and Wang, Ruosong and Du, Simon S and Krishnamurthy, Akshay},
	journal={arXiv preprint arXiv:1912.04136},
	year={2019}
}

@article{mannor2004sample,
	title={The sample complexity of exploration in the multi-armed bandit problem},
	author={Mannor, Shie and Tsitsiklis, John N},
	journal={Journal of Machine Learning Research},
	volume={5},
	number={Jun},
	pages={623--648},
	year={2004}
}

@inproceedings{carpentier2012bandit,
	title={Bandit theory meets compressed sensing for high dimensional stochastic linear bandit},
	author={Carpentier, Alexandra and Munos, R{\'e}mi},
	booktitle={Artificial Intelligence and Statistics},
	pages={190--198},
	year={2012},
	organization={PMLR}
}


@inproceedings{bubeck2009pure,
	title={Pure exploration in multi-armed bandits problems},
	author={Bubeck, S{\'e}bastien and Munos, R{\'e}mi and Stoltz, Gilles},
	booktitle={International conference on Algorithmic learning theory},
	pages={23--37},
	year={2009},
	organization={Springer}
}


@inproceedings{even2002pac,
	title={PAC bounds for multi-armed bandit and Markov decision processes},
	author={Even-Dar, Eyal and Mannor, Shie and Mansour, Yishay},
	booktitle={International Conference on Computational Learning Theory},
	pages={255--270},
	year={2002},
	organization={Springer}
}


@article{xu2018minimal,
  title={The minimal measurement number for low-rank matrix recovery},
  author={Xu, Zhiqiang},
  journal={Applied and Computational Harmonic Analysis},
  volume={44},
  number={2},
  pages={497--508},
  year={2018},
  publisher={Elsevier}
}
@article{wang2019generalized,
  title={Generalized phase retrieval: measurement number, matrix recovery and beyond},
  author={Wang, Yang and Xu, Zhiqiang},
  journal={Applied and Computational Harmonic Analysis},
  volume={47},
  number={2},
  pages={423--446},
  year={2019},
  publisher={Elsevier}
}
@misc{milneAG,
author={Milne, James S.},
title={Algebraic Geometry (v6.02)},
year={2017},
note={Available at www.jmilne.org/math/},
pages={221}
}
@book{shafarevich2013basic,
  title={Basic Algebraic Geometry 1: Varieties in Projective Space},
  author={Shafarevich, Igor R},
  year={2013},
  publisher={Springer Science \& Business Media}
}
@inproceedings{chen2020learning,
  title={Learning Polynomials in Few Relevant Dimensions},
  author={Chen, Sitan and Meka, Raghu},
  booktitle={Conference on Learning Theory},
  pages={1161--1227},
  year={2020},
  organization={PMLR}
}


@inproceedings{lu2021low,
	title={Low-rank generalized linear bandit problems},
	author={Lu, Yangyi and Meisami, Amirhossein and Tewari, Ambuj},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	pages={460--468},
	year={2021},
	organization={PMLR}
}

@article{hardt2014noisy,
	title={The noisy power method: A meta algorithm with applications},
	author={Hardt, Moritz and Price, Eric},
	journal={Advances in neural information processing systems},
	volume={27},
	pages={2861--2869},
	year={2014}
}

@article{wang2016online,
	title={Online and differentially-private tensor decomposition},
	author={Wang, Yining and Anandkumar, Animashree},
	journal={arXiv preprint arXiv:1606.06237},
	year={2016}
}

@inproceedings{jun2019bilinear,
	title={Bilinear bandits with low-rank structure},
	author={Jun, Kwang-Sung and Willett, Rebecca and Wright, Stephen and Nowak, Robert},
	booktitle={International Conference on Machine Learning},
	pages={3163--3172},
	year={2019},
	organization={PMLR}
}

@article{tropp2012user,
	title={User-friendly tail bounds for sums of random matrices},
	author={Tropp, Joel A},
	journal={Foundations of computational mathematics},
	volume={12},
	number={4},
	pages={389--434},
	year={2012},
	publisher={Springer}
}

@article{du2020few,
	title={Few-shot learning via learning the representation, provably},
	author={Du, Simon S and Hu, Wei and Kakade, Sham M and Lee, Jason D and Lei, Qi},
	journal={arXiv preprint arXiv:2002.09434},
	year={2020}
}

@article{candes2015phase,
	title={Phase retrieval via Wirtinger flow: Theory and algorithms},
	author={Candes, Emmanuel J and Li, Xiaodong and Soltanolkotabi, Mahdi},
	journal={IEEE Transactions on Information Theory},
	volume={61},
	number={4},
	pages={1985--2007},
	year={2015},
	publisher={IEEE}
}

@article{hao2020high,
	title={High-Dimensional Sparse Linear Bandits},
	author={Hao, Botao and Lattimore, Tor and Wang, Mengdi},
	journal={arXiv preprint arXiv:2011.04020},
	year={2020}
}

@inproceedings{hao2021online,
	title={Online Sparse Reinforcement Learning},
	author={Hao, Botao and Lattimore, Tor and Szepesv{\'a}ri, Csaba and Wang, Mengdi},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	pages={316--324},
	year={2021},
	organization={PMLR}
}

@article{arias2012fundamental,
	title={On the fundamental limits of adaptive sensing},
	author={Arias-Castro, Ery and Candes, Emmanuel J and Davenport, Mark A},
	journal={IEEE Transactions on Information Theory},
	volume={59},
	number={1},
	pages={472--481},
	year={2012},
	publisher={IEEE}
}

@article{musco2015randomized,
	title={Randomized block krylov methods for stronger and faster approximate singular value decomposition},
	author={Musco, Cameron and Musco, Christopher},
	journal={arXiv preprint arXiv:1504.05477},
	year={2015}
}

@inproceedings{allen2017first,
	title={First efficient convergence for streaming k-pca: a global, gap-free, and near-optimal rate},
	author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
	booktitle={2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS)},
	pages={487--492},
	year={2017},
	organization={IEEE}
}

@inproceedings{carpentier2015simple,
	title={Simple regret for infinitely many armed bandits},
	author={Carpentier, Alexandra and Valko, Michal},
	booktitle={International Conference on Machine Learning},
	pages={1133--1141},
	year={2015},
	organization={PMLR}
}

@article{anandkumar2014tensor,
	title={Tensor decompositions for learning latent variable models},
	author={Anandkumar, Animashree and Ge, Rong and Hsu, Daniel and Kakade, Sham M and Telgarsky, Matus},
	journal={Journal of machine learning research},
	volume={15},
	pages={2773--2832},
	year={2014},
	publisher={Journal of Machine Learning Research}
}

@article{sanjabi2019does,
	title={When does non-orthogonal tensor decomposition have no spurious local minima?},
	author={Sanjabi, Maziar and Baharlouei, Sina and Razaviyayn, Meisam and Lee, Jason D},
	journal={arXiv preprint arXiv:1911.09815},
	year={2019}
}

@article{cai2016optimal,
	title={Optimal rates of convergence for noisy sparse phase retrieval via thresholded Wirtinger flow},
	author={Cai, T Tony and Li, Xiaodong and Ma, Zongming and others},
	journal={The Annals of Statistics},
	volume={44},
	number={5},
	pages={2221--2251},
	year={2016},
	publisher={Institute of Mathematical Statistics}
}

@article{wang2019generalized,
	title={Generalized phase retrieval: measurement number, matrix recovery and beyond},
	author={Wang, Yang and Xu, Zhiqiang},
	journal={Applied and Computational Harmonic Analysis},
	volume={47},
	number={2},
	pages={423--446},
	year={2019},
	publisher={Elsevier}
}

@inproceedings{price2013lower,
	title={Lower bounds for adaptive sparse recovery},
	author={Price, Eric and Woodruff, David P},
	booktitle={Proceedings of the Twenty-Fourth Annual ACM-SIAM Symposium on Discrete Algorithms},
	pages={652--663},
	year={2013},
	organization={SIAM}
}
@article{lecue2013minimax,
	title={Minimax rate of convergence and the performance of ERM in phase recovery},
	author={Lecu{\'e}, Guillaume and Mendelson, Shahar},
	journal={arXiv preprint arXiv:1311.5024},
	year={2013}
}



@inproceedings{audibert2009minimax,
  title={Minimax Policies for Adversarial and Stochastic Bandits.},
  author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien and others},
  booktitle={COLT},
  volume={7},
  pages={1--122},
  year={2009}
}


@inproceedings{chu2011contextual,
  title={Contextual bandits with linear payoff functions},
  author={Chu, Wei and Li, Lihong and Reyzin, Lev and Schapire, Robert},
  booktitle={Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages={208--214},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}



@inproceedings{abbasi2011improved,
	title={Improved Algorithms for Linear Stochastic Bandits.},
	author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
	booktitle={NIPS},
	volume={11},
	pages={2312--2320},
	year={2011}
}

@article{johnson2016structured,
	title={Structured stochastic linear bandits},
	author={Johnson, Nicholas and Sivakumar, Vidyashankar and Banerjee, Arindam},
	journal={arXiv preprint arXiv:1606.05693},
	year={2016}
}


@article{gopalan2016low,
	title={Low-rank bandits with latent mixtures},
	author={Gopalan, Aditya and Maillard, Odalric-Ambrym and Zaki, Mohammadi},
	journal={arXiv preprint arXiv:1609.01508},
	year={2016}
}


@article{lale2019stochastic,
	title={Stochastic linear bandits with hidden low rank structure},
	author={Lale, Sahin and Azizzadenesheli, Kamyar and Anandkumar, Anima and Hassibi, Babak},
	journal={arXiv preprint arXiv:1901.09490},
	year={2019}
}

@inproceedings{lu2021low,
	title={Low-rank generalized linear bandit problems},
	author={Lu, Yangyi and Meisami, Amirhossein and Tewari, Ambuj},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	pages={460--468},
	year={2021},
	organization={PMLR}
}

@inproceedings{jun2019bilinear,
	title={Bilinear bandits with low-rank structure},
	author={Jun, Kwang-Sung and Willett, Rebecca and Wright, Stephen and Nowak, Robert},
	booktitle={International Conference on Machine Learning},
	pages={3163--3172},
	year={2019},
	organization={PMLR}
}

@inproceedings{garber2015online,
	title={Online learning of eigenvectors},
	author={Garber, Dan and Hazan, Elad and Ma, Tengyu},
	booktitle={International Conference on Machine Learning},
	pages={560--568},
	year={2015},
	organization={PMLR}
}

@inproceedings{katariya2017stochastic,
	title={Stochastic rank-1 bandits},
	author={Katariya, Sumeet and Kveton, Branislav and Szepesvari, Csaba and Vernade, Claire and Wen, Zheng},
	booktitle={Artificial Intelligence and Statistics},
	pages={392--401},
	year={2017},
	organization={PMLR}
}

@article{johnson2016structured,
	title={Structured stochastic linear bandits},
	author={Johnson, Nicholas and Sivakumar, Vidyashankar and Banerjee, Arindam},
	journal={arXiv preprint arXiv:1606.05693},
	year={2016}
}

@article{gopalan2016low,
	title={Low-rank bandits with latent mixtures},
	author={Gopalan, Aditya and Maillard, Odalric-Ambrym and Zaki, Mohammadi},
	journal={arXiv preprint arXiv:1609.01508},
	year={2016}
}

@article{lale2019stochastic,
	title={Stochastic linear bandits with hidden low rank structure},
	author={Lale, Sahin and Azizzadenesheli, Kamyar and Anandkumar, Anima and Hassibi, Babak},
	journal={arXiv preprint arXiv:1901.09490},
	year={2019}
}

@article{hao2020low,
	title={Low-rank Tensor Bandits},
	author={Hao, Botao and Zhou, Jie and Wen, Zheng and Sun, Will Wei},
	journal={arXiv preprint arXiv:2007.15788},
	year={2020}
}

@article{zhou2013tensor,
	title={Tensor regression with applications in neuroimaging data analysis},
	author={Zhou, Hua and Li, Lexin and Zhu, Hongtu},
	journal={Journal of the American Statistical Association},
	volume={108},
	number={502},
	pages={540--552},
	year={2013},
	publisher={Taylor \& Francis}
}

@inproceedings{abbasi2012online,
	title={Online-to-confidence-set conversions and application to sparse stochastic bandits},
	author={Abbasi-Yadkori, Yasin and Pal, David and Szepesvari, Csaba},
	booktitle={Artificial Intelligence and Statistics},
	pages={1--9},
	year={2012},
	organization={PMLR}
}


@article{wang2020reinforcement,
	title={Reinforcement learning with general value function approximation: Provably efficient approach via bounded eluder dimension},
	author={Wang, Ruosong and Salakhutdinov, Russ R and Yang, Lin},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	pages={6123--6135},
	year={2020}
}
@article{guhaniyogi2017bayesian,
	title={Bayesian tensor regression},
	author={Guhaniyogi, Rajarshi and Qamar, Shaan and Dunson, David B},
	journal={The Journal of Machine Learning Research},
	volume={18},
	number={1},
	pages={2733--2763},
	year={2017},
	publisher={JMLR. org}
}

@article{li2018tucker,
	title={Tucker tensor regression and neuroimaging analysis},
	author={Li, Xiaoshan and Xu, Da and Zhou, Hua and Li, Lexin},
	journal={Statistics in Biosciences},
	volume={10},
	number={3},
	pages={520--545},
	year={2018},
	publisher={Springer}
}

@inproceedings{filippi2010parametric,
	title={Parametric Bandits: The Generalized Linear Case.},
	author={Filippi, Sarah and Cappe, Olivier and Garivier, Aur{\'e}lien and Szepesv{\'a}ri, Csaba},
	booktitle={NIPS},
	volume={23},
	pages={586--594},
	year={2010}
}


@book{bochnak2013real,
  title={Real algebraic geometry},
  author={Bochnak, Jacek and Coste, Michel and Roy, Marie-Fran{\c{c}}oise},
  volume={36},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{kileel2019expressive,
  title={On the expressive power of deep polynomial neural networks},
  author={Kileel, Joe and Trager, Matthew and Bruna, Joan},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


@article{lee2008existence,
  title={{Existence of Asymptotic Solutions to Semi-linear Partial Difference Equations}},
  author={{Jason D. Lee} and Neuberger, John},
  journal={Joint Mathematics Meetings},
  pages={},
  year={2008}
}

@article{lee2010practical,
  title={{Practical Large-Scale Optimization for Max-Norm Regularization}},
  author={{Jason D. Lee} and Recht, Ben and Srebro, Nathan and Tropp, Joel and Salakhutdinov, Ruslan},
  journal={Neural Information Processing Systems (NIPS)},
  pages={1297--1305},
  year={2010}
}

@article{little2009estimation,
  title={{Estimation of Intrinsic Dimensionality of Samples from Noisy Low-Dimensional Manifolds in High Dimensions with Multiscale SVD}},
  author={Little, Anna V. and {Jason D. Lee} and Jung, Yoon-Mo and Maggioni, Mauro},
  journal={IEEE Workshop on Statistical Signal Processing (SSP)},
  pages={85--88},
  year={2009}  
}

@article{kliegl2010generalized,
  title={{Generalized DCell Structure for Load-Balanced Data Center Networks}},
  author={Kliegl, Markus and {Jason D. Lee} and Li, Jun and Zhang, Xinchao and Guo, Chuanxiong and Rinc{\'o}n, David},
  journal={IEEE Conference on Computer Communications (INFOCOM)},
  pages={1--5},
  year={2010}
}

@article{kliegl2010generalizedtech,
  title={Generalized DCell Structure for Load-Balanced Data Center Networks},
  author={Kliegl, Markus and {Jason D. Lee} and Li, Jun and Zhang, Xinchao and Guo, Chuanxiong and Rinc{\'o}n, David},
  journal={Microsoft Research Technical Report},
  pages={1--14},
  year={2009},
  url={http://research.microsoft.com/apps/pubs/default.aspx?id=103129}
}

@article{lee2011multiscale,
  title={{Multiscale Analysis of Time Series of Graphs}},
  author={{Jason D. Lee} and Maggioni, Mauro},
  journal={International Conference on Sampling Theory and Applications (SAMPTA)},
  year={2011}
}

@article{lee2010multiscale,
  title={{Multiscale Estimation of Intrinsic Dimensionality of Point Cloud Data and Multiscale Analysis of Dynamic Graphs}},
  author={{Jason D. Lee}},
  journal={Senior Thesis, Duke University},
  year={2010}
}

@article{leemulticlass,
  title={{Multiclass Clustering using a Semidefinite Relaxation}},
  author={{Jason D. Lee}},
  journal={Tech Report},
}

@article{lee2012proximal,
  title={{Proximal Newton-type Methods for Convex Optimization}},
  author={{Jason D. Lee} and Sun, Yuekai and Saunders, Michael},
  journal={Neural Information Processing Systems (NIPS)},
  pages={836--844},
  year={2012}
}

@article{lee2012convergence,
  title={{Convergence Analysis of Inexact Proximal Newton-Type Methods}},
  author={{Jason D. Lee} and Sun, Yuekai and Saunders, Michael A},
  journal={NIPS Workshop on Optimization in Machine Learning},
  pages={},
  year={2012}
}


@article{monajemi2013deterministic,
  title={{Deterministic Matrices Matching the Compressed Sensing Phase Transitions of Gaussian Random Matrices}},
  author={Monajemi, Hatef and Jafarpour, Sina and Gavish, Matan and {
Stat 330/CME 362 Collaboration} and Donoho, David L},
  journal={Proceedings of the National Academy of Sciences},
  volume={110},
  number={4},
  pages={1181--1186},
  year={2013},
  publisher={National Acad Sciences}
}

@article{lee2014proximal,
author = {{Jason D. Lee} and Sun, Yuekai and Saunders, Michael},
title = {{Proximal Newton-Type Methods for Minimizing Composite Functions}},
journal = {SIAM Journal on Optimization},
year = {2014}
}

@article{lee2013model,
  title={{On Model Selection Consistency of Penalized M-Estimators: a Geometric Theory}},
  author={{Jason D. Lee} and Sun, Yuekai and Taylor, Jonathan E. },
  journal={Neural Information Processing Systems (NIPS)},
  pages={342--350},
  year={2013}
}

@article{lee2015modelJournal,
  title={{On Model Selection Consistency of Regularized M-Estimators}},
  author={{Jason D. Lee} and Sun, Yuekai and Taylor, Jonathan E. },
  journal={Electronic Journal of Statistics},
  year={2015}
}


@article{lee2016exact,
  title={{Exact Inference after Model Selection via the Lasso}},
  author={{Jason D. Lee} and Sun, Dennis L. and Sun, Yuekai and Taylor, Jonathan E.  },
  journal={Annals of Statistics},
  year={2016}
}

@article{lee2013using,
  title={{Using Multiple Samples to Learn Mixture Models}},
  author={{Jason D. Lee} and Gilad-Bachrach, Ran and Caruana, Rich},
  journal={Neural Information Processing Systems (NIPS)},
  pages={324--332},
  year={2013}
}

@article{lee2014learning,
  title={{Learning the Structure of Mixed Graphical Models}},
  author={{Jason D. Lee} and Hastie, Trevor J},
  journal={Journal of Computational and Graphical Statistics},
  number={},
  pages={},
  year={2014},
  publisher={Taylor \& Francis}
}

@article{lee2013structure,
  title={{Structure Learning of Mixed Graphical Models}},
  author={{Jason D. Lee} and Hastie, Trevor},
  journal={Artificial Intelligence and Statistics (AISTATS)},
  pages={388--396},
  year={2013}
}

@article{lee2014exact,
  title={{Exact Post Model Selection Inference for Marginal Screening}},
  author={{Jason D. Lee} and Taylor, Jonathan E. },
  journal={Neural Information Processing Systems (NIPS)},
  pages={1--9},
  year={2014}
}

@article{benson2014scalable,
  title={{Scalable Methods for Nonnegative Matrix Factorizations of Near-Separable Tall-and-Skinny Matrices}},
  author={Benson, Austin R and {Jason D. Lee} and Rajwa, Bartek and Gleich, David F.},
  journal={Neural Information Processing Systems (NIPS)},
  pages={1--9},
  year={2014}
}

@article{lee2015significance,
  title={{Evaluating the Statistical Significance of Biclusters}},
  author={{Jason D. Lee} and Sun, Yuekai and Taylor, Jonathan E. },
  journal={Neural Information Processing Systems (NIPS)},
  pages={1--9},
  year={2015}
}

@article{lee2017one,
  title={{Communication-Efficient Distributed Sparse Regression}},
  author={{Jason D. Lee} and Liu, Qiang and Sun, Yuekai and Taylor, Jonathan E. },
  journal={Journal of Machine Learning Research},
  year={2017}
}

@article{hastie2015fast,
  title={{Matrix Completion and Low-Rank SVD via Fast Alternating Least Squares}},
  author={Hastie, Trevor and Mazumder, Rahul and {Jason D. Lee} and Zadeh, Reza},
  journal={Journal of Machine Learning Research},
  year={2015}
}

@article{lee2016gradient,
  title={Gradient Descent Converges to Minimizers},
  author={{Jason D. Lee} and Simchowitz, Max and Jordan, Michael I and Recht, Benjamin},
  journal={Conference on Learning Theory (COLT)},
  year={2016}
}

@article{zhang2016l1,
  title={l1-regularized Neural Networks are Improperly Learnable in Polynomial Time},
  author={Zhang, Yuchen and {Jason D. Lee} and Jordan, Michael I},
  journal={International Conference on Machine Learning (ICML)},
  year={2016}
}

@article{zhang2017learning,
  title={Learning Halfspaces and Neural Networks with Random Initialization},
  author={Zhang, Yuchen and {Jason D. Lee} and Wainwright, Martin J and Jordan, Michael I},
  journal={Artificial Intelligence and Statistics (AISTATS)},
  year={2017}
}

@article{liu2016kernelized,
  title={A Kernelized Stein Discrepancy for Goodness-of-fit Tests and Model Evaluation},
  author={Liu, Qiang and {Jason D. Lee} and Jordan, Michael I},
  journal={International Conference on Machine Learning (ICML)},
  year={2016}
}

@article{lee2017distributed,
  title={Distributed Stochastic Variance Reduced Gradient Methods},
  author={{Jason D. Lee} and Ma, Tengyu and Lin, Qihang and Yang, Tianbao},
  journal={Journal of Machine Learning Research},
  year={2017}
}

@article{ge2016matrix,
  title={Matrix Completion has No Spurious Local Minimum},
  author={Ge, Rong and {Jason D. Lee} and Ma, Tengyu},
  journal={Neural Information Processing Systems (NIPS)},
  year={2016}
}

@article{jordan2018communication,
  title={Communication-efficient distributed statistical learning},
  author={Jordan, Michael I and {Jason D. Lee} and Yang, Yun},
  journal={Journal of the American Statistics Association},
  year={2018}
}

@article{liu2017black,
  title={Black-box importance sampling},
  author={Liu, Qiang and Lee, Jason D},
  journal={Artificial Intelligence and Statistics (AISTATS)},
  year={2017}
}

@article{wang2017sketching,
  title={Sketching Meets Random Projection in the Dual: A Provable Recovery Algorithm for Big and High-dimensional Data},
  author={Wang, Jialei and Lee, Jason D and Mahdavi, Mehrdad and Kolar, Mladen and Srebro, Nathan},
  journal={Electronic Journal of Statistics},
  year={2017}
}

@article{wang2017sketchingAistat,
  title={Sketching Meets Random Projection in the Dual: A Provable Recovery Algorithm for Big and High-dimensional Data},
  author={Wang, Jialei and Lee, Jason D and Mahdavi, Mehrdad and Kolar, Mladen and Srebro, Nathan},
  journal={Artificial Intelligence and Statistics (AISTATS)},
  year={2017}
}


@article{du2017gradient,
  title={Gradient Descent Can Take Exponential Time to Escape Saddle Points},
  author={Du, Simon S and Jin, Chi and Lee, Jason D and Jordan, Michael I and Singh, Aarti and Poczos, Barnabas},
  journal={Neural Information Processing Systems (NIPS)},
  year={2017}
}

@article{du2018cnn,
  title={Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of Spurious Local Minima},
  author={Du, Simon S and Lee, Jason D and Tian, Yuandong and Poczos, Barnabas and Singh, Aarti},
  journal={International Conference on Machine Learning (ICML)},
  year={2018}
}

@article{ge2018learning,
  title={Learning One-hidden-layer Neural Networks with Landscape Design},
  author={Ge, Rong and Lee, Jason D and Ma, Tengyu},
  journal={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@article{lee2018first,
  title={First-order Methods Almost Always Avoid Saddle Points},
  author={Lee, Jason D and Panageas, Ioannis and Piliouras, Georgios and Simchowitz, Max and Jordan, Michael I and Recht, Benjamin},
  journal={Accepted at Math Programming},
  year={2018}
}

@article{du2018convolutional,
  title={When is a Convolutional Filter Easy to Learn?},
  author={Du, Simon S and Lee, Jason D and Tian, Yuandong},
  journal={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@article{soltanolkotabi2018theoretical,
  title={Theoretical insights into the optimization landscape of over-parameterized shallow neural networks},
  author={Soltanolkotabi, Mahdi and Javanmard, Adel and Lee, Jason D},
  journal={Transactions on Information Theory},
  year={2018}
}

@article{javanmard2018flexible,
  title={A Flexible Framework for Hypothesis Testing in High-dimensions},
  author={Javanmard, Adel and Lee, Jason D},
  journal={Accepted Journal of the Royal Statistical Society Series B},
  year={}
}

@article{chen2018statistical,
  title={Statistical inference for model parameters in stochastic gradient descent},
  author={Chen, Xi and Lee, Jason D and Tong, Xin T and Zhang, Yichen and others},
  journal={The Annals of Statistics},
  volume={48},
  number={1},
  pages={251--273},
  year={2020},
  publisher={Institute of Mathematical Statistics}
}
@article{liu2018inexact,
  title={An inexact subsampled proximal Newton-type method for large-scale machine learning},
  author={Liu, Xuanqing and Hsieh, Cho-Jui and Lee, Jason D and Sun, Yuekai},
  journal={Submitted to Journal of Machine Learning Research},
  year={}
}

@article{wu2018NoSpurious,
  title={No Spurious Local Minima in a Two Node Neural Network},
  author={Wu, Chenwei and Luo, Jiajun and Lee, Jason D},
  journal={International Conference on Learning Representations (ICLR) Workshop Track},
  year={2018}
}

@article{gunasekar2018characterizing,
  title={Characterizing Implicit Bias in Terms of Optimization Geometry},
  author={Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
  journal={International Conference on Machine Learning (ICML)},
  year={2018}
}

@article{nacson2018convergence,
  title={Convergence of Gradient Descent on Separable Data},
  author={Nacson, Mor Shpigel and Lee, Jason D. and Gunasekar, Suriya and Srebro, Nathan and Soudry, Daniel},
  journal={Artificial Intelligence and Statistics (AISTATS) },
  year={2019}
}

@article{du2018power, 
  title={On the Power of Over-parametrization in Neural Networks with Quadratic Activation},
  author={Du, Simon S and Lee, Jason D},
  journal={International Conference on Machine Learning (ICML)},
  year={2018}
}

@article{sanjabi2018solving,
  title={Solving Approximate Wasserstein GANs to Stationarity},
  author={Sanjabi, Maziar and Ba, Jimmy and Razaviyayn, Meisam and Lee, Jason D},
  journal={Neural Information Processing Systems (NIPS)},
  year={2018}
}

@article{hong2018gradient,
  title={Gradient Primal-Dual Algorithm Converges to Second-Order Stationary Solutions for Nonconvex Distributed Optimization},
  author={Hong, Mingyi and Lee, Jason D and Razaviyayn, Meisam},
  journal={International Conference on Machine Learning (ICML)},
  year={2018}
}

@article{lee2018stochastic,
  title={Stochastic Subgradient Converges in Polynomial Time on Nonsmooth Functions},
  author={Lee, Jason D },
  journal={Unpublished},
  year={2018}
}

@article{kakade2018provable,
  title={Provably Correct Automatic Subdifferentiation for Qualified Programs},
  author={Kakade, Sham and Lee, Jason D },
  journal={Neural Information Processing Systems (NIPS)},
  year={2018}
}

@article{liang2018adding,
  title={Adding One Neuron Can Eliminate All Bad Local Minima},
  author={Liang, Shiyu and Sun, Ruoyu and Lee, Jason D and Srikant, R},
  journal={Neural Information Processing Systems (NIPS)},
  year={2018}
}

@article{davis2018stochastic,
  title={Stochastic subgradient method converges on tame functions},
  author={Davis, Damek and Drusvyatskiy, Dmitriy and Kakade, Sham and Lee, Jason D},
  journal={Foundations of Computational Mathematics},
  year={2018}
}

@article{gunasekar2018implicit,
  title={Implicit Bias of Gradient Descent on Linear Convolutional Networks},
  author={Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
  journal={Neural Information Processing Systems (NIPS)},
  year={2018}
}

@article{du2018algorithmic,
  title={Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced},
  author={Du, Simon S and Hu, Wei and Lee, Jason D},
  journal={Neural Information Processing Systems (NIPS)},
  year={2018}
}

@article{nouiehed2018convergence,
  title={Convergence to Second-Order Stationarity for Constrained Non-Convex Optimization},
  author={Nouiehed, Maher and Lee, Jason D and Razaviyayn, Meisam},
  journal={Submitted to SIAM Journal on Optimization},
  year={2018}
}


@article{du2018gradient,
  title={Gradient Descent Finds Global Minima of Deep Neural Networks},
  author={Du, Simon S and Lee, Jason D and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
  journal={International Conference on Machine Learning (ICML)},
  year={2019}
}

@article{nacson2019lexicographic,
  title={
Lexicographic and Depth-Sensitive Margins in Homogeneous and Non-Homogeneous Training},
  author={Nacson, Mor Sphigel and Gunasekar, Suriya and Lee, Jason D and Srebro, Nathan and Soudry Daniel},
  journal={International Conference on Machine Learning (ICML)},
  year={2019}
}

@article{li2019incremental,
  title={Incremental (Sub)-Gradient Descent for Weakly Convex Optimization},
  author={Li, Xiao and Zhu, Zhihui and So, Anthony Man-Cho and Lee, Jason D.},
  journal={Submitted to SIOPT},
  year={2019}
}


@article{wei2018margin,
  title={Regularization Matters: Generalization and Optimization of Neural Nets v.s. their Induced Kernel.},
  author={Wei, Colin and Lee, Jason D and Liu, Qiang and Ma, Tengyu},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@article{nouiehed2019solving,
  title={Solving a class of non-convex min-max games using iterative first order methods},
  author={Nouiehed, Maher and Sanjabi, Maziar and Huang, Tianjian and Lee, Jason D and Razaviyayn, Meisam},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@article{cai2019neural,
  title={Neural Temporal-Difference Learning Converges to Global Optima},
  author={Cai, Qi and Yang, Zhuoran and Lee, Jason D and Wang, Zhaoran},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2019}
}


@article{bai2019beyond,
  title={Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks},
  author={Bai, Yu and Lee, Jason D},
  journal={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@article{agarwal2019optimality,
  title={Optimality and Approximation with Policy Gradient Methods in Markov Decision Processes},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Conference on Learning Theory (COLT)},
  year={2020}
}

@article{lei2019sgd,
  title={SGD Learns One-Layer Networks in WGANs},
  author={Lei, Qi and Lee, Jason D and Dimakis, Alexandros G and Daskalakis, Constantinos},
  journal={International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{makkuva2019optimal,
  title={Optimal transport mapping via input convex neural networks},
  author={Makkuva, Ashok Vardhan and Taghvaei, Amirhossein and Oh, Sewoong and Lee, Jason D},
  journal={International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{gao2019convergence,
  title={Convergence of Adversarial Training in Overparametrized Networks},
  author={Gao, Ruiqi and Cai, Tianle and Li, Haochuan and Wang, Liwei and Hsieh, Cho-Jui and Lee, Jason D},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2019}
}


@article{woodworth2019kernel,
  title={Kernel and Deep Regimes in Overparametrized Models},
  author={Woodworth, Blake and Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
  journal={Conference on Learning Theory (COLT)},
  year={2020}
}



@article{haochen2020shape,
  title={Shape Matters: Understanding the Implicit Bias of the Noise Covariance},
  author={HaoChen, Jeff Z. and Wei, Colin and Lee, Jason D. and Ma, Tengyu},
  journal={arXiv preprint arXiv:2006.08680},
  year={2020}
}

@article{du2020few,
  title={Few-shot learning via learning the representation, provably},
  author={Du, Simon S and Hu, Wei and Kakade, Sham M and Lee, Jason D and Lei, Qi},
  journal={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{du2020agnostic,
  title={Agnostic Q-learning with function approximation in deterministic systems: Tight bounds on approximation error and sample complexity},
  author={Du, Simon S and Lee, Jason D and Mahajan, Gaurav and Wang, Ruosong},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{moroshko2020implicit,
  title={Implicit Bias in Deep Linear Classification: Initialization Scale vs Training Accuracy},
  author={Moroshko, Edward and Gunasekar, Suriya and Woodworth, Blake and Lee, Jason D and Srebro, Nathan and Soudry, Daniel},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{chen2020towards,
  title={Towards Understanding Hierarchical Learning: Benefits of Neural Representations},
  author={Chen, Minshuo and Bai, Yu and Lee, Jason D and Zhao, Tuo and Wang, Huan and Xiong, Caiming and Socher, Richard},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{chen2020distributed,
  title={Distributed Estimation for Principal Component Analysis: a Gap-free Approach},
  author={Chen, Xi and Lee, Jason D and Li, He and Yang, Yun},
  journal={Journal of the American Statistical Association},
  year={2021}
}

@article{wu2020steepest,
  title={Steepest Descent Neural Architecture Optimization: Escaping Local Optimum with Signed Neural Splitting},
  author={Wu, Lemeng and Ye, Mao and Lei, Qi and Lee, Jason D and Liu, Qiang},
  journal={arXiv preprint arXiv:2003.10392},
  year={2020}
}

@article{fang2020modeling,
  title={Modeling from Features: a Mean-field Framework for Over-parameterized Deep Neural Networks},
  author={Fang, Cong and Lee, Jason D and Yang, Pengkun and Zhang, Tong},
  journal={arXiv preprint arXiv:2007.01452},
  year={2020}
}

@article{ji2020convergence,
  title={Convergence of Meta-Learning with Task-Specific Adaptation over Partial Parameters},
  author={Ji, Kaiyi and Lee, Jason D and Liang, Yingbin and Poor, H Vincent},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{su2020sanity,
  title={Sanity-Checking Pruning Methods: Random Tickets can Win the Jackpot},
  author={Su, Jingtong and Chen, Yihang and Cai, Tianle and Wu, Tianhao and Gao, Ruiqi and Wang, Liwei and Lee, Jason D},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{lee2020predicting,
  title={Predicting what you already know helps: Provable self-supervised learning},
  author={Lee, Jason D and Lei, Qi and Saunshi, Nikunj and Zhuo, Jiacheng},
  journal={arXiv preprint arXiv:2008.01064},
  year={2020}
}

@article{wang2020beyond,
  title={Beyond Lazy Training for Over-parameterized Tensor Decomposition},
  author={Wang, Xiang and Wu, Chenwei and Lee, Jason D and Ma, Tengyu and Ge, Rong},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{lee2020generalized,
  title={Generalized Leverage Score Sampling for Neural Networks},
  author={Lee, Jason D and Shen, Ruoqi and Song, Zhao and Wang, Mengdi and others},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{gu2020characterize,
  title={How to Characterize The Landscape of Overparameterized Convolutional Neural Networks},
  author={Gu, Yihong and Zhang, Weizhong and Fang, Cong and Lee, Jason D and Zhang, Tong},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{agarwal2020on,
  title={On the Theory of Policy Gradient Methods },
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={JMLR (short version at COLT)},
  year={2020}
}

@article{yang2020provable,
  title={Provable Benefits of Representation Learning in Linear Bandits},
  author={Yang, Jiaqi and Hu, Wei and Lee, Jason D and Du, Simon S},
  journal={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{du2021bilinear,
	title={Bilinear Classes: A Structural Framework for Provable Generalization in RL},
	author={Du, Simon S and Kakade, Sham M and Lee, Jason D and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
	journal={arXiv preprint arXiv:2103.10897},
	year={2021}
}

@article{damian2021label,
  title={Escaping Global Minimizers with Label Noise SGD},
  author={Damian, Alex and Ma, Tengyu and Lee, Jason D.},
  year={2021},
}

%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Zhao, Tuo at 2020-05-30 23:35:13 -0400 


%%

@article{damian2021label,
	title={Label Noise SGD Provably Prefers Flat Global Minimizers},
	author={Damian, Alex and Ma, Tengyu and Lee, Jason},
	journal={arXiv preprint arXiv:2106.06530},
	year={2021}
}

@inproceedings{kalimeris2019sgd,
  title={Sgd on neural networks learns functions of increasing complexity},
  author={Kalimeris, Dimitris and Kaplun, Gal and Nakkiran, Preetum and Edelman, Benjamin and Yang, Tristan and Barak, Boaz and Zhang, Haofeng},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3496--3506},
  year={2019}
}


@article{hu2020surprising,
  title={The Surprising Simplicity of the Early-Time Learning Dynamics of Neural Networks},
  author={Hu, Wei and Xiao, Lechao and Adlam, Ben and Pennington, Jeffrey},
  journal={arXiv preprint arXiv:2006.14599},
  year={2020}
}

@inproceedings{li2020learning,
  title={Learning Over-Parametrized Two-Layer Neural Networks beyond NTK},
  author={Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang R},
  booktitle={Conference on Learning Theory},
  pages={2613--2682},
  year={2020}
}

@inproceedings{diakonikolas2020algorithms,
  title={Algorithms and SQ Lower Bounds for PAC Learning One-Hidden-Layer ReLU Networks},
  author={Diakonikolas, Ilias and Kane, Daniel M and Kontonis, Vasilis and Zarifis, Nikos},
  booktitle={Conference on Learning Theory},
  pages={1514--1539},
  year={2020}
}

@article{goel2020superpolynomial,
  title={Superpolynomial Lower Bounds for Learning One-Layer Neural Networks using Gradient Descent},
  author={Goel, Surbhi and Gollakota, Aravind and Jin, Zhihan and Karmalkar, Sushrut and Klivans, Adam},
  journal={arXiv preprint arXiv:2006.12011},
  year={2020}
}


@inproceedings{mei2018mean,
  title={A mean field view of the landscape of two-layers neural networks},
  author={Mei, Song and Montanari, Andrea and Nguyen, Phan-Minh},
  booktitle={Proceedings of the National Academy of Sciences},
  volume={115},
  pages={E7665--E7671},
  year={2018}
}

@article{sirignano2018mean,
	title={Mean Field Analysis of Neural Networks},
	author={Sirignano, Justin and Spiliopoulos, Konstantinos},
	journal={arXiv preprint arXiv:1805.01053},
	year={2018}
}

@article{rotskoff2018neural,
	title={Neural networks as Interacting Particle Systems: Asymptotic convexity of the Loss Landscape and Universal Scaling of the Approximation Error},
	author={Rotskoff, Grant M and Vanden-Eijnden, Eric},
	journal={arXiv preprint arXiv:1805.00915},
	year={2018}
}



@inproceedings{chizat2018global,
  title={On the global convergence of gradient descent for over-parameterized models using optimal transport},
  author={Chizat, Lenaic and Bach, Francis},
  booktitle={Advances in neural information processing systems},
  pages={3040--3050},
  year={2018}
}

@article{dyer2019asymptotics,
	title={Asymptotics of wide networks from feynman diagrams},
	author={Dyer, Ethan and Gur-Ari, Guy},
	journal={arXiv preprint arXiv:1909.11304},
	year={2019}
}

@article{woodworth2020kernel,
	title={Kernel and rich regimes in overparametrized models},
	author={Woodworth, Blake and Gunasekar, Suriya and Lee, Jason D and Moroshko, Edward and Savarese, Pedro and Golan, Itay and Soudry, Daniel and Srebro, Nathan},
	journal={arXiv preprint arXiv:2002.09277},
	year={2020}
}


@article{allen2020backward,
  title={Backward Feature Correction: How Deep Learning Performs Deep Learning},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={arXiv preprint arXiv:2001.04413},
  year={2020}
}

@inproceedings{andoni2014learning,
  title={Learning polynomials with neural networks},
  author={Andoni, Alexandr and Panigrahy, Rina and Valiant, Gregory and Zhang, Li},
  booktitle={International conference on machine learning},
  pages={1908--1916},
  year={2014}
}

@article{montanari2018spectral,
  title={Spectral algorithms for tensor completion},
  author={Montanari, Andrea and Sun, Nike},
  journal={Communications on Pure and Applied Mathematics},
  volume={71},
  number={11},
  pages={2381--2425},
  year={2018},
  publisher={Wiley Online Library}
}

@inproceedings{li2018learning,
  title={Learning overparameterized neural networks via stochastic gradient descent on structured data},
  author={Li, Yuanzhi and Liang, Yingyu},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8157--8166},
  year={2018}
}

@article{yehudai2019power,
  title={On the power and limitations of random features for understanding neural networks},
  author={Yehudai, Gilad and Shamir, Ohad},
  journal={arXiv preprint arXiv:1904.00687},
  year={2019}
}

@inproceedings{ghorbani2019limitations,
  title={Limitations of Lazy Training of Two-layers Neural Network},
  author={Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9108--9118},
  year={2019}
}

@article{allen2019can,
  title={What Can ResNet Learn Efficiently, Going Beyond Kernels?},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={arXiv preprint arXiv:1905.10337},
  year={2019}
}

@inproceedings{wei2019regularization,
  title={Regularization matters: Generalization and optimization of neural nets vs their induced kernel},
  author={Wei, Colin and Lee, Jason D and Liu, Qiang and Ma, Tengyu},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9709--9721},
  year={2019}
}

@article{zou2018stochastic,
  title={Stochastic gradient descent optimizes over-parameterized deep relu networks},
  author={Zou, Difan and Cao, Yuan and Zhou, Dongruo and Gu, Quanquan},
  journal={arXiv preprint arXiv:1811.08888},
  year={2018}
}

@inproceedings{lee2016gradient,
	title={Gradient descent only converges to minimizers},
	author={Lee, Jason D and Simchowitz, Max and Jordan, Michael I and Recht, Benjamin},
	booktitle={Conference on learning theory},
	pages={1246--1257},
	year={2016}
}

@article{chen2020learning,
  title={Learning Polynomials of Few Relevant Dimensions},
  author={Chen, Sitan and Meka, Raghu},
  journal={arXiv preprint arXiv:2004.13748},
  year={2020}
}

@inproceedings{mu2014square,
  title={Square deal: Lower bounds and improved relaxations for tensor recovery},
  author={Mu, Cun and Huang, Bo and Wright, John and Goldfarb, Donald},
  booktitle={International conference on machine learning},
  pages={73--81},
  year={2014}
}

@inproceedings{morcos2018on,
title={On the importance of single directions for generalization},
author={Ari S. Morcos and David G.T. Barrett and Neil C. Rabinowitz and Matthew Botvinick},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=r1iuQjxCZ},
}

@article{huang2019dynamics,
  title={Dynamics of deep neural networks and neural tangent hierarchy},
  author={Huang, Jiaoyang and Yau, Horng-Tzer},
  journal={arXiv preprint arXiv:1909.08156},
  year={2019}
}

@article{bai2020taylorized,
  title={Taylorized Training: Towards Better Approximation of Neural Network Training at Finite Width},
  author={Bai, Yu and Krause, Ben and Wang, Huan and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:2002.04010},
  year={2020}
}

@article{chizat2018note,
	Author = {Chizat, Lenaic and Bach, Francis},
	Date-Added = {2020-06-01 13:19:34 -0400},
	Date-Modified = {2020-06-01 13:19:34 -0400},
	Journal = {arXiv preprint arXiv:1812.07956},
	Title = {A note on lazy training in supervised differentiable programming},
	Volume = {8},
	Year = {2018}}

@inproceedings{arora2019exact,
	Author = {Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {8139--8148},
	Title = {On exact computation with an infinitely wide neural net},
	Year = {2019}}

@inproceedings{chizat2019lazy,
	Author = {Chizat, Lenaic and Oyallon, Edouard and Bach, Francis},
	Booktitle = {Advances in Neural Information Processing Systems},
	Pages = {2933--2943},
	Title = {On lazy training in differentiable programming},
	Year = {2019}}

@inproceedings{du2019gradient,
	Author = {Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
	Booktitle = {International Conference on Machine Learning},
	Pages = {1675--1685},
	Title = {Gradient Descent Finds Global Minima of Deep Neural Networks},
	Year = {2019}}

@inproceedings{jacot2018neural,
	Author = {Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
	Booktitle = {Advances in neural information processing systems},
	Pages = {8571--8580},
	Title = {Neural tangent kernel: Convergence and generalization in neural networks},
	Year = {2018}}

@inproceedings{lee2019wide,
	Author = {Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
	Booktitle = {Advances in neural information processing systems},
	Pages = {8570--8581},
	Title = {Wide neural networks of any depth evolve as linear models under gradient descent},
	Year = {2019}}

@article{telgarsky2016benefits,
	Author = {Telgarsky, Matus},
	Date-Added = {2020-05-30 23:35:11 -0400},
	Date-Modified = {2020-05-30 23:35:11 -0400},
	Journal = {arXiv preprint arXiv:1602.04485},
	Title = {Benefits of depth in neural networks},
	Year = {2016}}

@inproceedings{arora2019exact,
	Author = {Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
	Booktitle = {Advances in Neural Information Processing Systems},
	Date-Added = {2020-05-30 23:34:29 -0400},
	Date-Modified = {2020-05-30 23:34:29 -0400},
	Pages = {8139--8148},
	Title = {On exact computation with an infinitely wide neural net},
	Year = {2019}}

@inproceedings{jacot2018neural,
	Author = {Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
	Booktitle = {Advances in neural information processing systems},
	Date-Added = {2020-05-30 23:33:51 -0400},
	Date-Modified = {2020-05-30 23:33:51 -0400},
	Pages = {8571--8580},
	Title = {Neural tangent kernel: Convergence and generalization in neural networks},
	Year = {2018}}

@article{chen2020nonparametric,
	Author = {Chen, Minshuo and Jiang, Haoming and Liao, Wenjing and Zhao, Tuo},
	Date-Added = {2020-05-30 23:30:13 -0400},
	Date-Modified = {2020-05-30 23:30:44 -0400},
	Journal = {arXiv preprint arXiv},
	Title = {Nonparametric Regression on Low-Dimensional Manifolds using Deep ReLU Networks},
	Year = {2020}}

@inproceedings{chen2019efficient,
	Author = {Chen, Minshuo and Jiang, Haoming and Liao, Wenjing and Zhao, Tuo},
	Booktitle = {Advances in Neural Information Processing Systems},
	Date-Added = {2020-05-30 23:29:59 -0400},
	Date-Modified = {2020-05-30 23:29:59 -0400},
	Pages = {8172--8182},
	Title = {Efficient approximation of deep relu networks for functions on low dimensional manifolds},
	Year = {2019}}

@article{yarotsky2017error,
	Author = {Yarotsky, Dmitry},
	Date-Added = {2020-05-30 23:29:32 -0400},
	Date-Modified = {2020-05-30 23:29:32 -0400},
	Journal = {Neural Networks},
	Pages = {103--114},
	Publisher = {Elsevier},
	Title = {Error bounds for approximations with deep ReLU networks},
	Volume = {94},
	Year = {2017}}

@article{allen2018convergence,
	Author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
	Date-Added = {2020-05-30 23:26:56 -0400},
	Date-Modified = {2020-05-30 23:26:56 -0400},
	Journal = {arXiv preprint arXiv:1811.03962},
	Title = {A convergence theory for deep learning via over-parameterization},
	Year = {2018}}

@article{arora2019fine,
	Author = {Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
	Date-Added = {2020-05-30 23:26:39 -0400},
	Date-Modified = {2020-05-30 23:26:39 -0400},
	Journal = {arXiv preprint arXiv:1901.08584},
	Title = {Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
	Year = {2019}}

@article{du2018gradient,
	Author = {Du, Simon S and Lee, Jason D and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
	Date-Added = {2020-05-30 23:25:27 -0400},
	Date-Modified = {2020-05-30 23:27:59 -0400},
	Journal = {arXiv preprint arXiv:1811.03804},
	Title = {Gradient descent finds global minima of deep neural networks},
	Year = {2018}}

@article{du2018gradient2,
	Author = {Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
	Date-Added = {2020-05-30 23:25:10 -0400},
	Date-Modified = {2020-05-30 23:28:03 -0400},
	Journal = {arXiv preprint arXiv:1810.02054},
	Title = {Gradient descent provably optimizes over-parameterized neural networks},
	Year = {2018}}

@article{huang2020deep,
	Author = {Huang, Kaixuan and Wang, Yuqing and Tao, Molei and Zhao, Tuo},
	Date-Added = {2020-05-30 23:22:00 -0400},
	Date-Modified = {2020-05-30 23:22:00 -0400},
	Journal = {arXiv preprint arXiv:2002.06262},
	Title = {Why Do Deep Residual Networks Generalize Better than Deep Feedforward Networks?--A Neural Tangent Kernel Perspective},
	Year = {2020}}

@article{devlin2018bert,
	Author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	Date-Added = {2020-05-30 22:53:25 -0400},
	Date-Modified = {2020-05-30 22:53:25 -0400},
	Journal = {arXiv preprint arXiv:1810.04805},
	Title = {Bert: Pre-training of deep bidirectional transformers for language understanding},
	Year = {2018}}

@inproceedings{girshick2014rich,
	Author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	Booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	Date-Added = {2020-05-30 22:43:31 -0400},
	Date-Modified = {2020-05-30 22:43:31 -0400},
	Pages = {580--587},
	Title = {Rich feature hierarchies for accurate object detection and semantic segmentation},
	Year = {2014}}

@inproceedings{mahajan2018exploring,
	Author = {Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and van der Maaten, Laurens},
	Booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
	Date-Added = {2020-05-30 22:41:53 -0400},
	Date-Modified = {2020-05-30 22:41:53 -0400},
	Pages = {181--196},
	Title = {Exploring the limits of weakly supervised pretraining},
	Year = {2018}}

@inproceedings{allen2019learning,
	Author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Liang, Yingyu},
	Booktitle = {Advances in neural information processing systems},
	Pages = {6155--6166},
	Title = {Learning and generalization in overparameterized neural networks, going beyond two layers},
	Year = {2019}}

@article{ghorbani2019linearized,
	Author = {Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
	Journal = {arXiv preprint arXiv:1904.12191},
	Title = {Linearized two-layers neural networks in high dimension},
	Year = {2019}}

@inproceedings{he2016deep,
	Author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	Booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	Pages = {770--778},
	Title = {Deep residual learning for image recognition},
	Year = {2016}}

@article{lecun2015deep,
	Author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	Journal = {nature},
	Number = {7553},
	Pages = {436--444},
	Publisher = {Nature Publishing Group},
	Title = {Deep learning},
	Volume = {521},
	Year = {2015}}

@article{vershynin2010introduction,
	Author = {Vershynin, Roman},
	Journal = {arXiv preprint arXiv:1011.3027},
	Title = {Introduction to the non-asymptotic analysis of random matrices},
	Year = {2010}}

@article{jin2019stochastic,
   title={Stochastic gradient descent escapes saddle points efficiently},
   author={Jin, Chi and Netrapalli, Praneeth and Ge, Rong and Kakade, Sham M and Jordan, Michael I},
   journal={arXiv preprint arXiv:1902.04811},
   year={2019}}

@inproceedings{bai2019beyond,
  title={Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks},
  author={Yu Bai and Jason D. Lee},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://openreview.net/forum?id=rkllGyBFPH}
}

@article{moulines2011non,
  title={Non-asymptotic analysis of stochastic approximation algorithms for machine learning},
  author={Moulines, Eric and Bach, Francis},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@article{ghorbani2019linearized,
  title={Linearized two-layers neural networks in high dimension},
  author={Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
  journal={arXiv preprint arXiv:1904.12191},
  year={2019}}

@article{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  journal={arXiv preprint arXiv:1901.08584},
  year={2019}}

@article{cao2019generalization,
  title={Generalization error bounds of gradient descent for learning overparameterized deep relu networks},
  author={Cao, Yuan and Gu, Quanquan},
  journal={arXiv preprint arXiv:1902.01384},
  year={2019}}

@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}}

@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}}

@article{hornik1991approximation,
  title={Approximation capabilities of multilayer feedforward networks},
  author={Hornik, Kurt},
  journal={Neural networks},
  volume={4},
  number={2},
  pages={251--257},
  year={1991},
  publisher={Elsevier}}