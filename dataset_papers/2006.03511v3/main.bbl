\begin{thebibliography}{49}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aggarwal et~al.(2015)Aggarwal, Salameh, and Hindle]{aggarwal2015using}
Karan Aggarwal, Mohammad Salameh, and Abram Hindle.
\newblock Using machine translation for converting python 2 to python 3 code.
\newblock Technical report, PeerJ PrePrints, 2015.

\bibitem[Allamanis et~al.(2014)Allamanis, Barr, Bird, and
  Sutton]{allamanis2014learning}
Miltiadis Allamanis, Earl~T Barr, Christian Bird, and Charles Sutton.
\newblock Learning natural coding conventions.
\newblock In \emph{Proceedings of the 22nd ACM SIGSOFT International Symposium
  on Foundations of Software Engineering}, pages 281--293, 2014.

\bibitem[Alon et~al.(2019{\natexlab{a}})Alon, Brody, Levy, and
  Yahav]{alon2018code2seq}
Uri Alon, Shaked Brody, Omer Levy, and Eran Yahav.
\newblock code2seq: Generating sequences from structured representations of
  code.
\newblock \emph{ICLR}, 2019{\natexlab{a}}.

\bibitem[Alon et~al.(2019{\natexlab{b}})Alon, Sadaka, Levy, and
  Yahav]{alon2019structural}
Uri Alon, Roy Sadaka, Omer Levy, and Eran Yahav.
\newblock Structural language models for any-code generation.
\newblock \emph{arXiv preprint arXiv:1910.00577}, 2019{\natexlab{b}}.

\bibitem[Amodio et~al.(2017)Amodio, Chaudhuri, and Reps]{amodio2017neural}
Matthew Amodio, Swarat Chaudhuri, and Thomas Reps.
\newblock Neural attribute machines for program generation.
\newblock \emph{arXiv preprint arXiv:1705.09231}, 2017.

\bibitem[Artetxe et~al.(2017)Artetxe, Labaka, and Agirre]{artetxe2017learning}
Mikel Artetxe, Gorka Labaka, and Eneko Agirre.
\newblock Learning bilingual word embeddings with (almost) no bilingual data.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, volume~1, pages
  451--462, 2017.

\bibitem[Artetxe et~al.(2018{\natexlab{a}})Artetxe, Labaka, and
  Agirre]{artetxe2018unsupervised}
Mikel Artetxe, Gorka Labaka, and Eneko Agirre.
\newblock Unsupervised statistical machine translation.
\newblock \emph{arXiv preprint arXiv:1809.01272}, 2018{\natexlab{a}}.

\bibitem[Artetxe et~al.(2018{\natexlab{b}})Artetxe, Labaka, Agirre, and
  Cho]{unsupNMTartetxe}
Mikel Artetxe, Gorka Labaka, Eneko Agirre, and Kyunghyun Cho.
\newblock Unsupervised neural machine translation.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018{\natexlab{b}}.

\bibitem[Bahdanau et~al.(2014)Bahdanau, Cho, and Bengio]{bahdanau2014neural}
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock \emph{arXiv preprint arXiv:1409.0473}, 2014.

\bibitem[Barone and Sennrich(2017)]{barone2017parallel}
Antonio Valerio~Miceli Barone and Rico Sennrich.
\newblock A parallel corpus of python functions and documentation strings for
  automated code documentation and code generation.
\newblock \emph{arXiv preprint arXiv:1707.02275}, 2017.

\bibitem[Bhoopchand et~al.(2016)Bhoopchand, Rockt{\"a}schel, Barr, and
  Riedel]{bhoopchand2016learning}
Avishkar Bhoopchand, Tim Rockt{\"a}schel, Earl Barr, and Sebastian Riedel.
\newblock Learning python code suggestion with a sparse pointer network.
\newblock \emph{arXiv preprint arXiv:1611.08307}, 2016.

\bibitem[Chen et~al.(2018)Chen, Liu, and Song]{chen2018tree}
Xinyun Chen, Chang Liu, and Dawn Song.
\newblock Tree-to-tree neural networks for program translation.
\newblock In \emph{Advances in neural information processing systems}, pages
  2547--2557, 2018.

\bibitem[Chen et~al.(2019)Chen, Kommrusch, Tufano, Pouchet, Poshyvanyk, and
  Monperrus]{chen2019sequencer}
Zimin Chen, Steve~James Kommrusch, Michele Tufano, Louis-No{\"e}l Pouchet,
  Denys Poshyvanyk, and Martin Monperrus.
\newblock Sequencer: Sequence-to-sequence learning for end-to-end program
  repair.
\newblock \emph{IEEE Transactions on Software Engineering}, 2019.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{CoRR}, abs/1810.04805, 2018.

\bibitem[Feng et~al.(2020)Feng, Guo, Tang, Duan, Feng, Gong, Shou, Qin, Liu,
  Jiang, et~al.]{feng2020codebert}
Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun
  Shou, Bing Qin, Ting Liu, Daxin Jiang, et~al.
\newblock Codebert: A pre-trained model for programming and natural languages.
\newblock \emph{arXiv preprint arXiv:2002.08155}, 2020.

\bibitem[Fu et~al.(2019)Fu, Chen, Liu, Chen, Tian, Koushanfar, and
  Zhao]{fu2019coda}
Cheng Fu, Huili Chen, Haolan Liu, Xinyun Chen, Yuandong Tian, Farinaz
  Koushanfar, and Jishen Zhao.
\newblock Coda: An end-to-end neural program decompiler.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3703--3714, 2019.

\bibitem[Gulcehre et~al.(2015)Gulcehre, Firat, Xu, Cho, Barrault, Lin,
  Bougares, Schwenk, and Bengio]{gulcehre2015using}
Caglar Gulcehre, Orhan Firat, Kelvin Xu, Kyunghyun Cho, Loic Barrault, Huei-Chi
  Lin, Fethi Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock On using monolingual corpora in neural machine translation.
\newblock \emph{arXiv preprint arXiv:1503.03535}, 2015.

\bibitem[Gupta et~al.(2017)Gupta, Pal, Kanade, and Shevade]{gupta2017deepfix}
Rahul Gupta, Soham Pal, Aditya Kanade, and Shirish Shevade.
\newblock Deepfix: Fixing common c language errors by deep learning.
\newblock In \emph{Thirty-First AAAI Conference on Artificial Intelligence},
  2017.

\bibitem[Guzm{\'a}n et~al.(2019)Guzm{\'a}n, Chen, Ott, Pino, Lample, Koehn,
  Chaudhary, and Ranzato]{guzman2019two}
Francisco Guzm{\'a}n, Peng-Jen Chen, Myle Ott, Juan Pino, Guillaume Lample,
  Philipp Koehn, Vishrav Chaudhary, and Marc'Aurelio Ranzato.
\newblock Two new evaluation datasets for low-resource machine translation:
  Nepali-english and sinhala-english.
\newblock \emph{arXiv preprint arXiv:1902.01382}, 2019.

\bibitem[He et~al.(2016)He, Xia, Qin, Wang, Yu, Liu, and Ma]{he2016dual}
Di~He, Yingce Xia, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, and Wei-Ying
  Ma.
\newblock Dual learning for machine translation.
\newblock In \emph{Advances in neural information processing systems}, pages
  820--828, 2016.

\bibitem[Hu et~al.(2018)Hu, Li, Xia, Lo, and Jin]{hu2018deep}
Xing Hu, Ge~Li, Xin Xia, David Lo, and Zhi Jin.
\newblock Deep code comment generation.
\newblock In \emph{Proceedings of the 26th Conference on Program
  Comprehension}, pages 200--210, 2018.

\bibitem[Karaivanov et~al.(2014)Karaivanov, Raychev, and
  Vechev]{karaivanov2014phrase}
Svetoslav Karaivanov, Veselin Raychev, and Martin Vechev.
\newblock Phrase-based statistical translation of programming languages.
\newblock In \emph{Proceedings of the 2014 ACM International Symposium on New
  Ideas, New Paradigms, and Reflections on Programming \& Software}, pages
  173--184, 2014.

\bibitem[Katz et~al.(2018)Katz, Ruchti, and Schulte]{katz2018using}
Deborah~S Katz, Jason Ruchti, and Eric Schulte.
\newblock Using recurrent neural networks for decompilation.
\newblock In \emph{2018 IEEE 25th International Conference on Software
  Analysis, Evolution and Reengineering (SANER)}, pages 346--356. IEEE, 2018.

\bibitem[Katz et~al.(2019)Katz, Olshaker, Goldberg, and Yahav]{katz2019towards}
Omer Katz, Yuval Olshaker, Yoav Goldberg, and Eran Yahav.
\newblock Towards neural decompilation.
\newblock \emph{arXiv preprint arXiv:1905.08325}, 2019.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Koehn(2004)]{koehn2004pharaoh}
Philipp Koehn.
\newblock Pharaoh: a beam search decoder for phrase-based statistical machine
  translation models.
\newblock In \emph{Conference of the Association for Machine Translation in the
  Americas}, pages 115--124. Springer, 2004.

\bibitem[Koehn et~al.(2007)Koehn, Hoang, Birch, Callison-Burch, Federico,
  Bertoldi, Cowan, Shen, Moran, Zens, Chris~Dyer, Constantin, and
  Herbst]{moses}
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello
  Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard
  Zens, Ondrej~Bojar Chris~Dyer, Alexandra Constantin, and Evan Herbst.
\newblock Moses: Open source toolkit for statistical machine translation.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics (ACL), demo session}, 2007.

\bibitem[Kudo and Richardson(2018)]{kudo2018sentencepiece}
Taku Kudo and John Richardson.
\newblock Sentencepiece: A simple and language independent subword tokenizer
  and detokenizer for neural text processing.
\newblock \emph{arXiv preprint arXiv:1808.06226}, 2018.

\bibitem[Lample and Conneau(2019)]{lample2019cross}
Guillaume Lample and Alexis Conneau.
\newblock Cross-lingual language model pretraining.
\newblock \emph{arXiv preprint arXiv:1901.07291}, 2019.

\bibitem[Lample et~al.(2018{\natexlab{a}})Lample, Conneau, Denoyer, and
  Ranzato]{lample2018unsupervised}
Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc'Aurelio Ranzato.
\newblock Unsupervised machine translation using monolingual corpora only.
\newblock \emph{ICLR}, 2018{\natexlab{a}}.

\bibitem[Lample et~al.(2018{\natexlab{b}})Lample, Conneau, Ranzato, Denoyer,
  and J{\'e}gou]{lample2018word}
Guillaume Lample, Alexis Conneau, Marc'Aurelio Ranzato, Ludovic Denoyer, and
  Herv{\'e} J{\'e}gou.
\newblock Word translation without parallel data.
\newblock In \emph{ICLR}, 2018{\natexlab{b}}.

\bibitem[Lample et~al.(2018{\natexlab{c}})Lample, Ott, Conneau, Denoyer, and
  Ranzato]{lample2018phrase}
Guillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer, and Marc'Aurelio
  Ranzato.
\newblock Phrase-based \& neural unsupervised machine translation.
\newblock In \emph{EMNLP}, 2018{\natexlab{c}}.

\bibitem[Lewis et~al.(2019)Lewis, Liu, Goyal, Ghazvininejad, Mohamed, Levy,
  Stoyanov, and Zettlemoyer]{lewis2019bart}
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
  Omer Levy, Ves Stoyanov, and Luke Zettlemoyer.
\newblock Bart: Denoising sequence-to-sequence pre-training for natural
  language generation, translation, and comprehension.
\newblock \emph{arXiv preprint arXiv:1910.13461}, 2019.

\bibitem[Li et~al.(2018)Li, Wang, Lyu, and King]{li2017code}
Jian Li, Yue Wang, Michael~R Lyu, and Irwin King.
\newblock Code completion with neural attention and pointer networks.
\newblock \emph{IJCAI}, 2018.

\bibitem[Maaten and Hinton(2008)]{maaten2008visualizing}
Laurens van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock \emph{Journal of machine learning research}, 9\penalty0
  (Nov):\penalty0 2579--2605, 2008.

\bibitem[Nguyen et~al.(2013)Nguyen, Nguyen, and Nguyen]{nguyen2013lexical}
Anh~Tuan Nguyen, Tung~Thanh Nguyen, and Tien~N Nguyen.
\newblock Lexical statistical machine translation for language migration.
\newblock In \emph{Proceedings of the 2013 9th Joint Meeting on Foundations of
  Software Engineering}, pages 651--654, 2013.

\bibitem[Oda et~al.(2015)Oda, Fudaba, Neubig, Hata, Sakti, Toda, and
  Nakamura]{oda2015learning}
Yusuke Oda, Hiroyuki Fudaba, Graham Neubig, Hideaki Hata, Sakriani Sakti,
  Tomoki Toda, and Satoshi Nakamura.
\newblock Learning to generate pseudo-code from source code using statistical
  machine translation (t).
\newblock In \emph{2015 30th IEEE/ACM International Conference on Automated
  Software Engineering (ASE)}, pages 574--584. IEEE, 2015.

\bibitem[Papineni et~al.(2002)Papineni, Roukos, Ward, and Zhu]{bleu}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock In \emph{Proceedings of the 40th annual meeting on association for
  computational linguistics}, pages 311--318. Association for Computational
  Linguistics, 2002.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in pytorch.
\newblock \emph{NIPS 2017 Autodiff Workshop}, 2017.

\bibitem[Rabinovich et~al.(2017)Rabinovich, Stern, and
  Klein]{rabinovich2017abstract}
Maxim Rabinovich, Mitchell Stern, and Dan Klein.
\newblock Abstract syntax networks for code generation and semantic parsing.
\newblock \emph{arXiv preprint arXiv:1704.07535}, 2017.

\bibitem[Sennrich et~al.(2015{\natexlab{a}})Sennrich, Haddow, and
  Birch]{sennrich2015improving}
Rico Sennrich, Barry Haddow, and Alexandra Birch.
\newblock Improving neural machine translation models with monolingual data.
\newblock In \emph{Proceedings of the 54th Annual Meeting of the Association
  for Computational Linguistics}, pages 86--96, 2015{\natexlab{a}}.

\bibitem[Sennrich et~al.(2015{\natexlab{b}})Sennrich, Haddow, and
  Birch]{sennrich2015neural}
Rico Sennrich, Barry Haddow, and Alexandra Birch.
\newblock Neural machine translation of rare words with subword units.
\newblock In \emph{Proceedings of the 54th Annual Meeting of the Association
  for Computational Linguistics}, pages 1715--1725, 2015{\natexlab{b}}.

\bibitem[Song et~al.(2019)Song, Tan, Qin, Lu, and Liu]{song2019mass}
Kaitao Song, Xu~Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu.
\newblock Mass: Masked sequence to sequence pre-training for language
  generation.
\newblock In \emph{International Conference on Machine Learning}, pages
  5926--5936, 2019.

\bibitem[Sutskever et~al.(2014)Sutskever, Vinyals, and
  Le]{sutskever2014sequence}
Ilya Sutskever, Oriol Vinyals, and Quoc~V Le.
\newblock Sequence to sequence learning with neural networks.
\newblock In \emph{Advances in neural information processing systems}, pages
  3104--3112, 2014.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Advances in neural information processing systems}, pages
  5998--6008, 2017.

\bibitem[Vincent et~al.(2008)Vincent, Larochelle, Bengio, and
  Manzagol]{vincent2008extracting}
Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol.
\newblock Extracting and composing robust features with denoising autoencoders.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, pages 1096--1103, 2008.

\bibitem[Wang et~al.(2017)Wang, Singh, and Su]{wang2017dynamic}
Ke~Wang, Rishabh Singh, and Zhendong Su.
\newblock Dynamic neural program embedding for program repair.
\newblock \emph{arXiv preprint arXiv:1711.07163}, 2017.

\bibitem[Yin and Neubig(2017)]{yin2017syntactic}
Pengcheng Yin and Graham Neubig.
\newblock A syntactic neural model for general-purpose code generation.
\newblock \emph{arXiv preprint arXiv:1704.01696}, 2017.

\bibitem[Zheng et~al.(2017)Zheng, Cheng, and Liu]{zheng2017maximum}
Hao Zheng, Yong Cheng, and Yang Liu.
\newblock Maximum expected likelihood estimation for zero-resource neural
  machine translation.
\newblock In \emph{IJCAI}, 2017.

\end{thebibliography}
