\begin{thebibliography}{}

\bibitem[{\'A}lvarez et~al., 2012]{alvarez2012kernels}
{\'A}lvarez, M.~A., Rosasco, L., Lawrence, N.~D., et~al. (2012).
\newblock Kernels for vector-valued functions: A review.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  4(3):195--266.

\bibitem[Andrade-Pacheco et~al., 2020]{andrade2020finding}
Andrade-Pacheco, R., Rerolle, F., Lemoine, J., Hernandez, L., Me{\"\i}t{\'e},
  A., Juziwelo, L., Bibaut, A.~F., van~der Laan, M.~J., Arnold, B.~F., and
  Sturrock, H.~J. (2020).
\newblock Finding hotspots: development of an adaptive spatial sampling
  approach.
\newblock {\em Scientific reports}, 10(1):1--12.

\bibitem[Astudillo and Frazier, 2019]{astudillo_bayesian_2019}
Astudillo, R. and Frazier, P. (2019).
\newblock Bayesian {Optimization} of {Composite} {Functions}.
\newblock In {\em International {Conference} on {Machine} {Learning}}, pages
  354--363. PMLR.
\newblock ISSN: 2640-3498.

\bibitem[Balandat et~al., 2020]{balandat_botorch_2020}
Balandat, M., Karrer, B., Jiang, D., Daulton, S., Letham, B., Wilson, A.~G.,
  and Bakshy, E. (2020).
\newblock {BoTorch}: {A} {Framework} for {Efficient} {Monte}-{Carlo} {Bayesian}
  {Optimization}.
\newblock In {\em Advances in {Neural} {Information} {Processing} {Systems}},
  volume~33.

\bibitem[Bliznyuk et~al., 2008]{bliznyuk2008bayesian}
Bliznyuk, N., Ruppert, D., Shoemaker, C., Regis, R., Wild, S., and Mugunthan,
  P. (2008).
\newblock Bayesian calibration and uncertainty analysis for computationally
  expensive models using optimization and radial basis function approximation.
\newblock {\em Journal of Computational and Graphical Statistics},
  17(2):270--294.

\bibitem[Bonilla et~al., 2007]{bonilla_multi-task_2007}
Bonilla, E.~V., Chai, K., and Williams, C. (2007).
\newblock Multi-task {Gaussian} {Process} {Prediction}.
\newblock In {\em Advances in {Neural} {Information} {Processing} {Systems}},
  volume~20, pages 153--160.

\bibitem[Boustati et~al., 2019]{boustati2019non}
Boustati, A., Damoulas, T., and Savage, R.~S. (2019).
\newblock Non-linear multitask learning with deep gaussian processes.
\newblock {\em arXiv preprint arXiv:1905.12407}.

\bibitem[Brockman et~al., 2016]{openaigym}
Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang,
  J., and Zaremba, W. (2016).
\newblock Openai gym.

\bibitem[Bruinsma et~al., 2020]{bruinsma2020scalable}
Bruinsma, W., Perim, E., Tebbutt, W., Hosking, S., Solin, A., and Turner, R.
  (2020).
\newblock Scalable exact inference in multi-output gaussian processes.
\newblock In {\em International Conference on Machine Learning}, pages
  1190--1201. PMLR.

\bibitem[Cakmak et~al., 2020]{cakmak2020risk}
Cakmak, S., Astudillo~Marban, R., Frazier, P., and Zhou, E. (2020).
\newblock Bayesian optimization of risk measures.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~33, pages 20130--20141. Curran Associates, Inc.

\bibitem[Char et~al., 2019]{char2019offline}
Char, I., Chung, Y., Neiswanger, W., Kandasamy, K., Nelson, A.~O., Boyer, M.,
  Kolemen, E., and Schneider, J. (2019).
\newblock Offline contextual bayesian optimization.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~32, pages 4627--4638.

\bibitem[Chevalier et~al., 2015]{chevalier2015fast}
Chevalier, C., Emery, X., and Ginsbourger, D. (2015).
\newblock Fast update of conditional simulation ensembles.
\newblock {\em Mathematical Geosciences}, 47(7):771--789.

\bibitem[Chiles and Delfiner, 2009]{chiles2009geostatistics}
Chiles, J.-P. and Delfiner, P. (2009).
\newblock {\em Geostatistics: modeling spatial uncertainty}, volume 497.
\newblock John Wiley \& Sons.

\bibitem[Chil{\`e}s and Lantu{\'e}joul, 2005]{chiles2005prediction}
Chil{\`e}s, J.-P. and Lantu{\'e}joul, C. (2005).
\newblock Prediction by conditional simulation: models and algorithms.
\newblock In {\em Space, Structure and Randomness}, pages 39--68. Springer.

\bibitem[Chowdhury and Gopalan, 2021]{chowdhury2021no}
Chowdhury, S.~R. and Gopalan, A. (2021).
\newblock No-regret algorithms for multi-task bayesian optimization.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1873--1881. PMLR.

\bibitem[Dai et~al., 2017]{dai2017efficient}
Dai, Z., {\'A}lvarez, M.~A., and Lawrence, N.~D. (2017).
\newblock Efficient modeling of latent information in supervised learning using
  gaussian processes.
\newblock In {\em Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pages 5137--5145.

\bibitem[Daulton et~al., 2020]{daulton_differentiable_2020}
Daulton, S., Balandat, M., and Bakshy, E. (2020).
\newblock Differentiable {Expected} {Hypervolume} {Improvement} for {Parallel}
  {Multi}-{Objective} {Bayesian} {Optimization}.
\newblock {\em Advances in Neural Information Processing Systems}, 33.

\bibitem[de~Fouquet, 1994]{de1994reminders}
de~Fouquet, C. (1994).
\newblock Reminders on the conditioning kriging.
\newblock In {\em Geostatistical simulations}, pages 131--145. Springer.

\bibitem[Deb, 2019]{deb2019constrained}
Deb, K. (2019).
\newblock Constrained multi-objective evolutionary algorithm.
\newblock In {\em Evolutionary and Swarm Intelligence Algorithms}, pages
  85--118. Springer.

\bibitem[Doucet, 2010]{doucet_note_2010}
Doucet, A. (2010).
\newblock A {Note} on {Efficient} {Conditional} {Simulation} of {Gaussian}
  {Distributions}.
\newblock
  \url{https://www.cs.ubc.ca/~arnaud/doucet_simulationconditionalgaussian.pdf}.

\bibitem[Dreifuerst et~al., 2020]{dreifuerst2020optimizing}
Dreifuerst, R.~M., Daulton, S., Qian, Y., Varkey, P., Balandat, M., Kasturia,
  S., Tomar, A., Yazdan, A., Ponnampalam, V., and Heath, R.~W. (2020).
\newblock Optimizing coverage and capacity in cellular networks using machine
  learning.
\newblock {\em arXiv preprint arXiv:2010.13710}.

\bibitem[Emery, 2007]{emery2007conditioning}
Emery, X. (2007).
\newblock Conditioning simulations of gaussian random fields by ordinary
  kriging.
\newblock {\em Mathematical Geology}, 39(6):607--623.

\bibitem[Emmerich, 2005]{emmerich2005single}
Emmerich, M. (2005).
\newblock Single-and multi-objective evolutionary design optimization assisted
  by gaussian random field metamodels.
\newblock {\em dissertation, Universit{\"a}t Dortmund}.

\bibitem[Emmerich et~al., 2011]{emmerich2011hypervolume}
Emmerich, M.~T., Deutz, A.~H., and Klinkenberg, J.~W. (2011).
\newblock Hypervolume-based expected improvement: Monotonicity properties and
  exact computation.
\newblock In {\em 2011 IEEE Congress of Evolutionary Computation (CEC)}, pages
  2147--2154. IEEE.

\bibitem[Eriksson and Poloczek, 2021]{eriksson2020scalable}
Eriksson, D. and Poloczek, M. (2021).
\newblock Scalable constrained bayesian optimization.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}. PMLR.

\bibitem[Feng et~al., 2020]{feng_high-dimensional_2020}
Feng, Q., Letham, B., Mao, H., and Bakshy, E. (2020).
\newblock High-{Dimensional} {Contextual} {Policy} {Search} with {Unknown}
  {Context} {Rewards} using {Bayesian} {Optimization}.
\newblock {\em Advances in Neural Information Processing Systems}, 33.

\bibitem[Feydy et~al., 2020]{feydy2020fast}
Feydy, J., Glaun{\`e}s, J., Charlier, B., and Bronstein, M. (2020).
\newblock Fast geometric learning with symbolic matrices.
\newblock {\em Advances in Neural Information Processing Systems}, 33(4):6.

\bibitem[Gardner et~al., 2018]{gardner_gpytorch_2018}
Gardner, J., Pleiss, G., Weinberger, K.~Q., Bindel, D., and Wilson, A.~G.
  (2018).
\newblock {GPyTorch}: {Blackbox} {Matrix}-{Matrix} {Gaussian} {Process}
  {Inference} with {GPU} {Acceleration}.
\newblock In {\em Advances in {Neural} {Information} {Processing} {Systems}},
  volume~31, pages 7576--7586.

\bibitem[Gardner et~al., 2014]{gardner2014bayesian}
Gardner, J.~R., Kusner, M.~J., Xu, Z.~E., Weinberger, K.~Q., and Cunningham,
  J.~P. (2014).
\newblock Bayesian optimization with inequality constraints.
\newblock In {\em International Conference on Machine Learning}, volume~32,
  pages 937--945. PMLR.

\bibitem[Gelbart et~al., 2014]{gelbart2014bayesian}
Gelbart, M.~A., Snoek, J., and Adams, R.~P. (2014).
\newblock Bayesian optimization with unknown constraints.
\newblock In {\em Uncertainty in Artificial Intelligence}, volume~30, pages
  250--259. AUAI Press.

\bibitem[Golub and Van~Loan, 2013]{golub_matrix_2013}
Golub, G.~H. and Van~Loan, C.~F. (2013).
\newblock {\em Matrix {Computations}}.
\newblock The Johns Hopkins University Press, 4 edition.

\bibitem[Goovaerts et~al., 1997]{goovaerts1997geostatistics}
Goovaerts, P. et~al. (1997).
\newblock {\em Geostatistics for natural resources evaluation}.
\newblock Oxford University Press on Demand.

\bibitem[Higdon et~al., 2008]{higdon2008computer}
Higdon, D., Gattiker, J., Williams, B., and Rightley, M. (2008).
\newblock Computer model calibration using high-dimensional output.
\newblock {\em Journal of the American Statistical Association},
  103(482):570--583.

\bibitem[Jiang et~al., 2020]{jiang_efficient_2020}
Jiang, S., Jiang, D., Balandat, M., Karrer, B., Gardner, J., and Garnett, R.
  (2020).
\newblock Efficient {Nonmyopic} {Bayesian} {Optimization} via {One}-{Shot}
  {Multi}-{Step} {Trees}.
\newblock In {\em Advances in {Neural} {Information} {Processing} {Systems}},
  volume~33.

\bibitem[Jones, 2008]{jones2008large}
Jones, D.~R. (2008).
\newblock Large-scale multi-disciplinary mass optimization in the auto
  industry.
\newblock In {\em MOPTA 2008 Conference (20 August 2008)}.

\bibitem[Khan et~al., 2002]{khan2002multi}
Khan, N., Goldberg, D.~E., and Pelikan, M. (2002).
\newblock Multi-objective bayesian optimization algorithm.
\newblock In {\em Proceedings of the 4th Annual Conference on Genetic and
  Evolutionary Computation}, pages 684--684.

\bibitem[Knowles, 2006]{knowles2006parego}
Knowles, J. (2006).
\newblock Parego: A hybrid algorithm with on-line landscape approximation for
  expensive multiobjective optimization problems.
\newblock {\em IEEE Transactions on Evolutionary Computation}, 10(1):50--66.

\bibitem[Krause and Ong, 2011]{krause2011contextual}
Krause, A. and Ong, C.~S. (2011).
\newblock Contextual gaussian process bandit optimization.
\newblock In {\em Advances in neural information processing systems}, pages
  2447--2455.

\bibitem[Larocque et~al., 2006]{larocque2006conditional}
Larocque, G., Dutilleul, P., Pelletier, B., and Fyles, J.~W. (2006).
\newblock Conditional gaussian co-simulation of regionalized components of soil
  variation.
\newblock {\em Geoderma}, 134(1-2):1--16.

\bibitem[Lewandowski et~al., 2009]{lewandowski2009generating}
Lewandowski, D., Kurowicka, D., and Joe, H. (2009).
\newblock Generating random correlation matrices based on vines and extended
  onion method.
\newblock {\em Journal of multivariate analysis}, 100(9):1989--2001.

\bibitem[{Lorch} et~al., 2020]{2020arXiv200407641L}
{Lorch}, L., {Kremer}, H., {Trouleau}, W., {Tsirtsis}, S., {Szanto}, A.,
  {Sch{\"o}lkopf}, B., and {Gomez-Rodriguez}, M. (2020).
\newblock {Quantifying the Effects of Contact Tracing, Testing, and Containment
  Measures in the Presence of Infection Hotspots}.
\newblock {\em arXiv e-prints}, page arXiv:2004.07641.

\bibitem[Nguyen et~al., 2014]{nguyen2014collaborative}
Nguyen, T.~V., Bonilla, E.~V., et~al. (2014).
\newblock Collaborative multi-output gaussian processes.
\newblock In {\em Uncertainty in Artifical Intelligence}, volume~30, pages
  643--652. AUAI Press.

\bibitem[Osyczka and Kundu, 1995]{osyczka1995new}
Osyczka, A. and Kundu, S. (1995).
\newblock A new method to solve generalized multicriteria optimization problems
  using the simple genetic algorithm.
\newblock {\em Structural optimization}, 10(2):94--99.

\bibitem[Paszke et~al., 2019]{paszke2019pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., et~al. (2019).
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock {\em Advances in Neural Information Processing Systems},
  32:8026--8037.

\bibitem[Pleiss et~al., 2018]{pleiss_constant-time_2018}
Pleiss, G., Gardner, J.~R., Weinberger, K.~Q., and Wilson, A.~G. (2018).
\newblock Constant-{Time} {Predictive} {Distributions} for {Gaussian}
  {Processes}.
\newblock In {\em Artificial {Intelligence} and {Statistics}}, volume
  arXiv:1803.06058 [cs, stat].

\bibitem[Pleiss et~al., 2020]{pleiss_fast_2020}
Pleiss, G., Jankowiak, M., Eriksson, D., Damle, A., and Gardner, J. (2020).
\newblock Fast {Matrix} {Square} {Roots} with {Applications} to {Gaussian}
  {Processes} and {Bayesian} {Optimization}.
\newblock In {\em Advances in {Neural} {Information} {Processing} {Systems}},
  volume~33.

\bibitem[Rakitsch et~al., 2013]{rakitsch2013noise}
Rakitsch, B., Lippert, C., Borgwardt, K., and Stegle, O. (2013).
\newblock It is all in the noise: Efficient multi-task gaussian process
  inference with structured residuals.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~26, pages 1466--1474. Curran Associates, Inc.

\bibitem[Rasmussen and Williams, 2008]{rasmussen_gaussian_2008}
Rasmussen, C.~E. and Williams, C. K.~I. (2008).
\newblock {\em Gaussian processes for machine learning}.
\newblock Adaptive computation and machine learning. MIT Press, Cambridge,
  Mass., 3. print edition.

\bibitem[Rockafellar et~al., 2000]{rockafellar2000optimization}
Rockafellar, R.~T., Uryasev, S., et~al. (2000).
\newblock Optimization of conditional value-at-risk.
\newblock {\em Journal of risk}, 2:21--42.

\bibitem[Rougier, 2008]{rougier2008efficient}
Rougier, J. (2008).
\newblock Efficient emulators for multivariate deterministic functions.
\newblock {\em Journal of Computational and Graphical Statistics},
  17(4):827--843.

\bibitem[Saatchi, 2011]{saatcci2012scalable}
Saatchi, Y. (2011).
\newblock {\em Scalable inference for structured Gaussian process models}.
\newblock PhD thesis, University of Cambridge.

\bibitem[Shah and Ghahramani, 2016]{shah16correlated}
Shah, A. and Ghahramani, Z. (2016).
\newblock Pareto frontier learning with expensive correlated objectives.
\newblock In {\em Proceedings of The 33rd International Conference on Machine
  Learning}, volume~48, pages 1919--1927, New York, New York, USA. PMLR.

\bibitem[Sorokin et~al., 2020]{sorokin2020interferobot}
Sorokin, D., Ulanov, A., Sazhina, E., and Lvovsky, A. (2020).
\newblock Interferobot: aligning an optical interferometer by a reinforcement
  learning agent.
\newblock {\em arXiv preprint arXiv:2006.02252}.

\bibitem[Stegle et~al., 2011]{stegle2011efficient}
Stegle, O., Lippert, C., Mooij, J., Lawrence, N., and Borgwardt, K. (2011).
\newblock Efficient inference in matrix-variate gaussian models with iid
  observation noise.
\newblock {\em Advances in Neural Information Processing Systems}, 24:1--9.

\bibitem[Swersky et~al., 2013]{swersky_multi-task_2013}
Swersky, K., Snoek, J., and Adams, R.~P. (2013).
\newblock Multi-task {Bayesian} optimization.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~26, pages 2004--2012, Red Hook, NY, USA. Curran Associates Inc.

\bibitem[Uhrenholt and Jensen, 2019]{uhrenholt2019efficient}
Uhrenholt, A.~K. and Jensen, B.~S. (2019).
\newblock Efficient bayesian optimization for target vector estimation.
\newblock In {\em The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 2661--2670. PMLR.

\bibitem[Wang et~al., 2019]{wang_exact_2019}
Wang, K.~A., Pleiss, G., Gardner, J.~R., Tyree, S., Weinberger, K.~Q., and
  Wilson, A.~G. (2019).
\newblock Exact {Gaussian} {Processes} on a {Million} {Data} {Points}.
\newblock In {\em Advances in {Neural} {Information} {Processing} {Systems}}.
\newblock arXiv: 1903.08114.

\bibitem[Wilson et~al., 2014]{wilson2014fast}
Wilson, A.~G., Gilboa, E., Cunningham, J.~P., and Nehorai, A. (2014).
\newblock Fast kernel learning for multidimensional pattern extrapolation.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~27, pages 3626--3634.

\bibitem[Wilson et~al., 2020a]{wilson_efficiently_2020}
Wilson, J., Borovitskiy, V., Terenin, A., Mostowsky, P., and Deisenroth, M.
  (2020a).
\newblock Efficiently sampling functions from {Gaussian} process posteriors.
\newblock In {\em International {Conference} on {Machine} {Learning}}, pages
  10292--10302. PMLR.
\newblock ISSN: 2640-3498.

\bibitem[Wilson et~al., 2018]{wilson2018maxbo}
Wilson, J., Hutter, F., and Deisenroth, M.~P. (2018).
\newblock Maximizing acquisition functions for {B}ayesian optimization.
\newblock In {\em Advances in Neural Information Processing Systems 31}, pages
  9905--9916.

\bibitem[Wilson et~al., 2020b]{wilson2020pathwise}
Wilson, J.~T., Borovitskiy, V., Terenin, A., Mostowsky, P., and Deisenroth,
  M.~P. (2020b).
\newblock Pathwise conditioning of gaussian processes.
\newblock {\em arXiv preprint arXiv:2011.04026}.

\bibitem[Yang et~al., 2017]{yang17}
Yang, K., Emmerich, M., Deutz, A., and Fonseca, C.~M. (2017).
\newblock Computing 3-d expected hypervolume improvement and related integrals
  in asymptotically optimal time.
\newblock In {\em 9th International Conference on Evolutionary Multi-Criterion
  Optimization - Volume 10173}, EMO 2017, page 685–700, Berlin, Heidelberg.
  Springer-Verlag.

\bibitem[Zhang, 2007]{zhang2007maximum}
Zhang, H. (2007).
\newblock Maximum-likelihood estimation for multivariate spatial linear
  coregionalization models.
\newblock {\em Environmetrics: The official journal of the International
  Environmetrics Society}, 18(2):125--139.

\bibitem[Zhe et~al., 2019]{zhe_scalable_2019}
Zhe, S., Xing, W., and Kirby, R.~M. (2019).
\newblock Scalable {High}-{Order} {Gaussian} {Process} {Regression}.
\newblock In {\em The 22nd {International} {Conference} on {Artificial}
  {Intelligence} and {Statistics}}, pages 2611--2620. PMLR.
\newblock ISSN: 2640-3498.

\bibitem[Zwicker, 2020]{zwicker2020py}
Zwicker, D. (2020).
\newblock py-pde: A python package for solving partial differential equations.
\newblock {\em Journal of Open Source Software}, 5(48):2158.

\end{thebibliography}
