\begin{thebibliography}{51}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alet et~al.(2021)Alet, Doblar, Zhou, Tenenbaum, Kawaguchi, and
  Finn]{alet2021noether}
F.~Alet, D.~Doblar, A.~Zhou, J.~Tenenbaum, K.~Kawaguchi, and C.~Finn.
\newblock Noether networks: meta-learning useful conserved quantities.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Bejnordi et~al.(2017)Bejnordi, Veta, Van~Diest, Van~Ginneken,
  Karssemeijer, Litjens, Van Der~Laak, Hermsen, Manson, Balkenhol,
  et~al.]{bejnordi2017diagnostic}
B.~E. Bejnordi, M.~Veta, P.~J. Van~Diest, B.~Van~Ginneken, N.~Karssemeijer,
  G.~Litjens, J.~A. Van Der~Laak, M.~Hermsen, Q.~F. Manson, M.~Balkenhol,
  et~al.
\newblock Diagnostic assessment of deep learning algorithms for detection of
  lymph node metastases in women with breast cancer.
\newblock \emph{Jama}, 318\penalty0 (22):\penalty0 2199--2210, 2017.

\bibitem[Benton et~al.(2020)Benton, Finzi, Izmailov, and
  Wilson]{benton2020learning}
G.~Benton, M.~Finzi, P.~Izmailov, and A.~G. Wilson.
\newblock Learning invariances in neural networks from training data.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 17605--17616, 2020.

\bibitem[Bogatskiy et~al.(2020)Bogatskiy, Anderson, Offermann, Roussi, Miller,
  and Kondor]{bogatskiy2020lorentz}
A.~Bogatskiy, B.~Anderson, J.~Offermann, M.~Roussi, D.~Miller, and R.~Kondor.
\newblock Lorentz group equivariant neural network for particle physics.
\newblock In \emph{International Conference on Machine Learning}, pages
  992--1002. PMLR, 2020.

\bibitem[Chatzipantazis et~al.(2021)Chatzipantazis, Pertigkiozoglou, Dobriban,
  and Daniilidis]{chatzipantazis2021learning}
E.~Chatzipantazis, S.~Pertigkiozoglou, E.~Dobriban, and K.~Daniilidis.
\newblock Learning augmentation distributions using transformed risk
  minimization.
\newblock \emph{arXiv preprint arXiv:2111.08190}, 2021.

\bibitem[Chen et~al.(2020)Chen, Dobriban, and Lee]{chen2020group}
S.~Chen, E.~Dobriban, and J.~H. Lee.
\newblock A group-theoretic framework for data augmentation.
\newblock \emph{Journal of Machine Learning Research}, 21\penalty0
  (245):\penalty0 1--71, 2020.

\bibitem[Cohen and Welling(2016)]{cohen2016group}
T.~Cohen and M.~Welling.
\newblock Group equivariant convolutional networks.
\newblock In \emph{International conference on machine learning}, pages
  2990--2999. PMLR, 2016.

\bibitem[Cohen et~al.(2018)Cohen, Geiger, K{\"o}hler, and
  Welling]{cohen2018spherical}
T.~S. Cohen, M.~Geiger, J.~K{\"o}hler, and M.~Welling.
\newblock Spherical cnns.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Cohen et~al.(2019)Cohen, Geiger, and Weiler]{cohen2018general}
T.~S. Cohen, M.~Geiger, and M.~Weiler.
\newblock A general theory of equivariant cnns on homogeneous spaces.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Dehmamy et~al.(2021)Dehmamy, Walters, Liu, Wang, and
  Yu]{dehmamy2021lie}
N.~Dehmamy, R.~Walters, Y.~Liu, D.~Wang, and R.~Yu.
\newblock Automatic symmetry discovery with lie algebra convolutional network.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Dieleman et~al.(2016)Dieleman, De~Fauw, and
  Kavukcuoglu]{dieleman2016exploiting}
S.~Dieleman, J.~De~Fauw, and K.~Kavukcuoglu.
\newblock Exploiting cyclic symmetry in convolutional neural networks.
\newblock In \emph{International conference on machine learning}, pages
  1889--1898. PMLR, 2016.

\bibitem[Esteves et~al.(2019{\natexlab{a}})Esteves, Sud, Luo, Daniilidis, and
  Makadia]{esteves2019cross}
C.~Esteves, A.~Sud, Z.~Luo, K.~Daniilidis, and A.~Makadia.
\newblock Cross-domain 3d equivariant image embeddings.
\newblock In \emph{International Conference on Machine Learning}, pages
  1812--1822. PMLR, 2019{\natexlab{a}}.

\bibitem[Esteves et~al.(2019{\natexlab{b}})Esteves, Xu, Allen-Blanchette, and
  Daniilidis]{esteves2019equivariant}
C.~Esteves, Y.~Xu, C.~Allen-Blanchette, and K.~Daniilidis.
\newblock Equivariant multi-view networks.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1568--1577, 2019{\natexlab{b}}.

\bibitem[Esteves et~al.(2020)Esteves, Makadia, and Daniilidis]{esteves2020spin}
C.~Esteves, A.~Makadia, and K.~Daniilidis.
\newblock Spin-weighted spherical cnns.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 8614--8625, 2020.

\bibitem[Falorsi et~al.(2019)Falorsi, de~Haan, Davidson, and
  Forr{\'e}]{falorsi2019reparameterizing}
L.~Falorsi, P.~de~Haan, T.~R. Davidson, and P.~Forr{\'e}.
\newblock Reparameterizing distributions on lie groups.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 3244--3253. PMLR, 2019.

\bibitem[Finzi et~al.(2020)Finzi, Stanton, Izmailov, and
  Wilson]{finzi2020generalizing}
M.~Finzi, S.~Stanton, P.~Izmailov, and A.~G. Wilson.
\newblock Generalizing convolutional neural networks for equivariance to lie
  groups on arbitrary continuous data.
\newblock In \emph{International Conference on Machine Learning}, pages
  3165--3176. PMLR, 2020.

\bibitem[Finzi et~al.(2021{\natexlab{a}})Finzi, Benton, and
  Wilson]{finzi2021residual}
M.~Finzi, G.~Benton, and A.~G. Wilson.
\newblock Residual pathway priors for soft equivariance constraints.
\newblock \emph{Advances in Neural Information Processing Systems}, 34,
  2021{\natexlab{a}}.

\bibitem[Finzi et~al.(2021{\natexlab{b}})Finzi, Welling, and
  Wilson]{finzi2021practical}
M.~Finzi, M.~Welling, and A.~G. Wilson.
\newblock A practical method for constructing equivariant multilayer
  perceptrons for arbitrary matrix groups.
\newblock In \emph{International Conference on Machine Learning}, pages
  3318--3328. PMLR, 2021{\natexlab{b}}.

\bibitem[Fuchs et~al.(2020)Fuchs, Worrall, Fischer, and Welling]{fuchs2020se}
F.~Fuchs, D.~Worrall, V.~Fischer, and M.~Welling.
\newblock Se (3)-transformers: 3d roto-translation equivariant attention
  networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 1970--1981, 2020.

\bibitem[Hataya et~al.(2020)Hataya, Zdenek, Yoshizoe, and
  Nakayama]{hataya2020faster}
R.~Hataya, J.~Zdenek, K.~Yoshizoe, and H.~Nakayama.
\newblock Faster autoaugment: Learning augmentation strategies using
  backpropagation.
\newblock In \emph{European Conference on Computer Vision}, pages 1--16.
  Springer, 2020.

\bibitem[Hoogeboom et~al.(2019)Hoogeboom, Peters, Van Den~Berg, and
  Welling]{hoogeboom2019integer}
E.~Hoogeboom, J.~Peters, R.~Van Den~Berg, and M.~Welling.
\newblock Integer discrete flows and lossless compression.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Hoogeboom et~al.(2021)Hoogeboom, Nielsen, Jaini, Forr{\'e}, and
  Welling]{hoogeboom2021argmax}
E.~Hoogeboom, D.~Nielsen, P.~Jaini, P.~Forr{\'e}, and M.~Welling.
\newblock Argmax flows and multinomial diffusion: Towards non-autoregressive
  language models.
\newblock \emph{arXiv preprint arXiv:2102.05379}, 2021.

\bibitem[Hutchinson et~al.(2021)Hutchinson, Le~Lan, Zaidi, Dupont, Teh, and
  Kim]{hutchinson2021lietransformer}
M.~J. Hutchinson, C.~Le~Lan, S.~Zaidi, E.~Dupont, Y.~W. Teh, and H.~Kim.
\newblock Lietransformer: equivariant self-attention for lie groups.
\newblock In \emph{International Conference on Machine Learning}, pages
  4533--4543. PMLR, 2021.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
S.~Ioffe and C.~Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{International conference on machine learning}, pages
  448--456. PMLR, 2015.

\bibitem[Jang et~al.(2016)Jang, Gu, and Poole]{jang2016categorical}
E.~Jang, S.~Gu, and B.~Poole.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock \emph{arXiv preprint arXiv:1611.01144}, 2016.

\bibitem[Kingma and Welling(2013)]{kingma2013auto}
D.~P. Kingma and M.~Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Knigge et~al.(2022)Knigge, Romero, and Bekkers]{knigge2022exploiting}
D.~M. Knigge, D.~W. Romero, and E.~J. Bekkers.
\newblock Exploiting redundancy: Separable group convolutional networks on lie
  groups.
\newblock In \emph{International Conference on Machine Learning}, pages
  11359--11386. PMLR, 2022.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
A.~Krizhevsky, G.~Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Laine and Aila(2016)]{laine2016temporal}
S.~Laine and T.~Aila.
\newblock Temporal ensembling for semi-supervised learning.
\newblock \emph{arXiv preprint arXiv:1610.02242}, 2016.

\bibitem[Larochelle et~al.(2007)Larochelle, Erhan, Courville, Bergstra, and
  Bengio]{larochelle2007empirical}
H.~Larochelle, D.~Erhan, A.~Courville, J.~Bergstra, and Y.~Bengio.
\newblock An empirical evaluation of deep architectures on problems with many
  factors of variation.
\newblock In \emph{Proceedings of the 24th international conference on Machine
  learning}, pages 473--480, 2007.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Lengyel and van Gemert(2021)]{lengyel2021exploiting}
A.~Lengyel and J.~van Gemert.
\newblock Exploiting learned symmetries in group equivariant convolutions.
\newblock In \emph{2021 IEEE International Conference on Image Processing
  (ICIP)}, pages 759--763. IEEE, 2021.

\bibitem[Li et~al.(2020)Li, Hu, Wang, Hospedales, Robertson, and
  Yang]{li2020dada}
Y.~Li, G.~Hu, Y.~Wang, T.~M. Hospedales, N.~M. Robertson, and Y.~Yang.
\newblock {DADA:} differentiable automatic data augmentation.
\newblock 2020.

\bibitem[Lim et~al.(2019)Lim, Kim, Kim, Kim, and Kim]{lim2019fast}
S.~Lim, I.~Kim, T.~Kim, C.~Kim, and S.~Kim.
\newblock Fast autoaugment.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Maddison et~al.(2016)Maddison, Mnih, and Teh]{maddison2016concrete}
C.~J. Maddison, A.~Mnih, and Y.~W. Teh.
\newblock The concrete distribution: A continuous relaxation of discrete random
  variables.
\newblock \emph{arXiv preprint arXiv:1611.00712}, 2016.

\bibitem[Romero et~al.(2020{\natexlab{a}})Romero, Bekkers, Tomczak, and
  Hoogendoorn]{romero2020attentive}
D.~Romero, E.~Bekkers, J.~Tomczak, and M.~Hoogendoorn.
\newblock Attentive group equivariant convolutional networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  8188--8199. PMLR, 2020{\natexlab{a}}.

\bibitem[Romero and Cordonnier(2020)]{romero2020group}
D.~W. Romero and J.-B. Cordonnier.
\newblock Group equivariant stand-alone self-attention for vision.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Romero et~al.(2020{\natexlab{b}})Romero, Bekkers, Tomczak, and
  Hoogendoorn]{romero2020wavelet}
D.~W. Romero, E.~J. Bekkers, J.~M. Tomczak, and M.~Hoogendoorn.
\newblock Wavelet networks: Scale equivariant learning from raw waveforms.
\newblock \emph{arXiv preprint arXiv:2006.05259}, 2020{\natexlab{b}}.

\bibitem[Romero et~al.(2020{\natexlab{c}})Romero, Kuzina, Bekkers, Tomczak, and
  Hoogendoorn]{romero2021ckconv}
D.~W. Romero, A.~Kuzina, E.~J. Bekkers, J.~M. Tomczak, and M.~Hoogendoorn.
\newblock Ckconv: Continuous kernel convolution for sequential data.
\newblock 2020{\natexlab{c}}.

\bibitem[Sch{\"u}tt et~al.(2017)Sch{\"u}tt, Kindermans, Sauceda, Chmiela,
  Tkatchenko, and M{\"u}ller]{schutt2017schnet}
K.~T. Sch{\"u}tt, P.-J. Kindermans, H.~E. Sauceda, S.~Chmiela, A.~Tkatchenko,
  and K.-R. M{\"u}ller.
\newblock Schnet: A continuous-filter convolutional neural network for modeling
  quantum interactions.
\newblock \emph{arXiv preprint arXiv:1706.08566}, 2017.

\bibitem[Sitzmann et~al.(2020)Sitzmann, Martel, Bergman, Lindell, and
  Wetzstein]{sitzmann2020implicit}
V.~Sitzmann, J.~Martel, A.~Bergman, D.~Lindell, and G.~Wetzstein.
\newblock Implicit neural representations with periodic activation functions.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Sosnovik et~al.(2020)Sosnovik, Szmaja, and
  Smeulders]{sosnovik2019scale}
I.~Sosnovik, M.~Szmaja, and A.~Smeulders.
\newblock Scale-equivariant steerable networks.
\newblock 2020.

\bibitem[van~der Ouderaa and van~der Wilk(2021)]{ouderaa2021}
T.~F. van~der Ouderaa and M.~van~der Wilk.
\newblock Learning invariant weights in neural networks.
\newblock \emph{Workshop in Uncertainty \& Robustness in Deep Learning, ICML},
  2021.

\bibitem[van~der Wilk et~al.(2018)van~der Wilk, Bauer, John, and
  Hensman]{van2018learning}
M.~van~der Wilk, M.~Bauer, S.~John, and J.~Hensman.
\newblock Learning invariances using the marginal likelihood.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Veeling et~al.(2018)Veeling, Linmans, Winkens, Cohen, and
  Welling]{veeling2018rotation}
B.~S. Veeling, J.~Linmans, J.~Winkens, T.~Cohen, and M.~Welling.
\newblock Rotation equivariant cnns for digital pathology.
\newblock In \emph{International Conference on Medical image computing and
  computer-assisted intervention}, pages 210--218. Springer, 2018.

\bibitem[Weiler and Cesa(2019)]{weiler2019general}
M.~Weiler and G.~Cesa.
\newblock General e (2)-equivariant steerable cnns.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Weiler et~al.(2018{\natexlab{a}})Weiler, Geiger, Welling, Boomsma, and
  Cohen]{weiler20183d}
M.~Weiler, M.~Geiger, M.~Welling, W.~Boomsma, and T.~Cohen.
\newblock 3d steerable cnns: Learning rotationally equivariant features in
  volumetric data.
\newblock \emph{arXiv preprint arXiv:1807.02547}, 2018{\natexlab{a}}.

\bibitem[Weiler et~al.(2018{\natexlab{b}})Weiler, Hamprecht, and
  Storath]{weiler2018learning}
M.~Weiler, F.~A. Hamprecht, and M.~Storath.
\newblock Learning steerable filters for rotation equivariant cnns.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 849--858, 2018{\natexlab{b}}.

\bibitem[Worrall and Welling(2019)]{worrall2019deep}
D.~Worrall and M.~Welling.
\newblock Deep scale-spaces: Equivariance over scale.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Worrall et~al.(2017)Worrall, Garbin, Turmukhambetov, and
  Brostow]{worrall2017harmonic}
D.~E. Worrall, S.~J. Garbin, D.~Turmukhambetov, and G.~J. Brostow.
\newblock Harmonic networks: Deep translation and rotation equivariance.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 5028--5037, 2017.

\bibitem[Zhou et~al.(2020)Zhou, Knowles, and Finn]{zhou2020meta}
A.~Zhou, T.~Knowles, and C.~Finn.
\newblock Meta-learning symmetries by reparameterization.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\end{thebibliography}
