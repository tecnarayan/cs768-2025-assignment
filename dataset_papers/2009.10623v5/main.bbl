\newcommand{\noopsort}[1]{} \newcommand{\printfirst}[2]{#1}
  \newcommand{\singleletter}[1]{#1} \newcommand{\switchargs}[2]{#2#1}
\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Barham, Chen, Chen, Davis, Dean, Devin,
  Ghemawat, Irving, Isard, et~al.]{abadi2016tensorflow}
Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M.,
  Ghemawat, S., Irving, G., Isard, M., et~al.
\newblock Tensorflow: A system for large-scale machine learning.
\newblock In \emph{12th $\{$USENIX$\}$ symposium on operating systems design
  and implementation ($\{$OSDI$\}$ 16)}, pp.\  265--283, 2016.

\bibitem[Ackley et~al.(1985)Ackley, Hinton, and Sejnowski]{ackley1985learning}
Ackley, D.~H., Hinton, G.~E., and Sejnowski, T.~J.
\newblock A learning algorithm for boltzmann machines.
\newblock \emph{Cognitive science}, 9\penalty0 (1):\penalty0 147--169, 1985.

\bibitem[Alet et~al.(2019)Alet, Weng, Lozano-Perez, and
  Kaelbling]{alet2019neural}
Alet, F., Weng, E., Lozano-Perez, T., and Kaelbling, L.
\newblock Neural relational inference with fast modular meta-learning.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)
  32}, 2019.

\bibitem[Amos \& Kolter(2017)Amos and Kolter]{amos2017optnet}
Amos, B. and Kolter, J.~Z.
\newblock Optnet: Differentiable optimization as a layer in neural networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, pp.\  136--145. JMLR, 2017.

\bibitem[Antoniou \& Storkey(2019)Antoniou and Storkey]{antoniou2019learning}
Antoniou, A. and Storkey, A.~J.
\newblock Learning to learn by self-critique.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  9940--9950, 2019.

\bibitem[Bartlett \& Mendelson(2002)Bartlett and
  Mendelson]{bartlett2002rademacher}
Bartlett, P.~L. and Mendelson, S.
\newblock Rademacher and gaussian complexities: Risk bounds and structural
  results.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0
  (Nov):\penalty0 463--482, 2002.

\bibitem[Bengio et~al.(1995)Bengio, Bengio, and Cloutier]{bengio1995search}
Bengio, S., Bengio, Y., and Cloutier, J.
\newblock On the search for new learning rules for anns.
\newblock \emph{Neural Processing Letters}, 2\penalty0 (4):\penalty0 26--30,
  1995.

\bibitem[Biggio et~al.(2013)Biggio, Corona, Maiorca, Nelson, {\v{S}}rndi{\'c},
  Laskov, Giacinto, and Roli]{biggio2013evasion}
Biggio, B., Corona, I., Maiorca, D., Nelson, B., {\v{S}}rndi{\'c}, N., Laskov,
  P., Giacinto, G., and Roli, F.
\newblock Evasion attacks against machine learning at test time.
\newblock In \emph{Joint European conference on machine learning and knowledge
  discovery in databases}, pp.\  387--402. Springer, 2013.

\bibitem[Bottou \& Vapnik(1992)Bottou and Vapnik]{bottou1992local}
Bottou, L. and Vapnik, V.
\newblock Local learning algorithms.
\newblock \emph{Neural computation}, 4\penalty0 (6):\penalty0 888--900, 1992.

\bibitem[Bradbury et~al.(2018)Bradbury, Frostig, Hawkins, Johnson, Leary,
  Maclaurin, Necula, Paszke, Vander{P}las, Wanderman-{M}ilne, and
  Zhang]{jax2018github}
Bradbury, J., Frostig, R., Hawkins, P., Johnson, M.~J., Leary, C., Maclaurin,
  D., Necula, G., Paszke, A., Vander{P}las, J., Wanderman-{M}ilne, S., and
  Zhang, Q.
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs.
\newblock \emph{github}, 2018.
\newblock URL \url{http://github.com/google/jax}.

\bibitem[Chapelle et~al.(2000)Chapelle, Vapnik, and
  Weston]{chapelle2000transductive}
Chapelle, O., Vapnik, V., and Weston, J.
\newblock Transductive inference for estimating values of functions.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  421--427, 2000.

\bibitem[Chapelle et~al.(2009)Chapelle, Scholkopf, and Zien]{chapelle2009semi}
Chapelle, O., Scholkopf, B., and Zien, A.
\newblock Semi-supervised learning (chapelle, o. et al., eds.; 2006)[book
  reviews].
\newblock \emph{IEEE Transactions on Neural Networks}, 20\penalty0
  (3):\penalty0 542--542, 2009.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock \emph{arXiv preprint arXiv:2002.05709}, 2020.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{cohen2019certified}
Cohen, J., Rosenfeld, E., and Kolter, Z.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1310--1320, 2019.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pp.\  248--255. Ieee, 2009.

\bibitem[Dhillon et~al.(2020)Dhillon, Chaudhari, Ravichandran, and
  Soatto]{dhillon2019baseline}
Dhillon, G.~S., Chaudhari, P., Ravichandran, A., and Soatto, S.
\newblock A baseline for few-shot image classification.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Donahue et~al.(2014)Donahue, Jia, Vinyals, Hoffman, Zhang, Tzeng, and
  Darrell]{donahue2014decaf}
Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., and
  Darrell, T.
\newblock Decaf: A deep convolutional activation feature for generic visual
  recognition.
\newblock In \emph{International conference on machine learning}, pp.\
  647--655, 2014.

\bibitem[Dumoulin et~al.(2016)Dumoulin, Shlens, and
  Kudlur]{dumoulin2016learned}
Dumoulin, V., Shlens, J., and Kudlur, M.
\newblock A learned representation for artistic style.
\newblock \emph{arXiv preprint arXiv:1610.07629}, 2016.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Finn, C., Abbeel, P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock \emph{arXiv preprint arXiv:1703.03400}, 2017.

\bibitem[Flennerhag et~al.(2019)Flennerhag, Rusu, Pascanu, Yin, and
  Hadsell]{flennerhag2019meta}
Flennerhag, S., Rusu, A.~A., Pascanu, R., Yin, H., and Hadsell, R.
\newblock Meta-learning with warped gradient descent.
\newblock \emph{arXiv preprint arXiv:1909.00025}, 2019.

\bibitem[Garcia \& Bruna(2017)Garcia and Bruna]{garcia2017few}
Garcia, V. and Bruna, J.
\newblock Few-shot learning with graph neural networks.
\newblock \emph{arXiv preprint arXiv:1711.04043}, 2017.

\bibitem[Grefenstette et~al.(2019)Grefenstette, Amos, Yarats, Htut, Molchanov,
  Meier, Kiela, Cho, and Chintala]{grefenstette2019generalized}
Grefenstette, E., Amos, B., Yarats, D., Htut, P.~M., Molchanov, A., Meier, F.,
  Kiela, D., Cho, K., and Chintala, S.
\newblock Generalized inner loop meta-learning.
\newblock \emph{arXiv preprint arXiv:1910.01727}, 2019.

\bibitem[Greydanus et~al.(2019)Greydanus, Dzamba, and
  Yosinski]{greydanus2019hamiltonian}
Greydanus, S., Dzamba, M., and Yosinski, J.
\newblock Hamiltonian neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  15353--15363, 2019.

\bibitem[Hadsell et~al.(2006)Hadsell, Chopra, and
  LeCun]{hadsell2006dimensionality}
Hadsell, R., Chopra, S., and LeCun, Y.
\newblock Dimensionality reduction by learning an invariant mapping.
\newblock In \emph{2006 IEEE Computer Society Conference on Computer Vision and
  Pattern Recognition (CVPR'06)}, volume~2, pp.\  1735--1742. IEEE, 2006.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[He et~al.(2019)He, Fan, Wu, Xie, and Girshick]{he2019momentum}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock \emph{arXiv preprint arXiv:1911.05722}, 2019.

\bibitem[Hinton(2002)]{hinton2002training}
Hinton, G.~E.
\newblock Training products of experts by minimizing contrastive divergence.
\newblock \emph{Neural computation}, 14\penalty0 (8):\penalty0 1771--1800,
  2002.

\bibitem[Hospedales et~al.(2020)Hospedales, Antoniou, Micaelli, and
  Storkey]{hospedales2020meta}
Hospedales, T., Antoniou, A., Micaelli, P., and Storkey, A.
\newblock Meta-learning in neural networks: A survey.
\newblock \emph{arXiv preprint arXiv:2004.05439}, 2020.

\bibitem[Ilyas et~al.(2019)Ilyas, Santurkar, Tsipras, Engstrom, Tran, and
  Madry]{ilyas2019adversarial}
Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., and Madry, A.
\newblock Adversarial examples are not bugs, they are features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  125--136, 2019.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{ioffe2015batch}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{arXiv preprint arXiv:1502.03167}, 2015.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock \emph{Citeseer}, 2009.

\bibitem[LeCun et~al.(2006)LeCun, Chopra, Hadsell, Ranzato, and
  Huang]{lecun2006tutorial}
LeCun, Y., Chopra, S., Hadsell, R., Ranzato, M., and Huang, F.
\newblock A tutorial on energy-based learning.
\newblock \emph{Predicting structured data}, 1\penalty0 (0), 2006.

\bibitem[Liu et~al.(2018)Liu, Lee, Park, Kim, Yang, Hwang, and
  Yang]{liu2018learning}
Liu, Y., Lee, J., Park, M., Kim, S., Yang, E., Hwang, S.~J., and Yang, Y.
\newblock Learning to propagate labels: Transductive propagation network for
  few-shot learning.
\newblock \emph{arXiv preprint arXiv:1805.10002}, 2018.

\bibitem[Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \emph{arXiv preprint arXiv:1706.06083}, 2017.

\bibitem[Mityagin(2015)]{mityagin2015zero}
Mityagin, B.
\newblock The zero set of a real analytic function.
\newblock \emph{arXiv preprint arXiv:1512.07276}, 2015.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Oord, A. v.~d., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  8024--8035, 2019.

\bibitem[Perez et~al.(2018)Perez, Strub, De~Vries, Dumoulin, and
  Courville]{perez2018film}
Perez, E., Strub, F., De~Vries, H., Dumoulin, V., and Courville, A.
\newblock Film: Visual reasoning with a general conditioning layer.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Rakelly et~al.(2019)Rakelly, Zhou, Quillen, Finn, and
  Levine]{rakelly2019efficient}
Rakelly, K., Zhou, A., Quillen, D., Finn, C., and Levine, S.
\newblock Efficient off-policy meta-reinforcement learning via probabilistic
  context variables.
\newblock \emph{arXiv preprint arXiv:1903.08254}, 2019.

\bibitem[Requeima et~al.(2019)Requeima, Gordon, Bronskill, Nowozin, and
  Turner]{requeima2019fast}
Requeima, J., Gordon, J., Bronskill, J., Nowozin, S., and Turner, R.~E.
\newblock Fast and flexible multi-task classification using conditional neural
  adaptive processes.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  7957--7968, 2019.

\bibitem[Reuther et~al.(2018)Reuther, Kepner, Byun, Samsi, Arcand, Bestor,
  Bergeron, Gadepally, Houle, Hubbell, et~al.]{reuther2018interactive}
Reuther, A., Kepner, J., Byun, C., Samsi, S., Arcand, W., Bestor, D., Bergeron,
  B., Gadepally, V., Houle, M., Hubbell, M., et~al.
\newblock Interactive supercomputing on 40,000 cores for machine learning and
  data analysis.
\newblock In \emph{2018 IEEE High Performance extreme Computing Conference
  (HPEC)}, pp.\  1--6. IEEE, 2018.

\bibitem[Salman et~al.(2019)Salman, Li, Razenshteyn, Zhang, Zhang, Bubeck, and
  Yang]{salman2019provably}
Salman, H., Li, J., Razenshteyn, I., Zhang, P., Zhang, H., Bubeck, S., and
  Yang, G.
\newblock Provably robust deep learning via adversarially trained smoothed
  classifiers.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  11289--11300, 2019.

\bibitem[Schmidhuber(1987)]{schmidhuber1987evolutionary}
Schmidhuber, J.
\newblock \emph{Evolutionary principles in self-referential learning, or on
  learning how to learn: the meta-meta-... hook}.
\newblock PhD thesis, Technische Universit{\"a}t M{\"u}nchen, 1987.

\bibitem[Suh \& Tedrake(2020)Suh and Tedrake]{suh2020surprising}
Suh, H. and Tedrake, R.
\newblock The surprising effectiveness of linear models for visual foresight in
  object pile manipulation.
\newblock \emph{arXiv preprint arXiv:2002.09093}, 2020.

\bibitem[Sun et~al.(2019)Sun, Wang, Liu, Miller, Efros, and Hardt]{sun2019test}
Sun, Y., Wang, X., Liu, Z., Miller, J., Efros, A.~A., and Hardt, M.
\newblock Test-time training for out-of-distribution generalization.
\newblock \emph{arXiv preprint arXiv:1909.13231}, 2019.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Thrun \& Pratt(1998)Thrun and Pratt]{thrun2012learning}
Thrun, S. and Pratt, L.
\newblock \emph{Learning to learn}.
\newblock Springer Science \& Business Media, 1998.

\bibitem[Tschiatschek et~al.(2018)Tschiatschek, Sahin, and
  Krause]{tschiatschek2018differentiable}
Tschiatschek, S., Sahin, A., and Krause, A.
\newblock Differentiable submodular maximization.
\newblock \emph{arXiv preprint arXiv:1803.01785}, 2018.

\bibitem[Vapnik(1995)]{vapnik1995nature}
Vapnik, V.~N.
\newblock The nature of statistical learning theory, 1995.

\bibitem[Wang et~al.(2019)Wang, Shelhamer, Olshausen, and
  Darrell]{wang2019dynamic}
Wang, D., Shelhamer, E., Olshausen, B., and Darrell, T.
\newblock Dynamic scale inference by entropy minimization.
\newblock \emph{arXiv preprint arXiv:1908.03182}, 2019.

\bibitem[Wu et~al.(2017)Wu, Wang, Xue, Sun, Freeman, and
  Tenenbaum]{wu2017marrnet}
Wu, J., Wang, Y., Xue, T., Sun, X., Freeman, W.~T., and Tenenbaum, J.~B.
\newblock Marrnet: 3d shape reconstruction via 2.5 d sketches.
\newblock \emph{arXiv preprint arXiv:1711.03129}, 2017.

\bibitem[Zhai et~al.(2020)Zhai, Dan, He, Zhang, Gong, Ravikumar, Hsieh, and
  Wang]{Zhai2020MACER}
Zhai, R., Dan, C., He, D., Zhang, H., Gong, B., Ravikumar, P., Hsieh, C.-J.,
  and Wang, L.
\newblock Macer: Attack-free and scalable robust training via maximizing
  certified radius.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=rJx1Na4Fwr}.

\bibitem[Zhang et~al.(2020)Zhang, Marklund, Dhawan, Gupta, Levine, and
  Finn]{zhang2020adaptive}
Zhang, M., Marklund, H., Dhawan, N., Gupta, A., Levine, S., and Finn, C.
\newblock Adaptive risk minimization: A meta-learning approach for tackling
  group distribution shift.
\newblock \emph{arXiv preprint arXiv:2007.02931}, 2020.

\bibitem[Zintgraf et~al.(2018)Zintgraf, Shiarlis, Kurin, Hofmann, and
  Whiteson]{zintgraf2018fast}
Zintgraf, L.~M., Shiarlis, K., Kurin, V., Hofmann, K., and Whiteson, S.
\newblock Fast context adaptation via meta-learning.
\newblock \emph{arXiv preprint arXiv:1810.03642}, 2018.

\end{thebibliography}
