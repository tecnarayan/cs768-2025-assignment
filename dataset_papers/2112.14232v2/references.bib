\begin{filecontents}
@inproceedings{neuripssecml18:Mosbach2018LogitPM,
  title={Logit Pairing Methods Can Fool Gradient-Based Attacks},
  author={Marius Mosbach and Maksym Andriushchenko and Thomas Alexander Trost and Matthias Hein and Dietrich Klakow},
  booktitle={NeurIPS 2018 Workshop on Security in Machine Learning},
  year={2018},
  note ={\url{https://arxiv.org/abs/1810.12042}},
}

@article{arxiv21:Akhtar2021AdvancesIA,
  title={Advances in adversarial attacks and defenses in computer vision: A survey},
  author={Naveed Akhtar and Ajmal S. Mian and Navid Kardan and Mubarak Shah},
  journal={ArXiv},
  year={2021},
  note ={\url{https://arxiv.org/abs/2108.00401}},
}

@inproceedings{iclr18:Raghunathan2018CertifiedDA,
  title={Certified Defenses against Adversarial Examples},
  author={Aditi Raghunathan and Jacob Steinhardt and Percy Liang},
  booktitle={International Conference on Learning Representations},
  year={2018},
  note ={\url{https://arxiv.org/abs/1801.09344}},
}

@article{icml18:Uesato2018AdversarialRA,
  title={Adversarial Risk and the Dangers of Evaluating Against Weak Attacks},
  author={Jonathan Uesato and Brendan O'Donoghue and A{\"a}ron van den Oord and Pushmeet Kohli},
  journal={International Conference on Machine Learning},
  year={2018},
  note ={\url{https://arxiv.org/abs/1802.05666}},
}

@article{cvpr18:Liao2018DefenseAA,
  title={Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser},
  author={Fangzhou Liao and Ming Liang and Yinpeng Dong and Tianyu Pang and Jun Zhu and Xiaolin Hu},
  journal={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2018},
  pages={1778-1787}
}

@article{arxiv18:Athalye2018OnTR,
  title={On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses},
  author={Anish Athalye and Nicholas Carlini},
  journal={ArXiv},
  year={2018},
  volume={abs/1804.03286}
}

@INPROCEEDINGS{eurosp16:PapernotLimitations,
  author={Papernot, Nicolas and McDaniel, Patrick and Jha, Somesh and Fredrikson, Matt and Celik, Z. Berkay and Swami, Ananthram},
  booktitle={2016 IEEE European Symposium on Security and Privacy (EuroS P)}, 
  title={The Limitations of Deep Learning in Adversarial Settings}, 
  year={2016},
  volume={},
  number={},
  pages={372-387},
  doi={10.1109/EuroSP.2016.36}}

@inproceedings{iclr17:Kurakin2017AdversarialML,
  title={Adversarial Machine Learning at Scale},
  author={Alexey Kurakin and Ian J. Goodfellow and Samy Bengio},
  booktitle={International Conference on Learning Representations},
  year={2017},
  note ={\url{https://arxiv.org/abs/1611.01236}},
}

@inproceedings{iclr20:Zhang2020TowardsSA,
  title={Towards Stable and Efficient Training of Verifiably Robust Neural Networks},
  author={Huan Zhang and Hongge Chen and Chaowei Xiao and Bo Li and Duane S. Boning and Cho-Jui Hsieh},
  booktitle={International Conference on Learning Representations},
  year={2020},
  note ={\url{https://arxiv.org/abs/1906.06316}},
}

@inproceedings{eccv20:Andriushchenko2020SquareAA,
  title={Square Attack: a query-efficient black-box adversarial attack via random search},
  author={Maksym Andriushchenko and Francesco Croce and Nicolas Flammarion and Matthias Hein},
  booktitle={ECCV},
  year={2020}
}

@inproceedings{icml20:Croce2020Minimally,
  title={Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack},
  author={Francesco Croce and Matthias Hein},
  booktitle={International Conference on Machine Learning},
  year={2020},
  note ={\url{https://arxiv.org/abs/1907.02044}},
}

@misc{arxiv18:Xiao2018GeneratingAE,
  title={Generating Adversarial Examples with Adversarial Networks},
  author={Chaowei Xiao and Bo Li and Jun-Yan Zhu and Warren He and M. Liu and Dawn Xiaodong Song},
  journal={ArXiv},
  year={2018},
  volume={abs/1801.02610}
}
@inproceedings{aisec17:Chen2017ZOOZO,
  title={ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models},
  author={Pin-Yu Chen and Huan Zhang and Yash Sharma and Jinfeng Yi and Cho-Jui Hsieh},
  booktitle={Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
  year={2017}
}

@inproceedings{asiaccs17:Papernot2016PracticalBA,
  title={Practical Black-Box Attacks against Deep Learning Systems using Adversarial Examples},
  author={Nicolas Papernot and Patrick Mcdaniel and Ian J. Goodfellow and Somesh Jha and Z. Berkay Celik and Ananthram Swami},
  booktitle={ACM ASIA Conference on Computer and Communications Security},
  year={2017},
  note ={\url{https://arxiv.org/abs/1602.02697}},
}

@inproceedings{iclr17:metzen2017detecting,
  title={On detecting adversarial perturbations},
  author={Metzen, Jan Hendrik and Genewein, Tim and Fischer, Volker and Bischoff, Bastian},
  year={2017},
  booktitle={International Conference on Learning Representations},
  note ={\url{https://arxiv.org/abs/1702.04267}},
}

@inproceedings{iclr15:adversarial,
     author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
      title={Explaining and Harnessing Adversarial Examples}, 
     year={2015},
    booktitle={International Conference on Learning Representations},
    note ={\url{https://arxiv.org/abs/1412.6572}},
}

@inproceedings{icml20:autopgd,
  author={Croce, Francesco and Hein, Matthias},
  title={Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
  booktitle={International Conference on Machine Learning},
  year={2020},
  note ={\url{https://arxiv.org/abs/2003.01690}},
}

@misc{arxiv21:robustbench,
  author =       {Francesco Croce and Maksym Andriushchenko and Vikash Sehwag and Edoardo Debenedetti and Nicolas Flammarion and Mung Chiang and Prateek Mittal and Matthias Hein},
  title =        {RobustBench: a standardized adversarial robustness benchmark},
  archivePrefix = "arXiv",
  eprint =       {2010.09670},
  primaryClass = "cs.LG",
  year =         2021,
  month =        jun,
  edition = "v2",
  url =          {https://arxiv.org/abs/2010.09670},
  howpublished = {arXiv preprint 2010.09670},
}

@inproceedings{iclr20:DSLH20,
  author={Gavin Weiguang Ding and Yash Sharma and Kry Yik Chau Lui and Ruitong Huang},
  title={MMA Training: Direct Input Space Margin Maximization through Adversarial Training},
  booktitle={International Conference on Learning Representations},
  year={2020},
  note ={\url{https://openreview.net/forum?id=HkeryxBtPB}},
}

@inproceedings{iclr20:WRK20,
  author={Eric Wong and Leslie Rice and J. Zico Kolter},
  title={Fast is better than free: Revisiting adversarial training
},
  booktitle={International Conference on Learning Representations},
  year={2020},
  note ={\url{https://arxiv.org/abs/2001.03994}},
}

@inproceedings{icml19:HLM19,
  author={Dan Hendrycks and Kimin Lee and Mantas Mazeika},
  title={Using Pre-Training Can Improve Model Robustness and Uncertainty},
  booktitle={International Conference on Machine Learning},
  year={2019},
  note ={\url{https://arxiv.org/abs/1901.09960}},
}

@inproceedings{iclr20:WZYBMG20,
  author={Yisen Wang and Difan Zou and Jinfeng Yi and James Bailey and Xingjun Ma and Quanquan Gu},
  title={Improving Adversarial Robustness Requires Revisiting Misclassified Examples},
  booktitle={International Conference on Learning Representations},
  year={2020},
  note ={\url{https://openreview.net/forum?id=rklOg6EFwS}},
}

@inproceedings{NeurIPS20:SWMJ20,
  author={Vikash Sehwag and Shiqi Wang and Prateek Mittal and Suman Jana},
  title={HYDRA: Pruning Adversarially Robust Neural Networks},
  booktitle={Conference on Neural Information Processing Systems},
  year={2020},
  note ={\url{https://arxiv.org/abs/2002.10509}},
}

@inproceedings{NeurIPS19:CRSLD19,
  author={Yair Carmon and Aditi Raghunathan and Ludwig Schmidt and Percy Liang and John C. Duchi},
  title={Unlabeled Data Improves Adversarial Robustness},
  booktitle={Conference on Neural Information Processing Systems},
  year={2019},
  note ={\url{https://arxiv.org/abs/1905.13736}},
}

@inproceedings{NeurIPS20:WXW20,
  author={Dongxian Wu and Shu-tao Xia and Yisen Wang},
  title={Adversarial Weight Perturbation Helps Robust Generalization},
  booktitle={Conference on Neural Information Processing Systems},
  year={2020},
  note ={\url{https://arxiv.org/abs/2004.05884}},
}

@inproceedings{NeurIPS20:SIEKM20,
  author={Hadi Salman and Andrew Ilyas and Logan Engstrom and Ashish Kapoor and Aleksander Madry},
  title={Do Adversarially Robust ImageNet Models Transfer Better?},
  booktitle={Conference on Neural Information Processing Systems},
  year={2020},
  note ={\url{https://arxiv.org/abs/2007.08489}},
}

@InProceedings{Oakland17:CarliniWagner,
  author =       {Nicholas Carlini and David Wagner},
  title =        {Towards Evaluating the Robustness of Neural Networks},
  booktitle =    {IEEE Symposium on Security and Privacy},
  year =         2017,
  pages =        {39-57},
  volume= {1},
  note =         {\url{https://arxiv.org/abs/1608.04644}},
}

@inproceedings{iclr18:PGD,
  author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
  title={Towards Deep Learning Models Resistant to Adversarial Attacks},
  booktitle={International Conference on Learning Representations},
  year={2018},
  note ={\url{https://arxiv.org/pdf/1706.06083}},
}

@misc{arxiv19:PixelNorm,
  author =       {Ayon Sen and Xiaojin Zhu and Liam Marshall and Robert Nowak},
  title =        {Should Adversarial Attacks Use Pixel p-Norm?},
  archivePrefix = "arXiv",
  eprint =       {1906.02439},
  primaryClass = "cs.LG",
  year =         2019,
  month =        jun,
  url =          {https://arxiv.org/abs/1906.02439},
  howpublished = {arXiv preprint 1906.02439},
}

@inproceedings{CVPRW18:Suitability,
  author={Mahmood Sharif and Lujo Bauer and Michael K. Reiter},
  title={On the Suitability of L{p}-norms for Creating and Preventing Adversarial Examples},
  booktitle={Conference on Computer Vision and Pattern Recognition Workshops},
  year={2018},
  note ={\url{https://arxiv.org/abs/1802.09653}},
}
 
@inproceedings{NeurIPS19:FreeTraining,
  author={Ali Shafahi and Mahyar Najibi and Amin Ghiasi and Zheng Xu and John Dickerson and Christoph Studer and Larry S. Davis and Gavin Taylor and Tom Goldstein},
  title={Adversarial Training for Free!},
  booktitle={Conference on Neural Information Processing Systems},
  year={2019},
  note ={\url{https://arxiv.org/abs/1904.12843}},
}

@inproceedings{NeurIPS20:Initializations,
  title={Diversity can be transferred: {O}utput diversification for white-and black-box attacks},
  author={Tashiro, Yusuke and Song, Yang and Ermon, Stefano},
  booktitle={Conference on Neural Information Processing Systems},
  year={2020},
  note={\url{}}
}	  

@inproceedings{ASA67:Normal,
  author =       {Edward E. Cureton},
  title =        {The Normal Approximation to the Signed-Rank Sampling Distribution When Zero Differences are Present},
  booktitle =    {Journal of the American Statistical Association},
  year =         1967,
  pages =        {1068-1069},
  volume= {62},
  note =         {\url{https://www.tandfonline.com/doi/abs/10.1080/01621459.1967.10500917}},
}

@inproceedings{iclr14:Intriguing,
  author={Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus},
  title={Intriguing properties of neural networks},
  booktitle={International Conference on Learning Representations},
  year={2014},
  note ={\url{https://arxiv.org/abs/1312.6199}},
}

@article{arxiv20:uncover,
  title={Uncovering the limits of adversarial training against norm-bounded adversarial examples},
  author={Gowal, Sven and Qin, Chongli and Uesato, Jonathan and Mann, Timothy and Kohli, Pushmeet},
  journal={arXiv preprint arXiv:2010.03593},
  year={2020}
}

@article{arxiv21:fixing,
  title={Fixing data augmentation to improve adversarial robustness},
  author={Rebuffi, Sylvestre-Alvise and Gowal, Sven and Calian, Dan A and Stimberg, Florian and Wiles, Olivia and Mann, Timothy},
  journal={arXiv preprint arXiv:2103.01946},
  year={2021}
}

@inproceedings{ECML13:Info,
  author={Battista Biggio and Igino Corona and Davide Maiorca and Blaine Nelson and Nedim Srndic and Pavel Laskov and Giorgio Giacinto and Fabio Roli},
  xtitle={IEvasion Attacks against Machine Learning at Test Time},
  title={Evasion Attacks against Machine Learning at Test Time},
  booktitle={European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases},
  year={2013},
  note ={\url{https://arxiv.org/abs/1708.06131}},
}
@inproceedings{CVPR16:Deepfool,
  author={Seyed-Mohsen Moosavi-Dezfooli and Alhussein Fawzi and Pascal Frossard},
  title={DeepFool: a simple and accurate method to fool deep neural networks},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  year={2016},
  note ={\url{https://arxiv.org/abs/1511.04599}},
}
@inproceedings{CVPR18:Greybox,
  author={Seyed-Mohsen Moosavi-Dezfooli and Ashish Shrivastava and Oncel Tuzel},
  title={Divide, Denoise, and Defend against Adversarial Attacks},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  year={2018},
  note ={\url{https://arxiv.org/abs/1802.06806}},
}

@inproceedings{iclr18:PixelDefend,
  author={Yang Song and Taesup Kim and Sebastian Nowozin and Stefano Ermon and Nate Kushman},
  title={PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples},
  booktitle={International Conference on Learning Representations},
  year={2018},
  note ={\url{https://arxiv.org/abs/1710.10766}},
}

@inproceedings{ICML20:lpnorms,
  title={Fundamental tradeoffs between invariance and sensitivity to adversarial perturbations},
  author={Florian Tram{\`e}r and Jens Behrmann and Nicholas Carlini and Nicolas Papernot and J{\"o}rn-Henrik Jacobsen},
  booktitle={International Conference on Machine Learning},
  xpages={9561--9571},
  year={2020},
  note ={\url{https://arxiv.org/abs/2002.04599}}

}

@inproceedings{NeurIPS17:Competition,
  author={Alexey Kurakin and Ian Goodfellow and Samy Bengio and Yinpeng Dong and Fangzhou Liao and Ming Liang and Tianyu Pang and Jun Zhu and Xiaolin Hu and Cihang Xie and Jianyu Wang and Zhishuai Zhang and Zhou Ren and Alan Yuille and Sangxia Huang and Yao Zhao and Yuzhe Zhao and Zhonglin Han and Junjiajia Long and Yerkebulan Berdibekov and Takuya Akiba and Seiya Tokui and Motoki Abe},
  title={Adversarial Attacks and Defences Competition},
  booktitle={Conference on Neural Information Processing Systems},
  year={2017},
  note ={\url{https://arxiv.org/abs/1804.00097}},
}

@inproceedings{iclr17:BasicIterative,
  author={Alexey Kurakin and Ian Goodfellow and Samy Bengio},
  title={Adversarial examples in the physical world},
  booktitle={International Conference on Learning Representations Workshop},
  year={2017},
  note ={\url{https://arxiv.org/abs/1607.02533}},
}

@inproceedings{CVPR18:Momentum,
  author={Yinpeng Dong and Fangzhou Liao and Tianyu Pang and Hang Su and Jun Zhu and Xiaolin Hu and Jianguo Li},
  title={Boosting Adversarial Attacks with Momentum},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  year={2018},
  note ={\url{https://arxiv.org/abs/1710.06081}},
}

@inproceedings{iclr18:Random,
  author={Florian Tram{\`e}r and Alexey Kurakin and Nicolas Papernot and Ian Goodfellow and Dan Boneh and Patrick McDaniel},
  title={Ensemble Adversarial Training: Attacks and Defenses},
  booktitle={International Conference on Learning Representations},
  year={2018},
  note ={\url{https://arxiv.org/abs/1705.07204}},
}

@inproceedings{ndss18:Squeezing,
  title={Feature squeezing: {D}etecting adversarial examples in deep neural networks},
  author={Xu, Weilin and Evans, David and Qi, Yanjun},
  xjournal={arXiv preprint arXiv:1704.01155},
  booktitle = {The Network and Distributed System Security Symposium (NDSS)},
  year={2018},
  note = {\url{https://arxiv.org/abs/1704.01155}}
}

@inproceedings{icml18:Obfuscated,
  title={Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples},
  author={Athalye, Anish and Carlini, Nicholas and Wagner, David},
  booktitle={International conference on machine learning},
  xpages={274--283},
  year={2018},
  xorganization={PMLR},
  note={\url{https://arxiv.org/abs/1802.00420}}
}
	    
@inproceedings{iclr18:DGAN,
  title={Defense-{GAN}: {P}rotecting classifiers against adversarial attacks using generative models},
  author={Samangouei, Pouya and Kabkab, Maya and Chellappa, Rama},
  xjournal={arXiv preprint arXiv:1805.06605},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{iclr18:JPEG,
  title={Countering adversarial images using input transformations},
  author={Guo, Chuan and Rana, Mayank and Cisse, Moustapha and Van Der Maaten, Laurens},
  xjournal={arXiv preprint arXiv:1711.00117},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{woot17:ensembles,
  title={Adversarial example defense: Ensembles of weak defenses are not strong},
  author={He, Warren and Wei, James and Chen, Xinyun and Carlini, Nicholas and Song, Dawn},
  booktitle={11th $\{$USENIX$\}$ workshop on offensive technologies ($\{$WOOT$\}$ 17)},
  year={2017}
}

@inproceedings{aisec17:detection,
  title={Adversarial examples are not easily detected: {B}ypassing ten detection methods},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={Proceedings of the 10th ACM workshop on artificial intelligence and security (AISec)},
  xpages={3--14},
  year={2017}
}
	  
@inproceedings{iclr18:LID,
  title={Characterizing adversarial subspaces using local intrinsic dimensionality},
  author={Ma, Xingjun and Li, Bo and Wang, Yisen and Erfani, Sarah M and Wijewickrema, Sudanthi and Schoenebeck, Grant and Song, Dawn and Houle, Michael E and Bailey, James},
  xjournal={arXiv preprint arXiv:1801.02613},  
  booktitle={International Conference on Learning Representations},
  year={2018}
}
	
@article{arxiv17:Detect,
  title={Detecting adversarial samples from artifacts},
  author={Feinman, Reuben and Curtin, Ryan R and Shintre, Saurabh and Gardner, Andrew B},
  journal={arXiv preprint arXiv:1703.00410},
  year={2017}
}
	
@inproceedings{cav19:Marabou,
  title={The marabou framework for verification and analysis of deep neural networks},
  author={Katz, Guy and Huang, Derek A and Ibeling, Duligur and Julian, Kyle and Lazarus, Christopher and Lim, Rachel and Shah, Parth and Thakoor, Shantanu and Wu, Haoze and Zelji{\'c}, Aleksandar and others},
  booktitle={International Conference on Computer Aided Verification},
  xpages={443--452},
  year={2019},
  xorganization={Springer}
}

@article{popl19:DeepPoly,
  title={An abstract domain for certifying neural networks},
  author={Singh, Gagandeep and Gehr, Timon and P{\"u}schel, Markus and Vechev, Martin},
  journal={Proceedings of the ACM on Programming Languages},
  volume={3},
  number={POPL},
  pages={1--30},
  year={2019},
  xpublisher={ACM New York, NY, USA}
}

@inproceedings{icml19:Provable,
  title={Provable defenses against adversarial examples via the convex outer adversarial polytope},
  author={Wong, Eric and Kolter, Zico},
  booktitle={International Conference on Machine Learning},
  xpages={5286--5295},
  year={2018},
  xorganization={PMLR}
}

@inproceedings{icml19:CSmooth,
  title={Certified adversarial robustness via randomized smoothing},
  author={Cohen, Jeremy and Rosenfeld, Elan and Kolter, Zico},
  booktitle={International Conference on Machine Learning},
  xpages={1310--1320},
  year={2019},
  xorganization={PMLR}
}

@inproceedings{oakland19:DPDefense,
  title={Certified robustness to adversarial examples with differential privacy},
  author={Lecuyer, Mathias and Atlidakis, Vaggelis and Geambasu, Roxana and Hsu, Daniel and Jana, Suman},
  booktitle={2019 IEEE Symposium on Security and Privacy (SP)},
  xpages={656--672},
  year={2019},
  xorganization={IEEE}
}

@inproceedings{icml20:CSmooth,
  title={Curse of dimensionality on randomized smoothing for certifiable robustness},
  author={Kumar, Aounon and Levine, Alexander and Goldstein, Tom and Feizi, Soheil},
  booktitle={International Conference on Machine Learning},
  xpages={5458--5467},
  year={2020},
  xorganization={PMLR}
}

@inproceedings{iclr15:Adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  xjournal={arXiv preprint arXiv:1412.6980},
  booktitle={International Conference on Learning Representations},
  year={2015},
  note={\url{https://arxiv.org/abs/1412.6980}}
}

@article{arxiv20:CompareDefenses ,
  title={Towards Understanding Fast Adversarial Training},
  author={Bai Li, Shiqi Wang, Suman Jana and Lawrence Carin},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.03089}
}

@article{stat59:Pratt ,
  title={Remarks on Zeros and Ties in the Wilcoxon Signed Rank Procedures },
  author={John W. Pratt},
  journal={Journal of the American Statistical Association},
  year={1959},
  volume={54},
  xpages={655--667}
}

@article{stat45:Wilcoxon ,
  title={Individual Comparisons by Ranking Methods},
  author={Frank Wilcoxon},
  journal={Biometrics Bulletin},
  year={1945},
  volume={1},
  xpages={80--83}
}

@inproceedings{ihmmsec20:linfrounding,
  title={What if Adversarial Samples were Digital Images?},
  author={Bonnet, Beno{\^i}t and Furon, Teddy and Bas, Patrick},
  	booktitle={IH{\&}MMSEC},
  	year={2020}  
}

@article{arxiv19:nonsign,
  title={An Alternative Surrogate Loss for {PGD}-based Adversarial Testing},
  author={Sven Gowal and Jonathan Uesato and Chongli Qin and Po-Sen Huang and Timothy Mann and Pushmeet Kohli},
journal={arXiv:1910.09338},	
year={2019}  
}
\end{filecontents}
