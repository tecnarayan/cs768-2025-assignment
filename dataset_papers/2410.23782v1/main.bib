% Long form of conference & journal abbreviations -- especially for camera ready
@String(PAMI  = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV  = {Int. J. Comput. Vis.})
@String(CVPR  = {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV  = {Int. Conf. Comput. Vis.})
@String(ECCV  = {Eur. Conf. Comput. Vis.})
@String(NeurIPS = {Adv. Neural Inform. Process. Syst.})
@String(ICML  = {Int. Conf. Mach. Learn.})
@String(ICLR  = {Int. Conf. Learn. Represent.})
@String(ACCV  = {Asian Conf. Comput. Vis.})
@String(BMVC  = {Brit. Mach. Vis. Conf.})
@String(CVPRW = {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {IEEE Int. Conf. Image Process.})
@String(ICPR  = {Int. Conf. Pattern Recog.})
@String(ICASSP=	{ICASSP})
@String(ICME  = {Int. Conf. Multimedia and Expo})
@String(JMLR  = {J. Mach. Learn. Res.})
@String(TMLR  = {Trans. Mach. Learn Res.})
@String(TOG   = {ACM Trans. Graph.})
@String(TIP   = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TCSVT = {IEEE Trans. Circuit Syst. Video Technol.})
@String(TMM   = {IEEE Trans. Multimedia})
@String(ACMMM = {ACM Int. Conf. Multimedia})
@String(PR    = {Pattern Recognition})

@String(MNI	  = {Nature Mach. Intell.})
@String(SPL	  = {IEEE Sign. Process. Letters})
@String(VR    = {Vis. Res.})
@String(JOV	  = {J. Vis.})
@String(TVC   = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF   = {Comput. Graph. Forum})
@String(CVM   = {Computational Visual Media})


% Short form of conference & journal abbreviations -- especially for submission version
% if desired, remove these macros in favor of the above ones
@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NeurIPS = {NeurIPS})
@String(ICML  = {ICML})
@String(ICLR  = {ICLR})
@String(ACCV  = {ACCV})
@String(BMVC  =	{BMVC})
@String(CVPRW = {CVPRW})
@String(AAAI  = {AAAI})
@String(IJCAI = {IJCAI})
@String(ICIP  = {ICIP})
@String(ICPR  = {ICPR})
@String(ICASSP=	{ICASSP})
@String(ICME  =	{ICME})
@String(JMLR  = {JMLR})
@String(TMLR  = {TMLR})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(PR    = {PR})


# Conferences
@inproceedings{ridnik2021imagenet,
  title={{ImageNet}-{21K} pretraining for the masses},
  author={Ridnik, Tal and Ben-Baruch, Emanuel and Noy, Asaf and Zelnik-Manor, Lihi},
  booktitle=NeurIPS,
  year={2021}
}

@inproceedings{dosovitskiy2020vit,
  title={An image is worth 16x16 words: {T}ransformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  booktitle=ICLR,
  year={2021}
}

@inproceedings{li2023vidtome,
  title={{VidToMe}: {V}ideo Token Merging for Zero-Shot Video Editing},
  author={Li, Xirui and Ma, Chao and Yang, Xiaokang and Yang, Ming-Hsuan},
  booktitle=CVPR,
  year={2024}
}

@inproceedings{bolya2023tomesd,
  title={Token Merging for Fast Stable Diffusion},
  author={Bolya, Daniel and Hoffman, Judy},
  booktitle={CVPR Workshop},
  year={2023}
}

@inproceedings{ren2023testa,
  title={{TESTA}: {T}emporal-Spatial Token Aggregation for Long-form Video-Language Understanding},
  author={Ren, Shuhuai and Chen, Sishuo and Li, Shicheng and Sun, Xu and Hou, Lu},
  booktitle={EMNLP},
  year={2023}
}

@inproceedings{fan2023motion,
  title={Motion-guided masking for spatiotemporal representation learning},
  author={Fan, David and Wang, Jue and Liao, Shuai and Zhu, Yi and Bhat, Vimal and Santos-Villalobos, Hector and MV, Rohith and Li, Xinyu},
  booktitle=ICCV,
  year={2023}
}

@inproceedings{bolya2022tome,
  title={Token {M}erging: {Y}our {ViT} but faster},
  author={Bolya, Daniel and Fu, Cheng-Yang and Dai, Xiaoliang and Zhang, Peizhao and Feichtenhofer, Christoph and Hoffman, Judy},
  booktitle=ICLR,
  year={2022}
}

@inproceedings{wu2018compressed,
  title={Compressed video action recognition},
  author={Wu, Chao-Yuan and Zaheer, Manzil and Hu, Hexiang and Manmatha, R and Smola, Alexander J and Kr{\"a}henb{\"u}hl, Philipp},
  booktitle=CVPR,
  year={2018}
}

@inproceedings{patrick2021orthoformer,
  title={Keeping your eye on the ball: {T}rajectory attention in video transformers},
  author={Patrick, Mandela and Campbell, Dylan and Asano, Yuki and Misra, Ishan and Metze, Florian and Feichtenhofer, Christoph and Vedaldi, Andrea and Henriques, Joao F.},
  booktitle=NeurIPS,
  year={2021}
}

@inproceedings{choromanski2020performer,
  title={Rethinking attention with performers},
  author={Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and Belanger, David and Colwell, Lucy J. and Weller, Adrian},
  booktitle=ICLR,
  year={2021}
}

@inproceedings{wang2023s5,
  title={Selective structured state-spaces for long-form video understanding},
  author={Wang, Jue and Zhu, Wentao and Wang, Pichao and Yu, Xiang and Liu, Linda and Omar, Mohamed and Hamid, Raffay},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{islam2022vis4mer,
  title={Long movie clip classification with state-space video models},
  author={Islam, Md Mohaiminul and Bertasius, Gedas},
  booktitle=ECCV,
  year={2022}
}

@inproceedings{gu2021s4,
  title={Efficiently modeling long sequences with structured state spaces},
  author={Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  booktitle=ICLR,
  year={2022}
}

@inproceedings{wu2021lvu,
  title={Towards long-form video understanding},
  author={Wu, Chao-Yuan and Philipp Kr\"{a}henb\"{u}hl},
  booktitle=CVPR,
  year={2021}
}

@inproceedings{tang2019coin,
  title={{COIN}: {A} large-scale dataset for comprehensive instructional video analysis},
  author={Tang, Yansong and Ding, Dajun and Rao, Yongming and Zheng, Yu and Zhang, Danyang and Zhao, Lili and Lu, Jiwen and Zhou, Jie},
  booktitle=CVPR,
  year={2019}
}

@inproceedings{kuehne2014breakfast,
  title={The language of actions: {R}ecovering the syntax and semantics of goal-directed human activities},
  author={Kuehne, Hilde and Arslan, Ali and Serre, Thomas},
  booktitle=CVPR,
  year={2014}
}

@inproceedings{liu2021swin,
  title={Swin transformer: {H}ierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle=ICCV,
  year={2021}
}

@inproceedings{kay2017kinetics,
  title={The kinetics human action video dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and Suleyman, Mustafa and Zisserman, Andrew},
  booktitle={arXiv},
  year={2017}
}

@inproceedings{hussein2019timeception,
  title={Timeception for complex action recognition},
  author={Hussein, Noureldien and Gavves, Efstratios and Smeulders, Arnold WM.},
  booktitle=CVPR,
  year={2019}
}

@inproceedings{hussein2019videograph,
  title={Video{G}raph: {R}ecognizing minutes-long human activities in videos},
  author={Hussein, Noureldien and Gavves, Efstratios and Smeulders, Arnold WM.},
  booktitle={ICCV Workshop},
  year={2019}
}

@inproceedings{zhou2021graph,
  title={Graph-based high-order relation modeling for long-term action recognition},
  author={Zhou, Jiaming and Lin, Kun-Yu and Li, Haoxin and Zheng, Wei-Shi},
  booktitle=CVPR,
  year={2021}
}

@inproceedings{lin2022learning,
  title={Learning to recognize procedural activities with distant supervision},
  author={Lin, Xudong and Petroni, Fabio and Bertasius, Gedas and Rohrbach, Marcus and Chang, Shih-Fu and Torresani, Lorenzo},
  booktitle=CVPR,
  year={2022}
}

@inproceedings{gotmare2018closer,
  title={A closer look at deep learning heuristics: {L}earning rate restarts, warmup and distillation},
  author={Gotmare, Akhilesh and Keskar, Nitish Shirish and Xiong, Caiming and Socher, Richard},
  booktitle={arXiv},
  year={2018}
}

@inproceedings{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={arXiv},
  year={2017}
}

@inproceedings{sun2019videobert,
  title={{VideoBERT}: {A} joint model for video and language representation learning},
  author={Sun, Chen and Myers, Austin and Vondrick, Carl and Murphy, Kevin and Schmid, Cordelia},
  booktitle=ICCV,
  year={2019}
}

# Journals
@article{tang2020comprehensive,
  title={Comprehensive instructional video analysis: {The COIN} dataset and performance evaluation},
  author={Tang, Yansong and Lu, Jiwen and Zhou, Jie},
  journal=PAMI,
  volume={43},
  number={9},
  pages={3138--3153},
  year={2020}
}



# Book, etc
@book{richardson2004h,
  title={H. 264 and {MPEG-4} video compression: video coding for next-generation multimedia},
  author={Richardson, Iain E.},
  year={2004},
}

@article{wien2015high,
  title={High efficiency video coding},
  author={Wien, Mathias},
  journal={Coding Tools and Specification},
  volume={24},
  year={2015}
}

@misc{movieclip,
    title = {{MovieClips}},
    url = {https://www.movieclips.com/}
}
@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})

@inproceedings{komodakis2018unsupervised,
  title={Unsupervised representation learning by predicting image rotations},
  author={Komodakis, Nikos and Gidaris, Spyros},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@inproceedings{pathak2016context,
  title={Context encoders: Feature learning by inpainting},
  author={Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2536--2544},
  year={2016}
}

@inproceedings{vincent2008extracting,
  title={Extracting and composing robust features with denoising autoencoders},
  author={Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre-Antoine},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={1096--1103},
  year={2008}
}

@article{song2018self,
  title={Self-supervised video hashing with hierarchical binary auto-encoder},
  author={Song, Jingkuan and Zhang, Hanwang and Li, Xiangpeng and Gao, Lianli and Wang, Meng and Hong, Richang},
  journal={IEEE Transactions on Image Processing},
  volume={27},
  number={7},
  pages={3210--3221},
  year={2018},
  publisher={IEEE}
}

@inproceedings{noroozi2016unsupervised,
  title={Unsupervised learning of visual representations by solving jigsaw puzzles},
  author={Noroozi, Mehdi and Favaro, Paolo},
  booktitle={European conference on computer vision},
  pages={69--84},
  year={2016},
  organization={Springer}
}

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9729--9738},
  year={2020}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent: A new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre H and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Avila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and others},
  journal={arXiv preprint arXiv:2006.07733},
  year={2020}
}

@article{chen2020improved,
  title={Improved baselines with momentum contrastive learning},
  author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  journal={arXiv preprint arXiv:2003.04297},
  year={2020}
}

@article{chen2020exploring,
  title={Exploring Simple Siamese Representation Learning},
  author={Chen, Xinlei and He, Kaiming},
  journal={arXiv preprint arXiv:2011.10566},
  year={2020}
}

@article{chen2021empirical,
  title={An empirical study of training self-supervised visual transformers},
  author={Chen, Xinlei and Xie, Saining and He, Kaiming},
  journal={arXiv preprint arXiv:2104.02057},
  year={2021}
}


@inproceedings{bertasius2021space,
  author    = {Gedas Bertasius and
               Heng Wang and
               Lorenzo Torresani},
  title     = {Is Space-Time Attention All You Need for Video Understanding?},
  booktitle = {ICML},
  year      = {2021}
}


@article{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  journal={arXiv preprint arXiv:2104.14294},
  year={2021}
}


@InProceedings{arnab2021vivit,
    author    = {Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu\v{c}i\'c, Mario and Schmid, Cordelia},
    title     = {ViViT: A Video Vision Transformer},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {6836-6846}
}



@InProceedings{fan2021multiscale,
    author    = {Fan, Haoqi and Xiong, Bo and Mangalam, Karttikeya and Li, Yanghao and Yan, Zhicheng and Malik, Jitendra and Feichtenhofer, Christoph},
    title     = {Multiscale Vision Transformers},
    booktitle = ICCV,
    year      = {2021}
}

@article{akbari2021vatt,
  title={{VATT}: {T}ransformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text},
  author={Akbari, Hassan and Yuan, Linagzhe and Qian, Rui and Chuang, Wei-Hong and Chang, Shih-Fu and Cui, Yin and Gong, Boqing},
  journal={arXiv},
  year={2021}
}

@article{recasens2021broaden,
  title={Broaden Your Views for Self-Supervised Video Learning},
  author={Recasens, Adri{\`a} and Luc, Pauline and Alayrac, Jean-Baptiste and Wang, Luyu and Strub, Florian and Tallec, Corentin and Malinowski, Mateusz and Patraucean, Viorica and Altch{\'e}, Florent and Valko, Michal and others},
  journal={arXiv preprint arXiv:2103.16559},
  year={2021}
}

@article{han2020self,
  title={Self-supervised co-training for video representation learning},
  author={Han, Tengda and Xie, Weidi and Zisserman, Andrew},
  journal={arXiv preprint arXiv:2010.09709},
  year={2020}
}

@inproceedings{wang2020understanding,
  title={Understanding contrastive representation learning through alignment and uniformity on the hypersphere},
  author={Wang, Tongzhou and Isola, Phillip},
  booktitle={International Conference on Machine Learning},
  pages={9929--9939},
  year={2020},
  organization={PMLR}
}

@inproceedings{Feichtenhofer_large,
  author    = {Christoph Feichtenhofer and
               Haoqi Fan and
               Bo Xiong and
               Ross B. Girshick and
               Kaiming He},
  title     = {A Large-Scale Study on Unsupervised Spatiotemporal Representation
               Learning},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
               2021, virtual, June 19-25, 2021},
  pages     = {3299--3309},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2021}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal={arXiv preprint arXiv:1706.03762},
  year={2017}
}

@article{devlin2018bert,
  title={{BERT}: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv},
  year={2018}
}

@inproceedings{wang2018non,
  title={Non-local neural networks},
  author={Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7794--7803},
  year={2018}
}

@article{wang2020end,
  title={End-to-End Video Instance Segmentation with Transformers},
  author={Wang, Yuqing and Xu, Zhaoliang and Wang, Xinlong and Shen, Chunhua and Cheng, Baoshan and Shen, Hao and Xia, Huaxia},
  journal={arXiv preprint arXiv:2011.14503},
  year={2020}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European Conference on Computer Vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}

@inproceedings{huang2019ccnet,
  title={Ccnet: Criss-cross attention for semantic segmentation},
  author={Huang, Zilong and Wang, Xinggang and Huang, Lichao and Huang, Chang and Wei, Yunchao and Liu, Wenyu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={603--612},
  year={2019}
}

@inproceedings{zhang2020dynamic,
  title={Dynamic graph message passing networks},
  author={Zhang, Li and Xu, Dan and Arnab, Anurag and Torr, Philip HS},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3726--3735},
  year={2020}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{touvron2020training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:2012.12877},
  year={2020}
}
@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  pages={1097--1105},
  year={2012}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  number={2},
  year={2016},
  publisher={MIT press Cambridge}
}

@article{simonyan2014two,
  title={Two-stream convolutional networks for action recognition in videos},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1406.2199},
  year={2014}
}

@article{goodfellow2014generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.2661},
  year={2014}
}

@article{korbar2018cooperative,
  title={Cooperative learning of audio and video models from self-supervised synchronization},
  author={Korbar, Bruno and Tran, Du and Torresani, Lorenzo},
  journal={arXiv preprint arXiv:1807.00230},
  year={2018}
}

@inproceedings{feichtenhofer2019slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6202--6211},
  year={2019}
}

@inproceedings{tran2018closer,
  title={A closer look at spatiotemporal convolutions for action recognition},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={6450--6459},
  year={2018}
}
@article{caron2020unsupervised,
  title={Unsupervised learning of visual features by contrasting cluster assignments},
  author={Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
  journal={arXiv preprint arXiv:2006.09882},
  year={2020}
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}


@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={arXiv preprint arXiv:1912.01703},
  year={2019}
}


@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}

@article{goyal2017accurate,
  title={Accurate, large minibatch sgd: Training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}

@inproceedings{goyal2017something,
  title={The" something something" video database for learning and evaluating visual common sense},
  author={Goyal, Raghav and Ebrahimi Kahou, Samira and Michalski, Vincent and Materzynska, Joanna and Westphal, Susanne and Kim, Heuna and Haenel, Valentin and Fruend, Ingo and Yianilos, Peter and Mueller-Freitag, Moritz and others},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={5842--5850},
  year={2017},
  note = {The Something-Something dataset is licensed for non-commercial, research purposes at \url{https://developer.qualcomm.com/downloads/data-license-agreement-research-use?referrer=node/68935.}}
}

@inproceedings{carreira2017quo,
  title={Quo vadis, action recognition? a new model and the kinetics dataset},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle={proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6299--6308},
  year={2017}
}


@inproceedings{han2019video,
  title={Video representation learning by dense predictive coding},
  author={Han, Tengda and Xie, Weidi and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},
  pages={0--0},
  year={2019}
}

@inproceedings{feichtenhofer2020x3d,
  title={X3d: Expanding architectures for efficient video recognition},
  author={Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={203--213},
  year={2020}
}

@inproceedings{tran2019video,
  title={Video classification with channel-separated convolutional networks},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Feiszli, Matt},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5552--5561},
  year={2019}
}

@inproceedings{wang2019gods,
  title={Gods: Generalized one-class discriminative subspaces for anomaly detection},
  author={Wang, Jue and Cherian, Anoop},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8201--8211},
  year={2019}
}
@inproceedings{wang2018learning,
  title={Learning discriminative video representations using adversarial perturbations},
  author={Wang, Jue and Cherian, Anoop},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={685--701},
  year={2018}
}

@InProceedings{Goroshin_2015_ICCV,
author = {Goroshin, Ross and Bruna, Joan and Tompson, Jonathan and Eigen, David and LeCun, Yann},
title = {Unsupervised Learning of Spatiotemporally Coherent Metrics},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {December},
year = {2015}
}

@article{DBLP:journals/corr/IsolaZKA15,
  author    = {Phillip Isola and
               Daniel Zoran and
               Dilip Krishnan and
               Edward H. Adelson},
  title     = {Learning visual groups from co-occurrences in space and time},
  journal   = {CoRR},
  volume    = {abs/1511.06811},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.06811},
  archivePrefix = {arXiv},
  eprint    = {1511.06811},
  timestamp = {Mon, 13 Aug 2018 16:48:47 +0200},
}

@InProceedings{Agrawal_2015_ICCV,
author = {Agrawal, Pulkit and Carreira, Joao and Malik, Jitendra},
title = {Learning to See by Moving},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {December},
year = {2015}
}

@InProceedings{pmlr-v37-srivastava15,
  title = 	 {Unsupervised Learning of Video Representations using LSTMs},
  author = 	 {Srivastava, Nitish and Mansimov, Elman and Salakhudinov, Ruslan},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {843--852},
  year = 	 {2015},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/srivastava15.pdf},
}

@INPROCEEDINGS{7410677,
  author={Wang, Xiaolong and Gupta, Abhinav},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Unsupervised Learning of Visual Representations Using Videos}, 
  year={2015},
  volume={},
  number={},
  pages={2794-2802},
  doi={10.1109/ICCV.2015.320}}
  
@conference{Misra-2016-5596,
author = {Ishan Misra and C. Lawrence Zitnick and Martial Hebert},
title = {Shuffle and Learn: Unsupervised Learning using Temporal Order Verification},
booktitle = {Proceedings of (ECCV) European Conference on Computer Vision},
year = {2016},
month = {October},
pages = {527 - 544},
}

@article{DBLP:journals/corr/abs-2008-03800,
  author    = {Rui Qian and
               Tianjian Meng and
               Boqing Gong and
               Ming{-}Hsuan Yang and
               Huisheng Wang and
               Serge J. Belongie and
               Yin Cui},
  title     = {Spatiotemporal Contrastive Video Representation Learning},
  journal   = {CoRR},
  volume    = {abs/2008.03800},
  year      = {2020},
  url       = {https://arxiv.org/abs/2008.03800},
  archivePrefix = {arXiv},
  eprint    = {2008.03800},
  timestamp = {Fri, 14 Aug 2020 15:14:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2008-03800.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}



@inproceedings{sevilla2021only,
  title={Only time can tell: Discovering temporal data for temporal modeling},
  author={Sevilla-Lara, Laura and Zha, Shengxin and Yan, Zhicheng and Goswami, Vedanuj and Feiszli, Matt and Torresani, Lorenzo},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={535--544},
  year={2021}
}
@inproceedings{wang2020video,
  title={Video modeling with correlation networks},
  author={Wang, Heng and Tran, Du and Torresani, Lorenzo and Feiszli, Matt},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={352--361},
  year={2020}
}

@article{sharir2021image,
  title={An Image is Worth 16x16 Words, What is a Video Worth?},
  author={Sharir, Gilad and Noy, Asaf and Zelnik-Manor, Lihi},
  journal={arXiv preprint arXiv:2103.13915},
  year={2021}
}

@inproceedings{liu2020teinet,
  title={Teinet: Towards an efficient architecture for video recognition},
  author={Liu, Zhaoyang and Luo, Donghao and Wang, Yabiao and Wang, Limin and Tai, Ying and Wang, Chengjie and Li, Jilin and Huang, Feiyue and Lu, Tong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={07},
  pages={11669--11676},
  year={2020}
}


@inproceedings{wu2018compressed,
  title={Compressed video action recognition},
  author={Wu, Chao-Yuan and Zaheer, Manzil and Hu, Hexiang and Manmatha, R and Smola, Alexander J and Kr{\"a}henb{\"u}hl, Philipp},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6026--6035},
  year={2018}
}

@inproceedings{dai2017deformable,
  title={Deformable convolutional networks},
  author={Dai, Jifeng and Qi, Haozhi and Xiong, Yuwen and Li, Yi and Zhang, Guodong and Hu, Han and Wei, Yichen},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={764--773},
  year={2017}
}

@article{zhu2020deformable,
  title={Deformable detr: Deformable transformers for end-to-end object detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  journal={arXiv preprint arXiv:2010.04159},
  year={2020}
}


@article{liu2021video,
  title={Video swin transformer},
  author={Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
  journal={arXiv preprint arXiv:2106.13230},
  year={2021}
}

@article{beltagy2020longformer,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={arXiv preprint arXiv:2004.05150},
  year={2020}
}

@inproceedings{zaheer2020big,
  title={Big Bird: Transformers for Longer Sequences.},
  author={Zaheer, Manzil and Guruganesh, Guru and Dubey, Kumar Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others},
  booktitle={NeurIPS},
  year={2020}
}

@article{dong2021cswin,
  title={Cswin transformer: A general vision transformer backbone with cross-shaped windows},
  author={Dong, Xiaoyi and Bao, Jianmin and Chen, Dongdong and Zhang, Weiming and Yu, Nenghai and Yuan, Lu and Chen, Dong and Guo, Baining},
  journal={arXiv preprint arXiv:2107.00652},
  year={2021}
}

@article{roy2021efficient,
  title={Efficient content-based sparse attention with routing transformers},
  author={Roy, Aurko and Saffar, Mohammad and Vaswani, Ashish and Grangier, David},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={53--68},
  year={2021},
  publisher={MIT Press}
}

@article{kitaev2020reformer,
  title={Reformer: The efficient transformer},
  author={Kitaev, Nikita and Kaiser, {\L}ukasz and Levskaya, Anselm},
  journal={arXiv preprint arXiv:2001.04451},
  year={2020}
}

@inproceedings{feichtenhofer2016convolutional,
  title={Convolutional two-stream network fusion for video action recognition},
  author={Feichtenhofer, Christoph and Pinz, Axel and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1933--1941},
  year={2016}
}

@inproceedings{bilen2016dynamic,
  title={Dynamic image networks for action recognition},
  author={Bilen, Hakan and Fernando, Basura and Gavves, Efstratios and Vedaldi, Andrea and Gould, Stephen},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3034--3042},
  year={2016}
}

@inproceedings{cherian2017generalized,
  title={Generalized rank pooling for activity recognition},
  author={Cherian, Anoop and Fernando, Basura and Harandi, Mehrtash and Gould, Stephen},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3222--3231},
  year={2017}
}

@inproceedings{wang2016temporal,
  title={Temporal segment networks: Towards good practices for deep action recognition},
  author={Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Van Gool, Luc},
  booktitle={European conference on computer vision},
  pages={20--36},
  year={2016},
  organization={Springer}
}

@inproceedings{sun2018optical,
  title={Optical flow guided feature: A fast and robust motion representation for video action recognition},
  author={Sun, Shuyang and Kuang, Zhanghui and Sheng, Lu and Ouyang, Wanli and Zhang, Wei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1390--1399},
  year={2018}
}

@article{wang2018temporal,
  title={Temporal segment networks for action recognition in videos},
  author={Wang, Limin and Xiong, Yuanjun and Wang, Zhe and Qiao, Yu and Lin, Dahua and Tang, Xiaoou and Van Gool, Luc},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={11},
  pages={2740--2755},
  year={2018},
  publisher={IEEE}
}

@article{jabri2020space,
  title={Space-time correspondence as a contrastive random walk},
  author={Jabri, Allan and Owens, Andrew and Efros, Alexei A},
  journal={arXiv preprint arXiv:2006.14613},
  year={2020}
}

@inproceedings{teed2020raft,
  title={Raft: Recurrent all-pairs field transforms for optical flow},
  author={Teed, Zachary and Deng, Jia},
  booktitle={European conference on computer vision},
  pages={402--419},
  year={2020},
  organization={Springer}
}

@article{tolstikhin2021mlp,
  title={Mlp-mixer: An all-mlp architecture for vision},
  author={Tolstikhin, Ilya and Houlsby, Neil and Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Unterthiner, Thomas and Yung, Jessica and Keysers, Daniel and Uszkoreit, Jakob and Lucic, Mario and others},
  journal={arXiv preprint arXiv:2105.01601},
  year={2021}
}

@inproceedings{li2018resound,
  title={Resound: Towards action recognition without representation bias},
  author={Li, Yingwei and Li, Yi and Vasconcelos, Nuno},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={513--528},
  year={2018}
}

@article{damen2020rescaling,
  title={Rescaling egocentric vision},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Furnari, Antonino and Kazakos, Evangelos and Ma, Jian and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  journal={arXiv preprint arXiv:2006.13256},
  year={2020},
  note = {The Epic-Kitchens-100 dataset is licensed under the Creative Commons Attribution-NonCommercial 4.0 International License.}
}

@article{fan2019more,
  title={More is less: Learning efficient video representations by big-little network and depthwise temporal aggregation},
  author={Fan, Quanfu and Chen, Chun-Fu and Kuehne, Hilde and Pistoia, Marco and Cox, David},
  journal={arXiv preprint arXiv:1912.00869},
  year={2019}
}

@article{neimark2021video,
  title={Video transformer network},
  author={Neimark, Daniel and Bar, Omri and Zohar, Maya and Asselmann, Dotan},
  journal={arXiv preprint arXiv:2102.00719},
  year={2021}
}

@inproceedings{lin2019tsm,
  title={Tsm: Temporal shift module for efficient video understanding},
  author={Lin, Ji and Gan, Chuang and Han, Song},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7083--7093},
  year={2019}
}

@inproceedings{zhu2019deformable,
  title={Deformable convnets v2: More deformable, better results},
  author={Zhu, Xizhou and Hu, Han and Lin, Stephen and Dai, Jifeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9308--9316},
  year={2019}
}

@inproceedings{KarpathyEtAl:CVPR2014,
  title={Large-scale video classification with convolutional neural networks},
  author={Karpathy, Andrej and Toderici, George and Shetty, Sanketh and Leung, Thomas and Sukthankar, Rahul and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={1725--1732},
  year={2014}
}

@inproceedings{DuEtAl:ICCV2015,
  title={Learning spatiotemporal features with 3d convolutional networks},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4489--4497},
  year={2015}
}

@inproceedings{DuEtAl:CVPR2018,
  title={A closer look at spatiotemporal convolutions for action recognition},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={6450--6459},
  year={2018}
}

@inproceedings{XieEtAl:ECCV2018,
  title={Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs in video classification},
  author={Xie, Saining and Sun, Chen and Huang, Jonathan and Tu, Zhuowen and Murphy, Kevin},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={305--321},
  year={2018}
}

@article{JiEtAl:TPAMI2013,
  title={3D convolutional neural networks for human action recognition},
  author={Ji, Shuiwang and Xu, Wei and Yang, Ming and Yu, Kai},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={1},
  pages={221--231},
  year={2012},
  publisher={IEEE}
}


@inproceedings{SunEtAl:CVPR2018,
  title={Optical flow guided feature: A fast and robust motion representation for video action recognition},
  author={Sun, Shuyang and Kuang, Zhanghui and Sheng, Lu and Ouyang, Wanli and Zhang, Wei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1390--1399},
  year={2018}
}

@InProceedings{LeeEtAl:ECCV2018,
author = {Lee, Myunggi and Lee, Seungeui and Son, Sungjoon and Park, Gyutae and Kwak, Nojun},
title = {Motion Feature Network: Fixed Motion Filter for Action Recognition},
booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}

@inproceedings{hommos2018using,
  title={Using phase instead of optical flow for action recognition},
  author={Hommos, Omar and Pintea, Silvia L and Mettes, Pascal SM and van Gemert, Jan C},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV) Workshops},
  pages={0--0},
  year={2018}
}

@InProceedings{Lin_2019_ICCV,
author = {Lin, Ji and Gan, Chuang and Han, Song},
title = {TSM: Temporal Shift Module for Efficient Video Understanding},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019}
}

@inproceedings{kwon2020motionsqueeze,
  title={Motionsqueeze: Neural motion feature learning for video understanding},
  author={Kwon, Heeseung and Kim, Manjin and Kwak, Suha and Cho, Minsu},
  booktitle={European Conference on Computer Vision},
  pages={345--362},
  year={2020},
  organization={Springer}
}
@inproceedings{li2020tea,
  title={Tea: Temporal excitation and aggregation for action recognition},
  author={Li, Yan and Ji, Bin and Shi, Xintian and Zhang, Jianguo and Kang, Bin and Wang, Limin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={909--918},
  year={2020}
}

@InProceedings{Kantorov_2014_CVPR,
author = {Kantorov, Vadim and Laptev, Ivan},
title = {Efficient Feature Extraction, Encoding and Classification for Action Recognition},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2014}
}

@InProceedings{Zhang_2016_CVPR,
author = {Zhang, Bowen and Wang, Limin and Wang, Zhe and Qiao, Yu and Wang, Hanli},
title = {Real-Time Action Recognition With Enhanced Motion Vector CNNs},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@inproceedings{kazakos2019epic,
  title={Epic-fusion: Audio-visual temporal binding for egocentric action recognition},
  author={Kazakos, Evangelos and Nagrani, Arsha and Zisserman, Andrew and Damen, Dima},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5492--5501},
  year={2019}
}

@inproceedings{wang2021interactive,
  title={Interactive Prototype Learning for Egocentric Action Recognition},
  author={Wang, Xiaohan and Zhu, Linchao and Wang, Heng and Yang, Yi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8168--8177},
  year={2021}
}

@inproceedings{zhou2018temporal,
  title={Temporal relational reasoning in videos},
  author={Zhou, Bolei and Andonian, Alex and Oliva, Aude and Torralba, Antonio},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={803--818},
  year={2018}
}

@inproceedings{zach2007duality,
  title={A duality based approach for realtime tv-l 1 optical flow},
  author={Zach, Christopher and Pock, Thomas and Bischof, Horst},
  booktitle={Joint pattern recognition symposium},
  pages={214--223},
  year={2007},
  organization={Springer}
}

@InProceedings{Kuehne11,
   author= "Kuehne, H. and Jhuang, H. and Garrote, E. and Poggio, T. and Serre, T.",
   title = "{HMDB}: a large video database for human motion recognition",
   booktitle = "Proceedings of the International Conference on Computer Vision (ICCV)",
   year = "2011",
}

@inproceedings{korbar2019scsampler,
  title={Scsampler: Sampling salient clips from video for efficient action recognition},
  author={Korbar, Bruno and Tran, Du and Torresani, Lorenzo},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6232--6242},
  year={2019}
}

@inproceedings{wu2019adaframe,
  title={Adaframe: Adaptive frame selection for fast video recognition},
  author={Wu, Zuxuan and Xiong, Caiming and Ma, Chih-Yao and Socher, Richard and Davis, Larry S},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1278--1287},
  year={2019}
}

@inproceedings{meng2020ar,
  title={Ar-net: Adaptive frame resolution for efficient action recognition},
  author={Meng, Yue and Lin, Chung-Ching and Panda, Rameswar and Sattigeri, Prasanna and Karlinsky, Leonid and Oliva, Aude and Saenko, Kate and Feris, Rogerio},
  booktitle={European Conference on Computer Vision},
  pages={86--104},
  year={2020},
  organization={Springer}
}

@article{wang2021efficient,
  title={Efficient video transformers with spatial-temporal token selection},
  author={Wang, Junke and Yang, Xitong and Li, Hengduo and Wu, Zuxuan and Jiang, Yu-Gang},
  journal={arXiv preprint arXiv:2111.11591},
  year={2021}
}

@inproceedings{meng2022adavit,
  title={{AdaViT}: {A}daptive Vision Transformers for Efficient Image Recognition},
  author={Meng, Lingchen and Li, Hengduo and Chen, Bor-Chun and Lan, Shiyi and Wu, Zuxuan and Jiang, Yu-Gang and Lim, Ser-Nam},
  booktitle={CVPR},
  year={2022}
}
@article{achiam2023gpt,
  title={{GPT-4} technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv},
  year={2023}
}


@misc{gemini,
    title = {Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
    url = {https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf}
}


@article{yin2021adavit,
  title={AdaViT: Adaptive Tokens for Efficient Vision Transformer},
  author={Yin, Hongxu and Vahdat, Arash and Alvarez, Jose and Mallya, Arun and Kautz, Jan and Molchanov, Pavlo},
  journal={arXiv preprint arXiv:2112.07658},
  year={2021}
}

@article{videoworldsimulators2024,
  title={Video generation models as world simulators},
  author={Tim Brooks and Bill Peebles and Connor Holmes and Will DePue and Yufei Guo and Li Jing and David Schnurr and Joe Taylor and Troy Luhman and Eric Luhman and Clarence Ng and Ricky Wang and Aditya Ramesh},
  year={2024},
  url={https://openai.com/research/video-generation-models-as-world-simulators},
}


@inproceedings{li2022mvitv2,
  title={{MViTv2}: {I}mproved multiscale vision transformers for classification and detection},
  author={Li, Yanghao and Wu, Chao-Yuan and Fan, Haoqi and Mangalam, Karttikeya and Xiong, Bo and Malik, Jitendra and Feichtenhofer, Christoph},
  booktitle={CVPR},
  year={2022}
}
@inproceedings{rao2021dynamicvit,
  title={{DynamicViT}: {E}fficient vision transformers with dynamic token sparsification},
  author={Rao, Yongming and Zhao, Wenliang and Liu, Benlin and Lu, Jiwen and Zhou, Jie and Hsieh, Cho-Jui},
  booktitle={NeurIPS},
  year={2021}
}

@article{liang2022not,
  title={Not all patches are what you need: Expediting vision transformers via token reorganizations},
  author={Liang, Youwei and Ge, Chongjian and Tong, Zhan and Song, Yibing and Wang, Jue and Xie, Pengtao},
  journal={arXiv preprint arXiv:2202.07800},
  year={2022}
}

@inproceedings{wu2022memvit,
  title={Mem{ViT}: {M}emory-augmented multiscale vision transformer for efficient long-term video recognition},
  author={Wu, Chao-Yuan and Li, Yanghao and Mangalam, Karttikeya and Fan, Haoqi and Xiong, Bo and Malik, Jitendra and Feichtenhofer, Christoph},
  booktitle={CVPR},
  year={2022}
}




@inproceedings{wang2022deformable,
  title={Deformable Video Transformer},
  author={Wang, Jue and Torresani, Lorenzo},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Machine Learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}

@article{gu2021efficiently,
  title={Efficiently modeling long sequences with structured state spaces},
  author={Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2111.00396},
  year={2021}
}

@article{gu2020hippo,
  title={Hippo: Recurrent memory with optimal polynomial projections},
  author={Gu, Albert and Dao, Tri and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1474--1487},
  year={2020}
}

  
@INPROCEEDINGS{moiveclip,
    title={COIN: A Large-scale Dataset for Comprehensive Instructional Video Analysis},
    author={ Tang,Yansong and  Ding, Dajun and  Rao,Yongming and Zheng, Yu  and  Zhang,Danyang and  Zhao,Lili and  Lu,Jiwen and  Zhou,Jie},
    booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    year={2019}
}

@article{jang2016categorical,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  journal={arXiv preprint arXiv:1611.01144},
  year={2016}
}

@inproceedings{lin2021vx2text,
  title={Vx2text: End-to-end learning of video-based text generation from multimodal inputs},
  author={Lin, Xudong and Bertasius, Gedas and Wang, Jue and Chang, Shih-Fu and Parikh, Devi and Torresani, Lorenzo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7005--7015},
  year={2021}
}

@article{tong2022videomae,
  title={Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training},
  author={Tong, Zhan and Song, Yibing and Wang, Jue and Wang, Limin},
  journal={arXiv preprint arXiv:2203.12602},
  year={2022}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}

@article{feichtenhofer2022masked,
  title={Masked Autoencoders As Spatiotemporal Learners},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Li, Yanghao and He, Kaiming},
  journal={arXiv preprint arXiv:2205.09113},
  year={2022}
}

@inproceedings{wang2022long,
  title={Long-short temporal contrastive learning of video transformers},
  author={Wang, Jue and Bertasius, Gedas and Tran, Du and Torresani, Lorenzo},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{yue2015beyond,
  title={Beyond short snippets: Deep networks for video classification},
  author={Yue-Hei Ng, Joe and Hausknecht, Matthew and Vijayanarasimhan, Sudheendra and Vinyals, Oriol and Monga, Rajat and Toderici, George},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4694--4702},
  year={2015}
}

@inproceedings{dey2017gate,
  title={Gate-variants of gated recurrent unit (GRU) neural networks},
  author={Dey, Rahul and Salem, Fathi M},
  booktitle={2017 IEEE 60th international midwest symposium on circuits and systems (MWSCAS)},
  pages={1597--1600},
  year={2017},
  organization={IEEE}
}

@inproceedings{feichtenhofer2017spatiotemporal,
  title={Spatiotemporal multiplier networks for video action recognition},
  author={Feichtenhofer, Christoph and Pinz, Axel and Wildes, Richard P},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{feichtenhofer2017temporal,
  title={Temporal Residual Networks for Dynamic Scene Recognition},
  author={Feichtenhofer, Christoph and Pinz, Axel and Wildes, Richard P},
  booktitle={CVPR},
  year={2017}
}


@inproceedings{tran2015learning,
  title={Learning spatiotemporal features with 3d convolutional networks},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4489--4497},
  year={2015}
}

@inproceedings{veeriah2015differential,
  title={Differential recurrent neural networks for action recognition},
  author={Veeriah, Vivek and Zhuang, Naifan and Qi, Guo-Jun},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4041--4049},
  year={2015}
}

@article{ullah2017action,
  title={Action recognition in video sequences using deep bi-directional LSTM with CNN features},
  author={Ullah, Amin and Ahmad, Jamil and Muhammad, Khan and Sajjad, Muhammad and Baik, Sung Wook},
  journal={IEEE access},
  volume={6},
  pages={1155--1166},
  year={2017},
  publisher={IEEE}
}

@inproceedings{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={NeurIPS},
  year={2020}
}

@article{dai2019transformer,
  title={Transformer-{XL}: Attentive language models beyond a fixed-length context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V and Salakhutdinov, Ruslan},
  journal={arXiv},
  year={2019}
}

@inproceedings{katharopoulos2020transformers,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle={International Conference on Machine Learning},
  pages={5156--5165},
  year={2020},
  organization={PMLR}
}

@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013},
  organization={PMLR}
}

@article{tustin1947method,
  title={A method of analysing the behaviour of linear systems in terms of time series},
  author={Tustin, Arnold},
  journal={Journal of the Institution of Electrical Engineers-Part IIA: Automatic Regulators and Servo Mechanisms},
  volume={94},
  number={1},
  pages={130--142},
  year={1947},
  publisher={IET}
}

@inproceedings{kuehne2014language,
  title={The language of actions: Recovering the syntax and semantics of goal-directed human activities},
  author={Kuehne, Hilde and Arslan, Ali and Serre, Thomas},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={780--787},
  year={2014}
}


@inproceedings{sunlong2022,
  title={Long-Form Video-Language Pre-Training with Multimodal Temporal Contrastive Learning},
  author={Sun, Yuchong and Liu, Bei and Xue, Hongwei and Sone, Ruihua and Yang, Huan and Fu, Jianlong},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{pan2021scalable,
  title={Scalable vision transformers with hierarchical pooling},
  author={Pan, Zizheng and Zhuang, Bohan and Liu, Jing and He, Haoyu and Cai, Jianfei},
  booktitle={Proceedings of the IEEE/cvf international conference on computer vision},
  pages={377--386},
  year={2021}
}

@article{gu2021combining,
  title={Combining recurrent, convolutional, and continuous-time models with linear state space layers},
  author={Gu, Albert and Johnson, Isys and Goel, Karan and Saab, Khaled and Dao, Tri and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={572--585},
  year={2021}
}



@article{choromanski2020rethinking,
  title={Rethinking attention with performers},
  author={Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and others},
  journal={arXiv preprint arXiv:2009.14794},
  year={2020}
}

@article{patrick2021keeping,
  title={Keeping your eye on the ball: Trajectory attention in video transformers},
  author={Patrick, Mandela and Campbell, Dylan and Asano, Yuki and Misra, Ishan and Metze, Florian and Feichtenhofer, Christoph and Vedaldi, Andrea and Henriques, Jo{\~a}o F},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={12493--12506},
  year={2021}
}
@article{carreira2018short,
  title={A short note about kinetics-600},
  author={Carreira, Joao and Noland, Eric and Banki-Horvath, Andras and Hillier, Chloe and Zisserman, Andrew},
  journal={arXiv},
  year={2018}
}

@inproceedings{miech2019howto100m,
  title={{HowTo100M}: {L}earning a text-video embedding by watching hundred million narrated video clips},
  author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
  booktitle={ICCV},
  pages={2630--2640},
  year={2019}
}

@inproceedings{feichtenhofer2021large,
  title={A large-scale study on unsupervised spatiotemporal representation learning},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Xiong, Bo and Girshick, Ross and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3299--3309},
  year={2021}
}

@article{nguyen2022s4nd,
  title={S4ND: Modeling Images and Videos as Multidimensional Signals Using State Spaces},
  author={Nguyen, Eric and Goel, Karan and Gu, Albert and Downs, Gordon W and Shah, Preey and Dao, Tri and Baccus, Stephen A and R{\'e}, Christopher},
  journal={Advances in neural information processing systems},
  year={2022}
}

@inproceedings{yin2022vit,
  title={A-ViT: Adaptive Tokens for Efficient Vision Transformer},
  author={Yin, Hongxu and Vahdat, Arash and Alvarez, Jose M and Mallya, Arun and Kautz, Jan and Molchanov, Pavlo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10809--10818},
  year={2022}
}



@inproceedings{zhang2017view,
  title={View adaptive recurrent neural networks for high performance human action recognition from skeleton data},
  author={Zhang, Pengfei and Lan, Cuiling and Xing, Junliang and Zeng, Wenjun and Xue, Jianru and Zheng, Nanning},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2117--2126},
  year={2017}
}

@inproceedings{baccouche2011sequential,
  title={Sequential deep learning for human action recognition},
  author={Baccouche, Moez and Mamalet, Franck and Wolf, Christian and Garcia, Christophe and Baskurt, Atilla},
  booktitle={International workshop on human behavior understanding},
  pages={29--39},
  year={2011},
  organization={Springer}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{ioffe2017batch,
  title={Batch renormalization: Towards reducing minibatch dependence in batch-normalized models},
  author={Ioffe, Sergey},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}


