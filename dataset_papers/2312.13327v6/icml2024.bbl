\begin{thebibliography}{56}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Biewald(2020)]{wandb}
Biewald, L.
\newblock Experiment tracking with weights and biases, 2020.
\newblock URL \url{https://www.wandb.com/}.
\newblock Software available from wandb.com.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1877--1901, 2020.

\bibitem[Chandak et~al.(2020)Chandak, Theocharous, Nota, and Thomas]{chandak2020lifelong}
Chandak, Y., Theocharous, G., Nota, C., and Thomas, P.
\newblock Lifelong learning with a changing action set.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~34, pp.\  3373--3380, 2020.

\bibitem[Chen et~al.(2021)Chen, Lu, Rajeswaran, Lee, Grover, Laskin, Abbeel, Srinivas, and Mordatch]{chen2021decision}
Chen, L., Lu, K., Rajeswaran, A., Lee, K., Grover, A., Laskin, M., Abbeel, P., Srinivas, A., and Mordatch, I.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 15084--15097, 2021.

\bibitem[Chevalier-Boisvert et~al.(2018)Chevalier-Boisvert, Willems, and Pal]{chevalier2018minimalistic}
Chevalier-Boisvert, M., Willems, L., and Pal, S.
\newblock Minimalistic gridworld environment for openai gym.
\newblock 2018.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Dorfman et~al.(2021)Dorfman, Shenfeld, and Tamar]{dorfman2021offline}
Dorfman, R., Shenfeld, I., and Tamar, A.
\newblock Offline meta reinforcement learning--identifiability challenges and effective data collection strategies.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 4607--4618, 2021.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, et~al.]{dosovitskiy2020image}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Duan et~al.(2016)Duan, Schulman, Chen, Bartlett, Sutskever, and Abbeel]{duan2016rl}
Duan, Y., Schulman, J., Chen, X., Bartlett, P.~L., Sutskever, I., and Abbeel, P.
\newblock Rl $^2$: Fast reinforcement learning via slow reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.02779}, 2016.

\bibitem[Dulac-Arnold et~al.(2015)Dulac-Arnold, Evans, van Hasselt, Sunehag, Lillicrap, Hunt, Mann, Weber, Degris, and Coppin]{dulac2015deep}
Dulac-Arnold, G., Evans, R., van Hasselt, H., Sunehag, P., Lillicrap, T., Hunt, J., Mann, T., Weber, T., Degris, T., and Coppin, B.
\newblock Deep reinforcement learning in large discrete action spaces.
\newblock \emph{arXiv preprint arXiv:1512.07679}, 2015.

\bibitem[Elhage et~al.(2021)Elhage, Nanda, Olsson, Henighan, Joseph, Mann, Askell, Bai, Chen, Conerly, DasSarma, Drain, Ganguli, Hatfield-Dodds, Hernandez, Jones, Kernion, Lovitt, Ndousse, Amodei, Brown, Clark, Kaplan, McCandlish, and Olah]{elhage2021mathematical}
Elhage, N., Nanda, N., Olsson, C., Henighan, T., Joseph, N., Mann, B., Askell, A., Bai, Y., Chen, A., Conerly, T., DasSarma, N., Drain, D., Ganguli, D., Hatfield-Dodds, Z., Hernandez, D., Jones, A., Kernion, J., Lovitt, L., Ndousse, K., Amodei, D., Brown, T., Clark, J., Kaplan, J., McCandlish, S., and Olah, C.
\newblock A mathematical framework for transformer circuits.
\newblock \emph{Transformer Circuits Thread}, 2021.
\newblock https://transformer-circuits.pub/2021/framework/index.html.

\bibitem[Elhage et~al.(2022)Elhage, Hume, Olsson, Schiefer, Henighan, Kravec, Hatfield-Dodds, Lasenby, Drain, Chen, Grosse, McCandlish, Kaplan, Amodei, Wattenberg, and Olah]{elhage2022superposition}
Elhage, N., Hume, T., Olsson, C., Schiefer, N., Henighan, T., Kravec, S., Hatfield-Dodds, Z., Lasenby, R., Drain, D., Chen, C., Grosse, R., McCandlish, S., Kaplan, J., Amodei, D., Wattenberg, M., and Olah, C.
\newblock Toy models of superposition.
\newblock \emph{Transformer Circuits Thread}, 2022.
\newblock URL \url{https://transformer-circuits.pub/2022/toy_model/index.html}.

\bibitem[Godey et~al.(2023)Godey, de~la Clergerie, and Sagot]{godey2023headless}
Godey, N., de~la Clergerie, {\'E}., and Sagot, B.
\newblock Headless language models: Learning without predicting with contrastive weight tying.
\newblock \emph{arXiv preprint arXiv:2309.08351}, 2023.

\bibitem[Gu et~al.(2021)Gu, Goel, and R{\'e}]{gu2021efficiently}
Gu, A., Goel, K., and R{\'e}, C.
\newblock Efficiently modeling long sequences with structured state spaces.
\newblock \emph{arXiv preprint arXiv:2111.00396}, 2021.

\bibitem[Hafner et~al.(2019)Hafner, Lillicrap, Ba, and Norouzi]{hafner2019dream}
Hafner, D., Lillicrap, T., Ba, J., and Norouzi, M.
\newblock Dream to control: Learning behaviors by latent imagination.
\newblock \emph{arXiv preprint arXiv:1912.01603}, 2019.

\bibitem[Hu et~al.(2022)Hu, Shen, Zhang, Chen, and Tao]{hu2022transforming}
Hu, S., Shen, L., Zhang, Y., Chen, Y., and Tao, D.
\newblock On transforming reinforcement learning by transformer: The development trajectory.
\newblock \emph{arXiv preprint arXiv:2212.14164}, 2022.

\bibitem[Jain et~al.(2020)Jain, Szot, and Lim]{jain2020generalization}
Jain, A., Szot, A., and Lim, J.~J.
\newblock Generalization to new actions in reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2011.01928}, 2020.

\bibitem[Jain et~al.(2021)Jain, Kosaka, Kim, and Lim]{jain2021know}
Jain, A., Kosaka, N., Kim, K.-M., and Lim, J.~J.
\newblock Know your action set: Learning action relations for reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Jaiswal et~al.(2020)Jaiswal, Babu, Zadeh, Banerjee, and Makedon]{jaiswal2020survey}
Jaiswal, A., Babu, A.~R., Zadeh, M.~Z., Banerjee, D., and Makedon, F.
\newblock A survey on contrastive self-supervised learning.
\newblock \emph{Technologies}, 9\penalty0 (1):\penalty0 2, 2020.

\bibitem[Janner et~al.(2021)Janner, Li, and Levine]{janner2021offline}
Janner, M., Li, Q., and Levine, S.
\newblock Offline reinforcement learning as one big sequence modeling problem.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 1273--1286, 2021.

\bibitem[Kirsch et~al.(2022)Kirsch, Flennerhag, van Hasselt, Friesen, Oh, and Chen]{kirsch2022introducing}
Kirsch, L., Flennerhag, S., van Hasselt, H., Friesen, A., Oh, J., and Chen, Y.
\newblock Introducing symmetries to black box meta reinforcement learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~36, pp.\  7202--7210, 2022.

\bibitem[Kirsch et~al.(2023)Kirsch, Harrison, Freeman, Sohl-Dickstein, and Schmidhuber]{kirsch2023towards}
Kirsch, L., Harrison, J., Freeman, C.~D., Sohl-Dickstein, J., and Schmidhuber, J.
\newblock Towards general-purpose in-context learning agents.
\newblock In \emph{NeurIPS 2023 Workshop on Distribution Shifts: New Frontiers with Foundation Models}, 2023.

\bibitem[Laskin et~al.(2022)Laskin, Wang, Oh, Parisotto, Spencer, Steigerwald, Strouse, Hansen, Filos, Brooks, et~al.]{laskin2022context}
Laskin, M., Wang, L., Oh, J., Parisotto, E., Spencer, S., Steigerwald, R., Strouse, D., Hansen, S., Filos, A., Brooks, E., et~al.
\newblock In-context reinforcement learning with algorithm distillation.
\newblock \emph{arXiv preprint arXiv:2210.14215}, 2022.

\bibitem[Lee et~al.(2023)Lee, Xie, Pacchiano, Chandak, Finn, Nachum, and Brunskill]{lee2023supervised}
Lee, J.~N., Xie, A., Pacchiano, A., Chandak, Y., Finn, C., Nachum, O., and Brunskill, E.
\newblock Supervised pretraining can learn in-context reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2306.14892}, 2023.

\bibitem[Lee et~al.(2022)Lee, Nachum, Yang, Lee, Freeman, Guadarrama, Fischer, Xu, Jang, Michalewski, et~al.]{lee2022multi}
Lee, K.-H., Nachum, O., Yang, M.~S., Lee, L., Freeman, D., Guadarrama, S., Fischer, I., Xu, W., Jang, E., Michalewski, H., et~al.
\newblock Multi-game decision transformers.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 27921--27936, 2022.

\bibitem[Li et~al.(2010)Li, Chu, Langford, and Schapire]{li2010contextual}
Li, L., Chu, W., Langford, J., and Schapire, R.~E.
\newblock A contextual-bandit approach to personalized news article recommendation.
\newblock In \emph{Proceedings of the 19th international conference on World wide web}, pp.\  661--670, 2010.

\bibitem[Li et~al.(2020)Li, Yang, and Luo]{li2020focal}
Li, L., Yang, R., and Luo, D.
\newblock Focal: Efficient fully-offline meta-reinforcement learning via distance metric learning and behavior regularization.
\newblock \emph{arXiv preprint arXiv:2010.01112}, 2020.

\bibitem[Li et~al.(2021)Li, Huang, Chen, Luo, Luo, and Huang]{li2021provably}
Li, L., Huang, Y., Chen, M., Luo, S., Luo, D., and Huang, J.
\newblock Provably improved context-based offline meta-rl with attention and contrastive learning.
\newblock \emph{arXiv preprint arXiv:2102.10774}, 2021.

\bibitem[Li et~al.(2023)Li, Luo, Lin, Zhang, Lu, and Ye]{li2023survey}
Li, W., Luo, H., Lin, Z., Zhang, C., Lu, Z., and Ye, D.
\newblock A survey on transformers in reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2301.03044}, 2023.

\bibitem[Lin et~al.(2023)Lin, Bai, and Mei]{lin2023transformers}
Lin, L., Bai, Y., and Mei, S.
\newblock Transformers as decision makers: Provable in-context reinforcement learning via supervised pretraining.
\newblock \emph{arXiv preprint arXiv:2310.08566}, 2023.

\bibitem[Lin et~al.(2022)Lin, Liu, and Sengupta]{lin2022switch}
Lin, Q., Liu, H., and Sengupta, B.
\newblock Switch trajectory transformer with distributional value approximation for multi-task reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2203.07413}, 2022.

\bibitem[Liu et~al.(2023)Liu, Yuan, Fu, Jiang, Hayashi, and Neubig]{liu2023pre}
Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G.
\newblock Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing.
\newblock \emph{ACM Computing Surveys}, 55\penalty0 (9):\penalty0 1--35, 2023.

\bibitem[London \& Joachims(2020)London and Joachims]{london2020offline}
London, B. and Joachims, T.
\newblock Offline policy evaluation with new arms.
\newblock 2020.

\bibitem[Loshchilov \& Hutter(2017)Loshchilov and Hutter]{loshchilov2017decoupled}
Loshchilov, I. and Hutter, F.
\newblock Decoupled weight decay regularization.
\newblock \emph{arXiv preprint arXiv:1711.05101}, 2017.

\bibitem[Lu et~al.(2023)Lu, Schroecker, Gu, Parisotto, Foerster, Singh, and Behbahani]{lu2023structured}
Lu, C., Schroecker, Y., Gu, A., Parisotto, E., Foerster, J., Singh, S., and Behbahani, F.
\newblock Structured state space models for in-context reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2303.03982}, 2023.

\bibitem[Mirchandani et~al.(2023)Mirchandani, Xia, Florence, Ichter, Driess, Arenas, Rao, Sadigh, and Zeng]{mirchandani2023large}
Mirchandani, S., Xia, F., Florence, P., Ichter, B., Driess, D., Arenas, M.~G., Rao, K., Sadigh, D., and Zeng, A.
\newblock Large language models as general pattern machines.
\newblock \emph{arXiv preprint arXiv:2307.04721}, 2023.

\bibitem[Nikulin et~al.(2023)Nikulin, Kurenkov, Zisman, Sinii, Agarkov, and Kolesnikov]{nikulin2023xlandminigrid}
Nikulin, A., Kurenkov, V., Zisman, I., Sinii, V., Agarkov, A., and Kolesnikov, S.
\newblock {XL}and-minigrid: Scalable meta-reinforcement learning environments in {JAX}.
\newblock In \emph{Intrinsically-Motivated and Open-Ended Learning Workshop, NeurIPS2023}, 2023.
\newblock URL \url{https://openreview.net/forum?id=xALDC4aHGz}.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Oord, A. v.~d., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan, Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison, Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{NEURIPS2019_9015}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., Bai, J., and Chintala, S.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pp.\  8024--8035. Curran Associates, Inc., 2019.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, Sutskever, et~al.]{radford2018improving}
Radford, A., Narasimhan, K., Salimans, T., Sutskever, I., et~al.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem[Rajeswaran et~al.(2017)Rajeswaran, Lowrey, Todorov, and Kakade]{rajeswaran2017towards}
Rajeswaran, A., Lowrey, K., Todorov, E.~V., and Kakade, S.~M.
\newblock Towards generalization and simplicity in continuous control.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Raparthy et~al.(2023)Raparthy, Hambro, Kirk, Henaff, and Raileanu]{raparthy2023generalization}
Raparthy, S.~C., Hambro, E., Kirk, R., Henaff, M., and Raileanu, R.
\newblock Generalization to new sequential decision making tasks with in-context learning.
\newblock \emph{arXiv preprint arXiv:2312.03801}, 2023.

\bibitem[Saxe et~al.(2013)Saxe, McClelland, and Ganguli]{saxe2013exact}
Saxe, A.~M., McClelland, J.~L., and Ganguli, S.
\newblock Exact solutions to the nonlinear dynamics of learning in deep linear neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6120}, 2013.

\bibitem[Schroff et~al.(2015)Schroff, Kalenichenko, and Philbin]{schroff2015facenet}
Schroff, F., Kalenichenko, D., and Philbin, J.
\newblock Facenet: A unified embedding for face recognition and clustering.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  815--823, 2015.

\bibitem[Sutton \& Barto(2018)Sutton and Barto]{sutton2018reinforcement}
Sutton, R.~S. and Barto, A.~G.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Team et~al.(2021)Team, Stooke, Mahajan, Barros, Deck, Bauer, Sygnowski, Trebacz, Jaderberg, Mathieu, et~al.]{team2021open}
Team, O. E.~L., Stooke, A., Mahajan, A., Barros, C., Deck, C., Bauer, J., Sygnowski, J., Trebacz, M., Jaderberg, M., Mathieu, M., et~al.
\newblock Open-ended learning leads to generally capable agents.
\newblock \emph{arXiv preprint arXiv:2107.12808}, 2021.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N., Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Wang et~al.(2024)Wang, Blaser, Daneshmand, and Zhang]{wang2024transformers}
Wang, J., Blaser, E., Daneshmand, H., and Zhang, S.
\newblock Transformers learn temporal difference methods for in-context reinforcement learning, 2024.

\bibitem[Wang et~al.(2016)Wang, Kurth-Nelson, Tirumala, Soyer, Leibo, Munos, Blundell, Kumaran, and Botvinick]{wang2016learning}
Wang, J.~X., Kurth-Nelson, Z., Tirumala, D., Soyer, H., Leibo, J.~Z., Munos, R., Blundell, C., Kumaran, D., and Botvinick, M.
\newblock Learning to reinforcement learn.
\newblock \emph{arXiv preprint arXiv:1611.05763}, 2016.

\bibitem[Wang et~al.(2023)Wang, Wang, Cao, Shen, and Huang]{wang2023images}
Wang, X., Wang, W., Cao, Y., Shen, C., and Huang, T.
\newblock Images speak in images: A generalist painter for in-context visual learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  6830--6839, 2023.

\bibitem[Weinberger \& Saul(2009)Weinberger and Saul]{weinberger2009distance}
Weinberger, K.~Q. and Saul, L.~K.
\newblock Distance metric learning for large margin nearest neighbor classification.
\newblock \emph{Journal of machine learning research}, 10\penalty0 (2), 2009.

\bibitem[Xu et~al.(2022)Xu, Shen, Zhang, Lu, Zhao, Tenenbaum, and Gan]{xu2022prompting}
Xu, M., Shen, Y., Zhang, S., Lu, Y., Zhao, D., Tenenbaum, J., and Gan, C.
\newblock Prompting decision transformer for few-shot policy generalization.
\newblock In \emph{international conference on machine learning}, pp.\  24631--24645. PMLR, 2022.

\bibitem[Ye et~al.(2023)Ye, Li, Wu, and Wang]{ye2023action}
Ye, J., Li, X., Wu, P., and Wang, F.
\newblock Action pick-up in dynamic action space reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2304.00873}, 2023.

\bibitem[Zhang et~al.(2018)Zhang, Ballas, and Pineau]{zhang2018dissection}
Zhang, A., Ballas, N., and Pineau, J.
\newblock A dissection of overfitting and generalization in continuous reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1806.07937}, 2018.

\bibitem[Zhang et~al.(2024)Zhang, Zeng, Wang, and Lu]{zhang2024tinyllama}
Zhang, P., Zeng, G., Wang, T., and Lu, W.
\newblock Tinyllama: An open-source small language model, 2024.

\bibitem[Zisman et~al.(2023)Zisman, Kurenkov, Nikulin, Sinii, and Kolesnikov]{zisman2023emergence}
Zisman, I., Kurenkov, V., Nikulin, A., Sinii, V., and Kolesnikov, S.
\newblock Emergence of in-context reinforcement learning from noise distillation.
\newblock \emph{arXiv preprint arXiv:2312.12275}, 2023.

\end{thebibliography}
