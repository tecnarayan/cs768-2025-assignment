\begin{thebibliography}{60}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Albuquerque et~al.(2019)Albuquerque, Monteiro, Darvishi, Falk, and
  Mitliagkas]{albuquerque2019generalizing}
Albuquerque, I., Monteiro, J., Darvishi, M., Falk, T.~H., and Mitliagkas, I.
\newblock Generalizing to unseen domains via distribution matching.
\newblock \emph{arXiv preprint arXiv:1911.00804}, 2019.

\bibitem[Arjovsky et~al.(2019)Arjovsky, Bottou, Gulrajani, and
  Lopez-Paz]{arjovsky2019invariant}
Arjovsky, M., Bottou, L., Gulrajani, I., and Lopez-Paz, D.
\newblock Invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[Bandi et~al.(2018)Bandi, Geessink, Manson, Van~Dijk, Balkenhol,
  Hermsen, Bejnordi, Lee, Paeng, Zhong, et~al.]{bandi2018detection}
Bandi, P., Geessink, O., Manson, Q., Van~Dijk, M., Balkenhol, M., Hermsen, M.,
  Bejnordi, B.~E., Lee, B., Paeng, K., Zhong, A., et~al.
\newblock From detection of individual metastases to classification of lymph
  node status at the patient level: the camelyon17 challenge.
\newblock \emph{IEEE transactions on medical imaging}, 38\penalty0
  (2):\penalty0 550--560, 2018.

\bibitem[Beery et~al.(2018)Beery, Van~Horn, and Perona]{beery2018recognition}
Beery, S., Van~Horn, G., and Perona, P.
\newblock Recognition in terra incognita.
\newblock In \emph{Proceedings of the European conference on computer vision
  (ECCV)}, pp.\  456--473, 2018.

\bibitem[Beery et~al.(2019)Beery, Morris, and Yang]{beery2019megadetector}
Beery, S., Morris, D., and Yang, S.
\newblock Efficient pipeline for camera trap image review.
\newblock \emph{arXiv preprint arXiv:1907.06772}, 2019.

\bibitem[Beery et~al.(2020)Beery, Liu, Morris, Piavis, Kapoor, Joshi, Meister,
  and Perona]{beery2020synthetic}
Beery, S., Liu, Y., Morris, D., Piavis, J., Kapoor, A., Joshi, N., Meister, M.,
  and Perona, P.
\newblock Synthetic examples improve generalization for rare classes.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, pp.\  863--873, 2020.

\bibitem[Beery et~al.(2021)Beery, Agarwal, Cole, and
  Birodkar]{beery2021iwildcam}
Beery, S., Agarwal, A., Cole, E., and Birodkar, V.
\newblock The iwildcam 2021 competition dataset.
\newblock \emph{arXiv preprint arXiv:2105.03494}, 2021.

\bibitem[Birodkar et~al.(2021)Birodkar, Lu, Li, Rathod, and
  Huang]{birodkar2021deepmac}
Birodkar, V., Lu, Z., Li, S., Rathod, V., and Huang, J.
\newblock The surprising impact of mask-head architecture on novel class
  segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  7015--7025, 2021.

\bibitem[Chen et~al.(2021{\natexlab{a}})Chen, Shui, and
  Marchand]{chen2021generalization}
Chen, Q., Shui, C., and Marchand, M.
\newblock Generalization bounds for meta-learning: An information-theoretic
  analysis.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 25878--25890, 2021{\natexlab{a}}.

\bibitem[Chen et~al.(2020)Chen, Dobriban, and Lee]{chen2020group}
Chen, S., Dobriban, E., and Lee, J.~H.
\newblock A group-theoretic framework for data augmentation.
\newblock \emph{The Journal of Machine Learning Research}, 21\penalty0
  (1):\penalty0 9885--9955, 2020.

\bibitem[Chen et~al.(2021{\natexlab{b}})Chen, Rosenfeld, Sellke, Ma, and
  Risteski]{chen2021iterative}
Chen, Y., Rosenfeld, E., Sellke, M., Ma, T., and Risteski, A.
\newblock Iterative feature matching: Toward provable domain generalization
  with logarithmic environments.
\newblock \emph{arXiv preprint arXiv:2106.09913}, 2021{\natexlab{b}}.

\bibitem[Cubuk et~al.(2020)Cubuk, Zoph, Shlens, and Le]{cubuk2020randaugment}
Cubuk, E.~D., Zoph, B., Shlens, J., and Le, Q.~V.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition workshops}, pp.\  702--703, 2020.

\bibitem[D'Amour et~al.(2020)D'Amour, Heller, Moldovan, Adlam, Alipanahi,
  Beutel, Chen, Deaton, Eisenstein, Hoffman, et~al.]{d2020underspecification}
D'Amour, A., Heller, K., Moldovan, D., Adlam, B., Alipanahi, B., Beutel, A.,
  Chen, C., Deaton, J., Eisenstein, J., Hoffman, M.~D., et~al.
\newblock Underspecification presents challenges for credibility in modern
  machine learning.
\newblock \emph{Journal of Machine Learning Research}, 2020.

\bibitem[Dao et~al.(2019)Dao, Gu, Ratner, Smith, De~Sa, and
  R{\'e}]{dao2019kernel}
Dao, T., Gu, A., Ratner, A., Smith, V., De~Sa, C., and R{\'e}, C.
\newblock A kernel theory of modern data augmentation.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1528--1537. PMLR, 2019.

\bibitem[Denton et~al.(2022)Denton, Wisdom, and Hershey]{denton2022improving}
Denton, T., Wisdom, S., and Hershey, J.~R.
\newblock Improving bird classification with unsupervised sound separation.
\newblock In \emph{ICASSP 2022-2022 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  636--640. IEEE, 2022.

\bibitem[DeVries \& Taylor(2017)DeVries and Taylor]{devries2017improved}
DeVries, T. and Taylor, G.~W.
\newblock Improved regularization of convolutional neural networks with cutout.
\newblock \emph{arXiv preprint arXiv:1708.04552}, 2017.

\bibitem[Ganin et~al.(2016)Ganin, Ustinova, Ajakan, Germain, Larochelle,
  Laviolette, Marchand, and Lempitsky]{ganin2016domain}
Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette,
  F., Marchand, M., and Lempitsky, V.
\newblock Domain-adversarial training of neural networks.
\newblock \emph{The journal of machine learning research}, 17\penalty0
  (1):\penalty0 2096--2030, 2016.

\bibitem[Gontijo-Lopes et~al.(2020)Gontijo-Lopes, Smullin, Cubuk, and
  Dyer]{gontijo2020affinity}
Gontijo-Lopes, R., Smullin, S.~J., Cubuk, E.~D., and Dyer, E.
\newblock Affinity and diversity: Quantifying mechanisms of data augmentation.
\newblock \emph{arXiv preprint arXiv:2002.08973}, 2020.

\bibitem[Gulrajani \& Lopez-Paz(2020)Gulrajani and
  Lopez-Paz]{gulrajani2020search}
Gulrajani, I. and Lopez-Paz, D.
\newblock In search of lost domain generalization.
\newblock \emph{arXiv preprint arXiv:2007.01434}, 2020.

\bibitem[Gy{\"o}rfi et~al.(2002)Gy{\"o}rfi, Kohler, Krzyzak, Walk,
  et~al.]{gyorfi2002distribution}
Gy{\"o}rfi, L., Kohler, M., Krzyzak, A., Walk, H., et~al.
\newblock \emph{A distribution-free theory of nonparametric regression},
  volume~1.
\newblock Springer, 2002.

\bibitem[He et~al.(2019)He, Xie, Chen, Zhang, Wang, and Tian]{he2019data}
He, Z., Xie, L., Chen, X., Zhang, Y., Wang, Y., and Tian, Q.
\newblock Data augmentation revisited: Rethinking the distribution gap between
  clean and augmented data.
\newblock \emph{arXiv preprint arXiv:1909.09148}, 2019.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Basart, Mu, Kadavath, Wang, Dorundo,
  Desai, Zhu, Parajuli, Guo, et~al.]{hendrycks2021many}
Hendrycks, D., Basart, S., Mu, N., Kadavath, S., Wang, F., Dorundo, E., Desai,
  R., Zhu, T., Parajuli, S., Guo, M., et~al.
\newblock The many faces of robustness: A critical analysis of
  out-of-distribution generalization.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  8340--8349, 2021.

\bibitem[Hoffman et~al.(2018)Hoffman, Tzeng, Park, Zhu, Isola, Saenko, Efros,
  and Darrell]{hoffman2018cycada}
Hoffman, J., Tzeng, E., Park, T., Zhu, J.-Y., Isola, P., Saenko, K., Efros, A.,
  and Darrell, T.
\newblock Cycada: Cycle-consistent adversarial domain adaptation.
\newblock In \emph{International conference on machine learning}, pp.\
  1989--1998. Pmlr, 2018.

\bibitem[Hopping et~al.(2022)Hopping, Kahl, and
  Klinck]{w_alexander_hopping_2022_7079124}
Hopping, W.~A., Kahl, S., and Klinck, H.
\newblock {A collection of fully-annotated soundscape recordings from the
  Southwestern Amazon Basin}, September 2022.
\newblock URL \url{https://doi.org/10.5281/zenodo.7079124}.

\bibitem[Hsu et~al.(2011)Hsu, Kakade, and Zhang]{hsu2011analysis}
Hsu, D., Kakade, S.~M., and Zhang, T.
\newblock An analysis of random design linear regression.
\newblock \emph{arXiv preprint arXiv:1106.2363}, 2011.

\bibitem[Ilse et~al.(2021)Ilse, Tomczak, and Forr{\'e}]{ilse2021selecting}
Ilse, M., Tomczak, J.~M., and Forr{\'e}, P.
\newblock Selecting data augmentation for simulating interventions.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4555--4562. PMLR, 2021.

\bibitem[Joly et~al.(2021)Joly, Go{\"e}au, Kahl, Picek, Lorieul, Cole, Deneu,
  Servajean, Durso, Bolon, et~al.]{joly2021overview}
Joly, A., Go{\"e}au, H., Kahl, S., Picek, L., Lorieul, T., Cole, E., Deneu, B.,
  Servajean, M., Durso, A., Bolon, I., et~al.
\newblock Overview of lifeclef 2021: an evaluation of machine-learning based
  species identification and species distribution prediction.
\newblock In \emph{Experimental IR Meets Multilinguality, Multimodality, and
  Interaction: 12th International Conference of the CLEF Association, CLEF
  2021, Virtual Event, September 21--24, 2021, Proceedings}, pp.\  371--393.
  Springer, 2021.

\bibitem[Jose \& Simeone(2021)Jose and Simeone]{jose2021information}
Jose, S.~T. and Simeone, O.
\newblock Information-theoretic generalization bounds for meta-learning and
  applications.
\newblock \emph{Entropy}, 23\penalty0 (1):\penalty0 126, 2021.

\bibitem[Kahl et~al.(2022)Kahl, Charif, and Klinck]{stefan_kahl_2022_7079380}
Kahl, S., Charif, R., and Klinck, H.
\newblock {A collection of fully-annotated soundscape recordings from the
  Northeastern United States}, August 2022.
\newblock URL \url{https://doi.org/10.5281/zenodo.7079380}.

\bibitem[Koh et~al.(2021)Koh, Sagawa, Marklund, Xie, Zhang, Balsubramani, Hu,
  Yasunaga, Phillips, Gao, et~al.]{koh2021wilds}
Koh, P.~W., Sagawa, S., Marklund, H., Xie, S.~M., Zhang, M., Balsubramani, A.,
  Hu, W., Yasunaga, M., Phillips, R.~L., Gao, I., et~al.
\newblock Wilds: A benchmark of in-the-wild distribution shifts.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5637--5664. PMLR, 2021.

\bibitem[Kumar et~al.(2022)Kumar, Shen, Bubeck, and Gunasekar]{kumar2022fine}
Kumar, A., Shen, R., Bubeck, S., and Gunasekar, S.
\newblock How to fine-tune vision models with sgd.
\newblock \emph{arXiv preprint arXiv:2211.09359}, 2022.

\bibitem[Long et~al.(2018)Long, Cao, Wang, and Jordan]{long2018conditional}
Long, M., Cao, Z., Wang, J., and Jordan, M.~I.
\newblock Conditional adversarial domain adaptation.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Lyle et~al.(2020)Lyle, van~der Wilk, Kwiatkowska, Gal, and
  Bloem-Reddy]{lyle2020benefits}
Lyle, C., van~der Wilk, M., Kwiatkowska, M., Gal, Y., and Bloem-Reddy, B.
\newblock On the benefits of invariance in neural networks.
\newblock \emph{arXiv preprint arXiv:2005.00178}, 2020.

\bibitem[Mahajan et~al.(2021)Mahajan, Tople, and Sharma]{mahajan2021domain}
Mahajan, D., Tople, S., and Sharma, A.
\newblock Domain generalization using causal matching.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7313--7324. PMLR, 2021.

\bibitem[Miller et~al.(2021)Miller, Taori, Raghunathan, Sagawa, Koh, Shankar,
  Liang, Carmon, and Schmidt]{miller2021accuracy}
Miller, J.~P., Taori, R., Raghunathan, A., Sagawa, S., Koh, P.~W., Shankar, V.,
  Liang, P., Carmon, Y., and Schmidt, L.
\newblock Accuracy on the line: on the strong correlation between
  out-of-distribution and in-distribution generalization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7721--7735. PMLR, 2021.

\bibitem[Navine et~al.(2022)Navine, Kahl, Tanimoto-Johnson, Klinck, and
  Hart]{amanda_navine_2022_7078499}
Navine, A., Kahl, S., Tanimoto-Johnson, A., Klinck, H., and Hart, P.
\newblock {A collection of fully-annotated soundscape recordings from the
  Island of Hawai'i}, September 2022.
\newblock URL \url{https://doi.org/10.5281/zenodo.7078499}.

\bibitem[Park et~al.(2019)Park, Chan, Zhang, Chiu, Zoph, Cubuk, and
  Le]{park2019specaugment}
Park, D.~S., Chan, W., Zhang, Y., Chiu, C.-C., Zoph, B., Cubuk, E.~D., and Le,
  Q.~V.
\newblock Specaugment: A simple data augmentation method for automatic speech
  recognition.
\newblock \emph{arXiv preprint arXiv:1904.08779}, 2019.

\bibitem[Puli et~al.(2022)Puli, Joshi, He, and Ranganath]{puli2022nuisances}
Puli, A., Joshi, N., He, H., and Ranganath, R.
\newblock Nuisances via negativa: Adjusting for spurious correlations via data
  augmentation.
\newblock \emph{arXiv preprint arXiv:2210.01302}, 2022.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry,
  G., Askell, A., Mishkin, P., Clark, J., et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International conference on machine learning}, pp.\
  8748--8763. PMLR, 2021.

\bibitem[Robey et~al.(2021)Robey, Pappas, and Hassani]{robey2021model}
Robey, A., Pappas, G.~J., and Hassani, H.
\newblock Model-based domain generalization.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 20210--20229, 2021.

\bibitem[Rosenfeld et~al.(2020)Rosenfeld, Ravikumar, and
  Risteski]{rosenfeld2020risks}
Rosenfeld, E., Ravikumar, P., and Risteski, A.
\newblock The risks of invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:2010.05761}, 2020.

\bibitem[Ruifrok et~al.(2001)Ruifrok, Johnston,
  et~al.]{ruifrok2001quantification}
Ruifrok, A.~C., Johnston, D.~A., et~al.
\newblock Quantification of histochemical staining by color deconvolution.
\newblock \emph{Analytical and quantitative cytology and histology},
  23\penalty0 (4):\penalty0 291--299, 2001.

\bibitem[Sagawa et~al.(2021)Sagawa, Koh, Lee, Gao, Xie, Shen, Kumar, Hu,
  Yasunaga, Marklund, et~al.]{sagawa2021extending}
Sagawa, S., Koh, P.~W., Lee, T., Gao, I., Xie, S.~M., Shen, K., Kumar, A., Hu,
  W., Yasunaga, M., Marklund, H., et~al.
\newblock Extending the wilds benchmark for unsupervised adaptation.
\newblock \emph{arXiv preprint arXiv:2112.05090}, 2021.

\bibitem[Sainburg(2022)]{noisereduce}
Sainburg, T.
\newblock Noise reduction in python using spectral gating, 2022.
\newblock URL \url{https://github.com/timsainb/noisereduce}.

\bibitem[Sun \& Saenko(2016)Sun and Saenko]{sun2016deep}
Sun, B. and Saenko, K.
\newblock Deep coral: Correlation alignment for deep domain adaptation.
\newblock In \emph{European conference on computer vision}, pp.\  443--450.
  Springer, 2016.

\bibitem[Sun et~al.(2017)Sun, Feng, and Saenko]{sun2017correlation}
Sun, B., Feng, J., and Saenko, K.
\newblock Correlation alignment for unsupervised domain adaptation.
\newblock In \emph{Domain Adaptation in Computer Vision Applications}, pp.\
  153--171. Springer, 2017.

\bibitem[Tellez et~al.(2018)Tellez, Balkenhol, Otte-H{\"o}ller, van~de Loo,
  Vogels, Bult, Wauters, Vreuls, Mol, Karssemeijer, et~al.]{tellez2018whole}
Tellez, D., Balkenhol, M., Otte-H{\"o}ller, I., van~de Loo, R., Vogels, R.,
  Bult, P., Wauters, C., Vreuls, W., Mol, S., Karssemeijer, N., et~al.
\newblock Whole-slide mitosis detection in h\&e breast histology using phh3 as
  a reference to train distilled stain-invariant convolutional networks.
\newblock \emph{IEEE transactions on medical imaging}, 37\penalty0
  (9):\penalty0 2126--2136, 2018.

\bibitem[Tellez et~al.(2019)Tellez, Litjens, B{\'a}ndi, Bulten, Bokhorst,
  Ciompi, and van~der Laak]{tellez2019quantifying}
Tellez, D., Litjens, G., B{\'a}ndi, P., Bulten, W., Bokhorst, J.-M., Ciompi,
  F., and van~der Laak, J.
\newblock Quantifying the effects of data augmentation and stain color
  normalization in convolutional neural networks for computational pathology.
\newblock \emph{Medical image analysis}, 58, 2019.

\bibitem[Wang et~al.(2022)Wang, Yi, Chen, and Zhu]{wang2022out}
Wang, R., Yi, M., Chen, Z., and Zhu, S.
\newblock Out-of-distribution generalization with causal invariant
  transformations.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  375--385, 2022.

\bibitem[Wang et~al.(2020)Wang, Li, and Kot]{wang2020heterogeneous}
Wang, Y., Li, H., and Kot, A.~C.
\newblock Heterogeneous domain generalization via domain mixup.
\newblock In \emph{ICASSP 2020-2020 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pp.\  3622--3626. IEEE, 2020.

\bibitem[Wiles et~al.(2021)Wiles, Gowal, Stimberg, Rebuffi, Ktena, Dvijotham,
  and Cemgil]{wiles2021fine}
Wiles, O., Gowal, S., Stimberg, F., Rebuffi, S.-A., Ktena, I., Dvijotham,
  K.~D., and Cemgil, A.~T.
\newblock A fine-grained analysis on distribution shift.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Wortsman et~al.(2022)Wortsman, Ilharco, Gadre, Roelofs, Gontijo-Lopes,
  Morcos, Namkoong, Farhadi, Carmon, Kornblith, et~al.]{wortsman2022model}
Wortsman, M., Ilharco, G., Gadre, S.~Y., Roelofs, R., Gontijo-Lopes, R.,
  Morcos, A.~S., Namkoong, H., Farhadi, A., Carmon, Y., Kornblith, S., et~al.
\newblock Model soups: averaging weights of multiple fine-tuned models improves
  accuracy without increasing inference time.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  23965--23998. PMLR, 2022.

\bibitem[Xu et~al.(2020)Xu, Zhang, Ni, Li, Wang, Tian, and
  Zhang]{xu2020adversarial}
Xu, M., Zhang, J., Ni, B., Li, T., Wang, C., Tian, Q., and Zhang, W.
\newblock Adversarial domain adaptation with domain mixup.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pp.\  6502--6509, 2020.

\bibitem[Yan et~al.(2020)Yan, Song, Li, Zou, and Ren]{yan2020improve}
Yan, S., Song, H., Li, N., Zou, L., and Ren, L.
\newblock Improve unsupervised domain adaptation with mixup training.
\newblock \emph{arXiv preprint arXiv:2001.00677}, 2020.

\bibitem[Yao et~al.(2022)Yao, Wang, Li, Zhang, Liang, Zou, and
  Finn]{yao2022improving}
Yao, H., Wang, Y., Li, S., Zhang, L., Liang, W., Zou, J., and Finn, C.
\newblock Improving out-of-distribution robustness via selective augmentation.
\newblock \emph{arXiv preprint arXiv:2201.00299}, 2022.

\bibitem[Yun et~al.(2019)Yun, Han, Oh, Chun, Choe, and Yoo]{yun2019cutmix}
Yun, S., Han, D., Oh, S.~J., Chun, S., Choe, J., and Yoo, Y.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pp.\  6023--6032, 2019.

\bibitem[Zhang et~al.(2017)Zhang, Cisse, Dauphin, and
  Lopez-Paz]{zhang2017mixup}
Zhang, H., Cisse, M., Dauphin, Y.~N., and Lopez-Paz, D.
\newblock mixup: Beyond empirical risk minimization.
\newblock \emph{arXiv preprint arXiv:1710.09412}, 2017.

\bibitem[Zhou et~al.(2020{\natexlab{a}})Zhou, Yang, Hospedales, and
  Xiang]{zhou2020deep}
Zhou, K., Yang, Y., Hospedales, T., and Xiang, T.
\newblock Deep domain-adversarial image generation for domain generalisation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pp.\  13025--13032, 2020{\natexlab{a}}.

\bibitem[Zhou et~al.(2020{\natexlab{b}})Zhou, Yang, Hospedales, and
  Xiang]{zhou2020learning}
Zhou, K., Yang, Y., Hospedales, T., and Xiang, T.
\newblock Learning to generate novel domains for domain generalization.
\newblock In \emph{European conference on computer vision}, pp.\  561--578.
  Springer, 2020{\natexlab{b}}.

\bibitem[Zhu(2012)]{zhu2012short}
Zhu, S.
\newblock A short note on the tail bound of wishart distribution.
\newblock \emph{arXiv preprint arXiv:1212.5860}, 2012.

\end{thebibliography}
