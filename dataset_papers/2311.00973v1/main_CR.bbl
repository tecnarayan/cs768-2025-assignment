\begin{thebibliography}{}

\bibitem[Abbasi-Yadkori et~al., 2011]{abbasi2011improved}
Abbasi-Yadkori, Y., P{\'a}l, D., and Szepesv{\'a}ri, C. (2011).
\newblock Improved algorithms for linear stochastic bandits.
\newblock {\em Advances in neural information processing systems}, 24.

\bibitem[Auer, 2002]{auer2002using}
Auer, P. (2002).
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock {\em Journal of Machine Learning Research}, 3(Nov):397--422.

\bibitem[Cesa-Bianchi et~al., 2013]{cesa2013gang}
Cesa-Bianchi, N., Gentile, C., and Zappella, G. (2013).
\newblock A gang of bandits.
\newblock {\em Advances in neural information processing systems}, 26.

\bibitem[Chu et~al., 2011]{chu2011contextual}
Chu, W., Li, L., Reyzin, L., and Schapire, R. (2011).
\newblock Contextual bandits with linear payoff functions.
\newblock In {\em Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics}, pages 208--214. JMLR Workshop and Conference Proceedings.

\bibitem[Dani et~al., 2008]{dani2008stochastic}
Dani, V., Hayes, T.~P., and Kakade, S.~M. (2008).
\newblock Stochastic linear optimization under bandit feedback.
\newblock {\em 21st Annual Conference on Learning Theory}, pages 355--366.

\bibitem[Dubey and Pentland, 2020]{dubey2020differentially}
Dubey, A. and Pentland, A. (2020).
\newblock Differentially-private federated linear bandits.
\newblock {\em Advances in Neural Information Processing Systems}, 33:6003--6014.

\bibitem[Han et~al., 2020]{han2020sequential}
Han, Y., Zhou, Z., Zhou, Z., Blanchet, J., Glynn, P.~W., and Ye, Y. (2020).
\newblock Sequential batch learning in finite-action linear contextual bandits.
\newblock {\em arXiv preprint arXiv:2004.06321}.

\bibitem[Harper and Konstan, 2015]{harper2015movielens}
Harper, F.~M. and Konstan, J.~A. (2015).
\newblock The {MovieLens} datasets: History and context.
\newblock {\em ACM Trans. Interact. Intell. Syst.}, 5(4):1--19.

\bibitem[He et~al., 2022a]{he2022simple}
He, J., Wang, T., Min, Y., and Gu, Q. (2022a).
\newblock A simple and provably efficient algorithm for asynchronous federated contextual linear bandits.
\newblock {\em arXiv preprint arXiv:2207.03106}.

\bibitem[He et~al., 2022b]{he2022nearly}
He, J., Zhou, D., Zhang, T., and Gu, Q. (2022b).
\newblock Nearly optimal algorithms for linear contextual bandits with adversarial corruptions.
\newblock {\em Advances in neural information processing systems}.

\bibitem[Huang et~al., 2021]{huang2021federated}
Huang, R., Wu, W., Yang, J., and Shen, C. (2021).
\newblock Federated linear contextual bandits.
\newblock {\em Advances in Neural Information Processing Systems}, 34:27057--27068.

\bibitem[Lattimore and Szepesv{\'a}ri, 2020]{lattimore2020bandit}
Lattimore, T. and Szepesv{\'a}ri, C. (2020).
\newblock {\em Bandit algorithms}.
\newblock Cambridge University Press.

\bibitem[Li and Wang, 2022a]{li2022asynchronous}
Li, C. and Wang, H. (2022a).
\newblock Asynchronous upper confidence bound algorithms for federated linear bandits.
\newblock In {\em International Conference on Artificial Intelligence and Statistics}, pages 6529--6553. PMLR.

\bibitem[Li and Wang, 2022b]{li2022communication}
Li, C. and Wang, H. (2022b).
\newblock Communication efficient federated learning for generalized linear bandits.
\newblock {\em arXiv preprint arXiv:2202.01087}.

\bibitem[Li et~al., 2010]{li2010contextual}
Li, L., Chu, W., Langford, J., and Schapire, R.~E. (2010).
\newblock A contextual-bandit approach to personalized news article recommendation.
\newblock In {\em Proceedings of the 19th international conference on World wide web}, pages 661--670.

\bibitem[Li et~al., 2020]{li2020federated}
Li, T., Song, L., and Fragouli, C. (2020).
\newblock Federated recommendation system via differential privacy.
\newblock In {\em 2020 IEEE International Symposium on Information Theory (ISIT)}, pages 2592--2597. IEEE.

\bibitem[Li et~al., 2019]{li2019nearly}
Li, Y., Wang, Y., and Zhou, Y. (2019).
\newblock Nearly minimax-optimal regret for linearly parameterized bandits.
\newblock In {\em Conference on Learning Theory}, pages 2173--2174. PMLR.

\bibitem[McMahan et~al., 2017]{mcmahan2017fl}
McMahan, B., Moore, E., Ramage, D., Hampson, S., and y~Arcas, B.~A. (2017).
\newblock Communication-efficient learning of deep networks from decentralized data.
\newblock In {\em Proc. AISTATS}, pages 1273--1282, Fort Lauderdale, FL, USA.

\bibitem[Ruan et~al., 2021]{ruan2021linear}
Ruan, Y., Yang, J., and Zhou, Y. (2021).
\newblock Linear bandits with limited adaptivity and learning distributional optimal design.
\newblock In {\em Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing}, pages 74--87.

\bibitem[Salgia and Zhao, 2023]{salgia2023distributed}
Salgia, S. and Zhao, Q. (2023).
\newblock Distributed linear bandits under communication constraints.
\newblock In {\em International Conference on Machine Learning}, pages 29845--29875. PMLR.

\bibitem[Shi et~al., 2021]{shi2021federated}
Shi, C., Shen, C., and Yang, J. (2021).
\newblock Federated multi-armed bandits with personalization.
\newblock In {\em International Conference on Artificial Intelligence and Statistics}, pages 2917--2925. PMLR.

\bibitem[Wang et~al., 2019]{wang2019distributed}
Wang, Y., Hu, J., Chen, X., and Wang, L. (2019).
\newblock Distributed bandit learning: Near-optimal regret with efficient communication.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Zhou and Gu, 2022]{zhou2022computationally}
Zhou, D. and Gu, Q. (2022).
\newblock Computationally efficient horizon-free reinforcement learning for linear mixture mdps.
\newblock {\em arXiv preprint arXiv:2205.11507}.

\bibitem[Zhou et~al., 2021]{zhou2021nearly}
Zhou, D., Gu, Q., and Szepesvari, C. (2021).
\newblock Nearly minimax optimal reinforcement learning for linear mixture markov decision processes.
\newblock In {\em Conference on Learning Theory}, pages 4532--4576. PMLR.

\end{thebibliography}
