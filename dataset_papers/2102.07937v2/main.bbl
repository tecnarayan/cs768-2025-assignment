\begin{thebibliography}{21}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aghasadeghi and Bretl(2011)]{aghasadeghi2011maximum}
Navid Aghasadeghi and Timothy Bretl.
\newblock Maximum entropy inverse reinforcement learning in continuous state
  spaces with path integrals.
\newblock In \emph{International Conference on Intelligent Robots and Systems},
  2011.

\bibitem[Alzer(1997)]{alzer1997some}
Horst Alzer.
\newblock On some inequalities for the gamma and psi functions.
\newblock \emph{Mathematics of computation}, 66\penalty0 (217):\penalty0
  373--389, 1997.

\bibitem[Arora and Doshi(2020)]{arora2020survey}
Saurabh Arora and Prashant Doshi.
\newblock A survey of inverse reinforcement learning: Challenges, methods and
  progress.
\newblock \emph{ArXiv 1806.06877}, 2020.

\bibitem[Batir(2008)]{batir2008new}
Necdet Batir.
\newblock New inequalities for the hurwitz zeta function.
\newblock \emph{Proceedings Mathematical Sciences}, 2008.

\bibitem[Benedetto and Czaja(2009)]{benedetto2009integration}
John~J Benedetto and Wojciech Czaja.
\newblock \emph{Integration and modern analysis}.
\newblock Springer, 2009.

\bibitem[Boularias et~al.(2011)Boularias, Kober, and
  Peters]{boularias2011relative}
Abdeslam Boularias, Jens Kober, and Jan Peters.
\newblock Relative entropy inverse reinforcement learning.
\newblock In \emph{AISTATS}, 2011.

\bibitem[Cooke(1950)]{cooke1950infinite}
R.G. Cooke.
\newblock \emph{Infinite Matrices and Sequence Spaces}.
\newblock Macmillan, 1950.
\newblock URL \url{https://books.google.com/books?id=T9Y0AAAAMAAJ}.

\bibitem[Finn et~al.(2016)Finn, Levine, and Abbeel]{finn2016guided}
Chelsea Finn, Sergey Levine, and Pieter Abbeel.
\newblock Guided cost learning: Deep inverse optimal control via policy
  optimization.
\newblock In \emph{ICML}, 2016.

\bibitem[Gershman et~al.(2009)Gershman, Pesaran, and Daw]{gershman2009human}
Samuel~J Gershman, Bijan Pesaran, and Nathaniel~D Daw.
\newblock Human reinforcement learning subdivides structured action spaces by
  learning effector-specific values.
\newblock \emph{Journal of Neuroscience}, 29\penalty0 (43):\penalty0
  13524--13531, 2009.

\bibitem[Izumi and Izumi(1968)]{izumi1968absolute}
Masako Izumi and Shin-ichi Izumi.
\newblock Absolute convergence of fourier series of convolution functions.
\newblock \emph{Journal of Approximation Theory}, 1968.

\bibitem[Komanduru and Honorio(2019)]{komanduru}
Abi Komanduru and Jean Honorio.
\newblock On the correctness and sample complexity of inverse reinforcement
  learning.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Levine and Koltun(2012)]{levine2012continuous}
Sergey Levine and Vladlen Koltun.
\newblock Continuous inverse optimal control with locally optimal examples.
\newblock In \emph{ICML}, 2012.

\bibitem[McLean and Woerdeman(2002)]{mclean2002spectral}
Jeremy~W McLean and Hugo~J Woerdeman.
\newblock Spectral factorizations and sums of squares representations via
  semidefinite programming.
\newblock \emph{SIAM journal on matrix analysis and applications}, 2002.

\bibitem[Metelli et~al.(2017)Metelli, Pirotta, and
  Restelli]{metelli2017compatible}
Alberto Metelli, Matteo Pirotta, and Marcello Restelli.
\newblock Compatible reward inverse reinforcement learning.
\newblock In \emph{The Thirty-first Annual Conference on Neural Information
  Processing Systems-NIPS 2017}, 2017.

\bibitem[Metelli et~al.(2021)Metelli, Ramponi, Concetti, and
  Restelli]{metelli2021provably}
Alberto~Maria Metelli, Giorgia Ramponi, Alessandro Concetti, and Marcello
  Restelli.
\newblock Provably efficient learning of transferable rewards.
\newblock In \emph{International Conference on Machine Learning}, pages
  7665--7676. PMLR, 2021.

\bibitem[Ng and Russell(2000)]{ng2000algorithms}
Andrew~Y Ng and Stuart Russell.
\newblock Algorithms for inverse reinforcement learning.
\newblock In \emph{ICML}, 2000.

\bibitem[Pirotta and Restelli(2016)]{pirotta2016inverse}
Matteo Pirotta and Marcello Restelli.
\newblock Inverse reinforcement learning through policy gradient minimization.
\newblock In \emph{Thirtieth AAAI Conference on Artificial Intelligence}, 2016.

\bibitem[Ramponi et~al.(2020)Ramponi, Likmeta, Metelli, Tirinzoni, and
  Restelli]{ramponi2020truly}
Giorgia Ramponi, Amarildo Likmeta, Alberto~Maria Metelli, Andrea Tirinzoni, and
  Marcello Restelli.
\newblock Truly batch model-free inverse reinforcement learning about multiple
  intentions.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 2359--2369. PMLR, 2020.

\bibitem[Rothkopf and Ballard(2013)]{rothkopf2013modular}
Constantin~A Rothkopf and Dana~H Ballard.
\newblock Modular inverse reinforcement learning for visuomotor behavior.
\newblock \emph{Biological cybernetics}, 107\penalty0 (4):\penalty0 477--490,
  2013.

\bibitem[Shivakumar and Sivakumar(2009)]{shivakumar2009review}
PN~Shivakumar and KC~Sivakumar.
\newblock A review of infinite matrices and their applications.
\newblock \emph{Linear Algebra and its Applications}, 430\penalty0
  (4):\penalty0 976--998, 2009.

\bibitem[Sutton and Barto(2018)]{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\end{thebibliography}
