\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Antunes et~al.(2018)Antunes, Ribeiro, Pereira, and
  Gomes]{Antunes2018b}
F.~Antunes, B.~Ribeiro, F.~C. Pereira, and R.~Gomes.
\newblock {Efficient Transport Simulation With Restricted Batch-Mode Active
  Learning}.
\newblock \emph{IEEE Transactions on Intelligent Transportation Systems},
  19\penalty0 (11):\penalty0 3642--3651, nov 2018.
\newblock ISSN 1524-9050.
\newblock \doi{10.1109/TITS.2018.2842695}.
\newblock URL \url{https://ieeexplore.ieee.org/document/8419064/}.

\bibitem[Bingham et~al.(2019)Bingham, Chen, Jankowiak, Obermeyer, Pradhan,
  Karaletsos, Singh, Szerlip, Horsfall, and Goodman]{bingham2018pyro}
E.~Bingham, J.~P. Chen, M.~Jankowiak, F.~Obermeyer, N.~Pradhan, T.~Karaletsos,
  R.~Singh, P.~Szerlip, P.~Horsfall, and N.~D. Goodman.
\newblock Pyro: Deep universal probabilistic programming.
\newblock \emph{The Journal of Machine Learning Research}, 20\penalty0
  (1):\penalty0 973--978, 2019.
\newblock URL \url{https://jmlr.csail.mit.edu/papers/v20/18-403}.

\bibitem[Bishop(2006)]{Bishop2006}
C.~M. Bishop.
\newblock \emph{{Pattern Recognition and Machine Learning}}.
\newblock Springer, 2006.
\newblock ISBN 978-0387-31073-2.
\newblock URL
  \url{http://research.microsoft.com/en-us/um/people/cmbishop/prml/}.

\bibitem[Burbidge et~al.(2007)Burbidge, Rowland, and King]{Burbidge2007}
R.~Burbidge, J.~J. Rowland, and R.~D. King.
\newblock {Active learning for regression based on query by committee}.
\newblock \emph{Lecture Notes in Computer Science (including subseries Lecture
  Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}, 4881
  LNCS:\penalty0 209--218, 2007.
\newblock ISSN 16113349.
\newblock \doi{10.1007/978-3-540-77226-2_22}.

\bibitem[Cai et~al.(2013)Cai, Zhang, and Zhou]{Cai2013}
W.~Cai, Y.~Zhang, and J.~Zhou.
\newblock {Maximizing expected model change for active learning in regression}.
\newblock \emph{Proceedings - IEEE International Conference on Data Mining,
  ICDM}, pages 51--60, 2013.
\newblock ISSN 15504786.
\newblock \doi{10.1109/ICDM.2013.104}.

\bibitem[Chabanet et~al.(2021)Chabanet, El-Haouzi, and
  Thomas]{chabanet2021coupling}
S.~Chabanet, H.~B. El-Haouzi, and P.~Thomas.
\newblock Coupling digital simulation and machine learning metamodel through an
  active learning approach in industry 4.0 context.
\newblock \emph{Computers in Industry}, 133:\penalty0 103529, 2021.

\bibitem[Chen and Ren(2009)]{Chen2009}
T.~Chen and J.~Ren.
\newblock {Bagging for Gaussian process regression}.
\newblock \emph{Neurocomputing}, 72\penalty0 (7-9):\penalty0 1605--1610, 2009.
\newblock ISSN 09252312.
\newblock \doi{10.1016/j.neucom.2008.09.002}.

\bibitem[Cole et~al.(2022)Cole, Gramacy, Warner, Bomarito, Leser, and
  Leser]{Cole2021}
D.~A. Cole, R.~B. Gramacy, J.~E. Warner, G.~F. Bomarito, P.~E. Leser, and W.~P.
  Leser.
\newblock Entropy-based adaptive design for contour finding and estimating
  reliability.
\newblock \emph{Journal of Quality Technology}, pages 1--18, 2022.
\newblock URL \url{https://doi.org/10.1080/00224065.2022.2053795}.

\bibitem[Fernandez et~al.(2020)Fernandez, Martino, Elvira, Delgado, and
  Lopez-Santiago]{Fernandez2020}
F.~L. Fernandez, L.~Martino, V.~Elvira, D.~Delgado, and J.~Lopez-Santiago.
\newblock {Adaptive Quadrature Schemes for Bayesian Inference via Active
  Learning}.
\newblock \emph{IEEE Access}, 8:\penalty0 208462--208483, 2020.
\newblock ISSN 21693536.
\newblock \doi{10.1109/ACCESS.2020.3038333}.

\bibitem[Gardner et~al.(2018)Gardner, Pleiss, Bindel, Weinberger, and
  Wilson]{Gardner2018}
J.~R. Gardner, G.~Pleiss, D.~Bindel, K.~Q. Weinberger, and A.~G. Wilson.
\newblock {Gpytorch: Blackbox matrix-matrix Gaussian process inference with GPU
  acceleration}.
\newblock \emph{Advances in Neural Information Processing Systems},
  31:\penalty0 7576--7586, 2018.
\newblock ISSN 10495258.

\bibitem[Gorissen et~al.(2009)Gorissen, Crombecq, Couckuyt, and
  Dhaene]{gorissen2009automatic}
D.~Gorissen, K.~Crombecq, I.~Couckuyt, and T.~Dhaene.
\newblock Automatic approximation of expensive functions with active learning.
\newblock In \emph{Foundations of Computational, Intelligence Volume 1}, pages
  35--62. Springer, 2009.

\bibitem[Gramacy(2020)]{Gramacy2020}
R.~B. Gramacy.
\newblock \emph{{Surrogates}}.
\newblock Chapman and Hall/CRC, mar 2020.
\newblock ISBN 9780367815493.
\newblock \doi{10.1201/9780367815493}.
\newblock URL \url{https://www.taylorfrancis.com/books/9781000766202}.

\bibitem[Gramacy and Lee(2008)]{Gramacy2008}
R.~B. Gramacy and H.~K. Lee.
\newblock Bayesian treed gaussian process models with an application to
  computer modeling.
\newblock \emph{Journal of the American Statistical Association}, 103, 2008.
\newblock ISSN 01621459.
\newblock \doi{10.1198/016214508000000689}.

\bibitem[Gramacy and Lee(2009)]{Gramacy2009}
R.~B. Gramacy and H.~K. Lee.
\newblock {Adaptive design and analysis of supercomputer experiments}.
\newblock \emph{Technometrics}, 51\penalty0 (2):\penalty0 130--145, 2009.
\newblock ISSN 00401706.
\newblock \doi{10.1198/TECH.2009.0015}.
\newblock URL \url{https://doi.org/10.1198/TECH.2009.0015}.

\bibitem[Gramacy and Lee(2012)]{Gramacy2012}
R.~B. Gramacy and H.~K. Lee.
\newblock Cases for the nugget in modeling computer experiments.
\newblock \emph{Statistics and Computing}, 22, 2012.
\newblock ISSN 09603174.
\newblock \doi{10.1007/s11222-010-9224-x}.

\bibitem[Guestrin et~al.(2005)Guestrin, Krause, and Singh]{Guestrin2005}
C.~Guestrin, A.~Krause, and A.~P. Singh.
\newblock {Near-optimal sensor placements in Gaussian processes}.
\newblock In \emph{Proceedings of the 22nd international conference on Machine
  learning - ICML '05}, volume~1, pages 265--272, New York, New York, USA,
  2005. ACM Press.
\newblock ISBN 1595931805.
\newblock \doi{10.1145/1102351.1102385}.
\newblock URL \url{http://portal.acm.org/citation.cfm?doid=1102351.1102385}.

\bibitem[Hensman et~al.(2015)Hensman, Matthews, and
  Ghahramani]{hensman2015scalable}
J.~Hensman, A.~Matthews, and Z.~Ghahramani.
\newblock Scalable variational gaussian process classification.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 351--360.
  PMLR, 2015.

\bibitem[Hoffman and Gelman(2014)]{Hoffman2014}
M.~D. Hoffman and A.~Gelman.
\newblock The no-u-turn sampler: adaptively setting path lengths in hamiltonian
  monte carlo.
\newblock \emph{J. Mach. Learn. Res.}, 15\penalty0 (1):\penalty0 1593--1623,
  2014.

\bibitem[Houlsby et~al.(2011)Houlsby, Husz{\'{a}}r, Ghahramani, and
  Lengyel]{Houlsby2011}
N.~Houlsby, F.~Husz{\'{a}}r, Z.~Ghahramani, and M.~Lengyel.
\newblock {Bayesian Active Learning for Classification and Preference
  Learning}.
\newblock \emph{arXiv}, pages 1--17, 2011.
\newblock URL \url{http://arxiv.org/abs/1112.5745}.

\bibitem[Houlsby et~al.(2012)Houlsby, Huszar, Ghahramani, and
  Hern{\'a}ndez-lobato]{houlsby2012collaborative}
N.~Houlsby, F.~Huszar, Z.~Ghahramani, and J.~Hern{\'a}ndez-lobato.
\newblock Collaborative gaussian processes for preference learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 25, 2012.

\bibitem[Iswanto(2021)]{Iswanto2021}
B.~H. Iswanto.
\newblock {Active learning by increasing model likelihood for Gaussian mixture
  models based classifiers}.
\newblock \emph{IOP Conference Series: Materials Science and Engineering},
  1098\penalty0 (3):\penalty0 032036, mar 2021.
\newblock ISSN 1757-8981.
\newblock \doi{10.1088/1757-899X/1098/3/032036}.
\newblock URL
  \url{https://iopscience.iop.org/article/10.1088/1757-899X/1098/3/032036}.

\bibitem[Keane et~al.(2008)Keane, Forrester, and Sobester]{Keane2008}
A.~Keane, A.~Forrester, and A.~Sobester.
\newblock \emph{Engineering Design via Surrogate Modelling: A Practical Guide}.
\newblock John Wiley \& Sons, 2008.
\newblock \doi{10.2514/4.479557}.

\bibitem[Kirsch et~al.(2019)Kirsch, van Amersfoort, and Gal]{Kirsch2019a}
A.~Kirsch, J.~van Amersfoort, and Y.~Gal.
\newblock {BatchBALD: Efficient and diverse batch acquisition for deep Bayesian
  active learning}.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.
\newblock ISSN 10495258.

\bibitem[Krogh and Vedelsby(1995)]{Krogh1995}
A.~Krogh and J.~Vedelsby.
\newblock {Neural network ensembles, cross validation, and active learning}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~7, pages 231--238, 1995.

\bibitem[Lalchand and Rasmussen(2020)]{Lalchand2019}
V.~Lalchand and C.~E. Rasmussen.
\newblock Approximate inference for fully bayesian gaussian process regression.
\newblock In \emph{Symposium on Advances in Approximate Bayesian Inference},
  pages 1--12. PMLR, 2020.

\bibitem[MacKay(1992)]{MacKay1992}
D.~J.~C. MacKay.
\newblock {Information-Based Objective Functions for Active Data Selection}.
\newblock \emph{Neural Computation}, 4\penalty0 (4):\penalty0 590--604, 1992.
\newblock ISSN 0899-7667.
\newblock \doi{10.1162/neco.1992.4.4.590}.

\bibitem[Marrel et~al.(2009)Marrel, Iooss, Laurent, and Roustant]{Marrel2009}
A.~Marrel, B.~Iooss, B.~Laurent, and O.~Roustant.
\newblock Calculations of sobol indices for the gaussian process metamodel.
\newblock \emph{Reliability Engineering and System Safety}, 94, 2009.
\newblock ISSN 09518320.
\newblock \doi{10.1016/j.ress.2008.07.008}.

\bibitem[O'Neill et~al.(2017)O'Neill, {Jane Delany}, and MacNamee]{ONeill2017}
J.~O'Neill, S.~{Jane Delany}, and B.~MacNamee.
\newblock {Model-Free and Model-Based Active Learning for Regression}.
\newblock In \emph{Advances in computational intelligence systems}, pages
  375--386. Springer, 2017.
\newblock ISBN 9783319465623.
\newblock \doi{10.1007/978-3-319-46562-3_24}.
\newblock URL \url{http://link.springer.com/10.1007/978-3-319-46562-3{\_}24}.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos,
  Cournapeau, Brucher, Perrot, and Duchesnay]{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2825--2830,
  2011.

\bibitem[Picheny et~al.(2013)Picheny, Wagner, and Ginsbourger]{Picheny2013}
V.~Picheny, T.~Wagner, and D.~Ginsbourger.
\newblock A benchmark of kriging-based infill criteria for noisy optimization.
\newblock \emph{Structural and Multidisciplinary Optimization}, 48, 2013.
\newblock ISSN 16151488.
\newblock \doi{10.1007/s00158-013-0919-4}.

\bibitem[RayChaudhuri and Hamey(1995)]{RayChaudhuri1995}
T.~RayChaudhuri and L.~G. Hamey.
\newblock {Minimization of data collection by active learning}.
\newblock \emph{IEEE International Conference on Neural Networks - Conference
  Proceedings}, 3:\penalty0 1338--1341, 1995.
\newblock \doi{10.1109/icnn.1995.487351}.

\bibitem[Riis et~al.(2021)Riis, Antunes, Gurtner, Pereira, Delgado, and {Lima
  Azevedo}]{Riis2021}
C.~Riis, F.~Antunes, G.~Gurtner, F.~C. Pereira, L.~Delgado, and C.~M. {Lima
  Azevedo}.
\newblock Active learning metamodels for atm simulation modeling.
\newblock In \emph{Proceedings of the 11th SESAR Innovation Days, 2021}, 2021.
\newblock URL \url{https://www.sesarju.eu/SIDs2021}.

\bibitem[Sauer et~al.(2022)Sauer, Gramacy, and Higdon]{Sauer2020}
A.~Sauer, R.~B. Gramacy, and D.~Higdon.
\newblock Active learning for deep gaussian process surrogates.
\newblock \emph{Technometrics}, 0\penalty0 (0):\penalty0 1--15, 2022.
\newblock \doi{10.1080/00401706.2021.2008505}.
\newblock URL \url{https://doi.org/10.1080/00401706.2021.2008505}.

\bibitem[Settles(2009)]{Settles2009}
B.~Settles.
\newblock \emph{Active learning literature survey}.
\newblock University of Wisconsin-Madison Department of Computer Sciences,
  2009.

\bibitem[Seung et~al.(1992)Seung, Opper, and Sompolinsky]{Seung1992}
H.~S. Seung, M.~Opper, and H.~Sompolinsky.
\newblock {Query by committee}.
\newblock In \emph{Proceedings of the fifth annual workshop on Computational
  learning theory - COLT '92}, pages 287--294, New York, New York, USA, 1992.
  ACM Press.
\newblock ISBN 089791497X.
\newblock \doi{10.1145/130385.130417}.
\newblock URL \url{http://portal.acm.org/citation.cfm?doid=130385.130417}.

\bibitem[Silverman(1985)]{Silverman1985}
B.~W. Silverman.
\newblock Some aspects of the spline smoothing approach to non-parametric
  regression curve fitting.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 47, 1985.
\newblock ISSN 0035-9246.
\newblock \doi{10.1111/j.2517-6161.1985.tb01327.x}.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{Snoek2012}
J.~Snoek, H.~Larochelle, and R.~P. Adams.
\newblock Practical bayesian optimization of machine learning algorithms.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~4, 2012.

\bibitem[Surjanovic and Bingham(2022)]{simulationlib}
S.~Surjanovic and D.~Bingham.
\newblock Virtual library of simulation experiments: Test functions and
  datasets.
\newblock Retrieved June 3, 2022, from \url{http://www.sfu.ca/~ssurjano}, 2022.

\bibitem[Svendsen et~al.(2020)Svendsen, Martino, and Camps-Valls]{Svendsen2020}
D.~H. Svendsen, L.~Martino, and G.~Camps-Valls.
\newblock {Active emulation of computer codes with Gaussian processes –
  Application to remote sensing}.
\newblock \emph{Pattern Recognition}, 100:\penalty0 107103, 2020.
\newblock ISSN 00313203.
\newblock \doi{10.1016/j.patcog.2019.107103}.
\newblock URL \url{https://doi.org/10.1016/j.patcog.2019.107103}.

\bibitem[Van~Kempen and Van~Vliet(2000)]{vanKempen2000}
G.~Van~Kempen and L.~Van~Vliet.
\newblock Mean and variance of ratio estimators used in fluorescence ratio
  imaging.
\newblock \emph{Cytometry: The Journal of the International Society for
  Analytical Cytology}, 39\penalty0 (4):\penalty0 300--305, 2000.

\bibitem[Williams and Rasmussen(1995)]{Williams1996}
C.~Williams and C.~Rasmussen.
\newblock Gaussian processes for regression.
\newblock \emph{Advances in Neural Information Processing Systems}, 8, 1995.

\bibitem[Williams and Rasmussen(2006)]{Rasmussen2006}
C.~K. Williams and C.~E. Rasmussen.
\newblock \emph{{Gaussian processes for machine learning}}, volume~2.
\newblock MIT press Cambridge, MA, 2006.

\bibitem[Wu(2018)]{Wu2018}
D.~Wu.
\newblock {Pool-Based Sequential Active Learning for Regression}.
\newblock \emph{Transactions on Neural Networks and Learning Systems},
  30\penalty0 (5):\penalty0 1348--1359, 2018.
\newblock ISSN 23318422.

\bibitem[Wu et~al.(2019)Wu, Lin, and Huang]{Wu2019a}
D.~Wu, C.~T. Lin, and J.~Huang.
\newblock {Active learning for regression using greedy sampling}.
\newblock \emph{Information Sciences}, 474:\penalty0 90--105, 2019.
\newblock ISSN 00200255.
\newblock \doi{10.1016/j.ins.2018.09.060}.
\newblock URL \url{https://doi.org/10.1016/j.ins.2018.09.060}.

\bibitem[Yang and Loog(2018)]{yang2018benchmark}
Y.~Yang and M.~Loog.
\newblock A benchmark and comparison of active learning for logistic
  regression.
\newblock \emph{Pattern Recognition}, 83:\penalty0 401--415, 2018.

\bibitem[Yao et~al.(2022)Yao, Vehtari, and Gelman]{Yao2020}
Y.~Yao, A.~Vehtari, and A.~Gelman.
\newblock Stacking for non-mixing bayesian computations: The curse and blessing
  of multimodal posteriors.
\newblock \emph{Journal of Machine Learning Research}, 23\penalty0
  (79):\penalty0 1--45, 2022.
\newblock URL \url{http://jmlr.org/papers/v23/20-1426}.

\bibitem[Zhao et~al.(2020)Zhao, Sun, Wang, and Cao]{Zhao2020a}
J.~Zhao, S.~Sun, H.~Wang, and Z.~Cao.
\newblock {Promoting active learning with mixtures of Gaussian processes}.
\newblock \emph{Knowledge-Based Systems}, 188:\penalty0 105044, 2020.
\newblock ISSN 09507051.
\newblock \doi{10.1016/j.knosys.2019.105044}.
\newblock URL \url{https://doi.org/10.1016/j.knosys.2019.105044}.

\end{thebibliography}
