\begin{thebibliography}{56}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achiam et~al.(2018)Achiam, Edwards, Amodei, and
  Abbeel]{achiam2018valor}
J.~Achiam, H.~Edwards, D.~Amodei, and P.~Abbeel.
\newblock Variational option discovery algorithms.
\newblock \emph{arXiv preprint arXiv:1807.10299}, 2018.

\bibitem[Andrychowicz et~al.(2017)Andrychowicz, Wolski, Ray, Schneider, Fong,
  Welinder, McGrew, Tobin, Abbeel, and Zaremba]{andrychowicz2017hindsight}
M.~Andrychowicz, F.~Wolski, A.~Ray, J.~Schneider, R.~Fong, P.~Welinder,
  B.~McGrew, J.~Tobin, P.~Abbeel, and W.~Zaremba.
\newblock Hindsight experience replay.
\newblock \emph{arXiv preprint arXiv:1707.01495}, 2017.

\bibitem[Ball et~al.(2020)Ball, Parker-Holder, Pacchiano, Choromanski, and
  Roberts]{ball2020ready}
P.~Ball, J.~Parker-Holder, A.~Pacchiano, K.~Choromanski, and S.~Roberts.
\newblock Ready policy one: World building through active learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  591--601. PMLR, 2020.

\bibitem[Bellemare et~al.(2016)Bellemare, Srinivasan, Ostrovski, Schaul,
  Saxton, and Munos]{bellemare2016cts}
M.~Bellemare, S.~Srinivasan, G.~Ostrovski, T.~Schaul, D.~Saxton, and R.~Munos.
\newblock Unifying count-based exploration and intrinsic motivation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1471--1479, 2016.

\bibitem[Beyer et~al.(2019)Beyer, Vincent, Teboul, Gelly, Geist, and
  Pietquin]{beyer2019mulex}
L.~Beyer, D.~Vincent, O.~Teboul, S.~Gelly, M.~Geist, and O.~Pietquin.
\newblock Mulex: Disentangling exploitation from exploration in deep rl.
\newblock \emph{arXiv preprint arXiv:1907.00868}, 2019.

\bibitem[Bucher et~al.(2020)Bucher, Schmeckpeper, Matni, and
  Daniilidis]{bucher2020adversarial}
B.~Bucher, K.~Schmeckpeper, N.~Matni, and K.~Daniilidis.
\newblock Adversarial curiosity.
\newblock \emph{arXiv preprint arXiv:2003.06082}, 2020.

\bibitem[Buesing et~al.(2018)Buesing, Weber, Racaniere, Eslami, Rezende,
  Reichert, Viola, Besse, Gregor, Hassabis, et~al.]{buesing2018dssm}
L.~Buesing, T.~Weber, S.~Racaniere, S.~Eslami, D.~Rezende, D.~P. Reichert,
  F.~Viola, F.~Besse, K.~Gregor, D.~Hassabis, et~al.
\newblock Learning and querying fast generative models for reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1802.03006}, 2018.

\bibitem[Burda et~al.(2018)Burda, Edwards, Storkey, and Klimov]{burda2018rnd}
Y.~Burda, H.~Edwards, A.~Storkey, and O.~Klimov.
\newblock Exploration by random network distillation.
\newblock \emph{arXiv preprint arXiv:1810.12894}, 2018.

\bibitem[Campos et~al.(2020)Campos, Trott, Xiong, Socher, Gir{\'o}-i Nieto, and
  Torres]{campos2020explore}
V.~Campos, A.~Trott, C.~Xiong, R.~Socher, X.~Gir{\'o}-i Nieto, and J.~Torres.
\newblock Explore, discover and learn: Unsupervised discovery of state-covering
  skills.
\newblock In \emph{International Conference on Machine Learning}, pages
  1317--1327. PMLR, 2020.

\bibitem[Chebotar et~al.(2021)Chebotar, Hausman, Lu, Xiao, Kalashnikov, Varley,
  Irpan, Eysenbach, Julian, Finn, et~al.]{chebotar2021actionable}
Y.~Chebotar, K.~Hausman, Y.~Lu, T.~Xiao, D.~Kalashnikov, J.~Varley, A.~Irpan,
  B.~Eysenbach, R.~Julian, C.~Finn, et~al.
\newblock Actionable models: Unsupervised offline reinforcement learning of
  robotic skills.
\newblock \emph{arXiv preprint arXiv:2104.07749}, 2021.

\bibitem[Cho et~al.(2014)Cho, Van~Merri{\"e}nboer, Gulcehre, Bahdanau,
  Bougares, Schwenk, and Bengio]{cho2014gru}
K.~Cho, B.~Van~Merri{\"e}nboer, C.~Gulcehre, D.~Bahdanau, F.~Bougares,
  H.~Schwenk, and Y.~Bengio.
\newblock Learning phrase representations using rnn encoder-decoder for
  statistical machine translation.
\newblock \emph{arXiv preprint arXiv:1406.1078}, 2014.

\bibitem[Choi et~al.(2020)Choi, Sharma, Levine, Lee, and
  Gu]{choi2020variational}
J.~Choi, A.~Sharma, S.~Levine, H.~Lee, and S.~S. Gu.
\newblock Variational empowerment as representation learning for goal-based
  reinforcement learning.
\newblock In \emph{Deep Reinforcement Learning workshop at the Conference on
  Neural Information Processing Systems (DRL)}, 2020.

\bibitem[Ebert et~al.(2018)Ebert, Finn, Dasari, Xie, Lee, and
  Levine]{ebert2018foresight}
F.~Ebert, C.~Finn, S.~Dasari, A.~Xie, A.~Lee, and S.~Levine.
\newblock Visual foresight: Model-based deep reinforcement learning for
  vision-based robotic control.
\newblock \emph{arXiv preprint arXiv:1812.00568}, 2018.

\bibitem[Ecoffet et~al.(2019)Ecoffet, Huizinga, Lehman, Stanley, and
  Clune]{ecoffet2019go}
A.~Ecoffet, J.~Huizinga, J.~Lehman, K.~O. Stanley, and J.~Clune.
\newblock Go-explore: a new approach for hard-exploration problems.
\newblock \emph{arXiv preprint arXiv:1901.10995}, 2019.

\bibitem[Eysenbach et~al.(2018)Eysenbach, Gupta, Ibarz, and
  Levine]{eysenbach2018diayn}
B.~Eysenbach, A.~Gupta, J.~Ibarz, and S.~Levine.
\newblock Diversity is all you need: learning skills without a reward function.
\newblock \emph{arXiv preprint arXiv:1802.06070}, 2018.

\bibitem[Eysenbach et~al.(2019)Eysenbach, Salakhutdinov, and
  Levine]{eysenbach2019search}
B.~Eysenbach, R.~Salakhutdinov, and S.~Levine.
\newblock Search on the replay buffer: Bridging planning and reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1906.05253}, 2019.

\bibitem[Finn and Levine(2017)]{finn2017foresight}
C.~Finn and S.~Levine.
\newblock Deep visual foresight for planning robot motion.
\newblock In \emph{Robotics and Automation (ICRA), 2017 IEEE International
  Conference on}, pages 2786--2793. IEEE, 2017.

\bibitem[Florensa et~al.(2018)Florensa, Held, Geng, and
  Abbeel]{florensa2018automatic}
C.~Florensa, D.~Held, X.~Geng, and P.~Abbeel.
\newblock Automatic goal generation for reinforcement learning agents.
\newblock In \emph{International conference on machine learning}, pages
  1515--1528. PMLR, 2018.

\bibitem[Florensa et~al.(2019)Florensa, Degrave, Heess, Springenberg, and
  Riedmiller]{florensa2019self}
C.~Florensa, J.~Degrave, N.~Heess, J.~T. Springenberg, and M.~Riedmiller.
\newblock Self-supervised learning of image embedding for continuous control.
\newblock \emph{arXiv preprint arXiv:1901.00943}, 2019.

\bibitem[Ghosh et~al.(2019)Ghosh, Gupta, Fu, Reddy, Devin, Eysenbach, and
  Levine]{ghosh2019learning}
D.~Ghosh, A.~Gupta, J.~Fu, A.~Reddy, C.~Devin, B.~Eysenbach, and S.~Levine.
\newblock Learning to reach goals without reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1912.06088}, 2019.

\bibitem[Gregor et~al.(2016)Gregor, Rezende, and Wierstra]{gregor2016vic}
K.~Gregor, D.~J. Rezende, and D.~Wierstra.
\newblock Variational intrinsic control.
\newblock \emph{arXiv preprint arXiv:1611.07507}, 2016.

\bibitem[Gupta et~al.(2019)Gupta, Kumar, Lynch, Levine, and
  Hausman]{gupta2019relay}
A.~Gupta, V.~Kumar, C.~Lynch, S.~Levine, and K.~Hausman.
\newblock Relay policy learning: Solving long-horizon tasks via imitation and
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1910.11956}, 2019.

\bibitem[Hafner et~al.(2018)Hafner, Lillicrap, Fischer, Villegas, Ha, Lee, and
  Davidson]{hafner2018planet}
D.~Hafner, T.~Lillicrap, I.~Fischer, R.~Villegas, D.~Ha, H.~Lee, and
  J.~Davidson.
\newblock Learning latent dynamics for planning from pixels.
\newblock \emph{arXiv preprint arXiv:1811.04551}, 2018.

\bibitem[Hafner et~al.(2019)Hafner, Lillicrap, Ba, and
  Norouzi]{hafner2019dreamer}
D.~Hafner, T.~Lillicrap, J.~Ba, and M.~Norouzi.
\newblock Dream to control: Learning behaviors by latent imagination.
\newblock \emph{arXiv preprint arXiv:1912.01603}, 2019.

\bibitem[Hafner et~al.(2020)Hafner, Lillicrap, Norouzi, and
  Ba]{hafner2020dreamerv2}
D.~Hafner, T.~Lillicrap, M.~Norouzi, and J.~Ba.
\newblock Mastering atari with discrete world models.
\newblock \emph{arXiv preprint arXiv:2010.02193}, 2020.

\bibitem[Hartikainen et~al.(2020)Hartikainen, Geng, Haarnoja, and
  Levine]{hartikainen2019dynamical}
K.~Hartikainen, X.~Geng, T.~Haarnoja, and S.~Levine.
\newblock Dynamical distance learning for semi-supervised and unsupervised
  skill discovery.
\newblock \emph{ICLR}, 2020.

\bibitem[Kaelbling(1993)]{kaelbling1993learning}
L.~P. Kaelbling.
\newblock Learning to achieve goals.
\newblock In \emph{IJCAI}, pages 1094--1099. Citeseer, 1993.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma and Welling(2013)]{kingma2013vae}
D.~P. Kingma and M.~Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Lakshminarayanan et~al.(2016)Lakshminarayanan, Pritzel, and
  Blundell]{lakshminarayanan2016simple}
B.~Lakshminarayanan, A.~Pritzel, and C.~Blundell.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock \emph{arXiv preprint arXiv:1612.01474}, 2016.

\bibitem[Lindley et~al.(1956)]{lindley1956expectedinfo}
D.~V. Lindley et~al.
\newblock On a measure of the information provided by an experiment.
\newblock \emph{The Annals of Mathematical Statistics}, 27\penalty0
  (4):\penalty0 986--1005, 1956.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015dqn}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~A. Rusu, J.~Veness, M.~G. Bellemare,
  A.~Graves, M.~Riedmiller, A.~K. Fidjeland, G.~Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529, 2015.

\bibitem[Nair et~al.(2018)Nair, Pong, Dalal, Bahl, Lin, and
  Levine]{nair2018imagined}
A.~V. Nair, V.~Pong, M.~Dalal, S.~Bahl, S.~Lin, and S.~Levine.
\newblock Visual reinforcement learning with imagined goals.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  9191--9200, 2018.

\bibitem[OpenAI et~al.(2021)OpenAI, Plappert, Sampedro, Xu, Akkaya, Kosaraju,
  Welinder, D'Sa, Petron, Pinto, et~al.]{openai2021asymmetric}
O.~OpenAI, M.~Plappert, R.~Sampedro, T.~Xu, I.~Akkaya, V.~Kosaraju,
  P.~Welinder, R.~D'Sa, A.~Petron, H.~P. d.~O. Pinto, et~al.
\newblock Asymmetric self-play for automatic goal discovery in robotic
  manipulation.
\newblock \emph{arXiv preprint arXiv:2101.04882}, 2021.

\bibitem[Pathak et~al.(2017)Pathak, Agrawal, Efros, and Darrell]{pathak2017icm}
D.~Pathak, P.~Agrawal, A.~A. Efros, and T.~Darrell.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition Workshops}, pages 16--17, 2017.

\bibitem[Pathak et~al.(2018)Pathak, Mahmoudieh, Luo, Agrawal, Chen, Shentu,
  Shelhamer, Malik, Efros, and Darrell]{pathak2018zero}
D.~Pathak, P.~Mahmoudieh, G.~Luo, P.~Agrawal, D.~Chen, Y.~Shentu, E.~Shelhamer,
  J.~Malik, A.~A. Efros, and T.~Darrell.
\newblock Zero-shot visual imitation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition workshops}, pages 2050--2053, 2018.

\bibitem[Pathak et~al.(2019)Pathak, Gandhi, and Gupta]{pathak2019disagreement}
D.~Pathak, D.~Gandhi, and A.~Gupta.
\newblock Self-supervised exploration via disagreement.
\newblock In \emph{International Conference on Machine Learning}, pages
  5062--5071, 2019.

\bibitem[Pong et~al.(2019)Pong, Dalal, Lin, Nair, Bahl, and
  Levine]{pong2019skewfit}
V.~H. Pong, M.~Dalal, S.~Lin, A.~Nair, S.~Bahl, and S.~Levine.
\newblock Skew-fit: State-covering self-supervised reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1903.03698}, 2019.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and Wierstra]{rezende2014vae}
D.~J. Rezende, S.~Mohamed, and D.~Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock \emph{arXiv preprint arXiv:1401.4082}, 2014.

\bibitem[Saxena et~al.(2021)Saxena, Ba, and Hafner]{saxena2021cwvae}
V.~Saxena, J.~Ba, and D.~Hafner.
\newblock Clockwork variational autoencoders.
\newblock \emph{arXiv preprint arXiv:2102.09532}, 2021.

\bibitem[Schaul et~al.(2015)Schaul, Horgan, Gregor, and
  Silver]{schaul2015universal}
T.~Schaul, D.~Horgan, K.~Gregor, and D.~Silver.
\newblock Universal value function approximators.
\newblock In \emph{International conference on machine learning}, pages
  1312--1320. PMLR, 2015.

\bibitem[Schmidhuber(1991)]{schmidhuber1991curiousmodel}
J.~Schmidhuber.
\newblock Curious model-building control systems.
\newblock In \emph{[Proceedings] 1991 IEEE International Joint Conference on
  Neural Networks}, pages 1458--1463. IEEE, 1991.

\bibitem[Schulz(2012)]{schulz2012finding}
L.~Schulz.
\newblock Finding new facts; thinking new thoughts.
\newblock \emph{Advances in child development and behavior}, 43:\penalty0
  269--294, 2012.

\bibitem[Sekar et~al.(2020)Sekar, Rybkin, Daniilidis, Abbeel, Hafner, and
  Pathak]{sekar2020plan2explore}
R.~Sekar, O.~Rybkin, K.~Daniilidis, P.~Abbeel, D.~Hafner, and D.~Pathak.
\newblock Planning to explore via self-supervised world models.
\newblock \emph{ICML}, 2020.

\bibitem[Shyam et~al.(2018)Shyam, Ja{\'s}kowski, and Gomez]{shyam2018max}
P.~Shyam, W.~Ja{\'s}kowski, and F.~Gomez.
\newblock Model-based active exploration.
\newblock \emph{arXiv preprint arXiv:1810.12162}, 2018.

\bibitem[Sukhbaatar et~al.(2018)Sukhbaatar, Lin, Kostrikov, Synnaeve, Szlam,
  and Fergus]{sukhbaatar2017intrinsic}
S.~Sukhbaatar, Z.~Lin, I.~Kostrikov, G.~Synnaeve, A.~Szlam, and R.~Fergus.
\newblock Intrinsic motivation and automatic curricula via asymmetric
  self-play.
\newblock \emph{ICLR}, 2018.

\bibitem[Sun et~al.(2011)Sun, Gomez, and Schmidhuber]{sun2011plansurprise}
Y.~Sun, F.~Gomez, and J.~Schmidhuber.
\newblock Planning to be surprised: Optimal bayesian exploration in dynamic
  environments.
\newblock In \emph{International Conference on Artificial General
  Intelligence}, pages 41--51. Springer, 2011.

\bibitem[Sutton and Barto(2018)]{sutton2018rl}
R.~S. Sutton and A.~G. Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Tassa et~al.(2018)Tassa, Doron, Muldal, Erez, Li, Casas, Budden,
  Abdolmaleki, Merel, Lefrancq, et~al.]{tassa2018dmcontrol}
Y.~Tassa, Y.~Doron, A.~Muldal, T.~Erez, Y.~Li, D.~d.~L. Casas, D.~Budden,
  A.~Abdolmaleki, J.~Merel, A.~Lefrancq, et~al.
\newblock Deepmind control suite.
\newblock \emph{arXiv preprint arXiv:1801.00690}, 2018.

\bibitem[Tian et~al.(2020)Tian, Nair, Ebert, Dasari, Eysenbach, Finn, and
  Levine]{tian2020model}
S.~Tian, S.~Nair, F.~Ebert, S.~Dasari, B.~Eysenbach, C.~Finn, and S.~Levine.
\newblock Model-based visual planning with self-supervised functional
  distances.
\newblock \emph{arXiv preprint arXiv:2012.15373}, 2020.

\bibitem[Warde-Farley et~al.(2018)Warde-Farley, Van~de Wiele, Kulkarni,
  Ionescu, Hansen, and Mnih]{warde2018discern}
D.~Warde-Farley, T.~Van~de Wiele, T.~Kulkarni, C.~Ionescu, S.~Hansen, and
  V.~Mnih.
\newblock Unsupervised control through non-parametric discriminative rewards.
\newblock \emph{arXiv preprint arXiv:1811.11359}, 2018.

\bibitem[Watter et~al.(2015)Watter, Springenberg, Boedecker, and
  Riedmiller]{watter2015embed}
M.~Watter, J.~T. Springenberg, J.~Boedecker, and M.~Riedmiller.
\newblock Embed to control: A locally linear latent dynamics model for control
  from raw images.
\newblock 2015.

\bibitem[Yarats et~al.(2021)Yarats, Fergus, Lazaric, and
  Pinto]{yarats2021drqv2}
D.~Yarats, R.~Fergus, A.~Lazaric, and L.~Pinto.
\newblock Mastering visual continuous control: Improved data-augmented
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2107.09645}, 2021.

\bibitem[Yu et~al.(2020)Yu, Quillen, He, Julian, Hausman, Finn, and
  Levine]{yu2020meta}
T.~Yu, D.~Quillen, Z.~He, R.~Julian, K.~Hausman, C.~Finn, and S.~Levine.
\newblock Meta-world: A benchmark and evaluation for multi-task and meta
  reinforcement learning.
\newblock In \emph{Conference on Robot Learning}, pages 1094--1100. PMLR, 2020.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and
  Wang]{zhang2018unreasonable}
R.~Zhang, P.~Isola, A.~A. Efros, E.~Shechtman, and O.~Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 586--595, 2018.

\bibitem[Zhang et~al.(2020)Zhang, Abbeel, and Pinto]{zhang2020automatic}
Y.~Zhang, P.~Abbeel, and L.~Pinto.
\newblock Automatic curriculum learning through value disagreement.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\end{thebibliography}
