@article{hinton2006fast,
  title={A fast learning algorithm for deep belief nets},
  author={Hinton, Geoffrey E and Osindero, Simon and Teh, Yee-Whye},
  journal={Neural computation},
  volume={18},
  number={7},
  pages={1527--1554},
  year={2006},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~â€¦}
}

@article{mcafee2012big,
  title={Big data: the management revolution},
  author={McAfee, Andrew and Brynjolfsson, Erik and Davenport, Thomas H and Patil, DJ and Barton, Dominic},
  journal={Harvard business review},
  volume={90},
  number={10},
  pages={60--68},
  year={2012},
  publisher={Cambridge}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{gu2016deep,
  title={Deep reinforcement learning for robotic manipulation},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  journal={arXiv preprint arXiv:1610.00633},
  volume={1},
  year={2016}
}

@article{li2019reinforcement,
  title={Reinforcement learning applications},
  author={Li, Yuxi},
  journal={arXiv preprint arXiv:1908.06973},
  year={2019}
}

@article{heaton2016deep,
  title={Deep portfolio theory},
  author={Heaton, JB and Polson, Nicholas G and Witte, JH},
  journal={arXiv preprint arXiv:1605.07230},
  year={2016}
}


@article{liu2021federated,
  title={Federated learning meets natural language processing: A survey},
  author={Liu, Ming and Ho, Stella and Wang, Mengqi and Gao, Longxiang and Jin, Yuan and Zhang, He},
  journal={arXiv preprint arXiv:2107.12603},
  year={2021}
}

@inproceedings{liu2021finrl,
  title={FinRL: Deep reinforcement learning framework to automate trading in quantitative finance},
  author={Liu, Xiao-Yang and Yang, Hongyang and Gao, Jiechao and Wang, Christina Dan},
  booktitle={Proceedings of the Second ACM International Conference on AI in Finance},
  pages={1--9},
  year={2021}
}

@inproceedings{bedi2022hidden,
  title={On the hidden biases of policy mirror ascent in continuous action spaces},
  author={Bedi, Amrit Singh and Chakraborty, Souradip and Parayil, Anjaly and Sadler, Brian M and Tokekar, Pratap and Koppel, Alec},
  booktitle={International Conference on Machine Learning},
  pages={1716--1731},
  year={2022},
  organization={PMLR}
}

@ARTICLE{qiu2021,
  author={Qiu, Shuang and Yang, Zhuoran and Ye, Jieping and Wang, Zhaoran},
  journal={IEEE Journal on Selected Areas in Information Theory}, 
  title={On Finite-Time Convergence of Actor-Critic Algorithm}, 
  year={2021},
  volume={2},
  number={2},
  pages={652-664},
  doi={10.1109/JSAIT.2021.3078754}}

  @book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@inproceedings{zhang2021,
  author    = {Yiming Zhang and
               Keith W. Ross},
  title     = {On-Policy Deep Reinforcement Learning for the Average-Reward Criterion},
  booktitle = {{ICML}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {12535--12545},
  publisher = {{PMLR}},
  year      = {2021}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016},
  organization={PMLR}
}


@article{borkar2000ode,
  title={The ODE method for convergence of stochastic approximation and reinforcement learning},
  author={Borkar, Vivek S and Meyn, Sean P},
  journal={SIAM Journal on Control and Optimization},
  volume={38},
  number={2},
  pages={447--469},
  year={2000},
  publisher={SIAM}
}

@article{pirotta2013adaptive,
  title={Adaptive step-size for policy gradient methods},
  author={Pirotta, Matteo and Restelli, Marcello and Bascetta, Luca},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  year={2013}
}

@article{pirotta2015policy,
  title={Policy gradient in lipschitz markov decision processes},
  author={Pirotta, Matteo and Restelli, Marcello and Bascetta, Luca},
  journal={Machine Learning},
  volume={100},
  pages={255--283},
  year={2015},
  publisher={Springer}
}

@inproceedings{agarwal2020optimality,
  title={Optimality and approximation with policy gradient methods in markov decision processes},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  booktitle={Conference on Learning Theory},
  pages={64--66},
  year={2020},
  organization={PMLR}
}


@inproceedings{wang2019neural,
  title={Neural Policy Gradient Methods: Global Optimality and Rates of Convergence},
  author={Wang, Lingxiao and Cai, Qi and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Learning Representations},
  year={2019}
}


@article{qiu2021finite,
  title={On finite-time convergence of actor-critic algorithm},
  author={Qiu, Shuang and Yang, Zhuoran and Ye, Jieping and Wang, Zhaoran},
  journal={IEEE Journal on Selected Areas in Information Theory},
  volume={2},
  number={2},
  pages={652--664},
  year={2021},
  publisher={IEEE}
}


@article{kumar2019sample,
  title={On the sample complexity of actor-critic method for reinforcement learning with function approximation},
  author={Kumar, Harshat and Koppel, Alec and Ribeiro, Alejandro},
  journal={arXiv preprint arXiv:1910.08412},
  year={2019}
}

@book{borkar2009stochastic,
  title={Stochastic approximation: a dynamical systems viewpoint},
  author={Borkar, Vivek S},
  volume={48},
  year={2009},
  publisher={Springer}
}

@inproceedings{mei2020global,
  title={On the global convergence rates of softmax policy gradient methods},
  author={Mei, Jincheng and Xiao, Chenjun and Szepesvari, Csaba and Schuurmans, Dale},
  booktitle={International Conference on Machine Learning},
  pages={6820--6829},
  year={2020},
  organization={PMLR}
}

@article{bhandari2019global,
  title={Global optimality guarantees for policy gradient methods},
  author={Bhandari, Jalaj and Russo, Daniel},
  journal={arXiv preprint arXiv:1906.01786},
  year={2019}
}

@article{bhandari2018,
  author    = {Jalaj Bhandari and
               Daniel Russo and
               Raghav Singal},
  title     = {A Finite Time Analysis of Temporal Difference Learning With Linear
               Function Approximation},
  journal   = {CoRR},
  volume    = {abs/1806.02450},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.02450},
  eprinttype = {arXiv},
  eprint    = {1806.02450},
  timestamp = {Mon, 13 Aug 2018 16:47:21 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-02450.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{dorfman2022,
  title = 	 {Adapting to Mixing Time in Stochastic Optimization with {M}arkovian Data},
  author =       {Dorfman, Ron and Levy, Kfir Yehuda},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {5429--5446},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/dorfman22a/dorfman22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/dorfman22a.html},

}

@article{duchi2011,
  author  = {John Duchi and Elad Hazan and Yoram Singer},
  title   = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2011},
  volume  = {12},
  number  = {61},
  pages   = {2121--2159},
  url     = {http://jmlr.org/papers/v12/duchi11a.html}
}

@article{duchi2012,
author = {Duchi, John C. and Agarwal, Alekh and Johansson, Mikael and Jordan, Michael I.},
title = {Ergodic Mirror Descent},
journal = {SIAM Journal on Optimization},
volume = {22},
number = {4},
pages = {1549-1578},
year = {2012},
doi = {10.1137/110836043},

URL = { 
        https://doi.org/10.1137/110836043
    
},
eprint = { 
        https://doi.org/10.1137/110836043  
}
}

@inproceedings{bresler2020,
  author    = {Dheeraj Nagaraj and
               Xian Wu and
               Guy Bresler and
               Prateek Jain and
               Praneeth Netrapalli},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {Least Squares Regression with Markovian Data: Fundamental Limits and
               Algorithms},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual},
  year      = {2020},
  url       = {https://proceedings.neurips.cc/paper/2020/hash/c22abfa379f38b5b0411bc11fa9bf92f-Abstract.html},
  timestamp = {Tue, 19 Jan 2021 15:56:50 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/NagarajWB0N20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{tadic2001convergence,
  title={On the convergence of temporal-difference learning with linear function approximation},
  author={Tadi{\'c}, Vladislav},
  journal={Machine learning},
  volume={42},
  pages={241--267},
  year={2001},
  publisher={Springer}
}

@article{bertsekas2011approximate,
  title={Approximate policy iteration: A survey and some new methods},
  author={Bertsekas, Dimitri P},
  journal={Journal of Control Theory and Applications},
  volume={9},
  number={3},
  pages={310--335},
  year={2011},
  publisher={Springer}
}

@article{borkar1997actor,
  title={The actor-critic algorithm as multi-time-scale stochastic approximation},
  author={Borkar, Vivek S and Konda, Vijaymohan R},
  journal={Sadhana},
  volume={22},
  pages={525--543},
  year={1997},
  publisher={Springer}
}

@inproceedings{Konda2000,
 author = {Konda, Vijay and Tsitsiklis, John},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Solla and T. Leen and K. M\"{u}ller},
 pages = {},
 publisher = {MIT Press},
 title = {Actor-Critic Algorithms},
 url = {https://proceedings.neurips.cc/paper/1999/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf},
 volume = {12},
 year = {1999}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@book{levin2017markov,
  title={Markov chains and mixing times},
  author={Levin, David A and Peres, Yuval},
  volume={107},
  year={2017},
  publisher={American Mathematical Soc.}
}

@article{sutton1988,
author = {Sutton, Richard},
year = {1988},
month = {08},
pages = {9-44},
title = {Learning to Predict by the Method of Temporal Differences},
volume = {3},
journal = {Machine Learning},
doi = {10.1007/BF00115009}
}

@article{riemer2021continual,
  title={Continual Learning In Environments With Polynomial Mixing Times},
  author={Riemer, Matthew and Raparthy, Sharath Chandra and Cases, Ignacio and Subbaraj, Gopeshh and Touzel, Maximilian Puelma and Rish, Irina},
  journal={arXiv preprint arXiv:2112.07066},
  year={2021}
}

@ARTICLE{roy1997,
  author={Tsitsiklis, J.N. and Van Roy, B.},
  journal={IEEE Transactions on Automatic Control}, 
  title={An analysis of temporal-difference learning with function approximation}, 
  year={1997},
  volume={42},
  number={5},
  pages={674-690},
  doi={10.1109/9.580874}}

@article{roy1999,
title = {Average cost temporal-difference learning},
author={Tsitsiklis, J.N. and Van Roy, B.},
journal = {Automatica},
volume = {35},
number = {11},
pages = {1799-1808},
year = {1999},
issn = {0005-1098},
doi = {https://doi.org/10.1016/S0005-1098(99)00099-0},
url = {https://www.sciencedirect.com/science/article/pii/S0005109899000990}
}

@inproceedings{xu2020improving,
author = {Xu, Tengyu and Wang, Zhe and Liang, Yingbin},
title = {Improving Sample Complexity Bounds for (Natural) Actor-Critic Algorithms},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {366},
numpages = {12},
location = {Vancouver, BC, Canada},
series = {NIPS'20}
}

@article{krizhevsky2017imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Communications of the ACM},
  volume={60},
  number={6},
  pages={84--90},
  year={2017},
  publisher={AcM New York, NY, USA}
}


@misc{chen2022finite,
  doi = {10.48550/ARXIV.2210.09921},
  
  url = {https://arxiv.org/abs/2210.09921},
  
  author = {Chen, Xuyang and Zhao, Lin},
  

  
  title = {Finite-time analysis of single-timescale actor-critic},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{wu2020finite,
  title={A finite-time analysis of two time-scale actor-critic methods},
  author={Wu, Yue Frank and Zhang, Weitong and Xu, Pan and Gu, Quanquan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17617--17628},
  year={2020}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{mitrophanov2005sensitivity,
  title={Sensitivity and convergence of uniformly ergodic Markov chains},
  author={Mitrophanov, A Yu},
  journal={Journal of Applied Probability},
  volume={42},
  number={4},
  pages={1003--1014},
  year={2005},
  publisher={Cambridge University Press}
}

@article{zou2019finite,
  title={Finite-sample analysis for sarsa with linear function approximation},
  author={Zou, Shaofeng and Xu, Tengyu and Liang, Yingbin},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{leahy2022convergence,
  title={Convergence of policy gradient for entropy regularized MDPs with neural network approximation in the mean-field regime},
  author={Leahy, James-Michael and Kerimkulov, Bekzhan and Siska, David and Szpruch, Lukasz},
  booktitle={International Conference on Machine Learning},
  pages={12222--12252},
  year={2022},
  organization={PMLR}
}

@article{zhang2020global,
  title={Global convergence of policy gradient methods to (almost) locally optimal policies},
  author={Zhang, Kaiqing and Koppel, Alec and Zhu, Hao and Basar, Tamer},
  journal={SIAM Journal on Control and Optimization},
  volume={58},
  number={6},
  pages={3586--3612},
  year={2020},
  publisher={SIAM}
}

@inproceedings{papini2018stochastic,
  title={Stochastic variance-reduced policy gradient},
  author={Papini, Matteo and Binaghi, Damiano and Canonaco, Giuseppe and Pirotta, Matteo and Restelli, Marcello},
  booktitle={International conference on machine learning},
  pages={4026--4035},
  year={2018},
  organization={PMLR}
}

@inproceedings{xu2020improved,
  title={An improved convergence analysis of stochastic variance-reduced policy gradient},
  author={Xu, Pan and Gao, Felicia and Gu, Quanquan},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={541--551},
  year={2020},
  organization={PMLR}
}

@inproceedings{melo2008analysis,
  title={An analysis of reinforcement learning with function approximation},
  author={Melo, Francisco S and Meyn, Sean P and Ribeiro, M Isabel},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={664--671},
  year={2008}
}
