\begin{thebibliography}{10}

\bibitem{Beck15}
Amir Beck and Shimrit Shtern.
\newblock Linearly convergent away-step conditional gradient for non-strongly
  convex functions.
\newblock {\em arXiv preprint arXiv:1504.05002}, 2015.

\bibitem{Candes09}
Emmanuel~J Cand{\`e}s and Benjamin Recht.
\newblock Exact matrix completion via convex optimization.
\newblock {\em Foundations of Computational mathematics}, 9(6):717--772, 2009.

\bibitem{Dudik12a}
Miroslav Dud\'{\i}k, Za\"{\i}d Harchaoui, and J{\'e}r{\^o}me Malick.
\newblock Lifted coordinate descent for learning with trace-norm
  regularization.
\newblock {\em Journal of Machine Learning Research - Proceedings Track},
  22:327--336, 2012.

\bibitem{FrankWolfe}
M.~Frank and P.~Wolfe.
\newblock An algorithm for quadratic programming.
\newblock {\em Naval Research Logistics Quarterly}, 3:149--154, 1956.

\bibitem{Freund15}
Robert~M Freund, Paul Grigas, and Rahul Mazumder.
\newblock An extended frank-wolfe method with" in-face" directions, and its
  application to low-rank matrix completion.
\newblock {\em arXiv preprint arXiv:1511.02204}, 2015.

\bibitem{Garber13b}
Dan Garber and Elad Hazan.
\newblock A linearly convergent conditional gradient algorithm with
  applications to online and stochastic optimization.
\newblock {\em CoRR}, abs/1301.4666, 2013.

\bibitem{Garber13}
Dan Garber and Elad Hazan.
\newblock Playing non-linear games with linear oracles.
\newblock In {\em 54th Annual {IEEE} Symposium on Foundations of Computer
  Science, {FOCS}}, 2013.

\bibitem{Garber15}
Dan Garber and Elad Hazan.
\newblock Fast and simple pca via convex optimization.
\newblock {\em arXiv preprint arXiv:1509.05647}, 2015.

\bibitem{GH15}
Dan Garber and Elad Hazan.
\newblock Faster rates for the frank-wolfe method over strongly-convex sets.
\newblock In {\em Proceedings of the 32nd International Conference on Machine
  Learning,{ICML}}, pages 541--549, 2015.

\bibitem{Gonen11}
Mehmet G{\"o}nen and Ethem Alpayd{\i}n.
\newblock Multiple kernel learning algorithms.
\newblock {\em The Journal of Machine Learning Research}, 12:2211--2268, 2011.

\bibitem{Dudik12b}
Za{\"{\i}}d Harchaoui, Matthijs Douze, Mattis Paulin, Miroslav Dud{\'{\i}}k,
  and J{\'{e}}r{\^{o}}me Malick.
\newblock Large-scale image classification with trace-norm regularization.
\newblock In {\em {IEEE} Conference on Computer Vision and Pattern Recognition,
  {CVPR}}, 2012.

\bibitem{Hazan08}
Elad Hazan.
\newblock Sparse approximate solutions to semidefinite programs.
\newblock In {\em 8th Latin American Theoretical Informatics Symposium,
  {LATIN}}, 2008.

\bibitem{Hazan12}
Elad Hazan and Satyen Kale.
\newblock Projection-free online learning.
\newblock In {\em Proceedings of the 29th International Conference on Machine
  Learning, {ICML}}, 2012.

\bibitem{Hazan16}
Elad Hazan and Haipeng Luo.
\newblock Variance-reduced and projection-free stochastic optimization.
\newblock {\em CoRR}, abs/1602.02101, 2016.

\bibitem{JaggiThesis}
Martin Jaggi.
\newblock Convex optimization without projection steps.
\newblock {\em CoRR}, abs/1108.1170, 2011.

\bibitem{Jaggi13b}
Martin Jaggi.
\newblock Revisiting frank-wolfe: Projection-free sparse convex optimization.
\newblock In {\em Proceedings of the 30th International Conference on Machine
  Learning, {ICML}}, 2013.

\bibitem{Jaggi10}
Martin Jaggi and Marek Sulovsk{\'{y}}.
\newblock A simple algorithm for nuclear norm regularized problems.
\newblock In {\em Proceedings of the 27th International Conference on Machine
  Learning, {ICML}}, 2010.

\bibitem{Sidrord15}
Chi Jin, Sham~M Kakade, Cameron Musco, Praneeth Netrapalli, and Aaron Sidford.
\newblock Robust shift-and-invert preconditioning: Faster and more sample
  efficient algorithms for eigenvector computation.
\newblock {\em arXiv preprint arXiv:1510.08896}, 2015.

\bibitem{EigenvaluesApprox}
J.~Kuczy\'{n}ski and H.~Wo\'{z}niakowski.
\newblock Estimating the largest eigenvalues by the power and lanczos
  algorithms with a random start.
\newblock {\em SIAM J. Matrix Anal. Appl.}, 13:1094--1122, October 1992.

\bibitem{Jaggi13c}
Simon Lacoste-Julien and Martin Jaggi.
\newblock An affine invariant linear convergence analysis for frank-wolfe
  algorithms.
\newblock {\em CoRR}, abs/1312.7864, 2013.

\bibitem{Jaggi15}
Simon Lacoste-Julien and Martin Jaggi.
\newblock On the global linear convergence of {F}rank-{W}olfe optimization
  variants.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  496--504, 2015.

\bibitem{Lan14}
Guanghui Lan and Yi~Zhou.
\newblock Conditional gradient sliding for convex optimization.
\newblock Technical report, Technical Report, 2014.

\bibitem{Lanckriet04}
Gert~RG Lanckriet, Nello Cristianini, Peter Bartlett, Laurent~El Ghaoui, and
  Michael~I Jordan.
\newblock Learning the kernel matrix with semidefinite programming.
\newblock {\em The Journal of Machine Learning Research}, 5:27--72, 2004.

\bibitem{Laue12}
S{\"{o}}ren Laue.
\newblock A hybrid algorithm for convex semidefinite optimization.
\newblock In {\em Proceedings of the 29th International Conference on Machine
  Learning, {ICML}}, 2012.

\bibitem{Polyak}
Evgeny~S Levitin and Boris~T Polyak.
\newblock Constrained minimization methods.
\newblock {\em USSR Computational mathematics and mathematical physics},
  6:1--50, 1966.

\bibitem{Negahban09}
Sahand Negahban, Bin Yu, Martin~J Wainwright, and Pradeep~K. Ravikumar.
\newblock A unified framework for high-dimensional analysis of m-estimators
  with decomposable regularizers.
\newblock In Y.~Bengio, D.~Schuurmans, J.~D. Lafferty, C.~K.~I. Williams, and
  A.~Culotta, editors, {\em Advances in Neural Information Processing Systems
  22}, pages 1348--1356. 2009.

\bibitem{Nesterov13}
Yurii Nesterov.
\newblock {\em Introductory lectures on convex optimization: A basic course},
  volume~87.
\newblock Springer Science \& Business Media, 2013.

\bibitem{Recht11}
Benjamin Recht.
\newblock A simpler approach to matrix completion.
\newblock {\em The Journal of Machine Learning Research}, 12:3413--3430, 2011.

\bibitem{ShalevShwartz11}
Shai Shalev{-}Shwartz, Alon Gonen, and Ohad Shamir.
\newblock Large-scale convex minimization with a low-rank constraint.
\newblock In {\em Proceedings of the 28th International Conference on Machine
  Learning, {ICML}}, 2011.

\bibitem{Shamir15}
Ohad Shamir.
\newblock A stochastic {PCA} and {SVD} algorithm with an exponential
  convergence rate.
\newblock In {\em Proceedings of the 32nd International Conference on Machine
  Learning, {ICML}}, 2015.

\bibitem{Weinberger05}
Kilian~Q Weinberger, John Blitzer, and Lawrence~K Saul.
\newblock Distance metric learning for large margin nearest neighbor
  classification.
\newblock In {\em Advances in neural information processing systems}, pages
  1473--1480, 2005.

\bibitem{Xing03}
Eric~P Xing, Andrew~Y Ng, Michael~I Jordan, and Stuart Russell.
\newblock Distance metric learning with application to clustering with
  side-information.
\newblock {\em Advances in neural information processing systems}, 15:505--512,
  2003.

\bibitem{Ying12}
Yiming Ying and Peng Li.
\newblock Distance metric learning with eigenvalue optimization.
\newblock {\em J. Mach. Learn. Res.}, 13(1):1--26, January 2012.

\bibitem{Zhang12}
Xinhua Zhang, Dale Schuurmans, and Yao-liang Yu.
\newblock Accelerated training for matrix-norm regularization: A boosting
  approach.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2906--2914, 2012.

\end{thebibliography}
