\begin{thebibliography}{DPvdBW14}

\bibitem[AFSU07]{amit2007uncovering}
Yonatan Amit, Michael Fink, Nathan Srebro, and Shimon Ullman.
\newblock Uncovering shared structures in multiclass classification.
\newblock In {\em Proceedings of the 24th international conference on Machine
  learning}, pages 17--24. ACM, 2007.

\bibitem[BBV16]{bandeira2016low}
Afonso~S Bandeira, Nicolas Boumal, and Vladislav Voroninski.
\newblock On the low-rank approach for semidefinite programs arising in
  synchronization and community detection.
\newblock {\em arXiv preprint arXiv:1602.04426}, 2016.

\bibitem[BH89]{baldi1989neural}
Pierre Baldi and Kurt Hornik.
\newblock Neural networks and principal component analysis: Learning from
  examples without local minima.
\newblock {\em Neural networks}, 2(1):53--58, 1989.

\bibitem[BM03]{burer2003nonlinear}
Samuel Burer and Renato~DC Monteiro.
\newblock A nonlinear programming algorithm for solving semidefinite programs
  via low-rank factorization.
\newblock {\em Mathematical Programming}, 95(2):329--357, 2003.

\bibitem[BNS16]{bhojanapalli2016personal}
S.~{Bhojanapalli}, B.~{Neyshabur}, and N.~{Srebro}.
\newblock {Global Optimality of Local Search for Low Rank Matrix Recovery}.
\newblock {\em ArXiv e-prints}, May 2016.

\bibitem[CLMW11]{candes2011robust}
Emmanuel~J Cand{\`e}s, Xiaodong Li, Yi~Ma, and John Wright.
\newblock Robust principal component analysis?
\newblock {\em Journal of the ACM (JACM)}, 58(3):11, 2011.

\bibitem[CR09]{candes2009exact}
Emmanuel~J Cand{\`e}s and Benjamin Recht.
\newblock Exact matrix completion via convex optimization.
\newblock {\em Foundations of Computational mathematics}, 9(6):717--772, 2009.

\bibitem[CT10]{candes2010power}
Emmanuel~J Cand{\`e}s and Terence Tao.
\newblock The power of convex relaxation: Near-optimal matrix completion.
\newblock {\em Information Theory, IEEE Transactions on}, 56(5):2053--2080,
  2010.

\bibitem[CW15]{chen2015fast}
Yudong Chen and Martin~J Wainwright.
\newblock Fast low-rank estimation by projected gradient descent: General
  statistical and algorithmic guarantees.
\newblock {\em arXiv preprint arXiv:1509.03025}, 2015.

\bibitem[DPvdBW14]{davenport20141}
Mark~A Davenport, Yaniv Plan, Ewout van~den Berg, and Mary Wootters.
\newblock 1-bit matrix completion.
\newblock {\em Information and Inference}, 3(3):189--223, 2014.

\bibitem[GHJY15]{ge2015escaping}
Rong Ge, Furong Huang, Chi Jin, and Yang Yuan.
\newblock Escaping from saddle points---online stochastic gradient for tensor
  decomposition.
\newblock {\em arXiv:1503.02101}, 2015.

\bibitem[Har14]{hardt2014understanding}
Moritz Hardt.
\newblock Understanding alternating minimization for matrix completion.
\newblock In {\em FOCS 2014}. IEEE, 2014.

\bibitem[HKZ12]{hsu2012tail}
Daniel Hsu, Sham~M Kakade, and Tong Zhang.
\newblock A tail inequality for quadratic forms of subgaussian random vectors.
\newblock {\em Electron. Commun. Probab}, 17(52):1--6, 2012.

\bibitem[HMZ14]{hastie2014matrix}
Trevor Hastie, Rahul Mazumder, Jason ~, and Reza Zadeh.
\newblock Matrix completion and low-rank svd via fast alternating least
  squares.
\newblock {\em Journal of Machine Learning Research}, 2014.

\bibitem[HW14]{hardt2014fast}
Moritz Hardt and Mary Wootters.
\newblock Fast matrix completion without the condition number.
\newblock In {\em COLT 2014}, pages 638--678, 2014.

\bibitem[{Imb}10]{2010arXiv1004.3821I}
R.~{Imbuzeiro Oliveira}.
\newblock {Sums of random Hermitian matrices and an inequality by Rudelson}.
\newblock {\em ArXiv e-prints}, April 2010.

\bibitem[JN15]{jain2015fast}
Prateek Jain and Praneeth Netrapalli.
\newblock Fast exact matrix completion with finite samples.
\newblock In {\em Proceedings of The 28th Conference on Learning Theory}, pages
  1007--1034, 2015.

\bibitem[JNS13]{jain2013low}
Prateek Jain, Praneeth Netrapalli, and Sujay Sanghavi.
\newblock Low-rank matrix completion using alternating minimization.
\newblock In {\em Proceedings of the forty-fifth annual ACM symposium on Theory
  of computing}, pages 665--674. ACM, 2013.

\bibitem[KMO10a]{keshavan2010matrix}
Raghunandan~H Keshavan, Andrea Montanari, and Sewoong Oh.
\newblock Matrix completion from a few entries.
\newblock {\em Information Theory, IEEE Transactions on}, 56(6):2980--2998,
  2010.

\bibitem[KMO10b]{keshavan2010matrixnoisy}
Raghunandan~H Keshavan, Andrea Montanari, and Sewoong Oh.
\newblock Matrix completion from noisy entries.
\newblock {\em The Journal of Machine Learning Research}, 11:2057--2078, 2010.

\bibitem[Kor09]{koren2009bellkor}
Yehuda Koren.
\newblock The bellkor solution to the netflix grand prize.
\newblock {\em Netflix prize documentation}, 81, 2009.

\bibitem[LLR16]{li2016recovery}
Yuanzhi Li, Yingyu Liang, and Andrej Risteski.
\newblock Recovery guarantee of weighted low-rank approximation via alternating
  minimization.
\newblock {\em arXiv preprint arXiv:1602.02262}, 2016.

\bibitem[LSJR16]{lee2016gradient}
Jason~D Lee, Max Simchowitz, Michael~I Jordan, and Benjamin Recht.
\newblock Gradient descent converges to minimizers.
\newblock {\em University of California, Berkeley}, 1050:16, 2016.

\bibitem[LW14]{loh2014support}
Po-Ling Loh and Martin~J Wainwright.
\newblock Support recovery without incoherence: A case for nonconvex
  regularization.
\newblock {\em arXiv preprint arXiv:1412.5632}, 2014.

\bibitem[LW15]{DBLP:journals/jmlr/LohW15}
Po{-}Ling Loh and Martin~J. Wainwright.
\newblock Regularized m-estimators with nonconvexity: statistical and
  algorithmic theory for local optima.
\newblock {\em Journal of Machine Learning Research}, 16:559--616, 2015.

\bibitem[MHT10]{mazumder2010spectral}
Rahul Mazumder, Trevor Hastie, and Robert Tibshirani.
\newblock Spectral regularization algorithms for learning large incomplete
  matrices.
\newblock {\em Journal of machine learning research}, 11(Aug):2287--2322, 2010.

\bibitem[NP06]{nesterov2006cubic}
Yurii Nesterov and Boris~T Polyak.
\newblock Cubic regularization of {N}ewton method and its global performance.
\newblock {\em Mathematical Programming}, 108(1):177--205, 2006.

\bibitem[NW12]{negahban2012restricted}
Sahand Negahban and Martin~J Wainwright.
\newblock Restricted strong convexity and weighted matrix completion: Optimal
  bounds with noise.
\newblock {\em Journal of Machine Learning Research}, 13(May):1665--1697, 2012.

\bibitem[Pem90]{pemantle1990nonconvergence}
Robin Pemantle.
\newblock Nonconvergence to unstable points in urn models and stochastic
  approximations.
\newblock {\em The Annals of Probability}, pages 698--712, 1990.

\bibitem[Rec11]{recht2011simpler}
Benjamin Recht.
\newblock A simpler approach to matrix completion.
\newblock {\em The Journal of Machine Learning Research}, 12:3413--3430, 2011.

\bibitem[RS05]{rennie2005fast}
Jasson~DM Rennie and Nathan Srebro.
\newblock Fast maximum margin matrix factorization for collaborative
  prediction.
\newblock In {\em Proceedings of the 22nd international conference on Machine
  learning}, pages 713--719. ACM, 2005.

\bibitem[SJ13]{srebro2003weighted}
Nathan Srebro and Tommi Jaakkola.
\newblock Weighted low-rank approximations.
\newblock In {\em ICML}, 2013.

\bibitem[SL15]{sun2015guaranteed}
Ruoyu Sun and Zhi-Quan Luo.
\newblock Guaranteed matrix completion via nonconvex factorization.
\newblock In {\em Foundations of Computer Science (FOCS), 2015 IEEE 56th Annual
  Symposium on}, pages 270--289. IEEE, 2015.

\bibitem[SQW15]{sun2015nonconvex}
Ju~Sun, Qing Qu, and John Wright.
\newblock When are nonconvex problems not scary?
\newblock {\em arXiv preprint arXiv:1510.06096}, 2015.

\bibitem[SRJ04]{srebro2004maximum}
Nathan Srebro, Rennie, and Tommi~S Jaakkola.
\newblock Maximum-margin matrix factorization.
\newblock In {\em Advances in neural information processing systems}, pages
  1329--1336, 2004.

\bibitem[SRO15]{DBLP:conf/icml/SaRO15}
Christopher~De Sa, Christopher R{\'{e}}, and Kunle Olukotun.
\newblock Global convergence of stochastic gradient descent for some non-convex
  matrix problems.
\newblock In {\em Proceedings of the 32nd International Conference on Machine
  Learning, {ICML} 2015, Lille, France, 6-11 July 2015}, pages 2332--2341,
  2015.

\bibitem[SS05]{srebro2005rank}
Nathan Srebro and Adi Shraibman.
\newblock Rank, trace-norm and max-norm.
\newblock In {\em International Conference on Computational Learning Theory},
  pages 545--560. Springer, 2005.

\bibitem[TBSR15]{tu2015low}
Stephen Tu, Ross Boczar, Mahdi Soltanolkotabi, and Benjamin Recht.
\newblock Low-rank solutions of linear matrix equations via procrustes flow.
\newblock {\em arXiv preprint arXiv:1507.03566}, 2015.

\bibitem[ZL16]{zheng2016convergence}
Qinqing Zheng and John Lafferty.
\newblock Convergence analysis for rectangular matrix completion using
  burer-monteiro factorization and gradient descent.
\newblock {\em arXiv preprint arXiv:1605.07051}, 2016.

\bibitem[ZWL15]{zhao2015nonconvex}
Tuo Zhao, Zhaoran Wang, and Han Liu.
\newblock A nonconvex optimization framework for low rank matrix estimation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  559--567, 2015.

\end{thebibliography}
