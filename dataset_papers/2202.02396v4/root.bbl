\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Baird(1995)]{baird_residual_1995}
Baird, L.
\newblock Residual {Algorithms}: {Reinforcement} {Learning} with {Function}
  {Approximation}.
\newblock \emph{Machine Learning Proceedings}, pp.\  30--37, 1995.

\bibitem[Carvalho et~al.(2021)Carvalho, Tateo, Muratore, and
  Peters]{carvalho_empirical_2021}
Carvalho, J., Tateo, D., Muratore, F., and Peters, J.
\newblock An {Empirical} {Analysis} of {Measure}-{Valued} {Derivatives} for
  {Policy} {Gradients}.
\newblock In \emph{2021 {International} {Joint} {Conference} on {Neural}
  {Networks} ({IJCNN})}, pp.\  1--10. IEEE, 2021.

\bibitem[Degris et~al.(2012)Degris, White, and Sutton]{degris_off-policy_2012}
Degris, T., White, M., and Sutton, R.~S.
\newblock Off-{Policy} {Actor}-{Critic}.
\newblock In \emph{Proceedings of the 29th {International} {Coference} on
  {Machine} {Learning}}, pp.\  179--186. Omnipress, 2012.

\bibitem[Deisenroth et~al.(2013)Deisenroth, Neumann, and
  Peters]{deisenroth_survey_2013}
Deisenroth, M.~P., Neumann, G., and Peters, J.
\newblock \emph{A {Survey} on {Policy} {Search} for {Robotics}}.
\newblock Now Publishers, 2013.

\bibitem[Fujimoto et~al.(2018)Fujimoto, van Hoof, and
  Meger]{fujimoto_addressing_2018}
Fujimoto, S., van Hoof, H., and Meger, D.
\newblock Addressing {Function} {Approximation} {Error} in {Actor}-{Critic}
  {Methods}.
\newblock \emph{Journal of Machine Learning Research}, 80, 2018.

\bibitem[Fujimoto et~al.(2019)Fujimoto, Meger, and
  Precup]{fujimoto_off-policy_2019}
Fujimoto, S., Meger, D., and Precup, D.
\newblock Off-{Policy} {Deep} {Reinforcement} {Learning} without {Exploration}.
\newblock In \emph{Proceeding of the 36th {International} {Conference} on
  {Machine} {Learning}}, pp.\  2052--2062, 2019.

\bibitem[Ghiassian et~al.(2020)Ghiassian, Patterson, Garg, Gupta, White, and
  White]{ghiassian_gradient_2020}
Ghiassian, S., Patterson, A., Garg, S., Gupta, D., White, A., and White, M.
\newblock Gradient {Temporal}-{Difference} {Learning} with {Regularized}
  {Corrections}.
\newblock In \emph{Proceedings of the 37th {International} {Conference} on
  {Machine} {Learning}}, pp.\  3524--3534. PMLR, 2020.

\bibitem[Graves et~al.(2021)Graves, Imani, Kumaraswamy, and
  White]{graves_off-policy_2021}
Graves, E., Imani, E., Kumaraswamy, R., and White, M.
\newblock Off-{Policy} {Actor}-{Critic} with {Emphatic} {Weightings}.
\newblock \emph{arXiv preprint arXiv:2111.08172}, 2021.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and
  Levine]{haarnoja_soft_2018}
Haarnoja, T., Zhou, A., Abbeel, P., and Levine, S.
\newblock Soft {Actor}-{Critic}: {Off}-{Policy} {Maximum} {Entropy} {Deep}
  {Reinforcement} {Learning} with a {Stochastic} {Actor}.
\newblock In \emph{Proceeding of the 35th {International} {Conference} on
  {Machine} {Learning}}, pp.\  1856--1865, 2018.

\bibitem[Heess et~al.(2015)Heess, Wayne, Silver, Lillicrap, Erez, and
  Tassa]{heess_learning_2015}
Heess, N., Wayne, G., Silver, D., Lillicrap, T., Erez, T., and Tassa, Y.
\newblock Learning {Continuous} {Control} {Policies} by {Stochastic} {Value}
  {Gradients}.
\newblock \emph{Advances in Neural Information Processing Systems},
  28:\penalty0 2944--2952, 2015.

\bibitem[Imani et~al.(2018)Imani, Graves, and White]{imani_off-policy_2018}
Imani, E., Graves, E., and White, M.
\newblock An {Off}-{Policy} {Policy} {Gradient} {Theorem} {Using} {Emphatic}
  {Weightings}.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  pp.\  96--106, 2018.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma_adam_2014}
Kingma, D.~P. and Ba, J.
\newblock {ADAM}: {A} {Method} for {Stochastic} {Optimization}.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kolter(2011)]{kolter_fixed_2011}
Kolter, J.
\newblock The {Fixed} {Points} of {Off}-{Policy} {TD}.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  volume~24, pp.\  2169--2177, 2011.

\bibitem[Lagoudakis \& Parr(2003)Lagoudakis and
  Parr]{lagoudakis_least-squares_2003}
Lagoudakis, M.~G. and Parr, R.
\newblock Least-{Squares} {Policy} {Iteration}.
\newblock \emph{Journal of Machine Learning Research}, 4:\penalty0 1107--1149,
  2003.
\newblock Publisher: JMLR. org.

\bibitem[Lan et~al.(2022)Lan, Tosatto, Farrahi, and
  Mahmood]{lan_model-free_2022}
Lan, Q., Tosatto, S., Farrahi, H., and Mahmood, A.~R.
\newblock Model-{Free} {Policy} {Learning} with {Reward} {Gradients}.
\newblock In \emph{Proceeding of the 25th {International} {Conference} on
  {Artificial} {Intelligence} and {Statistics} ({AISTATS})}, Virtual, 2022.

\bibitem[Levine et~al.(2020)Levine, Kumar, Tucker, and Fu]{levine_offline_2020}
Levine, S., Kumar, A., Tucker, G., and Fu, J.
\newblock Offline {Reinforcement} {Learning}: {Tutorial}, {Review}, and
  {Perspectives} on {Open} {Problems}.
\newblock \emph{arXiv preprint arXiv:2005.01643}, 2020.

\bibitem[Lillicrap et~al.(2016)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap_continuous_2016}
Lillicrap, T.~P., Hunt, J.~J., Pritzel, A., Heess, N., Erez, T., Tassa, Y.,
  Silver, D., and Wierstra, D.
\newblock Continuous {Control} with {Deep} {Reinforcement} {Learning}.
\newblock In \emph{International {Conference} on {Learning} {Representations}},
  2016.
\newblock URL \url{http://arxiv.org/abs/1509.02971}.
\newblock arXiv: 1509.02971.

\bibitem[Liu et~al.(2018)Liu, Li, Tang, and Zhou]{liu_breaking_2018}
Liu, Q., Li, L., Tang, Z., and Zhou, D.
\newblock Breaking the {Curse} of {Horizon}: {Infinite}-{Horizon}
  {Off}-{Policy} {Estimation}.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  pp.\  5356--5366, 2018.

\bibitem[Liu et~al.(2019)Liu, Swaminathan, Agarwal, and
  Brunskill]{liu_off-policy_2019}
Liu, Y., Swaminathan, A., Agarwal, A., and Brunskill, E.
\newblock Off-{Policy} {Policy} {Gradient} with {State} {Distribution}
  {Correction}.
\newblock \emph{arXiv:1904.08473}, 2019.
\newblock URL \url{http://arxiv.org/abs/1904.08473}.
\newblock arXiv: 1904.08473.

\bibitem[Lu et~al.(2018)Lu, Schuurmans, and Boutilier]{lu_non-delusional_2018}
Lu, T., Schuurmans, D., and Boutilier, C.
\newblock Non-{Delusional} {Q}-learning and {Value}-{Iteration}.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  pp.\  9949--9959. Curran Associates, Inc., 2018.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and
  Hassabis]{mnih_human-level_2015}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., Petersen,
  S., Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumaran, D., Wierstra,
  D., Legg, S., and Hassabis, D.
\newblock Human-{Level} {Control} {Through} {Deep} {Reinforcement} {Learning}.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.
\newblock ISSN 0028-0836, 1476-4687.
\newblock \doi{10.1038/nature14236}.
\newblock URL \url{http://www.nature.com/articles/nature14236}.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{mnih_asynchronous_2016}
Mnih, V., Badia, A.~P., Mirza, M., Graves, A., Lillicrap, T., Harley, T.,
  Silver, D., and Kavukcuoglu, K.
\newblock Asynchronous {Methods} for {Deep} {Reinforcement} {Learning}.
\newblock In \emph{Proceedings of the 33rd {International} {Conference} on
  {Machine} {Learning}}, pp.\  1928--1937, 2016.

\bibitem[Nachum et~al.(2019)Nachum, Dai, Kostrikov, Chow, Li, and
  Schuurmans]{nachum_algaedice:_2019}
Nachum, O., Dai, B., Kostrikov, I., Chow, Y., Li, L., and Schuurmans, D.
\newblock {AlgaeDICE}: {Policy} {Gradient} from {Arbitrary} {Experience}.
\newblock \emph{arXiv:1912.02074v1}, 2019.

\bibitem[Ni et~al.(2022)Ni, Zhang, Ji, Zhang, and Wang]{ni_optimal_2022}
Ni, C., Zhang, R., Ji, X., Zhang, X., and Wang, M.
\newblock Optimal {Estimation} of {Off}-{Policy} {Policy} {Gradient} via
  {Double} {Fitted} {Iteration}.
\newblock \emph{arXiv preprint arXiv:2202.00076}, 2022.

\bibitem[Nota \& Thomas(2019)Nota and Thomas]{nota_is_2019}
Nota, C. and Thomas, P.~S.
\newblock Is the {Policy} {Gradient} a {Gradient}?
\newblock \emph{arXiv preprint arXiv:1906.07073}, 2019.

\bibitem[Nota \& Thomas(2020)Nota and Thomas]{nota_is_2020}
Nota, C. and Thomas, P.~S.
\newblock Is the {Policy} {Gradient} a {Gradient}?
\newblock In \emph{Proceedings of the 19th {International} {Conference} on
  {Autonomous} {Agents} and {Multiagent} {Systems}}, 2020.

\bibitem[Owen(2013)]{owen_monte_2013}
Owen, A.~B.
\newblock \emph{Monte {Carlo} {Theory}, {Methods} and {Examples}}.
\newblock 2013.

\bibitem[Peshkin \& Shelton(2002)Peshkin and Shelton]{peshkin_learning_2002}
Peshkin, L. and Shelton, C.~R.
\newblock Learning from {Scarce} {Experience}.
\newblock In \emph{Proceedings of the {Nineteenth} {International} {Conference}
  on {Machine} {Learning}}, 2002.
\newblock URL \url{http://arxiv.org/abs/cs/0204043}.
\newblock arXiv: cs/0204043.

\bibitem[Shelton(2001)]{shelton_policy_2001}
Shelton, C.~R.
\newblock Policy {Improvement} for {POMDPs} {Using} {Normalized} {Importance}
  {Sampling}.
\newblock In \emph{Proceedings of the {Seventeenth} {Conference} on
  {Uncertainty} in {Artificial} {Intelligence}}, {UAI}'01, pp.\  496--503.
  Morgan Kaufmann Publishers Inc., 2001.
\newblock ISBN 978-1-55860-800-9.
\newblock event-place: Seattle, Washington.

\bibitem[Silver et~al.(2014)Silver, Lever, Heess, Degris, Wierstra, and
  Riedmiller]{silver_deterministic_2014}
Silver, D., Lever, G., Heess, N., Degris, T., Wierstra, D., and Riedmiller, M.
\newblock Deterministic {Policy} {Gradient} {Algorithms}.
\newblock In \emph{Proceedings of the 31 st {International} {Conference} on
  {Machine} {Learning}}, 2014.

\bibitem[Sutton(1988)]{sutton_learning_1988}
Sutton, R.~S.
\newblock Learning to {Predict} by the {Methods} of {Temporal} {Differences}.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0 (1):\penalty0
  9--44, 1988.
\newblock Publisher: Springer.

\bibitem[Sutton \& Barto(2018)Sutton and Barto]{sutton_reinforcement_2018}
Sutton, R.~S. and Barto, A.~G.
\newblock \emph{Reinforcement {Learning}: {An} {Introduction}}.
\newblock MIT press, 2018.

\bibitem[Sutton et~al.(2000)Sutton, McAllester, Singh, and
  Mansour]{sutton_policy_2000}
Sutton, R.~S., McAllester, D.~A., Singh, S.~P., and Mansour, Y.
\newblock Policy {Gradient} {Methods} for {Reinforcement} {Learning} with
  {Function} {Approximation}.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}},
  pp.\  1057--1063, 2000.

\bibitem[Sutton et~al.(2008)Sutton, Szepesv치ri, and
  Maei]{sutton_convergent_2008}
Sutton, R.~S., Szepesv치ri, C., and Maei, H.~R.
\newblock A {Convergent} {O}(n) {Algorithm} for {Off}-{Policy}
  temporal-{Difference} {Learning} with {Linear} {Function} {Approximation}.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}
  ({NIPS})}, volume~21, pp.\  1609--1616. MIT Press, 2008.

\bibitem[Sutton et~al.(2009)Sutton, Maei, Precup, Bhatnagar, Silver,
  Szepesv치ri, and Wiewiora]{sutton_fast_2009}
Sutton, R.~S., Maei, H.~R., Precup, D., Bhatnagar, S., Silver, D., Szepesv치ri,
  C., and Wiewiora, E.
\newblock Fast {Gradient}-{Descent} {Methods} for {Temporal}-{Difference}
  {Learning} with {Linear} {Function} {Approximation}.
\newblock In \emph{Proceedings of the 26th {Annual} {International}
  {Conference} on {Machine} {Learning}}, pp.\  993--1000, 2009.

\bibitem[Thomas(2014)]{thomas_bias_2014}
Thomas, P.
\newblock Bias in {Natural} {Actor}-{Critic} {Algorithms}.
\newblock In \emph{Proceeding of the 31st {International} {Conference} on
  {Machine} {Learning}}, pp.\  441--448, 2014.

\bibitem[Tosatto et~al.(2020)Tosatto, Carvalho, Abdulsamad, and
  Peters]{tosatto_nonparametric_2020}
Tosatto, S., Carvalho, J., Abdulsamad, H., and Peters, J.
\newblock A {Nonparametric} {Off}-{Policy} {Policy} {Gradient}.
\newblock In Chiappa, S. and Calandra, R. (eds.), \emph{Proceedings of the 23rd
  {International} {Conference} on {Artificial} {Intelligence} and {Statistics}
  ({AISTATS})}, Palermo, Italy, 2020.

\bibitem[Tosatto et~al.(2021)Tosatto, Carvalho, and Peters]{tosatto_batch_2021}
Tosatto, S., Carvalho, J., and Peters, J.
\newblock Batch {Reinforcement} {Learning} with a {Nonparametric}
  {Off}-{Policy} {Policy} {Gradient}.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, pp.\  1--1, 2021.
\newblock \doi{10.1109/TPAMI.2021.3088063}.

\bibitem[Tsitsiklis \& Van~Roy(1997)Tsitsiklis and
  Van~Roy]{tsitsiklis_analysis_1997}
Tsitsiklis, J.~N. and Van~Roy, B.
\newblock An {Analysis} of {Temporal}-{Difference} {Learning} with {Function}
  {Approximation}.
\newblock \emph{IEEE Transactions on Automatic Control}, 42\penalty0
  (5):\penalty0 674--690, 1997.
\newblock Publisher: IEEE.

\end{thebibliography}
