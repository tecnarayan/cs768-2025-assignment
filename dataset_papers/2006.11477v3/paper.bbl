\begin{thebibliography}{60}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
J.~L. Ba, J.~R. Kiros, and G.~E. Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv}, 2016.

\bibitem[Bachman et~al.(2019)Bachman, Hjelm, and
  Buchwalter]{bachman2019learning}
P.~Bachman, R.~D. Hjelm, and W.~Buchwalter.
\newblock Learning representations by maximizing mutual information across
  views.
\newblock In \emph{Proc. of NeurIPS}, 2019.

\bibitem[Baevski and Auli(2018)]{baevski2018adaptive}
A.~Baevski and M.~Auli.
\newblock Adaptive input representations for neural language modeling.
\newblock In \emph{Proc. of ICLR}, 2018.

\bibitem[Baevski et~al.(2019)Baevski, Auli, and
  Mohamed]{baevski2019effectiveness}
A.~Baevski, M.~Auli, and A.~Mohamed.
\newblock Effectiveness of self-supervised pre-training for speech recognition.
\newblock \emph{arXiv}, abs/1911.03912, 2019.

\bibitem[Baevski et~al.(2020)Baevski, Schneider, and
  Auli]{baevski2019vqwav2vec}
A.~Baevski, S.~Schneider, and M.~Auli.
\newblock vq-wav2vec: Self-supervised learning of discrete speech
  representations.
\newblock In \emph{Proc. of ICLR}, 2020.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
T.~Chen, S.~Kornblith, M.~Norouzi, and G.~Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock \emph{arXiv}, abs/2002.05709, 2020.

\bibitem[Chorowski et~al.(2019)Chorowski, Weiss, Bengio, and van~den
  Oord]{chorowski2019unsup}
J.~Chorowski, R.~J. Weiss, S.~Bengio, and A.~van~den Oord.
\newblock Unsupervised speech representation learning using wavenet
  autoencoders.
\newblock \emph{arXiv}, abs/1901.08810, 2019.

\bibitem[Chung et~al.(2019)Chung, Hsu, Tang, and Glass]{chung2019apc}
Y.~Chung, W.~Hsu, H.~Tang, and J.~R. Glass.
\newblock An unsupervised autoregressive model for speech representation
  learning.
\newblock \emph{arXiv}, abs/1904.03240, 2019.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv}, abs/1810.04805, 2018.

\bibitem[Dieleman et~al.(2018)Dieleman, van~den Oord, and
  Simonyan]{dieleman2018challenge}
S.~Dieleman, A.~van~den Oord, and K.~Simonyan.
\newblock The challenge of realistic music generation: modelling raw audio at
  scale.
\newblock \emph{arXiv}, 2018.

\bibitem[Eloff et~al.(2019)Eloff, Nortje, van Niekerk, Govender, Nortje,
  Pretorius, Van~Biljon, van~der Westhuizen, van Staden, and
  Kamper]{eloff2019unsupervised}
R.~Eloff, A.~Nortje, B.~van Niekerk, A.~Govender, L.~Nortje, A.~Pretorius,
  E.~Van~Biljon, E.~van~der Westhuizen, L.~van Staden, and H.~Kamper.
\newblock Unsupervised acoustic unit discovery for speech synthesis using
  discrete latent-variable neural networks.
\newblock \emph{arXiv}, abs/1904.07556, 2019.

\bibitem[Fan et~al.(2020)Fan, Grave, and Joulin]{fan2019reducing}
A.~Fan, E.~Grave, and A.~Joulin.
\newblock Reducing transformer depth on demand with structured dropout.
\newblock In \emph{Proc. of ICLR}, 2020.

\bibitem[Garofolo et~al.(1993)Garofolo, Lamel, Fisher, Fiscus, Pallett, and
  Dahlgren]{garofolo1993timit}
J.~S. Garofolo, L.~F. Lamel, W.~M. Fisher, J.~G. Fiscus, D.~S. Pallett, and
  N.~L. Dahlgren.
\newblock {The DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus CDROM}.
\newblock \emph{Linguistic Data Consortium}, 1993.

\bibitem[Graves et~al.(2006)Graves, Fernández, and Gomez]{graves2006ctc}
A.~Graves, S.~Fernández, and F.~Gomez.
\newblock Connectionist temporal classification: Labelling unsegmented sequence
  data with recurrent neural networks.
\newblock In \emph{Proc. of ICML}, 2006.

\bibitem[Gulati et~al.(2020)Gulati, Qin, Chiu, Parmar, Zhang, Yu, Han, Wang,
  Zhang, Wu, and Pang]{gulati2020conformer}
A.~Gulati, J.~Qin, C.-C. Chiu, N.~Parmar, Y.~Zhang, J.~Yu, W.~Han, S.~Wang,
  Z.~Zhang, Y.~Wu, and R.~Pang.
\newblock Conformer: Convolution-augmented transformer for speech recognition.
\newblock \emph{arXiv}, 2020.

\bibitem[Gumbel(1954)]{gumbel1954statistical}
E.~J. Gumbel.
\newblock \emph{Statistical theory of extreme values and some practical
  applications: a series of lectures}, volume~33.
\newblock US Government Printing Office, 1954.

\bibitem[Han et~al.(2020)Han, Zhang, Zhang, Yu, Chiu, Qin, Gulati, Pang, and
  Wu]{han2020contextnet}
W.~Han, Z.~Zhang, Y.~Zhang, J.~Yu, C.-C. Chiu, J.~Qin, A.~Gulati, R.~Pang, and
  Y.~Wu.
\newblock Contextnet: Improving convolutional neural networks for automatic
  speech recognition with global context.
\newblock \emph{arXiv}, 2020.

\bibitem[Harwath et~al.(2020)Harwath, Hsu, and Glass]{harwath2019learning}
D.~Harwath, W.-N. Hsu, and J.~Glass.
\newblock Learning hierarchical discrete linguistic units from
  visually-grounded speech.
\newblock In \emph{Proc. of ICLR}, 2020.

\bibitem[He et~al.(2019)He, Fan, Wu, Xie, and Girshick]{he2019momentum}
K.~He, H.~Fan, Y.~Wu, S.~Xie, and R.~Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock \emph{arXiv}, abs/1911.05722, 2019.

\bibitem[H{\'{e}}naff et~al.(2019)H{\'{e}}naff, Razavi, Doersch, Eslami, and
  van~den Oord]{henaff2019cpc}
O.~J. H{\'{e}}naff, A.~Razavi, C.~Doersch, S.~M.~A. Eslami, and A.~van~den
  Oord.
\newblock Data-efficient image recognition with contrastive predictive coding.
\newblock \emph{arXiv}, abs/1905.09272, 2019.

\bibitem[Hendrycks and Gimpel(2016)]{hendrycks2016gaussian}
D.~Hendrycks and K.~Gimpel.
\newblock Gaussian error linear units (gelus).
\newblock \emph{arXiv}, 2016.

\bibitem[Huang et~al.(2016)Huang, Sun, Liu, Sedra, and
  Weinberger]{huang2016deep}
G.~Huang, Y.~Sun, Z.~Liu, D.~Sedra, and K.~Weinberger.
\newblock Deep networks with stochastic depth.
\newblock \emph{arXiv}, 2016.

\bibitem[Hyv\"{a}rinen(2010)]{gutmann2010aistats}
M.~G.~A. Hyv\"{a}rinen.
\newblock {Noise-contrastive estimation: A new estimation principle for
  unnormalized statistical models}.
\newblock In \emph{Proc. of AISTATS}, 2010.

\bibitem[Jang et~al.(2016)Jang, Gu, and Poole]{jang2016gumbel}
E.~Jang, S.~Gu, and B.~Poole.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock \emph{arXiv}, abs/1611.01144, 2016.

\bibitem[Jegou et~al.(2011)Jegou, Douze, and Schmid]{jegou2011ieee}
H.~Jegou, M.~Douze, and C.~Schmid.
\newblock Product quantization for nearest neighbor search.
\newblock \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, 33\penalty0
  (1):\penalty0 117--128, Jan. 2011.

\bibitem[Jiang et~al.(2019)Jiang, Lei, Li, Luo, Hu, Zou, and
  Li]{jiang2019improving}
D.~Jiang, X.~Lei, W.~Li, N.~Luo, Y.~Hu, W.~Zou, and X.~Li.
\newblock Improving transformer-based speech recognition using unsupervised
  pre-training.
\newblock \emph{arXiv}, abs/1910.09932, 2019.

\bibitem[Kahn et~al.(2020)]{kahn2020librilight}
J.~Kahn et~al.
\newblock Libri-light: A benchmark for asr with limited or no supervision.
\newblock In \emph{Proc. of ICASSP}, 2020.

\bibitem[Kawakami et~al.(2020)Kawakami, Wang, Dyer, Blunsom, and van~den
  Oord]{kawakami2020learning}
K.~Kawakami, L.~Wang, C.~Dyer, P.~Blunsom, and A.~van~den Oord.
\newblock Learning robust and multilingual speech representations.
\newblock \emph{arXiv}, 2020.

\bibitem[Kingma and Ba(2015)]{kingma2015adam}
D.~P. Kingma and J.~Ba.
\newblock {Adam: A Method for Stochastic Optimization}.
\newblock In \emph{Proc. of ICLR}, 2015.

\bibitem[Laptev et~al.(2020)Laptev, Korostik, Svischev, Andrusenko, Medennikov,
  and Rybin]{aleks2020need}
A.~Laptev, R.~Korostik, A.~Svischev, A.~Andrusenko, I.~Medennikov, and
  S.~Rybin.
\newblock You do not need more data: Improving end-to-end speech recognition by
  text-to-speech data augmentation.
\newblock \emph{arXiv}, abs/2005.07157, 2020.

\bibitem[Lewis et~al.(2016)Lewis, Simon, and Fennig]{lewis2016ethnologue}
M.~P. Lewis, G.~F. Simon, and C.~D. Fennig.
\newblock Ethnologue: Languages of the world, nineteenth edition.
\newblock Online version: \url{http://www.ethnologue.com}, 2016.

\bibitem[Liu et~al.(2019{\natexlab{a}})Liu, Tu, yi~Lee, and shan
  Lee]{alex2019unsupervised}
A.~H. Liu, T.~Tu, H.~yi~Lee, and L.~shan Lee.
\newblock Towards unsupervised speech recognition and synthesis with quantized
  speech representation learning.
\newblock \emph{arXiv}, 2019{\natexlab{a}}.

\bibitem[Liu et~al.(2019{\natexlab{b}})Liu, Ott, Goyal, Du, Joshi, Chen, Levy,
  Lewis, Zettlemoyer, and Stoyanov]{liu2019roberta}
Y.~Liu, M.~Ott, N.~Goyal, J.~Du, M.~Joshi, D.~Chen, O.~Levy, M.~Lewis,
  L.~Zettlemoyer, and V.~Stoyanov.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019{\natexlab{b}}.

\bibitem[L\"{u}scher et~al.(2019)L\"{u}scher, Beck, Irie, Kitza, Michel, Zeyer,
  Schlüter, and Ney]{L_scher_2019}
C.~L\"{u}scher, E.~Beck, K.~Irie, M.~Kitza, W.~Michel, A.~Zeyer, R.~Schlüter,
  and H.~Ney.
\newblock Rwth asr systems for librispeech: Hybrid vs attention.
\newblock In \emph{Interspeech 2019}, 2019.

\bibitem[Maddison et~al.(2014)Maddison, Tarlow, and
  Minka]{maddison2014sampling}
C.~J. Maddison, D.~Tarlow, and T.~Minka.
\newblock A* sampling.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3086--3094, 2014.

\bibitem[Misra and van~der Maaten(2019)]{misra2019selfsupervised}
I.~Misra and L.~van~der Maaten.
\newblock Self-supervised learning of pretext-invariant representations.
\newblock \emph{arXiv}, 2019.

\bibitem[Mohamed et~al.(2019)Mohamed, Okhonko, and
  Zettlemoyer]{mohamed2019libri}
A.~Mohamed, D.~Okhonko, and L.~Zettlemoyer.
\newblock Transformers with convolutional context for {ASR}.
\newblock \emph{arXiv}, abs/1904.11660, 2019.

\bibitem[Ott et~al.(2018)Ott, Edunov, Grangier, and Auli]{ott2018scaling}
M.~Ott, S.~Edunov, D.~Grangier, and M.~Auli.
\newblock Scaling neural machine translation.
\newblock In \emph{Proc. of WMT}, 2018.

\bibitem[Ott et~al.(2019)Ott, Edunov, Baevski, Fan, Gross, Ng, Grangier, and
  Auli]{ott2019fairseq}
M.~Ott, S.~Edunov, A.~Baevski, A.~Fan, S.~Gross, N.~Ng, D.~Grangier, and
  M.~Auli.
\newblock fairseq: A fast, extensible toolkit for sequence modeling.
\newblock In \emph{Proc. of NAACL System Demonstrations}, 2019.

\bibitem[Panayotov et~al.(2015)Panayotov, Chen, Povey, and
  Khudanpur]{panayotov2015librispeech}
V.~Panayotov, G.~Chen, D.~Povey, and S.~Khudanpur.
\newblock Librispeech: an asr corpus based on public domain audio books.
\newblock In \emph{Proc. of ICASSP}, pages 5206--5210. IEEE, 2015.

\bibitem[Park et~al.(2019)Park, Chan, Zhang, Chiu, Zoph, Cubuk, and
  Le]{park2019specaugment}
D.~S. Park, W.~Chan, Y.~Zhang, C.-C. Chiu, B.~Zoph, E.~D. Cubuk, and Q.~V. Le.
\newblock Specaugment: A simple data augmentation method for automatic speech
  recognition.
\newblock In \emph{Proc. of Interspeech}, 2019.

\bibitem[Park et~al.(2020)Park, Zhang, Jia, Han, Chiu, Li, Wu, and
  Le]{park2020improved}
D.~S. Park, Y.~Zhang, Y.~Jia, W.~Han, C.-C. Chiu, B.~Li, Y.~Wu, and Q.~V. Le.
\newblock Improved noisy student training for automatic speech recognition.
\newblock \emph{arXiv}, abs/2005.09629, 2020.

\bibitem[Peters et~al.(2018)Peters, Neumann, Iyyer, Gardner, Clark, Lee, and
  Zettlemoyer]{peters2018acl}
M.~E. Peters, M.~Neumann, M.~Iyyer, M.~Gardner, C.~Clark, K.~Lee, and
  L.~Zettlemoyer.
\newblock Deep contextualized word representations.
\newblock In \emph{Proc. of ACL}, 2018.

\bibitem[{Pratap} et~al.(2019){Pratap}, {Hannun}, {Xu}, {Cai}, {Kahn},
  {Synnaeve}, {Liptchinsky}, and {Collobert}]{pratap2019w2l}
V.~{Pratap}, A.~{Hannun}, Q.~{Xu}, J.~{Cai}, J.~{Kahn}, G.~{Synnaeve},
  V.~{Liptchinsky}, and R.~{Collobert}.
\newblock Wav2letter++: A fast open-source speech recognition system.
\newblock In \emph{Proc. of ICASSP}, 2019.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, and
  Sutskever]{radford2018unsup}
A.~Radford, K.~Narasimhan, T.~Salimans, and I.~Sutskever.
\newblock Improving language understanding by generative pre-training.
\newblock
  \url{https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf},
  2018.

\bibitem[Ravanelli et~al.(2018)Ravanelli, Brakel, Omologo, and
  Bengio]{ravanelli2018light}
M.~Ravanelli, P.~Brakel, M.~Omologo, and Y.~Bengio.
\newblock Light gated recurrent units for speech recognition.
\newblock \emph{IEEE Transactions on Emerging Topics in Computational
  Intelligence}, 2\penalty0 (2):\penalty0 92--102, 2018.

\bibitem[Ravanelli et~al.(2020)Ravanelli, Zhong, Pascual, Swietojanski,
  Monteiro, Trmal, and Bengio]{ravanelli2020pasep}
M.~Ravanelli, J.~Zhong, S.~Pascual, P.~Swietojanski, J.~Monteiro, J.~Trmal, and
  Y.~Bengio.
\newblock Multi-task self-supervised learning for robust speech recognition.
\newblock \emph{arXiv}, 2020.

\bibitem[Rivière et~al.(2020)Rivière, Joulin, Mazaré, and
  Dupoux]{rivire2020unsupervised}
M.~Rivière, A.~Joulin, P.-E. Mazaré, and E.~Dupoux.
\newblock Unsupervised pretraining transfers well across languages.
\newblock \emph{arXiv}, abs/2002.02848, 2020.

\bibitem[Schneider et~al.(2019)Schneider, Baevski, Collobert, and
  Auli]{schneider2019wav2vec}
S.~Schneider, A.~Baevski, R.~Collobert, and M.~Auli.
\newblock wav2vec: Unsupervised pre-training for speech recognition.
\newblock In \emph{Proc. of Interspeech}, 2019.

\bibitem[Schuster and Nakajima(2012)]{schuster2012wordpieces}
M.~Schuster and K.~Nakajima.
\newblock Japanese and korean voice search.
\newblock In \emph{Proc. of ICASSP}, 2012.

\bibitem[Synnaeve et~al.(2020)Synnaeve, Xu, Kahn, Likhomanenko, Grave, Pratap,
  Sriram, Liptchinsky, and Collobert]{synnaeve2020end}
G.~Synnaeve, Q.~Xu, J.~Kahn, T.~Likhomanenko, E.~Grave, V.~Pratap, A.~Sriram,
  V.~Liptchinsky, and R.~Collobert.
\newblock End-to-end {ASR}: from {Supervised} to {Semi}-{Supervised} {Learning}
  with {Modern} {Architectures}.
\newblock \emph{arXiv}, abs/1911.08460, 2020.

\bibitem[Tjandra et~al.(2019)Tjandra, Sisman, Zhang, Sakti, Li, and
  Nakamura]{tjandra2019vqvae}
A.~Tjandra, B.~Sisman, M.~Zhang, S.~Sakti, H.~Li, and S.~Nakamura.
\newblock Vqvae unsupervised unit discovery and multi-scale code2spec inverter
  for zerospeech challenge 2019.
\newblock \emph{arXiv}, 1905.11449, 2019.

\bibitem[van~den Oord et~al.(2017)van~den Oord, Vinyals,
  et~al.]{oord2017neural}
A.~van~den Oord, O.~Vinyals, et~al.
\newblock Neural discrete representation learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6306--6315, 2017.

\bibitem[van~den Oord et~al.(2018)van~den Oord, Li, and Vinyals]{oord2018cpc}
A.~van~den Oord, Y.~Li, and O.~Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv}, abs/1807.03748, 2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017transformer}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  L.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Proc. of NIPS}, 2017.

\bibitem[Wang et~al.(2020)Wang, Tang, and Livescu]{wang2020unsupervised}
W.~Wang, Q.~Tang, and K.~Livescu.
\newblock Unsupervised pre-training of bidirectional speech encoders via masked
  reconstruction.
\newblock \emph{arXiv}, 2020.

\bibitem[Wu et~al.(2019)Wu, Fan, Baevski, Dauphin, and Auli]{wu2019pay}
F.~Wu, A.~Fan, A.~Baevski, Y.~N. Dauphin, and M.~Auli.
\newblock Pay less attention with lightweight and dynamic convolutions.
\newblock In \emph{Proc. of ICLR}, 2019.

\bibitem[Xu et~al.(2020)Xu, Likhomanenko, Kahn, Hannun, Synnaeve, and
  Collobert]{xu2020iterative}
Q.~Xu, T.~Likhomanenko, J.~Kahn, A.~Hannun, G.~Synnaeve, and R.~Collobert.
\newblock Iterative pseudo-labeling for speech recognition.
\newblock \emph{arXiv}, 2020.

\bibitem[Zeghidour et~al.(2018)Zeghidour, Usunier, Kokkinos, Schaiz, Synnaeve,
  and Dupoux]{zeghidour2018filters}
N.~Zeghidour, N.~Usunier, I.~Kokkinos, T.~Schaiz, G.~Synnaeve, and E.~Dupoux.
\newblock Learning filterbanks from raw speech for phone recognition.
\newblock In \emph{Proc. of ICASSP}, 2018.

\bibitem[Zhang et~al.(2020)Zhang, Lu, Sak, Tripathi, McDermott, Koo, and
  Kumar]{zhang2020transformer}
Q.~Zhang, H.~Lu, H.~Sak, A.~Tripathi, E.~McDermott, S.~Koo, and S.~Kumar.
\newblock Transformer transducer: A streamable speech recognition model with
  transformer encoders and rnn-t loss.
\newblock \emph{arXiv}, 2020.

\end{thebibliography}
