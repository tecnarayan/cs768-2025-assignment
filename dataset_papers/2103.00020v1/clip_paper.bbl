\begin{thebibliography}{211}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Barham, Chen, Chen, Davis, Dean, Devin,
  Ghemawat, Irving, Isard, et~al.]{abadi2016tensorflow}
Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M.,
  Ghemawat, S., Irving, G., Isard, M., et~al.
\newblock Tensorflow: A system for large-scale machine learning.
\newblock In \emph{12th $\{$USENIX$\}$ symposium on operating systems design
  and implementation ($\{$OSDI$\}$ 16)}, pp.\  265--283, 2016.

\bibitem[Alayrac et~al.(2020)Alayrac, Recasens, Schneider, Arandjelovi{\'c},
  Ramapuram, De~Fauw, Smaira, Dieleman, and Zisserman]{alayrac2020self}
Alayrac, J.-B., Recasens, A., Schneider, R., Arandjelovi{\'c}, R., Ramapuram,
  J., De~Fauw, J., Smaira, L., Dieleman, S., and Zisserman, A.
\newblock Self-supervised multimodal versatile networks.
\newblock \emph{arXiv preprint arXiv:2006.16228}, 2020.

\bibitem[Alcorn et~al.(2019)Alcorn, Li, Gong, Wang, Mai, Ku, and
  Nguyen]{alcorn2019strike}
Alcorn, M.~A., Li, Q., Gong, Z., Wang, C., Mai, L., Ku, W.-S., and Nguyen, A.
\newblock Strike (with) a pose: Neural networks are easily fooled by strange
  poses of familiar objects.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  4845--4854, 2019.

\bibitem[Andreas et~al.(2017)Andreas, Klein, and Levine]{andreas2017learning}
Andreas, J., Klein, D., and Levine, S.
\newblock Learning with latent language.
\newblock \emph{arXiv preprint arXiv:1711.00482}, 2017.

\bibitem[Assiri(2020)]{assiri2020stochastic}
Assiri, Y.
\newblock Stochastic optimization of plain convolutional neural networks with
  simple methods.
\newblock \emph{arXiv preprint arXiv:2001.08856}, 2020.

\bibitem[Bachman et~al.(2019)Bachman, Hjelm, and
  Buchwalter]{bachman2019learning}
Bachman, P., Hjelm, R.~D., and Buchwalter, W.
\newblock Learning representations by maximizing mutual information across
  views.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  15535--15545, 2019.

\bibitem[Barbu et~al.(2019)Barbu, Mayo, Alverio, Luo, Wang, Gutfreund,
  Tenenbaum, and Katz]{barbu2019objectnet}
Barbu, A., Mayo, D., Alverio, J., Luo, W., Wang, C., Gutfreund, D., Tenenbaum,
  J., and Katz, B.
\newblock Objectnet: A large-scale bias-controlled dataset for pushing the
  limits of object recognition models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  9453--9463, 2019.

\bibitem[Barnard et~al.(2003)Barnard, Duygulu, Forsyth, Freitas, Blei, and
  Jordan]{barnard2003matching}
Barnard, K., Duygulu, P., Forsyth, D., Freitas, N.~d., Blei, D.~M., and Jordan,
  M.~I.
\newblock Matching words and pictures.
\newblock \emph{Journal of machine learning research}, 3\penalty0
  (Feb):\penalty0 1107--1135, 2003.

\bibitem[Bechmann \& Bowker(2019)Bechmann and Bowker]{Bechmann2019}
Bechmann, A. and Bowker, G.~C.
\newblock Unsupervised by any other name: Hidden layers of knowledge production
  in artificial intelligence on social media.
\newblock \emph{Big Data {\&} Society}, 6\penalty0 (1):\penalty0
  205395171881956, January 2019.
\newblock \doi{10.1177/2053951718819569}.
\newblock URL \url{https://doi.org/10.1177/2053951718819569}.

\bibitem[Bengio et~al.(2003)Bengio, Ducharme, Vincent, and
  Jauvin]{bengio2003neural}
Bengio, Y., Ducharme, R., Vincent, P., and Jauvin, C.
\newblock A neural probabilistic language model.
\newblock \emph{Journal of machine learning research}, 3\penalty0
  (Feb):\penalty0 1137--1155, 2003.

\bibitem[Bhargava \& Forsyth(2019)Bhargava and Forsyth]{bhargava2019exposing}
Bhargava, S. and Forsyth, D.
\newblock Exposing and correcting the gender bias in image captioning datasets
  and models.
\newblock \emph{arXiv preprint arXiv:1912.00578}, 2019.

\bibitem[Blei et~al.(2003)Blei, Ng, and Jordan]{blei2003latent}
Blei, D.~M., Ng, A.~Y., and Jordan, M.~I.
\newblock Latent dirichlet allocation.
\newblock \emph{Journal of machine Learning research}, 3\penalty0
  (Jan):\penalty0 993--1022, 2003.

\bibitem[Bolukbasi et~al.(2016)Bolukbasi, Chang, Zou, Saligrama, and
  Kalai]{bolukbasi2016man}
Bolukbasi, T., Chang, K.-W., Zou, J.~Y., Saligrama, V., and Kalai, A.~T.
\newblock Man is to computer programmer as woman is to homemaker? debiasing
  word embeddings.
\newblock \emph{Advances in neural information processing systems},
  29:\penalty0 4349--4357, 2016.

\bibitem[Bowker \& Star(2000)Bowker and Star]{bowker2000sorting}
Bowker, G.~C. and Star, S.~L.
\newblock \emph{Sorting things out: Classification and its consequences}.
\newblock MIT press, 2000.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{arXiv preprint arXiv:2005.14165}, 2020.

\bibitem[Browne(2015)]{brownesurveillance}
Browne, S.
\newblock \emph{Dark Matters: Surveillance of Blackness}.
\newblock Duke University Press, 2015.

\bibitem[Bulent~Sariyildiz et~al.(2020)Bulent~Sariyildiz, Perez, and
  Larlus]{bulent2020learning}
Bulent~Sariyildiz, M., Perez, J., and Larlus, D.
\newblock Learning visual representations with caption annotations.
\newblock \emph{arXiv e-prints}, pp.\  arXiv--2008, 2020.

\bibitem[Buolamwini \& Gebru(2018)Buolamwini and
  Gebru]{buolamwini2018gendershades}
Buolamwini, J. and Gebru, T.
\newblock Gender shades: Intersectional accuracy disparities in commercial
  gender classification.
\newblock In \emph{Conference on fairness, accountability and transparency},
  pp.\  77--91, 2018.

\bibitem[Carreira et~al.(2019)Carreira, Noland, Hillier, and
  Zisserman]{carreira2019kinetics700}
Carreira, J., Noland, E., Hillier, C., and Zisserman, A.
\newblock A short note on the kinetics-700 human action dataset.
\newblock \emph{arXiv preprint arXiv:1907.06987}, 2019.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Radford, Child, Wu, Jun, Luan,
  and Sutskever]{chen2020generative}
Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., and Sutskever, I.
\newblock Generative pretraining from pixels.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1691--1703. PMLR, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2016)Chen, Xu, Zhang, and Guestrin]{chen2016training}
Chen, T., Xu, B., Zhang, C., and Guestrin, C.
\newblock Training deep nets with sublinear memory cost.
\newblock \emph{arXiv preprint arXiv:1604.06174}, 2016.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Norouzi, and
  Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock \emph{arXiv preprint arXiv:2002.05709}, 2020{\natexlab{b}}.

\bibitem[Chen et~al.(2020{\natexlab{c}})Chen, Kornblith, Swersky, Norouzi, and
  Hinton]{chen2020big}
Chen, T., Kornblith, S., Swersky, K., Norouzi, M., and Hinton, G.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock \emph{arXiv preprint arXiv:2006.10029}, 2020{\natexlab{c}}.

\bibitem[Chen \& Gupta(2015)Chen and Gupta]{chen2015webly}
Chen, X. and Gupta, A.
\newblock Webly supervised learning of convolutional networks.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  1431--1439, 2015.

\bibitem[Chen et~al.(2020{\natexlab{d}})Chen, Fan, Girshick, and
  He]{chen2020mocov2}
Chen, X., Fan, H., Girshick, R., and He, K.
\newblock Improved baselines with momentum contrastive learning.
\newblock \emph{arXiv preprint arXiv:2003.04297}, 2020{\natexlab{d}}.

\bibitem[Chen et~al.(2019)Chen, Li, Yu, Kholy, Ahmed, Gan, Cheng, and
  Liu]{chen2019uniter}
Chen, Y.-C., Li, L., Yu, L., Kholy, A.~E., Ahmed, F., Gan, Z., Cheng, Y., and
  Liu, J.
\newblock Uniter: Learning universal image-text representations.
\newblock \emph{arXiv preprint arXiv:1909.11740}, 2019.

\bibitem[Cheng et~al.(2017)Cheng, Han, and Lu]{cheng2017remote}
Cheng, G., Han, J., and Lu, X.
\newblock Remote sensing image scene classification: Benchmark and state of the
  art.
\newblock \emph{Proceedings of the IEEE}, 105\penalty0 (10):\penalty0
  1865--1883, 2017.

\bibitem[Choi et~al.(2019)Choi, Shallue, Nado, Lee, Maddison, and
  Dahl]{choi2019empirical}
Choi, D., Shallue, C.~J., Nado, Z., Lee, J., Maddison, C.~J., and Dahl, G.~E.
\newblock On empirical comparisons of optimizers for deep learning.
\newblock \emph{arXiv preprint arXiv:1910.05446}, 2019.

\bibitem[Coates et~al.(2011)Coates, Ng, and Lee]{coates2011analysis}
Coates, A., Ng, A., and Lee, H.
\newblock An analysis of single-layer networks in unsupervised feature
  learning.
\newblock In \emph{Proceedings of the fourteenth international conference on
  artificial intelligence and statistics}, pp.\  215--223, 2011.

\bibitem[Crawford(2017)]{Crawford2017}
Crawford, K.
\newblock The trouble with bias.
\newblock \emph{NIPS 2017 Keynote}, 2017.
\newblock URL \url{https://www.youtube.com/watch?v=fMym_BKWQzk}.

\bibitem[Dai \& Le(2015)Dai and Le]{dai2015semi}
Dai, A.~M. and Le, Q.~V.
\newblock Semi-supervised sequence learning.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  3079--3087, 2015.

\bibitem[D'Amour et~al.(2020)D'Amour, Heller, Moldovan, Adlam, Alipanahi,
  Beutel, Chen, Deaton, Eisenstein, Hoffman, et~al.]{d2020underspecification}
D'Amour, A., Heller, K., Moldovan, D., Adlam, B., Alipanahi, B., Beutel, A.,
  Chen, C., Deaton, J., Eisenstein, J., Hoffman, M.~D., et~al.
\newblock Underspecification presents challenges for credibility in modern
  machine learning.
\newblock \emph{arXiv preprint arXiv:2011.03395}, 2020.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{imagenet_cvpr09}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock {ImageNet: A Large-Scale Hierarchical Image Database}.
\newblock In \emph{CVPR09}, 2009.

\bibitem[Deng et~al.(2012)Deng, Berg, Satheesh, Su, Khosla, and
  Fei-Fei]{ILSVRC2012}
Deng, J., Berg, A.~C., Satheesh, S., Su, H., Khosla, A., and Fei-Fei, L.
\newblock Ilsvrc 2012, 2012.
\newblock URL \url{http://www.image-net.org/challenges/LSVRC/2012/}.

\bibitem[Desai \& Johnson(2020)Desai and Johnson]{desai2020virtex}
Desai, K. and Johnson, J.
\newblock Virtex: Learning visual representations from textual annotations.
\newblock \emph{arXiv preprint arXiv:2006.06666}, 2020.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Dhariwal et~al.(2020)Dhariwal, Jun, Payne, Kim, Radford, and
  Sutskever]{dhariwal2020jukebox}
Dhariwal, P., Jun, H., Payne, C., Kim, J.~W., Radford, A., and Sutskever, I.
\newblock Jukebox: A generative model for music.
\newblock \emph{arXiv preprint arXiv:2005.00341}, 2020.

\bibitem[Divvala et~al.(2014)Divvala, Farhadi, and
  Guestrin]{divvala2014learning}
Divvala, S.~K., Farhadi, A., and Guestrin, C.
\newblock Learning everything about anything: Webly-supervised visual concept
  learning.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  3270--3277, 2014.

\bibitem[Dodge \& Karam(2017)Dodge and Karam]{dodge2017study}
Dodge, S. and Karam, L.
\newblock A study and comparison of human and deep learning recognition
  performance under visual distortions.
\newblock In \emph{2017 26th international conference on computer communication
  and networks (ICCCN)}, pp.\  1--7. IEEE, 2017.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Elhoseiny et~al.(2013)Elhoseiny, Saleh, and
  Elgammal]{elhoseiny2013write}
Elhoseiny, M., Saleh, B., and Elgammal, A.
\newblock Write a classifier: Zero-shot learning using purely textual
  descriptions.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  2584--2591, 2013.

\bibitem[Faghri et~al.(2017)Faghri, Fleet, Kiros, and Fidler]{faghri2017vse++}
Faghri, F., Fleet, D.~J., Kiros, J.~R., and Fidler, S.
\newblock Vse++: Improving visual-semantic embeddings with hard negatives.
\newblock \emph{arXiv preprint arXiv:1707.05612}, 2017.

\bibitem[Fergus et~al.(2005)Fergus, Fei-Fei, Perona, and
  Zisserman]{fergus2005learning}
Fergus, R., Fei-Fei, L., Perona, P., and Zisserman, A.
\newblock Learning object categories from google's image search.
\newblock In \emph{Tenth IEEE International Conference on Computer Vision
  (ICCV'05) Volume 1}, volume~2, pp.\  1816--1823. IEEE, 2005.

\bibitem[Frome et~al.(2013)Frome, Corrado, Shlens, Bengio, Dean, Ranzato, and
  Mikolov]{frome2013devise}
Frome, A., Corrado, G.~S., Shlens, J., Bengio, S., Dean, J., Ranzato, M., and
  Mikolov, T.
\newblock Devise: A deep visual-semantic embedding model.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2121--2129, 2013.

\bibitem[Gan et~al.(2020)Gan, Chen, Li, Zhu, Cheng, and Liu]{gan2020large}
Gan, Z., Chen, Y.-C., Li, L., Zhu, C., Cheng, Y., and Liu, J.
\newblock Large-scale adversarial training for vision-and-language
  representation learning.
\newblock \emph{arXiv preprint arXiv:2006.06195}, 2020.

\bibitem[Gao et~al.(2020)Gao, Fisch, and Chen]{gao2020making}
Gao, T., Fisch, A., and Chen, D.
\newblock Making pre-trained language models better few-shot learners.
\newblock \emph{arXiv preprint arXiv:2012.15723}, 2020.

\bibitem[Garvie(2019)]{garvie2019}
Garvie, C., May 2019.
\newblock URL \url{https://www.flawedfacedata.com/}.

\bibitem[Geiger et~al.(2012)Geiger, Lenz, and Urtasun]{geiger2012kitti}
Geiger, A., Lenz, P., and Urtasun, R.
\newblock Are we ready for autonomous driving? the kitti vision benchmark
  suite.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2012.

\bibitem[Geirhos et~al.(2018)Geirhos, Rubisch, Michaelis, Bethge, Wichmann, and
  Brendel]{geirhos2018imagenet}
Geirhos, R., Rubisch, P., Michaelis, C., Bethge, M., Wichmann, F.~A., and
  Brendel, W.
\newblock Imagenet-trained cnns are biased towards texture; increasing shape
  bias improves accuracy and robustness.
\newblock \emph{arXiv preprint arXiv:1811.12231}, 2018.

\bibitem[Geirhos et~al.(2020)Geirhos, Jacobsen, Michaelis, Zemel, Brendel,
  Bethge, and Wichmann]{geirhos2020shortcut}
Geirhos, R., Jacobsen, J.-H., Michaelis, C., Zemel, R., Brendel, W., Bethge,
  M., and Wichmann, F.~A.
\newblock Shortcut learning in deep neural networks.
\newblock \emph{arXiv preprint arXiv:2004.07780}, 2020.

\bibitem[Gomez et~al.(2017)Gomez, Patel, Rusi{\~n}ol, Karatzas, and
  Jawahar]{gomez2017self}
Gomez, L., Patel, Y., Rusi{\~n}ol, M., Karatzas, D., and Jawahar, C.
\newblock Self-supervised learning of visual features through embedding images
  into text topic spaces.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  4230--4239, 2017.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Erhan, Carrier, Courville, Mirza,
  Hamner, Cukierski, Tang, Thaler, Lee, et~al.]{goodfellow2015challenges}
Goodfellow, I.~J., Erhan, D., Carrier, P.~L., Courville, A., Mirza, M., Hamner,
  B., Cukierski, W., Tang, Y., Thaler, D., Lee, D.-H., et~al.
\newblock Challenges in representation learning: A report on three machine
  learning contests.
\newblock \emph{Neural Networks}, 64:\penalty0 59--63, 2015.

\bibitem[Google()]{Google}
Google.
\newblock Google cloud api: Celebrity recognition.
\newblock URL \url{https://cloud.google.com/vision/docs/celebrity-recognition}.

\bibitem[Griewank \& Walther(2000)Griewank and Walther]{griewank2000algorithm}
Griewank, A. and Walther, A.
\newblock Algorithm 799: revolve: an implementation of checkpointing for the
  reverse or adjoint mode of computational differentiation.
\newblock \emph{ACM Transactions on Mathematical Software (TOMS)}, 26\penalty0
  (1):\penalty0 19--45, 2000.

\bibitem[Grill et~al.(2020)Grill, Strub, Altch{\'e}, Tallec, Richemond,
  Buchatskaya, Doersch, Pires, Guo, Azar, et~al.]{grill2020byol}
Grill, J.-B., Strub, F., Altch{\'e}, F., Tallec, C., Richemond, P.~H.,
  Buchatskaya, E., Doersch, C., Pires, B.~A., Guo, Z.~D., Azar, M.~G., et~al.
\newblock Bootstrap your own latent: A new approach to self-supervised
  learning.
\newblock \emph{arXiv preprint arXiv:2006.07733}, 2020.

\bibitem[Ha et~al.(2016)Ha, Dai, and Le]{ha2016hypernetworks}
Ha, D., Dai, A., and Le, Q.~V.
\newblock Hypernetworks.
\newblock \emph{arXiv preprint arXiv:1609.09106}, 2016.

\bibitem[Hancock et~al.(2018)Hancock, Bringmann, Varma, Liang, Wang, and
  R{\'e}]{hancock2018training}
Hancock, B., Bringmann, M., Varma, P., Liang, P., Wang, S., and R{\'e}, C.
\newblock Training classifiers with natural language explanations.
\newblock In \emph{Proceedings of the conference. Association for Computational
  Linguistics. Meeting}, volume 2018, pp.\  1884. NIH Public Access, 2018.

\bibitem[Hancock et~al.(2019)Hancock, Bordes, Mazare, and
  Weston]{hancock2019learning}
Hancock, B., Bordes, A., Mazare, P.-E., and Weston, J.
\newblock Learning from dialogue after deployment: Feed yourself, chatbot!
\newblock \emph{arXiv preprint arXiv:1901.05415}, 2019.

\bibitem[Harris et~al.(2020)Harris, Millman, van~der Walt, Gommers, Virtanen,
  Cournapeau, Wieser, Taylor, Berg, Smith, Kern, Picus, Hoyer, van Kerkwijk,
  Brett, Haldane, Fernández~del Río, Wiebe, Peterson, Gérard-Marchant,
  Sheppard, Reddy, Weckesser, Abbasi, Gohlke, and Oliphant]{2020NumPy-Array}
Harris, C.~R., Millman, K.~J., van~der Walt, S.~J., Gommers, R., Virtanen, P.,
  Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N.~J., Kern, R.,
  Picus, M., Hoyer, S., van Kerkwijk, M.~H., Brett, M., Haldane, A.,
  Fernández~del Río, J., Wiebe, M., Peterson, P., Gérard-Marchant, P.,
  Sheppard, K., Reddy, T., Weckesser, W., Abbasi, H., Gohlke, C., and Oliphant,
  T.~E.
\newblock Array programming with {NumPy}.
\newblock \emph{Nature}, 585:\penalty0 357–362, 2020.
\newblock \doi{10.1038/s41586-020-2649-2}.

\bibitem[Hays \& Efros(2008)Hays and Efros]{hays2008im2gps}
Hays, J. and Efros, A.~A.
\newblock Im2gps: estimating geographic information from a single image.
\newblock In \emph{2008 ieee conference on computer vision and pattern
  recognition}, pp.\  1--8. IEEE, 2008.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{he2015delving}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Delving deep into rectifiers: Surpassing human-level performance on
  imagenet classification.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  1026--1034, 2015.

\bibitem[He et~al.(2016{\natexlab{a}})He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016{\natexlab{a}}.

\bibitem[He et~al.(2016{\natexlab{b}})He, Zhang, Ren, and Sun]{he2016resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016{\natexlab{b}}.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020moco}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  9729--9738, 2020.

\bibitem[He et~al.(2019)He, Zhang, Zhang, Zhang, Xie, and Li]{he2019bag}
He, T., Zhang, Z., Zhang, H., Zhang, Z., Xie, J., and Li, M.
\newblock Bag of tricks for image classification with convolutional neural
  networks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  558--567, 2019.

\bibitem[He \& Peng(2017)He and Peng]{he2017fine}
He, X. and Peng, Y.
\newblock Fine-grained image classification via combining vision and language.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  5994--6002, 2017.

\bibitem[Helber et~al.(2019)Helber, Bischke, Dengel, and
  Borth]{helber2019eurosat}
Helber, P., Bischke, B., Dengel, A., and Borth, D.
\newblock Eurosat: A novel dataset and deep learning benchmark for land use and
  land cover classification.
\newblock \emph{IEEE Journal of Selected Topics in Applied Earth Observations
  and Remote Sensing}, 12\penalty0 (7):\penalty0 2217--2226, 2019.

\bibitem[Henaff(2020)]{henaff2020data}
Henaff, O.
\newblock Data-efficient image recognition with contrastive predictive coding.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4182--4192. PMLR, 2020.

\bibitem[Hendrycks \& Dietterich(2019)Hendrycks and
  Dietterich]{hendrycks2019benchmarking}
Hendrycks, D. and Dietterich, T.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock \emph{arXiv preprint arXiv:1903.12261}, 2019.

\bibitem[Hendrycks \& Gimpel(2016)Hendrycks and Gimpel]{hendrycks2016gaussian}
Hendrycks, D. and Gimpel, K.
\newblock Gaussian error linear units (gelus).
\newblock \emph{arXiv preprint arXiv:1606.08415}, 2016.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Zhao, Basart, Steinhardt, and
  Song]{hendrycks2019natural}
Hendrycks, D., Zhao, K., Basart, S., Steinhardt, J., and Song, D.
\newblock Natural adversarial examples.
\newblock \emph{arXiv preprint arXiv:1907.07174}, 2019.

\bibitem[Hendrycks et~al.(2020{\natexlab{a}})Hendrycks, Basart, Mu, Kadavath,
  Wang, Dorundo, Desai, Zhu, Parajuli, Guo, et~al.]{hendrycks2020many}
Hendrycks, D., Basart, S., Mu, N., Kadavath, S., Wang, F., Dorundo, E., Desai,
  R., Zhu, T., Parajuli, S., Guo, M., et~al.
\newblock The many faces of robustness: A critical analysis of
  out-of-distribution generalization.
\newblock \emph{arXiv preprint arXiv:2006.16241}, 2020{\natexlab{a}}.

\bibitem[Hendrycks et~al.(2020{\natexlab{b}})Hendrycks, Liu, Wallace, Dziedzic,
  Krishnan, and Song]{hendrycks2020pretrained}
Hendrycks, D., Liu, X., Wallace, E., Dziedzic, A., Krishnan, R., and Song, D.
\newblock Pretrained transformers improve out-of-distribution robustness.
\newblock \emph{arXiv preprint arXiv:2004.06100}, 2020{\natexlab{b}}.

\bibitem[Hestness et~al.(2017)Hestness, Narang, Ardalani, Diamos, Jun,
  Kianinejad, Patwary, Ali, Yang, and Zhou]{hestness2017deep}
Hestness, J., Narang, S., Ardalani, N., Diamos, G., Jun, H., Kianinejad, H.,
  Patwary, M., Ali, M., Yang, Y., and Zhou, Y.
\newblock Deep learning scaling is predictable, empirically.
\newblock \emph{arXiv preprint arXiv:1712.00409}, 2017.

\bibitem[Hill et~al.(2019)Hill, Lampinen, Schneider, Clark, Botvinick,
  McClelland, and Santoro]{hill2019environmental}
Hill, F., Lampinen, A., Schneider, R., Clark, S., Botvinick, M., McClelland,
  J.~L., and Santoro, A.
\newblock Environmental drivers of systematicity and generalization in a
  situated agent.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Hodosh et~al.(2013)Hodosh, Young, and Hockenmaier]{hodosh2013framing}
Hodosh, M., Young, P., and Hockenmaier, J.
\newblock Framing image description as a ranking task: Data, models and
  evaluation metrics.
\newblock \emph{Journal of Artificial Intelligence Research}, 47:\penalty0
  853--899, 2013.

\bibitem[Hongsuck~Seo et~al.(2018)Hongsuck~Seo, Weyand, Sim, and
  Han]{hongsuck2018cplanet}
Hongsuck~Seo, P., Weyand, T., Sim, J., and Han, B.
\newblock Cplanet: Enhancing image geolocalization by combinatorial
  partitioning of maps.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  536--551, 2018.

\bibitem[Howard \& Ruder(2018)Howard and Ruder]{howard2018universal}
Howard, J. and Ruder, S.
\newblock Universal language model fine-tuning for text classification.
\newblock \emph{arXiv preprint arXiv:1801.06146}, 2018.

\bibitem[Ilyas et~al.(2019)Ilyas, Santurkar, Tsipras, Engstrom, Tran, and
  Madry]{ilyas2019adversarial}
Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., and Madry, A.
\newblock Adversarial examples are not bugs, they are features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  125--136, 2019.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{ioffe2015batch}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{arXiv preprint arXiv:1502.03167}, 2015.

\bibitem[Jaderberg et~al.(2014)Jaderberg, Simonyan, Vedaldi, and
  Zisserman]{jaderberg2014deep}
Jaderberg, M., Simonyan, K., Vedaldi, A., and Zisserman, A.
\newblock Deep structured output learning for unconstrained text recognition.
\newblock \emph{arXiv preprint arXiv:1412.5903}, 2014.

\bibitem[Jaderberg et~al.(2015)Jaderberg, Simonyan, Zisserman,
  et~al.]{jaderberg2015spatial}
Jaderberg, M., Simonyan, K., Zisserman, A., et~al.
\newblock Spatial transformer networks.
\newblock \emph{Advances in neural information processing systems},
  28:\penalty0 2017--2025, 2015.

\bibitem[Johnson et~al.(2017)Johnson, Hariharan, van~der Maaten, Fei-Fei,
  Lawrence~Zitnick, and Girshick]{johnson2017clevr}
Johnson, J., Hariharan, B., van~der Maaten, L., Fei-Fei, L., Lawrence~Zitnick,
  C., and Girshick, R.
\newblock Clevr: A diagnostic dataset for compositional language and elementary
  visual reasoning.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  2901--2910, 2017.

\bibitem[Joulin et~al.(2016)Joulin, Van Der~Maaten, Jabri, and
  Vasilache]{joulin2016learning}
Joulin, A., Van Der~Maaten, L., Jabri, A., and Vasilache, N.
\newblock Learning visual features from large weakly supervised data.
\newblock In \emph{European Conference on Computer Vision}, pp.\  67--84.
  Springer, 2016.

\bibitem[Kalfaoglu et~al.(2020)Kalfaoglu, Kalkan, and
  Alatan]{kalfaoglu2020late}
Kalfaoglu, M., Kalkan, S., and Alatan, A.~A.
\newblock Late temporal modeling in 3d cnn architectures with bert for action
  recognition.
\newblock \emph{arXiv preprint arXiv:2008.01232}, 2020.

\bibitem[Kaplan et~al.(2020)Kaplan, McCandlish, Henighan, Brown, Chess, Child,
  Gray, Radford, Wu, and Amodei]{kaplan2020scaling}
Kaplan, J., McCandlish, S., Henighan, T., Brown, T.~B., Chess, B., Child, R.,
  Gray, S., Radford, A., Wu, J., and Amodei, D.
\newblock Scaling laws for neural language models.
\newblock \emph{arXiv preprint arXiv:2001.08361}, 2020.

\bibitem[Karpathy et~al.(2014)Karpathy, Joulin, and Fei-Fei]{karpathy2014deep}
Karpathy, A., Joulin, A., and Fei-Fei, L.~F.
\newblock Deep fragment embeddings for bidirectional image sentence mapping.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1889--1897, 2014.

\bibitem[Keyes(2018)]{keyes2018misgendering}
Keyes, O.
\newblock The misgendering machines: Trans/hci implications of automatic gender
  recognition.
\newblock \emph{Proceedings of the ACM on Human-Computer Interaction},
  2\penalty0 (CSCW):\penalty0 1--22, 2018.

\bibitem[Kiela et~al.(2020)Kiela, Firooz, Mohan, Goswami, Singh, Ringshia, and
  Testuggine]{kiela2020hateful}
Kiela, D., Firooz, H., Mohan, A., Goswami, V., Singh, A., Ringshia, P., and
  Testuggine, D.
\newblock The hateful memes challenge: Detecting hate speech in multimodal
  memes.
\newblock \emph{arXiv preprint arXiv:2005.04790}, 2020.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kiros et~al.(2014)Kiros, Salakhutdinov, and Zemel]{kiros2014unifying}
Kiros, R., Salakhutdinov, R., and Zemel, R.~S.
\newblock Unifying visual-semantic embeddings with multimodal neural language
  models.
\newblock \emph{arXiv preprint arXiv:1411.2539}, 2014.

\bibitem[Kiros et~al.(2015)Kiros, Zhu, Salakhutdinov, Zemel, Urtasun, Torralba,
  and Fidler]{kiros2015skip}
Kiros, R., Zhu, Y., Salakhutdinov, R.~R., Zemel, R., Urtasun, R., Torralba, A.,
  and Fidler, S.
\newblock Skip-thought vectors.
\newblock \emph{Advances in neural information processing systems},
  28:\penalty0 3294--3302, 2015.

\bibitem[Kolesnikov et~al.(2019)Kolesnikov, Beyer, Zhai, Puigcerver, Yung,
  Gelly, and Houlsby]{kolesnikov2019large}
Kolesnikov, A., Beyer, L., Zhai, X., Puigcerver, J., Yung, J., Gelly, S., and
  Houlsby, N.
\newblock Large scale learning of general visual representations for transfer.
\newblock \emph{arXiv preprint arXiv:1912.11370}, 2019.

\bibitem[Kornblith et~al.(2019)Kornblith, Shlens, and Le]{kornblith2019better}
Kornblith, S., Shlens, J., and Le, Q.~V.
\newblock Do better imagenet models transfer better?
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2661--2671, 2019.

\bibitem[Krishna et~al.(2017)Krishna, Zhu, Groth, Johnson, Hata, Kravitz, Chen,
  Kalantidis, Li, Shamma, et~al.]{krishna2017visual}
Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S.,
  Kalantidis, Y., Li, L.-J., Shamma, D.~A., et~al.
\newblock Visual genome: Connecting language and vision using crowdsourced
  dense image annotations.
\newblock \emph{International journal of computer vision}, 123\penalty0
  (1):\penalty0 32--73, 2017.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1097--1105, 2012.

\bibitem[Kuhnle \& Copestake(2017)Kuhnle and Copestake]{kuhnle2017shapeworld}
Kuhnle, A. and Copestake, A.
\newblock Shapeworld-a new test methodology for multimodal language
  understanding.
\newblock \emph{arXiv preprint arXiv:1704.04517}, 2017.

\bibitem[Kärkkäinen \& Joo(2019)Kärkkäinen and Joo]{1908.04913}
Kärkkäinen, K. and Joo, J.
\newblock Fairface: Face attribute dataset for balanced race, gender, and age,
  2019.

\bibitem[Lake et~al.(2016)Lake, Ullman, Tenenbaum, and
  Gershman]{lake2016building}
Lake, B.~M., Ullman, T.~D., Tenenbaum, J.~B., and Gershman, S.~J.
\newblock Building machines that learn and think like people, 2016.

\bibitem[Lampert et~al.(2009)Lampert, Nickisch, and
  Harmeling]{lampert2009learning}
Lampert, C.~H., Nickisch, H., and Harmeling, S.
\newblock Learning to detect unseen object classes by between-class attribute
  transfer.
\newblock In \emph{2009 IEEE Conference on Computer Vision and Pattern
  Recognition}, pp.\  951--958. IEEE, 2009.

\bibitem[Larochelle et~al.(2008)Larochelle, Erhan, and
  Bengio]{larochelle2008zero}
Larochelle, H., Erhan, D., and Bengio, Y.
\newblock Zero-data learning of new tasks.
\newblock 2008.

\bibitem[Le \& Mikolov(2014)Le and Mikolov]{le2014distributed}
Le, Q. and Mikolov, T.
\newblock Distributed representations of sentences and documents.
\newblock In \emph{International conference on machine learning}, pp.\
  1188--1196, 2014.

\bibitem[LeCun()]{lecun1998mnist}
LeCun, Y.
\newblock The mnist database of handwritten digits.
\newblock \emph{http://yann. lecun. com/exdb/mnist/}.

\bibitem[Lee()]{lee2013pseudo}
Lee, D.-H.
\newblock Pseudo-label: The simple and efficient semi-supervised learning
  method for deep neural networks.

\bibitem[Lei~Ba et~al.(2015)Lei~Ba, Swersky, Fidler, et~al.]{lei2015predicting}
Lei~Ba, J., Swersky, K., Fidler, S., et~al.
\newblock Predicting deep zero-shot convolutional neural networks using textual
  descriptions.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  4247--4255, 2015.

\bibitem[Li et~al.(2017)Li, Jabri, Joulin, and van~der Maaten]{li2017learning}
Li, A., Jabri, A., Joulin, A., and van~der Maaten, L.
\newblock Learning visual n-grams from web data.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  4183--4192, 2017.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Duan, Fang, Gong, and
  Jiang]{li2020unicoder}
Li, G., Duan, N., Fang, Y., Gong, M., and Jiang, D.
\newblock Unicoder-vl: A universal encoder for vision and language by
  cross-modal pre-training.
\newblock 2020{\natexlab{a}}.

\bibitem[Li et~al.(2016)Li, Miller, Chopra, Ranzato, and
  Weston]{li2016learning}
Li, J., Miller, A.~H., Chopra, S., Ranzato, M., and Weston, J.
\newblock Learning through dialogue interactions by asking questions.
\newblock \emph{arXiv preprint arXiv:1612.04936}, 2016.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Yin, Li, Hu, Zhang, Zhang, Wang, Hu,
  Dong, Wei, et~al.]{li2020oscar}
Li, X., Yin, X., Li, C., Hu, X., Zhang, P., Zhang, L., Wang, L., Hu, H., Dong,
  L., Wei, F., et~al.
\newblock Oscar: Object-semantics aligned pre-training for vision-language
  tasks.
\newblock \emph{arXiv preprint arXiv:2004.06165}, 2020{\natexlab{b}}.

\bibitem[Liang et~al.(2020)Liang, Zou, and Yu]{liang2020alice}
Liang, W., Zou, J., and Yu, Z.
\newblock Alice: Active learning with contrastive natural language
  explanations.
\newblock \emph{arXiv preprint arXiv:2009.10259}, 2020.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{lin2014microsoft}
Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D.,
  Doll{\'a}r, P., and Zitnick, C.~L.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{European conference on computer vision}, pp.\  740--755.
  Springer, 2014.

\bibitem[Linzen(2020)]{linzen2020can}
Linzen, T.
\newblock How can we accelerate progress towards human-like linguistic
  generalization?
\newblock \emph{arXiv preprint arXiv:2005.00955}, 2020.

\bibitem[Lippe et~al.(2020)Lippe, Holla, Chandra, Rajamanickam, Antoniou,
  Shutova, and Yannakoudakis]{lippe2020multimodal}
Lippe, P., Holla, N., Chandra, S., Rajamanickam, S., Antoniou, G., Shutova, E.,
  and Yannakoudakis, H.
\newblock A multimodal framework for the detection of hateful memes.
\newblock \emph{arXiv preprint arXiv:2012.12871}, 2020.

\bibitem[Liu et~al.(2018)Liu, Saleh, Pot, Goodrich, Sepassi, Kaiser, and
  Shazeer]{liu2018generating}
Liu, P.~J., Saleh, M., Pot, E., Goodrich, B., Sepassi, R., Kaiser, L., and
  Shazeer, N.
\newblock Generating wikipedia by summarizing long sequences.
\newblock \emph{arXiv preprint arXiv:1801.10198}, 2018.

\bibitem[Locatello et~al.(2020)Locatello, Bauer, Lucic, R{\"a}tsch, Gelly,
  Sch{\"o}lkopf, and Bachem]{locatello2020sober}
Locatello, F., Bauer, S., Lucic, M., R{\"a}tsch, G., Gelly, S., Sch{\"o}lkopf,
  B., and Bachem, O.
\newblock A sober look at the unsupervised learning of disentangled
  representations and their evaluation.
\newblock \emph{arXiv preprint arXiv:2010.14766}, 2020.

\bibitem[Loshchilov \& Hutter(2016)Loshchilov and Hutter]{loshchilov2016sgdr}
Loshchilov, I. and Hutter, F.
\newblock Sgdr: Stochastic gradient descent with warm restarts.
\newblock \emph{arXiv preprint arXiv:1608.03983}, 2016.

\bibitem[Loshchilov \& Hutter(2017)Loshchilov and
  Hutter]{loshchilov2017decoupled}
Loshchilov, I. and Hutter, F.
\newblock Decoupled weight decay regularization.
\newblock \emph{arXiv preprint arXiv:1711.05101}, 2017.

\bibitem[Lu et~al.(2019)Lu, Batra, Parikh, and Lee]{lu2019vilbert}
Lu, J., Batra, D., Parikh, D., and Lee, S.
\newblock Vilbert: Pretraining task-agnostic visiolinguistic representations
  for vision-and-language tasks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  13--23, 2019.

\bibitem[Lu et~al.(2020)Lu, Xiong, Li, Stroud, and Ross]{lu2020leveraging}
Lu, Z., Xiong, X., Li, Y., Stroud, J., and Ross, D.
\newblock Leveraging weakly supervised data and pose representation for action
  recognition, 2020.
\newblock URL \url{https://www.youtube.com/watch?v=KOQFxbPPLOE&t=1390s}.

\bibitem[Lucic et~al.(2018)Lucic, Kurach, Michalski, Gelly, and
  Bousquet]{lucic2018gans}
Lucic, M., Kurach, K., Michalski, M., Gelly, S., and Bousquet, O.
\newblock Are gans created equal? a large-scale study.
\newblock \emph{Advances in neural information processing systems},
  31:\penalty0 700--709, 2018.

\bibitem[Mahajan et~al.(2018)Mahajan, Girshick, Ramanathan, He, Paluri, Li,
  Bharambe, and van~der Maaten]{mahajan2018exploring}
Mahajan, D., Girshick, R., Ramanathan, V., He, K., Paluri, M., Li, Y.,
  Bharambe, A., and van~der Maaten, L.
\newblock Exploring the limits of weakly supervised pretraining.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  181--196, 2018.

\bibitem[McCann et~al.(2017)McCann, Bradbury, Xiong, and
  Socher]{mccann2017learned}
McCann, B., Bradbury, J., Xiong, C., and Socher, R.
\newblock Learned in translation: Contextualized word vectors.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  6294--6305, 2017.

\bibitem[McCann et~al.(2018)McCann, Keskar, Xiong, and
  Socher]{mccann2018natural}
McCann, B., Keskar, N.~S., Xiong, C., and Socher, R.
\newblock The natural language decathlon: Multitask learning as question
  answering.
\newblock \emph{arXiv preprint arXiv:1806.08730}, 2018.

\bibitem[Micikevicius et~al.(2017)Micikevicius, Narang, Alben, Diamos, Elsen,
  Garcia, Ginsburg, Houston, Kuchaiev, Venkatesh,
  et~al.]{micikevicius2017mixed}
Micikevicius, P., Narang, S., Alben, J., Diamos, G., Elsen, E., Garcia, D.,
  Ginsburg, B., Houston, M., Kuchaiev, O., Venkatesh, G., et~al.
\newblock Mixed precision training.
\newblock \emph{arXiv preprint arXiv:1710.03740}, 2017.

\bibitem[Miech et~al.(2019)Miech, Zhukov, Alayrac, Tapaswi, Laptev, and
  Sivic]{miech2019howto100m}
Miech, A., Zhukov, D., Alayrac, J.-B., Tapaswi, M., Laptev, I., and Sivic, J.
\newblock Howto100m: Learning a text-video embedding by watching hundred
  million narrated video clips.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  2630--2640, 2019.

\bibitem[Miech et~al.(2020{\natexlab{a}})Miech, Alayrac, Laptev, Sivic, and
  Zisserman]{miech2020rareact}
Miech, A., Alayrac, J.-B., Laptev, I., Sivic, J., and Zisserman, A.
\newblock Rareact: A video dataset of unusual interactions.
\newblock \emph{arXiv preprint arXiv:2008.01018}, 2020{\natexlab{a}}.

\bibitem[Miech et~al.(2020{\natexlab{b}})Miech, Alayrac, Smaira, Laptev, Sivic,
  and Zisserman]{miech2020end}
Miech, A., Alayrac, J.-B., Smaira, L., Laptev, I., Sivic, J., and Zisserman, A.
\newblock End-to-end learning of visual representations from uncurated
  instructional videos.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  9879--9889, 2020{\natexlab{b}}.

\bibitem[Mikolov et~al.(2013)Mikolov, Sutskever, Chen, Corrado, and
  Dean]{mikolov2013distributed}
Mikolov, T., Sutskever, I., Chen, K., Corrado, G.~S., and Dean, J.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock \emph{Advances in neural information processing systems},
  26:\penalty0 3111--3119, 2013.

\bibitem[Miller et~al.(2020)Miller, Krauth, Recht, and
  Schmidt]{miller2020effect}
Miller, J., Krauth, K., Recht, B., and Schmidt, L.
\newblock The effect of natural distribution shift on question answering
  models.
\newblock \emph{arXiv preprint arXiv:2004.14444}, 2020.

\bibitem[Mishra et~al.(2012)Mishra, Alahari, and Jawahar]{mishra2012scene}
Mishra, A., Alahari, K., and Jawahar, C.
\newblock Scene text recognition using higher order language priors.
\newblock 2012.

\bibitem[Mithun et~al.(2018)Mithun, Panda, Papalexakis, and
  Roy-Chowdhury]{mithun2018webly}
Mithun, N.~C., Panda, R., Papalexakis, E.~E., and Roy-Chowdhury, A.~K.
\newblock Webly supervised joint embedding for cross-modal image-text
  retrieval.
\newblock In \emph{Proceedings of the 26th ACM international conference on
  Multimedia}, pp.\  1856--1864, 2018.

\bibitem[Mori et~al.(1999)Mori, Takahashi, and Oka]{mori1999image}
Mori, Y., Takahashi, H., and Oka, R.
\newblock Image-to-word transformation based on dividing and vector quantizing
  images with words.
\newblock Citeseer, 1999.

\bibitem[Mu et~al.(2019)Mu, Liang, and Goodman]{mu2019shaping}
Mu, J., Liang, P., and Goodman, N.
\newblock Shaping visual representations with language for few-shot
  classification.
\newblock \emph{arXiv preprint arXiv:1911.02683}, 2019.

\bibitem[Muller-Budack et~al.(2018)Muller-Budack, Pustu-Iren, and
  Ewerth]{muller2018geolocation}
Muller-Budack, E., Pustu-Iren, K., and Ewerth, R.
\newblock Geolocation estimation of photos using a hierarchical model and scene
  classification.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  563--579, 2018.

\bibitem[Murty et~al.(2020)Murty, Koh, and Liang]{murty2020expbert}
Murty, S., Koh, P.~W., and Liang, P.
\newblock Expbert: Representation engineering with natural language
  explanations.
\newblock \emph{arXiv preprint arXiv:2005.01932}, 2020.

\bibitem[Narasimhan et~al.(2015)Narasimhan, Kulkarni, and
  Barzilay]{narasimhan2015language}
Narasimhan, K., Kulkarni, T., and Barzilay, R.
\newblock Language understanding for text-based games using deep reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1506.08941}, 2015.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Ng]{netzer2011reading}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock 2011.

\bibitem[Noble(2018)]{Noble2018}
Noble, S.~U.
\newblock Algorithms of oppression: How search engines reinforce racism.
\newblock 2018.

\bibitem[Nosek et~al.(2002)Nosek, Banaji, and Greenwald]{nosek2002harvesting}
Nosek, B.~A., Banaji, M.~R., and Greenwald, A.~G.
\newblock Harvesting implicit group attitudes and beliefs from a demonstration
  web site.
\newblock \emph{Group Dynamics: Theory, Research, and Practice}, 6\penalty0
  (1):\penalty0 101, 2002.

\bibitem[Oh et~al.(2011)Oh, Hoogs, Perera, Cuntoor, Chen, Lee, Mukherjee,
  Aggarwal, Lee, Davis, et~al.]{oh2011large}
Oh, S., Hoogs, A., Perera, A., Cuntoor, N., Chen, C.-C., Lee, J.~T., Mukherjee,
  S., Aggarwal, J., Lee, H., Davis, L., et~al.
\newblock A large-scale benchmark dataset for event recognition in surveillance
  video.
\newblock In \emph{CVPR 2011}, pp.\  3153--3160. IEEE, 2011.

\bibitem[Oliver et~al.(2018)Oliver, Odena, Raffel, Cubuk, and
  Goodfellow]{oliver2018realistic}
Oliver, A., Odena, A., Raffel, C.~A., Cubuk, E.~D., and Goodfellow, I.
\newblock Realistic evaluation of deep semi-supervised learning algorithms.
\newblock \emph{Advances in neural information processing systems},
  31:\penalty0 3235--3246, 2018.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Oord, A. v.~d., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Ordonez et~al.(2011)Ordonez, Kulkarni, and Berg]{ordonez2011im2text}
Ordonez, V., Kulkarni, G., and Berg, T.
\newblock Im2text: Describing images using 1 million captioned photographs.
\newblock \emph{Advances in neural information processing systems},
  24:\penalty0 1143--1151, 2011.

\bibitem[pandas~development team(2020)]{reback2020pandas}
pandas~development team, T.
\newblock pandas-dev/pandas: Pandas, February 2020.
\newblock URL \url{https://doi.org/10.5281/zenodo.3509134}.

\bibitem[Parkhi et~al.(2012)Parkhi, Vedaldi, Zisserman, and Jawahar]{parkhi12a}
Parkhi, O.~M., Vedaldi, A., Zisserman, A., and Jawahar, C.~V.
\newblock Cats and dogs.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition},
  2012.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{NEURIPS2019_9015}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E.,
  DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L.,
  Bai, J., and Chintala, S.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pp.\
  8024--8035, 2019.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos,
  Cournapeau, Brucher, Perrot, and Duchesnay]{scikit-learn}
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel,
  O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J.,
  Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2825--2830,
  2011.

\bibitem[Pennington et~al.(2014)Pennington, Socher, and
  Manning]{pennington2014glove}
Pennington, J., Socher, R., and Manning, C.~D.
\newblock Glove: Global vectors for word representation.
\newblock In \emph{Proceedings of the 2014 conference on empirical methods in
  natural language processing (EMNLP)}, pp.\  1532--1543, 2014.

\bibitem[Peters et~al.(2018)Peters, Neumann, Iyyer, Gardner, Clark, Lee, and
  Zettlemoyer]{peters2018deep}
Peters, M.~E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and
  Zettlemoyer, L.
\newblock Deep contextualized word representations.
\newblock \emph{arXiv preprint arXiv:1802.05365}, 2018.

\bibitem[Qi et~al.(2020)Qi, Su, Song, Cui, Bharti, and
  Sacheti]{qi2020imagebert}
Qi, D., Su, L., Song, J., Cui, E., Bharti, T., and Sacheti, A.
\newblock Imagebert: Cross-modal pre-training with large-scale weak-supervised
  image-text data.
\newblock \emph{arXiv preprint arXiv:2001.07966}, 2020.

\bibitem[Quattoni et~al.(2007)Quattoni, Collins, and
  Darrell]{quattoni2007learning}
Quattoni, A., Collins, M., and Darrell, T.
\newblock Learning visual representations using images with captions.
\newblock In \emph{2007 IEEE Conference on Computer Vision and Pattern
  Recognition}, pp.\  1--8. IEEE, 2007.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, and
  Sutskever]{radford2018improving}
Radford, A., Narasimhan, K., Salimans, T., and Sutskever, I.
\newblock Improving language understanding by generative pre-training, 2018.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{radford2019language}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.

\bibitem[Raffel et~al.(2019)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu]{raffel2019exploring}
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou,
  Y., Li, W., and Liu, P.~J.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock \emph{arXiv preprint arXiv:1910.10683}, 2019.

\bibitem[Raji et~al.(2020)Raji, Gebru, Mitchell, Buolamwini, Lee, and
  Denton]{2001.00964}
Raji, I.~D., Gebru, T., Mitchell, M., Buolamwini, J., Lee, J., and Denton, E.
\newblock Saving face: Investigating the ethical concerns of facial recognition
  auditing, 2020.

\bibitem[Ramanathan et~al.(2013)Ramanathan, Liang, and
  Fei-Fei]{ramanathan2013video}
Ramanathan, V., Liang, P., and Fei-Fei, L.
\newblock Video event understanding using natural language descriptions.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  905--912, 2013.

\bibitem[Rashtchian et~al.(2010)Rashtchian, Young, Hodosh, and
  Hockenmaier]{rashtchian2010collecting}
Rashtchian, C., Young, P., Hodosh, M., and Hockenmaier, J.
\newblock Collecting image annotations using amazon’s mechanical turk.
\newblock In \emph{Proceedings of the NAACL HLT 2010 Workshop on Creating
  Speech and Language Data with Amazon’s Mechanical Turk}, pp.\  139--147,
  2010.

\bibitem[Recht et~al.(2019)Recht, Roelofs, Schmidt, and
  Shankar]{recht2019imagenet}
Recht, B., Roelofs, R., Schmidt, L., and Shankar, V.
\newblock Do imagenet classifiers generalize to imagenet?
\newblock \emph{arXiv preprint arXiv:1902.10811}, 2019.

\bibitem[Salimans \& Kingma(2016)Salimans and Kingma]{salimans2016weight}
Salimans, T. and Kingma, D.~P.
\newblock Weight normalization: A simple reparameterization to accelerate
  training of deep neural networks.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  901--909, 2016.

\bibitem[Scheuerman et~al.(2019)Scheuerman, Paul, and
  Brubaker]{scheuerman2019computers}
Scheuerman, M.~K., Paul, J.~M., and Brubaker, J.~R.
\newblock How computers see gender: An evaluation of gender classification in
  commercial facial analysis services.
\newblock \emph{Proceedings of the ACM on Human-Computer Interaction},
  3\penalty0 (CSCW):\penalty0 1--33, 2019.

\bibitem[Schwemmer et~al.(2020)Schwemmer, Knight, Bello-Pardo, Oklobdzija,
  Schoonvelde, and Lockhart]{schwemmer2020diagnosing}
Schwemmer, C., Knight, C., Bello-Pardo, E.~D., Oklobdzija, S., Schoonvelde, M.,
  and Lockhart, J.~W.
\newblock Diagnosing gender bias in image recognition systems.
\newblock \emph{Socius}, 6:\penalty0 2378023120967171, 2020.

\bibitem[Sennrich et~al.(2015)Sennrich, Haddow, and Birch]{sennrich2015neural}
Sennrich, R., Haddow, B., and Birch, A.
\newblock Neural machine translation of rare words with subword units.
\newblock \emph{arXiv preprint arXiv:1508.07909}, 2015.

\bibitem[Shankar et~al.(2019)Shankar, Dave, Roelofs, Ramanan, Recht, and
  Schmidt]{shankar2019image}
Shankar, V., Dave, A., Roelofs, R., Ramanan, D., Recht, B., and Schmidt, L.
\newblock Do image classifiers generalize across time?
\newblock \emph{arXiv preprint arXiv:1906.02168}, 2019.

\bibitem[Sharma et~al.(2018)Sharma, Ding, Goodman, and
  Soricut]{sharma2018conceptual}
Sharma, P., Ding, N., Goodman, S., and Soricut, R.
\newblock Conceptual captions: A cleaned, hypernymed, image alt-text dataset
  for automatic image captioning.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  2556--2565,
  2018.

\bibitem[Singh et~al.(2019)Singh, Natarajan, Shah, Jiang, Chen, Batra, Parikh,
  and Rohrbach]{singh2019towards}
Singh, A., Natarajan, V., Shah, M., Jiang, Y., Chen, X., Batra, D., Parikh, D.,
  and Rohrbach, M.
\newblock Towards vqa models that can read.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  8317--8326, 2019.

\bibitem[Socher \& Fei-Fei(2010)Socher and Fei-Fei]{socher2010connecting}
Socher, R. and Fei-Fei, L.
\newblock Connecting modalities: Semi-supervised segmentation and annotation of
  images using unaligned text corpora.
\newblock In \emph{2010 IEEE Computer Society Conference on Computer Vision and
  Pattern Recognition}, pp.\  966--973. IEEE, 2010.

\bibitem[Socher et~al.(2013)Socher, Perelygin, Wu, Chuang, Manning, Ng, and
  Potts]{socher2013recursive}
Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C.~D., Ng, A.~Y., and
  Potts, C.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock In \emph{Proceedings of the 2013 conference on empirical methods in
  natural language processing}, pp.\  1631--1642, 2013.

\bibitem[Socher et~al.(2014)Socher, Karpathy, Le, Manning, and
  Ng]{socher2014grounded}
Socher, R., Karpathy, A., Le, Q.~V., Manning, C.~D., and Ng, A.~Y.
\newblock Grounded compositional semantics for finding and describing images
  with sentences.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  2:\penalty0 207--218, 2014.

\bibitem[Sohn(2016)]{sohn2016improved}
Sohn, K.
\newblock Improved deep metric learning with multi-class n-pair loss objective.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1857--1865, 2016.

\bibitem[Solaiman et~al.(2019)Solaiman, Brundage, Clark, Askell, Herbert-Voss,
  Wu, Radford, Krueger, Kim, Kreps, McCain, Newhouse, Blazakis, McGuffie, and
  Wang]{1908.09203}
Solaiman, I., Brundage, M., Clark, J., Askell, A., Herbert-Voss, A., Wu, J.,
  Radford, A., Krueger, G., Kim, J.~W., Kreps, S., McCain, M., Newhouse, A.,
  Blazakis, J., McGuffie, K., and Wang, J.
\newblock Release strategies and the social impacts of language models, 2019.

\bibitem[Soomro et~al.(2012)Soomro, Zamir, and Shah]{soomro2012ucf101}
Soomro, K., Zamir, A.~R., and Shah, M.
\newblock Ucf101: A dataset of 101 human actions classes from videos in the
  wild.
\newblock \emph{arXiv preprint arXiv:1212.0402}, 2012.

\bibitem[Speer(2019)]{speer-2019-ftfy}
Speer, R.
\newblock ftfy.
\newblock Zenodo, 2019.
\newblock URL \url{https://doi.org/10.5281/zenodo.2591652}.
\newblock Version 5.5.

\bibitem[Srivastava \& Salakhutdinov(2012)Srivastava and
  Salakhutdinov]{srivastava2012multimodal}
Srivastava, N. and Salakhutdinov, R.
\newblock Multimodal learning with deep boltzmann machines.
\newblock In \emph{NIPS}, 2012.

\bibitem[Srivastava et~al.(2017)Srivastava, Labutov, and
  Mitchell]{srivastava2017joint}
Srivastava, S., Labutov, I., and Mitchell, T.
\newblock Joint concept learning and semantic parsing from natural language
  explanations.
\newblock In \emph{Proceedings of the 2017 conference on empirical methods in
  natural language processing}, pp.\  1527--1536, 2017.

\bibitem[Stallkamp et~al.(2011)Stallkamp, Schlipsing, Salmen, and
  Igel]{GTSRB2011}
Stallkamp, J., Schlipsing, M., Salmen, J., and Igel, C.
\newblock The {G}erman {T}raffic {S}ign {R}ecognition {B}enchmark: A
  multi-class classification competition.
\newblock In \emph{IEEE International Joint Conference on Neural Networks},
  pp.\  1453--1460, 2011.

\bibitem[Stroud et~al.(2020)Stroud, Ross, Sun, Deng, Sukthankar, and
  Schmid]{stroud2020learning}
Stroud, J.~C., Ross, D.~A., Sun, C., Deng, J., Sukthankar, R., and Schmid, C.
\newblock Learning video representations from textual web supervision.
\newblock \emph{arXiv preprint arXiv:2007.14937}, 2020.

\bibitem[Szegedy et~al.(2016)Szegedy, Ioffe, Vanhoucke, and
  Alemi]{szegedy2016inception}
Szegedy, C., Ioffe, S., Vanhoucke, V., and Alemi, A.
\newblock Inception-v4, inception-resnet and the impact of residual connections
  on learning.
\newblock \emph{arXiv preprint arXiv:1602.07261}, 2016.

\bibitem[Tan \& Bansal(2019)Tan and Bansal]{tan2019lxmert}
Tan, H. and Bansal, M.
\newblock Lxmert: Learning cross-modality encoder representations from
  transformers.
\newblock \emph{arXiv preprint arXiv:1908.07490}, 2019.

\bibitem[Tan \& Le(2019)Tan and Le]{tan2019efficientnet}
Tan, M. and Le, Q.~V.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock \emph{arXiv preprint arXiv:1905.11946}, 2019.

\bibitem[Taori et~al.(2020)Taori, Dave, Shankar, Carlini, Recht, and
  Schmidt]{taori2020measuring}
Taori, R., Dave, A., Shankar, V., Carlini, N., Recht, B., and Schmidt, L.
\newblock Measuring robustness to natural distribution shifts in image
  classification.
\newblock \emph{arXiv preprint arXiv:2007.00644}, 2020.

\bibitem[Thomee et~al.(2016)Thomee, Shamma, Friedland, Elizalde, Ni, Poland,
  Borth, and Li]{thomee2016yfcc100m}
Thomee, B., Shamma, D.~A., Friedland, G., Elizalde, B., Ni, K., Poland, D.,
  Borth, D., and Li, L.-J.
\newblock Yfcc100m: The new data in multimedia research.
\newblock \emph{Communications of the ACM}, 59\penalty0 (2):\penalty0 64--73,
  2016.

\bibitem[Tian et~al.(2019)Tian, Krishnan, and Isola]{tian2019contrastive}
Tian, Y., Krishnan, D., and Isola, P.
\newblock Contrastive multiview coding.
\newblock \emph{arXiv preprint arXiv:1906.05849}, 2019.

\bibitem[Tian et~al.(2020)Tian, Wang, Krishnan, Tenenbaum, and
  Isola]{tian2020rethinking}
Tian, Y., Wang, Y., Krishnan, D., Tenenbaum, J.~B., and Isola, P.
\newblock Rethinking few-shot image classification: a good embedding is all you
  need?
\newblock \emph{arXiv preprint arXiv:2003.11539}, 2020.

\bibitem[Torralba et~al.(2008)Torralba, Fergus, and Freeman]{torralba200880}
Torralba, A., Fergus, R., and Freeman, W.~T.
\newblock 80 million tiny images: A large data set for nonparametric object and
  scene recognition.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 30\penalty0 (11):\penalty0 1958--1970, 2008.

\bibitem[Touvron et~al.(2019)Touvron, Vedaldi, Douze, and
  J{\'e}gou]{touvron2019fixing}
Touvron, H., Vedaldi, A., Douze, M., and J{\'e}gou, H.
\newblock Fixing the train-test resolution discrepancy.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  8252--8262, 2019.

\bibitem[Varadarajan \& Odobez(2009)Varadarajan and
  Odobez]{varadarajan2009topic}
Varadarajan, J. and Odobez, J.-M.
\newblock Topic models for scene analysis and abnormality detection.
\newblock In \emph{2009 IEEE 12th International Conference on Computer Vision
  Workshops, ICCV Workshops}, pp.\  1338--1345. IEEE, 2009.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  5998--6008, 2017.

\bibitem[Veeling et~al.(2018)Veeling, Linmans, Winkens, Cohen, and
  Welling]{veeling2018pcam}
Veeling, B.~S., Linmans, J., Winkens, J., Cohen, T., and Welling, M.
\newblock Rotation equivariant {CNNs} for digital pathology.
\newblock June 2018.

\bibitem[Virtanen et~al.(2020)Virtanen, Gommers, Oliphant, Haberland, Reddy,
  Cournapeau, Burovski, Peterson, Weckesser, Bright, {van der Walt}, Brett,
  Wilson, Millman, Mayorov, Nelson, Jones, Kern, Larson, Carey, Polat, Feng,
  Moore, {VanderPlas}, Laxalde, Perktold, Cimrman, Henriksen, Quintero, Harris,
  Archibald, Ribeiro, Pedregosa, {van Mulbregt}, and {SciPy 1.0
  Contributors}]{2020SciPy-NMeth}
Virtanen, P., Gommers, R., Oliphant, T.~E., Haberland, M., Reddy, T.,
  Cournapeau, D., Burovski, E., Peterson, P., Weckesser, W., Bright, J., {van
  der Walt}, S.~J., Brett, M., Wilson, J., Millman, K.~J., Mayorov, N., Nelson,
  A. R.~J., Jones, E., Kern, R., Larson, E., Carey, C.~J., Polat, {\.I}., Feng,
  Y., Moore, E.~W., {VanderPlas}, J., Laxalde, D., Perktold, J., Cimrman, R.,
  Henriksen, I., Quintero, E.~A., Harris, C.~R., Archibald, A.~M., Ribeiro,
  A.~H., Pedregosa, F., {van Mulbregt}, P., and {SciPy 1.0 Contributors}.
\newblock {{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in
  Python}.
\newblock \emph{Nature Methods}, 17:\penalty0 261--272, 2020.
\newblock \doi{10.1038/s41592-019-0686-2}.

\bibitem[Vo et~al.(2017)Vo, Jacobs, and Hays]{vo2017revisiting}
Vo, N., Jacobs, N., and Hays, J.
\newblock Revisiting im2gps in the deep learning era.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  2621--2630, 2017.

\bibitem[Wang et~al.(2018)Wang, Singh, Michael, Hill, Levy, and
  Bowman]{wang2018glue}
Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., and Bowman, S.~R.
\newblock Glue: A multi-task benchmark and analysis platform for natural
  language understanding.
\newblock \emph{arXiv preprint arXiv:1804.07461}, 2018.

\bibitem[Wang et~al.(2019)Wang, Ge, Lipton, and Xing]{wang2019learning}
Wang, H., Ge, S., Lipton, Z., and Xing, E.~P.
\newblock Learning robust global representations by penalizing local predictive
  power.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  10506--10518, 2019.

\bibitem[Wang et~al.(2020)Wang, Lu, Zhang, Yang, Bai, Xu, He, Wang, and
  Liu]{wang2020all}
Wang, H., Lu, P., Zhang, H., Yang, M., Bai, X., Xu, Y., He, M., Wang, Y., and
  Liu, W.
\newblock All you need is boundary: Toward arbitrary-shaped text spotting.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pp.\  12160--12167, 2020.

\bibitem[Wang et~al.(2009)Wang, Markert, and Everingham]{wang2009learning}
Wang, J., Markert, K., and Everingham, M.
\newblock Learning models for object recognition from natural language
  descriptions.
\newblock In \emph{BMVC}, volume~1, pp.\ ~2, 2009.

\bibitem[Weston et~al.(2010)Weston, Bengio, and Usunier]{weston2010large}
Weston, J., Bengio, S., and Usunier, N.
\newblock Large scale image annotation: learning to rank with joint word-image
  embeddings.
\newblock \emph{Machine learning}, 81\penalty0 (1):\penalty0 21--35, 2010.

\bibitem[Weston(2016)]{weston2016dialog}
Weston, J.~E.
\newblock Dialog-based language learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  829--837, 2016.

\bibitem[Weyand et~al.(2016)Weyand, Kostrikov, and Philbin]{weyand2016planet}
Weyand, T., Kostrikov, I., and Philbin, J.
\newblock Planet-photo geolocation with convolutional neural networks.
\newblock In \emph{European Conference on Computer Vision}, pp.\  37--55.
  Springer, 2016.

\bibitem[Wu et~al.(2019)Wu, Kirillov, Massa, Lo, and
  Girshick]{wu2019detectron2}
Wu, Y., Kirillov, A., Massa, F., Lo, W.-Y., and Girshick, R.
\newblock Detectron2.
\newblock \url{https://github.com/facebookresearch/detectron2}, 2019.

\bibitem[Wu et~al.(2018)Wu, Xiong, Yu, and Lin]{wu2018unsupervised}
Wu, Z., Xiong, Y., Yu, S., and Lin, D.
\newblock Unsupervised feature learning via non-parametric instance-level
  discrimination.
\newblock \emph{arXiv preprint arXiv:1805.01978}, 2018.

\bibitem[Xie et~al.(2020)Xie, Luong, Hovy, and Le]{xie2020self}
Xie, Q., Luong, M.-T., Hovy, E., and Le, Q.~V.
\newblock Self-training with noisy student improves imagenet classification.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10687--10698, 2020.

\bibitem[y~Arcas et~al.(2017)y~Arcas, Mitchell, and Todorov]{Arcas2017}
y~Arcas, B.~A., Mitchell, M., and Todorov, A.
\newblock Physiognomy’s new clothes.
\newblock 2017.
\newblock URL
  \url{https://medium.com/@blaisea/physiognomys-new-clothes-f2d4b59fdd6a}.

\bibitem[Yang et~al.(2020)Yang, Lu, Wang, Yin, Florencio, Wang, Zhang, Zhang,
  and Luo]{yang2020tap}
Yang, Z., Lu, Y., Wang, J., Yin, X., Florencio, D., Wang, L., Zhang, C., Zhang,
  L., and Luo, J.
\newblock Tap: Text-aware pre-training for text-vqa and text-caption.
\newblock \emph{arXiv preprint arXiv:2012.04638}, 2020.

\bibitem[Yogatama et~al.(2019)Yogatama, d'Autume, Connor, Kocisky, Chrzanowski,
  Kong, Lazaridou, Ling, Yu, Dyer, et~al.]{yogatama2019learning}
Yogatama, D., d'Autume, C. d.~M., Connor, J., Kocisky, T., Chrzanowski, M.,
  Kong, L., Lazaridou, A., Ling, W., Yu, L., Dyer, C., et~al.
\newblock Learning and evaluating general linguistic intelligence.
\newblock \emph{arXiv preprint arXiv:1901.11373}, 2019.

\bibitem[Young et~al.(2014)Young, Lai, Hodosh, and Hockenmaier]{young2014image}
Young, P., Lai, A., Hodosh, M., and Hockenmaier, J.
\newblock From image descriptions to visual denotations: New similarity metrics
  for semantic inference over event descriptions.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  2:\penalty0 67--78, 2014.

\bibitem[Yu et~al.(2020)Yu, Tang, Yin, Sun, Tian, Wu, and Wang]{yu2020ernie}
Yu, F., Tang, J., Yin, W., Sun, Y., Tian, H., Wu, H., and Wang, H.
\newblock Ernie-vil: Knowledge enhanced vision-language representations through
  scene graph.
\newblock \emph{arXiv preprint arXiv:2006.16934}, 2020.

\bibitem[Zeiler \& Fergus(2014)Zeiler and Fergus]{zeiler2014visualizing}
Zeiler, M.~D. and Fergus, R.
\newblock Visualizing and understanding convolutional networks.
\newblock In \emph{European conference on computer vision}, pp.\  818--833.
  Springer, 2014.

\bibitem[Zhai et~al.(2019)Zhai, Puigcerver, Kolesnikov, Ruyssen, Riquelme,
  Lucic, Djolonga, Pinto, Neumann, Dosovitskiy, et~al.]{zhai2019large}
Zhai, X., Puigcerver, J., Kolesnikov, A., Ruyssen, P., Riquelme, C., Lucic, M.,
  Djolonga, J., Pinto, A.~S., Neumann, M., Dosovitskiy, A., et~al.
\newblock A large-scale study of representation learning with the visual task
  adaptation benchmark.
\newblock \emph{arXiv preprint arXiv:1910.04867}, 2019.

\bibitem[Zhang(2019)]{zhang2019making}
Zhang, R.
\newblock Making convolutional networks shift-invariant again.
\newblock \emph{arXiv preprint arXiv:1904.11486}, 2019.

\bibitem[Zhang et~al.(2020)Zhang, Jiang, Miura, Manning, and
  Langlotz]{zhang2020contrastive}
Zhang, Y., Jiang, H., Miura, Y., Manning, C.~D., and Langlotz, C.~P.
\newblock Contrastive learning of medical visual representations from paired
  images and text.
\newblock \emph{arXiv preprint arXiv:2010.00747}, 2020.

\bibitem[Zuboff(2015)]{zuboff2015big}
Zuboff, S.
\newblock Big other: surveillance capitalism and the prospects of an
  information civilization.
\newblock \emph{Journal of Information Technology}, 30\penalty0 (1):\penalty0
  75--89, 2015.

\end{thebibliography}
