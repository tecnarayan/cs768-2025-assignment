\begin{thebibliography}{59}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Belghazi et~al.(2018)Belghazi, Baratin, Rajeswar, Ozair, Bengio,
  Courville, and Hjelm]{belghazi2018entropy}
Mohamed~Ishmael Belghazi, Aristide Baratin, Sai Rajeswar, Sherjil Ozair, Yoshua
  Bengio, Aaron Courville, and R~Devon Hjelm.
\newblock Mine: Mutual information neural estimation.
\newblock \emph{arXiv preprint arXiv:1801.04062}, 2018.

\bibitem[Brantley et~al.(2020)Brantley, Sun, and
  Henaff]{brantley2020disagreement}
Kiante Brantley, Wen Sun, and Mikael Henaff.
\newblock Disagreement-regularized imitation learning.
\newblock 2020.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Wojciech]{brockman2017openaigym}
Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman,
  Jie Tang, and Zaremba Wojciech.
\newblock Openai gym.
\newblock \emph{arXiv preprint arXiv:1606.01540}, 2016.

\bibitem[Brown(1951)]{brown1951fictitious}
George Brown.
\newblock Iterative solution of games by fictitious play.
\newblock \emph{Activity Analysis of Production and Allocation}, 1951.

\bibitem[Burda et~al.(2018)Burda, Edwards, Storkey, and Klimov]{burda2018rnd}
Yuri Burda, Harrison Edwards, Amos Storkey, and Oleg Klimov.
\newblock Exploration by random network distillation.
\newblock \emph{arXiv preprint arXiv:1810.12894}, 2018.

\bibitem[Dieng et~al.(2019)Dieng, Ruiz, Blei, and Titsias]{dieng2019prescribed}
Adji Dieng, Francisco Ruiz, David~M. Blei, and Michalis~K. Titsias.
\newblock Prescribed generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1910.04302}, 2019.

\bibitem[Dinh et~al.(2014)Dinh, Krueger, and Bengio]{dinh2014nice}
L~Dinh, D~Krueger, and Y~Bengio.
\newblock {NICE}: Non-linear independent components estimation.
\newblock \emph{arXiv preprint arXiv:1410.8516}, 2014.

\bibitem[Dinh et~al.(2016)Dinh, Sohl-Dickstein, and Bengio]{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real {NVP}.
\newblock \emph{arXiv preprint arXiv:1605.08803}, May 2016.

\bibitem[Du and Mordatch(2018)]{du2018ebm}
Yilun Du and Igor Mordatch.
\newblock Implicit generation and generalization in energy-based models.
\newblock \emph{arXiv preprint arXiv:1903.08689}, 2018.

\bibitem[Du and Mordatch(2019)]{du2019implicit}
Yilun Du and Igor Mordatch.
\newblock Implicit generation and generalization in energy-based models.
\newblock \emph{arXiv preprint arXiv:1903.08689}, 2019.

\bibitem[Fu et~al.(2017)Fu, Luo, and Levine]{fu2017learning}
Justin Fu, Katie Luo, and Sergey Levine.
\newblock Learning robust rewards with adversarial inverse reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1710.11248}, 2017.

\bibitem[Gao et~al.(2019)Gao, Nijkamp, Kingma, Xu, Dai, and Wu]{gao2019flow}
Ruiqi Gao, Erik Nijkamp, Diederik~P Kingma, Zhen Xu, Andrew~M Dai, and
  Ying~Nian Wu.
\newblock Flow contrastive estimation of energy-based models.
\newblock \emph{arXiv preprint arXiv:1912.00589}, 2019.

\bibitem[Germain et~al.(2015)Germain, Gregor, Murray, and
  Larochelle]{germain2015made}
Mathieu Germain, Karol Gregor, Iain Murray, and Hugo Larochelle.
\newblock Made: Masked autoencoder for distribution estimation.
\newblock \emph{arXiv preprint arXiv:1502.03509}, 2015.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pages
  2672--2680, 2014.

\bibitem[Guo et~al.(2014)Guo, Singh, Lee, Lewis, and Wang]{guo2014ataridagger}
Xiaoxiao Guo, Satinder Singh, Honglak Lee, Richard~L. Lewis, and Xiaoshi Wang.
\newblock Deep learning for real-time atari game play using offline monte-carlo
  tree search planning.
\newblock \emph{Advances in Neural Information Processing Systems 27 (NIPS
  2014)}, 2014.

\bibitem[Gutmann and Hyv{\"a}rinen(2010)]{gutmann2010noise}
Michael Gutmann and Aapo Hyv{\"a}rinen.
\newblock Noise-contrastive estimation: A new estimation principle for
  unnormalized statistical models.
\newblock In \emph{Proceedings of the Thirteenth International Conference on
  Artificial Intelligence and Statistics}, pages 297--304, 2010.

\bibitem[Haarnoja et~al.(2017)Haarnoja, Tang, Abbeel, and
  Levine]{haarnoja2017reinforcement}
Tuomas Haarnoja, Haoran Tang, Pieter Abbeel, and Sergey Levine.
\newblock Reinforcement learning with deep energy-based policies.
\newblock \emph{arXiv preprint arXiv:1702.08165}, 2017.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and
  Levine]{haarnoja2018soft}
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.
\newblock Soft {Actor-Critic}: {Off-Policy} maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock \emph{arXiv preprint arXiv:1801.01290}, January 2018.

\bibitem[Hazan et~al.(2019)Hazan, Kakade, Singh, and Soest]{hazan2019maxent}
Elad Hazan, Sham Kakade, Karan Singh, and Abby~Van Soest.
\newblock Provably efficient maximum entropy exploration.
\newblock \emph{arXiv preprint arXiv:1812.02690}, 2019.

\bibitem[Hill et~al.(2018)Hill, Raffin, Ernestus, Gleave, Kanervisto, Traore,
  Dhariwal, Hesse, Klimov, Nichol, Plappert, Radford, Schulman, Sidor, and
  Wu]{stable-baselines}
Ashley Hill, Antonin Raffin, Maximilian Ernestus, Adam Gleave, Anssi
  Kanervisto, Rene Traore, Prafulla Dhariwal, Christopher Hesse, Oleg Klimov,
  Alex Nichol, Matthias Plappert, Alec Radford, John Schulman, Szymon Sidor,
  and Yuhuai Wu.
\newblock Stable baselines.
\newblock \url{https://github.com/hill-a/stable-baselines}, 2018.

\bibitem[Ho and Ermon(2016)]{ho2016generative}
Jonathan Ho and Stefano Ermon.
\newblock Generative adversarial imitation learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4565--4573, 2016.

\bibitem[Huszár(2017)]{huszar2017implicit}
Ferenc Huszár.
\newblock Variational inference using implicit distributions.
\newblock \emph{arXiv preprint arXiv:1702.08235}, 2017.

\bibitem[Hyv{\"a}rinen(2005)]{hyvarinen2005estimation}
Aapo Hyv{\"a}rinen.
\newblock Estimation of {Non-Normalized} statistical models by score matching.
\newblock \emph{Journal of machine learning research: JMLR}, 6\penalty0
  (Apr):\penalty0 695--709, 2005.
\newblock ISSN 1532-4435, 1533-7928.

\bibitem[Islam et~al.(2019)Islam, Seraj, Bacon, and Precup]{islam2019maxent}
Riashat Islam, Raihan Seraj, Pierre-Luc Bacon, and Doina Precup.
\newblock Entropy regularization with discounted future state distribution in
  policy gradient methods.
\newblock \emph{arXiv preprint arXiv:1912.05104}, 2019.

\bibitem[Jin et~al.(2019)Jin, Netrapalli, and Jordan]{jin2019minmax}
Chi Jin, Praneeth Netrapalli, and Michael~I. Jordan.
\newblock What is local optimality in nonconvex-nonconcave minimax
  optimization?
\newblock \emph{arXiv preprint arXiv:1902.00618}, 2019.

\bibitem[Ke et~al.(2020)Ke, Barnes, Sun, Lee, Choudhury, and
  Srinivasa]{ke2019divergenceimitation}
Liyiming Ke, Matt Barnes, Wen Sun, Gilwoo Lee, Sanjiban Choudhury, and
  Siddhartha Srinivasa.
\newblock Imitation learning as f-divergence minimization.
\newblock \emph{arXiv preprint arXiv:1905.12888}, 2020.

\bibitem[Kim and Park(2018)]{kim2018mmdgail}
Kee-Eung Kim and Hyun~Soo Park.
\newblock Imitation learning via kernel mean embedding.
\newblock \emph{AAAI}, 2018.

\bibitem[Kim et~al.(2019)Kim, Gu, Song, Zhao, and Ermon]{kim2019cross}
Kuno Kim, Yihong Gu, Jiaming Song, Shengjia Zhao, and Stefano Ermon.
\newblock Domain adaptive imitation learning.
\newblock \emph{arXiv preprint arXiv:1910.00105}, 2019.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, December 2014.

\bibitem[Kingma and Dhariwal(2018)]{kingma2018glow}
Durk~P Kingma and Prafulla Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  10215--10224, 2018.

\bibitem[Kostrikov et~al.(2020)Kostrikov, Nachum, and
  Tompson]{kostrikov2020valuedice}
Ilya Kostrikov, Ofir Nachum, and Jonathan Tompson.
\newblock Imitation learning via off-policy distribution matching.
\newblock 2020.

\bibitem[Lee et~al.(2019)Lee, Eysenbach, Parisotto, Xing, Levine, and
  Salakhutdinov]{lee2019marginal}
Lisa Lee, Benjamin Eysenbach, Emilio Parisotto, Eric Xing, Sergey Levine, and
  Ruslan Salakhutdinov.
\newblock Efficient exploration via state marginal matching.
\newblock \emph{arXiv preprint arXiv:1906.05274}, 2019.

\bibitem[Liu et~al.(2007)Liu, Lafferty, and Wasserman]{liu2007nonparametric}
Han Liu, John Lafferty, and Larry Wasserman.
\newblock Sparse nonparametric density estimation in high dimensions using the
  rodeo.
\newblock volume~2 of \emph{Proceedings of Machine Learning Research}, pages
  283--290, San Juan, Puerto Rico, 21--24 Mar 2007. PMLR.

\bibitem[Miyato et~al.(2018)Miyato, Kataoka, Koyama, and
  Yoshida]{miyato2018spectral}
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida.
\newblock Spectral normalization for generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1802.05957}, 2018.

\bibitem[Mohamed and Lakshminarayanan(2016)]{mohamed2016implicit}
Shakir Mohamed and Balaji Lakshminarayanan.
\newblock Learning in implicit generative models.
\newblock \emph{arXiv preprint arXiv:1610.03483}, 2016.

\bibitem[Nguyen et~al.(2010)Nguyen, Wainwright, and Jordan]{nguyen2010nwj}
XuanLong Nguyen, Martin~J. Wainwright, and Michael~I. Jordan.
\newblock Estimating divergence functionals and the likelihood ratio by convex
  risk minimization.
\newblock \emph{arXiv preprint arXiv:0809.0853}, 2010.

\bibitem[Nowozin et~al.(2016)Nowozin, Cseke, and Tomioka]{nowozin2016f}
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka.
\newblock {{f-GAN}}: Training generative neural samplers using variational
  divergence minimization.
\newblock \emph{arXiv preprint arXiv:1606.00709}, June 2016.

\bibitem[Papamakarios et~al.(2017)Papamakarios, Pavlakou, and
  Murray]{papamakarios2017maf}
George Papamakarios, Theo Pavlakou, and Iain Murray.
\newblock Masked autoregressive flow for density estimation.
\newblock \emph{arXiv preprint arXiv:1705.07057}, 2017.

\bibitem[Pathak et~al.(2017)Pathak, Agrawal, Efros, and
  Darrell]{pathak2017inverse}
Deepak Pathak, Pulkit Agrawal, Alexei~A Efros, and Trevor Darrell.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock \emph{arXiv preprint arXiv:1705.05363}, 2017.

\bibitem[Pomerleau(1991)]{pomerleau1991efficient}
Dean~A Pomerleau.
\newblock Efficient training of artificial neural networks for autonomous
  navigation.
\newblock \emph{Neural computation}, 3\penalty0 (1):\penalty0 88--97, 1991.
\newblock ISSN 0899-7667.

\bibitem[Reddy et~al.(2017)Reddy, Dragan, and Levine]{reddy2017sqil}
Siddharth Reddy, Anca~D. Dragan, and Sergey Levine.
\newblock Sqil: Imitation learning via reinforcement learning with sparse
  rewards.
\newblock \emph{arXiv preprint arXiv:1905.11108}, 2017.

\bibitem[Ross and Bagnell(2010)]{ross2010efficient}
St{\'e}phane Ross and Drew Bagnell.
\newblock Efficient reductions for imitation learning.
\newblock In \emph{Proceedings of the thirteenth international conference on
  artificial intelligence and statistics}, pages 661--668, 2010.

\bibitem[Ross et~al.(2011{\natexlab{a}})Ross, Gordon, and Bagnell]{ross2011a}
St{\'e}phane Ross, Geoffrey Gordon, and Drew Bagnell.
\newblock A reduction of imitation learning and structured prediction to
  no-regret online learning.
\newblock In \emph{Proceedings of the fourteenth international conference on
  artificial intelligence and statistics}, pages 627--635, 2011{\natexlab{a}}.

\bibitem[Ross et~al.(2011{\natexlab{b}})Ross, Gordon, and
  Bagnell]{ross2011reduction}
St{\'e}phane Ross, Geoffrey Gordon, and Drew Bagnell.
\newblock A reduction of imitation learning and structured prediction to
  no-regret online learning.
\newblock In \emph{Proceedings of the fourteenth international conference on
  artificial intelligence and statistics}, pages 627--635, 2011{\natexlab{b}}.

\bibitem[Ross et~al.(2013)Ross, Melik-Barkhudarov, Shankar, Wendel, Dey,
  Bagnell, and Hebert]{ross2013uav}
Stephane Ross, Narek Melik-Barkhudarov, Kumar~Shaurya Shankar, Andreas Wendel,
  Debadeepta Dey, Andrew~J. Bagnell, and Martial Hebert.
\newblock Learning monocular reactive uav control in cluttered natural
  environments.
\newblock \emph{International Conference on Robotics and Automation (ICRA)},
  2013.

\bibitem[Salimans et~al.(2016)Salimans, Goodfellow, Zaremba, Cheung, Radford,
  and Chen]{salimans2016gantechniques}
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and
  Xi~Chen.
\newblock Improved techniques for training gans.
\newblock \emph{arXiv:1606.03498}, 2016.

\bibitem[Song et~al.(2018)Song, Ren, Sadigh, and Ermon]{song2018multi}
Jiaming Song, Hongyu Ren, Dorsa Sadigh, and Stefano Ermon.
\newblock Multi-agent generative adversarial imitation learning.
\newblock 2018.

\bibitem[Song and Ermon(2019)]{song2019gradients}
Yang Song and Stefano Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock \emph{arXiv preprint arXiv:1907.05600}, 2019.

\bibitem[Song et~al.(2019)Song, Garg, Shi, and Ermon]{song2019sliced}
Yang Song, Sahaj Garg, Jiaxin Shi, and Stefano Ermon.
\newblock Sliced score matching: A scalable approach to density and score
  estimation.
\newblock \emph{arXiv preprint arXiv:1905.07088}, 2019.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{todorov2012mujoco}
E~Todorov, T~Erez, and Y~Tassa.
\newblock {MuJoCo}: A physics engine for model-based control.
\newblock In \emph{2012 {IEEE/RSJ} International Conference on Intelligent
  Robots and Systems}, pages 5026--5033, October 2012.
\newblock \doi{10.1109/IROS.2012.6386109}.

\bibitem[Todorov(2014)]{todorov2014invertible}
Emanuel Todorov.
\newblock Convex and analytically-invertible dynamics with contacts and
  constraints: Theory and implementation in mujoco.
\newblock \emph{IEEE International Conference on Robotics and Automation
  (ICRA)}, 2014.

\bibitem[Uria et~al.(2013)Uria, Murray, and Larochelle]{uria2013rnade}
Benigno Uria, Iain Murray, and Hugo Larochelle.
\newblock {{RNADE}}: The real-valued neural autoregressive density-estimator.
\newblock In C~J~C Burges, L~Bottou, M~Welling, Z~Ghahramani, and K~Q
  Weinberger, editors, \emph{Advances in Neural Information Processing Systems
  26}, pages 2175--2183. Curran Associates, Inc., 2013.

\bibitem[Uria et~al.(2016)Uria, C{\^o}t{\'e}, Gregor, Murray, and
  Larochelle]{uria2016neural}
Benigno Uria, Marc-Alexandre C{\^o}t{\'e}, Karol Gregor, Iain Murray, and Hugo
  Larochelle.
\newblock Neural autoregressive distribution estimation.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 7184--7220, 2016.

\bibitem[van~den Oord et~al.(2016)van~den Oord, Kalchbrenner, and
  Kavukcuoglu]{oord2016pixel}
Aaron van~den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu.
\newblock Pixel recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1601.06759}, January 2016.

\bibitem[Van Den~Oord et~al.(2018)Van Den~Oord, Li, and Vinyals]{oord2018cpc}
Aaron Van Den~Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Wang et~al.(2019)Wang, Ciliberto, Amadori, and Demiris]{wang2020red}
Ruohan Wang, Carlo Ciliberto, Pierluigi Amadori, and Yiannis Demiris.
\newblock Random expert distillation: Imitation learning via expert policy
  support estimation.
\newblock 2019.

\bibitem[Wang et~al.(2017)Wang, Merel, Reed, Wayne, Freitas, and
  Heess]{wang2017diverse}
Ziyu Wang, Josh Merel, Scott Reed, Greg Wayne, Nando~de Freitas, and Nicolas
  Heess.
\newblock Robust imitation of diverse behaviors.
\newblock \emph{arXiv preprint arXiv:1707.02747}, 2017.

\bibitem[Wu et~al.(2019)Wu, Piergiovanni, and Ryoo]{wu2019futurebc}
Alan Wu, AJ~Piergiovanni, and Michael~S. Ryoo.
\newblock Model-based behavioral cloning with future image similarity learning.
\newblock \emph{arXiv preprint arXiv:1910.03157}, 2019.

\bibitem[Yu et~al.(2020)Yu, Song, Song, and Ermon]{yu2020training}
Lantao Yu, Yang Song, Jiaming Song, and Stefano Ermon.
\newblock Training deep energy-based models with f-divergence minimization.
\newblock \emph{arXiv preprint arXiv:2003.03463}, 2020.

\end{thebibliography}
