\begin{thebibliography}{36}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[glo()]{glop}
The glop linear solver.
\newblock \url{https://developers.google.com/optimization/lp/glop}.

\bibitem[Busoniu et~al.(2008)Busoniu, Babuska, and
  De~Schutter]{busoniu2008comprehensive}
Lucian Busoniu, Robert Babuska, and Bart De~Schutter.
\newblock A comprehensive survey of multiagent reinforcement learning.
\newblock \emph{IEEE Transactions on Systems, Man, And Cybernetics-Part C:
  Applications and Reviews, 38 (2), 2008}, 2008.

\bibitem[Churchill and Buro(2013)]{churchill_portfolio_2013}
David Churchill and Michael Buro.
\newblock Portfolio greedy search and simulation for large-scale combat in
  {StarCraft}.
\newblock In \emph{Computational Intelligence in Games ({CIG}), 2013 {IEEE}
  Conference on}, pages 1--8. {IEEE}, 2013.

\bibitem[Churchill et~al.(2012)Churchill, Saffidine, and
  Buro]{churchill_fast_2012}
David Churchill, Abdallah Saffidine, and Michael Buro.
\newblock Fast heuristic search for {RTS} game combat scenarios.
\newblock In \emph{{AIIDE}}, pages 112--117, 2012.

\bibitem[Churchill et~al.(2017)Churchill, Lin, and
  Synnaeve]{churchill_analysis_2017}
David Churchill, Zeming Lin, and Gabriel Synnaeve.
\newblock An analysis of model-based heuristic search techniques for
  {StarCraft} combat scenarios.
\newblock {AAAI} Publications, Thirteenth Artificial Intelligence and
  Interactive â€¦, 2017.

\bibitem[Diuk et~al.(2008)Diuk, Cohen, and Littman]{diuk2008object}
Carlos Diuk, Andre Cohen, and Michael~L Littman.
\newblock An object-oriented representation for efficient reinforcement
  learning.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, pages 240--247. ACM, 2008.

\bibitem[Foerster et~al.(2016)Foerster, Assael, de~Freitas, and
  Whiteson]{foerster_learning_2016}
Jakob Foerster, Ioannis~Alexandros Assael, Nando de~Freitas, and Shimon
  Whiteson.
\newblock Learning to communicate with deep multi-agent reinforcement learning.
\newblock In D.~D. Lee, M.~Sugiyama, U.~V. Luxburg, I.~Guyon, and R.~Garnett,
  editors, \emph{Advances in Neural Information Processing Systems 29}, pages
  2137--2145. Curran Associates, Inc., 2016.

\bibitem[Foerster et~al.(2018)Foerster, Farquhar, Afouras, Nardelli, and
  Whiteson]{foerster2018counterfactual}
Jakob~N Foerster, Gregory Farquhar, Triantafyllos Afouras, Nantas Nardelli, and
  Shimon Whiteson.
\newblock Counterfactual multi-agent policy gradients.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Frank and Wolfe(1956)]{frank1956algorithm}
Marguerite Frank and Philip Wolfe.
\newblock An algorithm for quadratic programming.
\newblock \emph{Naval Research Logistics (NRL)}, 3\penalty0 (1-2):\penalty0
  95--110, 1956.

\bibitem[Gleixner et~al.(2017)Gleixner, Eifler, Gally, Gamrath, Gemander,
  Gottwald, Hendel, Hojny, Koch, Miltenberger, M{\"u}ller, Pfetsch, Puchert,
  Rehfeldt, Schl{\"o}sser, Serrano, Shinano, Viernickel, Vigerske, Weninger,
  Witt, and Witzig]{GleixnerEiflerGallyetal.2017}
Ambros Gleixner, Leon Eifler, Tristan Gally, Gerald Gamrath, Patrick Gemander,
  Robert~Lion Gottwald, Gregor Hendel, Christopher Hojny, Thorsten Koch,
  Matthias Miltenberger, Benjamin M{\"u}ller, Marc~E. Pfetsch, Christian
  Puchert, Daniel Rehfeldt, Franziska Schl{\"o}sser, Felipe Serrano, Yuji
  Shinano, Jan~Merlin Viernickel, Stefan Vigerske, Dieter Weninger, Jonas~T.
  Witt, and Jakob Witzig.
\newblock The scip optimization suite 5.0.
\newblock Technical Report 17-61, ZIB, Takustr. 7, 14195 Berlin, 2017.

\bibitem[Guestrin et~al.(2002)Guestrin, Lagoudakis, and
  Parr]{guestrin_coordinated_2002}
Carlos Guestrin, Michail Lagoudakis, and Ronald Parr.
\newblock Coordinated reinforcement learning.
\newblock In \emph{{ICML}}, volume~2, pages 227--234, 2002.

\bibitem[Guestrin et~al.(2003)Guestrin, Koller, Gearhart, and
  Kanodia]{guestrin2003generalizing}
Carlos Guestrin, Daphne Koller, Chris Gearhart, and Neal Kanodia.
\newblock Generalizing plans to new environments in relational mdps.
\newblock In \emph{Proceedings of the 18th International Joint Conference on
  Artificial Intelligence}, IJCAI'03, pages 1003--1010, San Francisco, CA, USA,
  2003. Morgan Kaufmann Publishers Inc.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Jiang and Lu(2018)]{NIPS2018_7956}
Jiechuan Jiang and Zongqing Lu.
\newblock Learning attentional communication for multi-agent cooperation.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, \emph{Advances in Neural Information Processing
  Systems 31}, pages 7265--7275. Curran Associates, Inc., 2018.

\bibitem[Jiang et~al.(2018)Jiang, del Amo, and Lu]{Jiang2018GraphCR}
Jiechuan Jiang, I{\~n}igo~Fern{\'a}ndez del Amo, and Zongqing Lu.
\newblock Graph convolutional reinforcement learning for multi-agent
  cooperation.
\newblock \emph{CoRR}, abs/1810.09202, 2018.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Lillicrap et~al.()Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap_continuous_2015}
Timothy~P. Lillicrap, Jonathan~J. Hunt, Alexander Pritzel, Nicolas Heess, Tom
  Erez, Yuval Tassa, David Silver, and Daan Wierstra.
\newblock Continuous control with deep reinforcement learning.

\bibitem[Lin et~al.(2018)Lin, Zhao, Xu, and Zhou]{lin18}
Kaixiang Lin, Renyu Zhao, Zhe Xu, and Jiayu Zhou.
\newblock Efficient large-scale fleet management via multi-agent deep
  reinforcement learning.
\newblock In \emph{Proceedings of the 24th ACM SIGKDD International Conference
  on Knowledge Discovery \&\#38; Data Mining}, KDD '18, pages 1774--1783, New
  York, NY, USA, 2018. ACM.
\newblock ISBN 978-1-4503-5552-0.
\newblock \doi{10.1145/3219819.3219993}.

\bibitem[Lowe et~al.(2017)Lowe, WU, Tamar, Harb, Pieter~Abbeel, and
  Mordatch]{NIPS2017_7217}
Ryan Lowe, YI~WU, Aviv Tamar, Jean Harb, OpenAI Pieter~Abbeel, and Igor
  Mordatch.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock In I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems 30}, pages 6379--6390. Curran Associates,
  Inc., 2017.

\bibitem[Meuleau et~al.(1998)Meuleau, Hauskrecht, Kim, Peshkin, Kaelbling,
  Dean, and Boutilier]{meuleau1998solving}
Nicolas Meuleau, Milos Hauskrecht, Kee-Eung Kim, Leonid Peshkin, Leslie~Pack
  Kaelbling, Thomas Dean, and Craig Boutilier.
\newblock Solving very large weakly coupled {Markov} decision processes.
\newblock pages 165--172, 1998.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{mnih2016asynchronous}
Volodymyr Mnih, Adria~Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy
  Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  1928--1937, 2016.

\bibitem[Ontan{\'o}n et~al.(2013)Ontan{\'o}n, Synnaeve, Uriarte, Richoux,
  Churchill, and Preuss]{ontanon2013survey}
Santiago Ontan{\'o}n, Gabriel Synnaeve, Alberto Uriarte, Florian Richoux, David
  Churchill, and Mike Preuss.
\newblock A survey of real-time strategy game ai research and competition in
  starcraft.
\newblock \emph{IEEE Transactions on Computational Intelligence and AI in
  games}, 5\penalty0 (4):\penalty0 293--311, 2013.

\bibitem[Proper and Tadepalli(2009)]{proper2009solving}
Scott Proper and Prasad Tadepalli.
\newblock Solving {Multiagent} {Assignment} {Markov} {Decision} {Processes}.
\newblock In \emph{Proceedings of {The} 8th {International} {Conference} on
  {Autonomous} {Agents} and {Multiagent} {Systems} - {Volume} 1}, {AAMAS} '09,
  pages 681--688, Richland, SC, 2009. International Foundation for Autonomous
  Agents and Multiagent Systems.
\newblock ISBN 978-0-9817381-6-1.

\bibitem[Rashid et~al.(2018)Rashid, Samvelyan, de~Witt, Farquhar, Foerster, and
  Whiteson]{rashid2018qmix}
Tabish Rashid, Mikayel Samvelyan, Christian~Schroeder de~Witt, Gregory
  Farquhar, Jakob Foerster, and Shimon Whiteson.
\newblock Qmix: Monotonic value function factorisation for deep multi-agent
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1803.11485}, 2018.

\bibitem[Sanner and Boutilier(2012)]{sanner2012practical}
Scott Sanner and Craig Boutilier.
\newblock Practical linear value-approximation techniques for first-order mdps.
\newblock \emph{arXiv preprint arXiv:1206.6879}, 2012.

\bibitem[Singh et~al.(2019)Singh, Jain, and
  Sukhbaatar]{singh_individualized_2019}
Amanpreet Singh, Tushar Jain, and Sainbayar Sukhbaatar.
\newblock Individualized controlled continuous communication model for
  multiagent cooperative and competitive tasks.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Singh and Cohn(1998)]{singh_how_1998}
Satinder~P. Singh and David Cohn.
\newblock How to dynamically merge {Markov} decision processes.
\newblock In \emph{Advances in neural information processing systems}, pages
  1057--1063, 1998.

\bibitem[Sukhbaatar et~al.(2016)Sukhbaatar, Fergus,
  et~al.]{sukhbaatar2016learning}
Sainbayar Sukhbaatar, Rob Fergus, et~al.
\newblock Learning multiagent communication with backpropagation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2244--2252, 2016.

\bibitem[Sutton and Barto(2018)]{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Tesauro(2005)]{tesauro_online_2005}
Gerald Tesauro.
\newblock Online resource allocation using decompositional reinforcement
  learning.
\newblock In \emph{{AAAI}}, volume~5, pages 886--891, 2005.

\bibitem[Tian et~al.(2017)Tian, Gong, Shang, Wu, and Zitnick]{tian2017elf}
Yuandong Tian, Qucheng Gong, Wenling Shang, Yuxin Wu, and C.~Lawrence Zitnick.
\newblock Elf: An extensive, lightweight and flexible research platform for
  real-time strategy games.
\newblock \emph{Advances in Neural Information Processing Systems (NIPS)},
  2017.

\bibitem[Usunier et~al.(2016)Usunier, Synnaeve, Lin, and
  Chintala]{usunier2016episodic}
Nicolas Usunier, Gabriel Synnaeve, Zeming Lin, and Soumith Chintala.
\newblock Episodic exploration for deep deterministic policies: An application
  to starcraft micromanagement tasks.
\newblock \emph{arXiv preprint arXiv:1609.02993}, 2016.

\bibitem[Wang et~al.(2018)Wang, Girshick, Gupta, and He]{wang2018non}
Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He.
\newblock Non-local neural networks.
\newblock In \emph{The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2018.

\bibitem[Wawrzynski(2015)]{wawrzynski2015control}
Pawel Wawrzynski.
\newblock Control policy with autocorrelated noise in reinforcement learning
  for robotics.
\newblock \emph{International Journal of Machine Learning and Computing},
  5\penalty0 (2):\penalty0 91, 2015.

\bibitem[Yang et~al.(2018)Yang, Luo, Li, Zhou, Zhang, and Wang]{yang2018mean}
Yaodong Yang, Rui Luo, Minne Li, Ming Zhou, Weinan Zhang, and Jun Wang.
\newblock Mean field multi-agent reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1802.05438}, 2018.

\bibitem[Zambaldi et~al.(2018)Zambaldi, Raposo, Santoro, Bapst, Li, Babuschkin,
  Tuyls, Reichert, Lillicrap, Lockhart, et~al.]{zambaldi2018relational}
Vinicius Zambaldi, David Raposo, Adam Santoro, Victor Bapst, Yujia Li, Igor
  Babuschkin, Karl Tuyls, David Reichert, Timothy Lillicrap, Edward Lockhart,
  et~al.
\newblock Relational deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1806.01830}, 2018.

\end{thebibliography}
