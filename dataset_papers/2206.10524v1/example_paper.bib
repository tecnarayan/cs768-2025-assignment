@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@misc{fujimoto2019offpolicy,
      title={Off-Policy Deep Reinforcement Learning without Exploration}, 
      author={Scott Fujimoto and David Meger and Doina Precup},
      year={2019},
      eprint={1812.02900},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@InProceedings{laroche2019safe,
  title = 	 {Safe Policy Improvement with Baseline Bootstrapping},
  author =       {Laroche, Romain and Trichelair, Paul and Combes, Remi Tachet Des},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {3652--3661},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/laroche19a/laroche19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/laroche19a.html},
  abstract = 	 {This paper considers Safe Policy Improvement (SPI) in Batch Reinforcement Learning (Batch RL): from a fixed dataset and without direct access to the true environment, train a policy that is guaranteed to perform at least as well as the baseline policy used to collect the data. 	 Our approach, called SPI with Baseline Bootstrapping (SPIBB), is inspired by the knows-what-it-knows paradigm: it bootstraps the trained policy with the baseline when the uncertainty is high. 	 Our first algorithm, $\Pi_b$-SPIBB, comes with SPI theoretical guarantees. 	 We also implement a variant, $\Pi_{\leq b}$-SPIBB, that is even more efficient in practice. 	 We apply our algorithms to a motivational stochastic gridworld domain and further demonstrate on randomly generated MDPs the superiority of SPIBB with respect to existing algorithms, not only in safety but also in mean performance. 	 Finally, we implement a model-free version of SPIBB and show its benefits on a navigation task with deep RL implementation called SPIBB-DQN, which is, to the best of our knowledge, the first RL algorithm relying on a neural network representation able to train efficiently and reliably from batch data, without any interaction with the environment.}
}

@inproceedings{mcallister2019robustness,
  title={Robustness to out-of-distribution inputs via task-aware generative uncertainty},
  author={McAllister, Rowan and Kahn, Gregory and Clune, Jeff and Levine, Sergey},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={2083--2089},
  year={2019},
  organization={IEEE}
}

@article{richter2017safe,
  title={Safe visual navigation via deep learning and novelty detection},
  author={Richter, Charles and Roy, Nicholas},
  journal={RSS 2017},
  year={2017},
  publisher={Robotics: Science and Systems Foundation}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@misc{kumar2019stabilizing,
      title={Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction}, 
      author={Aviral Kumar and Justin Fu and George Tucker and Sergey Levine},
      year={2019},
      eprint={1906.00949},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{dean2020guaranteeing,
      title={Guaranteeing Safety of Learned Perception Modules via Measurement-Robust Control Barrier Functions}, 
      author={Sarah Dean and Andrew J. Taylor and Ryan K. Cosner and Benjamin Recht and Aaron D. Ames},
      year={2020},
      eprint={2010.16001},
      archivePrefix={arXiv},
      primaryClass={eess.SY}
}

@article{kidambi2020morel,
  title={Morel: Model-based offline reinforcement learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={arXiv preprint arXiv:2005.05951},
  year={2020}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}

@article{Deisenroth2015,
   title={Gaussian Processes for Data-Efficient Learning in Robotics and Control},
   volume={37},
   ISSN={2160-9292},
   url={http://dx.doi.org/10.1109/TPAMI.2013.218},
   DOI={10.1109/tpami.2013.218},
   number={2},
   journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Deisenroth, Marc Peter and Fox, Dieter and Rasmussen, Carl Edward},
   year={2015},
   month={Feb},
   pages={408–423}
}

@misc{chua2018deep,
      title={Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models}, 
      author={Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey Levine},
      year={2018},
      eprint={1805.12114},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{tassa2012,
  author={Tassa, Yuval and Erez, Tom and Todorov, Emanuel},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Synthesis and stabilization of complex behaviors through online trajectory optimization}, 
  year={2012},
  volume={},
  number={},
  pages={4906-4913},
  doi={10.1109/IROS.2012.6386025}}


@inproceedings{berkenkamp2017safe,
  title={Safe Model-based Reinforcement Learning with Stability Guarantees},
  author={Felix Berkenkamp and Matteo Turchetta and Angela P. Schoellig and Andreas Krause},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{fu2021drl,
title={D4{\{}RL{\}}: Datasets for Deep Data-Driven Reinforcement Learning},
author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
  booktitle={CoRR},
  year={2020}
}

@inproceedings{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@article{durkan2019neural,
  title={Neural spline flows},
  author={Durkan, Conor and Bekasov, Artur and Murray, Iain and Papamakarios, George},
  journal={Advances in Neural Information Processing Systems},
  year={2019}
}

@article{brunke2021safe,
  title={Safe learning in robotics: From learning-based control to safe reinforcement learning},
  author={Brunke, Lukas and Greeff, Melissa and Hall, Adam W and Yuan, Zhaocong and Zhou, Siqi and Panerati, Jacopo and Schoellig, Angela P},
  journal={arXiv preprint arXiv:2108.06266},
  year={2021}
}

@inproceedings{antos2007fqi,
 author = {Antos, Andr\'{a}s and Szepesv\'{a}ri, Csaba and Munos, R\'{e}mi},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Platt and D. Koller and Y. Singer and S. Roweis},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Fitted Q-iteration in continuous action-space MDPs},
 url = {https://proceedings.neurips.cc/paper/2007/file/da0d1111d2dc5d489242e60ebcbaf988-Paper.pdf},
 volume = {20},
 year = {2008}
}

@misc{hsu2014random,
      title={Random design analysis of ridge regression}, 
      author={Daniel Hsu and Sham M. Kakade and Tong Zhang},
      year={2014},
      eprint={1106.2363},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}

@misc{rltheorybook,
      title={Reinforcement Learning: Theory and Algorithms},
      author={Alekh Agarwal and Nan Jiang and Sham M. Kakade and Wen Sun},
      year={2021},
      url={https://rltheorybook.github.io/rltheorybook_AJKS.pdf}
}

@misc{kalashnikov2018qtopt,
      title={QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation}, 
      author={Dmitry Kalashnikov and Alex Irpan and Peter Pastor and Julian Ibarz and Alexander Herzog and Eric Jang and Deirdre Quillen and Ethan Holly and Mrinal Kalakrishnan and Vincent Vanhoucke and Sergey Levine},
      year={2018},
      eprint={1806.10293},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{codevilla2018endtoend,
      title={End-to-end Driving via Conditional Imitation Learning}, 
      author={Felipe Codevilla and Matthias Müller and Antonio López and Vladlen Koltun and Alexey Dosovitskiy},
      year={2018},
      eprint={1710.02410},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@book{SastryShankar1999Ns,
series = {Interdisciplinary applied mathematics ; v. 10},
publisher = {Springer},
booktitle = {Nonlinear systems : analysis, stability, and control},
isbn = {0387985131},
year = {1999},
title = {Nonlinear systems : analysis, stability, and control / Shankar Sastry.},
language = {eng},
address = {New York},
author = {Sastry, Shankar},
keywords = {Nonlinear systems; System analysis},
lccn = {99011798},
}

@article{SONTAG1989117,
title = {A ‘universal’ construction of Artstein's theorem on nonlinear stabilization},
journal = {Systems \& Control Letters},
volume = {13},
number = {2},
pages = {117-123},
year = {1989},
issn = {0167-6911},
author = {Eduardo D. Sontag},
keywords = {Smooth stabilization, Artstein's theorem},
abstract = {This note presents an explicit proof of the theorem - due to Artstein - which states that the existence of a smooth control-Lyapunov function implies smooth stabilizability. Moreover, the result is extended to the real-analytic and rational cases as well. The proof uses a ‘universal’ formula given by an algebraic function of Lie derivatives; this formula originates in the solution of a simple Riccati equation.}
}

@article{ames2017cbf,
  title={Control Barrier Function Based Quadratic Programs for Safety Critical Systems},
  author={A. Ames and X. Xu and J. Grizzle and P. Tabuada},
  journal={IEEE Transactions on Automatic Control},
  year={2017},
  volume={62},
  pages={3861-3876}
}

@article{Bansal2017,
  title={Hamilton-Jacobi reachability: A brief overview and recent advances},
  author={Somil Bansal and M. Chen and Sylvia L. Herbert and C. Tomlin},
  journal={2017 IEEE 56th Annual Conference on Decision and Control (CDC)},
  year={2017},
  pages={2242-2253}
}
@article{hinton2002training,
  title={Training products of experts by minimizing contrastive divergence},
  author={Hinton, Geoffrey E},
  journal={Neural computation},
  volume={14},
  number={8},
  pages={1771--1800},
  year={2002},
  publisher={MIT Press}
}

@article{Camilli2008,
author = {Camilli, Fabio and Grüne, Lars and Wirth, Fabian},
title = {Control Lyapunov Functions and Zubov's Method},
journal = {SIAM Journal on Control and Optimization},
volume = {47},
number = {1},
pages = {301-326},
year = {2008}
}

@article{ames2014rapidly,
  title={Rapidly exponentially stabilizing control lyapunov functions and hybrid zero dynamics},
  author={Ames, Aaron D and Galloway, Kevin and Sreenath, Koushil and Grizzle, Jessy W},
  journal={IEEE Transactions on Automatic Control},
  volume={59},
  number={4},
  pages={876--891},
  year={2014},
}

@book{murray2017mathematical,
  title={A mathematical introduction to robotic manipulation},
  author={Murray, Richard M and Li, Zexiang and Sastry, S Shankar},
  year={2017},
  publisher={CRC press}
}

@book{borrelli2017predictive,
  title={Predictive control for linear and hybrid systems},
  author={Borrelli, Francesco and Bemporad, Alberto and Morari, Manfred},
  year={2017},
  publisher={Cambridge University Press}
}

@conference{li2021rlbipedal,
author={ Zhongyu Li and Xuxin Cheng and Xue Bin Peng and Pieter Abbeel and Sergey Levine and Glen Berseth and Koushil Sreenath },
title={ Reinforcement Learning for Robust Parameterized Locomotion Control of Bipedal Robots },
booktitle={ IEEE International Conference on Robotics and Automation (ICRA) },
month={ June },
year={ 2021 }
}

@article{akkaya2019solving,
  title={Solving rubik's cube with a robot hand},
  author={Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and others},
  journal={arXiv preprint arXiv:1910.07113},
  year={2019}
}

@article{dai2021lyapunov,
  title={Lyapunov-stable neural-network control},
  author={Dai, Hongkai and Landry, Benoit and Yang, Lujie and Pavone, Marco and Tedrake, Russ},
  journal={arXiv preprint arXiv:2109.14152},
  year={2021}
}

@inproceedings{cheng2019end,
  title={End-to-end safe reinforcement learning through barrier functions for safety-critical continuous control tasks},
  author={Cheng, Richard and Orosz, G{\'a}bor and Murray, Richard M and Burdick, Joel W},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2019}
}

@misc{haarnoja2018soft,
      title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor}, 
      author={Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine},
      year={2018},
      eprint={1801.01290},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{openai,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@INPROCEEDINGS{SzepesvariFPI,
  author={Antos, Andras and Szepesvari, Csaba and Munos, Remi},
  booktitle={2007 IEEE International Symposium on Approximate Dynamic Programming and Reinforcement Learning}, 
  title={Value-Iteration Based Fitted Policy Iteration: Learning with a Single Trajectory}, 
  year={2007},
  volume={},
  number={},
  pages={330-337},
  doi={10.1109/ADPRL.2007.368207}}
  
@misc{simglucose,
    Author = {Jinyu Xie},
    Title = {Simglucose v0.2.1},
    Year = {2018},
    url={https://github.com/jxx123/simglucose},
}

@article{bharadhwaj2021conservative,
  title={Conservative Safety Critics for Exploration},
  author={Homanga Bharadhwaj and Aviral Kumar and Nicholas Rhinehart and Sergey Levine and F. Shkurti and Animesh Garg},
  journal={ArXiv},
  year={2020},
  volume={abs/2010.14497}
}

@inproceedings{codevilla2018end,
  title={End-to-end driving via conditional imitation learning},
  author={Codevilla, Felipe and M{\"u}ller, Matthias and L{\'o}pez, Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4693--4700},
  year={2018},
  organization={IEEE}
}

@article{thananjeyan2020safety,
  title={Safety Augmented Value Estimation From Demonstrations (SAVED): Safe Deep Model-Based RL for Sparse Cost Robotic Tasks},
  author={Brijen Thananjeyan and A. Balakrishna and Ugo Rosolia and Felix Li and Rowan McAllister and J. Gonzalez and Sergey Levine and F. Borrelli and Ken Goldberg},
  journal={IEEE Robotics and Automation Letters},
  year={2020},
  volume={5},
  pages={3612-3619}
}


@inproceedings{achiam2017constrained,
  title={Constrained Policy Optimization},
  author={Joshua Achiam and David Held and Aviv Tamar and P. Abbeel},
  booktitle={ICML},
  year={2017}
}

@article{bojarski2016end,
  title={End to End Learning for Self-Driving Cars},
  author={Mariusz Bojarski and D. Testa and Daniel Dworakowski and Bernhard Firner and Beat Flepp and Prasoon Goyal and L. Jackel and Mathew Monfort and Urs Muller and Jiakai Zhang and X. Zhang and Jake Zhao and Karol Zieba},
  journal={ArXiv},
  year={2016},
  volume={abs/1604.07316}
}
@inproceedings{ross2011reduction,
  title={A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning},
  author={St{\'e}phane Ross and Geoffrey J. Gordon and J. Bagnell},
  booktitle={AISTATS},
  year={2011}
}

@inproceedings{ziebart2010irl,
  title={Modeling Interaction via the Principle of Maximum Causal Entropy},
  author={Brian D. Ziebart and J. Bagnell and A. Dey},
  booktitle={ICML},
  year={2010}
}

@inproceedings{ho2016generative,
  title={Generative Adversarial Imitation Learning},
  author={Jonathan Ho and S. Ermon},
  booktitle={NIPS},
  year={2016}
}

  
@inproceedings{Nagumo1942berDL,
  title={{\"U}ber die Lage der Integralkurven gew{\"o}hnlicher Differentialgleichungen},
  author={Mitio Nagumo},
  year={1942}
}


@article{Herbert2017,
  title={FaSTrack: A modular framework for fast and guaranteed safe motion planning},
  author={Sylvia L. Herbert and M. Chen and S. Han and Somil Bansal and Jaime F. Fisac and C. Tomlin},
  journal={2017 IEEE 56th Annual Conference on Decision and Control (CDC)},
  year={2017},
  pages={1517-1522}
}

@article{Kumar2020cql,
  title={Conservative Q-Learning for Offline Reinforcement Learning},
  author={Aviral Kumar and Aurick Zhou and G. Tucker and Sergey Levine},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.04779}
}

@article{nair2021awac,
  title={Accelerating Online Reinforcement Learning with Offline Datasets},
  author={Ashvin Nair and Murtaza Dalal and Abhishek Gupta and Sergey Levine},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.09359}
}

@article{kidambi2021morel,
  title={MOReL : Model-Based Offline Reinforcement Learning},
  author={R. Kidambi and A. Rajeswaran and Praneeth Netrapalli and T. Joachims},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.05951}
}


@article{du2020implicit,
  title={Implicit Generation and Generalization in Energy-Based Models},
  author={Yilun Du and Igor Mordatch},
  journal={ArXiv},
  year={2019},
  volume={abs/1903.08689}
}

@inproceedings{grathwohl2020learning,
  title={Learning the Stein Discrepancy for Training and Evaluating Energy-Based Models without Sampling},
  author={Will Grathwohl and Kuan-Chieh Wang and J. Jacobsen and D. Duvenaud and R. Zemel},
  booktitle={ICML},
  year={2020}
}


@article{Carreira-Perpinan2005,
author = {Carreira-Perpi{\~{n}}{\'{a}}n, Miguel {\'{A}} and Hinton, Geoffrey E.},
isbn = {097273581X},
journal = {AISTATS 2005 - Proceedings of the 10th International Workshop on Artificial Intelligence and Statistics},
pages = {33--40},
title = {{On contrastive divergence learning}},
volume = {0},
year = {2005}
}


@article{Lygeros,
  title={On reachability and minimum cost optimal control},
  author={J. Lygeros},
  journal={Autom.},
  year={2004},
  volume={40},
  pages={917-927}
}


@article{mehrjou2020learning,
  title={Learning Dynamical Systems using Local Stability Priors},
  author={Mehrjou, Arash and Iannelli, Andrea and Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:2008.10053},
  year={2020}
}

@article{chang2020neural,
  title={Neural Lyapunov Control},
  author={Ya-Chien Chang and Nima Roohi and Sicun Gao},
  journal={ArXiv},
  year={2019},
  volume={abs/2005.00611}
}


@inproceedings{richards2018lyapunov,
  title={The lyapunov neural network: Adaptive stability certification for safe learning of dynamical systems},
  author={Richards, Spencer M and Berkenkamp, Felix and Krause, Andreas},
  booktitle={Conference on Robot Learning},
  pages={466--476},
  year={2018},
  organization={PMLR}
}

@article{mittal2020neural,
  title={Neural lyapunov model predictive control},
  author={Mittal, Mayank and Gallieri, Marco and Quaglino, Alessio and Salehian, Seyed Sina Mirrazavi and Koutn{\'\i}k, Jan},
  journal={arXiv preprint arXiv:2002.10451},
  year={2020}
}

@book{bacciotti1992local,
  title={Local stabilizability of nonlinear control systems},
  author={Bacciotti, Andrea},
  year={1992},
  publisher={World Scientific}
}

@article{primbs1999nonlinear,
  title={Nonlinear optimal control: A control Lyapunov function and receding horizon perspective},
  author={Primbs, James A and Nevisti{\'c}, Vesna and Doyle, John C},
  journal={Asian Journal of Control},
  volume={1},
  number={1},
  pages={14--24},
  year={1999},
  publisher={Wiley Online Library}
}

@article{grandia2020nonlinear,
  title={Nonlinear model predictive control of robotic systems with control lyapunov functions},
  author={Grandia, Ruben and Taylor, Andrew J and Singletary, Andrew and Hutter, Marco and Ames, Aaron D},
  journal={arXiv preprint arXiv:2006.01229},
  year={2020}
}


@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}


@INPROCEEDINGS{choi2020reinforcement, 
    AUTHOR    = {Jason Choi AND Fernando Castañeda AND Claire Tomlin AND Koushil Sreenath}, 
    TITLE     = {{Reinforcement Learning for Safety-Critical Control under Model Uncertainty, using Control Lyapunov Functions and Control Barrier Functions}}, 
    BOOKTITLE = {Robotics: Science and Systems}, 
    YEAR      = {2020}, 
    ADDRESS   = {Corvalis, OR}, 
}

@INPROCEEDINGS{taylor2019clflearning,
  author={A. J. {Taylor} and V. D. {Dorobantu} and H. M. {Le} and Y. {Yue} and A. D. {Ames}},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Episodic Learning with Control Lyapunov Functions for Uncertain Robotic Systems}, 
  year={2019},
  volume={},
  number={},
  pages={6878-6884},}
  
@ARTICLE{fisac2019safelearning,
  author={J. F. {Fisac} and A. K. {Akametalu} and M. N. {Zeilinger} and S. {Kaynama} and J. {Gillula} and C. J. {Tomlin}},
  journal={IEEE Transactions on Automatic Control}, 
  title={A general safety framework for learning-based control in uncertain robotic systems}, 
  year={2019},
  volume={64},
  number={7},
  pages={2737-2752},}
  
@inproceedings{chow2018lyapunov,
author = {Chow, Yinlam and Nachum, Ofir and Duenez-Guzman, Edgar and Ghavamzadeh, Mohammad},
title = {A Lyapunov-Based Approach to Safe Reinforcement Learning},
year = {2018},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {8103–8112},
numpages = {10},
series = {NIPS'18}
}



@inproceedings{ross2010efficient,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={661--668},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}


@INPROCEEDINGS{robey2020learningcbf,
  author={Robey, Alexander and Hu, Haimin and Lindemann, Lars and Zhang, Hanwen and Dimarogonas, Dimos V. and Tu, Stephen and Matni, Nikolai},
  booktitle={2020 59th IEEE Conference on Decision and Control (CDC)}, 
  title={Learning Control Barrier Functions from Expert Demonstrations}, 
  year={2020},
  volume={},
  number={},
  pages={3717-3724},}
  
@INPROCEEDINGS{fisac2019bridging,
  author={Fisac, Jaime F. and Lugovoy, Neil F. and Rubies-Royo, Vicenç and Ghosh, Shromona and Tomlin, Claire J.},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)}, 
  title={Bridging Hamilton-Jacobi Safety Analysis and Reinforcement Learning}, 
  year={2019},
  volume={},
  number={},
  pages={8550-8556},}
  
@article{alshiekh2018shielding,
title={Safe Reinforcement Learning via Shielding}, volume={32},
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Alshiekh, Mohammed and Bloem, Roderick and Ehlers, Rüdiger and Könighofer, Bettina and Niekum, Scott and Topcu, Ufuk}, year={2018}, month={Apr.} 
}

@ARTICLE{shao2021reachability,
  author={Shao, Yifei Simon and Chen, Chao and Kousik, Shreyas and Vasudevan, Ram},
  journal={IEEE Robotics and Automation Letters}, 
  title={Reachability-Based Trajectory Safeguard (RTS): A Safe and Fast Reinforcement Learning Safety Layer for Continuous Control}, 
  year={2021},
  volume={6},
  number={2},
  pages={3663-3670},}

@inproceedings{alshiekh2018safe,
  title={Safe reinforcement learning via shielding},
  author={Alshiekh, Mohammed and Bloem, Roderick and Ehlers, R{\"u}diger and K{\"o}nighofer, Bettina and Niekum, Scott and Topcu, Ufuk},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{perkins2002lyapunov,
  title={Lyapunov design for safe reinforcement learning},
  author={Perkins, Theodore J and Barto, Andrew G},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Dec},
  pages={803--832},
  year={2002}
}


@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={30},
  number={1},
  year={2016}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{tu2022sample,
  title={On the sample complexity of stability constrained imitation learning},
  author={Tu, Stephen and Robey, Alexander and Zhang, Tingnan and Matni, Nikolai},
  booktitle={Learning for Dynamics and Control Conference},
  year={2022},
  organization={PMLR}
}
