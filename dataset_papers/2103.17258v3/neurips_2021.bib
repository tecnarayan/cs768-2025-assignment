
@inproceedings{Nachum2017urex,
  author = {Nachum, Ofir and Norouzi, Mohammad and Schuurmans, Dale},
  title = {{Improving policy gradient by exploring under-appreciated rewards}},
  booktitle = {International Conference on Learning Representations},
  year = {2017},
}

@inproceedings{Abdolmaleki2018mpo,
  author = {Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  title = {{Maximum a posteriori policy optimisation}},
  booktitle = {International Conference on Learning Representations},
  year = {2018},
}

@inproceedings{ghasemipour2020divergence,
  title={A divergence minimization perspective on imitation learning methods},
  author={Ghasemipour, Seyed Kamyar Seyed and Zemel, Richard and Gu, Shixiang},
  booktitle={Conference on Robot Learning},
  year={2020},
}

@article{wu2018variance,
  title={Variance reduction for policy gradient with action-dependent factorized baselines},
  author={Wu, Cathy and Rajeswaran, Aravind and Duan, Yan and Kumar, Vikash and Bayen, Alexandre M and Kakade, Sham and Mordatch, Igor and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1803.07246},
  year={2018}
}

@inproceedings{toussaint2006probabilistic,
  title={Probabilistic inference for solving discrete and continuous state Markov Decision Processes},
  author={Toussaint, Marc and Storkey, Amos},
  booktitle={International conference on Machine learning},
  year={2006}
}

@article{grathwohl2017backpropagation,
  title={Backpropagation through the void: Optimizing control variates for black-box gradient estimation},
  author={Grathwohl, Will and Choi, Dami and Wu, Yuhuai and Roeder, Geoffrey and Duvenaud, David},
  journal={arXiv preprint arXiv:1711.00123},
  year={2017}
}

@article{liu2017action,
  title={Action-depedent Control Variates for Policy Optimization via Stein's Identity},
  author={Liu, Hao and Feng, Yihao and Mao, Yi and Zhou, Dengyong and Peng, Jian and Liu, Qiang},
  journal={arXiv preprint arXiv:1710.11198},
  year={2017}
}

@article{liu2016stein,
  title={Stein variational gradient descent: A general purpose bayesian inference algorithm},
  author={Liu, Qiang and Wang, Dilin},
  journal={arXiv preprint arXiv:1608.04471},
  year={2016}
}

@inproceedings{todorov2006linearly,
  title={Linearly-solvable Markov decision problems},
  author={Todorov, Emanuel},
  booktitle={Advances in Neural Information Processing Systems},
  year={2006}
}

@inproceedings{jaques2017sequence,
  title={Sequence tutor: Conservative fine-tuning of sequence generation models with kl-control},
  author={Jaques, Natasha and Gu, Shixiang and Bahdanau, Dzmitry and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Turner, Richard E and Eck, Douglas},
  booktitle={International Conference on Machine Learning},
  year={2017},
}

@inproceedings{Norouzi2016raml,
  author = {Norouzi, Mohammad and Bengio, Samy and Chen, Zhifeng and Jaitly, Navdeep and Schuster, Mike and Wu, Yonghui and Schuurmans, Dale},
  title = {{Reward augmented maximum likelihood for neural structured prediction}},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2016},
}

@inproceedings{Haarnoja:2018uya,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  year={2018}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement Learning with Deep Energy-Based Policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  year={2017}
}

@inproceedings{nachum2017pcl,
    title={Bridging the Gap Between Value and Policy Based Reinforcement Learning},
    author={Ofir Nachum and Mohammad Norouzi and Kelvin Xu and Dale Schuurmans},
    booktitle = {Advances in Neural Information Processing Systems},
    year={2017},
}

@article{Schulman2017PPO,
  title={Proximal Policy Optimization Algorithms},
  author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017},
}

@inproceedings{Schulman:2015uk,
  author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael and Abbeel, Pieter},
  title = {Trust region policy optimization},
  booktitle = {International Conference on Machine Learning},
  year = {2015},
}

@inproceedings{gu2016continuous,
  title={Continuous deep q-learning with model-based acceleration},
  author={Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  year={2016}
}

@inproceedings{Lillicrap2016,
  author={Timothy P. Lillicrap and
               Jonathan J. Hunt and
               Alexander Pritzel and
               Nicolas Heess and
               Tom Erez and
               Yuval Tassa and
               David Silver and
               Daan Wierstra},
  title={Continuous control with deep reinforcement learning},
  booktitle={International Conference on Learning Representations},
  year={2016},
}

@inproceedings{gu2016qprop,
    title={{Q-Prop}: Sample-Efficient Policy Gradient with An Off-Policy Critic},
    author={Shixiang Gu and Timothy Lillicrap and Zoubin Ghahramani and Richard E. Turner and Sergey Levine},
    year={2017},
    booktitle={International Conference on Learning Representations},
}

@inproceedings{fujimoto2018td3,
  title={Addressing Function Approximation Error in Actor-Critic Methods},
  author={Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle={International Conference on Machine Learning},
  year={2018},
}

@inproceedings{gu2017interpolated,
    title={Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning},
    author={Shixiang Gu and Timothy Lillicrap and Zoubin Ghahramani and Richard E. Turner and Bernhard Schölkopf and Sergey Levine},
    year={2017},
    booktitle={Advances in Neural Information Processing Systems},
}

@inproceedings{nachum2017trustpcl,
    title={Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
    author={Ofir Nachum and Mohammad Norouzi and Kelvin Xu and Dale Schuurmans},
    year={2017},
    booktitle={International Conference on Learning Representations},
}

@inproceedings{schulman2016gae,
    title={High-Dimensional Continuous Control Using Generalized Advantage Estimation},
    author={John Schulman and Philipp Moritz and Sergey Levine and Michael Jordan and Pieter Abbeel},
    booktitle = {International Conference on Learning Representations},
    year={2016}
}

@article{epg-journal,
   author = {Ciosek, Kamil and Whiteson, Shimon},
   title = {Expected Policy Gradients for Reinforcement Learning},
   journal = {Journal of Machine Learning Research},
   year = {2020},
 }
 
@inproceedings{Munos2016SafeAE,
  title={Safe and Efficient Off-Policy Reinforcement Learning},
  author={R{\'e}mi Munos and Tom Stepleton and Anna Harutyunyan and Marc G. Bellemare},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{wang2016acer,
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Rémi and Kavukcuoglu, Koray and de Freitas, Nando},
  title={Sample Efficient Actor-Critic with Experience Replay.},
  year={2016},
  booktitle={International Conference on Learning Representations},
}

@inproceedings{espeholt2018impala,
    title={IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures},
    author={Lasse Espeholt and Hubert Soyer and Remi Munos and Karen Simonyan and Volodymir Mnih and Tom Ward and Yotam Doron and Vlad Firoiu and Tim Harley and Iain Dunning and Shane Legg and Koray Kavukcuoglu},
    booktitle={International Conference on Machine Learning},
    year={2018},
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@inproceedings{hasselt2010double,
    title = {Double Q-learning},
    author = {Hado V. Hasselt},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2010},
}

@inproceedings{hasselt2015deep,
    title={Deep Reinforcement Learning with Double Q-learning},
    author={Hado van Hasselt and Arthur Guez and David Silver},
    year={2015},
    booktitle={AAAI Conference on Artificial Intelligence},
}

@inproceedings{wang2015dueling,
    title={Dueling Network Architectures for Deep Reinforcement Learning},
    author={Ziyu Wang and Tom Schaul and Matteo Hessel and Hado van Hasselt and Marc Lanctot and Nando de Freitas},
    year={2016},
    booktitle={International Conference on Machine Learning},
}

@inproceedings{lan2020maxmin,
    title={Maxmin Q-learning: Controlling the Estimation Bias of Q-learning},
    author={Qingfeng Lan and Yangchen Pan and Alona Fyshe and Martha White},
    year={2020},
    booktitle={International Conference on Learning Representations},
}

@article{peng2019awr,
    title={{Advantage-Weighted Regression}: Simple and Scalable Off-Policy Reinforcement Learning},
    author={Xue Bin Peng and Aviral Kumar and Grace Zhang and Sergey Levine},
    year={2019},
    journal={arXiv preprint arXiv:1910.00177},
}

@article{levine2018reinforcement,
    title={{Reinforcement Learning and Control as Probabilistic Inference}: Tutorial and Review},
    author={Sergey Levine},
    year={2018},
    journal={arXiv preprint arXiv:1805.00909},
}

@article{wang2020critic,
    title={Critic Regularized Regression},
    author={Ziyu Wang and Alexander Novikov and Konrad Zolna and Jost Tobias Springenberg and Scott Reed and Bobak Shahriari and Noah Siegel and Josh Merel and Caglar Gulcehre and Nicolas Heess and Nando de Freitas},
    year={2020},
    journal={arXiv preprint arXiv:2006.15134},
}

@inproceedings{Siegel2020KeepDW,
  title={Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning},
  author={Noah Y. Siegel and Jost Tobias Springenberg and Felix Berkenkamp and Abbas Abdolmaleki and Michael Neunert and Thomas Lampe and Roland Hafner and Martin A. Riedmiller},
  booktitle={International Conference on Learning Representations},
  year={2020},
}
@inproceedings {MasashiOkada2019,
 author = {Masashi Okada and Tadahiro Taniguchi},
 title = {Variational Inference MPC for Bayesian Model-based Reinforcement Learning},
 booktitle ={Conference on Robot Learning},
 year = {2019},
}

@article{hoffman2020acme,
    title={Acme: A Research Framework for Distributed Reinforcement Learning},
    author={Matt Hoffman and Bobak Shahriari and John Aslanides and Gabriel
        Barth-Maron and Feryal Behbahani and Tamara Norman and Abbas Abdolmaleki
        and Albin Cassirer and Fan Yang and Kate Baumli and Sarah Henderson and
        Alex Novikov and Sergio Gómez Colmenarejo and Serkan Cabi and Caglar
        Gulcehre and Tom Le Paine and Andrew Cowie and Ziyu Wang and Bilal Piot
        and Nando de Freitas},
    year={2020},
    journal={arXiv preprint arXiv:2006.00979},
}

@article{alex2020importance,
    title={Importance Weighted Policy Learning and Adaption},
    author={Alexandre Galashov and Jakub Sygnowski and Guillaume Desjardins and Jan Humplik and Leonard Hasenclever and Rae Jeong and Yee Whye Teh and Nicolas Heess},
    year={2020},
    journal={arXiv preprint arXiv:2009.04875},
}

@inproceedings{Oh2018SIL,
  title={Self-Imitation Learning},
  author={Junhyuk Oh and Yijie Guo and Satinder Singh and Honglak Lee},
  booktitle={International Conference on Machine Learning},
  year={2018}
}

@inproceedings{song2020vmpo,
    title={V-MPO: On-Policy Maximum a Posteriori Policy Optimization for Discrete and Continuous Control},
    author={H. Francis Song and Abbas Abdolmaleki and Jost Tobias Springenberg and Aidan Clark and Hubert Soyer and Jack W. Rae and Seb Noury and Arun Ahuja and Siqi Liu and Dhruva Tirumala and Nicolas Heess and Dan Belov and Martin Riedmiller and Matthew M. Botvinick},
    year={2020},
    booktitle={International Conference on Learning Representations},
}

@inproceedings{peters2010reps,
    author={Peters, Jan and M\"{u}lling, Katharina and Alt\"{u}n, Yasemin},
    title={Relative Entropy Policy Search},
    year={2010},
    booktitle={AAAI Conference on Artificial Intelligence},
}

@inproceedings{rawlik2012psi,
    author={Rawlik, Konrad and Toussaint, Marc and Vijayakumar, Sethu},
    year={2012},
    title={On Stochastic Optimal Control and Reinforcement Learning by Approximate Inference},
    booktitle={International Joint Conference on Artificial Intelligence},
}

@article{haarnoja2018sacapps,
    title={Soft Actor-Critic Algorithms and Applications},
    author={Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine},
    journal={arXiv preprint arXiv:1812.05905},
    year={2018}
}

@article{hafner2020action,
  title={Action and Perception as Divergence Minimization},
  author={Hafner, Danijar and Ortega, Pedro A and Ba, Jimmy and Parr, Thomas and Friston, Karl and Heess, Nicolas},
  journal={arXiv preprint arXiv:2009.01791},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={International Conference on Intelligent Robots and Systems},
  year={2012},
}

@article{tang2020hindsight,
  title={Hindsight Expectation Maximization for Goal-conditioned Reinforcement Learning},
  author={Tang, Yunhao and Kucukelbir, Alp},
  journal={arXiv preprint arXiv:2006.07549},
  year={2020}
}

@inproceedings{andrychowicz2021what,
    title={What Matters for On-Policy Deep Actor-Critic Methods? A Large-Scale Study},
    author={Marcin Andrychowicz and Anton Raichuk and Piotr Sta{\'n}czyk and Manu Orsini and Sertan Girgin and Rapha{\"e}l Marinier and Leonard Hussenot and Matthieu Geist and Olivier Pietquin and Marcin Michalski and Sylvain Gelly and Olivier Bachem},
    booktitle={International Conference on Learning Representations},
    year={2021},
}

@inproceedings{henderson2017deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{engstrom2019implementation,
  title={Implementation Matters in Deep RL: A Case Study on PPO and TRPO},
  author={Engstrom, Logan and Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Janoos, Firdaus and Rudolph, Larry and Madry, Aleksander},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{duan2016benchmarking,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  year={2016}
}

@article{fujita2019chainerrl,
  author  = {Yasuhiro Fujita and Prabhat Nagarajan and Toshiki Kataoka and Takahiro Ishikawa},
  title   = {ChainerRL: A Deep Reinforcement Learning Library},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
}

@inproceedings{peters2007reinforcement,
  title={Reinforcement learning by reward-weighted regression for operational space control},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  year={2007}
}

@inproceedings{fellows2019virel,
  title={VIREL: A variational inference framework for reinforcement learning},
  author={Fellows, Matthew and Mahajan, Anuj and Rudner, Tim GJ and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

@inproceedings{odonoghue2020making,
      title={Making Sense of Reinforcement Learning and Probabilistic Inference}, 
      author={Brendan O'Donoghue and Ian Osband and Catalin Ionescu},
      year={2020},
      booktitle={International Conference on Learning Representations},
}

@inproceedings{neumann2011variational,
  title={Variational inference for policy search in changing situations},
  author={Neumann, Gerhard and others},
  booktitle={International Conference on Machine Learning},
  year={2011}
}

@article{abdolmaleki2018relative,
      title={Relative Entropy Regularized Policy Iteration}, 
      author={Abbas Abdolmaleki and Jost Tobias Springenberg and Jonas Degrave and Steven Bohez and Yuval Tassa and Dan Belov and Nicolas Heess and Martin Riedmiller},
      year={2018},
      journal={arXiv preprint arXiv:1812.02256},
}

@article{mitchell2020offline,
      title={Offline Meta-Reinforcement Learning with Advantage Weighting}, 
      author={Eric Mitchell and Rafael Rafailov and Xue Bin Peng and Sergey Levine and Chelsea Finn},
      year={2020},
      journal={arXiv preprint arXiv:2008.06043},
}

@article{nair2020accelerating,
      title={Accelerating Online Reinforcement Learning with Offline Datasets}, 
      author={Ashvin Nair and Murtaza Dalal and Abhishek Gupta and Sergey Levine},
      year={2020},
      journal={arXiv preprint arXiv:2006.09359},
}

@inproceedings{todorov2008general,
  title={General duality between optimal control and estimation},
  author={Todorov, Emanuel},
  booktitle={IEEE Conference on Decision and Control},
  year={2008},
}

@inproceedings{fox2015taming,
  title={Taming the noise in reinforcement learning via soft updates},
  author={Fox, Roy and Pakman, Ari and Tishby, Naftali},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  year={2016}
}

@inproceedings{toussaint2009robot,
  title={Robot trajectory optimization using approximate inference},
  author={Toussaint, Marc},
  booktitle={International Conference on Machine Learning},
  year={2009}
}

@inproceedings{ghosh2020operator,
      title={An operator view of policy gradient methods}, 
      author={Dibya Ghosh and Marlos C. Machado and Nicolas Le Roux},
      year={2020},
      booktitle = {Advances in Neural Information Processing Systems},
}

@inproceedings{nachum2016improving,
  title={Improving policy gradient by exploring under-appreciated rewards},
  author={Nachum, Ofir and Norouzi, Mohammad and Schuurmans, Dale},
  booktitle = {International Conference on Learning Representations},
  year={2017}
}

@inproceedings{norouzi2016reward,
  title={Reward augmented maximum likelihood for neural structured prediction},
  author={Norouzi, Mohammad and Bengio, Samy and Jaitly, Navdeep and Schuster, Mike and Wu, Yonghui and Schuurmans, Dale and others},
  booktitle={Advances In Neural Information Processing Systems},
  year={2016}
}

@inproceedings{kober2008power,
  title={Policy search for motor primitives in robotics},
  author={Kober, Jens and Peters, Jan},
  booktitle={Advances in neural information processing systems},
  year={2008}
}

@techreport{minka2005divergence,
  title={Divergence measures and message passing},
  author={Minka, Tom and others},
  year={2005},
  institution={Technical report, Microsoft Research}
}

@article{gym2016openai,
  Author={Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title={OpenAI Gym},
  Year={2016},
  journal={arXiv preprint arXiv:1606.01540},
}

@article{tassa2018deepmind,
    title={DeepMind Control Suite}, 
    author={Yuval Tassa and Yotam Doron and Alistair Muldal and Tom Erez and Yazhe Li and Diego de Las Casas and David Budden and Abbas Abdolmaleki and Josh Merel and Andrew Lefrancq and Timothy Lillicrap and Martin Riedmiller},
    year={2018},
    journal={arXiv preprint arXiv:1801.00690},
}

@InProceedings{tucker18amirage,
    title = {The Mirage of Action-Dependent Baselines in Reinforcement Learning},
    author = {Tucker, George and Bhupatiraju, Surya and Gu, Shixiang and Turner, Richard and Ghahramani, Zoubin and Levine, Sergey},
    booktitle = {International Conference on Machine Learning},
    year={2018}
}

@InProceedings{geist2019rmdp,
  title = {A Theory of Regularized {M}arkov Decision Processes},
  author = {Geist, Matthieu and Scherrer, Bruno and Pietquin, Olivier},
  booktitle = {International Conference on Machine Learning},
  year = {2019},
}

@InProceedings{vieillard2021leverage,
  title={Leverage the Average: an Analysis of KL Regularization in RL}, 
  author={Nino Vieillard and Tadashi Kozuno and Bruno Scherrer and Olivier Pietquin and Rémi Munos and Matthieu Geist},
  year={2021},
  booktitle = {Advances in Neural Information Processing Systems}
}

@inproceedings{lee2020slac,
  title={Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model},
  author={Alex X. Lee and Anusha Nagabandi and Pieter Abbeel and Sergey Levine},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{clevert2016fast,
    title={Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)}, 
    author={Djork-Arné Clevert and Thomas Unterthiner and Sepp Hochreiter},
    year={2016},
    booktitle = {International Conference on Learning Representations},
}

@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

@article{Wu:2019wl,
  author = {Wu, Yifan and Tucker, George and Nachum, Ofir},
  title = {{Behavior Regularized Offline Reinforcement Learning}},
  journal = {arXiv preprint arXiv:1911.11361},
  year = {2019},
}

@article{islam2017reproducibility,
    title={Reproducibility of Benchmarked Deep Reinforcement Learning Tasks for Continuous Control},
    author={Riashat Islam and Peter Henderson and Maziar Gomrokchi and Doina Precup},
    year={2017},
    journal = {arXiv preprint arXiv:1708.04133},
}


@article{wang2019benchmarking,
    title={Benchmarking Model-Based Reinforcement Learning},
    author={Tingwu Wang and Xuchan Bao and Ignasi Clavera and Jerrick Hoang and Yeming Wen and Eric Langlois and Shunshi Zhang and Guodong Zhang and Pieter Abbeel and Jimmy Ba},
    year={2019},
    journal = {arXiv preprint arXiv:1907.02057},
}

@article{bhatt2019crossnorm,
    title={CrossNorm: Normalization for Off-Policy TD Reinforcement Learning},
    author={Aditya Bhatt and Max Argus and Artemij Amiranashvili and Thomas Brox},
    year={2019},
    journal = {arXiv preprint arXiv:1902.05605},
}

@inproceedings{kuznetsov2020tqc,
    title={Controlling Overestimation Bias with Truncated Mixture of Continuous Distributional Quantile Critics}, 
    author={Arsenii Kuznetsov and Pavel Shvechikov and Alexander Grishin and Dmitry Vetrov},
    year={2020},
    booktitle = {International Conference on Machine Learning},
}

@inproceedings{gogianu2021spectral,
      title={Spectral Normalisation for Deep Reinforcement Learning: an Optimisation Perspective}, 
      author={Florin Gogianu and Tudor Berariu and Mihaela Rosca and Claudia Clopath and Lucian Busoniu and Razvan Pascanu},
      year={2021},
      booktitle = {International Conference on Machine Learning},
}

@techreport{baird1993advantage,
  title={Advantage updating},
  author={Baird III, Leemon C},
  year={1993},
  institution={WRIGHT LAB WRIGHT-PATTERSON AFB OH}
}