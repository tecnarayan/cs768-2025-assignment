\begin{thebibliography}{26}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Auer et~al.(2002{\natexlab{a}})Auer, Cesa-Bianchi, and
  Fischer]{AuerCF02}
Peter Auer, Nicol{\`o} Cesa-Bianchi, and Paul Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock \emph{Machine Learning}, 47\penalty0 (2-3):\penalty0 235--256,
  2002{\natexlab{a}}.

\bibitem[Auer et~al.(2002{\natexlab{b}})Auer, Cesa-Bianchi, Freund, and
  Schapire]{AuerCFS02}
Peter Auer, Nicol{\`o} Cesa-Bianchi, Yoav Freund, and Robert~E. Schapire.
\newblock The nonstochastic multiarmed bandit problem.
\newblock \emph{SIAM J. Comput.}, 32\penalty0 (1):\penalty0 48--77,
  2002{\natexlab{b}}.

\bibitem[Berry and Fristedt(1985)]{BF85}
Donald~A. Berry and Bert Fristedt.
\newblock \emph{Bandit problems: {S}equential Allocation of Experiments}.
\newblock Chapman and Hall, 1985.

\bibitem[Bubeck and Cesa{-}Bianchi(2012)]{BCB12}
S{\'{e}}bastien Bubeck and Nicol{\`{o}} Cesa{-}Bianchi.
\newblock Regret analysis of stochastic and nonstochastic multi-armed bandit
  problems.
\newblock \emph{Foundations and TrendsÂ® in Machine Learning}, 5\penalty0
  (1):\penalty0 1--122, 2012.

\bibitem[Chen et~al.(2013)Chen, Lakshmanan, and Castillo]{chen2013information}
Wei Chen, Laks V.~S. Lakshmanan, and Carlos Castillo.
\newblock \emph{Information and Influence Propagation in Social Networks}.
\newblock Morgan \& Claypool Publishers, 2013.

\bibitem[Chen et~al.(2016{\natexlab{a}})Chen, Hu, Li, Li, Liu, and
  Lu]{ChenGeneral16}
Wei Chen, Wei Hu, Fu~Li, Jian Li, Yu~Liu, and Pinyan Lu.
\newblock Combinatorial multi-armed bandit with general reward functions.
\newblock In \emph{NIPS}, 2016{\natexlab{a}}.

\bibitem[Chen et~al.(2016{\natexlab{b}})Chen, Wang, Yuan, and Wang]{CWYW16}
Wei Chen, Yajun Wang, Yang Yuan, and Qinshi Wang.
\newblock Combinatorial multi-armed bandit and its extension to
  probabilistically triggered arms.
\newblock \emph{Journal of Machine Learning Research}, 17\penalty0
  (50):\penalty0 1--33, 2016{\natexlab{b}}.
\newblock A preliminary version appeared as Chen, Wang, and Yuan,
  ``combinatorial multi-armed bandit: General framework, results and
  applications'', ICML'2013.

\bibitem[Combes et~al.(2015)Combes, Talebi, Proutiere, and Lelarge]{Combes2015}
Richard Combes, M.~Sadegh Talebi, Alexandre Proutiere, and Marc Lelarge.
\newblock Combinatorial bandits revisited.
\newblock In \emph{NIPS}, 2015.

\bibitem[Gai et~al.(2012)Gai, Krishnamachari, and Jain]{Yi2012}
Yi~Gai, Bhaskar Krishnamachari, and Rahul Jain.
\newblock Combinatorial network optimization with unknown variables:
  Multi-armed bandits with linear rewards and individual observations.
\newblock \emph{IEEE/ACM Transactions on Networking}, 20, 2012.

\bibitem[Gopalan et~al.(2014)Gopalan, Mannor, and Mansour]{GMM14}
Aditya Gopalan, Shie Mannor, and Yishay Mansour.
\newblock Thompson sampling for complex online problems.
\newblock In \emph{Proceedings of the 31st International Conference on Machine
  Learning (ICML)}, 2014.

\bibitem[Hoeffding(1963)]{hoeffding63}
Wassily Hoeffding.
\newblock Probability inequalities for sums of bounded random variables.
\newblock \emph{Journal of the American Statistical Association}, 58\penalty0
  (301):\penalty0 13--30, 1963.

\bibitem[Kempe et~al.(2003)Kempe, Kleinberg, and Tardos]{kempe03}
David Kempe, Jon~M. Kleinberg, and {\'E}va Tardos.
\newblock Maximizing the spread of influence through a social network.
\newblock In \emph{Proceedings of the 9th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining (KDD)}, pages 137--146, 2003.

\bibitem[Kveton et~al.(2014)Kveton, Wen, Ashkan, Eydgahi, and
  Eriksson]{KWAEE14}
Branislav Kveton, Zheng Wen, Azin Ashkan, Hoda Eydgahi, and Brian Eriksson.
\newblock Matroid bandits: Fast combinatorial optimization with learning.
\newblock In \emph{Proceedings of the 30th Conference on Uncertainty in
  Artificial Intelligence (UAI)}, 2014.

\bibitem[Kveton et~al.(2015{\natexlab{a}})Kveton, Szepesv{\'a}ri, Wen, and
  Ashkan]{kveton2015cascading}
Branislav Kveton, Csaba Szepesv{\'a}ri, Zheng Wen, and Azin Ashkan.
\newblock Cascading bandits: learning to rank in the cascade model.
\newblock In \emph{Proceedings of the 32th International Conference on Machine
  Learning}, 2015{\natexlab{a}}.

\bibitem[Kveton et~al.(2015{\natexlab{b}})Kveton, Wen, Ashkan, and
  Szepesv\'{a}ri]{KWAS15}
Branislav Kveton, Zheng Wen, Azin Ashkan, and Csaba Szepesv\'{a}ri.
\newblock Tight regret bounds for stochastic combinatorial semi-bandits.
\newblock In \emph{Proceedings of the 18th International Conference on
  Artificial Intelligence and Statistics}, 2015{\natexlab{b}}.

\bibitem[Kveton et~al.(2015{\natexlab{c}})Kveton, Wen, Ashkan, and
  Szepesvari]{kveton2015combinatorial}
Branislav Kveton, Zheng Wen, Azin Ashkan, and Csaba Szepesvari.
\newblock Combinatorial cascading bandits.
\newblock \emph{Advances in Neural Information Processing Systems},
  2015{\natexlab{c}}.

\bibitem[Lagr{\'e}e et~al.(2016)Lagr{\'e}e, Vernade, and Capp{\'e}]{Lagree2016}
Paul Lagr{\'e}e, Claire Vernade, and Olivier Capp{\'e}.
\newblock Multiple-play bandits in the position-based model.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1597--1605, 2016.

\bibitem[Lei et~al.(2015)Lei, Maniu, Mo, Cheng, and Senellart]{LeiMMCS15}
Siyu Lei, Silviu Maniu, Luyi Mo, Reynold Cheng, and Pierre Senellart.
\newblock Online influence maximization.
\newblock In \emph{KDD}, 2015.

\bibitem[Mitzenmacher and Upfal(2005)]{MU05}
Michael Mitzenmacher and Eli Upfal.
\newblock \emph{Probability and Computing}.
\newblock Cambridge University Press, 2005.

\bibitem[Robbins(1952)]{Robbins52}
Herbert Robbins.
\newblock Some aspects of the sequential design of experiments.
\newblock \emph{Bulletin American Mathematical Society}, 55:\penalty0 527--535,
  1952.

\bibitem[Sutton and Barto(1998)]{SB98}
Richard~S. Sutton and Andrew~G. Barto.
\newblock \emph{Reinforcement Learning: {A}n Introduction}.
\newblock MIT Press, 1998.

\bibitem[Thompson(1933)]{thompson1933likelihood}
William~R Thompson.
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock \emph{Biometrika}, 25\penalty0 (3/4):\penalty0 285--294, 1933.

\bibitem[Vaswani et~al.(2015)Vaswani, Lakshmanan, and Schmidt]{VaswaniL15}
Sharan Vaswani, Laks V.~S. Lakshmanan, and Mark Schmidt.
\newblock Influence maximization with bandits.
\newblock In \emph{NIPS Workshop on Networks in the Social and Information
  Sciences}, 2015.

\bibitem[Vaswani et~al.(2017)Vaswani, Kveton, Wen, Ghavamzadeh, Lakshmanan, and
  Schmidt]{VKWGLS17}
Sharan Vaswani, Branislav Kveton, Zheng Wen, Mohammad Ghavamzadeh, Laks~V.S.
  Lakshmanan, and Mark Schmidt.
\newblock Diffusion independent semi-bandit influence maximization.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning (ICML)}, 2017.
\newblock to appear.

\bibitem[Wen et~al.(2016)Wen, Kveton, and Valko]{Wen2016}
Zheng Wen, Branislav Kveton, and Michal Valko.
\newblock Influence maximization with semi-bandit feedback.
\newblock \emph{CoRR}, abs/1605.06593v1, 2016.

\bibitem[Yang et~al.(2016)Yang, Mao, Pei, and He]{YangMPH16}
Yu~Yang, Xiangbo Mao, Jian Pei, and Xiaofei He.
\newblock Continuous influence maximization: What discounts should we offer to
  social network users?
\newblock In \emph{Proceedings of the 2016 International Conference on
  Management of Data (SIGMOD)}, 2016.

\end{thebibliography}
