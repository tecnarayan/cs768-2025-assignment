\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agrawal and Goyal(2012)]{TS12}
Shipra Agrawal and Navin Goyal.
\newblock Analysis of {T}hompson sampling for the multi-armed bandit problem.
\newblock In \emph{Conference on Learning Theory}, pages 39--1, 2012.

\bibitem[Ailon et~al.(2014)Ailon, Karnin, and Joachims]{Ailon+14}
Nir Ailon, Zohar~Shay Karnin, and Thorsten Joachims.
\newblock Reducing dueling bandits to cardinal bandits.
\newblock In \emph{ICML}, volume~32, pages 856--864, 2014.

\bibitem[Audibert and Bubeck(2010)]{Audibert+10}
Jean-Yves Audibert and S{\'e}bastien Bubeck.
\newblock Best arm identification in multi-armed bandits.
\newblock In \emph{COLT-23th Conference on Learning Theory-2010}, pages 13--p,
  2010.

\bibitem[Auer et~al.(2002{\natexlab{a}})Auer, Cesa-Bianchi, and
  Fischer]{Auer+02}
Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock \emph{Machine learning}, 47\penalty0 (2-3):\penalty0 235--256,
  2002{\natexlab{a}}.

\bibitem[Auer et~al.(2002{\natexlab{b}})Auer, Cesa-Bianchi, Freund, and
  Schapire]{auer+02N}
Peter Auer, Nicol\'{o} Cesa-Bianchi, Yoav Freund, and Robert~E. Schapire.
\newblock The nonstochastic multiarmed bandit problem.
\newblock \emph{SIAM Journal of Computing}, 32\penalty0 (1):\penalty0 48--77,
  2002{\natexlab{b}}.

\bibitem[Bengs et~al.(2021)Bengs, Busa-Fekete, El~Mesaoudi-Paul, and
  H{\"u}llermeier]{Busa14survey}
Viktor Bengs, R{\'o}bert Busa-Fekete, Adil El~Mesaoudi-Paul, and Eyke
  H{\"u}llermeier.
\newblock Preference-based online learning with dueling bandits: A survey.
\newblock \emph{J. Mach. Learn. Res.}, 22:\penalty0 7--1, 2021.

\bibitem[Besbes et~al.(2014)Besbes, Gur, and Zeevi]{besbes+14}
Omar Besbes, Yonatan Gur, and Assaf Zeevi.
\newblock Stochastic multi-armed-bandit problem with non-stationary rewards.
\newblock \emph{Advances in Neural Information Processing Systems},
  27:\penalty0 199--207, 2014.

\bibitem[Besbes et~al.(2015)Besbes, Gur, and Zeevi]{besbes+15}
Omar Besbes, Yonatan Gur, and Assaf Zeevi.
\newblock Non-stationary stochastic optimization.
\newblock \emph{Operations research}, 63\penalty0 (5):\penalty0 1227--1244,
  2015.

\bibitem[Brost et~al.(2016)Brost, Seldin, Cox, and Lioma]{Brost+16}
Brian Brost, Yevgeny Seldin, Ingemar~J. Cox, and Christina Lioma.
\newblock Multi-dueling bandits and their application to online ranker
  evaluation.
\newblock \emph{CoRR}, abs/1608.06253, 2016.

\bibitem[Chen et~al.(2019)Chen, Lee, Luo, and Wei]{luo+19}
Yifang Chen, Chung-Wei Lee, Haipeng Luo, and Chen-Yu Wei.
\newblock A new algorithm for non-stationary contextual bandits: Efficient,
  optimal, and parameter-free.
\newblock \emph{In Proceedings of the 32nd Conference on Learning Theory},
  99:\penalty0 1--30, 2019.

\bibitem[Cheung et~al.(2019{\natexlab{a}})Cheung, Simchi-Levi, and Zhu]{zhu1}
Wang~Chi Cheung, David Simchi-Levi, and Ruihao Zhu.
\newblock Learning to optimize under non-stationarity.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 1079--1087. PMLR, 2019{\natexlab{a}}.

\bibitem[Cheung et~al.(2019{\natexlab{b}})Cheung, Simchi-Levi, and Zhu]{zhu2}
Wang~Chi Cheung, David Simchi-Levi, and Ruihao Zhu.
\newblock Non-stationary reinforcement learning: The blessing of (more)
  optimism.
\newblock \emph{Available at SSRN 3397818}, 2019{\natexlab{b}}.

\bibitem[Dud{\'\i}k et~al.(2015)Dud{\'\i}k, Hofmann, Schapire, Slivkins, and
  Zoghi]{CDB}
Miroslav Dud{\'\i}k, Katja Hofmann, Robert~E Schapire, Aleksandrs Slivkins, and
  Masrour Zoghi.
\newblock Contextual dueling bandits.
\newblock In \emph{Conference on Learning Theory}, pages 563--587, 2015.

\bibitem[Dudik et~al.(2015)Dudik, Hofmann, Schapire, Slivkins, and
  Zoghi]{dudik+15}
Miroslav Dudik, Katja Hofmann, Robert~E Schapire, Aleksandrs Slivkins, and
  Masrour Zoghi.
\newblock Contextual dueling bandits.
\newblock \emph{Conference on Learning Theory}, pages 563--587, 2015.

\bibitem[Gajane et~al.(2015)Gajane, Urvoy, and Cl{\'e}rot]{Adv_DB}
Pratik Gajane, Tanguy Urvoy, and Fabrice Cl{\'e}rot.
\newblock A relative exponential weighing algorithm for adversarial
  utility-based dueling bandits.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning}, pages 218--227, 2015.

\bibitem[Grover et~al.(2018)Grover, Markov, Attia, Jin, Perkins, Cheong, Chen,
  Yang, Harris, Chueh, et~al.]{delay1}
Aditya Grover, Todor Markov, Peter Attia, Norman Jin, Nicolas Perkins, Bryan
  Cheong, Michael Chen, Zi~Yang, Stephen Harris, William Chueh, et~al.
\newblock Best arm identification in multi-armed bandits with delayed feedback.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 833--842. PMLR, 2018.

\bibitem[Kalyanakrishnan et~al.(2012)Kalyanakrishnan, Tewari, Auer, and
  Stone]{Kalyanakrishnan+12}
Shivaram Kalyanakrishnan, Ambuj Tewari, Peter Auer, and Peter Stone.
\newblock P{AC} subset selection in stochastic multi-armed bandits.
\newblock In \emph{ICML}, volume~12, pages 655--662, 2012.

\bibitem[Komiyama et~al.(2015)Komiyama, Honda, Kashima, and
  Nakagawa]{Komiyama+15}
Junpei Komiyama, Junya Honda, Hisashi Kashima, and Hiroshi Nakagawa.
\newblock Regret lower bound and optimal algorithm in dueling bandit problem.
\newblock In \emph{COLT}, pages 1141--1154, 2015.

\bibitem[Lattimore and Szepesv{\'a}ri(2018)]{CsabaNotes18}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock Bandit algorithms.
\newblock \emph{preprint}, 2018.

\bibitem[Luo et~al.(2018)Luo, Wei, Agarwal, and Langford]{luo+18}
Haipeng Luo, Chen-Yu Wei, Alekh Agarwal, and John Langford.
\newblock Efficient contextual bandits in non-stationary worlds.
\newblock \emph{In Proceedings of the 31st Conference On Learning Theory},
  75:\penalty0 1739--1776, 2018.

\bibitem[Ren et~al.(2018)Ren, Liu, and Shroff]{Ren+18}
Wenbo Ren, Jia Liu, and Ness~B Shroff.
\newblock P{AC} ranking from pairwise and listwise queries: Lower bounds and
  upper bounds.
\newblock \emph{arXiv preprint arXiv:1806.02970}, 2018.

\bibitem[Saha and Gopalan(2018)]{SGrank18}
Aadirupa Saha and Aditya Gopalan.
\newblock Active ranking with subset-wise preferences.
\newblock \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, 2018.

\bibitem[Saha and Gopalan(2019{\natexlab{a}})]{SG19}
Aadirupa Saha and Aditya Gopalan.
\newblock Combinatorial bandits with relative feedback.
\newblock In \emph{Advances in Neural Information Processing Systems},
  2019{\natexlab{a}}.

\bibitem[Saha and Gopalan(2019{\natexlab{b}})]{SGwin18}
Aadirupa Saha and Aditya Gopalan.
\newblock {PAC Battling Bandits in the Plackett-Luce Model}.
\newblock In \emph{Algorithmic Learning Theory}, pages 700--737,
  2019{\natexlab{b}}.

\bibitem[Saha and Gopalan(2020)]{SG20}
Aadirupa Saha and Aditya Gopalan.
\newblock Best-item learning in random utility models with subset choices.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 4281--4291. PMLR, 2020.

\bibitem[Saha et~al.(2021)Saha, Koren, and Mansour]{ADB}
Aadirupa Saha, Tomer Koren, and Yishay Mansour.
\newblock Adversarial dueling bandits.
\newblock In \emph{International Conference on Machine Learning}, pages
  9235--9244. PMLR, 2021.

\bibitem[Segal et~al.(2021)Segal, Koren, Mansour, et~al.]{delay2}
Shahar Segal, Tomer Koren, Yishay Mansour, et~al.
\newblock Stochastic multi-armed bandits with unrestricted delay distributions.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Seldin et~al.(2014)Seldin, Bartlett, Crammer, and
  Abbasi-Yadkori]{paid1}
Yevgeny Seldin, Peter Bartlett, Koby Crammer, and Yasin Abbasi-Yadkori.
\newblock Prediction with limited advice and multiarmed bandits with paid
  observations.
\newblock In \emph{International Conference on Machine Learning}, pages
  280--287. PMLR, 2014.

\bibitem[Sui et~al.(2017)Sui, Zhuang, Burdick, and Yue]{Sui+17}
Yanan Sui, Vincent Zhuang, Joel Burdick, and Yisong Yue.
\newblock Multi-dueling bandits with dependent arms.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence},
  UAI'17, 2017.

\bibitem[Sz{\"o}r{\'e}nyi et~al.(2015)Sz{\"o}r{\'e}nyi, Busa-Fekete, Paul, and
  H{\"u}llermeier]{Busa_pl}
Bal{\'a}zs Sz{\"o}r{\'e}nyi, R{\'o}bert Busa-Fekete, Adil Paul, and Eyke
  H{\"u}llermeier.
\newblock Online rank elicitation for plackett-luce: A dueling bandits
  approach.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  604--612, 2015.

\bibitem[Wei and Luo(2021)]{wei21}
Chen-Yu Wei and Haipeng Luo.
\newblock Non-stationary reinforcement learning without prior knowledge: An
  optimal black-box approach.
\newblock \emph{In Proceedings of the 32nd International Conference on Learning
  Theory}, 2021.

\bibitem[Wu and Liu(2016)]{DTS}
Huasen Wu and Xin Liu.
\newblock Double {T}hompson sampling for dueling bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  649--657, 2016.

\bibitem[Yue and Joachims(2009)]{Yue+09}
Yisong Yue and Thorsten Joachims.
\newblock Interactively optimizing information retrieval systems as a dueling
  bandits problem.
\newblock In \emph{Proceedings of the 26th Annual International Conference on
  Machine Learning}, pages 1201--1208. ACM, 2009.

\bibitem[Yue et~al.(2012)Yue, Broder, Kleinberg, and Joachims]{Yue+12}
Yisong Yue, Josef Broder, Robert Kleinberg, and Thorsten Joachims.
\newblock The $k$-armed dueling bandits problem.
\newblock \emph{Journal of Computer and System Sciences}, 78\penalty0
  (5):\penalty0 1538--1556, 2012.

\bibitem[Zoghi et~al.(2014{\natexlab{a}})Zoghi, Whiteson, Munos, Rijke,
  et~al.]{Zoghi+14RUCB}
Masrour Zoghi, Shimon Whiteson, Remi Munos, Maarten~de Rijke, et~al.
\newblock Relative upper confidence bound for the $k$-armed dueling bandit
  problem.
\newblock In \emph{JMLR Workshop and Conference Proceedings}, number~32, pages
  10--18. JMLR, 2014{\natexlab{a}}.

\bibitem[Zoghi et~al.(2014{\natexlab{b}})Zoghi, Whiteson, De~Rijke, and
  Munos]{Zoghi+14RCS}
Masrour Zoghi, Shimon~A Whiteson, Maarten De~Rijke, and Remi Munos.
\newblock Relative confidence sampling for efficient on-line ranker evaluation.
\newblock In \emph{Proceedings of the 7th ACM international conference on Web
  search and data mining}, pages 73--82. ACM, 2014{\natexlab{b}}.

\bibitem[Zoghi et~al.(2015)Zoghi, Karnin, Whiteson, and De~Rijke]{Zoghi+15}
Masrour Zoghi, Zohar~S Karnin, Shimon Whiteson, and Maarten De~Rijke.
\newblock Copeland dueling bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  307--315, 2015.

\end{thebibliography}
