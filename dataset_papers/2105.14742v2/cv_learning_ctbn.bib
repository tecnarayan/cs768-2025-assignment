

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2018}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@article{Studer2016,
author = {Studer, Lukas and Zechner, Christoph and Reumann, Matthias and Pauleve,Loic and Martinez ,Maria Rodriguez and Koeppl,Heinz},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Studer, Zechner, Reumann - 2016 - Marginalized Continuous Time Bayesian Networks for Network Reconstruction from Incomplete Observations.pdf:pdf},
isbn = {9781577357605},
journal = {Proceedings of the 30th Conference on Artificial Intelligence (AAAI 2016)},
keywords = {continuous time bayesian network,graph reconstruction,sequential monte carlo},
mendeley-groups = {Graphs},
pages = {2051--2057},
title = {Marginalized Continuous Time Bayesian Networks for Network Reconstruction from Incomplete Observations},
year = {2016}
}

@article{Nodelman1995,
author = {Nodelman, Uri and Shelton, Christian R and Koller, Daphne},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Nodelman, Shelton, Koller - Unknown - Continuous Time Bayesian Networks.pdf:pdf},
journal = {Proceedings of the 18th Conference on Uncertainty in Artificial Intelligence},
keywords = {Statistics},
mendeley-groups = {Graphs},
pages = {378--387},
title = {Continuous Time Bayesian Networks},
year = {1995}
}

@article{Nodelman2003,
abstract = {Continuous time Bayesian networks (CTBNs) describe structured stochastic processes with finitely many states that evolve over continuous time. A CTBN is a directed (possibly cyclic) dependency graph over a set of variables, each of which represents a finite state continuous time Markov process whose transition model is a function of its parents. We address the problem of learning parameters and structure of a CTBN from fully observed data. We define a conjugate prior for CTBNs, and show how it can be used both for Bayesian parameter estimation and as the basis of a Bayesian score for structure learning. Because acyclicity is not a constraint in CTBNs, we can show that the structure learning problem is significantly easier, both in theory and in practice, than structure learning for dynamic Bayesian networks (DBNs). Furthermore, as CTBNs can tailor the parameters and dependency structure to the different time granularities of the evolution of different variables, they can provide a better fit to continuous-time processes than DBNs with a fixed time granularity.},
archivePrefix = {arXiv},
arxivId = {1212.2498},
author = {Nodelman, Uri and Shelton, Christian R. and Koller, Daphne},
eprint = {1212.2498},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Nodelman, Shelton, Koller - 2012 - Learning continuous time Bayesian networks.pdf:pdf},
journal = {Proceedings of the 19th Conference on Uncertainty in Artificial Intelligence},
mendeley-groups = {Graphs},
pages = {451--458},
title = {Learning continuous time Bayesian networks},
year = {2003}
}

@article{Nodelman2005,
abstract = {Continuous time Bayesian networks (CTBNs) describe structured stochastic processes with finitely many states that evolve over continuous time. A CTBN is a directed (possibly cyclic) dependency graph over a set of variables, each of which represents a finite state continuous time Markov process whose transition model is a function of its parents. We address the problem of learning the parameters and structure of a CTBN from partially observed data. We show how to apply expectation maximization (EM) and structural expectation maximization (SEM) to CTBNs. The availability of the EM algorithm allows us to extend the representation of CTBNs to allow a much richer class of transition durations distributions, known as phase distributions. This class is a highly expressive semi-parametric representation, which can approximate any duration distribution arbitrarily closely. This extension to the CTBN framework addresses one of the main limitations of both CTBNs and DBNs - the restriction to exponentially / geometrically distributed duration. We present experimental results on a real data set of people's life spans, showing that our algorithm learns reasonable models - structure and parameters - from partially observed data, and, with the use of phase distributions, achieves better performance than DBNs.},
archivePrefix = {arXiv},
arxivId = {http://arxiv.org/abs/1207.1402},
author = {Nodelman, Uri and Shelton, Christian R and Koller, Daphne},
eprint = {/arxiv.org/abs/1207.1402},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Nodelman, Shelton, Koller - Unknown - Expectation Maximization and Complex Duration Distributions for Continuous Time Bayesian Networks.pdf:pdf},
isbn = {0-9749039-1-4},
journal = {Proc. Twenty-first Conference on Uncertainty in Artificial Intelligence},
primaryClass = {http:},
title = {Expectation Maximization and Complex Duration Distributions for Continuous Time Bayesian Networks},
pages = {pages 421--430},
year = {2005}
}
@article{Cohn2010,
abstract = {Continuous-time Bayesian networks is a natural structured representation language for multi-component stochastic processes that evolve continuously over time. Despite the compact representation provided by this language, inference in such models},
author = {Cohn, Ido and El-Hay, Tal and Friedman, Nir and Kupferman, Raz},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Cohn, Kupferman RAZ - 2010 - Mean Field Variational Approximation for Continuous-Time Bayesian Networks Tal El-Hay Nir Friedman.pdf:pdf},
isbn = {1532-4435},
journal = {Journal Of Machine Learning Research},
keywords = {continuous time Bayesian networks,continuous time Markov processes,mean field approximation,variational approximations},
pages = {2745--2783},
title = {Mean field variational approximation for continuous-time Bayesian networks},
volume = {11},
year = {2010}
}
@article{El-Hay2010,
abstract = {Many temporal processes can be naturally modeled as a stochastic system that evolves continuously over time. The representation language of continuous-time Bayesian networks allows to succinctly describe multi-component continuous-time stochastic processes. A crucial element in applications of such models is inference. Here we introduce a variational approximation scheme, which is a natural extension of Belief Propagation for continuous-time processes. In this scheme, we view messages as inhomogeneous Markov processes over individual components. This leads to a relatively simple procedure that allows to easily incorporate adaptive ordinary differential equation (ODE) solvers to perform individual steps. We provide the theoretical foundations for the approximation, and show how it performs on a range of networks. Our results demonstrate that our method is quite accurate on singly connected networks, and provides close approximations in more complex ones.},
author = {El-Hay, Tal and Cohn, Ido and Friedman, Nir and Kupferman, Raz},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/El-Hay et al. - Unknown - Continuous-Time Belief Propagation.pdf:pdf},
isbn = {9781605589077},
journal = {Proceedings of the 27th International Conference on Machine Learning},
keywords = {computational,information theoretic learning with statistics,theory {\&} algorithms},
pages = {343--350},
title = {Continuous-Time Belief Propagation},
year = {2010}
}

@article{Vazquez2017,
abstract = {The analytical description of the dynamics in models with discrete variables (e.g. Ising spins) is a notoriously difficult problem, which can only be tackled under some approximation. Recently a novel variational approach to solve the stationary dynamical regime has been introduced by Pelizzola (2013 Eur. Phys. J. B 86 120), where simple closed equations are derived under mean-field approximations based on the cluster variational method. Here we propose to use the same approximation based on the cluster variational method also for the non-stationary regime, which has not been considered up to now within this framework. We check the validity of this approximation in describing the non-stationary dynamical regime of several Ising models defined on Erd?s?R{\'{e}}nyi random graphs: we study ferromagnetic models with symmetric and partially asymmetric couplings, models with random fields and also spin glass models. A comparison with the actual Glauber dynamics, solved numerically, shows that one of the two studied approximations (the so-called 'diamond' approximation) provides very accurate results in all the systems studied. Only for the spin glass models do we find some small discrepancies in the very low temperature phase, probably due to the existence of a large number of metastable states. Given the PAPER: Disordered systems, classical and quantum simplicity of the equations to be solved, we believe the diamond approximation should be considered as the 'minimal standard' in the description of the non-stationary regime of Ising-like models: any new method pretending to provide a better approximate description to the dynamics of Ising-like models should perform at least as good as the diamond approximation.},
author = {V{\'{a}}zquez, Eduardo Dom{\'{i}}nguez and Ferraro, Gino Del and Ricci-Tersenghi, Federico},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Dom{\'{i}}nguez V{\'{a}}zquez, Ferraro, Ricci-Tersenghi - 2017 - A simple analytical description of the non-stationary dynamics in Ising spin syst.pdf:pdf},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
keywords = {aging,cavity and replica method,glassy dynamics,slow relaxation},
number = {3},
pages = {033303},
title = {A simple analytical description of the non-stationary dynamics in Ising spin systems},
volume = {2017},
year = {2017}
}

@article{Pelizzola2017,
abstract = {We investigate different mean-field-like approximations for stochastic dynamics on graphs, within the framework of a cluster-variational approach. In analogy with its equilibrium counterpart, this approach allows one to give a unified view of various (previously known) approximation schemes, and suggests quite a systematic way to improve the level of accuracy. We compare the different approximations with Monte Carlo simulations on a reversible (susceptible-infected-susceptible) discrete-time epidemic-spreading model on random graphs.},
archivePrefix = {arXiv},
arxivId = {1702.06822},
author = {Pelizzola, Alessandro and Pretti, Marco},
eprint = {1702.06822},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Pelizzola, Pretti - 2017 - Variational approximations for stochastic dynamics on graphs.pdf:pdf},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
number = {7},
pages = {1--28},
title = {Variational approximations for stochastic dynamics on graphs},
volume = {2017},
year = {2017}
}


@article{Pretti2005,
abstract = {Exactness of the cluster variation method and factorization of the equilibrium probabilityfor the Wako?Saito?Munoz?Eaton model of protein folding Alessandro Pelizzola Characterizing and improving generalized belief propagation algorithms on the 2DEdwards?Anderson model Eduardo Dom{\'{i}}nguez, Alejandro Lage-Castellanos, Roberto Mulet et al. Abstract The cluster variation method (CVM) is a hierarchy of approximate variational techniques for discrete (Ising-like) models in equilibrium statistical mechanics, improving on the mean-field approximation and the Bethe?Peierls approximation, which can be regarded as the lowest level of the CVM. In recent years it has been applied both in statistical physics and to inference and optimization problems formulated in terms of probabilistic graphical models. The foundations of the CVM are briefly reviewed, and the relations with similar techniques are discussed. The main properties of the method are considered, with emphasis on its exactness for particular models and on its asymptotic properties. The problem of the minimization of the variational free energy, which arises in the CVM, is also addressed, and recent results about both provably convergent and message-passing algorithms are discussed.},
author = {Pretti, Marco and Pelizzola, Alessandro and van Mourik, Jort and Wemmenhove, B and Kappen, H J and Heskes, Tom and Opper, Manfred and Wiegerinck, Wim and {Ho Yeung}, Chi and Saad, David and Aurell, Erik and Mahmoudi, Hamed},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Pretti et al. - 2005 - Cluster variation method in statistical physics and probabilistic graphical models.pdf:pdf},
journal = {J. Phys. A: Math. Gen. J. Phys. A: Math. Gen},
number = {38},
pages = {309--339},
title = {Cluster variation method in statistical physics and probabilistic graphical models},
volume = {38},
year = {2005}
}

@article{Acerbi2014,
abstract = {Background: Dynamic aspects of gene regulatory networks are typically investigated by measuring system variables at multiple time points. Current state-of-the-art computational approaches for reconstructing gene networks directly build on such data, making a strong assumption that the system evolves in a synchronous fashion at fixed points in time. However, nowadays omics data are being generated with increasing time course granularity. Thus, modellers now have the possibility to represent the system as evolving in continuous time and to improve the models' expressiveness. Results: Continuous time Bayesian networks are proposed as a new approach for gene network reconstruction from time course expression data. Their performance was compared to two state-of-the-art methods: dynamic Bayesian networks and Granger causality analysis. On simulated data, the methods comparison was carried out for networks of increasing size, for measurements taken at different time granularity densities and for measurements unevenly spaced over time. Continuous time Bayesian networks outperformed the other methods in terms of the accuracy of regulatory interactions learnt from data for all network sizes. Furthermore, their performance degraded smoothly as the size of the network increased. Continuous time Bayesian networks were significantly better than dynamic Bayesian networks for all time granularities tested and better than Granger causality for dense time series. Both continuous time Bayesian networks and Granger causality performed robustly for unevenly spaced time series, with no significant loss of performance compared to the evenly spaced case, while the same did not hold true for dynamic Bayesian networks. The comparison included the IRMA experimental datasets which confirmed the effectiveness of the proposed method. Continuous time Bayesian networks were then applied to elucidate the regulatory mechanisms controlling murine T helper 17 (Th17) cell differentiation and were found to be effective in discovering well-known regulatory mechanisms, as well as new plausible biological insights. Conclusions: Continuous time Bayesian networks were effective on networks of both small and large size and were particularly feasible when the measurements were not evenly distributed over time. Reconstruction of the murine Th17 cell differentiation network using continuous time Bayesian networks revealed several autocrine loops, suggesting that Th17 cells may be auto regulating their own differentiation process.},
author = {Acerbi, Enzo and Zelante, Teresa and Narang, Vipin and Stella, Fabio},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Acerbi et al. - 2014 - Gene network inference using continuous time Bayesian networks a comparative study and application to Th17 cell d.pdf:pdf},
journal = {BMC Bioinformatics},
keywords = {Continuous time Bayesian network,Gene network reconstruction,Time course},
title = {Gene network inference using continuous time Bayesian networks: a comparative study and application to Th17 cell differentiation},
volume = {15},
year = {2014}
}
@article{Schadt2005,
abstract = {A key goal of biomedical research is to elucidate the complex network of gene interactions underlying complex traits such as common human diseases. Here we detail a multistep procedure for identifying potential key drivers of complex traits that integrates DNA-variation and gene-expression data with other complex trait data in segregating mouse populations. Ordering gene expression traits relative to one another and relative to other complex traits is achieved by systematically testing whether variations in DNA that lead to variations in relative transcript abundances statistically support an independent, causative or reactive function relative to the complex traits under consideration. We show that this approach can predict transcriptional responses to single gene-perturbation experiments using gene-expression data in the context of a segregating mouse population. We also demonstrate the utility of this approach by identifying and experimentally validating the involvement of three new genes in susceptibility to obesity.},
author = {Schadt, Eric E and Lamb, John and Yang, Xia and Zhu, Jun and Edwards, Steve and Thakurta, Debraj Guha and Sieberts, Solveig K and Monks, Stephanie and Reitman, Marc and Zhang, Chunsheng and Lum, Pek Yee and Leonardson, Amy and Thieringer, Rolf and Metzger, Joseph M and Yang, Liming and Castle, John and Zhu, Haoyuan and Kash, Shera F and Drake, Thomas A and Sachs, Alan and Lusis, Aldons J},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Schadt et al. - 2005 - An integrative genomics approach to infer causal associations between gene expression and disease.pdf:pdf},
isbn = {1061-4036 (Print)$\backslash$r1061-4036 (Linking)},
journal = {Nature Genetics},
month = {jul},
number = {7},
pages = {710--717},
pmid = {15965475},
publisher = {Nature Publishing Group},
title = {An integrative genomics approach to infer causal associations between gene expression and disease},
volume = {37},
year = {2005}
}

@article{Opper2001,
abstract = {We develop an advanced mean field method for approximating averages in probabilistic data models that is based on the Thouless-Anderson-Palmer (TAP) approach of disorder physics. In contrast to conventional TAP, where the knowledge of the distribution of couplings between the random variables is required, our method adapts to the concrete couplings. We demonstrate the validity of our approach, which is so far restricted to models with nonglassy behavior, by replica calculations for a wide class of models as well as by simulations for a real data set.},
archivePrefix = {arXiv},
arxivId = {cond-mat/0102274},
author = {Opper, Manfred and Winther, Ole},
eprint = {0102274},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Opper, Winther - 2001 - Tractable Approximations for Probabilistic Models The Adaptive Thouless-Anderson-Palmer Mean Field Approach.pdf:pdf},
journal = {Physical Review Letters},
keywords = {0250 ? r,PACS numbers},
mendeley-groups = {Graphs},
number = {17},
pages = {3695--3699},
pmid = {11329302},
primaryClass = {cond-mat},
title = {Tractable approximations for probabilistic models: The adaptive Thouless-Anderson-Palmer mean field approach},
volume = {86},
year = {2001}
}

@article{Klann2012,
abstract = {Cells are highly organized objects containing millions of molecules. Each biomolecule has a specific shape in order to interact with others in the complex machinery. Spatial dynamics emerge in this system on length and time scales which can not yet be modeled with full atomic detail. This review gives an overview of methods which can be used to simulate the complete cell at least with molecular detail, especially Brownian dynamics simulations. Such simulations require correct implementation of the diffusion-controlled reaction scheme occurring on this level. Implementations and applications of spatial simulations are presented, and finally it is discussed how the atomic level can be included for instance in multi-scale simulation methods.},
author = {Klann, Michael and Koeppl, Heinz},
journal =  {International Journal of Molecular Sciences},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Klann, Koeppl - 2012 - Spatial Simulations in Systems Biology From Molecules to Cells.pdf:pdf},
isbn = {4144632121},
keywords = {Brownian dynamics,agent-based modeling,diffusion-controlled reactions,fractal kinetics,nonlinear diffusion,spatial-temporal dynamics},
number = {6},
pages = {7798--7827},
pmid = {22837728},
title = {Spatial Simulations in Systems Biology: From Molecules to Cells},
volume = {13},
year = {2012}
}

@article{Creixell2015,
abstract = {Genomic information on tumors from 50 cancer types cataloged by the International Cancer Genome Consortium (ICGC) shows that only a few well-studied driver genes are frequently mutated, in contrast to many infrequently mutated genes that may also contribute to tumor biology. Hence there has been large interest in developing pathway and network analysis methods that group genes and illuminate the processes involved. We provide an overview of these analysis techniques and show where they guide mechanistic and translational investigations.},
author = {Creixell, Pau and Reimand, J{\"{u}}ri and Haider, Syed and Wu, Guanming and Shibata, Tatsuhiro and Vazquez, Miguel and Mustonen, Ville and Gonzalez-Perez, Abel and Pearson, John and Sander, Chris and Raphael, Benjamin J and Marks, Debora S and Ouellette, B F Francis and Valencia, Alfonso and Bader, Gary D and Boutros, Paul C and Stuart, Joshua M and Linding, Rune and Lopez-Bigas, Nuria and Stein, Lincoln D and {Mutation Consequences and Pathway Analysis Working Group of the International Cancer Genome Consortium}, Mutation Consequences and Pathway Analysis Working Group of the International Cancer Genome},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Creixell et al. - 2015 - Pathway and network analysis of cancer genomes.pdf:pdf},
journal = {Nature methods},
month = {jul},
number = {7},
pages = {615--621},
pmid = {26125594},
publisher = {NIH Public Access},
title = {Pathway and network analysis of cancer genomes.},
volume = {12},
year = {2015}
}

@article{Yedidia2000,
abstract = {This is an updated and expanded version of TR2000-26, but it is still in draft form. Belief propagation (BP)was only supposed towork for tree-like networks butworks surprisingly well in many applications involving networks with loops, including turbo codes. However, there has been little understanding of the algorithm or the nature of the solutions it finds for general graphs. We show that BP can only converge to a stationary point of an approximate free energy, known as the Bethe free energy in statistical physics. This result characterizes BP fixed-points and makes connections with variational approaches to approximate inference. More importantly, our analysis lets us build on the progress made in statistical physics since Bethes approximation was introduced in 1935. Kikuchi and others have shown how to construct more accurate free energy approximations, of which Bethes approximation is the simplest. Exploiting the insights from our analysis, we derive generalized belief propagation (GBP) versions of these Kikuchi approximations. These new message passing algorithms can be significantly more accurate than ordinary BP, at an adjustable increase in complexity. We illustrate such a new GBP algorithm on a grid Markov network and show that it gives much more accurate marginal probabilities than those found using ordinary BP.},
archivePrefix = {arXiv},
arxivId = {0911.0211v2},
author = {Yedidia, Jonathan S and Freeman, William T and Weiss, Yair},
eprint = {0911.0211v2},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Yedidia, Freeman, Weiss - 2001 - Bethe free energy, Kikuchi approximations, and belief propagation algorithms.pdf:pdf},
isbn = {0018-9448},
journal = {Advances in neural information},
pages = {657--663},
title = {Bethe free energy, Kikuchi approximations, and belief propagation algorithms},
volume = {13},
year = {2000}
}

@article{Kikuchi1951,
abstract = {applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Kikuchi, Ryoichi},
eprint = {arXiv:1011.1669v3},
isbn = {9788578110796},
journal = {Physical Review},
keywords = {Algorithms,Bioinformatics,Combinatorial Libraries,Computational Biology/Bioinformatics,Computer Appl. in Life Sciences,Microarrays},
month = {mar},
number = {6},
pages = {988--1003},
pmid = {25246403},
publisher = {BioMed Central},
title = {A theory of cooperative phenomena},
volume = {81},
year = {1951}
}

@article{El-Hay2011,
abstract = {Continuous - Time Bayesian Networks is a general compact representation language for multi-component continuous - time processes. ...},
archivePrefix = {arXiv},
arxivId = {1206.3251},
author = {El-Hay, Tal and Kupferman, R and Friedman, N},
eprint = {1206.3251},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/El-Hay, Friedman, Kupferman - Unknown - Gibbs Sampling in Factorized Continuous-Time Markov Processes.pdf:pdf},
isbn = {0-9749039-4-9},
journal = {Proceedings of the 22th Conference on Uncertainty in Artificial Intelligence},
title = {Gibbs sampling in factorized continuous-time Markov processes},
year = {2011}
}

@article{Opper2008,
abstract = {Markov jump processes play an important role in a large number of application domains. However, realistic systems are analytically intractable and they have tra-ditionally been analysed using simulation based techniques, which do not provide a framework for statistical inference. We propose a mean field approximation to perform posterior inference and parameter estimation. The approximation allows a practical solution to the inference problem, while still retaining a good degree of accuracy. We illustrate our approach on two biologically motivated systems.},
author = {Opper, Manfred and Sanguinetti, Guido},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Opper, Sanguinetti - Unknown - Variational inference for Markov jump processes.pdf:pdf},
journal = {Advances in Neural Information Processing Systems 20},
pages = {1105--1112},
title = {Variational inference for Markov jump processes},
year = {2008}
}

@article{Wonham1964,
abstract = {1. Introduction. A current problem in control theory is that of estimat-ing the dynamical sate of a physical system, on the basis of data perturbed by noise. Solution of the estimation problem is usuully immediate if one knows the probability distribution of the system state at each instant of time, eondiLionM on the data available up o that instant. It is therefore of interest o ask how this posterior probability distribution evolves with time, and if possible to specify the dynamical structure of a filter (i.e., analog device) which generates the posterior distribution when is input is the time function actually observed. In the present paper, filters of this type ure defined by means of stochastic differential equations for the posterior distribution in which the observed time function appears as a forcing term. Differential equations for this purpose were introduced in 1960 by Stratonovi5 [1], who also indicated their application to stochastic control problems [2]. When the dynamical system under observation is linear and the noise is white Gaussian it hs been shown [3] that StratonoviS's equation cn be solved formally to yield the sLoehusLic differential equation of the optimal (linear) filter. When the function o be estimated is a Markov step process and the noise is while Gaussia the optimal (non,linear) filter equations were stated in [4]. The latter equations are discussed in more detail in 3, below; they differ from those of SLratonovi5 in a sense to be noted in the sequel. For one example, discussed in 3, performance of the optimal nonlinear filter is evaluated numerically and is found to be somewhat better than that of the simpler Wiener filter, particularly when the noise intensity is low. In 4, the equations of 3 are generalized heuristically to the ease where the state space of the step process is continuous, and iu 5 some tentative remarks are made on the form of the solutions. Some parallel work on noisy observation of a diffusion process has been reported by Kushner in recent pper [5].},
author = {Wonham, W. M.},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Wonham - 1965 - SOME APPLICATIONS OF STOCHASTIC DIFFERENTIAL EQUATIONS TO OPTIMAL NONLINEAR FILTERING(2).pdf:pdf},
journal = {Journal of the Society for Industrial and Applied Mathematics Series A Control},
number = {3},
pages = {347--369},
title = {Some Applications of Stochastic Differential Equations to Optimal Nonlinear Filtering},
volume = {2},
year = {1964}
}

@article{Yedidia2005,
abstract = {Important inference problems in statistical physics, computer vision, error-correcting coding theory, and artificial intelligence can all be reformulated as the computation of marginal probabilities on factor graphs. The belief propagation (BP) algorithm is an efficient way to solve these problems that is exact when the factor graph is a tree, but only approximate when the factor graph has cycles. We show that BP fixed points correspond to the stationary points of the Bethe approximation of the free energy for a factor graph. We explain how to obtain region-based free energy approximations that improve the Bethe approximation, and corresponding generalized belief propagation (GBP) algorithms. We emphasize the conditions a free energy approximation must satisfy in order to be a "valid" or "maxent-normal" approximation. We describe the relationship between four different methods that can be used to generate valid approximations: the "Bethe method", the "junction graph method", the "cluster variation method", and the "region graph method". Finally, we explain how to tell whether a region-based approximation, and its corresponding GBP algorithm, is likely to be accurate, and describe empirical results showing that GBP can significantly outperform BP.},
archivePrefix = {arXiv},
arxivId = {0911.0211v2},
author = {Yedidia, Jonathan S and Freeman, William T and Weiss, Yair},
eprint = {0911.0211v2},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Yedidia, Freeman, Weiss - 2004 - Constructing Free Energy Approximations and Generalized Belief Propagation Algorithms.pdf:pdf},
isbn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
keywords = {Belief propagation (BP),Bethe free energy,Cluster variation method,Generalized belief propagation (GBP),Kikuchi free energy,Message passing,Sum-product algorithm},
number = {7},
pages = {2282--2312},
title = {Constructing free-energy approximations and generalized belief propagation algorithms},
volume = {51},
year = {2005}
}


@article{Fan2008,
abstract = {We first present a sampling algorithm for continuous time Bayesian networks based on importance sampling. We then extend it to continuous-time particle filtering and smoothing algorithms. The three algorithms can estimate the expectation of any function of a trajectory, conditioned on any evidence set constraining the values of subsets of the variables over subsets of the timeline. We present experimental results on their accuracies and time efficiencies, and compare them to expectation propagation.},
author = {Fan, Yu and Shelton, CR},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Fan, Shelton - Unknown - Sampling for Approximate Inference in Continuous Time Bayesian Networks.pdf:pdf},
journal = {AI and Math},
title = {Sampling for approximate inference in continuous time Bayesian networks},
year = {2008}
}

@article{Rao2012,
abstract = {Markov jump processes (or continuous-time Markov chains) are a simple and important class of continuous-time dynamical systems. In this paper, we tackle the problem of simulating from the posterior distribution over paths in these models, given partial and noisy observations. Our approach is an auxiliary variable Gibbs sampler, and is based on the idea of uniformization. This sets up a Markov chain over paths by alternately sampling a finite set of virtual jump times given the current path and then sampling a new path given the set of extant and virtual jump times using a standard hidden Markov model forward filtering-backward sampling algorithm. Our method is exact and does not involve approximations like time-discretization. We demonstrate how our sampler extends naturally to MJP-based models like Markov-modulated Poisson processes and continuous-time Bayesian networks and show significant computational benefits over state-of-the-art MCMC samplers for these models.},
archivePrefix = {arXiv},
arxivId = {1208.4818},
author = {Rao, Vinayak and Teh, Yee Whye},
eprint = {1208.4818},
isbn = {978-0-9749039-7-2},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {Gibbs sampler,MCMC,Markov jump process,Markov-modulated Poisson process,continuous-time Bayesian network,uniformization},
pages = {3295--3320},
title = {Fast MCMC sampling for Markov jump processes and extensions},
volume = {14},
year = {2012}
}


@article{Cantone2009,
author = {Cantone, Irene and Marucci, Lucia and Iorio, Francesco and Ricci, Maria Aurelia and Belcastro, Vincenzo and Bansal, Mukesh and Santini, Stefania and {Di Bernardo}, Mario and di Bernardo, Diego and Cosma, Maria Pia},
rmv = {10.1016/J.CELL.2009.01.055},
issn = {0092-8674},
journal = {Cell},
month = {apr},
number = {1},
pages = {172--181},
publisher = {Cell Press},
title = {A Yeast Synthetic Network for In Vivo Assessment of Reverse-Engineering and Modeling Approaches},
volume = {137},
year = {2009}
}

@article{Stolovitzky,
author = {Stolovitzky, Gustavo and Prill, Robert J and Califano, Andrea},
rmv = {10.1111/j.1749-6632.2009.04497.x},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Stolovitzky, Prill, Califano - Unknown - THE CHALLENGES OF SYSTEMS BIOLOGY Lessons from the DREAM2 Challenges A Community Effort to Asse.pdf:pdf},
isbn = {9781573317511},
issn = {17496632},
journal = {Annals of the New York Academy of Sciences},
keywords = {Assessment methods,Machine learning,Mathematical modeling,Network theory,Pathway inference,Reverse engineering,Systems biology},
pages = {159--195},
pmid = {19348640},
title = {Lessons from the DREAM2 challenges: A community effort to assess biological network inference},
volume = {1158},
year = {2009}
}

@article{Bansal2007,
author = {Bansal, Mukesh and Belcastro, Vincenzo and Ambesi-Impiombato, Alberto and di Bernardo, Diego},
rmv = {10.1038/msb4100120},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Bansal et al. - 2007 - How to infer gene networks from expression profiles.pdf:pdf},
issn = {1744-4292},
journal = {Molecular systems biology},
pages = {78},
pmid = {17299415},
publisher = {European Molecular Biology Organization},
title = {How to infer gene networks from expression profiles.},
volume = {3},
year = {2007}
}

@article{Bansal2006,
author = {Bansal, Mukesh and Gatta, Giusy Della and di Bernardo, Diego},
rmv = {10.1093/bioinformatics/btl003},
isbn = {1367-4803},
issn = {13674803},
journal = {Bioinformatics},
month = {apr},
number = {7},
pages = {815--822},
pmid = {16418235},
title = {Inference of gene regulatory networks and compound mode of action from time course gene expression profiles},
volume = {22},
year = {2006}
}


@article{Yu2004,
author = {Yu, Jing and Smith, V. Anne and Wang, Paul P. and Hartemink, Alexander J. and Jarvis, Erich D.},
rmv = {10.1093/bioinformatics/bth448},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Yu et al. - 2004 - Advances to Bayesian network inference for generating causal networks from observational biological data.pdf:pdf},
isbn = {1367-4803 (Print)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
month = {dec},
number = {18},
pages = {3594--3603},
pmid = {15284094},
publisher = {Oxford University Press},
title = {Advances to Bayesian network inference for generating causal networks from observational biological data},
volume = {20},
year = {2004}
}

@article{Friedman1999,
abstract = {A large portion of real-world data is stored in com-mercial relational database systems. In contrast, most statistical learning methods work only with " flat " data representations. Thus, to apply these methods, we are forced to convert our data into a flat form, thereby losing much of the relational structure present in our database. This paper builds on the recent work on probabilistic relational mod-els (PRMs), and describes how to learn them from databases. PRMs allow the properties of an object to depend probabilistically both on other proper-ties of that object and on properties of related ob-jects. Although PRMs are significantly more ex-pressive than standard models, such as Bayesian networks, we show how to extend well-known sta-tistical methods for learning Bayesian networks to learn these models. We describe both parameter estimation and structure learning ? the automatic induction of the dependency structure in a model. Moreover, we show how the learning procedure can exploit standard database retrieval techniques for efficient learning from large datasets. We present experimental results on both real and synthetic re-lational databases.},
author = {Friedman, Nir and Getoor, Lise and Koller, Daphne and Pfeffer, Avi},
journal = {In Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence (IJCAI-99)},
month = {August},
title = {Learning Probabilistic Relational Models},
year = {1999}
}

@article{Glauber1963,
abstract = {The individual spins of the Ising model are assumed to interact with an external agency (e.g., a heat reservoir) which causes them to change their states randomly with time. Coupling between the spins is introduced through the assumption that the transition probabilities for any one spin depend on the values of the neighboring spins. This dependence is determined, in part, by the detailed balancing condition obeyed by the equilibrium state of the model. The Markoff process which describes the spin functions is analyzed in detail for the case of a closed N?member chain. The expectation values of the individual spins and of the products of pairs of spins, each of the pair evaluated at a different time, are found explicitly. The influence of a uniform, time?varying magnetic field upon the model is discussed, and the frequency?dependent magnetic susceptibility is found in the weak?field limit. Some fluctuation?dissipation theorems are derived which relate the susceptibility to the Fourier transform of the time?dependent correlation function of the magnetization at equilibrium.},
annote = {NULL},
author = {Glauber, Roy J},
rmv = {10.1063/1.1703954},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Glauber - 1963 - Time-Dependent Statistics of the Ising Model.pdf:pdf},
isbn = {0022-2488},
issn = {00222488},
journal = {J. Math. Phys.},
mendeley-groups = {Graphs},
number = {1963},
pages = {294--307},
title = {Time-Dependent Statistics of the Ising Model},
volume = {4},
year = {1963}
}


@article{Penfold2011,
abstract = {Inferring, or 'reverse-engineering', gene networks can be defined as the process of identifying gene interactions from experimental data through computational analysis. Gene expression data from microarrays are typically used for this purpose. Here we compared different reverse-engineering algorithms for which ready-to-use software was available and that had been tested on experimental data sets. We show that reverse-engineering algorithms are indeed able to correctly infer regulatory interactions among genes, at least when one performs perturbation experiments complying with the algorithm requirements. These algorithms are superior to classic clustering algorithms for the purpose of finding regulatory interactions among genes, and, although further improvements are needed, have reached a discreet performance for being practically useful.},
author = {Penfold, Christopher A. and Wild, David L.},
rmv = {10.1098/rsfs.2011.0053},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Penfold, Wild - 2011 - How to infer gene networks from expression profiles, revisited(3).pdf:pdf},
isbn = {1744-4292 (Electronic)$\backslash$r1744-4292 (Linking)},
issn = {20428901},
journal = {Interface Focus},
keywords = {Gene expression,Gene-regulatory networks,Inference},
month = {dec},
number = {6},
pages = {857--870},
pmid = {17299415},
publisher = {Royal Society},
title = {How to infer gene networks from expression profiles, revisited},
volume = {1},
year = {2011}
}


@article{Friedman2008,
abstract = {We consider the problem of estimating sparse graphs by a lasso penalty applied to the inverse covariance matrix. Using a coordinate descent procedure for the lasso, we develop a simple algorithm? the Graphical Lasso? that is remarkably fast: it solves a 1000 node prob-lem (? 500, 000 parameters) in at most a minute, and is 30 to 4000 times faster than competing methods. It also provides a conceptual link between the exact problem and the approximation suggested by Meinshausen {\&} B{\"{u}}hlmann (2006). We illustrate the method on some cell-signaling data from proteomics.},
author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
rmv = {10.1093/biostatistics/kxm045},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Friedman, Hastie, Tibshirani - 2007 - Sparse inverse covariance estimation with the graphical lasso.pdf:pdf},
journal = {Biostatistics2},
mendeley-groups = {Graphs},
number = {3},
pages = {432--441},
pmid = {18079126},
title = {Sparse covariance estimation},
volume = {9},
year = {2008}
}

@article{Tibshirani2005,
abstract = {The lasso penalizes a least squares regression by the sum of the absolute values (L 1 -norm) of the coefficients. The form of this penalty encourages sparse solutions (with many coefficients equal to 0). We propose the 'fused lasso', a generalization that is designed for prob-lems with features that can be ordered in some meaningful way. The fused lasso penalizes the L 1 -norm of both the coefficients and their successive differences. Thus it encourages sparsity of the coefficients and also sparsity of their differences?i.e. local constancy of the coefficient profile. The fused lasso is especially useful when the number of features p is much greater than N, the sample size. The technique is also extended to the 'hinge' loss function that underlies the support vector classifier.We illustrate the methods on examples from protein mass spectroscopy and gene expression data.},
author = {Tibshirani, Robert and Saunders, Michael and Rosset, Saharon and Zhu, Ji and Knight, Keith},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Tibshirani et al. - 2005 - Sparsity and smoothness via the fused lasso.pdf:pdf},
journal = {J. R. Statist. Soc. B},
keywords = {Fused lasso,Gene expression,Lasso,Least squares regression,Protein mass spectroscopy,Sparse solutions,Support vector classifier},
mendeley-groups = {Graphs},
number = {1},
pages = {91--108},
title = {Sparsity and smoothness via the fused lasso},
volume = {67},
year = {2005}
}

@article{Wang2012,
abstract = {Recently, the graphical lasso procedure has become popular in estimating Gaussian graphical models. In this paper, we introduce a fully Bayesian treatment of graphical lasso models. We first investigate the graphical lasso prior that has been relatively unexplored. Using data augmentation, we develop a simple but highly efficient block Gibbs sampler for simulating covariance matrices. We then generalize the Bayesian graphical lasso to the Bayesian adaptive graphical lasso. Finally, we illustrate and compare the results from our approach to those obtained using the standard graphical lasso procedures for real and simulated data. In terms of both covariance matrix estimation and graphical structure learning, the Bayesian adaptive graphical lasso appears to be the top overall performer among a range of frequentist and Bayesian methods.},
author = {Wang, Hao},
rmv = {10.1214/12-BA729},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Wang - 2012 - Bayesian graphical lasso models and eficient posterior computation.pdf:pdf},
issn = {19360975},
journal = {Bayesian Analysis},
keywords = {Adaptive graphical lasso,Block gibbs sampler,Constrained parameter spaces,Covariance matrix estimation,Double-exponential distribution,Graphical lasso},
mendeley-groups = {Graphs},
number = {4},
pages = {867--886},
title = {Bayesian graphical lasso models and eficient posterior computation},
volume = {7},
year = {2012}
}

@article{Linzner2018,
author = {Linzner, Dominik and Koeppl, Heinz},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Linzner, Koeppl - 2018 - Cluster Variational Approximations for Structure Learning of Continuous-Time Bayesian Networks from Incomple(3).pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {7880--7890},
title = {Cluster Variational Approximations for Structure Learning of Continuous-Time Bayesian Networks from Incomplete Data},
year = {2018}
}

@article{Battistin2017,
abstract = {Despite our improved ability to probe biological systems at a higher spatio-temporal resolution, the high dimensionality of the biological systems often prevents sufficient sampling of the state space. Even with large scale datasets, such as gene microarrays or multi-neuronal recording techniques, the vari-ables we are recording from are typically only a small subset, if wisely chosen, representing the most relevant degrees of freedom. The remaining variables, or the so called hidden variables, are most likely coupled to the observed ones, and affect their statistics and consequently our inference about the function of the system and the way it performs this function. Two important questions then arise in this context: which var-iables should we choose to observe and collect data from? and how much can we learn from data in the presence of hidden variables? In this paper we suggest that recent algorithmic developments rooting in the statistical physics of complex systems constitute a promising set of tools to extract relevant features from high-throughput data and a fruitful avenue of research for coming years.},
author = {Battistin, Claudia and Dunn, Benjamin and Roudi, Yasser},
rmv = {10.1016/j.coisb.2016.12.010},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Battistin, Dunn, Roudi - 2017 - Learning with unknowns Analyzing biological data in the presence of hidden variables.pdf:pdf},
journal = {Current Opinion in Systems Biology},
keywords = {Generalized linear models,Hidden nodes,Ising model,Maximum entropy,Statistical models},
pages = {122--128},
title = {Learning with unknowns: Analyzing biological data in the presence of hidden variables},
volume = {1},
year = {2017}
}

@book{Koller2010,
abstract = {1. Introduction -- 2. Foundations -- I. Representation -- 3. Bayesian Network Representation -- 4. Undirected Graphical Models -- 5. Local Probabilistic Models -- 6. Template-Based Representations -- 7. Gaussian Network Models -- 8. Exponential Family -- II. Inference -- 9. Exact Inference: Variable Elimination -- 10. Exact Inference: Clique Trees -- 11. Inference as Optimization -- 12. Particle-Based Approximate Inference -- 13. MAP Inference -- 14. Inference in Hybrid Networks -- 15. Inference in Temporal Models -- III. Learning -- 16. Learning Graphical Models: Overview -- 17. Parameter Estimation -- 18. Structure Learning in Bayesian Networks -- 19. Partially Observed Data -- 20. Learning Undirected Models -- IV. Actions and Decisions -- 21. Causality -- 22. Utilities and Decisions -- 23. Structured Decision Problems -- 24. Epilogue -- A. Background Material.},
author = {Koller, Daphne and Friedman, Nir},
isbn = {0262013193},
pages = {1233},
publisher = {MIT Press},
title = {Probabilistic graphical models principles and techniques},
year = {2010}
}

@article{Meinshausen2006,
abstract = {The pattern of zero entries in the inverse covariance matrix of a multivariate normal distribution corresponds to conditional independence restrictions between variables. Covariance selection aims at estimating those structural zeros from data. We show that neighborhood selection with the Lasso is a computationally attractive alternative to standard covariance selection for sparse high-dimensional graphs. Neighborhood selection estimates the conditional independence restrictions separately for each node in the graph and is hence equivalent to variable selection for Gaussian linear models. We show that the proposed neighborhood selection scheme is consistent for sparse high-dimensional graphs. Consistency hinges on the choice of the penalty parameter. The oracle value for optimal prediction does not lead to a consistent neighborhood estimate. Controlling instead the probability of falsely joining some distinct connectivity components of the graph, consistent estimation for sparse graphs is achieved (with exponential rates), even when the number of variables grows as the number of observations raised to an arbitrary power.},
archivePrefix = {arXiv},
arxivId = {math/0608017},
author = {Meinshausen, Nicolai and B{\"{u}}hlmann, Peter},
rmv = {10.1214/009053606000000281},
eprint = {0608017},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Meinshausen, B{\"{u}}hlmann - 2006 - High-dimensional graphs and variable selection with the Lasso.pdf:pdf},
isbn = {0090-5364},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Covariance selection,Gaussian graphical models,Linear regression,Penalized regression},
mendeley-groups = {Graphs},
number = {3},
pages = {1436--1462},
pmid = {239471300013},
primaryClass = {math},
title = {High-dimensional graphs and variable selection with the Lasso},
volume = {34},
year = {2006}
}

@article{Glauber1963,
abstract = {The individual spins of the Ising model are assumed to interact with an external agency (e.g., a heat reservoir) which causes them to change their states randomly with time. Coupling between the spins is introduced through the assumption that the transition probabilities for any one spin depend on the values of the neighboring spins. This dependence is determined, in part, by the detailed balancing condition obeyed by the equilibrium state of the model. The Markoff process which describes the spin functions is analyzed in detail for the case of a closed N‐member chain. The expectation values of the individual spins and of the products of pairs of spins, each of the pair evaluated at a different time, are found explicitly. The influence of a uniform, time‐varying magnetic field upon the model is discussed, and the frequency‐dependent magnetic susceptibility is found in the weak‐field limit. Some fluctuation‐dissipation theorems are derived which relate the susceptibility to the Fourier transform of the time‐dependent correlation function of the magnetization at equilibrium.},
annote = {NULL},
author = {Glauber, Roy J},
rmv = {10.1063/1.1703954},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Glauber - 1963 - Time-Dependent Statistics of the Ising Model.pdf:pdf},
isbn = {0022-2488},
issn = {00222488},
journal = {J. Math. Phys.},
mendeley-groups = {Graphs},
number = {1963},
pages = {294--307},
title = {Time-Dependent Statistics of the Ising Model},
volume = {4},
year = {1963}
}

@article{Nandy2018,
abstract = {Main approaches for learning Bayesian networks can be classified as constraint-based, score-based or hybrid methods. Although high-dimensional consistency results are available for constraint-based methods like the PC algorithm, such results have not been proved for score-based or hybrid methods, and most of the hybrid methods have not even shown to be consistent in the classical setting where the number of variables remains fixed and the sample size tends to infinity. In this paper, we show that consistency of hybrid methods based on greedy equivalence search (GES) can be achieved in the classical setting with adaptive restrictions on the search space that depend on the current state of the algorithm. Moreover, we prove consistency of GES and adaptively restricted GES (ARGES) in several sparse high-dimensional settings. ARGES scales well to sparse graphs with thousands of variables and our simulation study indicates that both GES and ARGES generally outperform the PC algorithm.},
author = {Nandy, Preetam and Hauser, Alain and Maathuis, Marloes H},
rmv = {10.1214/17-AOS1654},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Nandy, Hauser, Maathuis - 2018 - HIGH-DIMENSIONAL CONSISTENCY IN SCORE-BASED AND HYBRID STRUCTURE LEARNING.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Bayesian network,Consistency,Directed acyclic graph (DAG),Greedy equivalence search (GES),High-dimensional data,Hybrid method,Linear structural equation model (linear SEM),Score-based method,Structure learning},
number = {6A},
pages = {3151--3183},
title = {High-dimensional consistency in score-based and hybrid structure learning},
volume = {46},
year = {2018}
}

@article{Zou2009,
abstract = {In computational biology, one often faces the problem of deriving the causal relationship among different elements such as genes, proteins, metabolites, neurons and so on, based upon multi-dimensional temporal data. Currently, there are two common approaches used to explore the network structure among elements. One is the Granger causality approach, and the other is the dynamic Bayesian network inference approach. Both have at least a few thousand publications reported in the literature. A key issue is to choose which approach is used to tackle the data, in particular when they give rise to contradictory results. In this paper, we provide an answer by focusing on a systematic and computationally intensive comparison between the two approaches on both synthesized and experimental data. For synthesized data, a critical point of the data length is found: the dynamic Bayesian network outperforms the Granger causality approach when the data length is short, and vice versa. We then test our results in experimental data of short length which is a common scenario in current biological experiments: it is again confirmed that the dynamic Bayesian network works better. When the data size is short, the dynamic Bayesian network inference performs better than the Granger causality approach; otherwise the Granger causality approach is better.},
author = {Zou, Cunlu and Feng, Jianfeng},
rmv = {10.1186/1471-2105-10-122},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Zou, Feng - 2009 - Granger causality vs. dynamic Bayesian network inference a comparative study.pdf:pdf},
issn = {1471-2105},
journal = {BMC Bioinformatics},
keywords = {Algorithms,Bioinformatics,Combinatorial Libraries,Computational Biology/Bioinformatics,Computer Appl. in Life Sciences,Microarrays},
month = {dec},
number = {1},
pages = {122},
publisher = {BioMed Central},
title = {Granger causality vs. dynamic Bayesian network inference: a comparative study},
volume = {10},
year = {2009}
}

@book{Spirtes2000,
abstract = {2nd ed. / Peter Spirtes, Clark Glymour, and Richard Scheines ; with additional material by David Heckerman [and others]. The authors address the assumptions and methods that allow us to turn observations into causal knowledge, and use even incomplete causal knowledge in planning and prediction to influence and control our environment.What assumptions and methods allow us to turn observations into causal knowledge, and how can even incomplete causal knowledge be used in planning and prediction to influence and control our environment? In this book Peter Spirtes, Clark Glymour, and Richard Scheines address these questions using the formalism of Bayes networks, with results that have been applied in diverse areas of research in the social, behavioral, and physical sciences.The authors show that although experimental and observational study designs may not always permit the same inferences, they are subject to uniform principles. They axiomatize the connection between causal structure and probabilistic independence, explore several varieties of causal indistinguishability, formulate a theory of manipulation, and develop asymptotically reliable procedures for searching over equivalence classes of causal models, including models of categorical data and structural equation models with and without latent variables.The authors show that the relationship between causality and probability can also help to clarify such diverse topics in statistics as the comparative power of experimentation versus observation, Simpson's paradox, errors in regression models, retrospective versus prospective sampling, and variable selection.The second edition contains a new introduction and an extensive survey of advances and applications that have appeared since the first edition was published in 1993. 1. Introduction and advertisement -- 2. Formal preliminaries -- 3. Causation and prediction : axioms and explications -- 4. Statistical indistinguishability -- 5. Discovery algorithms for causally sufficient structures -- 6. Discovery algorithms without causal sufficiency -- 7. Prediction -- 8. Regression, causation, and prediction -- 9. The design of empirical studies -- 10. The structure of the unobserved -- 11. Elaborating linear theories with unmeasured variables -- 12. Prequels and sequels -- 13. Proofs of theorems.},
author = {Spirtes, Peter. and Glymour, Clark N. and Scheines, Richard.},
isbn = {9780262194402},
pages = {543},
publisher = {MIT Press},
title = {Causation, prediction, and search.},
year = {2000}
}

@book{Pearl2000,
abstract = {Chapter headings: Introduction to Probabilities, Graphs, and Causal Models; A Theory of Inferred Causation; Causal Diagrams and the Identification of Causal Effects; Actions, Plans, and Direct Effects; Causality and Structural Models in Social Science and Economics; Simpson's Paradoxon, Confounding, and Collapsibility; The Logic of Structure-Based Counterfactuals; Imperfect Experiments: Bounding Effects and Counterfactuals; Probability of Causation: Interpretation and Identification; The Actual Cause; Epilogue: The Art and Science of Cause and Effect},
author = {Pearl, Judea},
file = {:Users/dominik/Downloads/Judea Pearl - Causality{\_} Models, Reasoning, and Inference-Cambridge University Press (2000) (2).pdf:pdf},
isbn = {0521773628},
pages = {1--386},
title = {Causality Second Edition},
year = {2000}
}

@article{Lindley1972,
abstract = {},
author = {Lindley, Dennis V.},
rmv = {citeulike-article-id:3888442},
file = {},
isbn = {0521773628},
pages = {1--386},
title = {Bayesian statistics, a review, volume 2},
year = {1972}
}


@article{Eberhardt2006,
 ISSN = {00397857, 15730964},
 abstract = {We consider the problems arising from using sequences of experiments to discover the causal structure among a set of variables, none of whom are known ahead of time to be an "outcome". In particular, we present various approaches to resolve conflicts in the experimental results arising from sampling variability in the experiments. We provide a sufficient condition that allows for pooling of data from experiments with different joint distributions over the variables. Satisfaction of the condition allows for an independence test with greater sample size that may resolve some of the conflicts in the experimental results. The pooling condition has its own problems, but should—due to its generality—be informative to techniques for meta-analysis.},
 author = {Frederick Eberhardt},
 journal = {Synthese},
 number = {3},
 pages = {433--442},
 publisher = {Springer},
 title = {A Sufficient Condition for Pooling Data},
 volume = {163},
 year = {2008}
}



@article{Cavagnaro2016,
author = {Cavagnaro, Daniel R and Aranovich, Gabriel J and Mcclure, Samuel M and Pitt, Mark A and Myung, Jay I},
rmv = {10.1007/s11166-016-9242-y},
file = {:Users/dominik/Downloads/Cavagnaro2016{\_}Article{\_}OnTheFunctionalFormOfTemporalD.pdf:pdf},
issn = {0895-5646},
journal = {Journal of Risk and Uncertainty},
keywords = {Temporal discounting,Intertemporal choice,Adaptive},
pages = {233--254},
publisher = {Journal of Risk and Uncertainty},
title = {On the functional form of temporal discounting : An optimized adaptive test},
year = {2016}
}

@article{Dehghannasiri2015,
abstract = {Of major interest to translational genomics is the intervention in gene regulatory networks (GRNs) to affect cell behavior; in particular, to alter pathological phenotypes. Owing to the complexity of GRNs, accurate network inference is practically challenging and GRN models often contain considerable amounts of uncertainty. Considering the cost and time required for conducting biological experiments, it is desirable to have a systematic method for prioritizing potential experiments so that an experiment can be chosen to optimally reduce network uncertainty. Moreover, from a translational perspective it is crucial that GRN uncertainty be quantified and reduced in a manner that pertains to the operational cost that it induces, such as the cost of network intervention. In this work, we utilize the concept of mean objective cost of uncertainty (MOCU) to propose a novel framework for optimal experimental design. In the proposed framework, potential experiments are prioritized based on the MOCU expected to remain after conducting the experiment. Based on this prioritization, one can select an optimal experiment with the largest potential to reduce the pertinent uncertainty present in the current network model. We demonstrate the effectiveness of the proposed method via extensive simulations based on synthetic and real gene regulatory networks.},
author = {Dehghannasiri, Roozbeh and Yoon, Byung Jun and Dougherty, Edward R},
rmv = {10.1109/TCBB.2014.2377733},
file = {:Users/dominik/Downloads/06975098.pdf:pdf},
issn = {15455963},
journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
keywords = {Mean objective cost of uncertainty (MOCU),experimental design,gene regulatory network (GRN),network intervention},
number = {4},
pages = {938--950},
publisher = {IEEE},
title = {Optimal Experimental Design for Gene Regulatory Networks in the Presence of Uncertainty},
volume = {12},
year = {2015}
}


@article{JayI.MyungandMarkA.Pitt2015,
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Jay I. Myung and Mark A. Pitt},
journal = {Psychological Review},
rmv = {10.1038/jid.2014.371},
eprint = {NIHMS150003},
file = {:Users/dominik/Downloads/nihms-123525.pdf:pdf},
isbn = {6176321972},
issn = {15231747},
keywords = {epiblast,gfp fusion,histone h2b-,icm,lineage specification,live imaging,mouse blastocyst,pdgfr $\alpha$,primitive endoderm},
number = {2},
pages = {612--615},
pmid = {1000000221},
title = {Optimal Experimental Design for Model Discrimination},
volume = {135},
year = {2015}
}

@article{Lindgren2018,
abstract = {We consider the minimum cost intervention design problem: Given the essential graph of a causal graph and a cost to intervene on a variable, identify the set of interventions with minimum total cost that can learn any causal graph with the given essential graph. We first show that this problem is NP-hard. We then prove that we can achieve a constant factor approximation to this problem with a greedy algorithm. We then constrain the sparsity of each intervention. We develop an algorithm that returns an intervention design that is nearly optimal in terms of size for sparse graphs with sparse interventions and we discuss how to use it when there are costs on the vertices.},
archivePrefix = {arXiv},
arxivId = {1810.11867},
author = {Lindgren, Erik M. and Dimakis, Alexandros G. and Kocaoglu, Murat and Vishwanath, Sriram},
eprint = {1810.11867},
file = {:Users/dominik/Downloads/7774-experimental-design-for-cost-aware-learning-of-causal-graphs.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {5279--5289},
title = {Experimental design for cost-aware learning of causal graphs},
year = {2018}
}

@article{Steinke2007,
abstract = {Background: Identifying large gene regulatory networks is an important task, while the acquisition of data through perturbation experiments (e.g., gene switches, RNAi, heterozygotes) is expensive. It is thus desirable to use an identification method that effectively incorporates available prior knowledge - such as sparse connectivity - and that allows to design experiments such that maximal information is gained from each one. Results: Our main contributions are twofold: a method for consistent inference of network structure is provided, incorporating prior knowledge about sparse connectivity. The algorithm is time efficient and robust to violations of model assumptions. Moreover, we show how to use it for optimal experimental design, reducing the number of required experiments substantially. We employ sparse linear models, and show how to perform full Bayesian inference for these. We not only estimate a single maximum likelihood network, but compute a posterior distribution over networks, using a novel variant of the expectation propagation method. The representation of uncertainty enables us to do effective experimental design in a standard statistical setting: experiments are selected such that the experiments are maximally informative. Conclusion: Few methods have addressed the design issue so far. Compared to the most well-known one, our method is more transparent, and is shown to perform qualitatively superior. In the former, hard and unrealistic constraints have to be placed on the network structure for mere computational tractability, while such are not required in our method. We demonstrate reconstruction and optimal experimental design capabilities on tasks generated from realistic non-linear network simulators. {\textcopyright} 2007 Steinke et al; licensee BioMed Central Ltd.},
author = {Steinke, Florian and Seeger, Matthias and Tsuda, Koji},
file = {:Users/dominik/Downloads/Steinke2007{\_}Article{\_}ExperimentalDesignForEfficient.pdf:pdf},
issn = {17520509},
journal = {BMC Systems Biology},
pages = {1--15},
title = {Experimental design for efficient identification of gene regulatory networks using sparse Bayesian models},
volume = {1},
year = {2007}
}
@article{Sebastiani2000,
abstract = {When Shannon entropy is used as a criterion in the optimal design of experiments, advantage can be taken of the classical identity representing the joint entropy of parameters and observations as the sum of the marginal entropy of the observations and the preposterior conditional entropy of the parameters. Following previous work in which this idea was used in spatial sampling, the method is applied to standard parameterized Bayesian optimal experimental design. Under suitable conditions, which include non-linear as well as linear regression models, it is shown in a few steps that maximizing the marginal entropy of the sample is equivalent to minimizing the preposterior entropy, the usual Bayesian criterion, thus avoiding the use of conditional distributions. It is shown using this marginal formulation that under normality assumptions every standard model which has a two-point prior distribution on the parameters gives an optimal design supported on a single point. Other results include a new asymptotic formula which applies as the error variance is large and bounds on support size.},
author = {Sebastiani, Paola and Wynn, Henry P.},
rmv = {10.1111/1467-9868.00225},
file = {:Users/dominik/Downloads/1467-9868.00225.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Bayesian optimal design,Finite mixture,Shannon entropy},
number = {1},
pages = {145--157},
title = {Maximum entropy sampling and optimal Bayesian experimental design},
volume = {62},
year = {2000}
}

@article{Tong2001,
abstract = {The task of causal structure discovery from empirical data is a fundamental problem in many areas. Experimental data is crucial for accomplishing this task. However, experiments are typically expensive, and must be selected with great care. This paper uses active learning to determine the experiments that are most informative towards uncovering the underlying structure. We formalize the causal learning task as that of learning the structure of a causal Bayesian network. We consider an active learner that is allowed to conduct experiments, where it intervenes in the domain by setting the values of certain variables. We provide a theoretical framework for the active learning problem, and an algorithm that actively chooses the experiments to perform based on the model learned so far. Experimental results show that active learning can substantially reduce the number of observations required to determine the structure of a domain.},
author = {Tong, Simon and Koller, Daphne},
file = {:Users/dominik/Downloads/822a839111f126de263ca7d7841a05766e25.pdf:pdf},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {863--869},
title = {Active learning for structure in Bayesian networks},
year = {2001}
}

@article{Foster2019,
abstract = {Bayesian optimal experimental design (BOED) is a principled framework for making efficient use of limited experimental resources. Unfortunately, its applicability is hampered by the difficulty of obtaining accurate estimates of the expected information gain (EIG) of an experiment. To address this, we introduce several classes of fast EIG estimators by building on ideas from amortized variational inference. We show theoretically and empirically that these estimators can provide significant gains in speed and accuracy over previous approaches. We further demonstrate the practicality of our approach on a number of end-to-end experiments.},
archivePrefix = {arXiv},
arxivId = {1903.05480},
author = {Foster, Adam and Jankowiak, Martin and Bingham, Eli and Horsfall, Paul and Teh, Yee Whye and Rainforth, Tom and Goodman, Noah},
eprint = {1903.05480},
file = {:Users/dominik/Downloads/9553-variational-bayesian-optimal-experimental-design.pdf:pdf;:Users/dominik/Downloads/9553-variational-bayesian-optimal-experimental-design-supplemental(1)/variational{\_}boed{\_}supplement.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {1--18},
title = {Variational Bayesian Optimal Experimental Design},
year = {2019}
}


@article{Rainforth2018,
abstract = {Many problems in machine learning and statistics involve nested expectations and thus do not permit conventional Monte Carlo (MC) estimation. For such problems, one must nest estimators, such that terms in an outer estimator themselves involve calculation of a separate, nested, estimation. We investigate the statistical implications of nesting MC estimators, including cases of multiple levels of nesting, and establish the conditions under which they converge. We derive corresponding rates of convergence and provide empirical evidence that these rates are observed in practice. We further establish a number of pitfalls that can arise from naive nesting of MC estimators, provide guidelines about how these can be avoided, and lay out novel methods for reformulating certain classes of nested expectation problems into single expectations, leading to improved convergence rates. We demonstrate the applicability of our work by using our results to develop a new estimator for discrete Bayesian experimental design problems and derive error bounds for a class of variational objectives.},
archivePrefix = {arXiv},
arxivId = {1709.06181},
author = {Rainforth, Tom and Cornish, Robert and Yang, Hongseok and Warrington, Andrew and Wood, Frank},
eprint = {1709.06181},
file = {:Users/dominik/Downloads/rainforth18a.pdf:pdf},
isbn = {9781510867963},
journal = {35th International Conference on Machine Learning, ICML 2018},
pages = {6789--6817},
title = {On nesting Monte Carlo estimators},
volume = {10},
year = {2018}
}

@article{Box1967,
abstract = {This paper is concerned with research, the object of which is to discover the mechanism for a particular phenomenon leading to a specific mathematical model. Such investigations are distinguished from those in which the object is merely to estimate the output y of a process over a range of values of the input ∊1, ∊2, {\ldots}, ∊k. Frequently, a number of possible mechanisms are suggested from theoretical considerations leading to a number of different mathematical models. To discriminate among these a sequential procedure is developed in which calculations made after each experiment determine the most discriminatory process conditions for use in the next experiment. The method is illustrated with examples. {\textcopyright} 1967 Taylor {\&} Francis Group, LLC.},
author = {Box, G. E.P. and Hill, W J},
rmv = {10.1080/00401706.1967.10490441},
file = {:Users/dominik/Downloads/box1967.pdf:pdf},
issn = {15372723},
journal = {Technometrics},
number = {1},
pages = {57--71},
title = {Discrimination Among Mechanistic Models},
volume = {9},
year = {1967}
}

@article{Ng2004,
abstract = {One goal of experimentation is to identify which design parameters most significantly influence the mean performance of a system. Another goal is to obtain good parameter estimates for a response model that quantifies how the mean performance depends on influential parameters. Most experimental design techniques focus on one goal at a time. This paper proposes a new entropy-based design criterion for follow-up experiments that jointly identifies the important parameters and reduces the variance of parameter estimates. We simplify computations for the normal linear model by identifying an approximation that leads to a closed form solution. The criterion is applied to an example from the experimental design literature, to a known model and to a critical care facility simulation experiment. {\textcopyright} 2004 Wiley Periodicals, Inc.},
author = {Ng, Szu Hui and Chick, Stephen E.},
rmv = {10.1002/nav.20046},
file = {:Users/dominik/Downloads/Design of follow-up experiments for improving model discrimination and parameter estimation.pdf:pdf},
issn = {0894069X},
journal = {Naval Research Logistics},
keywords = {Design of experiments,Entropy,Model discrimination,Parameter estimation,Simulation},
number = {8},
pages = {1129--1148},
title = {Design of follow-up experiments for improving model discrimination and parameter estimation},
volume = {51},
year = {2004}
}

@article{Reilly1970,
author = {Reilly, P M},
rmv = {10.1002/cjce.5450480213},
file = {:Users/dominik/Downloads/reilly1970.pdf:pdf},
issn = {00084034},
journal = {The Canadian Journal of Chemical Engineering},
number = {2},
pages = {168--173},
title = {Statistical methods in model discrimination},
volume = {48},
year = {1970}
}

@inproceedings{Poole2019,
abstract = {Estimating and optimizing Mutual Information (MI) is core to many problems in machine learning; however, bounding MI in high dimensions is challenging. To establish tractable and scalable objectives, recent work has turned to variational bounds parameterized by neural networks, but the relationships and tradeoffs between these bounds remains unclear. In this work, wc unify these recent developments in a single framework. We find that the existing variational lower bounds degrade when the MI is large, exhibiting either high bias or high variance. To address this problem, we introduce a continuum of lower bounds that encompasses previous bounds and flexibly trades off bias and variance. On high-dimensional, controlled problems, we empirically characterize the bias and variance of the bounds and their gradients and demonstrate the effectiveness of our new bounds for estimation and representation learning.},
archivePrefix = {arXiv},
arxivId = {1905.06922},
author = {Poole, Ben and Ozair, Sherjil and {Van Den Oord}, A{\"{a}}ron and Alemi, Alexander A and Tucker, George},
booktitle = {36th International Conference on Machine Learning, ICML 2019},
eprint = {1905.06922},
file = {:Users/dominik/Downloads/1905.06922.pdf:pdf},
isbn = {9781510886988},
pages = {9036--9049},
title = {On variational bounds of mutual information},
volume = {2019-June},
year = {2019}
}

@inproceedings{Eaton2007,
abstract = {We show how to apply the dynamic programming algorithm of Koivisto and Sood [KS04, Koi06], which computes the exact posterior marginal edge probabilities p(G ij = 1|D) of a DAG G given data D, to the case where the data is obtained by interventions (experiments). In particular, we consider the case where the targets of the interventions are a priori unknown. We show that it is possible to learn the targets of intervention at the same time as learning the causal structure. We apply our exact technique to a biological data set that had previously been analyzed using MCMC [SPP+05, EW06, WGH06].},
author = {Eaton, Daniel and Murphy, Kevin},
booktitle = {Journal of Machine Learning Research},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Eaton, Murphy - Unknown - Exact Bayesian structure learning from uncertain interventions.pdf:pdf},
issn = {15324435},
pages = {107--114},
title = {Exact Bayesian structure learning from uncertain interventions},
volume = {2},
year = {2007}
}

@article{ChalonerK.Verdinelli1987,
abstract = {The environment in which W. S. Gosset (Student) worked as a brewer at Guinness' Brewery at the turn of the century is described fully enough to show how it forced him to confront problems of small sample statistics, using the techniques he picked up from Karl Pearson. R. A. Fisher's interest in human genetics prompted biometrical applications of his mathematical training even as an undergraduate. As soon as he considered Student's work, he perceived its importance and began to extend its applications. Consequently, when he started work at Rothamsted Experimental Station in 1919, he was ready to respond to the experimental problems by developing statistical theory along with appropriate methods of experimental analysis and design. {\textcopyright} 1987, Institute of Mathematical Statistics. All Rights Reserved.},
author = {Chaloner, K. and Verdinelli, I.},
rmv = {10.1214/ss/1177013437},
file = {:Users/dominik/Downloads/euclid.ss.1177009939.pdf:pdf},
issn = {08834237},
journal = {Statistical Science},
keywords = {Analysis of variance,Correlation,Fisher,Gosset,Small samples,Student's t},
number = {1},
pages = {45--54},
title = {Bayesian Experimental Design: A Review},
volume = {2},
year = {1987}
}

@article{Lindley1956,
abstract = {A measure is introduced of the information provided by an experiment. The measure is derived from the work of Shannon [10] and involves the knowledge prior to performing the experiment, expressed through a prior probability distribution over the parameter space. The measure is used to compare some pairs of experiments without reference to prior distributions; this method of comparison is contrasted with the methods discussed by Blackwell. Finally, the measure is applied to provide a solution to some problems of experimental design, where the object of experimentation is not to reach decisions but rather to gain knowledge about the world.},
author = {Lindley, D. V.},
rmv = {10.1214/aoms/1177728069},
file = {:Users/dominik/Downloads/euclid.aoms.1177728069.pdf:pdf},
issn = {0003-4851},
journal = {The Annals of Mathematical Statistics},
number = {4},
pages = {986--1005},
title = {On a Measure of the Information Provided by an Experiment},
volume = {27},
year = {1956}
}

@article{Liepe2013,
abstract = {Our understanding of most biological systems is in its infancy. Learning their structure and intricacies is fraught with challenges, and often side-stepped in favour of studying the function of different gene products in isolation from their physiological context. Constructing and inferring global mathematical models from experimental data is, however, central to systems biology. Different experimental setups provide different insights into such systems. Here we show how we can combine concepts from Bayesian inference and information theory in order to identify experiments that maximize the information content of the resulting data. This approach allows us to incorporate preliminary information; it is global and not constrained to some local neighbourhood in parameter space and it readily yields information on parameter robustness and confidence. Here we develop the theoretical framework and apply it to a range of exemplary problems that highlight how we can improve experimental investigations into the structure and dynamics of biological systems and their behavior. {\textcopyright} 2013 Liepe et al.},
author = {Liepe, Juliane and Filippi, Sarah and Komorowski, Micha{\l} and Stumpf, Michael P.H.},
rmv = {10.1371/journal.pcbi.1002888},
file = {:Users/dominik/Downloads/journal.pcbi.1002888.PDF:PDF},
issn = {1553734X},
journal = {PLoS Computational Biology},
number = {1},
pmid = {23382663},
title = {Maximizing the Information Content of Experiments in Systems Biology},
volume = {9},
year = {2013}
}

@article{bhps,
author ={ESRC Research Centre on Micro-social Change},
title = {British household panel survey},
year = {2003},
journal = {http://iserwww.essex.ac.uk/bhps. Colchester: The Data Archive}
}


@article{Rubenstein2017,
abstract = {We consider the problem of learning the functions computing children from parents in a Structural Causal Model once the underlying causal graph has been identified. This is in some sense the second step after causal discovery. Taking a probabilistic approach to estimating these functions, we derive a natural myopic active learning scheme that identifies the intervention which is optimally informative about all of the unknown functions jointly, given previously observed data. We test the derived algorithms on simple examples, to demonstrate that they produce a structured exploration policy that significantly improves on unstructured base-lines.},
archivePrefix = {arXiv},
arxivId = {1706.10234},
author = {Rubenstein, Paul K. and Tolstikhin, Ilya and Hennig, Philipp and Schoelkopf, Bernhard},
eprint = {1706.10234},
file = {:Users/dominik/Downloads/2.pdf:pdf},
title = {Probabilistic Active Learning of Functions in Structural Causal Models},
journal = {http://arxiv.org/abs/1706.10234},
year = {2017}
}

@article{He2008,
abstract = {The causal discovery from data is important for various scientific investigations. Because we cannot distinguish the different directed acyclic graphs (DAGs) in a Markov equivalence class learned from observational data, we have to collect further information on causal structures from experiments with external interventions. In this paper, we propose an active learning approach for discovering causal structures in which we first find a Markov equivalence class from observational data, and then we orient undirected edges in every chain component via intervention experiments separately. In the experiments, some variables are manipulated through external interventions. We discuss two kinds of intervention experiments, randomized experiment and quasi-experiment. Furthermore, we give two optimal designs of experiments, a batch-intervention design and a sequential-intervention design, to minimize the number of manipulated variables and the set of candidate structures based on the minimax and the maximum entropy criteria. We show theoretically that structural learning can be done locally in subgraphs of chain components without need of checking illegal v-structures and cycles in the whole network and that a Markov equivalence subclass obtained after each intervention can still be depicted as a chain graph.},
author = {He, Yang Bo and Geng, Zhi},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/He, Geng - 2008 - Active Learning of Causal Networks with Intervention Experiments and Optimal Designs.pdf:pdf},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {Active learning,Causal networks,Directed acyclic graphs,Intervention,Markov equivalence class,Optimal design,Structural learning},
pages = {2523--2547},
title = {Active learning of causal networks with intervention experiments and optimal designs},
volume = {9},
year = {2008}
}

@article{Linzner2019,
abstract = {Continuous-time Bayesian Networks (CTBNs) represent a compact yet powerful framework for understanding multivariate time-series data. Given complete data, parameters and structure can be estimated efficiently in closed-form. However, if data is incomplete, the latent states of the CTBN have to be estimated by laboriously simulating the intractable dynamics of the assumed CTBN. This is a problem, especially for structure learning tasks, where this has to be done for each element of super-exponentially growing set of possible structures. In order to circumvent this notorious bottleneck, we develop a novel gradient-based approach to structure learning. Instead of sampling and scoring all possible structures individually, we assume the generator of the CTBN to be composed as a mixture of generators stemming from different structures. In this framework, structure learning can be performed via a gradient-based optimization of mixture weights. We combine this approach with a novel variational method that allows for the calculation of the marginal likelihood of a mixture in closed-form. We proof the scalability of our method by learning structures of previously inaccessible sizes from synthetic and real-world data.},
archivePrefix = {arXiv},
arxivId = {1909.04570},
author = {Linzner, Dominik and Schmidt, Michael and Koeppl, Heinz},
eprint = {1909.04570},
file = {:Users/dominik/Downloads/8631-scalable-structure-learning-of-continuous-time-bayesian-networks-from-incomplete-data.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {1--11},
title = {Scalable Structure Learning of Continuous-Time Bayesian Networks from Incomplete Data},
year = {2019}
}

@article{Spirtes2010,
author = {Spirtes, Peter},
rmv = {10.1177/0049124196024003004},
file = {:Users/dominik/Downloads/spirtes10a.pdf:pdf},
issn = {00491241},
journal = {Journal of Machine Learning Research},
keywords = {bayesian networks,causal inference,causation},
pages = {1643--1662},
title = {Introduction to Causal Inference},
volume = {11},
year = {2010}
}

@article{Ryan2016,
abstract = {Bayesian experimental design is a fast growing area of research with many real-world applications. As computational power has increased over the years, so has the development of simulation-based design methods, which involve a number of algorithms, such as Markov chain Monte Carlo, sequential Monte Carlo and approximate Bayes methods, facilitating more complex design problems to be solved. The Bayesian framework provides a unified approach for incorporating prior information and/or uncertainties regarding the statistical model with a utility function which describes the experimental aims. In this paper, we provide a general overview on the concepts involved in Bayesian experimental design, and focus on describing some of the more commonly used Bayesian utility functions and methods for their estimation, as well as a number of algorithms that are used to search over the design space to find the Bayesian optimal design. We also discuss other computational strategies for further research in Bayesian optimal design.},
author = {Ryan, Elizabeth G. and Drovandi, Christopher C. and Mcgree, James M. and Pettitt, Anthony N.},
rmv = {10.1111/insr.12107},
file = {:Users/dominik/Downloads/insr.12107 (1).pdf:pdf},
issn = {17515823},
journal = {International Statistical Review},
keywords = {Bayesian optimal design,Decision theory,Posterior distribution approximation,Stochastic optimisation,Utility function},
number = {1},
pages = {128--154},
title = {A Review of Modern Computational Algorithms for Bayesian Optimal Design},
volume = {84},
year = {2016}
}

@article{Daniel1996,
abstract = {Fractional factorial, Plackett-Burman, and other multifactor designs are often effective in practice due to factor sparsity. That is, just a few of the many factors studied will have major effects. In those active factors, these designs can have high resolution. We have previously developed a Bayesian method based on the idea of model discrimination that uncovers the active factors. Sometimes, the results of a fractional experiment are ambiguous due to confounding among the possible effects, and more than one model may be consistent with the data. Within the Bayesian construct, we have developed a method for designing a follow-up experiment to resolve this ambiguity. The idea is to choose runs that allow maximum discrimination among the plausible models. This method is more general than methods that algebraically decouple aliased interactions and more appropriate than optimal design methods that require specification of a single model. The method is illustrated through examples of fractional experiments. {\textcopyright} 1996 Taylor {\&} Francis Group, LLC.},
author = {Daniel, R. Daniel and Steinberg, David M. and Box, George},
rmv = {10.1080/00401706.1996.10484538},
file = {:Users/dominik/Downloads/1271297 (1).pdf:pdf},
issn = {15372723},
journal = {Technometrics},
keywords = {Bayesian models,Design augmentation,Factor sparsity,Model discrimination,Screening designs},
number = {4},
pages = {303--313},
title = {Follow-up designs to resolve confounding in multifactor experiments},
volume = {38},
year = {1996}
}

@article{Lewi2009,
author = {Lewi, Jeremy and Butera, Robert and Paninski, Liam},
file = {:Users/dominik/Downloads/lewi-nc08.pdf:pdf},
journal = {Neural Computation},
number = {21},
pages = {619--687},
title = {Sequential Optimal Design of Neurophysiology Experiments},
year = {2009}
}

@article{Soch2016,
abstract = {We derive the Kullback-Leibler divergence for the normal-gamma distribution and show that it is identical to the Bayesian complexity penalty for the univariate general linear model with conjugate priors. Based on this finding, we provide two applications of the KL divergence, one in simulated and one in empirical data.},
archivePrefix = {arXiv},
arxivId = {1611.01437},
author = {Soch, Joram and Allefeld, Carsten},
eprint = {1611.01437},
file = {:Users/dominik/Downloads/1611.01437.pdf:pdf},
pages = {0--10},
title = {Kullback-Leibler Divergence for the Normal-Gamma Distribution},
year = {2016}
}

@article{Yasuda2006,
abstract = {We expand some approximate free energies in the cluster variation method for random Ising models with respect to exchange interactions, and compare them with the Plefka's expansion. It can be clarified that some approximate free energies in the cluster variation method include all terms relating to specific clusters (or diagrams) in Plefka's expansion. Revealing the relationship between Plefka's expansion and the cluster variation method allows us to understand how the cluster variation method treats correlations among nodes.},
author = {Yasuda, Muneki and Tanaka, Kazuyuki},
rmv = {10.1143/JPSJ.75.084006},
file = {:Users/dominik/Library/Application Support/Mendeley Desktop/Downloaded/Yasuda, Tanaka - 2006 - The relationship between Plefka's expansion and the cluster variation method.pdf:pdf},
issn = {00319015},
journal = {Journal of the Physical Society of Japan},
keywords = {Bethe approximation,Cluster variation method,Plefka's expansion,Probabilistic information processing,Random Ising model,Statistical-mechanical informatics,TAP equation},
number = {8},
title = {The relationship between Plefka's expansion and the cluster variation method},
volume = {75},
year = {2006}
}

@inproceedings{10.1145/3233188.3233217,
author = {Prangemeier, Tim and Wildner, Christian and Hanst, Maleen and Koeppl, Heinz},
title = {Maximizing Information Gain for the Characterization of Biomolecular Circuits},
year = {2018},
isbn = {9781450357111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
rmv = {10.1145/3233188.3233217},
abstract = {Quantitatively predictive models of biomolecular circuits are important tools for the design of synthetic biology and molecular communication circuits. The information content of typical time-lapse single-cell data for the inference of kinetic parameters is not only limited by measurement uncertainty and intrinsic stochasticity but also by the employed perturbations. Novel microfluidic devices enable the synthesis of temporal chemical concentration profiles. The informativeness of a perturbation can be quantified based on mutual information. We propose an approximate method to perform optimal experimental design of such perturbation profiles. To estimate the mutual information we perform a multivariate log-normal approximation of the joint distribution over parameters and observations and scan the design space using Metropolis-Hastings sampling. The method is demonstrated by finding optimal perturbation sequences for synthetic case studies on a gene expression model with varying reporter characteristics.},
booktitle = {Proceedings of the 5th ACM International Conference on Nanoscale Computing and Communication},
articleno = {1},
numpages = {6},
keywords = {information theory, information gain, chemical reaction networks, synthetic biology molecular communication, optimal experimental design, molecular programming},
location = {Reykjavik, Iceland},
series = {NANOCOM '18}
}

@INPROCEEDINGS{6426738,
  author={Zechner, C. and Nandy, P. and Unger, M. and Koeppl, H.},
  booktitle={2012 IEEE 51st IEEE Conference on Decision and Control (CDC)}, 
  title={Optimal variational perturbations for the inference of stochastic reaction dynamics}, 
  year={2012},
  volume={},
  number={},
  pages={5336-5341},
  rmv={10.1109/CDC.2012.6426738}}
  
  @book{norris_1997, place={Cambridge}, series={Cambridge Series in Statistical and Probabilistic Mathematics}, title={Markov Chains}, publisher={Cambridge University Press}, author={Norris, J. R.}, year={1997}, collection={Cambridge Series in Statistical and Probabilistic Mathematics}}