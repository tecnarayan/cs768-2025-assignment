\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Simonyan and Zisserman(2015)]{DBLP:journals/corr/SimonyanZ14a}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In Yoshua Bengio and Yann LeCun, editors, \emph{3rd International
  Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May
  7-9, 2015, Conference Track Proceedings}, 2015.
\newblock URL \url{http://arxiv.org/abs/1409.1556}.

\bibitem[Chen et~al.(2019)Chen, Liu, Kira, Wang, and Huang]{chen2019closer}
Wei-Yu Chen, Yen-Cheng Liu, Zsolt Kira, Yu-Chiang~Frank Wang, and Jia-Bin
  Huang.
\newblock A closer look at few-shot classification.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Pan and Yang(2009)]{pan2009survey}
Sinno~Jialin Pan and Qiang Yang.
\newblock A survey on transfer learning.
\newblock \emph{IEEE Transactions on knowledge and data engineering},
  22\penalty0 (10):\penalty0 1345--1359, 2009.

\bibitem[Ganin and Lempitsky(2015)]{ganin2015unsupervised}
Yaroslav Ganin and Victor Lempitsky.
\newblock Unsupervised domain adaptation by backpropagation.
\newblock In \emph{International conference on machine learning}, pages
  1180--1189. PMLR, 2015.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  1126--1135. PMLR, 2017.

\bibitem[Ravi and Larochelle(2017)]{RaviL17}
Sachin Ravi and Hugo Larochelle.
\newblock Optimization as a model for few-shot learning.
\newblock In \emph{5th International Conference on Learning Representations,
  {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track
  Proceedings}, 2017.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Kavukcuoglu, and
  Wierstra]{VinyalsBLKW16}
Oriol Vinyals, Charles Blundell, Tim Lillicrap, Koray Kavukcuoglu, and Daan
  Wierstra.
\newblock Matching networks for one shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems 29: Annual
  Conference on Neural Information Processing Systems 2016, December 5-10,
  2016, Barcelona, Spain}, pages 3630--3638, 2016.

\bibitem[Snell et~al.(2017)Snell, Swersky, and Zemel]{Prototypical2017}
Jake Snell, Kevin Swersky, and Richard~S. Zemel.
\newblock Prototypical networks for few-shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4077--4087, 2017.

\bibitem[Hariharan and Girshick(2017)]{HariharanG17}
Bharath Hariharan and Ross~B. Girshick.
\newblock Low-shot visual recognition by shrinking and hallucinating features.
\newblock In \emph{{IEEE} International Conference on Computer Vision, {ICCV}
  2017, Venice, Italy, October 22-29, 2017}, pages 3037--3046. {IEEE} Computer
  Society, 2017.

\bibitem[Wang et~al.(2018)Wang, Girshick, Hebert, and Hariharan]{WangGHH18}
Yu{-}Xiong Wang, Ross~B. Girshick, Martial Hebert, and Bharath Hariharan.
\newblock Low-shot learning from imaginary data.
\newblock In \emph{2018 {IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2018, Salt Lake City, UT, USA, June 18-22, 2018}, pages
  7278--7286. Computer Vision Foundation / {IEEE} Computer Society, 2018.

\bibitem[Gidaris and Komodakis(2018)]{GidarisK18}
Spyros Gidaris and Nikos Komodakis.
\newblock Dynamic few-shot visual learning without forgetting.
\newblock In \emph{2018 {IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2018, Salt Lake City, UT, USA, June 18-22, 2018}, pages
  4367--4375. Computer Vision Foundation / {IEEE} Computer Society, 2018.

\bibitem[Qi et~al.(2018)Qi, Brown, and Lowe]{QiBL18}
Hang Qi, Matthew Brown, and David~G. Lowe.
\newblock Low-shot learning with imprinted weights.
\newblock In \emph{2018 {IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2018, Salt Lake City, UT, USA, June 18-22, 2018}, pages
  5822--5830. Computer Vision Foundation / {IEEE} Computer Society, 2018.

\bibitem[Yang et~al.(2021)Yang, Liu, and Xu]{yang2020free}
Shuo Yang, Lu~Liu, and Min Xu.
\newblock Free lunch for few-shot learning: Distribution calibration.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Huynh et~al.(2021)Huynh, Phung, and Zhao]{huynh2021optimal}
Viet Huynh, Dinh~Q Phung, and He~Zhao.
\newblock Optimal transport for deep generative models: State of the art and
  research challenges.
\newblock In \emph{IJCAI}, pages 4450--4457, 2021.

\bibitem[Zhao et~al.(2021)Zhao, Phung, Huynh, Le, and Buntine]{zhao2020neural}
He~Zhao, Dinh Phung, Viet Huynh, Trung Le, and Wray Buntine.
\newblock Neural topic model via optimal transport.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Wang et~al.(2022)Wang, Guo, Zhao, Zheng, Tanwisuth, Chen, and
  Zhou]{wang2021representing}
Dongsheng Wang, Dandan Guo, He~Zhao, Huangjie Zheng, Korawat Tanwisuth,
  Bo~Chen, and Mingyuan Zhou.
\newblock Representing mixtures of word embeddings with mixtures of topic
  embeddings.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Bui et~al.(2022)Bui, Le, Tran, Zhao, and Phung]{bui2021unified}
Anh~Tuan Bui, Trung Le, Quan~Hung Tran, He~Zhao, and Dinh Phung.
\newblock A unified {W}asserstein distributional robustness framework for
  adversarial training.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Guo et~al.(2022)Guo, Li, Zheng, Zhao, Zhou, and Zha]{guo2022learning}
Dandan Guo, Zhuo Li, Meixi Zheng, He~Zhao, Mingyuan Zhou, and Hongyuan Zha.
\newblock Learning to re-weight examples with optimal transport for imbalanced
  classification.
\newblock \emph{arXiv preprint arXiv:2208.02951}, 2022.

\bibitem[Peyr{\'{e}} and Cuturi(2019)]{PeyreC2019OT}
Gabriel Peyr{\'{e}} and Marco Cuturi.
\newblock Computational optimal transport.
\newblock \emph{Found. Trends Mach. Learn.}, 11\penalty0 (5-6):\penalty0
  355--607, 2019.

\bibitem[Cuturi(2013)]{cuturi2013sinkhorn}
Marco Cuturi.
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock \emph{Advances in neural information processing systems},
  26:\penalty0 2292--2300, 2013.

\bibitem[Tukey et~al.(1977)]{tukey1977exploratory}
John~W Tukey et~al.
\newblock \emph{Exploratory data analysis}, volume~2.
\newblock Reading, Mass., 1977.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock volume~27, 2014.

\bibitem[Rumelhart et~al.(1986)Rumelhart, Hinton, and
  Williams]{rumelhart1986learning}
David~E Rumelhart, Geoffrey~E Hinton, and Ronald~J Williams.
\newblock Learning representations by back-propagating errors.
\newblock \emph{nature}, 323\penalty0 (6088):\penalty0 533--536, 1986.

\bibitem[Zhang et~al.(2018)Zhang, Che, Ghahramani, Bengio, and
  Song]{zhang2018metagan}
Ruixiang Zhang, Tong Che, Zoubin Ghahramani, Yoshua Bengio, and Yangqiu Song.
\newblock Metagan: An adversarial approach to few-shot learning.
\newblock \emph{NeurIPS}, 2:\penalty0 8, 2018.

\bibitem[Gao et~al.(2018)Gao, Shou, Zareian, Zhang, and Chang]{GaoSZZC18}
Hang Gao, Zheng Shou, Alireza Zareian, Hanwang Zhang, and Shih{-}Fu Chang.
\newblock Low-shot learning via covariance-preserving adversarial augmentation
  networks.
\newblock In \emph{Advances in Neural Information Processing Systems 31: Annual
  Conference on Neural Information Processing Systems 2018, NeurIPS 2018,
  December 3-8, 2018, Montr{\'{e}}al, Canada}, pages 983--993, 2018.

\bibitem[Schwartz et~al.(2018)Schwartz, Karlinsky, Shtok, Harary, Marder,
  Kumar, Feris, Giryes, and Bronstein]{SchwartzKSHMKFG18}
Eli Schwartz, Leonid Karlinsky, Joseph Shtok, Sivan Harary, Mattias Marder,
  Abhishek Kumar, Rog{\'{e}}rio~Schmidt Feris, Raja Giryes, and Alexander~M.
  Bronstein.
\newblock Delta-encoder: an effective sample synthesis method for few-shot
  object recognition.
\newblock In \emph{Advances in Neural Information Processing Systems 31: Annual
  Conference on Neural Information Processing Systems 2018, NeurIPS 2018,
  December 3-8, 2018, Montr{\'{e}}al, Canada}, pages 2850--2860, 2018.

\bibitem[Xian et~al.(2018)Xian, Lorenz, Schiele, and Akata]{xian2018feature}
Yongqin Xian, Tobias Lorenz, Bernt Schiele, and Zeynep Akata.
\newblock Feature generating networks for zero-shot learning.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 5542--5551, 2018.

\bibitem[Zhang et~al.(2019)Zhang, Zhao, Ni, Xu, and Yang]{ZhangZNXY19}
Jian Zhang, Chenglong Zhao, Bingbing Ni, Minghao Xu, and Xiaokang Yang.
\newblock Variational few-shot learning.
\newblock In \emph{2019 {IEEE/CVF} International Conference on Computer Vision,
  {ICCV} 2019, Seoul, Korea (South), October 27 - November 2, 2019}, pages
  1685--1694. {IEEE}, 2019.

\bibitem[Zhang et~al.(2020)Zhang, Cai, Lin, and Shen]{zhang2020deepemd}
Chi Zhang, Yujun Cai, Guosheng Lin, and Chunhua Shen.
\newblock Deepemd: Few-shot image classification with differentiable earth
  mover's distance and structured classifiers.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 12203--12213, 2020.

\bibitem[dan Guo et~al.(2022)dan Guo, Tian, Zhang, Zhou, and
  Zha]{dan2022learning}
Dan dan Guo, Long Tian, Minghe Zhang, Mingyuan Zhou, and Hongyuan Zha.
\newblock Learning prototype-oriented set representations for meta-learning.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Yurochkin et~al.(2019)Yurochkin, Claici, Chien, Mirzazadeh, and
  Solomon]{YurochkinCCMS19}
Mikhail Yurochkin, Sebastian Claici, Edward Chien, Farzaneh Mirzazadeh, and
  Justin~M. Solomon.
\newblock Hierarchical optimal transport for document representation.
\newblock In Hanna~M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence
  d'Alch{\'{e}}{-}Buc, Emily~B. Fox, and Roman Garnett, editors, \emph{Advances
  in Neural Information Processing Systems 32: Annual Conference on Neural
  Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019,
  Vancouver, BC, Canada}, pages 1599--1609, 2019.

\bibitem[Ravi and Larochelle(2016)]{ravi2016optimization}
Sachin Ravi and Hugo Larochelle.
\newblock Optimization as a model for few-shot learning.
\newblock 2016.

\bibitem[Ren et~al.(2018)Ren, Triantafillou, Ravi, Snell, Swersky, Tenenbaum,
  Larochelle, and Zemel]{DBLP:conf/iclr/RenTRSSTLZ18}
Mengye Ren, Eleni Triantafillou, Sachin Ravi, Jake Snell, Kevin Swersky,
  Joshua~B. Tenenbaum, Hugo Larochelle, and Richard~S. Zemel.
\newblock Meta-learning for semi-supervised few-shot classification.
\newblock In \emph{6th International Conference on Learning Representations,
  {ICLR} 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track
  Proceedings}. OpenReview.net, 2018.
\newblock URL \url{https://openreview.net/forum?id=HJcSzz-CZ}.

\bibitem[Welinder et~al.(2010)Welinder, Branson, Mita, Wah, Schroff, Belongie,
  and Perona]{welinder2010caltech}
Peter Welinder, Steve Branson, Takeshi Mita, Catherine Wah, Florian Schroff,
  Serge Belongie, and Pietro Perona.
\newblock Caltech-ucsd birds 200.
\newblock 2010.

\bibitem[Bertinetto et~al.(2018{\natexlab{a}})Bertinetto, Henriques, Torr, and
  Vedaldi]{cifadataset}
Luca Bertinetto, Joao~F Henriques, Philip~HS Torr, and Andrea Vedaldi.
\newblock Meta-learning with differentiable closed-form solvers.
\newblock \emph{arXiv preprint arXiv:1805.08136}, 2018{\natexlab{a}}.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and Fei{-}Fei]{imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael~S. Bernstein,
  Alexander~C. Berg, and Li~Fei{-}Fei.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{Int. J. Comput. Vis.}, 115\penalty0 (3):\penalty0 211--252,
  2015.

\bibitem[Krizhevsky et~al.(2010)Krizhevsky, Nair, and
  Hinton]{krizhevsky2010cifar}
Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.
\newblock Cifar-10 (canadian institute for advanced research).
\newblock \emph{URL http://www. cs. toronto. edu/kriz/cifar. html}, 5:\penalty0
  4, 2010.

\bibitem[Mangla et~al.(2020)Mangla, Kumari, Sinha, Singh, Krishnamurthy, and
  Balasubramanian]{mangla2020charting}
Puneet Mangla, Nupur Kumari, Abhishek Sinha, Mayank Singh, Balaji
  Krishnamurthy, and Vineeth~N Balasubramanian.
\newblock Charting the right manifold: Manifold mixup for few-shot learning.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, pages 2218--2227, 2020.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, et~al.]{pedregosa2011scikit}
Fabian Pedregosa, Ga{\"e}l Varoquaux, Alexandre Gramfort, Vincent Michel,
  Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
  Weiss, Vincent Dubourg, et~al.
\newblock Scikit-learn: Machine learning in python.
\newblock \emph{the Journal of machine Learning research}, 12:\penalty0
  2825--2830, 2011.

\bibitem[Liu et~al.(2020{\natexlab{a}})Liu, Schiele, and Sun]{LiuSS20}
Yaoyao Liu, Bernt Schiele, and Qianru Sun.
\newblock An ensemble of epoch-wise empirical bayes for few-shot learning.
\newblock In Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan{-}Michael
  Frahm, editors, \emph{Computer Vision - {ECCV} 2020 - 16th European
  Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part {XVI}}, volume
  12361 of \emph{Lecture Notes in Computer Science}, pages 404--421. Springer,
  2020{\natexlab{a}}.

\bibitem[Rusu et~al.(2019)Rusu, Rao, Sygnowski, Vinyals, Pascanu, Osindero, and
  Hadsell]{RusuRSVPOH19}
Andrei~A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu,
  Simon Osindero, and Raia Hadsell.
\newblock Meta-learning with latent embedding optimization.
\newblock In \emph{7th International Conference on Learning Representations,
  {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019}. OpenReview.net, 2019.

\bibitem[Liu et~al.(2020{\natexlab{b}})Liu, Cao, Lin, Li, Zhang, Long, and
  Hu]{LiuCLL0LH20}
Bin Liu, Yue Cao, Yutong Lin, Qi~Li, Zheng Zhang, Mingsheng Long, and Han Hu.
\newblock Negative margin matters: Understanding margin in few-shot
  classification.
\newblock In Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan{-}Michael
  Frahm, editors, \emph{Computer Vision - {ECCV} 2020 - 16th European
  Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part {IV}}, volume
  12349 of \emph{Lecture Notes in Computer Science}, pages 438--455. Springer,
  2020{\natexlab{b}}.

\bibitem[Tian et~al.(2020)Tian, Wang, Krishnan, Tenenbaum, and
  Isola]{tian2020rethinking}
Yonglong Tian, Yue Wang, Dilip Krishnan, Joshua~B Tenenbaum, and Phillip Isola.
\newblock Rethinking few-shot image classification: a good embedding is all you
  need?
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part XIV 16}, pages 266--282.
  Springer, 2020.

\bibitem[Sung et~al.(2018)Sung, Yang, Zhang, Xiang, Torr, and
  Hospedales]{sung2018learning}
Flood Sung, Yongxin Yang, Li~Zhang, Tao Xiang, Philip~HS Torr, and Timothy~M
  Hospedales.
\newblock Learning to compare: Relation network for few-shot learning.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1199--1208, 2018.

\bibitem[Bertinetto et~al.(2018{\natexlab{b}})Bertinetto, Henriques, Torr, and
  Vedaldi]{bertinetto2018meta}
Luca Bertinetto, Joao~F Henriques, Philip~HS Torr, and Andrea Vedaldi.
\newblock Meta-learning with differentiable closed-form solvers.
\newblock \emph{arXiv preprint arXiv:1805.08136}, 2018{\natexlab{b}}.

\bibitem[Ravichandran et~al.(2019)Ravichandran, Bhotika, and
  Soatto]{ravichandran2019few}
Avinash Ravichandran, Rahul Bhotika, and Stefano Soatto.
\newblock Few-shot learning with embedded class models and shot-free meta
  training.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 331--339, 2019.

\bibitem[Lee et~al.(2019)Lee, Maji, Ravichandran, and Soatto]{lee2019meta}
Kwonjoon Lee, Subhransu Maji, Avinash Ravichandran, and Stefano Soatto.
\newblock Meta-learning with differentiable convex optimization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 10657--10665, 2019.

\bibitem[Chizat et~al.(2020)Chizat, Roussillon, L{\'{e}}ger, Vialard, and
  Peyr{\'{e}}]{ChizatRLVP20}
L{\'{e}}na{\"{\i}}c Chizat, Pierre Roussillon, Flavien L{\'{e}}ger,
  Fran{\c{c}}ois{-}Xavier Vialard, and Gabriel Peyr{\'{e}}.
\newblock Faster wasserstein distance estimation with the sinkhorn divergence.
\newblock In \emph{Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020,
  December 6-12, 2020, virtual}, 2020.

\bibitem[Altschuler et~al.(2017)Altschuler, Weed, and Rigollet]{AltschulerWR17}
Jason Altschuler, Jonathan Weed, and Philippe Rigollet.
\newblock Near-linear time approximation algorithms for optimal transport via
  sinkhorn iteration.
\newblock In \emph{Advances in Neural Information Processing Systems 30: Annual
  Conference on Neural Information Processing Systems 2017, December 4-9, 2017,
  Long Beach, CA, {USA}}, pages 1964--1974, 2017.

\bibitem[Dvurechensky et~al.(2018)Dvurechensky, Gasnikov, and
  Kroshnin]{DvurechenskyGK18}
Pavel~E. Dvurechensky, Alexander~V. Gasnikov, and Alexey Kroshnin.
\newblock Computational optimal transport: Complexity by accelerated gradient
  descent is better than by sinkhorn's algorithm.
\newblock In Jennifer~G. Dy and Andreas Krause, editors, \emph{Proceedings of
  the 35th International Conference on Machine Learning, {ICML} 2018,
  Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15, 2018}, volume~80 of
  \emph{Proceedings of Machine Learning Research}, pages 1366--1375. {PMLR},
  2018.

\bibitem[Van~der Maaten and Hinton(2008)]{van2008visualizing}
Laurens Van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock \emph{Journal of machine learning research}, 9\penalty0 (11), 2008.

\end{thebibliography}
