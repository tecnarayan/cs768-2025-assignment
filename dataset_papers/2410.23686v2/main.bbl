\begin{thebibliography}{10}

\bibitem{abu-el-haija_MixHopHigherOrderGraph_2019}
Sami {Abu-El-Haija}, Bryan Perozzi, Amol Kapoor, Nazanin Alipourfard, Kristina Lerman, Hrayr Harutyunyan, Greg~Ver Steeg, and Aram Galstyan.
\newblock {{MixHop}}: {{Higher-Order Graph Convolutional Architectures}} via {{Sparsified Neighborhood Mixing}}.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, pages 21--29, {Long Beach, USA}, 2019. {PMLR}.

\bibitem{alon_BottleneckGraphNeural_2021}
Uri Alon and Eran Yahav.
\newblock On the {{Bottleneck}} of {{Graph Neural Networks}} and its {{Practical Implications}}.
\newblock In {\em International {{Conference}} on {{Learning Representations}}}, {Virtual Only}, 2021.

\bibitem{baek_AccurateLearningGraph_2022}
Jinheon Baek, Minki Kang, and Sung~Ju Hwang.
\newblock Accurate {{Learning}} of {{Graph Representations}} with {{Graph Multiset Pooling}}.
\newblock In {\em International {{Conference}} on {{Learning Representations}}}, {virtual}, 2022.

\bibitem{Banach1922}
Stefan Banach.
\newblock Sur les opérations dans les ensembles abstraits et leur application aux équations intégrales.
\newblock {\em Fundamenta Mathematicae}, 3(1):133--181, 1922.

\bibitem{bo_LowfrequencyInformationGraph_2021}
Deyu Bo, Xiao Wang, Chuan Shi, and Huawei Shen.
\newblock Beyond {{Low-frequency Information}} in {{Graph Convolutional Networks}}.
\newblock In {\em {{AAAI Conference}} on {{Artificial Intelligence}}}, volume~35, pages 3950--3957, {virtual}, 2021.

\bibitem{bresson_ResidualGatedGraph_2018}
Xavier Bresson and Thomas Laurent.
\newblock Residual {{Gated Graph ConvNets}}, 2018.

\bibitem{cai_ConnectionMPNNGraph_2023}
Chen Cai, Truong~Son Hy, Rose Yu, and Yusu Wang.
\newblock On the {{Connection Between MPNN}} and {{Graph Transformer}}.
\newblock In {\em Proceedings of the 40th {{International Conference}} on {{Machine Learning}}}, pages 3408--3430. {PMLR}, 2023.

\bibitem{cai_NoteOverSmoothingGraph_2020}
Chen Cai and Yusu Wang.
\newblock A {{Note}} on {{Over-Smoothing}} for {{Graph Neural Networks}}.
\newblock {\em arXiv:2006.13318 [cs, stat]}, 2020.

\bibitem{chen_NAGphormerTokenizedGraph_2023}
Jinsong Chen, Kaiyuan Gao, Gaichao Li, and Kun He.
\newblock {{NAGphormer}}: {{A Tokenized Graph Transformer}} for {{Node Classification}} in {{Large Graphs}}.
\newblock In {\em International {{Conference}} for {{Learning Representations}}}, 2023.

\bibitem{chen_SimpleDeepGraph_2020}
Ming Chen, Zhewei Wei, Zengfeng Huang, Bolin Ding, and Yaliang Li.
\newblock Simple and {{Deep Graph Convolutional Networks}}.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, pages 1725--1735, {virtual}, 2020. {PMLR}.

\bibitem{chien_AdaptiveUniversalGeneralized_2022}
Eli Chien, Jianhao Peng, Pan Li, and Olgica Milenkovic.
\newblock Adaptive {{Universal Generalized PageRank Graph Neural Network}}.
\newblock In {\em International {{Conference}} on {{Learning Representations}}}, {virtual}, 2022.

\bibitem{deac_ExpanderGraphPropagation_2022}
Andreea Deac, Marc Lackenby, and Petar Veli{\v c}kovi{\'c}.
\newblock Expander {{Graph Propagation}}.
\newblock In {\em {{Learning}} on {{Graphs Conference}}}, volume 198, page~38. {PMLR}, 2022.

\bibitem{defferrard_ConvolutionalNeuralNetworks_2017}
Micha{\"e}l Defferrard, Xavier Bresson, and Pierre Vandergheynst.
\newblock Convolutional {{Neural Networks}} on {{Graphs}} with {{Fast Localized Spectral Filtering}}.
\newblock {\em arXiv:1606.09375 [cs, stat]}, 2017.

\bibitem{digiovanni_OverSquashingMessagePassing_2023}
Francesco Di~Giovanni, Lorenzo Giusti, Federico Barbero, Giulia Luise, Pietro Lio', and Michael Bronstein.
\newblock On {{Over-Squashing}} in {{Message Passing Neural Networks}}: {{The Impact}} of {{Width}}, {{Depth}}, and {{Topology}}.
\newblock In {\em International Conference on Machine Learning}, 2023.

\bibitem{giovanni_HowDoesOversquashing_2023}
Francesco Di~Giovanni, T.~Konstantin Rusch, Michael Bronstein, Andreea Deac, Marc Lackenby, Siddhartha Mishra, and Petar Veli{\v c}kovi{\'c}.
\newblock How does over-squashing affect the power of {{GNNs}}?
\newblock {\em Transactions on Machine Learning Research}, 2023.

\bibitem{diao_RelationalAttentionGeneralizing_2023a}
Cameron Diao and Ricky Loynd.
\newblock Relational {{Attention}}: {{Generalizing Transformers}} for {{Graph-Structured Tasks}}.
\newblock In {\em {{International Conference}} on {{Learning Representations}}}, 2023.

\bibitem{dwivedi_LongRangeGraph_2022}
Vijay~Prakash Dwivedi, Ladislav Ramp{\'a}{\v s}ek, Michael Galkin, Ali Parviz, Guy Wolf, Anh~Tuan Luu, and Dominique Beaini.
\newblock Long {{Range Graph Benchmark}}.
\newblock In {\em Advances in {{Neural Information Processing Systems}}}, volume~35, pages 22326--22340, 2022.

\bibitem{fey_FastGraphRepresentation_2019}
Matthias Fey and Jan~Eric Lenssen.
\newblock Fast {{Graph Representation Learning}} with {{PyTorch Geometric}}.
\newblock In {\em International {{Conference}} on {{Learning Representations Workshop}} on {{Graphs}} and {{Manifolds}}}, 2019.

\bibitem{franceschi_LearningDiscreteStructures_2019}
Luca Franceschi, Mathias Niepert, Massimiliano Pontil, and Xiao He.
\newblock Learning {{Discrete Structures}} for {{Graph Neural Networks}}.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, pages 1972--1982. {PMLR}, 2019.

\bibitem{gao_GraphUNets_2019}
Hongyang Gao and Shuiwang Ji.
\newblock Graph {{U-Nets}}.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, pages 2083--2092, {Long Beach, California, USA}, 2019. {PMLR}.

\bibitem{gasteiger_PredictThenPropagate_2018}
Johannes Gasteiger, Aleksandar Bojchevski, and Stephan G{\"u}nnemann.
\newblock Predict then {{Propagate}}: {{Graph Neural Networks}} meet {{Personalized PageRank}}.
\newblock In {\em International {{Conference}} on {{Learning Representations}}}, {Addis Ababa, Ethiopia}, 2018.

\bibitem{gilmer_NeuralMessagePassing_2017}
Justin Gilmer, Samuel~S. Schoenholz, Patrick~F. Riley, Oriol Vinyals, and George~E. Dahl.
\newblock Neural {{Message Passing}} for {{Quantum Chemistry}}.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, volume~70, pages 1263--1272, {Sydney, Australia}, 2017. {PMLR}.

\bibitem{gu_EfficientlyModelingLong_2021}
Albert Gu, Karan Goel, and Christopher Re.
\newblock Efficiently {{Modeling Long Sequences}} with {{Structured State Spaces}}.
\newblock In {\em International {{Conference}} on {{Learning Representations}}}, 2021.

\bibitem{gutteridge_DRewDynamicallyRewired_2023}
Benjamin Gutteridge, Xiaowen Dong, Michael~M. Bronstein, and Francesco~Di Giovanni.
\newblock {{DRew}}: {{Dynamically Rewired Message Passing}} with {{Delay}}.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, pages 12252--12267. {PMLR}, 2023.

\bibitem{hamilton_InductiveRepresentationLearning_2017}
William~L. Hamilton, Rex Ying, and Jure Leskovec.
\newblock Inductive representation learning on large graphs.
\newblock In {\em International {{Conference}} on {{Neural Information Processing Systems}}}, pages 1025--1035, {Red Hook, USA}, 2017. {Curran Associates Inc.}

\bibitem{hochreiter_LongShortTermMemory_1997}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long {{Short-Term Memory}}.
\newblock {\em Neural Computation}, 9(8):1735--1780, 1997.

\bibitem{hu_OpenGraphBenchmark_2020}
Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec.
\newblock Open {{Graph Benchmark}}: {{Datasets}} for {{Machine Learning}} on {{Graphs}}.
\newblock In {\em Advances in {{Neural Information Processing Systems}}}, volume~33, pages 22118--22133. {Curran Associates, Inc.}, 2020.

\bibitem{hu*_StrategiesPretrainingGraph_2019}
Weihua Hu*, Bowen Liu*, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, and Jure Leskovec.
\newblock Strategies for {{Pre-training Graph Neural Networks}}.
\newblock In {\em International {{Conference}} on {{Learning Representations}}}, 2019.

\bibitem{huang_GoingDeeperPermutationSensitive_2022}
Zhongyu Huang, Yingheng Wang, Chaozhuo Li, and Huiguang He.
\newblock Going {{Deeper}} into {{Permutation-Sensitive Graph Neural Networks}}.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, pages 9377--9409, {Baltimore, Maryland, USA}, 2022. {PMLR}.

\bibitem{hwang_RevisitingVirtualNodes_2021}
EunJeong Hwang, Veronika Thost, Shib~Sankar Dasgupta, and Tengfei Ma.
\newblock Revisiting {{Virtual Nodes}} in {{Graph Neural Networks}} for {{Link Prediction}}.
\newblock 2021.

\bibitem{kazi_DifferentiableGraphModule_2023}
Anees Kazi, Luca Cosmo, Seyed-Ahmad Ahmadi, Nassir Navab, and Michael~M. Bronstein.
\newblock Differentiable {{Graph Module}} ({{DGM}}) for {{Graph Convolutional Networks}}.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 45(2):1606--1617, 2023.

\bibitem{kingma_AdamMethodStochastic_2015}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {{A Method}} for {{Stochastic Optimization}}.
\newblock In {\em International {{Conference}} for {{Learning Representations}}}, {San Diego, USA}, 2015.

\bibitem{kipf_SemiSupervisedClassificationGraph_2017}
Thomas~N. Kipf and Max Welling.
\newblock Semi-{{Supervised Classification}} with {{Graph Convolutional Networks}}.
\newblock In {\em International {{Conference}} on {{Learning Representations}}}, {Toulon, France}, 2017.

\bibitem{klicpera_DiffusionImprovesGraph_2019}
Johannes Klicpera, Stefan {Wei{\ss} enberger}, and Stephan G{\"u}nnemann.
\newblock Diffusion {{Improves Graph Learning}}.
\newblock In {\em International {{Conference}} on {{Advances}} in {{Neural Information Processing Systems}}}, volume~32, pages 13333--13345, {Vancouver, Canada}, 2019. {Curran Associates, Inc.}

\bibitem{kreuzer_RethinkingGraphTransformers_2021}
Devin Kreuzer, Dominique Beaini, Will Hamilton, Vincent L{\'e}tourneau, and Prudencio Tossou.
\newblock Rethinking {{Graph Transformers}} with {{Spectral Attention}}.
\newblock In {\em Advances in {{Neural Information Processing Systems}}}, volume~34, pages 21618--21629. {Curran Associates, Inc.}, 2021.

\bibitem{krizhevsky_ImageNetClassificationDeep_2017}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E. Hinton.
\newblock {{ImageNet}} classification with deep convolutional neural networks.
\newblock {\em Communications of the ACM}, 60(6):84--90, 2017.

\bibitem{lee_SelfAttentionGraphPooling_2019}
Junhyun Lee, Inyeop Lee, and Jaewoo Kang.
\newblock Self-{{Attention Graph Pooling}}.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, pages 3734--3743, {Long Beach, California, USA}, 2019. {PMLR}.

\bibitem{snapnets}
Jure Leskovec and Andrej Krevl.
\newblock {SNAP Datasets}: {Stanford} large network dataset collection.
\newblock \url{http://snap.stanford.edu/data}, 2014.

\bibitem{li_DeeperInsightsGraph_2018}
Qimai Li, Zhichao Han, and Xiao-Ming Wu.
\newblock Deeper {{Insights}} into {{Graph Convolutional Networks}} for {{Semi-Supervised Learning}}.
\newblock In {\em {{AAAI Conference}} on {{Artificial Intelligence}}}, {New Orleans, USA}, 2018.

\bibitem{li_FindingGlobalHomophily_2022}
Xiang Li, Renyu Zhu, Yao Cheng, Caihua Shan, Siqiang Luo, Dongsheng Li, and Weining Qian.
\newblock Finding {{Global Homophily}} in {{Graph Neural Networks When Meeting Heterophily}}.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, volume 162, pages 13242--13256, {Baltimore, Maryland, USA}, 2022. {PMLR}.

\bibitem{lim_LargeScaleLearning_2021}
Derek Lim, Felix Hohne, Xiuyu Li, Sijia~Linda Huang, Vaishnavi Gupta, Omkar Bhalerao, and Ser~Nam Lim.
\newblock Large {{Scale Learning}} on {{Non-Homophilous Graphs}}: {{New Benchmarks}} and {{Strong Simple Methods}}.
\newblock In {\em Advances in {{Neural Information Processing Systems}}}, volume~34, pages 20887--20902. {Curran Associates, Inc.}, 2021.

\bibitem{liu_BoostingGraphStructure_2022}
Xin Liu, Jiayang Cheng, Yangqiu Song, and Xin Jiang.
\newblock Boosting {{Graph Structure Learning}} with {{Dummy Nodes}}.
\newblock In {\em {{International Conference}} on {{Machine Learning}}}, pages 13704--13716. {PMLR}, 2022.

\bibitem{mialon_GraphiTEncodingGraph_2021}
Gr{\'e}goire Mialon, Dexiong Chen, Margot Selosse, and Julien Mairal.
\newblock {{GraphiT}}: {{Encoding Graph Structure}} in {{Transformers}}.
\newblock {\em arXiv preprint}.

\bibitem{morris_TUDatasetCollectionBenchmark_2020}
Christopher Morris, Nils~M. Kriege, Franka Bause, Kristian Kersting, Petra Mutzel, and Marion Neumann.
\newblock {{TUDataset}}: {{A}} collection of benchmark datasets for learning with graphs.
\newblock In {\em International {{Conference}} on {{Machine Learning Workshop}} on {{Graph Representation Learning}} and {{Beyond}}}, {Virtual Only}, 2020. {arXiv}.

\bibitem{niepert_LearningConvolutionalNeural_2016}
Mathias Niepert, Mohamed Ahmed, and Konstantin Kutzkov.
\newblock Learning convolutional neural networks for graphs.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, volume~48, pages 2014--2023, {New York, NY, USA}, 2016. {PMLR}.

\bibitem{oono_GraphNeuralNetworks_2021}
Kenta Oono and Taiji Suzuki.
\newblock Graph {{Neural Networks Exponentially Lose Expressive Power}} for {{Node Classification}}.
\newblock In {\em International {{Conference}} for {{Learning Representations}}}, 2021.

\bibitem{paszke_PyTorchImperativeStyle_2019}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas K{\"o}pf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith Chintala.
\newblock {{PyTorch}}: An imperative style, high-performance deep learning library.
\newblock In {\em International {{Conference}} on {{Neural Information Processing Systems}}}, pages 8026--8037, {Red Hook, NY, USA}, 2019. {Curran Associates Inc.}

\bibitem{pei_DynamicsinspiredNeuromorphicVisual_2023}
Zhengqi Pei and Shuhui Wang.
\newblock Dynamics-inspired {{Neuromorphic Visual Representation Learning}}.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, pages 27521--27541. {PMLR}, 2023.

\bibitem{platonov_CriticalLookEvaluation_2023}
Oleg Platonov, Denis Kuznedelev, Michael Diskin, Artem Babenko, and Liudmila Prokhorenkova.
\newblock A critical look at the evaluation of {{GNNs}} under heterophily: {{Are}} we really making progress?
\newblock In {\em The {{Eleventh International Conference}} on {{Learning Representations}}}, {Kigali, Rwanda}, 2023.

\bibitem{qian_ProbabilisticallyRewiredMessagePassing_2023}
Chendi Qian, Andrei Manolache, Kareem Ahmed, Zhe Zeng, Guy~Van den Broeck, Mathias Niepert, and Christopher Morris.
\newblock Probabilistically {{Rewired Message-Passing Neural Networks}}.
\newblock In {\em {{International Conference}} on {{Learning Representations}}}, 2023.

\bibitem{rahmani_GraphNeuralNetworks_2023}
Saeed Rahmani, Asiye Baghbani, Nizar Bouguila, and Zachary Patterson.
\newblock Graph {{Neural Networks}} for {{Intelligent Transportation Systems}}: {{A Survey}}.
\newblock {\em IEEE Transactions on Intelligent Transportation Systems}, 24(8):8846--8885, 2023.

\bibitem{rampasek_RecipeGeneralPowerful_2022}
Ladislav Ramp{\'a}{\v s}ek, Michael Galkin, Vijay~Prakash Dwivedi, Anh~Tuan Luu, Guy Wolf, and Dominique Beaini.
\newblock Recipe for a {{General}}, {{Powerful}}, {{Scalable Graph Transformer}}.
\newblock In {\em Advances in {{Neural Information Processing Systems}}}, volume~35, pages 14501--14515, {New Orleans, USA}, 2022.

\bibitem{ranjan_ASAPAdaptiveStructure_2020}
Ekagra Ranjan, Soumya Sanyal, and Partha Talukdar.
\newblock {{ASAP}}: {{Adaptive Structure Aware Pooling}} for {{Learning Hierarchical Graph Representations}}.
\newblock In {\em {{AAAI Conference}} on {{Artificial Intelligence}}}, volume~34, pages 5470--5477, {New York, NY, USA}, 2020.

\bibitem{scarselli_GraphNeuralNetwork_2009}
Franco Scarselli, Marco Gori, Ah~Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini.
\newblock The {{Graph Neural Network Model}}.
\newblock {\em IEEE Transactions on Neural Networks}, 20(1):61--80, 2009.

\bibitem{shchur_PitfallsGraphNeural_2019}
Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan G{\"u}nnemann.
\newblock Pitfalls of {{Graph Neural Network Evaluation}}.
\newblock {\em arXiv:1811.05868 [cs, stat]}, 2019.

\bibitem{shi_MaskedLabelPrediction_2021}
Yunsheng Shi, Zhengjie Huang, Shikun Feng, Hui Zhong, Wenjing Wang, and Yu~Sun.
\newblock Masked {{Label Prediction}}: {{Unified Message Passing Model}} for {{Semi-Supervised Classification}}.
\newblock In {\em {{International Joint Conference}} on {{Artificial Intelligence}}}, volume~2, pages 1548--1554, {Virtual Event / Montreal, Canada}, 2021. {ijcai.org}.

\bibitem{shirzad_ExphormerSparseTransformers_2023}
Hamed Shirzad, Ameya Velingker, Balaji Venkatachalam, Danica~J. Sutherland, and Ali~Kemal Sinop.
\newblock Exphormer: {{Sparse Transformers}} for {{Graphs}}.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, volume 202, {Honolulu, USA}, 2023. {PMLR}.

\bibitem{sun_AllinARow_2023}
Junshu Sun, Shuhui Wang, Xinzhe Han, Zhe Xue, and Qingming Huang.
\newblock All in a row: {{Compressed}} convolution networks for graphs.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, volume 202, pages 33061--33076, {Honolulu, USA}, 2023. {PMLR}.

\bibitem{sun_HomophilyStructureawarePath_2022}
Yifei Sun, Haoran Deng, Yang Yang, Chunping Wang, Jiarong Xu, Renhong Huang, Linfeng Cao, Yang Wang, and Lei Chen.
\newblock Beyond {{Homophily}}: {{Structure-aware Path Aggregation Graph Neural Network}}.
\newblock In {\em {{International Joint Conference}} on {{Artificial Intelligence}}}, volume~3, pages 2233--2240, 2022.

\bibitem{topping_UnderstandingOversquashingBottlenecks_2021}
Jake Topping, Francesco Di~Giovanni, Benjamin~Paul Chamberlain, Xiaowen Dong, and Michael~M. Bronstein.
\newblock Understanding over-squashing and bottlenecks on graphs via curvature.
\newblock In {\em International {{Conference}} for {{Learning Representations}}}, 2021.

\bibitem{t-SNE}
Laurens Van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock {\em Journal of machine learning research}, 9(11), 2008.

\bibitem{vaswani_AttentionAllYou_2017}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N. Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em International {{Conference}} on {{Neural Information Processing Systems}}}, pages 6000--6010, {Red Hook, NY, USA}, 2017. {Curran Associates Inc.}

\bibitem{velickovic_MessagePassingAll_2022}
Petar Veli{\v c}kovi{\'c}.
\newblock Message passing all the way up.
\newblock In {\em International Conference on Learning Representation Workshop on Geometrical and Topological Representation Learning}, 2022.

\bibitem{velickovic_GraphAttentionNetworks_2018}
Petar Veli{\v c}kovi{\'c}, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li{\`o}, and Yoshua Bengio.
\newblock Graph {{Attention Networks}}.
\newblock In {\em International {{Conference}} on {{Learning Representations}}}, {Vancouver, Canada}, 2018.

\bibitem{wang_PROSEGraphStructure_2023}
Huizhao Wang, Yao Fu, Tao Yu, Linghui Hu, Weihao Jiang, and Shiliang Pu.
\newblock {{PROSE}}: {{Graph Structure Learning}} via {{Progressive Strategy}}.
\newblock In {\em {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}}, pages 2337--2348, New York, NY, USA, 2023. Association for Computing Machinery.

\bibitem{wu_SimplifyingGraphConvolutional_2019}
Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, and Kilian Weinberger.
\newblock Simplifying {{Graph Convolutional Networks}}.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, pages 6861--6871, {Long Beach, USA}, 2019. {PMLR}.

\bibitem{wu_StructuralEntropyGuided_2022}
Junran Wu, Xueyuan Chen, Shangzhe Li, and Ke~Xu.
\newblock Structural entropy guided graph hierarchical pooling.
\newblock In {\em International Conference on Machine Learning}, volume 162, pages 24017--24030, {Baltimore, Maryland, USA}, 2022. {PMLR}.

\bibitem{wu_DIFFormerScalableGraph_2023}
Qitian Wu, Chenxiao Yang, Wentao Zhao, Yixuan He, David Wipf, and Junchi Yan.
\newblock {{DIFFormer}}: {{Scalable}} ({{Graph}}) {{Transformers Induced}} by {{Energy Constrained Diffusion}}.
\newblock In {\em The {{Eleventh International Conference}} on {{Learning Representations}}}, 2023.

\bibitem{wu_NodeFormerScalableGraph_2022}
Qitian Wu, Wentao Zhao, Zenan Li, David Wipf, and Junchi Yan.
\newblock {{NodeFormer}}: {{A Scalable Graph Structure Learning Transformer}} for {{Node Classification}}.
\newblock In {\em Advances in {{Neural Information Processing Systems}}}, 2022.

\bibitem{wu_SGFormerSimplifyingEmpowering_2023}
Qitian Wu, Wentao Zhao, Chenxiao Yang, Hengrui Zhang, Fan Nie, Haitian Jiang, Yatao Bian, and Junchi Yan.
\newblock {{SGFormer}}: {{Simplifying}} and {{Empowering Transformers}} for {{Large-Graph Representations}}.
\newblock In {\em {{Conference}} on {{Neural Information Processing Systems}}}, 2023.

\bibitem{xu*_HowPowerfulAre_2019}
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka.
\newblock How {{Powerful}} are {{Graph Neural Networks}}?
\newblock In {\em International {{Conference}} on {{Learning Representations}}}, {New Orleans, LA, USA}, 2019.

\bibitem{ying_TransformersReallyPerform_2021}
Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di~He, Yanming Shen, and Tie-Yan Liu.
\newblock Do {{Transformers Really Perform Bad}} for {{Graph Representation}}?
\newblock In {\em Advances in {{Neural Information Processing Systems}}}, volume~34, pages 28877--28888. {Curran Associates, Inc.}, 2021.

\bibitem{ying_HierarchicalGraphRepresentation_2018}
Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec.
\newblock Hierarchical {{Graph Representation Learning}} with {{Differentiable Pooling}}.
\newblock In {\em Advances in {{Neural Information Processing Systems}}}, volume~31, pages 4805--4815, {Montr\'eal, Canada}, 2018. {Curran Associates, Inc.}

\bibitem{yuan_StructPoolStructuredGraph_2020}
Hao Yuan and Shuiwang Ji.
\newblock {{StructPool}}: {{Structured Graph Pooling}} via {{Conditional Random Fields}}.
\newblock In {\em International {{Conference}} on {{Learning Representations}}}, {Addis Ababa, Ethiopia}, 2020.

\bibitem{zaidi_PretrainingDenoisingMolecular_2023}
Sheheryar Zaidi, Michael Schaarschmidt, James Martens, Hyunjik Kim, Yee~Whye Teh, Alvaro {Sanchez-Gonzalez}, Peter Battaglia, Razvan Pascanu, and Jonathan Godwin.
\newblock Pre-training via {{Denoising}} for {{Molecular Property Prediction}}.
\newblock In {\em The {{Eleventh International Conference}} on {{Learning Representations}}}, 2023.

\bibitem{zhao_GraphGLOWUniversalGeneralizable_2023}
Wentao Zhao, Qitian Wu, Chenxiao Yang, and Junchi Yan.
\newblock {{GraphGLOW}}: {{Universal}} and {{Generalizable Structure Learning}} for {{Graph Neural Networks}}.
\newblock In {\em Proceedings of the 29th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}}, pages 3525--3536, New York, NY, USA, 2023. Association for Computing Machinery.

\bibitem{zhou_GraphNeuralNetworks_2020}
Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, and Maosong Sun.
\newblock Graph neural networks: {{A}} review of methods and applications.
\newblock {\em AI Open}, 1:57--81, 2020.

\bibitem{zhu_HomophilyGraphNeural_2020}
Jiong Zhu, Yujun Yan, Lingxiao Zhao, Mark Heimann, Leman Akoglu, and Danai Koutra.
\newblock Beyond homophily in graph neural networks: Current limitations and effective designs.
\newblock In {\em {{International Conference}} on {{Neural Information Processing Systems}}}, pages 7793--7804, {Red Hook, NY, USA}, 2020. {Curran Associates Inc.}

\bibitem{zhu_DeepGraphStructure_2021}
Yanqiao Zhu, Weizhi Xu, Jinghao Zhang, Qiang Liu, Shu Wu, and Liang Wang.
\newblock Deep {{Graph Structure Learning}} for {{Robust Representations}}: {{A Survey}}.
\newblock {\em arXiv:2103.03036 [cs]}, 2021.

\end{thebibliography}
