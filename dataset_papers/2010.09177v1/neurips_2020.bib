@inproceedings{pan2020reinforcement,
  title     = {Reinforcement Learning with Dynamic Boltzmann Softmax Updates},
  author    = {Pan, Ling and Cai, Qingpeng and Meng, Qi and Chen, Wei and Huang, Longbo},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence},
  pages     = {1992--1998},
  year      = {2020}
}


@inproceedings{ciosek2018expected,
  title={Expected policy gradients},
  author={Ciosek, Kamil and Whiteson, Shimon},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{nachum2018smoothed,
  title={Smoothed Action Value Functions for Learning Gaussian Policies},
  author={Nachum, Ofir and Norouzi, Mohammad and Tucker, George and Schuurmans, Dale},
  booktitle={International Conference on Machine Learning},
  pages={3692--3700},
  year={2018}
}

@inproceedings{ciosek2019better,
  title={Better Exploration with Optimistic Actor Critic},
  author={Ciosek, Kamil and Vuong, Quan and Loftin, Robert and Hofmann, Katja},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1785--1796},
  year={2019}
}


@inproceedings{khadka2018evolution,
  title={Evolution-guided policy gradient in reinforcement learning},
  author={Khadka, Shauharda and Tumer, Kagan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1188--1200},
  year={2018}
}


@inproceedings{gu2016continuous,
  title={Continuous deep q-learning with model-based acceleration},
  author={Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={2829--2838},
  year={2016}
}



@inproceedings{cesa2017boltzmann,
  title={Boltzmann exploration done right},
  author={Cesa-Bianchi, Nicol{\`o} and Gentile, Claudio and Lugosi, G{\'a}bor and Neu, Gergely},
  booktitle={Advances in neural information processing systems},
  pages={6284--6293},
  year={2017}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{goodfellow2014qualitatively,
  title={Qualitatively characterizing neural network optimization problems},
  author={Goodfellow, Ian J and Vinyals, Oriol and Saxe, Andrew M},
  journal={arXiv preprint arXiv:1412.6544},
  year={2014}
}

@inproceedings{littman1996generalized,
  title={A generalized reinforcement-learning model: Convergence and applications},
  author={Littman, Michael L and Szepesv{\'a}ri, Csaba},
  booktitle={ICML},
  volume={96},
  pages={310--318},
  year={1996}
}

@misc{td3_code,
  author = {Fujimoto, Scott},
  title = {Open-source implementation for {\uppercase{TD3}}},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/sfujim/TD3}}
}

@inproceedings{kim2019deepmellow,
  title={Deepmellow: removing the need for a target network in deep Q-learning},
  author={Kim, Seungchan and Asadi, Kavosh and Littman, Michael and Konidaris, George},
  booktitle={Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI},
  pages={10--16},
  year={2019}
}

@inproceedings{dauphin2014identifying,
  title={Identifying and attacking the saddle point problem in high-dimensional non-convex optimization},
  author={Dauphin, Yann N and Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Ganguli, Surya and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2933--2941},
  year={2014}
}

@article{bellman1957dynamic,
  title={Dynamic Programming},
  author={Bellman, Richard Ernest},
  year={1957},
  publisher={Courier Dover Publications}
}


@inproceedings{ahmed2019understanding,
  title={Understanding the Impact of Entropy on Policy Optimization},
  author={Ahmed, Zafarali and Le Roux, Nicolas and Norouzi, Mohammad and Schuurmans, Dale},
  booktitle={International Conference on Machine Learning},
  pages={151--160},
  year={2019}
}

@inproceedings{jaakkola1994convergence,
  title={Convergence of stochastic iterative dynamic programming algorithms},
  author={Jaakkola, Tommi and Jordan, Michael I and Singh, Satinder P},
  booktitle={Advances in neural information processing systems},
  pages={703--710},
  year={1994}
}

@inproceedings{thrun1993issues,
  title={Issues in using function approximation for reinforcement learning},
  author={Thrun, Sebastian and Schwartz, Anton},
  booktitle={Proceedings of the 1993 Connectionist Models Summer School Hillsdale, NJ. Lawrence Erlbaum},
  year={1993}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{sutton2011reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2011},
  publisher={Cambridge, MA: MIT Press}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement Learning with Deep Energy-Based Policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1352--1361},
  year={2017}
}

@inproceedings{chow2018path,
  title={Path consistency learning in tsallis entropy regularized mdps},
  author={Chow, Yinlam and Nachum, Ofir and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={979--988},
  year={2018}
}

@inproceedings{buckman2018sample,
  title={Sample-efficient reinforcement learning with stochastic ensemble value expansion},
  author={Buckman, Jacob and Hafner, Danijar and Tucker, George and Brevdo, Eugene and Lee, Honglak},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8224--8234},
  year={2018}
}

@article{feinberg2018model,
  title={Model-based value estimation for efficient model-free reinforcement learning},
  author={Feinberg, Vladimir and Wan, Alvin and Stoica, Ion and Jordan, Michael I and Gonzalez, Joseph E and Levine, Sergey},
  journal={arXiv preprint arXiv:1803.00101},
  year={2018}
}

@article{barth2018distributed,
  title={Distributed distributional deterministic policy gradients},
  author={Barth-Maron, Gabriel and Hoffman, Matthew W and Budden, David and Dabney, Will and Horgan, Dan and Tb, Dhruva and Muldal, Alistair and Heess, Nicolas and Lillicrap, Timothy},
  journal={arXiv preprint arXiv:1804.08617},
  year={2018}
}

@article{horgan2018distributed,
  title={Distributed prioritized experience replay},
  author={Horgan, Dan and Quan, John and Budden, David and Barth-Maron, Gabriel and Hessel, Matteo and Van Hasselt, Hado and Silver, David},
  journal={arXiv preprint arXiv:1803.00933},
  year={2018}
}

@article{achiam2019towards,
  title={Towards characterizing divergence in deep q-learning},
  author={Achiam, Joshua and Knight, Ethan and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1903.08894},
  year={2019}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{asadi2017alternative,
  title={An alternative softmax operator for reinforcement learning},
  author={Asadi, Kavosh and Littman, Michael L},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={243--252},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  year={2014}
}


@article{fujimoto2018addressing,
  title={Addressing Function Approximation Error in Actor-Critic Methods},
  author={Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle={Proceedings of the 35th International Conference on Machine Learning, {ICML} 2018},
  year={2018}
}

@inproceedings{asadi2017alternative,
  title={An alternative softmax operator for reinforcement learning},
  author={Asadi, Kavosh and Littman, Michael L},
  booktitle={Proceedings of the 34th International Conference on Machine Learning, {ICML} 2017},
  pages={243--252},
  year={2016}
}

@inproceedings{anschel2017averaged,
  title={Averaged-dqn: Variance reduction and stabilization for deep reinforcement learning},
  author={Anschel, Oron and Baram, Nir and Shimkin, Nahum},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={176--185},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{lan2020maxmin,
title={Maxmin Q-learning: Controlling the Estimation Bias of Q-learning},
author={Qingfeng Lan and Yangchen Pan and Alona Fyshe and Martha White},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Bkg0u3Etwr}
}

@article{watkins1989learning,
  title={Learning from delayed rewards},
  author={Watkins, Christopher John Cornish Hellaby},
  year={1989},
  publisher={King's College, Cambridge}
}

@article{song2018revisiting,
  title={Revisiting the Softmax Bellman Operator: New Benefits and New Perspective},
  author={Song, Zhao and Parr, Ronald E and Carin, Lawrence},
  journal={arXiv preprint arXiv:1812.00456},
  year={2018}
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Thirtieth AAAI conference on artificial intelligence},
  year={2016}
}

@inproceedings{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, Hado V},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2613--2621},
  year={2010}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{catto2011box2d,
  title={Box2d: A 2d physics engine for games},
  author={Catto, Erin},
  year={2011}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{haarnoja2018soft,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1861--1870},
  year={2018}
}