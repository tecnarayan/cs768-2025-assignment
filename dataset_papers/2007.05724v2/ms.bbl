\begin{thebibliography}{27}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Adams and Zemel(2011)]{Adams2011RankingVS}
R.~P. Adams and R.~S. Zemel.
\newblock Ranking via sinkhorn propagation.
\newblock \emph{ArXiv}, abs/1106.1925, 2011.

\bibitem[Andriyash et~al.(2018)Andriyash, Vahdat, and
  Macready]{Andriyash2018ImprovedGO}
E.~Andriyash, A.~Vahdat, and W.~G. Macready.
\newblock Improved gradient-based optimization over discrete distributions.
\newblock \emph{ArXiv}, abs/1810.00116, 2018.

\bibitem[Berrada et~al.(2018)Berrada, Zisserman, and Kumar]{berrada2018smooth}
L.~Berrada, A.~Zisserman, and M.~P. Kumar.
\newblock Smooth loss functions for deep top-k classification.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Berthet et~al.(2020)Berthet, Blondel, Teboul, Cuturi, Vert, and
  Bach]{berthet2020learning}
Q.~Berthet, M.~Blondel, O.~Teboul, M.~Cuturi, J.-P. Vert, and F.~R. Bach.
\newblock Learning with differentiable perturbed optimizers.
\newblock \emph{ArXiv}, abs/2002.08676, 2020.

\bibitem[Blondel et~al.(2020)Blondel, Teboul, Berthet, and
  Djolonga]{Blondel2020FastDS}
M.~Blondel, O.~Teboul, Q.~Berthet, and J.~Djolonga.
\newblock Fast differentiable sorting and ranking.
\newblock In \emph{ICML}, 2020.

\bibitem[Domke(2010)]{NIPS2010_4107}
J.~Domke.
\newblock Implicit differentiation by perturbation.
\newblock In \emph{Advances in Neural Information Processing Systems 23}.
  Curran Associates, Inc., 2010.

\bibitem[Grover et~al.(2019)Grover, Wang, Zweig, and
  Ermon]{grover2018stochastic}
A.~Grover, E.~Wang, A.~Zweig, and S.~Ermon.
\newblock Stochastic optimization of sorting networks via continuous
  relaxations.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=H1eSS3CcKX}.

\bibitem[Hazan et~al.(2010)Hazan, Keshet, and McAllester]{NIPS2010_4069}
T.~Hazan, J.~Keshet, and D.~A. McAllester.
\newblock Direct loss minimization for structured prediction.
\newblock In \emph{Advances in Neural Information Processing Systems 23}.
  Curran Associates, Inc., 2010.

\bibitem[Jang et~al.(2016)Jang, Gu, and Poole]{Jang2016CategoricalRW}
E.~Jang, S.~Gu, and B.~Poole.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock \emph{International Conference on Learning Representations}, 2016.

\bibitem[Jin et~al.(2020)Jin, Barzilay, and Jaakkola]{jin2020hierarchical}
W.~Jin, R.~Barzilay, and T.~Jaakkola.
\newblock Hierarchical generation of molecular graphs using structural motifs.
\newblock \emph{ArXiv}, abs/2002.03230, 2020.

\bibitem[Kendall et~al.(2017)Kendall, Badrinarayanan, , and
  Cipolla]{kendall2015bayesian}
A.~Kendall, V.~Badrinarayanan, , and R.~Cipolla.
\newblock Bayesian segnet: Model uncertainty in deep convolutional
  encoder-decoder architectures for scene understanding.
\newblock In \emph{Proceedings of the British Machine Vision Conference
  ({BMVC})}, 2017.

\bibitem[Keshet et~al.(2011)Keshet, Cheng, Stoehr, and
  McAllester]{Keshet2011DirectER}
J.~Keshet, C.-C. Cheng, M.~Stoehr, and D.~A. McAllester.
\newblock Direct error rate minimization of hidden markov models.
\newblock In \emph{INTERSPEECH}, 2011.

\bibitem[Kool et~al.(2019)Kool, van Hoof, and Welling]{conf/icml/KoolHW19}
W.~Kool, H.~van Hoof, and M.~Welling.
\newblock Stochastic beams and where to find them: The gumbel-top-k trick for
  sampling sequences without replacement.
\newblock In \emph{ICML}, volume~97 of \emph{Proceedings of Machine Learning
  Research}, pages 3499--3508. PMLR, 2019.
\newblock URL
  \url{http://dblp.uni-trier.de/db/conf/icml/icml2019.html#KoolHW19}.

\bibitem[Linderman et~al.(2018)Linderman, Mena, Cooper, Paninski, and
  Cunningham]{pmlr-v84-linderman18a}
S.~Linderman, G.~Mena, H.~Cooper, L.~Paninski, and J.~Cunningham.
\newblock Reparameterizing the birkhoff polytope for variational permutation
  inference.
\newblock In \emph{Proceedings of the Twenty-First International Conference on
  Artificial Intelligence and Statistics}, volume~84 of \emph{Proceedings of
  Machine Learning Research}, pages 1618--1627, 2018.

\bibitem[Lorberbom et~al.(2018)Lorberbom, Gane, Jaakkola, and
  Hazan]{Lorberbom2018DirectOT}
G.~Lorberbom, A.~Gane, T.~S. Jaakkola, and T.~Hazan.
\newblock Direct optimization through arg max for discrete variational
  auto-encoder.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Lorberbom et~al.(2019)Lorberbom, Maddison, Heess, Hazan, and
  Tarlow]{lorberbom2019direct}
G.~Lorberbom, C.~J. Maddison, N.~M.~O. Heess, T.~Hazan, and D.~Tarlow.
\newblock Direct policy gradients: Direct optimization of policies in discrete
  action spaces.
\newblock \emph{ArXiv}, abs/1906.06062, 2019.

\bibitem[Maddison et~al.(2017)Maddison, Mnih, and
  Teh]{DBLP:conf/iclr/MaddisonMT17}
C.~J. Maddison, A.~Mnih, and Y.~W. Teh.
\newblock The concrete distribution: {A} continuous relaxation of discrete
  random variables.
\newblock In \emph{5th International Conference on Learning Representations,
  {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track
  Proceedings}. OpenReview.net, 2017.
\newblock URL \url{https://openreview.net/forum?id=S1jE5L5gl}.

\bibitem[Mena et~al.(2018)Mena, Belanger, Linderman, and
  Snoek]{mena2018learning}
E.~G. Mena, D.~Belanger, S.~Linderman, and J.~Snoek.
\newblock Learning latent permutations with gumbel-sinkhorn networks.
\newblock \emph{International Conference on Learning Representations}, 2018.

\bibitem[Niculae et~al.(2018)Niculae, Martins, Blondel, and
  Cardie]{Niculae2018SparseMAPDS}
V.~Niculae, A.~F.~T. Martins, M.~Blondel, and C.~Cardie.
\newblock Sparsemap: Differentiable sparse structured inference.
\newblock In \emph{ICML}, 2018.

\bibitem[Paulus et~al.(2020)Paulus, Choi, Tarlow, Krause, and
  Maddison]{Paulus2020GradientEW}
M.~B. Paulus, D.~Choi, D.~Tarlow, A.~Krause, and C.~J. Maddison.
\newblock Gradient estimation with stochastic softmax tricks.
\newblock \emph{ArXiv}, abs/2006.08063, 2020.

\bibitem[Pl\"{o}tz and Roth(2018)]{NIPS2018_7386}
T.~Pl\"{o}tz and S.~Roth.
\newblock Neural nearest neighbors networks.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, \emph{Advances in Neural Information Processing
  Systems 31}, pages 1087--1098. Curran Associates, Inc., 2018.
\newblock URL
  \url{http://papers.nips.cc/paper/7386-neural-nearest-neighbors-networks.pdf}.

\bibitem[Pogancic et~al.(2020)Pogancic, Paulus, Musil, Martius, and
  Rolinek]{DBLP:conf/iclr/PogancicPMMR20}
M.~V. Pogancic, A.~Paulus, V.~Musil, G.~Martius, and M.~Rolinek.
\newblock Differentiation of blackbox combinatorial solvers.
\newblock In \emph{8th International Conference on Learning Representations,
  {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}. OpenReview.net, 2020.
\newblock URL \url{https://openreview.net/forum?id=BkevoJSYPB}.

\bibitem[{Santa Cruz} et~al.(2019){Santa Cruz}, {Fernando}, {Cherian}, and
  {Gould}]{8481554}
R.~{Santa Cruz}, B.~{Fernando}, A.~{Cherian}, and S.~{Gould}.
\newblock Visual permutation learning.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 41\penalty0 (12):\penalty0 3100--3114, 2019.

\bibitem[Song et~al.(2016)Song, Schwing, Zemel, and
  Urtasun]{Song2016TrainingDN}
Y.~Song, A.~G. Schwing, R.~S. Zemel, and R.~Urtasun.
\newblock Training deep neural networks via direct loss minimization.
\newblock In \emph{ICML}, 2016.

\bibitem[Wiseman and Rush(2016)]{wiseman2016sequence}
S.~Wiseman and A.~M. Rush.
\newblock Sequence-to-sequence learning as beam-search optimization.
\newblock In \emph{Proceedings of the 2016 Conference on Empirical Methods in
  Natural Language Processing}, pages 1296--1306, Austin, Texas, Nov. 2016.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/D16-1137}.
\newblock URL \url{https://www.aclweb.org/anthology/D16-1137}.

\bibitem[Xie and Ermon(2019)]{DBLP:conf/ijcai/XieE19}
S.~M. Xie and S.~Ermon.
\newblock Reparameterizable subset sampling via continuous relaxations.
\newblock In S.~Kraus, editor, \emph{Proceedings of the Twenty-Eighth
  International Joint Conference on Artificial Intelligence, {IJCAI} 2019,
  Macao, China, August 10-16, 2019}, pages 3919--3925. ijcai.org, 2019.
\newblock \doi{10.24963/ijcai.2019/544}.
\newblock URL \url{https://doi.org/10.24963/ijcai.2019/544}.

\bibitem[Xie et~al.(2020)Xie, Dai, Chen, Dai, Zhao, Zha, Wei, and
  Pfister]{Xie2020DifferentiableTO}
Y.~Xie, H.~Dai, M.~Chen, B.~Dai, T.~Zhao, H.~Zha, W.~Wei, and T.~Pfister.
\newblock Differentiable top-k operator with optimal transport.
\newblock \emph{ArXiv}, abs/2002.06504, 2020.

\end{thebibliography}
