\begin{thebibliography}{87}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[De~Raedt et~al.(2021)De~Raedt, Duman{\v{c}}i{\'c}, Manhaeve, and
  Marra]{de2021statistical}
Luc De~Raedt, Sebastijan Duman{\v{c}}i{\'c}, Robin Manhaeve, and Giuseppe
  Marra.
\newblock From statistical relational to neural-symbolic artificial
  intelligence.
\newblock In \emph{Proceedings of the Twenty-Ninth International Conference on
  International Joint Conferences on Artificial Intelligence}, pages
  4943--4950, 2021.

\bibitem[Garcez et~al.(2022)Garcez, Bader, Bowman, Lamb, de~Penning, Illuminoo,
  Poon, and Gerson~Zaverucha]{garcez2022neural}
Artur~dâ€™Avila Garcez, Sebastian Bader, Howard Bowman, Luis~C Lamb, Leo
  de~Penning, BV~Illuminoo, Hoifung Poon, and COPPE Gerson~Zaverucha.
\newblock Neural-symbolic learning and reasoning: A survey and interpretation.
\newblock \emph{Neuro-Symbolic Artificial Intelligence: The State of the Art},
  342:\penalty0 1, 2022.

\bibitem[Giunchiglia et~al.(2022)Giunchiglia, Stoian, and
  Lukasiewicz]{giunchiglia2022deep}
Eleonora Giunchiglia, Mihaela~Catalina Stoian, and Thomas Lukasiewicz.
\newblock Deep learning with logical constraints.
\newblock \emph{arXiv preprint arXiv:2205.00523}, 2022.

\bibitem[Dash et~al.(2022)Dash, Chitlangia, Ahuja, and
  Srinivasan]{dash2022review}
Tirtharaj Dash, Sharad Chitlangia, Aditya Ahuja, and Ashwin Srinivasan.
\newblock A review of some techniques for inclusion of domain-knowledge into
  deep neural networks.
\newblock \emph{Scientific Reports}, 12\penalty0 (1):\penalty0 1--15, 2022.

\bibitem[Diligenti et~al.(2017)Diligenti, Gori, and
  Sacca]{diligenti2017semantic}
Michelangelo Diligenti, Marco Gori, and Claudio Sacca.
\newblock Semantic-based regularization for learning and inference.
\newblock \emph{Artificial Intelligence}, 2017.

\bibitem[Donadello et~al.(2017)Donadello, Serafini, and
  Garcez]{donadello2017logic}
Ivan Donadello, Luciano Serafini, and Artur~D'Avila Garcez.
\newblock Logic tensor networks for semantic image interpretation.
\newblock In \emph{IJCAI}, 2017.

\bibitem[Manhaeve et~al.(2018)Manhaeve, Dumancic, Kimmig, Demeester, and
  De~Raedt]{manhaeve2018deepproblog}
Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, and Luc
  De~Raedt.
\newblock {DeepProbLog: Neural Probabilistic Logic Programming}.
\newblock \emph{NeurIPS}, 2018.

\bibitem[Xu et~al.(2018)Xu, Zhang, Friedman, Liang, and Broeck]{xu2018semantic}
Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, and Guy Broeck.
\newblock A semantic loss function for deep learning with symbolic knowledge.
\newblock In \emph{ICML}, 2018.

\bibitem[Giunchiglia and Lukasiewicz(2020)]{giunchiglia2020coherent}
Eleonora Giunchiglia and Thomas Lukasiewicz.
\newblock Coherent hierarchical multi-label classification networks.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Ahmed et~al.(2022{\natexlab{a}})Ahmed, Teso, Chang, Van~den Broeck,
  and Vergari]{ahmed2022semantic}
Kareem Ahmed, Stefano Teso, Kai-Wei Chang, Guy Van~den Broeck, and Antonio
  Vergari.
\newblock {Semantic Probabilistic Layers for Neuro-Symbolic Learning}.
\newblock In \emph{NeurIPS}, 2022{\natexlab{a}}.

\bibitem[Li et~al.(2023)Li, Liu, Yao, Xu, Chen, Ma, Jian,
  et~al.]{li2023learning}
Zenan Li, Zehua Liu, Yuan Yao, Jingwei Xu, Taolue Chen, Xiaoxing Ma, L~Jian,
  et~al.
\newblock Learning with logical constraints but without shortcut satisfaction.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem[Xie et~al.(2022)Xie, Kersting, and Neider]{xie2022neuro}
Xuan Xie, Kristian Kersting, and Daniel Neider.
\newblock Neuro-symbolic verification of deep neural networks.
\newblock 2022.

\bibitem[Rudin(2019)]{rudin2019stop}
Cynthia Rudin.
\newblock Stop explaining black box machine learning models for high stakes
  decisions and use interpretable models instead.
\newblock \emph{Nature Machine Intelligence}, 1\penalty0 (5):\penalty0
  206--215, 2019.

\bibitem[Chen et~al.(2019)Chen, Li, Tao, Barnett, Rudin, and Su]{chen2019looks}
Chaofan Chen, Oscar Li, Daniel Tao, Alina Barnett, Cynthia Rudin, and
  Jonathan~K Su.
\newblock This looks like that: Deep learning for interpretable image
  recognition.
\newblock \emph{NeurIPS}, 2019.

\bibitem[Chen et~al.(2020)Chen, Bei, and Rudin]{chen2020concept}
Zhi Chen, Yijie Bei, and Cynthia Rudin.
\newblock Concept whitening for interpretable image recognition.
\newblock \emph{Nature Machine Intelligence}, 2020.

\bibitem[DeGrave et~al.(2021)DeGrave, Janizek, and Lee]{degrave2021ai}
Alex~J DeGrave, Joseph~D Janizek, and Su-In Lee.
\newblock Ai for radiographic covid-19 detection selects shortcuts over signal.
\newblock \emph{Nature Machine Intelligence}, pages 1--10, 2021.

\bibitem[Maiettini et~al.(2019)Maiettini, Pasquale, Tikhanoff, Rosasco, and
  Natale]{maiettini2019weakly}
Elisa Maiettini, Giulia Pasquale, Vadim Tikhanoff, Lorenzo Rosasco, and Lorenzo
  Natale.
\newblock A weakly supervised strategy for learning object detection on a
  humanoid robot.
\newblock In \emph{2019 IEEE-RAS 19th International Conference on Humanoid
  Robots (Humanoids)}, pages 194--201. IEEE, 2019.

\bibitem[Badue et~al.(2021)Badue, Guidolini, Carneiro, Azevedo, Cardoso,
  Forechi, Jesus, Berriel, Paixao, Mutz, et~al.]{badue2021self}
Claudine Badue, R{\^a}nik Guidolini, Raphael~Vivacqua Carneiro, Pedro Azevedo,
  Vinicius~B Cardoso, Avelino Forechi, Luan Jesus, Rodrigo Berriel, Thiago~M
  Paixao, Filipe Mutz, et~al.
\newblock Self-driving cars: A survey.
\newblock \emph{Expert Systems with Applications}, 165:\penalty0 113816, 2021.

\bibitem[Fredrikson et~al.(2023)Fredrikson, Lu, Vijayakumar, Jha, Ganesh, and
  Wang]{fredrikson2023learning}
Matt Fredrikson, Kaiji Lu, Saranya Vijayakumar, Somesh Jha, Vijay Ganesh, and
  Zifan Wang.
\newblock Learning modulo theories.
\newblock \emph{arXiv preprint arXiv:2301.11435}, 2023.

\bibitem[Manhaeve et~al.(2021{\natexlab{a}})Manhaeve, Duman{\v{c}}i{\'c},
  Kimmig, Demeester, and De~Raedt]{manhaeve2021neural}
Robin Manhaeve, Sebastijan Duman{\v{c}}i{\'c}, Angelika Kimmig, Thomas
  Demeester, and Luc De~Raedt.
\newblock Neural probabilistic logic programming in deepproblog.
\newblock \emph{Artificial Intelligence}, 298:\penalty0 103504,
  2021{\natexlab{a}}.

\bibitem[Marconato et~al.(2023)Marconato, Bontempo, Ficarra, Calderara,
  Passerini, and Teso]{marconato2023neuro}
Emanuele Marconato, Gianpaolo Bontempo, Elisa Ficarra, Simone Calderara, Andrea
  Passerini, and Stefano Teso.
\newblock Neuro symbolic continual learning: Knowledge, reasoning shortcuts and
  concept rehearsal.
\newblock In \emph{ICML}, 2023.

\bibitem[LeCun(1998)]{lecun1998mnist}
Yann LeCun.
\newblock The mnist database of handwritten digits.
\newblock \emph{http://yann. lecun. com/exdb/mnist/}, 1998.

\bibitem[Fischer et~al.(2019)Fischer, Balunovic, Drachsler-Cohen, Gehr, Zhang,
  and Vechev]{fischer2019dl2}
Marc Fischer, Mislav Balunovic, Dana Drachsler-Cohen, Timon Gehr, Ce~Zhang, and
  Martin Vechev.
\newblock Dl2: Training and querying neural networks with logic.
\newblock In \emph{International Conference on Machine Learning}, pages
  1931--1941. PMLR, 2019.

\bibitem[Ahmed et~al.(2022{\natexlab{b}})Ahmed, Wang, Chang, and Van~den
  Broeck]{ahmed2022neuro}
Kareem Ahmed, Eric Wang, Kai-Wei Chang, and Guy Van~den Broeck.
\newblock Neuro-symbolic entropy regularization.
\newblock In \emph{UAI}, 2022{\natexlab{b}}.

\bibitem[Hoernle et~al.(2022)Hoernle, Karampatsis, Belle, and
  Gal]{hoernle2022multiplexnet}
Nick Hoernle, Rafael~Michael Karampatsis, Vaishak Belle, and Kobi Gal.
\newblock Multiplexnet: Towards fully satisfied logical constraints in neural
  networks.
\newblock In \emph{AAAI}, 2022.

\bibitem[Diligenti et~al.(2012)Diligenti, Gori, Maggini, and
  Rigutini]{diligenti2012bridging}
Michelangelo Diligenti, Marco Gori, Marco Maggini, and Leonardo Rigutini.
\newblock Bridging logic and kernel machines.
\newblock \emph{Machine learning}, 86\penalty0 (1):\penalty0 57--88, 2012.

\bibitem[Pryor et~al.(2022)Pryor, Dickens, Augustine, Albalak, Wang, and
  Getoor]{pryor2022neupsl}
Connor Pryor, Charles Dickens, Eriq Augustine, Alon Albalak, William Wang, and
  Lise Getoor.
\newblock Neupsl: Neural probabilistic soft logic.
\newblock \emph{arXiv preprint arXiv:2205.14268}, 2022.

\bibitem[De~Raedt and Kimmig(2015)]{de2015probabilistic}
Luc De~Raedt and Angelika Kimmig.
\newblock Probabilistic (logic) programming concepts.
\newblock \emph{Machine Learning}, 2015.

\bibitem[Darwiche and Marquis(2002)]{darwiche2002knowledge}
Adnan Darwiche and Pierre Marquis.
\newblock A knowledge compilation map.
\newblock \emph{Journal of Artificial Intelligence Research}, 17:\penalty0
  229--264, 2002.

\bibitem[Vergari et~al.(2021)Vergari, Choi, Liu, Teso, and Van~den
  Broeck]{vergari2021compositional}
Antonio Vergari, YooJung Choi, Anji Liu, Stefano Teso, and Guy Van~den Broeck.
\newblock A compositional atlas of tractable circuit operations for
  probabilistic inference.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Manhaeve et~al.(2021{\natexlab{b}})Manhaeve, Marra, and
  De~Raedt]{manhaeve2021approximate}
Robin Manhaeve, Giuseppe Marra, and Luc De~Raedt.
\newblock Approximate inference for neural probabilistic logic programming.
\newblock In \emph{KR}, 2021{\natexlab{b}}.

\bibitem[Huang et~al.(2021)Huang, Li, Chen, Samel, Naik, Song, and
  Si]{huang2021scallop}
Jiani Huang, Ziyang Li, Binghong Chen, Karan Samel, Mayur Naik, Le~Song, and
  Xujie Si.
\newblock Scallop: From probabilistic deductive databases to scalable
  differentiable reasoning.
\newblock \emph{NeurIPS}, 2021.

\bibitem[Winters et~al.(2022)Winters, Marra, Manhaeve, and
  De~Raedt]{winters2022deepstochlog}
Thomas Winters, Giuseppe Marra, Robin Manhaeve, and Luc De~Raedt.
\newblock {DeepStochLog: Neural Stochastic Logic Programming}.
\newblock In \emph{AAAI}, 2022.

\bibitem[van Krieken et~al.(2022)van Krieken, Thanapalasingam, Tomczak, van
  Harmelen, and Teije]{van2022anesi}
Emile van Krieken, Thiviyan Thanapalasingam, Jakub~M Tomczak, Frank van
  Harmelen, and Annette~ten Teije.
\newblock A-nesi: A scalable approximate method for probabilistic neurosymbolic
  inference.
\newblock \emph{arXiv preprint arXiv:2212.12393}, 2022.

\bibitem[Sch{\"o}lkopf et~al.(2021)Sch{\"o}lkopf, Locatello, Bauer, Ke,
  Kalchbrenner, Goyal, and Bengio]{scholkopf2021toward}
Bernhard Sch{\"o}lkopf, Francesco Locatello, Stefan Bauer, Nan~Rosemary Ke, Nal
  Kalchbrenner, Anirudh Goyal, and Yoshua Bengio.
\newblock Toward causal representation learning.
\newblock \emph{Proceedings of the IEEE}, 2021.

\bibitem[Suter et~al.(2019)Suter, Miladinovic, Sch{\"o}lkopf, and
  Bauer]{suter2019robustly}
Raphael Suter, Djordje Miladinovic, Bernhard Sch{\"o}lkopf, and Stefan Bauer.
\newblock Robustly disentangled causal mechanisms: Validating deep
  representations for interventional robustness.
\newblock In \emph{International Conference on Machine Learning}, pages
  6056--6065. PMLR, 2019.

\bibitem[Von~K{\"u}gelgen et~al.(2021)Von~K{\"u}gelgen, Sharma, Gresele,
  Brendel, Sch{\"o}lkopf, Besserve, and Locatello]{vonkugelgen2021self}
Julius Von~K{\"u}gelgen, Yash Sharma, Luigi Gresele, Wieland Brendel, Bernhard
  Sch{\"o}lkopf, Michel Besserve, and Francesco Locatello.
\newblock Self-supervised learning with data augmentations provably isolates
  content from style.
\newblock \emph{Advances in neural information processing systems},
  34:\penalty0 16451--16467, 2021.

\bibitem[Quinonero-Candela et~al.(2008)Quinonero-Candela, Sugiyama,
  Schwaighofer, and Lawrence]{quinonero2008dataset}
Joaquin Quinonero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil~D
  Lawrence.
\newblock \emph{Dataset shift in machine learning}.
\newblock Mit Press, 2008.

\bibitem[Marconato et~al.(2022)Marconato, Passerini, and
  Teso]{marconato2022glancenets}
Emanuele Marconato, Andrea Passerini, and Stefano Teso.
\newblock Glancenets: Interpretabile, leak-proof concept-based models.
\newblock \emph{NeurIPS}, 2022.

\bibitem[Hinton and Zemel(1993)]{hinton1993autoencoders}
Geoffrey~E Hinton and Richard Zemel.
\newblock Autoencoders, minimum description length and helmholtz free energy.
\newblock \emph{Advances in neural information processing systems}, 6, 1993.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In \emph{International conference on machine learning}, 2014.

\bibitem[Kingma and Welling(2014)]{kingma2014auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock In \emph{International conference on machine learning}, 2014.

\bibitem[Ghosh et~al.(2020)Ghosh, Sajjadi, Vergari, Black, and
  Sch{\"o}lkopf]{ghosh2020variational}
Partha Ghosh, Mehdi~SM Sajjadi, Antonio Vergari, Michael~J Black, and Bernhard
  Sch{\"o}lkopf.
\newblock From variational to deterministic autoencoders.
\newblock In \emph{ICLR}, 2020.

\bibitem[Misino et~al.(2022)Misino, Marra, and Sansone]{misino2022vael}
Eleonora Misino, Giuseppe Marra, and Emanuele Sansone.
\newblock {VAEL: Bridging Variational Autoencoders and Probabilistic Logic
  Programming}.
\newblock \emph{NeurIPS}, 2022.

\bibitem[Locatello et~al.(2019)Locatello, Bauer, Lucic, Raetsch, Gelly,
  Sch{\"o}lkopf, and Bachem]{locatello2019challenging}
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly,
  Bernhard Sch{\"o}lkopf, and Olivier Bachem.
\newblock Challenging common assumptions in the unsupervised learning of
  disentangled representations.
\newblock In \emph{ICML}, 2019.

\bibitem[Locatello et~al.(2020{\natexlab{a}})Locatello, Poole, R{\"a}tsch,
  Sch{\"o}lkopf, Bachem, and Tschannen]{locatello2020weakly}
Francesco Locatello, Ben Poole, Gunnar R{\"a}tsch, Bernhard Sch{\"o}lkopf,
  Olivier Bachem, and Michael Tschannen.
\newblock Weakly-supervised disentanglement without compromises.
\newblock In \emph{International Conference on Machine Learning}, pages
  6348--6359. PMLR, 2020{\natexlab{a}}.

\bibitem[Shu et~al.(2019)Shu, Chen, Kumar, Ermon, and Poole]{shu2019weakly}
Rui Shu, Yining Chen, Abhishek Kumar, Stefano Ermon, and Ben Poole.
\newblock Weakly supervised disentanglement with guarantees.
\newblock In \emph{ICLR}, 2019.

\bibitem[M{\"u}ller et~al.(2019)M{\"u}ller, Kornblith, and
  Hinton]{muller2019does}
Rafael M{\"u}ller, Simon Kornblith, and Geoffrey~E Hinton.
\newblock When does label smoothing help?
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Li et~al.(2021)Li, Du, van~de Ven, and Mordatch]{li2021energy}
Shuang Li, Yilun Du, Gido~Martijn van~de Ven, and Igor Mordatch.
\newblock Energy-based models for continual learning.
\newblock In \emph{Energy Based Models Workshop-ICLR 2021}, 2021.

\bibitem[Li et~al.(2020)Li, Huang, Hong, Chen, Wu, and Zhu]{li2020closed}
Qing Li, Siyuan Huang, Yining Hong, Yixin Chen, Ying~Nian Wu, and Song-Chun
  Zhu.
\newblock Closed loop neural-symbolic learning via integrating neural
  perception, grammar parsing, and symbolic reasoning.
\newblock In \emph{International Conference on Machine Learning}, pages
  5884--5894. PMLR, 2020.

\bibitem[Wei et~al.(2022)Wei, Xie, Cheng, Feng, An, and Li]{wei2022mitigating}
Hongxin Wei, Renchunzi Xie, Hao Cheng, Lei Feng, Bo~An, and Yixuan Li.
\newblock Mitigating neural network overconfidence with logit normalization.
\newblock In \emph{International Conference on Machine Learning}, pages
  23631--23644. PMLR, 2022.

\bibitem[Mukhoti et~al.(2020)Mukhoti, Kulharia, Sanyal, Golodetz, Torr, and
  Dokania]{mukhoti2020calibrating}
Jishnu Mukhoti, Viveka Kulharia, Amartya Sanyal, Stuart Golodetz, Philip Torr,
  and Puneet Dokania.
\newblock Calibrating deep neural networks using focal loss.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 15288--15299, 2020.

\bibitem[Carratino et~al.(2022)Carratino, Ciss{\'e}, Jenatton, and
  Vert]{carratino2022mixup}
Luigi Carratino, Moustapha Ciss{\'e}, Rodolphe Jenatton, and Jean-Philippe
  Vert.
\newblock On mixup regularization.
\newblock \emph{The Journal of Machine Learning Research}, 23\penalty0
  (1):\penalty0 14632--14662, 2022.

\bibitem[Xu et~al.(2020)Xu, Yang, Gong, Lin, Wu, Li, and
  Vasconcelos]{xu2020boia}
Yiran Xu, Xiaoyin Yang, Lihang Gong, Hsuan-Chu Lin, Tz-Ying Wu, Yunsheng Li,
  and Nuno Vasconcelos.
\newblock Explainable object-induced action decision for autonomous vehicles.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2020.

\bibitem[Sawada and Nakamura(2022)]{sawada2022concept}
Yoshihide Sawada and Keigo Nakamura.
\newblock Concept bottleneck model with additional unsupervised concepts.
\newblock \emph{IEEE Access}, 10:\penalty0 41758--41765, 2022.

\bibitem[Geirhos et~al.(2020)Geirhos, Jacobsen, Michaelis, Zemel, Brendel,
  Bethge, and Wichmann]{geirhos2020shortcut}
Robert Geirhos, J{\"o}rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel,
  Wieland Brendel, Matthias Bethge, and Felix~A Wichmann.
\newblock Shortcut learning in deep neural networks.
\newblock \emph{Nature Machine Intelligence}, 2\penalty0 (11):\penalty0
  665--673, 2020.

\bibitem[Lapuschkin et~al.(2019)Lapuschkin, W{\"a}ldchen, Binder, Montavon,
  Samek, and M{\"u}ller]{lapuschkin2019unmasking}
Sebastian Lapuschkin, Stephan W{\"a}ldchen, Alexander Binder, Gr{\'e}goire
  Montavon, Wojciech Samek, and Klaus-Robert M{\"u}ller.
\newblock Unmasking clever hans predictors and assessing what machines really
  learn.
\newblock \emph{Nature communications}, 10\penalty0 (1):\penalty0 1--8, 2019.

\bibitem[Xiao et~al.(2020)Xiao, Engstrom, Ilyas, and Madry]{xiao2020noise}
Kai~Yuanqing Xiao, Logan Engstrom, Andrew Ilyas, and Aleksander Madry.
\newblock Noise or signal: The role of image backgrounds in object recognition.
\newblock In \emph{ICLR}, 2020.

\bibitem[Schramowski et~al.(2020)Schramowski, Stammer, Teso, Brugger, Herbert,
  Shao, Luigs, Mahlein, and Kersting]{schramowski2020making}
Patrick Schramowski, Wolfgang Stammer, Stefano Teso, Anna Brugger, Franziska
  Herbert, Xiaoting Shao, Hans-Georg Luigs, Anne-Katrin Mahlein, and Kristian
  Kersting.
\newblock Making deep neural networks right for the right scientific reasons by
  interacting with their explanations.
\newblock \emph{Nature Machine Intelligence}, 2\penalty0 (8):\penalty0
  476--486, 2020.

\bibitem[Ross et~al.(2017)Ross, Hughes, and Doshi-Velez]{ross2017right}
Andrew~Slavin Ross, Michael~C Hughes, and Finale Doshi-Velez.
\newblock Right for the right reasons: training differentiable models by
  constraining their explanations.
\newblock In \emph{Proceedings of the 26th International Joint Conference on
  Artificial Intelligence}, pages 2662--2670, 2017.

\bibitem[Parascandolo et~al.(2020)Parascandolo, Neitz, ORVIETO, Gresele, and
  Sch{\"o}lkopf]{parascandolo2020learning}
Giambattista Parascandolo, Alexander Neitz, ANTONIO ORVIETO, Luigi Gresele, and
  Bernhard Sch{\"o}lkopf.
\newblock Learning explanations that are hard to vary.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Teso et~al.(2023)Teso, Alkan, Stammer, and Daly]{teso2023leveraging}
Stefano Teso, {\"O}znur Alkan, Wolfang Stammer, and Elizabeth Daly.
\newblock Leveraging explanations in interactive machine learning: An overview.
\newblock \emph{Frontiers in Artificial Intelligence}, 2023.

\bibitem[Stammer et~al.(2021)Stammer, Memmel, Schramowski, and
  Kersting]{stammer2021interactive}
Wolfgang Stammer, Marius Memmel, Patrick Schramowski, and Kristian Kersting.
\newblock Interactive disentanglement: Learning concepts by interacting with
  their prototype representations.
\newblock \emph{arXiv preprint arXiv:2112.02290}, 2021.

\bibitem[Bengio et~al.(2013)Bengio, Courville, and
  Vincent]{bengio2013representation}
Yoshua Bengio, Aaron Courville, and Pascal Vincent.
\newblock Representation learning: A review and new perspectives.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 35\penalty0 (8):\penalty0 1798--1828, 2013.

\bibitem[Hyv{\"a}rinen et~al.(2023)Hyv{\"a}rinen, Khemakhem, and
  Morioka]{hyvarinen2023nonlinear}
Aapo Hyv{\"a}rinen, Ilyes Khemakhem, and Hiroshi Morioka.
\newblock Nonlinear independent component analysis for principled
  disentanglement in unsupervised deep learning.
\newblock \emph{Patterns}, 4\penalty0 (10), 2023.

\bibitem[Khemakhem et~al.(2020)Khemakhem, Kingma, Monti, and
  Hyvarinen]{khemakhem2020variational}
Ilyes Khemakhem, Diederik Kingma, Ricardo Monti, and Aapo Hyvarinen.
\newblock {Variational autoencoders and nonlinear ICA: A unifying framework}.
\newblock In \emph{AISTATS}, 2020.

\bibitem[Buchholz et~al.(2022)Buchholz, Besserve, and
  Sch{\"o}lkopf]{buchholz2022function}
Simon Buchholz, Michel Besserve, and Bernhard Sch{\"o}lkopf.
\newblock Function classes for identifiable nonlinear independent component
  analysis.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 16946--16961, 2022.

\bibitem[Gresele et~al.(2021)Gresele, Von~K{\"u}gelgen, Stimper, Sch{\"o}lkopf,
  and Besserve]{gresele2021independent}
Luigi Gresele, Julius Von~K{\"u}gelgen, Vincent Stimper, Bernhard
  Sch{\"o}lkopf, and Michel Besserve.
\newblock Independent mechanism analysis, a new concept?
\newblock \emph{Advances in neural information processing systems},
  34:\penalty0 28233--28248, 2021.

\bibitem[Ahuja et~al.(2023)Ahuja, Mahajan, Wang, and
  Bengio]{ahuja2023interventional}
Kartik Ahuja, Divyat Mahajan, Yixin Wang, and Yoshua Bengio.
\newblock Interventional causal representation learning.
\newblock In \emph{International conference on machine learning}, pages
  372--407. PMLR, 2023.

\bibitem[Liang et~al.(2023)Liang, Keki{\'c}, von K{\"u}gelgen, Buchholz,
  Besserve, Gresele, and Sch{\"o}lkopf]{liang2023causal}
Wendong Liang, Armin Keki{\'c}, Julius von K{\"u}gelgen, Simon Buchholz, Michel
  Besserve, Luigi Gresele, and Bernhard Sch{\"o}lkopf.
\newblock Causal component analysis.
\newblock \emph{arXiv preprint arXiv:2305.17225}, 2023.

\bibitem[von K{\"u}gelgen et~al.(2023)von K{\"u}gelgen, Besserve, Liang,
  Gresele, Keki{\'c}, Bareinboim, Blei, and
  Sch{\"o}lkopf]{von2023nonparametric}
Julius von K{\"u}gelgen, Michel Besserve, Wendong Liang, Luigi Gresele, Armin
  Keki{\'c}, Elias Bareinboim, David~M Blei, and Bernhard Sch{\"o}lkopf.
\newblock Nonparametric identifiability of causal representations from unknown
  interventions.
\newblock \emph{arXiv preprint arXiv:2306.00542}, 2023.

\bibitem[Maziarka et~al.(2022)Maziarka, Nowak, Wo{\l}czyk, and
  Bedychaj]{maziarka2022relationship}
{\L}ukasz Maziarka, Aleksandra Nowak, Maciej Wo{\l}czyk, and Andrzej Bedychaj.
\newblock On the relationship between disentanglement and multi-task learning.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 625--641. Springer, 2022.

\bibitem[Lachapelle et~al.(2023)Lachapelle, Deleu, Mahajan, Mitliagkas, Bengio,
  Lacoste-Julien, and Bertrand]{lachapelle2023synergies}
S{\'e}bastien Lachapelle, Tristan Deleu, Divyat Mahajan, Ioannis Mitliagkas,
  Yoshua Bengio, Simon Lacoste-Julien, and Quentin Bertrand.
\newblock Synergies between disentanglement and sparsity: generalization and
  identifiability in multi-task learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  18171--18206. PMLR, 2023.

\bibitem[Fumero et~al.(2023)Fumero, Wenzel, Zancato, Achille, Rodol{\`a},
  Soatto, Sch{\"o}lkopf, and Locatello]{fumero2023leveraging}
Marco Fumero, Florian Wenzel, Luca Zancato, Alessandro Achille, Emanuele
  Rodol{\`a}, Stefano Soatto, Bernhard Sch{\"o}lkopf, and Francesco Locatello.
\newblock Leveraging sparse and shared feature activations for disentangled
  representation learning.
\newblock \emph{arXiv preprint arXiv:2304.07939}, 2023.

\bibitem[Locatello et~al.(2020{\natexlab{b}})Locatello, Tschannen, Bauer,
  R{\"a}tsch, Sch{\"o}lkopf, and Bachem]{locatello2020disentangling}
Francesco Locatello, Michael Tschannen, Stefan Bauer, Gunnar R{\"a}tsch,
  Bernhard Sch{\"o}lkopf, and Olivier Bachem.
\newblock Disentangling factors of variations using few labels.
\newblock In \emph{International Conference on Learning Representations},
  2020{\natexlab{b}}.

\bibitem[Nie et~al.(2020)Nie, Karras, Garg, Debnath, Patney, Patel, and
  Anandkumar]{nie2020semi}
Weili Nie, Tero Karras, Animesh Garg, Shoubhik Debnath, Anjul Patney, Ankit~B
  Patel, and Anima Anandkumar.
\newblock Semi-supervised stylegan for disentanglement learning.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, pages 7360--7369, 2020.

\bibitem[Tang and Ellis(2023)]{tang2023perception}
Hao Tang and Kevin Ellis.
\newblock From perception to programs: regularize, overparameterize, and
  amortize.
\newblock In \emph{International Conference on Machine Learning}, pages
  33616--33631. PMLR, 2023.

\bibitem[Daniele et~al.(2022)Daniele, Campari, Malhotra, and
  Serafini]{daniele2022deep}
Alessandro Daniele, Tommaso Campari, Sagar Malhotra, and Luciano Serafini.
\newblock Deep symbolic learning: Discovering symbols and rules from
  perceptions.
\newblock \emph{arXiv preprint arXiv:2208.11561}, 2022.

\bibitem[Koh et~al.(2020)Koh, Nguyen, Tang, Mussmann, Pierson, Kim, and
  Liang]{koh2020concept}
Pang~Wei Koh, Thao Nguyen, Yew~Siang Tang, Stephen Mussmann, Emma Pierson, Been
  Kim, and Percy Liang.
\newblock Concept bottleneck models.
\newblock In \emph{International Conference on Machine Learning}, pages
  5338--5348. PMLR, 2020.

\bibitem[Zarlenga et~al.(2022)Zarlenga, Barbiero, Ciravegna, Marra, Giannini,
  Diligenti, Shams, Precioso, Melacci, Weller, et~al.]{zarlenga2022concept}
Mateo~Espinosa Zarlenga, Pietro Barbiero, Gabriele Ciravegna, Giuseppe Marra,
  Francesco Giannini, Michelangelo Diligenti, Zohreh Shams, Frederic Precioso,
  Stefano Melacci, Adrian Weller, et~al.
\newblock Concept embedding models.
\newblock \emph{arXiv preprint arXiv:2209.09056}, 2022.

\bibitem[Giannini et~al.(2018)Giannini, Diligenti, Gori, and
  Maggini]{giannini2018convex}
Francesco Giannini, Michelangelo Diligenti, Marco Gori, and Marco Maggini.
\newblock On a convex logic fragment for learning and reasoning.
\newblock \emph{IEEE Transactions on Fuzzy Systems}, 2018.

\bibitem[Cover(1999)]{cover1999elements}
Thomas~M Cover.
\newblock \emph{Elements of information theory}.
\newblock John Wiley \& Sons, 1999.

\bibitem[Ahmed et~al.(2023)Ahmed, Chang, and Van~den Broeck]{AhmedKLR23}
Kareem Ahmed, Kai-Wei Chang, and Guy Van~den Broeck.
\newblock A pseudo-semantic loss for deep generative models with logical
  constraints.
\newblock In \emph{Knowledge and Logical Reasoning in the Era of Data-driven
  Learning Workshop}, July 2023.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Carraro(2022)]{LTNtorch}
Tommaso Carraro.
\newblock {LTNtorch: PyTorch implementation of Logic Tensor Networks}, mar
  2022.
\newblock URL \url{https://doi.org/10.5281/zenodo.6394282}.

\bibitem[Kingma and Ba(2015)]{KingmaB14@adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In Yoshua Bengio and Yann LeCun, editors, \emph{3rd International
  Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May
  7-9, 2015, Conference Track Proceedings}, 2015.
\newblock URL \url{http://arxiv.org/abs/1412.6980}.

\bibitem[Ren et~al.(2015)Ren, He, Girshick, and Sun]{ren2015faster}
Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock \emph{Advances in neural information processing systems}, 28, 2015.

\end{thebibliography}
