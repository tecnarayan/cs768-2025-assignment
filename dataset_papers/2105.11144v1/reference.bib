@inproceedings{du2019gradient,
	title={Gradient descent finds global minima of deep neural networks},
	author={Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
	booktitle={International Conference on Machine Learning},
	year={2019},
}

@inproceedings{allen2019convergence,
	title={A convergence theory for deep learning via over-parameterization},
	author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
	booktitle={International Conference on Machine Learning},
	year={2019},
}

@article{krizhevsky2009learning,
	title={Learning multiple layers of features from tiny images},
	author={Krizhevsky, Alex and Hinton, Geoffrey},
	year={2009},
	publisher={Citeseer}
}

@inproceedings{he2016deep,
	title={Deep residual learning for image recognition},
	author={He, K. and Zhang, X. and Ren, S. and Sun, J.},
	booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
	year={2016}
}

@inproceedings{wang2018glue,
	title={Glue: A multi-task benchmark and analysis platform for natural language understanding},
	author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@inproceedings{vaswani2017attention,
	title={Attention is all you need},
	author={Vaswani, A. and Shazeer, N. and Parmar, N. and Uszkoreit, J. and Jones, L. and Gomez, A. N and Kaiser, {\L}. and Polosukhin, I.},
	booktitle={Advances in Neural Information Processing Systems},
	year={2017}
}

@techreport{raghunathan2019adversarial,
	title={Adversarial training can hurt generalization},
	author={Raghunathan, Aditi and Xie, Sang Michael and Yang, Fanny and Duchi, John C and Liang, Percy},
	number={arXiv:1906.06032},
	type={Preprint},
	year={2019}
}

@techreport{kannan2018adversarial,
	title={Adversarial logit pairing},
	author={Kannan, Harini and Kurakin, Alexey and Goodfellow, Ian},
	number={arXiv:1803.06373},
	type={Preprint},
	year={2018}
}

@article{xu2012robustness,
	title={Robustness and generalization},
	author={Xu, Huan and Mannor, Shie},
	journal={Machine learning},
	volume={86},
	number={3},
	pages={391--423},
	year={2012},
	publisher={Springer}
}

@techreport{bubeck2014convex,
	title={Convex optimization: Algorithms and complexity},
	author={Bubeck, S{\'e}bastien},
	number={arXiv:1405.4980},
	type={Preprint},
	year={2014}
}


@inproceedings{yin2019rademacher,
	title={Rademacher complexity for adversarially robust generalization},
	author={Yin, Dong and Kannan, Ramchandran and Bartlett, Peter},
	booktitle={International Conference on Machine Learning},
	year={2019},
}

@book{van2000weak,
	author={Aad W. van der Vaart and Jon A. Wellner},  
	year= {2000}, 
	series={Springer series in statistics},
	title={Weak convergence and empirical processes},
	publisher={Springer}
}

@book{wainwright2019,
	author={Wainwright, Martin J.},  
	year= {2019}, 
	series={Cambridge Series in Statistical and Probabilistic Mathematics},
	title={High-dimensional statistics: a non-asymptotic viewpoint},
	publisher={Cambridge University Press}
}

@book{vershynin2018, 
	place={Cambridge}, 
	author={Vershynin, Roman}, 
	year={2018},
	series={Cambridge Series in Statistical and Probabilistic Mathematics},
	title={High-dimensional probability: an introduction with applications in data science}, 
	publisher={Cambridge University Press},
	collection={Cambridge Series in Statistical and Probabilistic Mathematics}
}

@inproceedings{madry2018towards,
	title={Towards deep learning models resistant to adversarial attacks},
	author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@inproceedings{xie2020adversarial,
	title={Adversarial examples improve image recognition},
	author={Xie, Cihang and Tan, Mingxing and Gong, Boqing and Wang, Jiang and Yuille, Alan L and Le, Quoc V},
	booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
	year={2020}
}

@inproceedings{nouiehed2019solving,
	title={Solving a class of non-convex min-max games using iterative first order methods},
	author={Nouiehed, Maher and Sanjabi, Maziar and Huang, Tianjian and Lee, Jason D and Razaviyayn, Meisam},
	booktitle={Advances in Neural Information Processing Systems},
	year={2019}
}

@misc{duchi2016lecture,
	title={Lecture notes for statistics 311/electrical engineering 377},
	author={Duchi, John},
	note= {\url{http://web.stanford.edu/class/stats311/lecture-notes.pdf}},
	year={2016}
}

@inproceedings{rakhlin2012making,
	title={Making gradient descent optimal for strongly convex stochastic optimization},
	author={Rakhlin, Alexander and Shamir, Ohad and Sridharan, Karthik},
	booktitle={International Coference on Machine Learning},
	year={2012}
}

@inproceedings{hendrycks2020pretrained,
	title={Pretrained transformers improve out-of-distribution robustness},
	author={Hendrycks, Dan and Liu, Xiaoyuan and Wallace, Eric and Dziedzic, Adam and Krishnan, Rishabh and Song, Dawn},
	booktitle={Annual Conference of the Association for Computational Linguistics},
	year={2020}
}

@inproceedings{deng2009imagenet,
	title={Imagenet: A large-scale hierarchical image database},
	author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
	year={2009}
}

@inproceedings{devlin2019bert,
	title={BERT: Pre-training of deep bidirectional transformers for language understanding},
	author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	booktitle={Conference of the North American Chapter of the Association for Computational Linguistics},
	year={2019}
}

@inproceedings{lyu2019gradient,
	title={Gradient descent maximizes the margin of homogeneous neural networks},
	author={Lyu, Kaifeng and Li, Jian},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@article{soudry2018implicit,
	title={The implicit bias of gradient descent on separable data},
	author={Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
	journal={The Journal of Machine Learning Research},
	volume={19},
	number={1},
	pages={2822--2878},
	year={2018},
	publisher={JMLR. org}
}

@inproceedings{volpi2018generalizing,
	title={Generalizing to unseen domains via adversarial data augmentation},
	author={Volpi, Riccardo and Namkoong, Hongseok and Sener, Ozan and Duchi, John C and Murino, Vittorio and Savarese, Silvio},
	booktitle={Advances in Neural Information Processing Systems},
	year={2018}
}

@techreport{hendrycks2020many,
	title={The many faces of robustness: A critical analysis of out-of-distribution generalization},
	author={Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and others},
	number={arXiv:2006.16241},
	type={Preprint},
	year={2020}
}

@inproceedings{hendrycks2019using,
	title={Using Pre-Training Can Improve Model Robustness and Uncertainty},
	author={Hendrycks, Dan and Lee, Kimin and Mazeika, Mantas},
	booktitle={International Conference on Machine Learning},
	year={2019}
}

@inproceedings{sinha2018certifying,
	title={Certifying some distributional robustness with principled adversarial training},
	author={Sinha, Aman and Namkoong, Hongseok and Duchi, John},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@phdthesis{namkoong2019reliable,
	title={Reliable machine learning via distributional robustness},
	author={Namkoong, Hongseok},
	year={2019},
	school={Stanford University}
}

@techreport{duchi2016statistics,
	title={Statistics of robust optimization: A generalized empirical likelihood approach},
	author={Duchi, John and Glynn, Peter and Namkoong, Hongseok},
	number={arXiv:1610.03425},
	type={Preprint},
	year={2016}
}

@inproceedings{lee2018minimax,
	title={Minimax statistical learning with wasserstein distances},
	author={Lee, Jaeho and Raginsky, Maxim},
	booktitle={Advances in Neural Information Processing Systems},
	year={2018}
}

@inproceedings{lam2015quantifying,
	title={Quantifying input uncertainty in stochastic optimization},
	author={Lam, H and Zhou, E},
	booktitle={Winter Simulation Conference},
	year={2015}
}

@article{esfahani2018data,
	title={Data-driven distributionally robust optimization using the Wasserstein metric: Performance guarantees and tractable reformulations},
	author={Esfahani, Peyman Mohajerin and Kuhn, Daniel},
	journal={Mathematical Programming},
	volume={171},
	number={1-2},
	pages={115--166},
	year={2018},
	publisher={Springer}
}

@techreport{gao2016distributionally,
	title={Distributionally robust stochastic optimization with Wasserstein distance},
	author={Gao, Rui and Kleywegt, Anton J},
	number={arXiv:1604.02199},
	type={Preprint},
	year={2016}
}

@techreport{gao2017wasserstein,
	title={Wasserstein distributional robustness and regularization in statistical learning},
	author={Gao, Rui and Chen, Xi and Kleywegt, Anton J},
	number={arXiv:1712.06050},
	type={Preprint},
	year={2017}
}

@inproceedings{goodfellow2015explaning,
	author    = {Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
	title     = {Explaining and harnessing adversarial examples},
	booktitle = {International Conference on Learning Representations},
	year      = {2015},
}

@techreport{szegedy2013intriguing,
	title={Intriguing properties of neural networks},
	author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
	number={arXiv:1312.6199},
	type={Preprint},
	year={2013}
}

@article{weiss2016survey,
	title={A survey of transfer learning},
	author={Weiss, Karl and Khoshgoftaar, Taghi M and Wang, DingDing},
	journal={Journal of Big data},
	volume={3},
	number={1},
	pages={9},
	year={2016},
	publisher={Springer}
}

@article{schmidt2018adversarially,
	title={Adversarially robust generalization requires more data},
	author={Schmidt, Ludwig and Santurkar, Shibani and Tsipras, Dimitris and Talwar, Kunal and Madry, Aleksander},
	journal={Advances in Neural Information Processing Systems},
	volume={31},
	pages={5014--5026},
	year={2018}
}

@article{shapiro2017distributionally,
	title={Distributionally robust stochastic programming},
	author={Shapiro, Alexander},
	journal={SIAM Journal on Optimization},
	volume={27},
	number={4},
	pages={2258--2275},
	year={2017},
	publisher={SIAM}
}

@inproceedings{zhang2019theoretically,
	title={Theoretically principled trade-off between robustness and accuracy},
	author={Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael},
	booktitle={International Conference on Machine Learning},
	year={2019}
}

@inproceedings{shafahi2019adversarial,
	title={Adversarial training for free!},
	author={Shafahi, Ali and Najibi, Mahyar and Ghiasi, Mohammad Amin and Xu, Zheng and Dickerson, John and Studer, Christoph and Davis, Larry S and Taylor, Gavin and Goldstein, Tom},
	booktitle={Advances in Neural Information Processing Systems},
	year={2019}
}

@inproceedings{qin2019adversarial,
	title={Adversarial robustness through local linearization},
	author={Qin, Chongli and Martens, James and Gowal, Sven and Krishnan, Dilip and Dvijotham, Krishnamurthy and Fawzi, Alhussein and De, Soham and Stanforth, Robert and Kohli, Pushmeet},
	booktitle={Advances in Neural Information Processing Systems},
	year={2019}
}

@inproceedings{kornblith2019better,
	title={Do better imagenet models transfer better?},
	author={Kornblith, Simon and Shlens, Jonathon and Le, Quoc V},
	booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
	year={2019}
}

@inproceedings{li2019inductive,
	title={Inductive bias of gradient descent based adversarial training on separable data},
	author={Li, Yan and Fang, Ethan X and Xu, Huan and Zhao, Tuo},
	booktitle={International Conference on Learning Representations},
	year={2020}
}

@techreport{salman2020adversarially,
	title={Do adversarially robust imagenet models transfer better?},
	author={Salman, Hadi and Ilyas, Andrew and Engstrom, Logan and Kapoor, Ashish and Madry, Aleksander},
	number={arXiv:2007.08489},
	type={Preprint},
	year={2020}
}

@inproceedings{hendrycks2018benchmarking,
	title={Benchmarking neural network robustness to common corruptions and perturbations},
	author={Hendrycks, Dan and Dietterich, Thomas},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@inproceedings{ben2007analysis,
	title={Analysis of representations for domain adaptation},
	author={Ben-David, Shai and Blitzer, John and Crammer, Koby and Pereira, Fernando},
	booktitle={Advances in neural information processing systems},
	year={2007}
}

@inproceedings{zhu2019freelb,
	title={Freelb: Enhanced adversarial training for natural language understanding},
	author={Zhu, Chen and Cheng, Yu and Gan, Zhe and Sun, Siqi and Goldstein, Tom and Liu, Jingjing},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@article{jiang2019smart,
	title={Smart: Robust and efficient fine-tuning for pre-trained natural language models through principled regularized optimization},
	author={Jiang, Haoming and He, Pengcheng and Chen, Weizhu and Liu, Xiaodong and Gao, Jianfeng and Zhao, Tuo},
	journal={Annual Conference of the Association for Computational Linguistics},
	year={2020}
}


@inproceedings{socher2013recursive,
	title={Recursive deep models for semantic compositionality over a sentiment treebank},
	author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
	booktitle={Conference on Empirical Methods in Natural Language Processing},
	year={2013}
}

@inproceedings{maas2011learning,
	title={Learning word vectors for sentiment analysis},
	author={Maas, Andrew and Daly, Raymond E and Pham, Peter T and Huang, Dan and Ng, Andrew Y and Potts, Christopher},
	booktitle={Annual Conference of the Association for Computational Linguistics},
	year={2011}
}

@inproceedings{cer2017semeval,
	title={SemEval-2017 task 1: semantic textual similarity multilingual and crosslingual focused evaluation},
	author={Cer, Daniel and Diab, Mona and Agirre, Eneko and Lopez-Gazpio, I{\~n}igo and Specia, Lucia},
	booktitle={International Workshop on Semantic Evaluation},
	year={2017}
}

@inproceedings{williams2018broad,
	title={A broad-coverage challenge corpus for sentence understanding through inference},
	author={Williams, Adina and Nangia, Nikita and Bowman, Samuel},
	booktitle={Conference of the North American Chapter of the Association for Computational Linguistics},
	year={2018}
}

@inproceedings{loshchilov2018decoupled,
	title={Decoupled weight decay regularization},
	author={Loshchilov, Ilya and Hutter, Frank},
	booktitle={International Conference on Learning Representations},
	year={2018}
}


@techreport{liu2020toward,
	title={Toward a theory of optimization for over-parameterized systems of non-linear equations: the lessons of deep learning},
	author={Liu, Chaoyue and Zhu, Libin and Belkin, Mikhail},
	number={arXiv:2003.00307},
	type={Preprint},
	year={2020}
}

@inproceedings{recht2019imagenet,
	title={Do ImageNet classifiers generalize to imageNet?},
	author={Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
	booktitle={International Conference on Machine Learning},
	year={2019}
}

@inproceedings{schneider2020improving,
	title={Improving robustness against common corruptions by covariate shift adaptation},
	author={Schneider, Steffen and Rusak, Evgenia and Eck, Luisa and Bringmann, Oliver and Brendel, Wieland and Bethge, Matthias},
	booktitle={Advances in Neural Information Processing Systems},
	year={2020}
}

@techreport{salman2020unadversarial,
	title={Unadversarial examples: designing objects for robust vision},
	author={Salman, Hadi and Ilyas, Andrew and Engstrom, Logan and Vemprala, Sai and Madry, Aleksander and Kapoor, Ashish},
	number={arXiv:2012.12235},
	type={Preprint},
	year={2020}
}

@article{tu2020empirical,
	title={An empirical study on robustness to spurious correlations using pre-trained language models},
	author={Tu, Lifu and Lalwani, Garima and Gella, Spandana and He, He},
	journal={Transactions of the Association for Computational Linguistics},
	volume={8},
	pages={621--633},
	year={2020},
	publisher={MIT Press}
}

@techreport{lohn2020estimating,
	title={Estimating the brittleness of AI: safety integrity levels and the need for testing out-of-distribution performance},
	author={Lohn, Andrew J},
	number={arXiv:2009.00802},
	type={Preprint},
	year={2020}
}

@article{levy2020large,
	title={Large-scale methods for distributionally robust optimization},
	author={Levy, Daniel and Carmon, Yair and Duchi, John C and Sidford, Aaron},
	journal={Advances in Neural Information Processing Systems},
	year={2020}
}

@article{ben2013robust,
	title={Robust solutions of optimization problems affected by uncertain probabilities},
	author={Ben-Tal, Aharon and Den Hertog, Dick and De Waegenaere, Anja and Melenberg, Bertrand and Rennen, Gijs},
	journal={Management Science},
	volume={59},
	number={2},
	pages={341--357},
	year={2013},
	publisher={INFORMS}
}

@inproceedings{dosovitskiy2020image,
	title={An image is worth 16x16 words: Transformers for image recognition at scale},
	author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
	booktitle={International Conference on Learning Representations},
	year={2021}
}

@misc{radford2021learning,
	title={Learning Transferable Visual Models From Natural Language Supervision},
	author={Radford, Ale and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
	year={2021},
	note={\url{https://openai.com/blog/clip/}},
}

@techreport{brown2020language,
	title={Language models are few-shot learners},
	author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
	journal={arXiv:2005.14165},
	type={Preprint},
	year={2020}
}

@book{villani2008optimal,
	title={Optimal transport: old and new},
	author={Villani, C{\'e}dric},
	volume={338},
	year={2008},
	publisher={Springer Science \& Business Media}
}

@inproceedings{athalye2018obfuscated,
	title={Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples},
	author={Athalye, Anish and Carlini, Nicholas and Wagner, David},
	booktitle={International Conference on Machine Learning},
	year={2018}
}

@techreport{nagarajan2020understanding,
	title={Understanding the failure modes of out-of-distribution generalization},
	author={Nagarajan, Vaishnavh and Andreassen, Anders and Neyshabur, Behnam},
	number={arXiv:2010.15775},
	type={Preprint},
	year={2020}
}

@techreport{hardt2016identity,
	title={Identity matters in deep learning},
	author={Hardt, Moritz and Ma, Tengyu},
	number={arXiv:1611.04231},
	type={Preprint},
	year={2016}
}

@inproceedings{xie2017diversity,
	title={Diversity leads to generalization in neural networks},
	author={Xie, Bo and Liang, Yingyu and Song, Le},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	year={2017}
}

@inproceedings{staib2019distributionally,
	title={Distributionally robust optimization and generalization in kernel methods},
	author={Staib, Matthew and Jegelka, Stefanie},
	booktitle={Advances in Neural Information Processing Systems},
	year={2019}
}

@inproceedings{utrera2020adversarially,
	title={Adversarially-trained deep nets transfer better},
	author={Utrera, Francisco and Kravitz, Evan and Erichson, N Benjamin and Khanna, Rajiv and Mahoney, Michael W},
	booktitle={International Conference on Learning Representations},
	year={2021}
}

@inproceedings{wolf2020transformers,
	title={Transformers: State-of-the-art natural language processing},
	author={Wolf, Thomas and Chaumond, Julien and Debut, Lysandre and Sanh, Victor and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and others},
	booktitle={Conference on Empirical Methods in Natural Language Processing},
	year={2020}
}

@techreport{liu2019roberta,
	title={Roberta: A robustly optimized bert pretraining approach},
	author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	number={arXiv:1907.11692},
	type={Preprint},
	year={2019}
}