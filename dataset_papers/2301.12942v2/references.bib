@inproceedings{putta2022scale,
  title={Scale-free adversarial multi armed bandits},
  author={Putta, Sudeep Raja and Agrawal, Shipra},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={910--930},
  year={2022},
  organization={PMLR}
}
@article{luo2021policy,
  title={Policy Optimization in Adversarial MDPs: Improved Exploration via Dilated Bonuses},
  author={Luo, Haipeng and Wei, Chen-Yu and Lee, Chung-Wei},
  journal={arXiv preprint arXiv:2107.08346},
  year={2021}
}
@article{luo2021policy_nipsver,
  title={Policy optimization in adversarial mdps: Improved exploration via dilated bonuses},
  author={Luo, Haipeng and Wei, Chen-Yu and Lee, Chung-Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={22931--22942},
  year={2021}
}
@article{dani2008price,
  title={The price of bandit information for online optimization},
  author={Dani, Varsha and Kakade, Sham M and Hayes, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={20},
  year={2008}
}
@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}
@article{foster2016learning,
  title={Learning in games: Robustness of fast convergence},
  author={Foster, Dylan J and Li, Zhiyuan and Lykouris, Thodoris and Sridharan, Karthik and Tardos, Eva},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}
@article{auer2002nonstochastic,
  title={The nonstochastic multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  journal={SIAM journal on computing},
  volume={32},
  number={1},
  pages={48--77},
  year={2002},
  publisher={SIAM}
}
@inproceedings{yang2020reinforcement,
  title={Reinforcement learning in feature space: Matrix bandit, kernels, and regret bound},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={10746--10756},
  year={2020},
  organization={PMLR}
}
@inproceedings{zanette2021cautiously,
  title={Cautiously optimistic policy optimization and exploration with linear function approximation},
  author={Zanette, Andrea and Cheng, Ching-An and Agarwal, Alekh},
  booktitle={Conference on Learning Theory},
  pages={4473--4525},
  year={2021},
  organization={PMLR}
}
@inproceedings{shani2020optimistic,
  title={Optimistic policy optimization with bandit feedback},
  author={Shani, Lior and Efroni, Yonathan and Rosenberg, Aviv and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={8604--8613},
  year={2020},
  organization={PMLR}
}

@article{neu2021online,
  title={Online learning in MDPs with linear function approximation and bandit feedback.},
  author={Neu, Gergely and Olkhovskaya, Julia},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={10407--10417},
  year={2021}
}
@article{agarwal2020pc,
  title={Pc-pg: Policy cover directed exploration for provable policy gradient learning},
  author={Agarwal, Alekh and Henaff, Mikael and Kakade, Sham and Sun, Wen},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={13399--13412},
  year={2020}
}

@inproceedings{neu2020efficient,
  title={Efficient and robust algorithms for adversarial linear contextual bandits},
  author={Neu, Gergely and Olkhovskaya, Julia},
  booktitle={Conference on Learning Theory},
  pages={3049--3068},
  year={2020},
  organization={PMLR}
}

@article{zimin2013online,
  title={Online learning in episodic Markovian decision processes by relative entropy policy search},
  author={Zimin, Alexander and Neu, Gergely},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}
@inproceedings{rosenberg2019online,
  title={Online convex optimization in adversarial markov decision processes},
  author={Rosenberg, Aviv and Mansour, Yishay},
  booktitle={International Conference on Machine Learning},
  pages={5478--5486},
  year={2019},
  organization={PMLR}
}
@inproceedings{jin2020learning,
  title={Learning adversarial markov decision processes with bandit feedback and unknown transition},
  author={Jin, Chi and Jin, Tiancheng and Luo, Haipeng and Sra, Suvrit and Yu, Tiancheng},
  booktitle={International Conference on Machine Learning},
  pages={4860--4869},
  year={2020},
  organization={PMLR}
}
@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}
@inproceedings{wei2021learning,
  title={Learning infinite-horizon average-reward mdps with linear function approximation},
  author={Wei, Chen-Yu and Jahromi, Mehdi Jafarnia and Luo, Haipeng and Jain, Rahul},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3007--3015},
  year={2021},
  organization={PMLR}
}

@inproceedings{cai2020provably,
  title={Provably efficient exploration in policy optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={1283--1294},
  year={2020},
  organization={PMLR}
}
@inproceedings{zimmert2022return,
  title={Return of the bias: Almost minimax optimal high probability bounds for adversarial linear bandits},
  author={Zimmert, Julian and Lattimore, Tor},
  booktitle={Conference on Learning Theory},
  pages={3285--3312},
  year={2022},
  organization={PMLR}
}



@inproceedings{abbasi2019politex,
  title={Politex: Regret bounds for policy iteration using expert prediction},
  author={Abbasi-Yadkori, Yasin and Bartlett, Peter and Bhatia, Kush and Lazic, Nevena and Szepesvari, Csaba and Weisz, Gell{\'e}rt},
  booktitle={International Conference on Machine Learning},
  pages={3692--3702},
  year={2019},
  organization={PMLR}
}

@inproceedings{wei2018more,
  title={More adaptive algorithms for adversarial bandits},
  author={Wei, Chen-Yu and Luo, Haipeng},
  booktitle={Conference On Learning Theory},
  pages={1263--1291},
  year={2018},
  organization={PMLR}
}
@article{zheng2019equipping,
  title={Equipping experts/bandits with long-term memory},
  author={Zheng, Kai and Luo, Haipeng and Diakonikolas, Ilias and Wang, Liwei},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}
@article{abernethy2015fighting,
  title={Fighting bandits with a new kind of smoothness},
  author={Abernethy, Jacob D and Lee, Chansoo and Tewari, Ambuj},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  pages={2197--2205},
  year={2015}
}
@inproceedings{zhou2021provably,
  title={Provably efficient reinforcement learning for discounted mdps with feature mapping},
  author={Zhou, Dongruo and He, Jiafan and Gu, Quanquan},
  booktitle={International Conference on Machine Learning},
  pages={12793--12802},
  year={2021},
  organization={PMLR}
}
@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={In Proc. 19th International Conference on Machine Learning},
  year={2002},
  organization={Citeseer}
}
@inproceedings{ito2021parameter,
  title={Parameter-free multi-armed bandit algorithms with hybrid data-dependent regret bounds},
  author={Ito, Shinji},
  booktitle={Conference on Learning Theory},
  pages={2552--2583},
  year={2021},
  organization={PMLR}
}
@article{wang2020reward,
  title={On reward-free reinforcement learning with linear function approximation},
  author={Wang, Ruosong and Du, Simon S and Yang, Lin and Salakhutdinov, Russ R},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={17816--17826},
  year={2020}
}
@inproceedings{bubeck2012towards,
  title={Towards minimax policies for online linear optimization with bandit feedback},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and Kakade, Sham M},
  booktitle={Conference on Learning Theory},
  pages={41--1},
  year={2012},
  organization={JMLR Workshop and Conference Proceedings}
}
@article{tropp2012user,
  title={User-friendly tail bounds for sums of random matrices},
  author={Tropp, Joel A},
  journal={Foundations of computational mathematics},
  volume={12},
  number={4},
  pages={389--434},
  year={2012},
  publisher={Springer}
}
@article{meng2010optimal,
  title={The optimal perturbation bounds of the Moore--Penrose inverse under the Frobenius norm},
  author={Meng, Lingsheng and Zheng, Bing},
  journal={Linear algebra and its applications},
  volume={432},
  number={4},
  pages={956--963},
  year={2010},
  publisher={Elsevier}
}
@inproceedings{he2022near,
  title={Near-optimal Policy Optimization Algorithms for Learning Adversarial Linear Mixture MDPs},
  author={He, Jiafan and Zhou, Dongruo and Gu, Quanquan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4259--4280},
  year={2022},
  organization={PMLR}
}
@inproceedings{chu2011contextual,
  title={Contextual bandits with linear payoff functions},
  author={Chu, Wei and Li, Lihong and Reyzin, Lev and Schapire, Robert},
  booktitle={Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages={208--214},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}
@article{ito2020tight,
  title={Tight first-and second-order regret bounds for adversarial linear bandits},
  author={Ito, Shinji and Hirahara, Shuichi and Soma, Tasuku and Yoshida, Yuichi},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2028--2038},
  year={2020}
}
@article{wainwright2019variance,
  title={Variance-reduced $ Q $-learning is minimax optimal},
  author={Wainwright, Martin J},
  journal={arXiv preprint arXiv:1906.04697},
  year={2019}
}
@article{zhang2020almost,
  title={Almost optimal model-free reinforcement learningvia reference-advantage decomposition},
  author={Zhang, Zihan and Zhou, Yuan and Ji, Xiangyang},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15198--15207},
  year={2020}
}
@article{sherman2023improved,
  title={Improved regret for efficient online reinforcement learning with linear function approximation},
  author={Sherman, Uri and Koren, Tomer and Mansour, Yishay},
  journal={arXiv preprint arXiv:2301.13087},
  year={2023}
}
@article{kong2023improved,
  title={Improved Regret Bounds for Linear Adversarial MDPs via Linear Optimization},
  author={Kong, Fang and Zhang, Xiangcheng and Wang, Baoxiang and Li, Shuai},
  journal={arXiv preprint arXiv:2302.06834},
  year={2023}
}
@article{wagenmaker2022instance,
  title={Instance-dependent near-optimal policy identification in linear mdps via online experiment design},
  author={Wagenmaker, Andrew and Jamieson, Kevin G},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={5968--5981},
  year={2022}
}
@article{lancewicki2023delay,
  title={Delay-Adapted Policy Optimization and Improved Regret for Adversarial MDP with Delayed Bandit Feedback},
  author={Lancewicki, Tal and Rosenberg, Aviv and Sotnikov, Dmitry},
  journal={arXiv preprint arXiv:2305.07911},
  year={2023}
}