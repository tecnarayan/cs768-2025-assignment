\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Antoulas and Sorensen(2001)]{antoulas2001approximation}
A.~C. Antoulas and D.~C. Sorensen.
\newblock Approximation of large-scale dynamical systems: An overview.
\newblock \emph{International Journal of Applied Mathematics and Computer Science}, 11\penalty0 (5):\penalty0 1093--1121, 2001.

\bibitem[Besselink et~al.(2014)Besselink, van~de Wouw, Scherpen, and Nijmeijer]{besselink2014model}
B.~Besselink, N.~van~de Wouw, J.~M. Scherpen, and H.~Nijmeijer.
\newblock Model reduction for nonlinear systems by incremental balanced truncation.
\newblock \emph{IEEE Transactions on Automatic Control}, 59\penalty0 (10):\penalty0 2739--2753, 2014.

\bibitem[Bradbury et~al.(2018)Bradbury, Frostig, Hawkins, Johnson, Leary, Maclaurin, Necula, Paszke, VanderPlas, Wanderman-Milne, et~al.]{jax}
J.~Bradbury, R.~Frostig, P.~Hawkins, M.~J. Johnson, C.~Leary, D.~Maclaurin, G.~Necula, A.~Paszke, J.~VanderPlas, S.~Wanderman-Milne, et~al.
\newblock Jax: composable transformations of python+ numpy programs.
\newblock 2018.

\bibitem[Chen(1984)]{linsysbook}
C.-T. Chen.
\newblock \emph{Linear system theory and design}.
\newblock Saunders college publishing, 1984.

\bibitem[Cheng et~al.(2024)Cheng, Zhang, and Shi]{cheng2024survey}
H.~Cheng, M.~Zhang, and J.~Q. Shi.
\newblock A survey on deep neural network pruning: Taxonomy, comparison, analysis, and recommendations.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2024.

\bibitem[Cheng et~al.(2019)Cheng, Scherpen, and Besselink]{cheng2019balanced}
X.~Cheng, J.~M. Scherpen, and B.~Besselink.
\newblock Balanced truncation of networked linear passive systems.
\newblock \emph{Automatica}, 104:\penalty0 17--25, 2019.

\bibitem[Curtain and Zwart(2012)]{curtain2012introduction}
R.~F. Curtain and H.~Zwart.
\newblock \emph{An introduction to infinite-dimensional linear systems theory}, volume~21.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Evci et~al.(2020)Evci, Gale, Menick, Castro, and Elsen]{evci2020rigging}
U.~Evci, T.~Gale, J.~Menick, P.~S. Castro, and E.~Elsen.
\newblock Rigging the lottery: Making all tickets winners.
\newblock In \emph{International conference on machine learning}, pages 2943--2952. PMLR, 2020.

\bibitem[Gale et~al.(2019)Gale, Elsen, and Hooker]{gale2019state}
T.~Gale, E.~Elsen, and S.~Hooker.
\newblock The state of sparsity in deep neural networks.
\newblock \emph{arXiv preprint arXiv:1902.09574}, 2019.

\bibitem[Goel et~al.(2022)Goel, Gu, Donahue, and R{\'e}]{sashimi}
K.~Goel, A.~Gu, C.~Donahue, and C.~R{\'e}.
\newblock Itâ€™s raw! audio generation with state-space models.
\newblock In \emph{International Conference on Machine Learning}, pages 7616--7633. PMLR, 2022.

\bibitem[Green and Limebeer(2012)]{robctrlbook}
M.~Green and D.~J. Limebeer.
\newblock \emph{Linear robust control}.
\newblock Courier Corporation, 2012.

\bibitem[Gu and Dao(2023)]{mamba}
A.~Gu and T.~Dao.
\newblock Mamba: Linear-time sequence modeling with selective state spaces.
\newblock \emph{arXiv preprint arXiv:2312.00752}, 2023.

\bibitem[Gu et~al.(2020)Gu, Dao, Ermon, Rudra, and R{\'e}]{hippo}
A.~Gu, T.~Dao, S.~Ermon, A.~Rudra, and C.~R{\'e}.
\newblock Hippo: Recurrent memory with optimal polynomial projections.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1474--1487, 2020.

\bibitem[Gu et~al.(2021)Gu, Johnson, Goel, Saab, Dao, Rudra, and R{\'e}]{lssl}
A.~Gu, I.~Johnson, K.~Goel, K.~Saab, T.~Dao, A.~Rudra, and C.~R{\'e}.
\newblock Combining recurrent, convolutional, and continuous-time models with linear state space layers.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 572--585, 2021.

\bibitem[Gu et~al.(2022{\natexlab{a}})Gu, Goel, Gupta, and R{\'e}]{s4d}
A.~Gu, K.~Goel, A.~Gupta, and C.~R{\'e}.
\newblock On the parameterization and initialization of diagonal state space models.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 35971--35983, 2022{\natexlab{a}}.

\bibitem[Gu et~al.(2022{\natexlab{b}})Gu, Goel, and R\'e]{s4}
A.~Gu, K.~Goel, and C.~R\'e.
\newblock Efficiently modeling long sequences with structured state spaces.
\newblock In \emph{The International Conference on Learning Representations}, 2022{\natexlab{b}}.

\bibitem[Gupta et~al.(2022)Gupta, Gu, and Berant]{dss}
A.~Gupta, A.~Gu, and J.~Berant.
\newblock Diagonal state spaces are as effective as structured state spaces.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 22982--22994, 2022.

\bibitem[Han et~al.(2015)Han, Pool, Tran, and Dally]{han2015learning}
S.~Han, J.~Pool, J.~Tran, and W.~Dally.
\newblock Learning both weights and connections for efficient neural network.
\newblock \emph{Advances in neural information processing systems}, 28, 2015.

\bibitem[He et~al.(2017)He, Zhang, and Sun]{he2017channel}
Y.~He, X.~Zhang, and J.~Sun.
\newblock Channel pruning for accelerating very deep neural networks.
\newblock In \emph{Proceedings of the IEEE international conference on computer vision}, pages 1389--1397, 2017.

\bibitem[Hendrycks and Gimpel(2016)]{gelu}
D.~Hendrycks and K.~Gimpel.
\newblock Gaussian error linear units (gelus).
\newblock \emph{arXiv preprint arXiv:1606.08415}, 2016.

\bibitem[Horn and Johnson(2012)]{horn2012matrix}
R.~A. Horn and C.~R. Johnson.
\newblock \emph{Matrix analysis}.
\newblock Cambridge university press, 2012.

\bibitem[Jones and Kerrigan(2010)]{jones2010discretization}
B.~L. Jones and E.~C. Kerrigan.
\newblock When is the discretization of a spatially distributed system good enough for control?
\newblock \emph{Automatica}, 46\penalty0 (9):\penalty0 1462--1468, 2010.

\bibitem[Kailath(1980)]{kailath1980linear}
T.~Kailath.
\newblock \emph{Linear systems}, volume 156.
\newblock Prentice-Hall Englewood Cliffs, NJ, 1980.

\bibitem[Khalil et~al.(1996)Khalil, Doyle, and Glover]{khalil1996robust}
I.~Khalil, J.~Doyle, and K.~Glover.
\newblock \emph{Robust and optimal control}.
\newblock Prentice hall, 1996.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton, et~al.]{cifar}
A.~Krizhevsky, G.~Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Lee et~al.(2021)Lee, Park, Mo, Ahn, and Shin]{lamp}
J.~Lee, S.~Park, S.~Mo, S.~Ahn, and J.~Shin.
\newblock Layer-adaptive sparsity for the magnitude-based pruning.
\newblock In \emph{The International Conference on Learning Representations}, 2021.

\bibitem[Li and White(1999)]{li1999efficient}
J.-R. Li and J.~White.
\newblock Efficient model reduction of interconnect via approximate system gramians.
\newblock In \emph{1999 IEEE/ACM International Conference on Computer-Aided Design. Digest of Technical Papers (Cat. No. 99CH37051)}, pages 380--383. IEEE, 1999.

\bibitem[Linsley et~al.(2018)Linsley, Kim, Veerabadran, Windolf, and Serre]{pathfinder}
D.~Linsley, J.~Kim, V.~Veerabadran, C.~Windolf, and T.~Serre.
\newblock Learning long-range spatial dependencies with horizontal gated recurrent units.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Maas et~al.(2011)Maas, Daly, Pham, Huang, Ng, and Potts]{sentiment}
A.~Maas, R.~E. Daly, P.~T. Pham, D.~Huang, A.~Y. Ng, and C.~Potts.
\newblock Learning word vectors for sentiment analysis.
\newblock In \emph{Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies}, pages 142--150, 2011.

\bibitem[Mocanu et~al.(2018)Mocanu, Mocanu, Stone, Nguyen, Gibescu, and Liotta]{mocanu2018scalable}
D.~C. Mocanu, E.~Mocanu, P.~Stone, P.~H. Nguyen, M.~Gibescu, and A.~Liotta.
\newblock Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science.
\newblock \emph{Nature communications}, 9\penalty0 (1):\penalty0 2383, 2018.

\bibitem[Morcos et~al.(2019)Morcos, Yu, Paganini, and Tian]{morcos2019one}
A.~Morcos, H.~Yu, M.~Paganini, and Y.~Tian.
\newblock One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Nangia and Bowman(2018)]{listops}
N.~Nangia and S.~R. Bowman.
\newblock Listops: A diagnostic dataset for latent tree learning.
\newblock \emph{arXiv preprint arXiv:1804.06028}, 2018.

\bibitem[Neyshabur et~al.(2015)Neyshabur, Tomioka, and Srebro]{neyshabur2015norm}
B.~Neyshabur, R.~Tomioka, and N.~Srebro.
\newblock Norm-based capacity control in neural networks.
\newblock In \emph{Conference on learning theory}, pages 1376--1401. PMLR, 2015.

\bibitem[Parnichkun et~al.(2024)Parnichkun, Massaroli, Moro, Smith, Hasani, Lechner, An, R{\'e}, Asama, Ermon, et~al.]{rtf}
R.~N. Parnichkun, S.~Massaroli, A.~Moro, J.~T. Smith, R.~Hasani, M.~Lechner, Q.~An, C.~R{\'e}, H.~Asama, S.~Ermon, et~al.
\newblock State-free inference of state-space models: The transfer function approach.
\newblock \emph{arXiv preprint arXiv:2405.06147}, 2024.

\bibitem[Penzl(2006)]{penzl2006algorithms}
T.~Penzl.
\newblock Algorithms for model reduction of large dynamical systems.
\newblock \emph{Linear algebra and its applications}, 415\penalty0 (2-3):\penalty0 322--343, 2006.

\bibitem[Petreczky et~al.(2013)Petreczky, Wisniewski, and Leth]{petreczky2013balanced}
M.~Petreczky, R.~Wisniewski, and J.~Leth.
\newblock Balanced truncation for linear switched systems.
\newblock \emph{Nonlinear Analysis: Hybrid Systems}, 10:\penalty0 4--20, 2013.

\bibitem[Qin and Sun(2023)]{qin2023observer}
Y.~Qin and Z.~Sun.
\newblock Observer-based asynchronous event-triggered robust \textit{H}$_\infty$ adaptive switching control for nonlinear industrial cyber physical systems under data injection attacks.
\newblock \emph{International Journal of Control, Automation and Systems}, 21\penalty0 (7):\penalty0 2175--2182, 2023.

\bibitem[Radev et~al.(2009)Radev, Muthukrishnan, and Qazvinian]{aan}
D.~R. Radev, P.~Muthukrishnan, and V.~Qazvinian.
\newblock The {ACL} {A}nthology network corpus.
\newblock In M.-Y. Kan and S.~Teufel, editors, \emph{Proceedings of the 2009 Workshop on Text and Citation Analysis for Scholarly Digital Libraries}, pages 54--61, Suntec City, Singapore, Aug. 2009. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/W09-3607}.

\bibitem[Rush and Karamcheti(2022)]{annotateds4}
S.~Rush and S.~Karamcheti.
\newblock The annotated s4.
\newblock In \emph{Blog Track at {ICLR}}, 2022.

\bibitem[Safonov and Chiang(1988)]{safonov1988schur}
M.~Safonov and R.~Chiang.
\newblock A schur method for balanced model reduction.
\newblock In \emph{1988 American Control Conference}, pages 1036--1040. IEEE, 1988.

\bibitem[Smith et~al.(2023)Smith, Warrington, and Linderman]{s5}
J.~T. Smith, A.~Warrington, and S.~Linderman.
\newblock Simplified state space layers for sequence modeling.
\newblock In \emph{The International Conference on Learning Representations}, 2023.

\bibitem[Tay et~al.(2021)Tay, Dehghani, Abnar, Shen, Bahri, Pham, Rao, Yang, Ruder, and Metzler]{lra}
Y.~Tay, M.~Dehghani, S.~Abnar, Y.~Shen, D.~Bahri, P.~Pham, J.~Rao, L.~Yang, S.~Ruder, and D.~Metzler.
\newblock Long range arena : A benchmark for efficient transformers.
\newblock In \emph{The International Conference on Learning Representations}, 2021.

\bibitem[Warden(2018)]{sc35}
P.~Warden.
\newblock Speech commands: A dataset for limited-vocabulary speech recognition.
\newblock \emph{arXiv preprint arXiv:1804.03209}, 2018.

\bibitem[Xu et~al.(2023)Xu, Wang, Geng, Wu, Li, and Lin]{xu2023efficient}
K.~Xu, Z.~Wang, X.~Geng, M.~Wu, X.~Li, and W.~Lin.
\newblock Efficient joint optimization of layer-adaptive weight pruning in deep neural networks.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 17447--17457, 2023.

\bibitem[Zhang et~al.(2023)Zhang, Saab, Poli, Dao, Goel, and R{\'e}]{spacetime}
M.~Zhang, K.~K. Saab, M.~Poli, T.~Dao, K.~Goel, and C.~R{\'e}.
\newblock Effectively modeling time series with simple discrete state spaces.
\newblock \emph{The International Conference on Learning Representations}, 2023.

\bibitem[Zheng et~al.(2023)Zheng, Shi, Wu, and Jiang]{zheng2023robust}
Q.~Zheng, W.~Shi, K.~Wu, and S.~Jiang.
\newblock Robust \textit{H}$_\infty$ and guaranteed cost filtering for ts fuzzy systems with multipath quantizations.
\newblock \emph{International Journal of Control, Automation and Systems}, 21\penalty0 (2):\penalty0 671--683, 2023.

\bibitem[Zhu and Gupta(2017)]{zhu2017prune}
M.~Zhu and S.~Gupta.
\newblock To prune, or not to prune: exploring the efficacy of pruning for model compression.
\newblock \emph{arXiv preprint arXiv:1710.01878}, 2017.

\end{thebibliography}
