\begin{thebibliography}{33}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Arora et~al.(2012)Arora, Hazan, and Kale]{arora2012multiplicative}
S.~Arora, E.~Hazan, and S.~Kale.
\newblock The multiplicative weights update method: a meta-algorithm and
  applications.
\newblock \emph{Theory of Computing}, 8\penalty0 (1):\penalty0 121--164, 2012.

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, and Gentile]{auer2002adaptive}
P.~Auer, N.~Cesa-Bianchi, and C.~Gentile.
\newblock Adaptive and self-confident on-line learning algorithms.
\newblock \emph{Journal of Computer and System Sciences}, 64\penalty0
  (1):\penalty0 48--75, 2002.

\bibitem[Cesa-Bianchi and Lugosi(2006)]{cesa2006prediction}
N.~Cesa-Bianchi and G.~Lugosi.
\newblock \emph{Prediction, learning, and games}.
\newblock Cambridge university press, 2006.

\bibitem[Cesa-Bianchi et~al.(2007)Cesa-Bianchi, Mansour, and
  Stoltz]{cesa2007improved}
N.~Cesa-Bianchi, Y.~Mansour, and G.~Stoltz.
\newblock Improved second-order bounds for prediction with expert advice.
\newblock \emph{Machine Learning}, 66\penalty0 (2-3):\penalty0 321--352, 2007.

\bibitem[Chiang et~al.(2012)Chiang, Yang, Lee, Mahdavi, Lu, Jin, and
  Zhu]{chiang2012online}
C.-K. Chiang, T.~Yang, C.-J. Lee, M.~Mahdavi, C.-J. Lu, R.~Jin, and S.~Zhu.
\newblock Online optimization with gradual variations.
\newblock In \emph{Conference on Learning Theory}, pages 6--1, 2012.

\bibitem[De~Rooij et~al.(2014)De~Rooij, Van~Erven, Gr{\"u}nwald, and
  Koolen]{de2014follow}
S.~De~Rooij, T.~Van~Erven, P.~D. Gr{\"u}nwald, and W.~M. Koolen.
\newblock Follow the leader if you can, hedge if you must.
\newblock \emph{The Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 1281--1316, 2014.

\bibitem[Duchi et~al.(2011)Duchi, Hazan, and Singer]{duchi2011adaptive}
J.~Duchi, E.~Hazan, and Y.~Singer.
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock \emph{Journal of machine learning research}, 12\penalty0
  (Jul):\penalty0 2121--2159, 2011.

\bibitem[Erven et~al.(2011)Erven, Koolen, Rooij, and
  Gr{\"u}nwald]{erven2011adaptive}
T.~V. Erven, W.~M. Koolen, S.~D. Rooij, and P.~Gr{\"u}nwald.
\newblock Adaptive hedge.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1656--1664, 2011.

\bibitem[Foster et~al.(2015)Foster, Rakhlin, and Sridharan]{foster2015adaptive}
D.~J. Foster, A.~Rakhlin, and K.~Sridharan.
\newblock Adaptive online learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3375--3383, 2015.

\bibitem[Foster et~al.(2017)Foster, Rakhlin, and Sridharan]{foster2017zigzag}
D.~J. Foster, A.~Rakhlin, and K.~Sridharan.
\newblock Zigzag: A new approach to adaptive online learning.
\newblock In \emph{Conference on Learning Theory}, pages 876--924, 2017.

\bibitem[Freund and Schapire(1995)]{freund1995desicion}
Y.~Freund and R.~E. Schapire.
\newblock A desicion-theoretic generalization of on-line learning and an
  application to boosting.
\newblock In \emph{European conference on computational learning theory}, pages
  23--37. Springer, 1995.

\bibitem[Gupta et~al.(2019)Gupta, Koren, and Talwar]{gupta2019better}
A.~Gupta, T.~Koren, and K.~Talwar.
\newblock Better algorithms for stochastic bandits with adversarial
  corruptions.
\newblock In \emph{Conference on Learning Theory}, pages 1562--1578, 2019.

\bibitem[Hazan(2016)]{OPT-013}
E.~Hazan.
\newblock Introduction to online convex optimization.
\newblock \emph{Foundations and TrendsÂ® in Optimization}, 2\penalty0
  (3-4):\penalty0 157--325, 2016.
\newblock ISSN 2167-3888.
\newblock \doi{10.1561/2400000013}.

\bibitem[Hazan and Kale(2010)]{hazan2010extracting}
E.~Hazan and S.~Kale.
\newblock Extracting certainty from uncertainty: Regret bounded by variation in
  costs.
\newblock \emph{Machine learning}, 80\penalty0 (2-3):\penalty0 165--188, 2010.

\bibitem[Jun et~al.(2018)Jun, Li, Ma, and Zhu]{jun2018adversarial}
K.-S. Jun, L.~Li, Y.~Ma, and J.~Zhu.
\newblock Adversarial attacks on stochastic bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3640--3649, 2018.

\bibitem[Kapoor et~al.(2019)Kapoor, Patel, and Kar]{kapoor2019corruption}
S.~Kapoor, K.~K. Patel, and P.~Kar.
\newblock Corruption-tolerant bandit learning.
\newblock \emph{Machine Learning}, 108\penalty0 (4):\penalty0 687--715, 2019.

\bibitem[Koolen and Van~Erven(2015)]{koolen2015second}
W.~M. Koolen and T.~Van~Erven.
\newblock Second-order quantile methods for experts and combinatorial games.
\newblock In \emph{Conference on Learning Theory}, pages 1155--1175, 2015.

\bibitem[Koolen et~al.(2014)Koolen, Van~Erven, and
  Gr{\"u}nwald]{koolen2014learning}
W.~M. Koolen, T.~Van~Erven, and P.~Gr{\"u}nwald.
\newblock Learning the learning rate for prediction with expert advice.
\newblock In \emph{Advances in neural information processing systems}, pages
  2294--2302, 2014.

\bibitem[Koolen et~al.(2016)Koolen, Gr{\"u}nwald, and van
  Erven]{koolen2016combining}
W.~M. Koolen, P.~Gr{\"u}nwald, and T.~van Erven.
\newblock Combining adversarial guarantees and stochastic fast rates in online
  learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4457--4465, 2016.

\bibitem[Littlestone et~al.(1989)Littlestone, Warmuth,
  et~al.]{littlestone1989weighted}
N.~Littlestone, M.~K. Warmuth, et~al.
\newblock \emph{The weighted majority algorithm}.
\newblock University of California, Santa Cruz, Computer Research Laboratory,
  1989.

\bibitem[Liu and Shroff(2019)]{liu2019data}
F.~Liu and N.~Shroff.
\newblock Data poisoning attacks on stochastic bandits.
\newblock \emph{arXiv preprint arXiv:1905.06494}, 2019.

\bibitem[Lykouris et~al.(2018)Lykouris, Mirrokni, and
  Paes~Leme]{lykouris2018stochastic}
T.~Lykouris, V.~Mirrokni, and R.~Paes~Leme.
\newblock Stochastic bandits robust to adversarial corruptions.
\newblock In \emph{Proceedings of the 50th Annual ACM SIGACT Symposium on
  Theory of Computing}, pages 114--122, 2018.

\bibitem[Lykouris et~al.(2019)Lykouris, Simchowitz, Slivkins, and
  Sun]{lykouris2019corruption}
T.~Lykouris, M.~Simchowitz, A.~Slivkins, and W.~Sun.
\newblock Corruption robust exploration in episodic reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1911.08689}, 2019.

\bibitem[Mourtada and Ga{\"\i}ffas(2019)]{mourtada2019optimality}
J.~Mourtada and S.~Ga{\"\i}ffas.
\newblock On the optimality of the hedge algorithm in the stochastic regime.
\newblock \emph{Journal of Machine Learning Research}, 20\penalty0
  (83):\penalty0 1--28, 2019.

\bibitem[Orabona(2019)]{orabona2019modern}
F.~Orabona.
\newblock A modern introduction to online learning.
\newblock \emph{arXiv preprint arXiv:1912.13213}, 2019.

\bibitem[Orabona and P{\'a}l(2018)]{orabona2018scale}
F.~Orabona and D.~P{\'a}l.
\newblock Scale-free online learning.
\newblock \emph{Theoretical Computer Science}, 716:\penalty0 50--69, 2018.

\bibitem[Rakhlin and Sridharan(2013)]{rakhlin2013online}
A.~Rakhlin and K.~Sridharan.
\newblock Online learning with predictable sequences.
\newblock In \emph{Conference on Learning Theory}, pages 993--1019, 2013.

\bibitem[Sani et~al.(2014)Sani, Neu, and Lazaric]{sani2014exploiting}
A.~Sani, G.~Neu, and A.~Lazaric.
\newblock Exploiting easy data in online optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  810--818, 2014.

\bibitem[Shalev-Shwartz et~al.(2012)]{shalev2012online}
S.~Shalev-Shwartz et~al.
\newblock Online learning and online convex optimization.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  4\penalty0 (2):\penalty0 107--194, 2012.

\bibitem[van Erven and Koolen(2016)]{van2016metagrad}
T.~van Erven and W.~M. Koolen.
\newblock Metagrad: Multiple learning rates in online learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3666--3674, 2016.

\bibitem[Van~Erven et~al.(2015)Van~Erven, Grunwald, Mehta, Reid, Williamson,
  et~al.]{van2015fast}
T.~Van~Erven, P.~Grunwald, N.~A. Mehta, M.~Reid, R.~Williamson, et~al.
\newblock Fast rates in statistical and online learning.
\newblock 2015.

\bibitem[Wei and Luo(2018)]{wei2018more}
C.-Y. Wei and H.~Luo.
\newblock More adaptive algorithms for adversarial bandits.
\newblock \emph{Proceedings of Machine Learning Research vol}, 75:\penalty0
  1--29, 2018.

\bibitem[Zimmert and Seldin(2019)]{zimmert2019optimal}
J.~Zimmert and Y.~Seldin.
\newblock An optimal algorithm for stochastic and adversarial bandits.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 467--475, 2019.

\end{thebibliography}
