\begin{thebibliography}{95}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[pyt()]{pytorchcv}
{Computer vision models on PyTorch}.
\newblock URL \url{https://pypi.org/project/pytorchcv/}.

\bibitem[Alzantot et~al.(2019)Alzantot, Sharma, Chakraborty, Zhang, Hsieh, and Srivastava]{genattack}
Alzantot, M., Sharma, Y., Chakraborty, S., Zhang, H., Hsieh, C.-J., and Srivastava, M.~B.
\newblock Genattack: Practical black-box attacks with gradient-free optimization.
\newblock In \emph{Proceedings of the genetic and evolutionary computation conference}, 2019.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and Wagner]{obfuscated}
Athalye, A., Carlini, N., and Wagner, D.
\newblock Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Brendel et~al.(2018)Brendel, Rauber, and Bethge]{boundary}
Brendel, W., Rauber, J., and Bethge, M.
\newblock Decision-based adversarial attacks: Reliable attacks against black-box machine learning models.
\newblock In \emph{Proceedings of International Conference on Learning Representations}, 2018.

\bibitem[Cai et~al.(2020)Cai, Yao, Dong, Gholami, Mahoney, and Keutzer]{zeroq}
Cai, Y., Yao, Z., Dong, Z., Gholami, A., Mahoney, M.~W., and Keutzer, K.
\newblock {ZeroQ: A novel zero shot quantization framework}.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2020.

\bibitem[Caldarola et~al.(2022)Caldarola, Caputo, and Ciccone]{caldarola2022improving}
Caldarola, D., Caputo, B., and Ciccone, M.
\newblock Improving generalization in federated learning by seeking flat minima.
\newblock In \emph{European Conference on Computer Vision}, 2022.

\bibitem[Carmon et~al.(2019)Carmon, Raghunathan, Schmidt, Duchi, and Liang]{unlabelddata}
Carmon, Y., Raghunathan, A., Schmidt, L., Duchi, J.~C., and Liang, P.~S.
\newblock Unlabeled data improves adversarial robustness.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Cha et~al.(2021)Cha, Chun, Lee, Cho, Park, Lee, and Park]{cha2021swad}
Cha, J., Chun, S., Lee, K., Cho, H.-C., Park, S., Lee, Y., and Park, S.
\newblock Swad: Domain generalization by seeking flat minima.
\newblock \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Choi et~al.(2021)Choi, Hong, Park, Kim, and Lee]{qimera}
Choi, K., Hong, D., Park, N., Kim, Y., and Lee, J.
\newblock {Qimera: Data-free quantization with synthetic boundary supporting samples}.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Choi et~al.(2022)Choi, Lee, Hong, Yu, Park, Kim, and Lee]{ait}
Choi, K., Lee, H., Hong, D., Yu, J., Park, N., Kim, Y., and Lee, J.
\newblock It's all in the teacher: Zero-shot quantization brought closer to the teacher.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022.

\bibitem[Croce \& Hein(2020)Croce and Hein]{autoattack}
Croce, F. and Hein, M.
\newblock Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Croce et~al.(2020)Croce, Andriushchenko, Sehwag, Debenedetti, Flammarion, Chiang, Mittal, and Hein]{robustbench}
Croce, F., Andriushchenko, M., Sehwag, V., Debenedetti, E., Flammarion, N., Chiang, M., Mittal, P., and Hein, M.
\newblock Robustbench: a standardized adversarial robustness benchmark.
\newblock \emph{arXiv preprint arXiv:2010.09670}, 2020.

\bibitem[Dandi et~al.(2022)Dandi, Barba, and Jaggi]{dandi2022implicit}
Dandi, Y., Barba, L., and Jaggi, M.
\newblock Implicit gradient alignment in distributed and federated learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, 2022.

\bibitem[DeVries \& Taylor(2017)DeVries and Taylor]{cutout}
DeVries, T. and Taylor, G.~W.
\newblock Improved regularization of convolutional neural networks with cutout.
\newblock \emph{arXiv preprint arXiv:1708.04552}, 2017.

\bibitem[Eshratifar et~al.(2018)Eshratifar, Eigen, and Pedram]{eshratifar2018gradient}
Eshratifar, A.~E., Eigen, D., and Pedram, M.
\newblock Gradient agreement as an optimization objective for meta-learning.
\newblock \emph{arXiv preprint arXiv:1810.08178}, 2018.

\bibitem[Fang et~al.(2019)Fang, Song, Shen, Wang, Chen, and Song]{dfad}
Fang, G., Song, J., Shen, C., Wang, X., Chen, D., and Song, M.
\newblock Data-free adversarial distillation.
\newblock \emph{arXiv preprint arXiv:1912.11006}, 2019.

\bibitem[Fernando et~al.(2022)Fernando, Shen, Liu, Chaudhury, Murugesan, and Chen]{fernando2022mitigating}
Fernando, H.~D., Shen, H., Liu, M., Chaudhury, S., Murugesan, K., and Chen, T.
\newblock Mitigating gradient bias in multi-objective learning: A provably convergent approach.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Foret et~al.(2020)Foret, Kleiner, Mobahi, and Neyshabur]{sam}
Foret, P., Kleiner, A., Mobahi, H., and Neyshabur, B.
\newblock Sharpness-aware minimization for efficiently improving generalization.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Ghiasi et~al.(2022)Ghiasi, Kazemi, Reich, Zhu, Goldblum, and Goldstein]{plugin}
Ghiasi, A., Kazemi, H., Reich, S., Zhu, C., Goldblum, M., and Goldstein, T.
\newblock Plug-in inversion: Model-agnostic inversion for vision with data augmentations.
\newblock In \emph{International Conference on Machine Learning}, 2022.

\bibitem[Goldblum et~al.(2020)Goldblum, Fowl, Feizi, and Goldstein]{ard}
Goldblum, M., Fowl, L., Feizi, S., and Goldstein, T.
\newblock Adversarially robust distillation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, 2020.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville, and Bengio]{gan}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2014.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Han et~al.(2021)Han, Park, Wang, and Liu]{rdskd}
Han, P., Park, J., Wang, S., and Liu, Y.
\newblock Robustness and diversity seeking data-free knowledge distillation.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and Signal Processing}, 2021.

\bibitem[Hathaliya \& Tanwar(2020)Hathaliya and Tanwar]{hathaliya2020exhaustive}
Hathaliya, J.~J. and Tanwar, S.
\newblock An exhaustive survey on security and privacy issues in healthcare 4.0.
\newblock \emph{Computer Communications}, 2020.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2016.

\bibitem[Huang et~al.(2020)Huang, Zhang, and Zhang]{mixup}
Huang, L., Zhang, C., and Zhang, H.
\newblock Self-adaptive training: Beyond empirical risk minimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Huang et~al.(2022)Huang, Lu, Deb, and Boddeti]{archview}
Huang, S., Lu, Z., Deb, K., and Boddeti, V.~N.
\newblock Revisiting residual networks for adversarial robustness: An architectural perspective.
\newblock \emph{arXiv preprint arXiv:2212.11005}, 2022.

\bibitem[Izmailov et~al.(2018)Izmailov, Podoprikhin, Garipov, Vetrov, and Wilson]{izmailov2018averaging}
Izmailov, P., Podoprikhin, D., Garipov, T., Vetrov, D., and Wilson, A.~G.
\newblock Averaging weights leads to wider optima and better generalization.
\newblock In \emph{34th Conference on Uncertainty in Artificial Intelligence}, 2018.

\bibitem[Jiang et~al.(2019)Jiang, Neyshabur, Mobahi, Krishnan, and Bengio]{jiang2019fantastic}
Jiang, Y., Neyshabur, B., Mobahi, H., Krishnan, D., and Bengio, S.
\newblock Fantastic generalization measures and where to find them.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Keskar et~al.(2017)Keskar, Mudigere, Nocedal, Smelyanskiy, and Tang]{keskar2016large}
Keskar, N.~S., Mudigere, D., Nocedal, J., Smelyanskiy, M., and Tang, P. T.~P.
\newblock On large-batch training for deep learning: Generalization gap and sharp minima.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Khim \& Loh(2018)Khim and Loh]{khim2018adversarial}
Khim, J. and Loh, P.-L.
\newblock Adversarial risk bounds via function transformation.
\newblock \emph{arXiv preprint arXiv:1810.09519}, 2018.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton, et~al.]{cifar}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images, 2009.
\newblock URL \url{http://www.cs.utoronto.ca/~kriz/learning-features-2009-TR.pdf}.

\bibitem[Kurmi et~al.(2021)Kurmi, Subramanian, and Namboodiri]{kurmi2021domain}
Kurmi, V.~K., Subramanian, V.~K., and Namboodiri, V.~P.
\newblock Domain impression: A source data free domain adaptation method.
\newblock In \emph{Proceedings of the IEEE/CVF winter conference on applications of computer vision}, 2021.

\bibitem[Lee et~al.(2019)Lee, Edwards, Molloy, and Su]{steal}
Lee, T., Edwards, B., Molloy, I., and Su, D.
\newblock Defending against neural network model stealing attacks using deceptive perturbations.
\newblock In \emph{IEEE Security and Privacy Workshops}, 2019.

\bibitem[Li et~al.(2018)Li, Xu, Taylor, Studer, and Goldstein]{li2018visualizing}
Li, H., Xu, Z., Taylor, G., Studer, C., and Goldstein, T.
\newblock Visualizing the loss landscape of neural nets.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Li \& Spratling(2022)Li and Spratling]{aug_alone}
Li, L. and Spratling, M.~W.
\newblock Data augmentation alone can improve adversarial training.
\newblock In \emph{The International Conference on Learning Representations}, 2022.

\bibitem[Li et~al.(2022)Li, Ma, Chen, Xiao, and Gu]{PSAQ-VIT}
Li, Z., Ma, L., Chen, M., Xiao, J., and Gu, Q.
\newblock Patch similarity aware data-free quantization for vision transformers.
\newblock In \emph{European Conference on Computer Vision}, 2022.

\bibitem[Liu et~al.(2021{\natexlab{a}})Liu, Ding, Shaham, Rahayu, Farokhi, and Lin]{liu2021machine}
Liu, B., Ding, M., Shaham, S., Rahayu, W., Farokhi, F., and Lin, Z.
\newblock When machine learning meets privacy: A survey and outlook.
\newblock \emph{ACM Computing Surveys}, 2021{\natexlab{a}}.

\bibitem[Liu et~al.(2021{\natexlab{b}})Liu, Liu, Jin, Stone, and Liu]{liu2021conflict}
Liu, B., Liu, X., Jin, X., Stone, P., and Liu, Q.
\newblock Conflict-averse gradient descent for multi-task learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021{\natexlab{b}}.

\bibitem[Liu et~al.(2020)Liu, Salzmann, Lin, Tomioka, and S{\"u}sstrunk]{liu2020loss}
Liu, C., Salzmann, M., Lin, T., Tomioka, R., and S{\"u}sstrunk, S.
\newblock On the loss landscape of adversarial training: Identifying challenges and how to overcome them.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Liu et~al.(2021{\natexlab{c}})Liu, Zhang, and Wang]{zaq}
Liu, Y., Zhang, W., and Wang, J.
\newblock Zero-shot adversarial quantization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021{\natexlab{c}}.

\bibitem[Liu et~al.(2022)Liu, Cheng, Gao, Liu, Zhang, and Song]{adaptiveauto}
Liu, Y., Cheng, Y., Gao, L., Liu, X., Zhang, Q., and Song, J.
\newblock Practical evaluation of adversarial robustness via adaptive auto attack.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022.

\bibitem[Lopes et~al.(2017)Lopes, Fenu, and Starner]{dfkd}
Lopes, R.~G., Fenu, S., and Starner, T.
\newblock Data-free knowledge distillation for deep neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems Workshops}, 2017.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and Vladu]{madry}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Mansilla et~al.(2021)Mansilla, Echeveste, Milone, and Ferrante]{mansilla2021domain}
Mansilla, L., Echeveste, R., Milone, D.~H., and Ferrante, E.
\newblock Domain generalization via gradient surgery.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021.

\bibitem[Moosavi-Dezfooli et~al.(2019)Moosavi-Dezfooli, Fawzi, Uesato, and Frossard]{moosavi2019robustness}
Moosavi-Dezfooli, S.-M., Fawzi, A., Uesato, J., and Frossard, P.
\newblock Robustness via curvature regularization, and vice versa.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2019.

\bibitem[Naeem et~al.(2020)Naeem, Oh, Uh, Choi, and Yoo]{gandiversitymetric}
Naeem, M.~F., Oh, S.~J., Uh, Y., Choi, Y., and Yoo, J.
\newblock Reliable fidelity and diversity metrics for generative models.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Nagel et~al.(2019)Nagel, Baalen, Blankevoort, and Welling]{dfq}
Nagel, M., Baalen, M.~v., Blankevoort, T., and Welling, M.
\newblock Data-free quantization through weight equalization and bias correction.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision}, 2019.

\bibitem[Nayak et~al.(2022)Nayak, Rawal, and Chakraborty]{dad}
Nayak, G.~K., Rawal, R., and Chakraborty, A.
\newblock Dad: Data-free adversarial defense at test time.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, 2022.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and Ng]{svhn}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In \emph{Advances in Neural Information Processing Systems Workshops}, 2011.

\bibitem[Nie et~al.(2022)Nie, Guo, Huang, Xiao, Vahdat, and Anandkumar]{diffpure}
Nie, W., Guo, B., Huang, Y., Xiao, C., Vahdat, A., and Anandkumar, A.
\newblock Diffusion models for adversarial purification.
\newblock In \emph{International Conference on Machine Learning}, 2022.

\bibitem[Odena et~al.(2017)Odena, Olah, and Shlens]{acgan}
Odena, A., Olah, C., and Shlens, J.
\newblock {Conditional image synthesis with auxiliary classifier GANs}.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Patashnik et~al.(2021)Patashnik, Wu, Shechtman, Cohen-Or, and Lischinski]{clip}
Patashnik, O., Wu, Z., Shechtman, E., Cohen-Or, D., and Lischinski, D.
\newblock Styleclip: Text-driven manipulation of stylegan imagery.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision}, 2021.

\bibitem[P{\'e}rez et~al.(2021)P{\'e}rez, Alfarra, Jeanneret, Rueda, Thabet, Ghanem, and Arbel{\'a}ez]{TTE}
P{\'e}rez, J.~C., Alfarra, M., Jeanneret, G., Rueda, L., Thabet, A., Ghanem, B., and Arbel{\'a}ez, P.
\newblock Enhancing adversarial robustness via test-time transformation ensembling.
\newblock In \emph{Proceedings of International Conference on Computer Vision}, 2021.

\bibitem[Phan et~al.(2022)Phan, Tran, Tran, Ho, Phung, and Le]{phan2022improving}
Phan, H., Tran, L., Tran, N.~N., Ho, N., Phung, D., and Le, T.
\newblock Improving multi-task learning via seeking task-based flat regions.
\newblock \emph{arXiv preprint arXiv:2211.13723}, 2022.

\bibitem[Qin et~al.(2019)Qin, Martens, Gowal, Krishnan, Dvijotham, Fawzi, De, Stanforth, and Kohli]{qin2019adversarial}
Qin, C., Martens, J., Gowal, S., Krishnan, D., Dvijotham, K., Fawzi, A., De, S., Stanforth, R., and Kohli, P.
\newblock Adversarial robustness through local linearization.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Ramesh et~al.(2021)Ramesh, Pavlov, Goh, Gray, Voss, Radford, Chen, and Sutskever]{dalle}
Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., and Sutskever, I.
\newblock Zero-shot text-to-image generation.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Rebuffi et~al.(2021)Rebuffi, Gowal, Calian, Stimberg, Wiles, and Mann]{rebuffi2021data}
Rebuffi, S.-A., Gowal, S., Calian, D.~A., Stimberg, F., Wiles, O., and Mann, T.~A.
\newblock Data augmentation can improve robustness.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Rice et~al.(2020)Rice, Wong, and Kolter]{robustoverfitting}
Rice, L., Wong, E., and Kolter, Z.
\newblock Overfitting in adversarially robust deep learning.
\newblock In \emph{Proceedings of the International Conference on Machine Learning}, 2020.

\bibitem[Richardson \& Weiss(2018)Richardson and Weiss]{ndb}
Richardson, E. and Weiss, Y.
\newblock On gans and gmms.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Sabour et~al.(2016)Sabour, Cao, Faghri, and Fleet]{latentattack}
Sabour, S., Cao, Y., Faghri, F., and Fleet, D.~J.
\newblock Adversarial manipulation of deep representations.
\newblock \emph{International Conference on Learning Representations}, 2016.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton, Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans, et~al.]{imagen}
Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E.~L., Ghasemipour, K., Gontijo~Lopes, R., Karagol~Ayan, B., Salimans, T., et~al.
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and Madry]{schmidt2018adversarially}
Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., and Madry, A.
\newblock Adversarially robust generalization requires more data.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Sehwag et~al.(2021)Sehwag, Mahloujifar, Handina, Dai, Xiang, Chiang, and Mittal]{proxy}
Sehwag, V., Mahloujifar, S., Handina, T., Dai, S., Xiang, C., Chiang, M., and Mittal, P.
\newblock Robust learning meets generative models: Can proxy distributions improve adversarial robustness?
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Shi et~al.(2022)Shi, Seely, Torr, N, Hannun, Usunier, and Synnaeve]{shi2022gradient}
Shi, Y., Seely, J., Torr, P., N, S., Hannun, A., Usunier, N., and Synnaeve, G.
\newblock Gradient matching for domain generalization.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Shokri et~al.(2017)Shokri, Stronati, Song, and Shmatikov]{mia}
Shokri, R., Stronati, M., Song, C., and Shmatikov, V.
\newblock Membership inference attacks against machine learning models.
\newblock In \emph{IEEE Symposium on Security and Privacy}, 2017.

\bibitem[Srinivas \& Babu(2015)Srinivas and Babu]{dfpruning}
Srinivas, S. and Babu, R.~V.
\newblock Data-free parameter pruning for deep neural networks.
\newblock In \emph{British Machine Vision Conference}, 2015.

\bibitem[Stutz et~al.(2021)Stutz, Hein, and Schiele]{flatminima}
Stutz, D., Hein, M., and Schiele, B.
\newblock Relating adversarially robust generalization to flat minima.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan, Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and Wojna]{smoothing}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2016.

\bibitem[Tenison et~al.(2022)Tenison, Sreeramadas, Mugunthan, Oyallon, Belilovsky, and Rish]{tenison2022gradient}
Tenison, I., Sreeramadas, S.~A., Mugunthan, V., Oyallon, E., Belilovsky, E., and Rish, I.
\newblock Gradient masked averaging for federated learning.
\newblock \emph{arXiv preprint arXiv:2201.11986}, 2022.

\bibitem[Terj{\'e}k(2019)]{terjek2019adversarial}
Terj{\'e}k, D.
\newblock Adversarial lipschitz regularization.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Truong et~al.(2021)Truong, Maini, Walls, and Papernot]{dfme}
Truong, J.-B., Maini, P., Walls, R.~J., and Papernot, N.
\newblock Data-free model extraction.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021.

\bibitem[Uesato et~al.(2018)Uesato, O’donoghue, Kohli, and Oord]{spsa}
Uesato, J., O’donoghue, B., Kohli, P., and Oord, A.
\newblock Adversarial risk and the dangers of evaluating against weak attacks.
\newblock In \emph{Proceedings of International Conference on Machine Learning}, 2018.

\bibitem[Wang et~al.(2021)Wang, Li, Singh, Lu, and Vasconcelos]{imagine}
Wang, P., Li, Y., Singh, K.~K., Lu, J., and Vasconcelos, N.
\newblock Imagine: Image synthesis by image-guided model inversion.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2021.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Zhang, Lei, and Zhang]{wang2023sharpness}
Wang, P., Zhang, Z., Lei, Z., and Zhang, L.
\newblock Sharpness-aware gradient matching for domain generalization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2019)Wang, Zou, Yi, Bailey, Ma, and Gu]{mart}
Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., and Gu, Q.
\newblock Improving adversarial robustness requires revisiting misclassified examples.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Chen, Yang, Guo, Jiang, Zhang, and Qi]{dfard}
Wang, Y., Chen, Z., Yang, D., Guo, P., Jiang, K., Zhang, W., and Qi, L.
\newblock Model robustness meets data privacy: Adversarial robustness distillation without original data.
\newblock \emph{arXiv preprint arXiv:2303.11611}, 2023{\natexlab{b}}.

\bibitem[Wu et~al.(2020)Wu, Xia, and Wang]{weightperturb}
Wu, D., Xia, S.-T., and Wang, Y.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Xu et~al.(2020)Xu, Li, Zhuang, Liu, Cao, Liang, and Tan]{gdfq}
Xu, S., Li, H., Zhuang, B., Liu, J., Cao, J., Liang, C., and Tan, M.
\newblock Generative low-bitwidth data free quantization.
\newblock In \emph{European Conference on Computer Vision}, 2020.

\bibitem[Yang et~al.(2023)Yang, Shi, Wei, Liu, Zhao, Ke, Pfister, and Ni]{medmnistv2}
Yang, J., Shi, R., Wei, D., Liu, Z., Zhao, L., Ke, B., Pfister, H., and Ni, B.
\newblock Medmnist v2-a large-scale lightweight benchmark for 2d and 3d biomedical image classification.
\newblock \emph{Scientific Data}, 2023.

\bibitem[Yang et~al.(2020)Yang, Rashtchian, Zhang, Salakhutdinov, and Chaudhuri]{yang2020closer}
Yang, Y.-Y., Rashtchian, C., Zhang, H., Salakhutdinov, R.~R., and Chaudhuri, K.
\newblock A closer look at accuracy vs. robustness.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Yao et~al.(2021)Yao, Bielik, Tsankov, and Vechev]{automated}
Yao, C., Bielik, P., Tsankov, P., and Vechev, M.
\newblock Automated discovery of adaptive attacks on adversarial defenses.
\newblock \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Yin et~al.(2019)Yin, Kannan, and Bartlett]{yin2019rademacher}
Yin, D., Kannan, R., and Bartlett, P.
\newblock Rademacher complexity for adversarially robust generalization.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Yin et~al.(2020)Yin, Molchanov, Alvarez, Li, Mallya, Hoiem, Jha, and Kautz]{deepinversion}
Yin, H., Molchanov, P., Alvarez, J.~M., Li, Z., Mallya, A., Hoiem, D., Jha, N.~K., and Kautz, J.
\newblock Dreaming to distill: Data-free knowledge transfer via deepinversion.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2020.

\bibitem[Yu et~al.(2020)Yu, Kumar, Gupta, Levine, Hausman, and Finn]{yu2020gradient}
Yu, T., Kumar, S., Gupta, A., Levine, S., Hausman, K., and Finn, C.
\newblock Gradient surgery for multi-task learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Yun et~al.(2019)Yun, Han, Oh, Chun, Choe, and Yoo]{cutmix}
Yun, S., Han, D., Oh, S.~J., Chun, S., Choe, J., and Yoo, Y.
\newblock Cutmix: Regularization strategy to train strong classifiers with localizable features.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2019.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and Komodakis]{wrn}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock In \emph{British Machine Vision Conference}, 2016.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, El~Ghaoui, and Jordan]{trades}
Zhang, H., Yu, Y., Jiao, J., Xing, E., El~Ghaoui, L., and Jordan, M.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Zhao et~al.(2022)Zhao, Zhang, and Hu]{zhao2022penalizing}
Zhao, Y., Zhang, H., and Hu, X.
\newblock Penalizing gradient norm for efficiently improving generalization in deep learning.
\newblock In \emph{International Conference on Machine Learning}, 2022.

\bibitem[Zhong et~al.(2022)Zhong, Lin, Nan, Liu, Zhang, Tian, and Ji]{intraq}
Zhong, Y., Lin, M., Nan, G., Liu, J., Zhang, B., Tian, Y., and Ji, R.
\newblock Intraq: Learning synthetic images with intra-class heterogeneity for zero-shot network quantization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022.

\bibitem[Zhou et~al.(2020)Zhou, Wu, Liu, Liu, and Zhu]{dast}
Zhou, M., Wu, J., Liu, Y., Liu, S., and Zhu, C.
\newblock Dast: Data-free substitute training for adversarial attacks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2020.

\bibitem[Zhu et~al.(2021)Zhu, Hofstee, Peltenburg, Lee, and Alars]{autorecon}
Zhu, B., Hofstee, P., Peltenburg, J., Lee, J., and Alars, Z.
\newblock {AutoReCon: Neural architecture search-based reconstruction for data-free compression}.
\newblock In \emph{International Joint Conferences on Artificial Intelligence}, 2021.

\bibitem[Zhu et~al.(2022)Zhu, Yao, Han, Zhang, Liu, Niu, Zhou, Xu, and Yang]{iad}
Zhu, J., Yao, J., Han, B., Zhang, J., Liu, T., Niu, G., Zhou, J., Xu, J., and Yang, H.
\newblock Reliable adversarial distillation with unreliable teachers.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Zi et~al.(2021)Zi, Zhao, Ma, and Jiang]{rslad}
Zi, B., Zhao, S., Ma, X., and Jiang, Y.-G.
\newblock Revisiting adversarial robustness distillation: Robust soft labels make student better.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision}, 2021.

\end{thebibliography}
