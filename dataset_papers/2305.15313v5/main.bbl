\begin{thebibliography}{25}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agustsson \& Theis(2020)Agustsson and Theis]{agustsson2020universally}
Eirikur Agustsson and Lucas Theis.
\newblock Universally quantized neural compression.
\newblock In \emph{Advances in Neural Information Processing Systems}, volume~33, 2020.

\bibitem[Amdahl(1967)]{amdahl1967validity}
Gene~M Amdahl.
\newblock Validity of the single processor approach to achieving large scale computing capabilities.
\newblock In \emph{Proceedings of the April 18-20, 1967, spring joint computer conference}, pp.\  483--485, 1967.

\bibitem[Bateman \& Erd{\'e}lyi(1953)Bateman and Erd{\'e}lyi]{bateman1953higher}
Harry Bateman and Arthur Erd{\'e}lyi.
\newblock \emph{Higher transcendental functions}, volume~1.
\newblock McGraw-Hill book company, 1953.

\bibitem[Corless et~al.(1996)Corless, Gonnet, Hare, Jeffrey, and Knuth]{corless1996lambert}
Robert~M. Corless, Gaston~H. Gonnet, David E.~G. Hare, David~J. Jeffrey, and Donald~E. Knuth.
\newblock On the {Lambert} {W} function.
\newblock \emph{Advances in Computational mathematics}, 5:\penalty0 329--359, 1996.

\bibitem[Flamich \& Theis(2023)Flamich and Theis]{flamich2023adaptive}
Gergely Flamich and Lucas Theis.
\newblock Adaptive greedy rejection sampling.
\newblock In \emph{IEEE International Symposium on Information Theory (ISIT)}, pp.\  454--459, 2023.

\bibitem[Flamich et~al.(2020)Flamich, Havasi, and Hern{\'a}ndez~Lobato]{flamich2020compressing}
Gergely Flamich, Marton Havasi, and Jos{\'e}~Miguel Hern{\'a}ndez~Lobato.
\newblock Compressing images by encoding their latent representations with relative entropy coding.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Flamich et~al.(2022)Flamich, Markou, and Hern{\'a}ndez~Lobato]{flamich2022fast}
Gergely Flamich, Stratis Markou, and Jos{\'e}~Miguel Hern{\'a}ndez~Lobato.
\newblock Fast relative entropy coding with {A*} coding.
\newblock In \emph{International Conference on Machine Learning}, pp.\  6548--6577, 2022.

\bibitem[Flamich et~al.(2023)Flamich, Markou, and Hern{\'a}ndez~Lobato]{flamich2023faster}
Gergely Flamich, Stratis Markou, and Jos{\'e}~Miguel Hern{\'a}ndez~Lobato.
\newblock Faster relative entropy coding with greedy rejection coding.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2023.

\bibitem[Guo et~al.(2023)Guo, Flamich, He, Chen, and Hern{\'a}ndez~Lobato]{guo2023compression}
Zongyu Guo, Gergely Flamich, Jiajun He, Zhibo Chen, and Jos{\'e}~Miguel Hern{\'a}ndez~Lobato.
\newblock Compression with {Bayesian} implicit neural representations.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2023.

\bibitem[Harsha et~al.(2007)Harsha, Jain, McAllester, and Radhakrishnan]{harsha2007communication}
Prahladh Harsha, Rahul Jain, David McAllester, and Jaikumar Radhakrishnan.
\newblock The communication complexity of correlation.
\newblock In \emph{Twenty-Second Annual IEEE Conference on Computational Complexity (CCC'07)}, pp.\  10--23. IEEE, 2007.

\bibitem[Havasi et~al.(2018)Havasi, Peharz, and Hern{\'a}ndez~Lobato]{havasi2018minimal}
Marton Havasi, Robert Peharz, and Jos{\'e}~Miguel Hern{\'a}ndez~Lobato.
\newblock Minimal random code learning: Getting bits back from compressed model parameters.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[He et~al.(2023)He, Flamich, Guo, and Hern{\'a}ndez~Lobato]{he2023recombiner}
Jiajun He, Gergely Flamich, Zongyu Guo, and Jos{\'e}~Miguel Hern{\'a}ndez~Lobato.
\newblock {RECOMBINER}: Robust and enhanced compression with {Bayesian} implicit neural representations.
\newblock \emph{arXiv preprint arXiv:2309.17182}, 2023.

\bibitem[Hegazy \& Li(2022)Hegazy and Li]{hegazy2022randomized}
Mahmoud Hegazy and Cheuk~Ting Li.
\newblock Randomized quantization with exact error distribution.
\newblock In \emph{2022 IEEE Information Theory Workshop (ITW)}, pp.\  350--355. IEEE, 2022.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{kingma2013auto}
Diederik~P. Kingma and Max Welling.
\newblock Auto-encoding variational {Bayes}.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Kingman(1992)]{kingman1992poisson}
John F.~C. Kingman.
\newblock \emph{Poisson Processes}.
\newblock Oxford Studies in Probability. Clarendon Press, 1992.
\newblock ISBN 9780191591242.

\bibitem[Li \& El~Gamal(2018)Li and El~Gamal]{li2018strong}
Cheuk~Ting Li and Abbas El~Gamal.
\newblock Strong functional representation lemma and applications to coding theorems.
\newblock \emph{IEEE Transactions on Information Theory}, 64\penalty0 (11):\penalty0 6967--6978, 2018.

\bibitem[Liu \& Verdu(2018)Liu and Verdu]{liu2018rejection}
Jingbo Liu and Sergio Verdu.
\newblock Rejection sampling and noncausal sampling under moment constraints.
\newblock In \emph{2018 IEEE International Symposium on Information Theory (ISIT)}, pp.\  1565--1569. IEEE, 2018.

\bibitem[Maddison(2016)]{maddison2016poisson}
Chris~J. Maddison.
\newblock A {Poisson} process model for {Monte Carlo}.
\newblock \emph{Perturbation, Optimization, and Statistics}, pp.\  193--232, 2016.

\bibitem[Maddison et~al.(2014)Maddison, Tarlow, and Minka]{maddison2014sampling}
Chris~J. Maddison, Daniel Tarlow, and Tom Minka.
\newblock {A*} sampling.
\newblock In \emph{Advances in Neural Information Processing Systems}, volume~27, pp.\  3086--3094, 2014.

\bibitem[Muldowney et~al.(2012)Muldowney, Ostaszewski, and Wojdowski]{muldowney2012darth}
Pat Muldowney, Krzysztof Ostaszewski, and Wojciech Wojdowski.
\newblock The {Darth Vader} rule.
\newblock \emph{Tatra Mountains Mathematical Publications}, 52\penalty0 (1):\penalty0 53--63, 2012.

\bibitem[Rissanen \& Langdon(1979)Rissanen and Langdon]{rissanen1979arithmetic}
Jorma Rissanen and Glen~G Langdon.
\newblock Arithmetic coding.
\newblock \emph{IBM Journal of research and development}, 23\penalty0 (2):\penalty0 149--162, 1979.

\bibitem[Shah et~al.(2022)Shah, Chen, Balle, Kairouz, and Theis]{shah2021optimal}
Abhin Shah, Wei-Ning Chen, Johannes Balle, Peter Kairouz, and Lucas Theis.
\newblock Optimal compression of locally differentially private mechanisms.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pp.\  7680--7723. PMLR, 2022.

\bibitem[Theis \& Yosri(2022)Theis and Yosri]{theis2021algorithms}
Lucas Theis and Noureldin Yosri.
\newblock Algorithms for the communication of samples.
\newblock In \emph{International Conference on Machine Learning}, 2022.

\bibitem[Theis et~al.(2022)Theis, Salimans, Hoffman, and Mentzer]{theis2022lossy}
Lucas Theis, Tim Salimans, Matthew~D. Hoffman, and Fabian Mentzer.
\newblock Lossy compression with {Gaussian} diffusion.
\newblock arXiv:2206.08889, 2022.

\bibitem[Ziv(1985)]{ziv1985universal}
Jacob Ziv.
\newblock On universal quantization.
\newblock \emph{IEEE Transactions on Information Theory}, 31\penalty0 (3):\penalty0 344--347, 1985.

\end{thebibliography}
