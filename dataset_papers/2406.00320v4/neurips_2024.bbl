\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Betker et~al.(2023)Betker, Goh, Jing, Brooks, Wang, Li, Ouyang, Zhuang, Lee, Guo, et~al.]{betker2023improving}
James Betker, Gabriel Goh, Li~Jing, Tim Brooks, Jianfeng Wang, Linjie Li, Long Ouyang, Juntang Zhuang, Joyce Lee, Yufei Guo, et~al.
\newblock Improving image generation with better captions.
\newblock \emph{Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf}, 2\penalty0 (3):\penalty0 8, 2023.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Xie, Vedaldi, and Zisserman]{chen2020vggsound}
Honglie Chen, Weidi Xie, Andrea Vedaldi, and Andrew Zisserman.
\newblock Vggsound: A large-scale audio-visual dataset.
\newblock In \emph{ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pp.\  721--725. IEEE, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Zhang, Tan, Xiao, Huang, and Gan]{chen2020generating}
Peihao Chen, Yang Zhang, Mingkui Tan, Hongdong Xiao, Deng Huang, and Chuang Gan.
\newblock Generating visually aligned sound from videos.
\newblock \emph{IEEE Transactions on Image Processing}, 29:\penalty0 8292--8302, 2020{\natexlab{b}}.

\bibitem[Dormand \& Prince(1980)Dormand and Prince]{dormand1980family}
John~R Dormand and Peter~J Prince.
\newblock A family of embedded runge-kutta formulae.
\newblock \emph{Journal of computational and applied mathematics}, 6\penalty0 (1):\penalty0 19--26, 1980.

\bibitem[Du et~al.(2023)Du, Chen, Salamon, Russell, and Owens]{du2023conditional}
Yuexi Du, Ziyang Chen, Justin Salamon, Bryan Russell, and Andrew Owens.
\newblock Conditional generation of audio from video via foley analogies.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  2426--2436, 2023.

\bibitem[Esser et~al.(2024)Esser, Kulal, Blattmann, Entezari, M{\"u}ller, Saini, Levi, Lorenz, Sauer, Boesel, et~al.]{esser2024scaling}
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas M{\"u}ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et~al.
\newblock Scaling rectified flow transformers for high-resolution image synthesis.
\newblock \emph{arXiv preprint arXiv:2403.03206}, 2024.

\bibitem[Gemmeke et~al.(2017)Gemmeke, Ellis, Freedman, Jansen, Lawrence, Moore, Plakal, and Ritter]{gemmeke2017audio}
Jort~F Gemmeke, Daniel~PW Ellis, Dylan Freedman, Aren Jansen, Wade Lawrence, R~Channing Moore, Manoj Plakal, and Marvin Ritter.
\newblock Audio set: An ontology and human-labeled dataset for audio events.
\newblock In \emph{2017 IEEE international conference on acoustics, speech and signal processing (ICASSP)}, pp.\  776--780. IEEE, 2017.

\bibitem[Ghose \& Prevost(2022)Ghose and Prevost]{ghose2022foleygan}
Sanchita Ghose and John~J Prevost.
\newblock Foleygan: Visually guided generative adversarial network-based synchronous sound generation in silent videos.
\newblock \emph{IEEE Transactions on Multimedia}, 2022.

\bibitem[Girdhar et~al.(2023)Girdhar, El-Nouby, Liu, Singh, Alwala, Joulin, and Misra]{girdhar2023imagebind}
Rohit Girdhar, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan~Vasudev Alwala, Armand Joulin, and Ishan Misra.
\newblock Imagebind: One embedding space to bind them all.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  15180--15190, 2023.

\bibitem[Griffin \& Lim(1984)Griffin and Lim]{griffin1984signal}
Daniel Griffin and Jae Lim.
\newblock Signal estimation from modified short-time fourier transform.
\newblock \emph{IEEE Transactions on acoustics, speech, and signal processing}, 32\penalty0 (2):\penalty0 236--243, 1984.

\bibitem[Guo et~al.(2024)Guo, Du, Ma, Chen, and Yu]{guo2024voiceflow}
Yiwei Guo, Chenpeng Du, Ziyang Ma, Xie Chen, and Kai Yu.
\newblock Voiceflow: Efficient text-to-speech with rectified flow matching.
\newblock In \emph{ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pp.\  11121--11125. IEEE, 2024.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 6840--6851, 2020.

\bibitem[Huang et~al.(2023)Huang, Ren, Huang, Yang, Ye, Zhang, Liu, Yin, Ma, and Zhao]{huang2023make}
Jiawei Huang, Yi~Ren, Rongjie Huang, Dongchao Yang, Zhenhui Ye, Chen Zhang, Jinglin Liu, Xiang Yin, Zejun Ma, and Zhou Zhao.
\newblock Make-an-audio 2: Temporal-enhanced text-to-audio generation.
\newblock \emph{arXiv preprint arXiv:2305.18474}, 2023.

\bibitem[Huang et~al.(2024)Huang, Sharma, Xu, Ryali, Li, Li, Ghosh, Malik, Feichtenhofer, et~al.]{huang2024mavil}
Po-Yao Huang, Vasu Sharma, Hu~Xu, Chaitanya Ryali, Yanghao Li, Shang-Wen Li, Gargi Ghosh, Jitendra Malik, Christoph Feichtenhofer, et~al.
\newblock Mavil: Masked audio-video learners.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Iashin \& Rahtu(2021)Iashin and Rahtu]{iashin2021taming}
Vladimir Iashin and Esa Rahtu.
\newblock Taming visually guided sound generation.
\newblock In \emph{The 32st British Machine Vision Virtual Conference}. BMVA Press, 2021.

\bibitem[Le et~al.(2024)Le, Vyas, Shi, Karrer, Sari, Moritz, Williamson, Manohar, Adi, Mahadeokar, et~al.]{le2024voicebox}
Matthew Le, Apoorv Vyas, Bowen Shi, Brian Karrer, Leda Sari, Rashel Moritz, Mary Williamson, Vimal Manohar, Yossi Adi, Jay Mahadeokar, et~al.
\newblock Voicebox: Text-guided multilingual universal speech generation at scale.
\newblock \emph{Advances in neural information processing systems}, 36, 2024.

\bibitem[Lee et~al.(2022)Lee, Ping, Ginsburg, Catanzaro, and Yoon]{lee2022bigvgan}
Sang-gil Lee, Wei Ping, Boris Ginsburg, Bryan Catanzaro, and Sungroh Yoon.
\newblock Bigvgan: A universal neural vocoder with large-scale training.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2022.

\bibitem[Lipman et~al.(2022)Lipman, Chen, Ben-Hamu, Nickel, and Le]{lipman2022flow}
Yaron Lipman, Ricky~TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le.
\newblock Flow matching for generative modeling.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2022.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Chen, Yuan, Mei, Liu, Mandic, Wang, and Plumbley]{liu2023audioldm}
Haohe Liu, Zehua Chen, Yi~Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, and Mark~D Plumbley.
\newblock Audioldm: Text-to-audio generation with latent diffusion models.
\newblock \emph{arXiv preprint arXiv:2301.12503}, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Tian, Yuan, Liu, Mei, Kong, Wang, Wang, Wang, and Plumbley]{liu2023audioldm2}
Haohe Liu, Qiao Tian, Yi~Yuan, Xubo Liu, Xinhao Mei, Qiuqiang Kong, Yuping Wang, Wenwu Wang, Yuxuan Wang, and Mark~D Plumbley.
\newblock Audioldm 2: Learning holistic audio generation with self-supervised pretraining.
\newblock \emph{arXiv preprint arXiv:2308.05734}, 2023{\natexlab{b}}.

\bibitem[Liu et~al.(2022)Liu, Gong, et~al.]{liu2022flow}
Xingchao Liu, Chengyue Gong, et~al.
\newblock Flow straight and fast: Learning to generate and transfer data with rectified flow.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2022.

\bibitem[Liu et~al.(2023{\natexlab{c}})Liu, Zhang, Ma, Peng, et~al.]{liu2023instaflow}
Xingchao Liu, Xiwen Zhang, Jianzhu Ma, Jian Peng, et~al.
\newblock Instaflow: One step is enough for high-quality diffusion-based text-to-image generation.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2023{\natexlab{c}}.

\bibitem[Liu et~al.(2024)Liu, Zhang, Li, Yan, Gao, Chen, Yuan, Huang, Sun, Gao, et~al.]{liu2024sora}
Yixin Liu, Kai Zhang, Yuan Li, Zhiling Yan, Chujie Gao, Ruoxi Chen, Zhengqing Yuan, Yue Huang, Hanchi Sun, Jianfeng Gao, et~al.
\newblock Sora: A review on background, technology, limitations, and opportunities of large vision models.
\newblock \emph{arXiv preprint arXiv:2402.17177}, 2024.

\bibitem[Lu et~al.(2022)Lu, Zhou, Bao, Chen, Li, and Zhu]{lu2022dpm}
Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu.
\newblock Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 5775--5787, 2022.

\bibitem[Luo et~al.(2024)Luo, Yan, Hu, and Zhao]{luo2024diff}
Simian Luo, Chuanhao Yan, Chenxu Hu, and Hang Zhao.
\newblock Diff-foley: Synchronized video-to-audio synthesis with latent diffusion models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Mehta et~al.(2024)Mehta, Tu, Beskow, Sz{\'e}kely, and Henter]{mehta2024matcha}
Shivam Mehta, Ruibo Tu, Jonas Beskow, {\'E}va Sz{\'e}kely, and Gustav~Eje Henter.
\newblock Matcha-tts: A fast tts architecture with conditional flow matching.
\newblock In \emph{ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pp.\  11341--11345. IEEE, 2024.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, Sutskever, et~al.]{radford2018improving}
Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et~al.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pp.\  8748--8763. PMLR, 2021.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  10684--10695, 2022.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton, Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans, et~al.]{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 36479--36494, 2022.

\bibitem[Sheffer \& Adi(2023)Sheffer and Adi]{sheffer2023hear}
Roy Sheffer and Yossi Adi.
\newblock I hear your true colors: Image guided audio generation.
\newblock In \emph{ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pp.\  1--5. IEEE, 2023.

\bibitem[Singer et~al.(2022)Singer, Polyak, Hayes, Yin, An, Zhang, Hu, Yang, Ashual, Gafni, et~al.]{singer2022make}
Uriel Singer, Adam Polyak, Thomas Hayes, Xi~Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, et~al.
\newblock Make-a-video: Text-to-video generation without text-video data.
\newblock \emph{arXiv preprint arXiv:2209.14792}, 2022.

\bibitem[Tseng et~al.(2024)Tseng, Berry, Chen, Chiu, Lin, Liu, Peng, Shih, Wang, Wu, et~al.]{tseng2024av}
Yuan Tseng, Layne Berry, Yi-Ting Chen, I-Hsiang Chiu, Hsuan-Hao Lin, Max Liu, Puyuan Peng, Yi-Jen Shih, Hung-Yu Wang, Haibin Wu, et~al.
\newblock Av-superb: A multi-task evaluation benchmark for audio-visual representation models.
\newblock In \emph{ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pp.\  6890--6894. IEEE, 2024.

\bibitem[Vyas et~al.(2023)Vyas, Shi, Le, Tjandra, Wu, Guo, Zhang, Zhang, Adkins, Ngan, et~al.]{vyas2023audiobox}
Apoorv Vyas, Bowen Shi, Matthew Le, Andros Tjandra, Yi-Chiao Wu, Baishan Guo, Jiemin Zhang, Xinyue Zhang, Robert Adkins, William Ngan, et~al.
\newblock Audiobox: Unified audio generation with natural language prompts.
\newblock \emph{arXiv preprint arXiv:2312.15821}, 2023.

\bibitem[Wang et~al.(2024{\natexlab{a}})Wang, Ma, Pascual, Cartwright, and Cai]{wang2024v2a}
Heng Wang, Jianbo Ma, Santiago Pascual, Richard Cartwright, and Weidong Cai.
\newblock V2a-mapper: A lightweight solution for vision-to-audio generation by connecting foundation models.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~38, pp.\  15492--15501, 2024{\natexlab{a}}.

\bibitem[Wang et~al.()Wang, Zhang, Cheng, Huang, Liu, Ye, Huang, Zhao, Jin, Gao, et~al.]{wangfreebind}
Zehan Wang, Ziang Zhang, Xize Cheng, Rongjie Huang, Luping Liu, Zhenhui Ye, Haifeng Huang, Yang Zhao, Tao Jin, Peng Gao, et~al.
\newblock Freebind: Free lunch in unified multimodal space via knowledge fusion.
\newblock In \emph{Forty-first International Conference on Machine Learning}.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Zhang, Liu, Zhao, Huang, Jin, and Zhao]{wang2023extending}
Zehan Wang, Ziang Zhang, Luping Liu, Yang Zhao, Haifeng Huang, Tao Jin, and Zhou Zhao.
\newblock Extending multi-modal contrastive representations.
\newblock \emph{arXiv preprint arXiv:2310.08884}, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Zhao, Huang, Liu, Yin, Tang, Li, Wang, Zhang, and Zhao]{wang2023connecting}
Zehan Wang, Yang Zhao, Haifeng Huang, Jiageng Liu, Aoxiong Yin, Li~Tang, Linjun Li, Yongqi Wang, Ziang Zhang, and Zhou Zhao.
\newblock Connecting multi-modal contrastive representations.
\newblock \emph{Advances in Neural Information Processing Systems}, 36:\penalty0 22099--22114, 2023{\natexlab{b}}.

\bibitem[Wang et~al.(2024{\natexlab{b}})Wang, Zhang, Zhang, Liu, Huang, Cheng, Zhao, and Zhao]{wang2024omnibind}
Zehan Wang, Ziang Zhang, Hang Zhang, Luping Liu, Rongjie Huang, Xize Cheng, Hengshuang Zhao, and Zhou Zhao.
\newblock Omnibind: Large-scale omni multimodal representation via binding spaces.
\newblock \emph{arXiv preprint arXiv:2407.11895}, 2024{\natexlab{b}}.

\bibitem[Wu et~al.(2023)Wu, Chen, Zhang, Hui, Berg-Kirkpatrick, and Dubnov]{wu2023large}
Yusong Wu, Ke~Chen, Tianyu Zhang, Yuchen Hui, Taylor Berg-Kirkpatrick, and Shlomo Dubnov.
\newblock Large-scale contrastive language-audio pretraining with feature fusion and keyword-to-caption augmentation.
\newblock In \emph{ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pp.\  1--5. IEEE, 2023.

\bibitem[Xing et~al.(2024)Xing, He, Tian, Wang, and Chen]{xing2024seeing}
Yazhou Xing, Yingqing He, Zeyue Tian, Xintao Wang, and Qifeng Chen.
\newblock Seeing and hearing: Open-domain visual-audio generation with diffusion latent aligners.
\newblock \emph{arXiv preprint arXiv:2402.17723}, 2024.

\end{thebibliography}
