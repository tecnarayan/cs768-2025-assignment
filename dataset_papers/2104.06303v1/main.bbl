\begin{thebibliography}{48}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdolmaleki et~al.(2018)Abdolmaleki, Springenberg, Degrave, Bohez,
  Tassa, Belov, Heess, and Riedmiller]{mpo}
Abdolmaleki, A., Springenberg, J.~T., Degrave, J., Bohez, S., Tassa, Y., Belov,
  D., Heess, N., and Riedmiller, M.
\newblock Relative entropy regularized policy iteration, 2018.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Ba, J.~L., Kiros, J.~R., and Hinton, G.~E.
\newblock Layer normalization, 2016.

\bibitem[Barth-Maron et~al.(2018)Barth-Maron, Hoffman, Budden, Dabney, Horgan,
  TB, Muldal, Heess, and Lillicrap]{d4pg}
Barth-Maron, G., Hoffman, M.~W., Budden, D., Dabney, W., Horgan, D., TB, D.,
  Muldal, A., Heess, N., and Lillicrap, T.
\newblock {D}istributed {D}istributional {D}eterministic {P}olicy {G}radients,
  2018.

\bibitem[Bhardwaj et~al.(2020)Bhardwaj, Handa, Fox, and
  Boots]{bhardwaj2020information}
Bhardwaj, M., Handa, A., Fox, D., and Boots, B.
\newblock Information theoretic model predictive q-learning.
\newblock In \emph{Learning for Dynamics and Control}, pp.\  840--850. PMLR,
  2020.

\bibitem[Brown \& Sandholm(2018)Brown and Sandholm]{brown2018superhuman}
Brown, N. and Sandholm, T.
\newblock Superhuman {AI} for heads-up no-limit poker: Libratus beats top
  professionals.
\newblock \emph{Science}, 359\penalty0 (6374):\penalty0 418--424, 2018.

\bibitem[Byravan et~al.(2020)Byravan, Springenberg, Abdolmaleki, Hafner,
  Neunert, Lampe, Siegel, Heess, and Riedmiller]{byravan2020imagined}
Byravan, A., Springenberg, J.~T., Abdolmaleki, A., Hafner, R., Neunert, M.,
  Lampe, T., Siegel, N., Heess, N., and Riedmiller, M.
\newblock Imagined value gradients: Model-based policy optimization with
  transferable latent dynamics models.
\newblock In \emph{Conference on Robot Learning}, pp.\  566--589. PMLR, 2020.

\bibitem[Chaslot et~al.(2008)Chaslot, Winands, Herik, Uiterwijk, and
  Bouzy]{progressive_widening}
Chaslot, G., Winands, M., Herik, H., Uiterwijk, J., and Bouzy, B.
\newblock Progressive strategies for monte-carlo tree search.
\newblock \emph{New Mathematics and Natural Computation}, 04:\penalty0
  343--357, 11 2008.
\newblock \doi{10.1142/S1793005708001094}.

\bibitem[Coulom(2006)]{coulom:mcts}
Coulom, R.
\newblock Efficient selectivity and backup operators in monte-carlo tree
  search.
\newblock In \emph{International conference on computers and games}, pp.\
  72--83. Springer, 2006.

\bibitem[Dulac-Arnold et~al.(2016)Dulac-Arnold, Evans, van Hasselt, Sunehag,
  Lillicrap, Hunt, Mann, Weber, Degris, and Coppin]{dulacarnold2016deep}
Dulac-Arnold, G., Evans, R., van Hasselt, H., Sunehag, P., Lillicrap, T., Hunt,
  J., Mann, T., Weber, T., Degris, T., and Coppin, B.
\newblock Deep reinforcement learning in large discrete action spaces, 2016.

\bibitem[Dulac-Arnold et~al.(2020)Dulac-Arnold, Levine, Mankowitz, Li,
  Paduraru, Gowal, and Hester]{dulacarnold2020empirical}
Dulac-Arnold, G., Levine, N., Mankowitz, D.~J., Li, J., Paduraru, C., Gowal,
  S., and Hester, T.
\newblock An empirical investigation of the challenges of real-world
  reinforcement learning, 2020.

\bibitem[Ghosh et~al.(2020)Ghosh, Machado, and Roux]{ghosh2020operator}
Ghosh, D., Machado, M.~C., and Roux, N.~L.
\newblock An operator view of policy gradient methods, 2020.

\bibitem[Grill et~al.(2020)Grill, Altché, Tang, Hubert, Valko, Antonoglou, and
  Munos]{grill2020montecarlo}
Grill, J.-B., Altché, F., Tang, Y., Hubert, T., Valko, M., Antonoglou, I., and
  Munos, R.
\newblock Monte-carlo tree search as regularized policy optimization, 2020.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and
  Levine]{haarnoja2018soft}
Haarnoja, T., Zhou, A., Abbeel, P., and Levine, S.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor, 2018.

\bibitem[Hafner et~al.(2018)Hafner, Lillicrap, Fischer, Villegas, Ha, Lee, and
  Davidson]{hafner:planet}
Hafner, D., Lillicrap, T., Fischer, I., Villegas, R., Ha, D., Lee, H., and
  Davidson, J.
\newblock Learning latent dynamics for planning from pixels.
\newblock \emph{arXiv preprint arXiv:1811.04551}, 2018.

\bibitem[Hafner et~al.(2019)Hafner, Lillicrap, Ba, and
  Norouzi]{hafner2019dream}
Hafner, D., Lillicrap, T., Ba, J., and Norouzi, M.
\newblock Dream to control: Learning behaviors by latent imagination.
\newblock \emph{arXiv preprint arXiv:1912.01603}, 2019.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{resv2}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Identity mappings in deep residual networks.
\newblock \emph{CoRR}, abs/1603.05027, 2016.
\newblock URL \url{http://arxiv.org/abs/1603.05027}.

\bibitem[Hennigan et~al.(2020)Hennigan, Cai, Norman, and
  Babuschkin]{haiku2020github}
Hennigan, T., Cai, T., Norman, T., and Babuschkin, I.
\newblock {H}aiku: {S}onnet for {JAX}, 2020.
\newblock URL \url{http://github.com/deepmind/dm-haiku}.

\bibitem[Hochreiter \& Schmidhuber(1997)Hochreiter and Schmidhuber]{lstm}
Hochreiter, S. and Schmidhuber, J.
\newblock Long short-term memory.
\newblock \emph{Neural Comput.}, 9\penalty0 (8):\penalty0 1735–1780, November
  1997.
\newblock ISSN 0899-7667.
\newblock \doi{10.1162/neco.1997.9.8.1735}.
\newblock URL \url{https://doi.org/10.1162/neco.1997.9.8.1735}.

\bibitem[Hoffman et~al.(2020)Hoffman, Shahriari, Aslanides, Barth-Maron,
  Behbahani, Norman, Abdolmaleki, Cassirer, Yang, Baumli, Henderson, Novikov,
  Colmenarejo, Cabi, Gulcehre, Paine, Cowie, Wang, Piot, and
  de~Freitas]{hoffman2020acme}
Hoffman, M., Shahriari, B., Aslanides, J., Barth-Maron, G., Behbahani, F.,
  Norman, T., Abdolmaleki, A., Cassirer, A., Yang, F., Baumli, K., Henderson,
  S., Novikov, A., Colmenarejo, S.~G., Cabi, S., Gulcehre, C., Paine, T.~L.,
  Cowie, A., Wang, Z., Piot, B., and de~Freitas, N.
\newblock Acme: A research framework for distributed reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2006.00979}, 2020.
\newblock URL \url{https://arxiv.org/abs/2006.00979}.

\bibitem[Kearns et~al.(1999)Kearns, Mansour, and
  Ng]{kearns-mansour-ng:sparse-sampling}
Kearns, M., Mansour, Y., and Ng, A.~Y.
\newblock A sparse sampling algorithm for near-optimal planning in large markov
  decision processes.
\newblock In \emph{Proceedings of the 16th International Joint Conference on
  Artificial Intelligence - Volume 2}, IJCAI'99, pp.\  1324–1331, San
  Francisco, CA, USA, 1999. Morgan Kaufmann Publishers Inc.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{CoRR}, abs/1412.6980, 2015.

\bibitem[Koul et~al.(2020)Koul, Kumar, Fern, and Majumdar]{koul2020dream}
Koul, A., Kumar, V.~V., Fern, A., and Majumdar, S.
\newblock Dream and search to control: Latent space planning for continuous
  control, 2020.

\bibitem[Lillicrap et~al.(2015)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap2015continuous}
Lillicrap, T.~P., Hunt, J.~J., Pritzel, A., Heess, N., Erez, T., Tassa, Y.,
  Silver, D., and Wierstra, D.
\newblock Continuous control with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1509.02971}, 2015.

\bibitem[Loshchilov \& Hutter(2017)Loshchilov and Hutter]{adam_weight_decay}
Loshchilov, I. and Hutter, F.
\newblock Fixing weight decay regularization in adam.
\newblock \emph{CoRR}, abs/1711.05101, 2017.
\newblock URL \url{http://arxiv.org/abs/1711.05101}.

\bibitem[Merel et~al.(2019)Merel, Ahuja, Pham, Tunyasuvunakool, Liu, Tirumala,
  Heess, and Wayne]{merel2018hierarchical}
Merel, J., Ahuja, A., Pham, V., Tunyasuvunakool, S., Liu, S., Tirumala, D.,
  Heess, N., and Wayne, G.
\newblock Hierarchical visuomotor control of humanoids.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=BJfYvo09Y7}.

\bibitem[Moerland et~al.(2018)Moerland, Broekens, Plaat, and
  Jonker]{moerland2018a0c}
Moerland, T.~M., Broekens, J., Plaat, A., and Jonker, C.~M.
\newblock {A0C}: {A}lpha{Z}ero in continuous action space, 2018.

\bibitem[Morav{\v{c}}{\'\i}k et~al.(2017)Morav{\v{c}}{\'\i}k, Schmid, Burch,
  Lis{\`y}, Morrill, Bard, Davis, Waugh, Johanson, and Bowling]{deepstack}
Morav{\v{c}}{\'\i}k, M., Schmid, M., Burch, N., Lis{\`y}, V., Morrill, D.,
  Bard, N., Davis, T., Waugh, K., Johanson, M., and Bowling, M.
\newblock Deepstack: Expert-level artificial intelligence in heads-up no-limit
  poker.
\newblock \emph{Science}, 356\penalty0 (6337):\penalty0 508--513, 2017.

\bibitem[Peng et~al.(2019)Peng, Kumar, Zhang, and Levine]{peng2019advantage}
Peng, X.~B., Kumar, A., Zhang, G., and Levine, S.
\newblock Advantage-weighted regression: Simple and scalable off-policy
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1910.00177}, 2019.

\bibitem[Pich{\'e} et~al.(2018)Pich{\'e}, Thomas, Ibrahim, Bengio, and
  Pal]{piche2018probabilistic}
Pich{\'e}, A., Thomas, V., Ibrahim, C., Bengio, Y., and Pal, C.
\newblock Probabilistic planning with sequential monte carlo methods.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Rubin(1987)]{sir}
Rubin, D.~B.
\newblock The calculation of posterior distributions by data augmentation:
  Comment: A noniterative sampling/importance resampling alternative to the
  data augmentation algorithm for creating a few imputations when fractions of
  missing information are modest: The sir algorithm.
\newblock \emph{Journal of the American Statistical Association}, 82\penalty0
  (398):\penalty0 543--546, 1987.
\newblock ISSN 01621459.
\newblock URL \url{http://www.jstor.org/stable/2289460}.

\bibitem[Rust(1997)]{rust1997}
Rust, J.
\newblock Using randomization to break the curse of dimensionality.
\newblock \emph{Econometrica}, 65\penalty0 (3):\penalty0 487--516, 1997.
\newblock ISSN 00129682, 14680262.
\newblock URL \url{http://www.jstor.org/stable/2171751}.

\bibitem[Schaul et~al.(2016)Schaul, Quan, Antonoglou, and Silver]{Schaul2016}
Schaul, T., Quan, J., Antonoglou, I., and Silver, D.
\newblock Prioritized experience replay.
\newblock In \emph{International Conference on Learning Representations},
  Puerto Rico, 2016.

\bibitem[Schrittwieser et~al.(2020)Schrittwieser, Antonoglou, Hubert, Simonyan,
  Sifre, Schmitt, Guez, Lockhart, Hassabis, Graepel, Lillicrap, and
  Silver]{muzero}
Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L.,
  Schmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., Lillicrap,
  T.~P., and Silver, D.
\newblock Mastering {A}tari, {G}o, {C}hess and {S}hogi by {P}lanning with a
  {L}earned {M}odel.
\newblock \emph{Nature}, 588\penalty0 (7839):\penalty0 604--609, 2020.

\bibitem[Schulman et~al.(2015)Schulman, Levine, Abbeel, Jordan, and
  Moritz]{schulman2015trust}
Schulman, J., Levine, S., Abbeel, P., Jordan, M., and Moritz, P.
\newblock Trust region policy optimization.
\newblock In \emph{International conference on machine learning}, pp.\
  1889--1897. PMLR, 2015.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Silver et~al.(2014)Silver, Lever, Heess, Degris, Wierstra, and
  Riedmiller]{ddpg2014silver}
Silver, D., Lever, G., Heess, N., Degris, T., Wierstra, D., and Riedmiller, M.
\newblock Deterministic policy gradient algorithms.
\newblock In Xing, E.~P. and Jebara, T. (eds.), \emph{Proceedings of the 31st
  International Conference on Machine Learning}, volume~32 of \emph{Proceedings
  of Machine Learning Research}, pp.\  387--395, Bejing, China, 22--24 Jun
  2014. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v32/silver14.html}.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, van~den
  Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot, Dieleman,
  Grewe, Nham, Kalchbrenner, Sutskever, Lillicrap, Leach, Kavukcuoglu, Graepel,
  and Hassabis]{Silver16AG}
Silver, D., Huang, A., Maddison, C.~J., Guez, A., Sifre, L., van~den Driessche,
  G., Schrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M.,
  Dieleman, S., Grewe, D., Nham, J., Kalchbrenner, N., Sutskever, I.,
  Lillicrap, T., Leach, M., Kavukcuoglu, K., Graepel, T., and Hassabis, D.
\newblock Mastering the game of {Go} with deep neural networks and tree search.
\newblock \emph{Nature}, 529\penalty0 (7587):\penalty0 484--489, January 2016.

\bibitem[Silver et~al.(2018)Silver, Hubert, Schrittwieser, Antonoglou, Lai,
  Guez, Lanctot, Sifre, Kumaran, Graepel, et~al.]{Silver18AZ}
Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A.,
  Lanctot, M., Sifre, L., Kumaran, D., Graepel, T., et~al.
\newblock A general reinforcement learning algorithm that masters chess, shogi,
  and {Go} through self-play.
\newblock \emph{Science}, 362\penalty0 (6419):\penalty0 1140--1144, 2018.

\bibitem[Song et~al.(2020)Song, Abdolmaleki, Springenberg, Clark, Soyer, Rae,
  Noury, Ahuja, Liu, Tirumala, Heess, Belov, Riedmiller, and
  Botvinick]{Song2020VMPO}
Song, H.~F., Abdolmaleki, A., Springenberg, J.~T., Clark, A., Soyer, H., Rae,
  J.~W., Noury, S., Ahuja, A., Liu, S., Tirumala, D., Heess, N., Belov, D.,
  Riedmiller, M., and Botvinick, M.~M.
\newblock {V-MPO}: On-policy maximum a posteriori policy optimization for
  discrete and continuous control.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=SylOlp4FvH}.

\bibitem[Springenberg et~al.(2020)Springenberg, Heess, Mankowitz, Merel,
  Byravan, Abdolmaleki, Kay, Degrave, Schrittwieser, Tassa,
  et~al.]{springenberg2020local}
Springenberg, J.~T., Heess, N., Mankowitz, D., Merel, J., Byravan, A.,
  Abdolmaleki, A., Kay, J., Degrave, J., Schrittwieser, J., Tassa, Y., et~al.
\newblock Local search for policy iteration in continuous control.
\newblock \emph{arXiv preprint arXiv:2010.05545}, 2020.

\bibitem[Sutton(1988)]{sutton88}
Sutton, R.~S.
\newblock Learning to predict by the methods of temporal differences.
\newblock 1988.
\newblock URL
  \url{http://incompleteideas.net/papers/sutton-88-with-erratum.pdf}.

\bibitem[Tang \& Agrawal(2020)Tang and Agrawal]{tang2020discretizing}
Tang, Y. and Agrawal, S.
\newblock Discretizing continuous action space for on-policy optimization,
  2020.

\bibitem[Tassa et~al.(2018)Tassa, Doron, Muldal, Erez, Li, de~Las~Casas,
  Budden, Abdolmaleki, Merel, Lefrancq, Lillicrap, and
  Riedmiller]{tassa2018deepmind}
Tassa, Y., Doron, Y., Muldal, A., Erez, T., Li, Y., de~Las~Casas, D., Budden,
  D., Abdolmaleki, A., Merel, J., Lefrancq, A., Lillicrap, T., and Riedmiller,
  M.
\newblock Deepmind control suite, 2018.

\bibitem[Tassa et~al.(2020)Tassa, Tunyasuvunakool, Muldal, Doron, Liu, Bohez,
  Merel, Erez, Lillicrap, and Heess]{tassa2020dm_control}
Tassa, Y., Tunyasuvunakool, S., Muldal, A., Doron, Y., Liu, S., Bohez, S.,
  Merel, J., Erez, T., Lillicrap, T., and Heess, N.
\newblock dm\_control: Software and tasks for continuous control.
\newblock \emph{arXiv preprint arXiv:2006.12983}, 2020.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{mujoco}
Todorov, E., Erez, T., and Tassa, Y.
\newblock Mujoco: A physics engine for model-based control.
\newblock pp.\  5026--5033, 10 2012.
\newblock ISBN 978-1-4673-1737-5.
\newblock \doi{10.1109/IROS.2012.6386109}.

\bibitem[Williams(1992)]{williams1992simple}
Williams, R.~J.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 229--256, 1992.

\bibitem[Yang et~al.(2020)Yang, Duvaud, and Wei]{yang2020continuous}
Yang, X., Duvaud, W., and Wei, P.
\newblock Continuous control for searching and planning with a learned model,
  2020.

\bibitem[Zahavy et~al.(2020)Zahavy, Xu, Veeriah, Hessel, Oh, van Hasselt,
  Silver, and Singh]{zahavy2020stacx}
Zahavy, T., Xu, Z., Veeriah, V., Hessel, M., Oh, J., van Hasselt, H.~P.,
  Silver, D., and Singh, S.
\newblock A self-tuning actor-critic algorithm.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\end{thebibliography}
