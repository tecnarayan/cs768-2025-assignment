\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Jiang et~al.(2017)Jiang, Krishnamurthy, Agarwal, Langford, and
  Schapire]{jiang2017contextual}
Nan Jiang, Akshay Krishnamurthy, Alekh Agarwal, John Langford, and Robert~E.
  Schapire.
\newblock Contextual decision processes with low {B}ellman rank are
  {PAC}-learnable.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A. Rusu, Joel Veness,
  Marc~G. Bellemare, Alex Graves, Martin Riedmiller, Andreas~K. Fidjeland,
  Georg Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis
  Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, and
  Demis Hassabis.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 2015.

\bibitem[Kearns and Singh(2002)]{kearns2002near}
Michael Kearns and Satinder Singh.
\newblock Near-optimal reinforcement learning in polynomial time.
\newblock \emph{Machine Learning}, 2002.

\bibitem[Brafman and Tennenholtz(2003)]{brafman2003r}
Ronen~I. Brafman and Moshe Tennenholtz.
\newblock R-max -- a general polynomial time algorithm for near-optimal
  reinforcement learning.
\newblock \emph{Journal of Machine Learning Research}, 2003.

\bibitem[Strehl and Littman(2005)]{strehl2005theoretical}
Alexander~L. Strehl and Michael~L. Littman.
\newblock A theoretical analysis of model-based interval estimation.
\newblock In \emph{International Conference on Machine learning}, 2005.

\bibitem[Strehl et~al.(2006)Strehl, Li, Wiewiora, Langford, and
  Littman]{strehl2006pac}
Alexander~L. Strehl, Lihong Li, Eric Wiewiora, John Langford, and Michael~L.
  Littman.
\newblock {PAC} model-free reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2006.

\bibitem[Auer et~al.(2009)Auer, Jaksch, and Ortner]{auer2009near}
Peter Auer, Thomas Jaksch, and Ronald Ortner.
\newblock Near-optimal regret bounds for reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2009.

\bibitem[Dann and Brunskill(2015)]{dann2015sample}
Christoph Dann and Emma Brunskill.
\newblock Sample complexity of episodic fixed-horizon reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2015.

\bibitem[Azar et~al.(2017)Azar, Osband, and Munos]{azar2017minimax}
Mohammad~Gheshlaghi Azar, Ian Osband, and R{\'e}mi Munos.
\newblock Minimax regret bounds for reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Dann et~al.(2017)Dann, Lattimore, and Brunskill]{dann2017unifying}
Christoph Dann, Tor Lattimore, and Emma Brunskill.
\newblock Unifying {PAC} and regret: Uniform {PAC} bounds for episodic
  reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Kakade et~al.(2003)Kakade, Kearns, and
  Langford]{kakade2003exploration}
Sham~M. Kakade, Michael Kearns, and John Langford.
\newblock Exploration in metric state spaces.
\newblock In \emph{International Conference on Machine Learning}, 2003.

\bibitem[Pazis and Parr(2013)]{pazis2013pac}
Jason Pazis and Ronald Parr.
\newblock {PAC} optimal exploration in continuous space {M}arkov decision
  processes.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2013.

\bibitem[Grande et~al.(2014)Grande, Walsh, and How]{grande2014sample}
Robert Grande, Thomas Walsh, and Jonathan How.
\newblock Sample efficient reinforcement learning with gaussian processes.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Pazis and Parr(2016)]{pazis2016efficient}
Jason Pazis and Ronald Parr.
\newblock Efficient {PAC}-optimal exploration in concurrent, continuous state
  {MDP}s with delayed updates.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2016.

\bibitem[Wen and Van~Roy(2013)]{wen2013efficient}
Zheng Wen and Benjamin Van~Roy.
\newblock Efficient exploration and value function generalization in
  deterministic systems.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2013.

\bibitem[Wen and Van~Roy(2017)]{wen2017efficient}
Zheng Wen and Benjamin Van~Roy.
\newblock Efficient reinforcement learning in deterministic systems with value
  function generalization.
\newblock \emph{Mathematics of Operations Research}, 2017.

\bibitem[Krishnamurthy et~al.(2016)Krishnamurthy, Agarwal, and
  Langford]{krishnamurthy2016contextual}
Akshay Krishnamurthy, Alekh Agarwal, and John Langford.
\newblock {PAC} reinforcement learning with rich observations.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Hsu(2010)]{hsu2010algorithms}
Daniel~Joseph Hsu.
\newblock \emph{Algorithms for active learning}.
\newblock PhD thesis, UC San Diego, 2010.

\bibitem[Agarwal et~al.(2014)Agarwal, Hsu, Kale, Langford, Li, and
  Schapire]{agarwal2014taming}
Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, and Robert~E.
  Schapire.
\newblock Taming the monster: A fast and simple algorithm for contextual
  bandits.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Ross and Bagnell(2014)]{ross2014reinforcement}
Stephane Ross and J~Andrew Bagnell.
\newblock Reinforcement and imitation learning via interactive no-regret
  learning.
\newblock \emph{arXiv:1406.5979}, 2014.

\bibitem[Chang et~al.(2015)Chang, Krishnamurthy, Agarwal, Daume~III, and
  Langford]{chang2015learning}
Kai-Wei Chang, Akshay Krishnamurthy, Alekh Agarwal, Hal Daume~III, and John
  Langford.
\newblock Learning to search better than your teacher.
\newblock In \emph{International Conference on Machine Learning}, 2015.

\bibitem[Allwein et~al.(2000)Allwein, Schapire, and
  Singer]{allwein2000reducing}
Erin~L. Allwein, Robert~E. Schapire, and Yoram Singer.
\newblock Reducing multiclass to binary: A unifying approach for margin
  classifiers.
\newblock \emph{Journal of Machine Learning Research}, 2000.

\bibitem[Johnson et~al.(2016)Johnson, Hofmann, Hutton, and
  Bignell]{johnson2016malmo}
Matthew Johnson, Katja Hofmann, Tim Hutton, and David Bignell.
\newblock {The Malmo Platform for artificial intelligence experimentation}.
\newblock In \emph{International Joint Conference on Artificial Intelligence},
  2016.

\bibitem[Kearns and Koller(1999)]{kearns1999efficient}
Michael Kearns and Daphne Koller.
\newblock Efficient reinforcement learning in factored {MDP}s.
\newblock In \emph{International Joint Conference on Artificial Intelligence},
  1999.

\bibitem[Li et~al.(2006)Li, Walsh, and Littman]{li2006towards}
Lihong Li, Thomas~J. Walsh, and Michael~L. Littman.
\newblock {Towards a unified theory of state abstraction for MDPs}.
\newblock In \emph{International Symposium on Artificial Intelligence and
  Mathematics}, 2006.

\bibitem[Azizzadenesheli et~al.(2016{\natexlab{a}})Azizzadenesheli, Lazaric,
  and Anandkumar]{azizzadenesheli2016romdp}
Kamyar Azizzadenesheli, Alessandro Lazaric, and Animashree Anandkumar.
\newblock Reinforcement learning in rich-observation {MDP}s using spectral
  methods.
\newblock \emph{arXiv:1611.03907}, 2016{\natexlab{a}}.

\bibitem[Azizzadenesheli et~al.(2016{\natexlab{b}})Azizzadenesheli, Lazaric,
  and Anandkumar]{azizzadenesheli2016reinforcement}
Kamyar Azizzadenesheli, Alessandro Lazaric, and Animashree Anandkumar.
\newblock Reinforcement learning of {POMDP}s using spectral methods.
\newblock In \emph{Conference on Learning Theory}, 2016{\natexlab{b}}.

\bibitem[Guo et~al.(2016)Guo, Doroudi, and Brunskill]{guo2016pac}
Zhaohan~Daniel Guo, Shayan Doroudi, and Emma Brunskill.
\newblock A {PAC} {RL} algorithm for episodic {POMDP}s.
\newblock In \emph{Artificial Intelligence and Statistics}, 2016.

\bibitem[Russo and Van~Roy(2013)]{russo2013eluder}
Dan Russo and Benjamin Van~Roy.
\newblock Eluder dimension and the sample complexity of optimistic exploration.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2013.

\bibitem[Osband and Van~Roy(2014)]{osband2014model}
Ian Osband and Benjamin Van~Roy.
\newblock Model-based reinforcement learning and the {E}luder dimension.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2014.

\bibitem[Anthony and Bartlett(2009)]{anthony2009neural}
Martin Anthony and Peter~L Bartlett.
\newblock \emph{Neural network learning: Theoretical foundations}.
\newblock Cambridge University Press, 2009.

\bibitem[Dai et~al.(2018)Dai, Shaw, Li, Xiao, He, Liu, Chen, and
  Song]{dai2018sbeed}
Bo~Dai, Albert Shaw, Lihong Li, Lin Xiao, Niao He, Zhen Liu, Jianshu Chen, and
  Le~Song.
\newblock Sbeed: Convergent reinforcement learning with nonlinear function
  approximation.
\newblock In \emph{International Conference on Machine Learning}, pages
  1133--1142, 2018.

\bibitem[Beygelzimer et~al.(2009)Beygelzimer, Langford, and
  Ravikumar]{beygelzimer2009error}
Alina Beygelzimer, John Langford, and Pradeep Ravikumar.
\newblock Error-correcting tournaments.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  2009.

\bibitem[Langford and Beygelzimer(2005)]{langford2005sensitive}
John Langford and Alina Beygelzimer.
\newblock Sensitive error correcting output codes.
\newblock In \emph{International Conference on Computational Learning Theory},
  2005.

\bibitem[Langford and Zhang(2008)]{langford2008epoch}
John Langford and Tong Zhang.
\newblock The epoch-greedy algorithm for multi-armed bandits with side
  information.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2008.

\bibitem[Ross(2013)]{ross2013interactive}
Stephane Ross.
\newblock \emph{Interactive learning for sequential decisions and predictions}.
\newblock PhD thesis, Carnegie Mellon University, 2013.

\bibitem[Khachiyan(1980)]{khachiyan1980polynomial}
Leonid~G Khachiyan.
\newblock Polynomial algorithms in linear programming.
\newblock \emph{USSR Computational Mathematics and Mathematical Physics}, 1980.

\bibitem[Gordon(1995)]{gordon1995stable}
Geoffrey~J Gordon.
\newblock Stable function approximation in dynamic programming.
\newblock In \emph{International Conference on Machine Learning}, 1995.

\bibitem[Bagnell et~al.(2004)Bagnell, Kakade, Schneider, and
  Ng]{bagnell2004policy}
J~Andrew Bagnell, Sham~M Kakade, Jeff~G Schneider, and Andrew~Y Ng.
\newblock Policy search by dynamic programming.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2004.

\bibitem[Arora et~al.(2012)Arora, Hazan, and Kale]{arora2012multiplicative}
Sanjeev Arora, Elad Hazan, and Satyen Kale.
\newblock The multiplicative weights update method: a meta-algorithm and
  applications.
\newblock \emph{Theory of Computing}, 2012.

\bibitem[Munos and Szepesv{\'a}ri(2008)]{munos2008finite}
R{\'e}mi Munos and Csaba Szepesv{\'a}ri.
\newblock Finite-time bounds for fitted value iteration.
\newblock \emph{Journal of Machine Learning Research}, 2008.

\bibitem[Antos et~al.(2008)Antos, Szepesv{\'a}ri, and Munos]{antos2008learning}
Andr{\'a}s Antos, Csaba Szepesv{\'a}ri, and R{\'e}mi Munos.
\newblock Learning near-optimal policies with {B}ellman-residual minimization
  based fitted policy iteration and a single sample path.
\newblock \emph{Machine Learning}, 2008.

\bibitem[Gretton et~al.(2012)Gretton, Borgwardt, Rasch, Sch{\"o}lkopf, and
  Smola]{gretton2012kernel}
Arthur Gretton, Karsten~M. Borgwardt, Malte~J. Rasch, Bernhard Sch{\"o}lkopf,
  and Alexander~J. Smola.
\newblock A kernel two-sample test.
\newblock \emph{Journal of Machine Learning Research}, 2012.

\bibitem[Sch{\"o}lkopf and Smola(2002)]{scholkopf2002learning}
Bernhard Sch{\"o}lkopf and Alexander~J. Smola.
\newblock \emph{Learning with kernels: support vector machines, regularization,
  optimization, and beyond}.
\newblock MIT Press, 2002.

\bibitem[Gr{\"o}tschel et~al.(1981)Gr{\"o}tschel, Lov{\'a}sz, and
  Schrijver]{grotschel1981ellipsoid}
Martin Gr{\"o}tschel, L{\'a}szl{\'o} Lov{\'a}sz, and Alexander Schrijver.
\newblock The ellipsoid method and its consequences in combinatorial
  optimization.
\newblock \emph{Combinatorica}, 1981.

\bibitem[Ernst et~al.(2005)Ernst, Geurts, and Wehenkel]{ernst2005tree}
Damien Ernst, Pierre Geurts, and Louis Wehenkel.
\newblock Tree-based batch mode reinforcement learning.
\newblock \emph{Journal of Machine Learning Research}, 2005.

\bibitem[Farahmand et~al.(2010)Farahmand, Szepesv{\'a}ri, and
  Munos]{farahmand2010error}
Amir-Massoud Farahmand, Csaba Szepesv{\'a}ri, and R{\'e}mi Munos.
\newblock Error propagation for approximate policy and value iteration.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2010.

\end{thebibliography}
