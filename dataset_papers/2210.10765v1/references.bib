@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{kalashnikov2018qt,
  title={QT-Opt: Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  journal={arXiv preprint arXiv:1806.10293},
  year={2018}
}

@article{lumbrl,
  author    = {Kevin Lu and
               Aditya Grover and
               Pieter Abbeel and
               Igor Mordatch},
  title     = {Reset-Free Lifelong Learning with Skill-Space Planning},
  journal   = {CoRR},
  volume    = {abs/2012.03548},
  year      = {2020},
}

@inproceedings{nagabandi2020deep,
  title={Deep dynamics models for learning dexterous manipulation},
  author={Nagabandi, Anusha and Konolige, Kurt and Levine, Sergey and Kumar, Vikash},
  booktitle={Conference on Robot Learning},
  pages={1101--1112},
  year={2020},
  organization={PMLR}
}

@article{sharma2020emergent,
  title={Emergent Real-World Robotic Skills via Unsupervised Off-Policy Reinforcement Learning},
  author={Sharma, Archit and Ahn, Michael and Levine, Sergey and Kumar, Vikash and Hausman, Karol and Gu, Shixiang},
  journal={arXiv preprint arXiv:2004.12974},
  year={2020}
}

@inproceedings{zhu2019dexterous,
  title={Dexterous manipulation with deep reinforcement learning: Efficient, general, and low-cost},
  author={Zhu, Henry and Gupta, Abhishek and Rajeswaran, Aravind and Levine, Sergey and Kumar, Vikash},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={3651--3657},
  year={2019},
  organization={IEEE}
}

@inproceedings{yang2020data,
  title={Data efficient reinforcement learning for legged robots},
  author={Yang, Yuxiang and Caluwaerts, Ken and Iscen, Atil and Zhang, Tingnan and Tan, Jie and Sindhwani, Vikas},
  booktitle={Conference on Robot Learning},
  pages={1--10},
  year={2020},
  organization={PMLR}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{zhu2020ingredients,
  title={The Ingredients of Real-World Robotic Reinforcement Learning},
  author={Zhu, Henry and Yu, Justin and Gupta, Abhishek and Shah, Dhruv and Hartikainen, Kristian and Singh, Avi and Kumar, Vikash and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.12570},
  year={2020}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}
@inproceedings{kohl2004policy,
  title={Policy gradient reinforcement learning for fast quadrupedal locomotion},
  author={Kohl, Nate and Stone, Peter},
  booktitle={IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA'04. 2004},
  volume={3},
  pages={2619--2624},
  year={2004},
  organization={IEEE}
}

@inproceedings{ng2003autonomous,
  title={Autonomous helicopter flight via reinforcement learning.},
  author={Ng, Andrew Y and Kim, H Jin and Jordan, Michael I and Sastry, Shankar and Ballianda, Shiv},
  booktitle={NIPS},
  volume={16},
  year={2003},
  organization={Citeseer}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{finn2016deep,
  title={Deep spatial autoencoders for visuomotor learning},
  author={Finn, Chelsea and Tan, Xin Yu and Duan, Yan and Darrell, Trevor and Levine, Sergey and Abbeel, Pieter},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={512--519},
  year={2016},
  organization={IEEE}
}

@inproceedings{ghadirzadeh2017deep,
  title={Deep predictive policy training using reinforcement learning},
  author={Ghadirzadeh, Ali and Maki, Atsuto and Kragic, Danica and Bj{\"o}rkman, M{\aa}rten},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={2351--2358},
  year={2017},
  organization={IEEE}
}

@inproceedings{chebotar2017combining,
  title={Combining model-based and model-free updates for trajectory-centric reinforcement learning},
  author={Chebotar, Yevgen and Hausman, Karol and Zhang, Marvin and Sukhatme, Gaurav and Schaal, Stefan and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={703--711},
  year={2017},
  organization={PMLR}
}

@article{haarnoja2018learning,
  title={Learning to walk via deep reinforcement learning},
  author={Haarnoja, Tuomas and Ha, Sehoon and Zhou, Aurick and Tan, Jie and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.11103},
  year={2018}
}

@misc{ha2020learning,
      title={Learning to Walk in the Real World with Minimal Human Effort}, 
      author={Sehoon Ha and Peng Xu and Zhenyu Tan and Sergey Levine and Jie Tan},
      year={2020},
      eprint={2002.08550},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}

@article{moldovan2012safe,
  title={Safe exploration in markov decision processes},
  author={Moldovan, Teodor Mihai and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1205.4810},
  year={2012}
}

@article{thananjeyan2020recovery,
  title={Recovery rl: Safe reinforcement learning with learned recovery zones},
  author={Thananjeyan, Brijen and Balakrishna, Ashwin and Nair, Suraj and Luo, Michael and Srinivasan, Krishnan and Hwang, Minho and Gonzalez, Joseph E and Ibarz, Julian and Finn, Chelsea and Goldberg, Ken},
  journal={arXiv preprint arXiv:2010.15920},
  year={2020}
}

@article{eysenbach2017leave,
  title={Leave no trace: Learning to reset for safe and autonomous reinforcement learning},
  author={Eysenbach, Benjamin and Gu, Shixiang and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.06782},
  year={2017}
}

@inproceedings{han2015learning,
  title={Learning compound multi-step controllers under unknown dynamics},
  author={Han, Weiqiao and Levine, Sergey and Abbeel, Pieter},
  booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={6435--6442},
  year={2015},
  organization={IEEE}
}

@article{chow2018lyapunov,
  title={A lyapunov-based approach to safe reinforcement learning},
  author={Chow, Yinlam and Nachum, Ofir and Duenez-Guzman, Edgar and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1805.07708},
  year={2018}
}

@inproceedings{bansal2017hamilton,
  title={Hamilton-Jacobi reachability: A brief overview and recent advances},
  author={Bansal, Somil and Chen, Mo and Herbert, Sylvia and Tomlin, Claire J},
  booktitle={2017 IEEE 56th Annual Conference on Decision and Control (CDC)},
  pages={2242--2253},
  year={2017},
  organization={IEEE}
}

@article{fisac2018general,
  title={A general safety framework for learning-based control in uncertain robotic systems},
  author={Fisac, Jaime F and Akametalu, Anayo K and Zeilinger, Melanie N and Kaynama, Shahab and Gillula, Jeremy and Tomlin, Claire J},
  journal={IEEE Transactions on Automatic Control},
  volume={64},
  number={7},
  pages={2737--2752},
  year={2018},
  publisher={IEEE}
}

@inproceedings{florensa2017reverse,
  title={Reverse curriculum generation for reinforcement learning},
  author={Florensa, Carlos and Held, David and Wulfmeier, Markus and Zhang, Michael and Abbeel, Pieter},
  booktitle={Conference on robot learning},
  pages={482--495},
  year={2017},
  organization={PMLR}
}

@article{sukhbaatar2017intrinsic,
  title={Intrinsic motivation and automatic curricula via asymmetric self-play},
  author={Sukhbaatar, Sainbayar and Lin, Zeming and Kostrikov, Ilya and Synnaeve, Gabriel and Szlam, Arthur and Fergus, Rob},
  journal={arXiv preprint arXiv:1703.05407},
  year={2017}
}

@inproceedings{florensa2018automatic,
  title={Automatic goal generation for reinforcement learning agents},
  author={Florensa, Carlos and Held, David and Geng, Xinyang and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1515--1528},
  year={2018},
  organization={PMLR}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{khetarpal2020towards,
  title={Towards Continual Reinforcement Learning: A Review and Perspectives},
  author={Khetarpal, Khimya and Riemer, Matthew and Rish, Irina and Precup, Doina},
  journal={arXiv preprint arXiv:2012.13490},
  year={2020}
}

@article{puterman1990markov,
  title={Markov decision processes},
  author={Puterman, Martin L},
  journal={Handbooks in operations research and management science},
  volume={2},
  pages={331--434},
  year={1990},
  publisher={Elsevier}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={IJCAI},
  pages={1094--1099},
  year={1993},
  organization={Citeseer}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015},
  organization={PMLR}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={In Proc. 19th International Conference on Machine Learning},
  year={2002},
  organization={Citeseer}
}

@article{zeng2020tossingbot,
  title={Tossingbot: Learning to throw arbitrary objects with residual physics},
  author={Zeng, Andy and Song, Shuran and Lee, Johnny and Rodriguez, Alberto and Funkhouser, Thomas},
  journal={IEEE Transactions on Robotics},
  volume={36},
  number={4},
  pages={1307--1319},
  year={2020},
  publisher={IEEE}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@inproceedings{pinto2016supersizing,
  title={Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours},
  author={Pinto, Lerrel and Gupta, Abhinav},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={3406--3413},
  year={2016},
  organization={IEEE}
}

@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}

@article{berkenkamp2017safe,
  title={Safe model-based reinforcement learning with stability guarantees},
  author={Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela P and Krause, Andreas},
  journal={arXiv preprint arXiv:1705.08551},
  year={2017}
}

@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}

@article{turchetta2016safe,
  title={Safe exploration in finite markov decision processes with gaussian processes},
  author={Turchetta, Matteo and Berkenkamp, Felix and Krause, Andreas},
  journal={arXiv preprint arXiv:1606.04753},
  year={2016}
}

@inproceedings{alshiekh2018safe,
  title={Safe reinforcement learning via shielding},
  author={Alshiekh, Mohammed and Bloem, Roderick and Ehlers, R{\"u}diger and K{\"o}nighofer, Bettina and Niekum, Scott and Topcu, Ufuk},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{matiisen2019teacher,
  title={Teacher--student curriculum learning},
  author={Matiisen, Tambet and Oliver, Avital and Cohen, Taco and Schulman, John},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={9},
  pages={3732--3740},
  year={2019},
  publisher={IEEE}
}

@article{narvekar2018learning,
  title={Learning curriculum policies for reinforcement learning},
  author={Narvekar, Sanmit and Stone, Peter},
  journal={arXiv preprint arXiv:1812.00285},
  year={2018}
}

@article{goodfellow2014generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.2661},
  year={2014}
}

@article{pong2018temporal,
  title={Temporal difference models: Model-free deep rl for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.09081},
  year={2018}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1707.01495},
  year={2017}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@inproceedings{yahya2017collective,
  title={Collective robot reinforcement learning with distributed asynchronous guided policy search},
  author={Yahya, Ali and Li, Adrian and Kalakrishnan, Mrinal and Chebotar, Yevgen and Levine, Sergey},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={79--86},
  year={2017},
  organization={IEEE}
}

@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@article{Tesauro1995TeporalDL,
  title={Temporal difference learning and TD-Gammon},
  author={G. Tesauro},
  journal={Commun. ACM},
  year={1995},
  volume={38},
  pages={58-68}
}

@article{Rajeswaran2018LearningCD,
  title={Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations},
  author={A. Rajeswaran and V. Kumar and Abhishek Gupta and John Schulman and E. Todorov and Sergey Levine},
  journal={ArXiv},
  year={2018},
  volume={abs/1709.10087}
}

@article{Gupta2021ResetFreeRL,
  title={Reset-Free Reinforcement Learning via Multi-Task Learning: Learning Dexterous Manipulation Behaviors without Human Intervention},
  author={Abhishek Gupta and Justin Yu and Tony Zhao and Vikash Kumar and Aaron Rovinsky and Kelvin Xu and Thomas Devlin and Sergey Levine},
  journal={ArXiv},
  year={2021},
  volume={abs/2104.11203}
}

@article{Xu2020ContinualLO,
  title={Continual Learning of Control Primitives: Skill Discovery via Reset-Games},
  author={Kelvin Xu and Siddharth Verma and Chelsea Finn and Sergey Levine},
  journal={ArXiv},
  year={2020},
  volume={abs/2011.05286}
}

@article{kalashnikov2021mt,
  title={MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale},
  author={Kalashnikov, Dmitry and Varley, Jacob and Chebotar, Yevgen and Swanson, Benjamin and Jonschkowski, Rico and Finn, Chelsea and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:2104.08212},
  year={2021}
}

@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={arXiv preprint arXiv:2001.06782},
  year={2020}
}

@article{lu2020reset,
  title={Reset-Free Lifelong Learning with Skill-Space Planning},
  author={Lu, Kevin and Grover, Aditya and Abbeel, Pieter and Mordatch, Igor},
  journal={arXiv preprint arXiv:2012.03548},
  year={2020}
}

@article{hafner2017tensorflow,
  title={Tensorflow agents: Efficient batched reinforcement learning in tensorflow},
  author={Hafner, Danijar and Davidson, James and Vanhoucke, Vincent},
  journal={arXiv preprint arXiv:1709.02878},
  year={2017}
}

@article{konidaris2009skill,
  title={Skill discovery in continuous reinforcement learning domains using skill chaining},
  author={Konidaris, George and Barto, Andrew},
  journal={Advances in neural information processing systems},
  volume={22},
  pages={1015--1023},
  year={2009}
}

% NEW CITATIONS --- 
@inproceedings{wagener2021safe,
  title={Safe reinforcement learning using advantage-based intervention},
  author={Wagener, Nolan C and Boots, Byron and Cheng, Ching-An},
  booktitle={International Conference on Machine Learning},
  pages={10630--10640},
  year={2021},
  organization={PMLR}
}

@article{sharma2021autonomous,
  title={Autonomous Reinforcement Learning: Formalism and Benchmarking},
  author={Sharma, Archit and Xu, Kelvin and Sardana, Nikhil and Gupta, Abhishek and Hausman, Karol and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2112.09605},
  year={2021}
}

@article{thananjeyan2020safety,
  title={Safety augmented value estimation from demonstrations (saved): Safe deep model-based rl for sparse cost robotic tasks},
  author={Thananjeyan, Brijen and Balakrishna, Ashwin and Rosolia, Ugo and Li, Felix and McAllister, Rowan and Gonzalez, Joseph E and Levine, Sergey and Borrelli, Francesco and Goldberg, Ken},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={2},
  pages={3612--3619},
  year={2020},
  publisher={IEEE}
}

@article{rosolia2017learning,
  title={Learning model predictive control for iterative tasks. a data-driven control framework},
  author={Rosolia, Ugo and Borrelli, Francesco},
  journal={IEEE Transactions on Automatic Control},
  volume={63},
  number={7},
  pages={1883--1896},
  year={2017},
  publisher={IEEE}
}

@article{sun2021safe,
  title={Safe exploration by solving early terminated mdp},
  author={Sun, Hao and Xu, Ziping and Fang, Meng and Peng, Zhenghao and Guo, Jiadong and Dai, Bo and Zhou, Bolei},
  journal={arXiv preprint arXiv:2107.04200},
  year={2021}
}

@article{thomas2021safe,
  title={Safe Reinforcement Learning by Imagining the Near Future},
  author={Thomas, Garrett and Luo, Yuping and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{bharadhwaj2020conservative,
  title={Conservative safety critics for exploration},
  author={Bharadhwaj, Homanga and Kumar, Aviral and Rhinehart, Nicholas and Levine, Sergey and Shkurti, Florian and Garg, Animesh},
  journal={arXiv preprint arXiv:2010.14497},
  year={2020}
}

@article{srinivasan2020learning,
  title={Learning to be safe: Deep rl with a safety critic},
  author={Srinivasan, Krishnan and Eysenbach, Benjamin and Ha, Sehoon and Tan, Jie and Finn, Chelsea},
  journal={arXiv preprint arXiv:2010.14603},
  year={2020}
}

@article{thananjeyan2021recovery,
  title={Recovery rl: Safe reinforcement learning with learned recovery zones},
  author={Thananjeyan, Brijen and Balakrishna, Ashwin and Nair, Suraj and Luo, Michael and Srinivasan, Krishnan and Hwang, Minho and Gonzalez, Joseph E and Ibarz, Julian and Finn, Chelsea and Goldberg, Ken},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={3},
  pages={4915--4922},
  year={2021},
  publisher={IEEE}
}

@article{grinsztajn2021there,
  title={There Is No Turning Back: A Self-Supervised Approach for Reversibility-Aware Reinforcement Learning},
  author={Grinsztajn, Nathan and Ferret, Johan and Pietquin, Olivier and Geist, Matthieu and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{turchetta2020safe,
  title={Safe reinforcement learning via curriculum induction},
  author={Turchetta, Matteo and Kolobov, Andrey and Shah, Shital and Krause, Andreas and Agarwal, Alekh},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12151--12162},
  year={2020}
}

@article{dalal2018safe,
  title={Safe exploration in continuous action spaces},
  author={Dalal, Gal and Dvijotham, Krishnamurthy and Vecerik, Matej and Hester, Todd and Paduraru, Cosmin and Tassa, Yuval},
  journal={arXiv preprint arXiv:1801.08757},
  year={2018}
}

@article{wabersich2018safe,
  title={Safe exploration of nonlinear dynamical systems: A predictive safety filter for reinforcement learning},
  author={Wabersich, Kim P and Zeilinger, Melanie N},
  journal={arXiv preprint arXiv:1812.05506},
  year={2018}
}

@article{perkins2002lyapunov,
  title={Lyapunov design for safe reinforcement learning},
  author={Perkins, Theodore J and Barto, Andrew G},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Dec},
  pages={803--832},
  year={2002}
}

@inproceedings{li2020robust,
  title={Robust model predictive shielding for safe reinforcement learning with stochastic dynamics},
  author={Li, Shuo and Bastani, Osbert},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7166--7172},
  year={2020},
  organization={IEEE}
}

@article{bastanisafe,
  title={Safe Reinforcement Learning via Statistical Model Predictive Shielding},
  author={Bastani, Osbert and Li, Shuo and Xu, Anton}
}

@article{tessler2018reward,
  title={Reward constrained policy optimization},
  author={Tessler, Chen and Mankowitz, Daniel J and Mannor, Shie},
  journal={arXiv preprint arXiv:1805.11074},
  year={2018}
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={22--31},
  year={2017},
  organization={PMLR}
}

@inproceedings{zanger2021safe,
  title={Safe continuous control with constrained model-based policy optimization},
  author={Zanger, Moritz A and Daaboul, Karam and Z{\"o}llner, J Marius},
  booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={3512--3519},
  year={2021},
  organization={IEEE}
}

@article{chow2017risk,
  title={Risk-constrained reinforcement learning with percentile risk criteria},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad and Janson, Lucas and Pavone, Marco},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={6070--6120},
  year={2017},
  publisher={JMLR. org}
}

@article{scobee2019maximum,
  title={Maximum likelihood constraint inference for inverse reinforcement learning},
  author={Scobee, Dexter RR and Sastry, S Shankar},
  journal={arXiv preprint arXiv:1909.05477},
  year={2019}
}

@inproceedings{malik2021inverse,
  title={Inverse constrained reinforcement learning},
  author={Malik, Shehryar and Anwar, Usman and Aghasi, Alireza and Ahmed, Ali},
  booktitle={International Conference on Machine Learning},
  pages={7390--7399},
  year={2021},
  organization={PMLR}
}

@article{stocking2021discretizing,
  title={Discretizing Dynamics for Maximum Likelihood Constraint Inference},
  author={Stocking, Kaylene C and McPherson, David L and Matthew, Robert P and Tomlin, Claire J},
  journal={arXiv preprint arXiv:2109.04874},
  year={2021}
}

@inproceedings{fischer2021sampling,
  title={Sampling-based Inverse Reinforcement Learning Algorithms with Safety Constraints},
  author={Fischer, Johannes and Eyberg, Christoph and Werling, Moritz and Lauer, Martin},
  booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={791--798},
  organization={IEEE}
}

@inproceedings{bastani2021safe,
  title={Safe reinforcement learning via statistical model predictive shielding},
  author={Bastani, Osbert and Li, Shuo and Xu, Anton},
  booktitle={Robotics: Science and Systems},
  year={2021}
}

@inproceedings{kruusmaa2007don,
  title={Don't do things you can't undo: reversibility models for generating safe behaviours},
  author={Kruusmaa, Maarja and Gavshin, Yuri and Eppendahl, Adam},
  booktitle={Proceedings 2007 IEEE International Conference on Robotics and Automation},
  pages={1134--1139},
  year={2007},
  organization={IEEE}
}

@article{rahaman2020learning,
  title={Learning the arrow of time for problems in reinforcement learning},
  author={Rahaman, Nasim and Wolf, Steffen and Goyal, Anirudh and Remme, Roman and Bengio, Yoshua},
  year={2020}
}

@article{savinov2018episodic,
  title={Episodic curiosity through reachability},
  author={Savinov, Nikolay and Raichuk, Anton and Marinier, Rapha{\"e}l and Vincent, Damien and Pollefeys, Marc and Lillicrap, Timothy and Gelly, Sylvain},
  journal={arXiv preprint arXiv:1810.02274},
  year={2018}
}

@article{krakovna2018penalizing,
  title={Penalizing side effects using stepwise relative reachability},
  author={Krakovna, Victoria and Orseau, Laurent and Kumar, Ramana and Martic, Miljan and Legg, Shane},
  journal={arXiv preprint arXiv:1806.01186},
  year={2018}
}

@article{badia2020never,
  title={Never give up: Learning directed exploration strategies},
  author={Badia, Adri{\`a} Puigdom{\`e}nech and Sprechmann, Pablo and Vitvitskyi, Alex and Guo, Daniel and Piot, Bilal and Kapturowski, Steven and Tieleman, Olivier and Arjovsky, Mart{\'\i}n and Pritzel, Alexander and Bolt, Andew and others},
  journal={arXiv preprint arXiv:2002.06038},
  year={2020}
}

@article{nair2018time,
  title={Time reversal as self-supervision},
  author={Nair, Suraj and Babaeizadeh, Mohammad and Finn, Chelsea and Levine, Sergey and Kumar, Vikash},
  journal={arXiv preprint arXiv:1810.01128},
  year={2018}
}

@inproceedings{gupta2021reset,
  title={Reset-free reinforcement learning via multi-task learning: Learning dexterous manipulation behaviors without human intervention},
  author={Gupta, Abhishek and Yu, Justin and Zhao, Tony Z and Kumar, Vikash and Rovinsky, Aaron and Xu, Kelvin and Devlin, Thomas and Levine, Sergey},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6664--6671},
  year={2021},
  organization={IEEE}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@article{co2020ecological,
  title={Ecological Reinforcement Learning},
  author={Co-Reyes, John D and Sanjeev, Suvansh and Berseth, Glen and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.12478},
  year={2020}
}

@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@article{sharma2021autonomouscurr,
  title={Autonomous Reinforcement Learning via Subgoal Curricula},
  author={Sharma, Archit and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{sharma2022state,
  title={A State-Distribution Matching Approach to Non-Episodic Reinforcement Learning},
  author={Sharma, Archit and Ahmad, Rehaan and Finn, Chelsea},
  journal={arXiv preprint arXiv:2205.05212},
  year={2022}
}

@article{kim2022automating,
  title={Automating Reinforcement Learning with Example-based Resets},
  author={Kim, Jigang and hyeon Park, J and Cho, Daesol and Kim, H Jin},
  journal={IEEE Robotics and Automation Letters},
  year={2022},
  publisher={IEEE}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{knox2009interactively,
  title={Interactively shaping agents via human reinforcement: The TAMER framework},
  author={Knox, W Bradley and Stone, Peter},
  booktitle={Proceedings of the fifth international conference on Knowledge capture},
  pages={9--16},
  year={2009}
}

@inproceedings{macglashan2017interactive,
  title={Interactive learning from policy-dependent human feedback},
  author={MacGlashan, James and Ho, Mark K and Loftin, Robert and Peng, Bei and Wang, Guan and Roberts, David L and Taylor, Matthew E and Littman, Michael L},
  booktitle={International Conference on Machine Learning},
  pages={2285--2294},
  year={2017},
  organization={PMLR}
}

@inproceedings{akrour2011preference,
  title={Preference-based policy learning},
  author={Akrour, Riad and Schoenauer, Marc and Sebag, Michele},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={12--27},
  year={2011},
  organization={Springer}
}

@inproceedings{sugiyama2012preference,
  title={Preference-learning based inverse reinforcement learning for dialog control},
  author={Sugiyama, Hiroaki and Meguro, Toyomi and Minami, Yasuhiro},
  booktitle={Thirteenth Annual Conference of the International Speech Communication Association},
  year={2012}
}

@inproceedings{wirth2013preference,
  title={Preference-based reinforcement learning: A preliminary survey},
  author={Wirth, Christian and F{\"u}rnkranz, Johannes},
  booktitle={Proceedings of the ECML/PKDD-13 Workshop on Reinforcement Learning from Generalized Feedback: Beyond Numeric Rewards},
  year={2013},
  organization={Citeseer}
}

@book{sadigh2017active,
  title={Active preference-based learning of reward functions},
  author={Sadigh, Dorsa and Dragan, Anca D and Sastry, Shankar and Seshia, Sanjit A},
  year={2017}
}

@inproceedings{biyik2018batch,
  title={Batch active preference-based learning of reward functions},
  author={Biyik, Erdem and Sadigh, Dorsa},
  booktitle={Conference on robot learning},
  pages={519--528},
  year={2018},
  organization={PMLR}
}

@article{lee2021pebble,
  title={Pebble: Feedback-efficient interactive reinforcement learning via relabeling experience and unsupervised pre-training},
  author={Lee, Kimin and Smith, Laura and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2106.05091},
  year={2021}
}

@inproceedings{arzate2020survey,
  title={A survey on interactive reinforcement learning: design principles and open challenges},
  author={Arzate Cruz, Christian and Igarashi, Takeo},
  booktitle={Proceedings of the 2020 ACM designing interactive systems conference},
  pages={1195--1209},
  year={2020}
}

@article{wang2018interactive,
  title={Interactive Reinforcement Learning with Dynamic Reuse of Prior Knowledge from Human/Agent's Demonstration},
  author={Wang, Zhaodong and Taylor, Matthew E},
  journal={arXiv preprint arXiv:1805.04493},
  year={2018}
}

@inproceedings{faulkner2020interactive,
  title={Interactive reinforcement learning with inaccurate feedback},
  author={Faulkner, Taylor A Kessler and Short, Elaine Schaertl and Thomaz, Andrea L},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7498--7504},
  year={2020},
  organization={IEEE}
}

@inproceedings{wang2022skill,
  title={Skill preferences: Learning to extract and execute robotic skills from human feedback},
  author={Wang, Xiaofei and Lee, Kimin and Hakhamaneshi, Kourosh and Abbeel, Pieter and Laskin, Michael},
  booktitle={Conference on Robot Learning},
  pages={1259--1268},
  year={2022},
  organization={PMLR}
}

@article{hoque2021thriftydagger,
  title={ThriftyDAgger: Budget-aware novelty and risk gating for interactive imitation learning},
  author={Hoque, Ryan and Balakrishna, Ashwin and Novoseller, Ellen and Wilcox, Albert and Brown, Daniel S and Goldberg, Ken},
  journal={arXiv preprint arXiv:2109.08273},
  year={2021}
}

@inproceedings{menda2019ensembledagger,
  title={Ensembledagger: A bayesian approach to safe imitation learning},
  author={Menda, Kunal and Driggs-Campbell, Katherine and Kochenderfer, Mykel J},
  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5041--5048},
  year={2019},
  organization={IEEE}
}

@article{zhang2016query,
  title={Query-efficient imitation learning for end-to-end autonomous driving},
  author={Zhang, Jiakai and Cho, Kyunghyun},
  journal={arXiv preprint arXiv:1605.06450},
  year={2016}
}

@inproceedings{hoque2021lazydagger,
  title={Lazydagger: Reducing context switching in interactive imitation learning},
  author={Hoque, Ryan and Balakrishna, Ashwin and Putterman, Carl and Luo, Michael and Brown, Daniel S and Seita, Daniel and Thananjeyan, Brijen and Novoseller, Ellen and Goldberg, Ken},
  booktitle={2021 IEEE 17th International Conference on Automation Science and Engineering (CASE)},
  pages={502--509},
  year={2021},
  organization={IEEE}
}

@article{yarats2021drqv2,
  title={Mastering Visual Continuous Control: Improved Data-Augmented Reinforcement Learning},
  author={Denis Yarats and Rob Fergus and Alessandro Lazaric and Lerrel Pinto},
  journal={arXiv preprint arXiv:2107.09645},
  year={2021}
}

@inproceedings{yarats2021image,
  title={Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels},
  author={Denis Yarats and Ilya Kostrikov and Rob Fergus},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=GY6-6sTvGaf}
}
