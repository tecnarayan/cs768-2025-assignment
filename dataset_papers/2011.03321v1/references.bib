@article{erdos2019matrix,
  title={The matrix Dyson equation and its applications for random matrices},
  author={Erdos, Laszlo},
  journal={arXiv preprint arXiv:1903.10060},
  year={2019}
}

@article{shazeer2017outrageously,
  title={Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},
  author={Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  journal={arXiv preprint arXiv:1701.06538},
  year={2017}
}

@article{adiwardana2020towards,
  title={Towards a Human-like Open-Domain Chatbot},
  author={Adiwardana, Daniel and Luong, Minh-Thang and So, David R and Hall, Jamie and Fiedel, Noah and Thoppilan, Romal and Yang, Zi and Kulshreshtha, Apoorv and Nemade, Gaurav and Lu, Yifeng and others},
  journal={arXiv preprint arXiv:2001.09977},
  year={2020}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI Blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{vapnik1999overview,
  title={An overview of statistical learning theory},
  author={Vapnik, Vladimir N},
  journal={IEEE transactions on neural networks},
  volume={10},
  number={5},
  pages={988--999},
  year={1999},
  publisher={IEEE}
}

@article{geman1992neural,
  title={Neural networks and the bias/variance dilemma},
  author={Geman, Stuart and Bienenstock, Elie and Doursat, Ren{\'e}},
  journal={Neural computation},
  volume={4},
  number={1},
  pages={1--58},
  year={1992},
  publisher={MIT Press}
}

@article{neal2018modern,
  title={A modern take on the bias-variance tradeoff in neural networks},
  author={Neal, Brady and Mittal, Sarthak and Baratin, Aristide and Tantia, Vinayak and Scicluna, Matthew and Lacoste-Julien, Simon and Mitliagkas, Ioannis},
  journal={arXiv preprint arXiv:1810.08591},
  year={2018}
}

@inproceedings{nagarajan2019uniform,
  title={Uniform convergence may be unable to explain generalization in deep learning},
  author={Nagarajan, Vaishnavh and Kolter, J Zico},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11611--11622},
  year={2019}
}

@inproceedings{neyshabur2017exploring,
  title={Exploring generalization in deep learning},
  author={Neyshabur, Behnam and Bhojanapalli, Srinadh and McAllester, David and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5947--5956},
  year={2017}
}

@article{li2019enhanced,
  title={Enhanced Convolutional Neural Tangent Kernels},
  author={Li, Zhiyuan and Wang, Ruosong and Yu, Dingli and Du, Simon S and Hu, Wei and Salakhutdinov, Ruslan and Arora, Sanjeev},
  journal={arXiv preprint arXiv:1911.00809},
  year={2019}
}

@book{mingo2017free,
  title={Free probability and random matrices},
  author={Mingo, James A and Speicher, Roland},
  volume={35},
  publisher={Springer},
  year={2017}
}

@article{ghorbani2019linearized,
  title={Linearized two-layers neural networks in high dimension},
  author={Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
  journal={arXiv preprint arXiv:1904.12191},
  year={2019}
}

@article{banna2015limiting,
  title={On the limiting spectral distribution for a large class of symmetric random matrices with correlated entries},
  author={Banna, Marwa and Merlev{\`e}de, Florence and Peligrad, Magda},
  journal={Stochastic Processes and their Applications},
  volume={125},
  number={7},
  pages={2700--2726},
  year={2015},
  publisher={Elsevier}
}

@article{helton2018applications,
  title={Applications of realizations (aka linearizations) to free probability},
  author={Helton, J William and Mai, Tobias and Speicher, Roland},
  journal={Journal of Functional Analysis},
  volume={274},
  number={1},
  pages={1--79},
  year={2018},
  publisher={Elsevier}
}

@article{far2006spectra,
  title={Spectra of large block matrices},
  author={Far, Reza Rashidi and Oraby, Tamer and Bryc, Wlodzimierz and Speicher, Roland},
  journal={arXiv preprint cs/0610045},
  year={2006}
}

@inproceedings{pennington2018spectrum,
  title={The spectrum of the fisher information matrix of a single-hidden-layer neural network},
  author={Pennington, Jeffrey and Worah, Pratik},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5410--5419},
  year={2018}
}

@article{louart2018random,
  title={A random matrix approach to neural networks},
  author={Louart, Cosme and Liao, Zhenyu and Couillet, Romain and others},
  journal={The Annals of Applied Probability},
  volume={28},
  number={2},
  pages={1190--1248},
  year={2018},
  publisher={Institute of Mathematical Statistics}
}

@article{peche2019note,
  title={A note on the Pennington-Worah distribution},
  author={P{\'e}ch{\'e}, S and others},
  journal={Electronic Communications in Probability},
  volume={24},
  year={2019},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@article{adlam2019random,
  title={A Random Matrix Perspective on Mixtures of Nonlinearities for Deep Learning},
  author={Adlam, Ben and Levinson, Jake and Pennington, Jeffrey},
  journal={arXiv preprint arXiv:1912.00827},
  year={2019}
}

@inproceedings{pennington2017nonlinear,
  title={Nonlinear random matrix theory for deep learning},
  author={Pennington, Jeffrey and Worah, Pratik},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2637--2646},
  year={2017}
}

@article{xiao2019disentangling,
  title={Disentangling trainability and generalization in deep learning},
  author={Xiao, Lechao and Pennington, Jeffrey and Schoenholz, Samuel S},
  journal={arXiv preprint arXiv:1912.13053},
  year={2019}
}

@inproceedings{arora2019exact,
  title={On exact computation with an infinitely wide neural net},
  author={Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8139--8148},
  year={2019}
}

@article{du2018gradient,
  title={Gradient descent finds global minima of deep neural networks},
  author={Du, Simon S and Lee, Jason D and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
  journal={arXiv preprint arXiv:1811.03804},
  year={2018}
}

@article{du2018provably,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  journal={arXiv preprint arXiv:1810.02054},
  year={2018}
}

@inproceedings{chizat2019lazy,
  title={On lazy training in differentiable programming},
  author={Chizat, Lenaic and Oyallon, Edouard and Bach, Francis},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2933--2943},
  year={2019}
}

@incollection{neal1996priors,
  title={Priors for infinite networks},
  author={Neal, Radford M},
  booktitle={Bayesian Learning for Neural Networks},
  pages={29--53},
  year={1996},
  publisher={Springer}
}

@inproceedings{lee2019wide,
  title={Wide neural networks of any depth evolve as linear models under gradient descent},
  author={Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
  booktitle={Advances in neural information processing systems},
  pages={8570--8581},
  year={2019}
}

@article{matthews2018gaussian,
  title={Gaussian process behaviour in wide deep neural networks},
  author={Matthews, Alexander G de G and Rowland, Mark and Hron, Jiri and Turner, Richard E and Ghahramani, Zoubin},
  journal={arXiv preprint arXiv:1804.11271},
  year={2018}
}

@article{lee2017deep,
  title={Deep neural networks as gaussian processes},
  author={Lee, Jaehoon and Bahri, Yasaman and Novak, Roman and Schoenholz, Samuel S and Pennington, Jeffrey and Sohl-Dickstein, Jascha},
  journal={arXiv preprint arXiv:1711.00165},
  year={2017}
}

@article{mitra2019understanding,
  title={Understanding overfitting peaks in generalization error: Analytical risk curves for $ l\_2 $ and $ l\_1 $ penalized interpolation},
  author={Mitra, Partha P},
  journal={arXiv preprint arXiv:1906.03667},
  year={2019}
}

@article{hastie2019surprises,
  title={Surprises in high-dimensional ridgeless least squares interpolation},
  author={Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:1903.08560},
  year={2019}
}

@article{belkin2019two,
  title={Two models of double descent for weak features},
  author={Belkin, Mikhail and Hsu, Daniel and Xu, Ji},
  journal={arXiv preprint arXiv:1903.07571},
  year={2019}
}

@article{nakkiran2019deep,
  title={Deep double descent: Where bigger models and more data hurt},
  author={Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1912.02292},
  year={2019}
}

@article{geiger2019scaling,
  title={Scaling description of generalization with number of parameters in deep learning},
  author={Geiger, Mario and Jacot, Arthur and Spigler, Stefano and Gabriel, Franck and Sagun, Levent and d'Ascoli, St{\'e}phane and Biroli, Giulio and Hongler, Cl{\'e}ment and Wyart, Matthieu},
  journal={arXiv preprint arXiv:1901.01608},
  year={2019}
}

@article{advani2017high,
  title={High-dimensional dynamics of generalization error in neural networks},
  author={Advani, Madhu S and Saxe, Andrew M},
  journal={arXiv preprint arXiv:1710.03667},
  year={2017}
}

@inproceedings{belkin2018overfitting,
  title={Overfitting or perfect fitting? risk bounds for classification and regression rules that interpolate},
  author={Belkin, Mikhail and Hsu, Daniel J and Mitra, Partha},
  booktitle={Advances in neural information processing systems},
  pages={2300--2311},
  year={2018}
}

@article{liang2018just,
  title={Just interpolate: Kernel "ridgeless" regression can generalize},
  author={Liang, Tengyuan and Rakhlin, Alexander},
  journal={arXiv preprint arXiv:1808.00387},
  year={2018}
}

@article{belkin2018does,
  title={Does data interpolation contradict statistical optimality?},
  author={Belkin, Mikhail and Rakhlin, Alexander and Tsybakov, Alexandre B},
  journal={arXiv preprint arXiv:1806.09471},
  year={2018}
}

@article{belkin2018understand,
  title={To understand deep learning we need to understand kernel learning},
  author={Belkin, Mikhail and Ma, Siyuan and Mandal, Soumik},
  journal={arXiv preprint arXiv:1802.01396},
  year={2018}
}

@article{mei2019generalization,
  title={The generalization error of random features regression: Precise asymptotics and double descent curve},
  author={Mei, Song and Montanari, Andrea},
  journal={arXiv preprint arXiv:1908.05355},
  year={2019}
}

@inproceedings{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle={Advances in neural information processing systems},
  pages={8571--8580},
  year={2018}
}

@article{belkin2019reconciling,
  title={Reconciling modern machine-learning practice and the classical bias--variance trade-off},
  author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={32},
  pages={15849--15854},
  year={2019},
  publisher={National Acad Sciences}
}

@article{jacot2020implicit,
  title={Implicit regularization of random feature models},
  author={Jacot, Arthur and {\c{S}}im{\c{s}}ek, Berfin and Spadaro, Francesco and Hongler, Cl{\'e}ment and Gabriel, Franck},
  journal={arXiv preprint arXiv:2002.08404},
  year={2020}
}

@article{yang2020rethinking,
  title={Rethinking bias-variance trade-off for generalization of neural networks},
  author={Yang, Zitong and Yu, Yaodong and You, Chong and Steinhardt, Jacob and Ma, Yi},
  journal={arXiv preprint arXiv:2002.11328},
  year={2020}
}

@article{zhang2016understanding,
  title={Understanding deep learning requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1611.03530},
  year={2016}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}


@inproceedings{rahimi2008random,
  title={Random features for large-scale kernel machines},
  author={Rahimi, Ali and Recht, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={1177--1184},
  year={2008}
}
@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@inproceedings{adlamneural,
  title={The Neural Tangent Kernel in High Dimensions: Triple Descent and a Multi-Scale Theory of Generalization},
  author={Adlam, Ben and Pennington, Jeffrey},
  booktitle     = {Proceedings of the 37th International Conference on Machine Learning (ICML 2020)},
  year      = {2020}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@article{d2020double,
  title={Double trouble in double descent: Bias and variance (s) in the lazy regime},
  author={d'Ascoli, St{\'e}phane and Refinetti, Maria and Biroli, Giulio and Krzakala, Florent},
  journal={arXiv preprint arXiv:2003.01054},
  year={2020}
}


@article{kobak2018optimal,
  title={Optimal ridge penalty for real-world high-dimensional data can be zero or negative due to the implicit ridge regularization},
  author={Kobak, Dmitry and Lomond, Jonathan and Sanchez, Benoit},
  journal={arXiv preprint arXiv:1805.10939},
  year={2018}
}

@article{stone1994use,
  title={The use of polynomial splines and their tensor products in multivariate function estimation},
  author={Stone, Charles J},
  journal={The Annals of Statistics},
  pages={118--171},
  year={1994},
  publisher={JSTOR}
}

@article{huang1998projection,
  title={Projection estimation in multiple regression with application to functional ANOVA models},
  author={Huang, Jianhua Z and others},
  journal={The annals of statistics},
  volume={26},
  number={1},
  pages={242--272},
  year={1998},
  publisher={Institute of Mathematical Statistics}
}

@article{owen2003dimension,
  title={The dimension distribution and quadrature test functions},
  author={Owen, Art B},
  journal={Statistica Sinica},
  pages={1--17},
  year={2003},
  publisher={JSTOR}
}

@article{efron1981jackknife,
  title={The jackknife estimate of variance},
  author={Efron, Bradley and Stein, Charles},
  journal={The Annals of Statistics},
  pages={586--596},
  year={1981},
  publisher={JSTOR}
}