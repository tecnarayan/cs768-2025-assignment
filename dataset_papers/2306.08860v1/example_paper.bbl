\begin{thebibliography}{40}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Balaji et~al.(2022)Balaji, Nah, Huang, Vahdat, Song, Kreis, Aittala,
  Aila, Laine, Catanzaro, et~al.]{ediffi}
Balaji, Y., Nah, S., Huang, X., Vahdat, A., Song, J., Kreis, K., Aittala, M.,
  Aila, T., Laine, S., Catanzaro, B., et~al.
\newblock ediffi: Text-to-image diffusion models with an ensemble of expert
  denoisers.
\newblock \emph{arXiv preprint arXiv:2211.01324}, 2022.

\bibitem[Bao et~al.(2022)Bao, Li, Zhu, and Zhang]{analytic-dpm}
Bao, F., Li, C., Zhu, J., and Zhang, B.
\newblock Analytic-dpm: an analytic estimate of the optimal reverse variance in
  diffusion probabilistic models.
\newblock \emph{arXiv preprint arXiv:2201.06503}, 2022.

\bibitem[Chen et~al.(2020)Chen, Zhang, Zen, Weiss, Norouzi, and Chan]{wavegrad}
Chen, N., Zhang, Y., Zen, H., Weiss, R.~J., Norouzi, M., and Chan, W.
\newblock Wavegrad: Estimating gradients for waveform generation.
\newblock \emph{arXiv preprint arXiv:2009.00713}, 2020.

\bibitem[Choi et~al.(2022)Choi, Lee, Shin, Kim, Kim, and Yoon]{perception}
Choi, J., Lee, J., Shin, C., Kim, S., Kim, H., and Yoon, S.
\newblock Perception prioritized training of diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  11472--11481, 2022.

\bibitem[Dhariwal \& Nichol(2021)Dhariwal and Nichol]{diffusion_beat_gan}
Dhariwal, P. and Nichol, A.
\newblock Diffusion models beat gans on image synthesis.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 8780--8794, 2021.

\bibitem[Elsken et~al.(2019)Elsken, Metzen, and Hutter]{nas-survey}
Elsken, T., Metzen, J.~H., and Hutter, F.
\newblock Neural architecture search: A survey.
\newblock \emph{The Journal of Machine Learning Research}, 20\penalty0
  (1):\penalty0 1997--2017, 2019.

\bibitem[Goodfellow et~al.(2020)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{gan}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial networks.
\newblock \emph{Communications of the ACM}, 63\penalty0 (11):\penalty0
  139--144, 2020.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ddpm}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 6840--6851, 2020.

\bibitem[Ho et~al.(2022)Ho, Salimans, Gritsenko, Chan, Norouzi, and
  Fleet]{videodiff}
Ho, J., Salimans, T., Gritsenko, A., Chan, W., Norouzi, M., and Fleet, D.~J.
\newblock Video diffusion models.
\newblock \emph{arXiv preprint arXiv:2204.03458}, 2022.

\bibitem[Jaderberg et~al.(2017)Jaderberg, Dalibard, Osindero, Czarnecki,
  Donahue, Razavi, Vinyals, Green, Dunning, Simonyan, et~al.]{pbt}
Jaderberg, M., Dalibard, V., Osindero, S., Czarnecki, W.~M., Donahue, J.,
  Razavi, A., Vinyals, O., Green, T., Dunning, I., Simonyan, K., et~al.
\newblock Population based training of neural networks.
\newblock \emph{arXiv preprint arXiv:1711.09846}, 2017.

\bibitem[Jing et~al.(2022)Jing, Corso, Berlinghieri, and Jaakkola]{subspace}
Jing, B., Corso, G., Berlinghieri, R., and Jaakkola, T.
\newblock Subspace diffusion generative models.
\newblock \emph{arXiv preprint arXiv:2205.01490}, 2022.

\bibitem[Kim et~al.(2021)Kim, Shin, Song, Kang, and Moon]{soft}
Kim, D., Shin, S., Song, K., Kang, W., and Moon, I.-C.
\newblock Soft truncation: A universal training technique of score-based
  diffusion model for high precision score estimation.
\newblock \emph{arXiv preprint arXiv:2106.05527}, 2021.

\bibitem[Kingma \& Gao(2023)Kingma and Gao]{ELBOweights}
Kingma, D.~P. and Gao, R.
\newblock Understanding the diffusion objective as a weighted integral of
  elbos.
\newblock \emph{arXiv preprint arXiv:2303.00848}, 2023.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{vae}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kong et~al.(2020)Kong, Ping, Huang, Zhao, and Catanzaro]{diffwave}
Kong, Z., Ping, W., Huang, J., Zhao, K., and Catanzaro, B.
\newblock Diffwave: A versatile diffusion model for audio synthesis.
\newblock \emph{arXiv preprint arXiv:2009.09761}, 2020.

\bibitem[Li et~al.(2022)Li, Yang, Chang, Chen, Feng, Xu, Li, and Chen]{srdiff}
Li, H., Yang, Y., Chang, M., Chen, S., Feng, H., Xu, Z., Li, Q., and Chen, Y.
\newblock Srdiff: Single image super-resolution with diffusion probabilistic
  models.
\newblock \emph{Neurocomputing}, 479:\penalty0 47--59, 2022.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{mscoco}
Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D.,
  Doll{\'a}r, P., and Zitnick, C.~L.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{European conference on computer vision}, pp.\  740--755.
  Springer, 2014.

\bibitem[Liu et~al.(2022)Liu, Ren, Lin, and Zhao]{pndm}
Liu, L., Ren, Y., Lin, Z., and Zhao, Z.
\newblock Pseudo numerical methods for diffusion models on manifolds.
\newblock \emph{arXiv preprint arXiv:2202.09778}, 2022.

\bibitem[Lu et~al.(2022)Lu, Zhou, Bao, Chen, Li, and Zhu]{dpm-solver}
Lu, C., Zhou, Y., Bao, F., Chen, J., Li, C., and Zhu, J.
\newblock Dpm-solver: A fast ode solver for diffusion probabilistic model
  sampling in around 10 steps.
\newblock \emph{arXiv preprint arXiv:2206.00927}, 2022.

\bibitem[Luo et~al.(2018)Luo, Tian, Qin, Chen, and Liu]{nao}
Luo, R., Tian, F., Qin, T., Chen, E., and Liu, T.-Y.
\newblock Neural architecture optimization.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Luo \& Hu(2021)Luo and Hu]{diffusion3d}
Luo, S. and Hu, W.
\newblock Diffusion probabilistic models for 3d point cloud generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  2837--2845, 2021.

\bibitem[Nichol \& Dhariwal(2021)Nichol and Dhariwal]{iddpm}
Nichol, A.~Q. and Dhariwal, P.
\newblock Improved denoising diffusion probabilistic models.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  8162--8171. PMLR, 2021.

\bibitem[Ning et~al.(2020)Ning, Zheng, Zhao, Wang, and Yang]{gates}
Ning, X., Zheng, Y., Zhao, T., Wang, Y., and Yang, H.
\newblock A generic graph-based neural architecture encoding scheme for
  predictor-based nas.
\newblock In \emph{European Conference on Computer Vision}, pp.\  189--204.
  Springer, 2020.

\bibitem[Real et~al.(2019)Real, Aggarwal, Huang, and Le]{evonas}
Real, E., Aggarwal, A., Huang, Y., and Le, Q.~V.
\newblock Regularized evolution for image classifier architecture search.
\newblock In \emph{Proceedings of the aaai conference on artificial
  intelligence}, volume~33, pp.\  4780--4789, 2019.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{ldm}
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10684--10695, 2022.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and Brox]{unet}
Ronneberger, O., Fischer, P., and Brox, T.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{International Conference on Medical image computing and
  computer-assisted intervention}, pp.\  234--241. Springer, 2015.

\bibitem[Saharia et~al.(2022)Saharia, Ho, Chan, Salimans, Fleet, and
  Norouzi]{imagesr}
Saharia, C., Ho, J., Chan, W., Salimans, T., Fleet, D.~J., and Norouzi, M.
\newblock Image super-resolution via iterative refinement.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2022.

\bibitem[Sen(1968)]{kd}
Sen, P.~K.
\newblock Estimates of the regression coefficient based on kendall's tau.
\newblock \emph{Journal of the American statistical association}, 63\penalty0
  (324):\penalty0 1379--1389, 1968.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{2015diffusion}
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2256--2265. PMLR, 2015.

\bibitem[Song et~al.(2020{\natexlab{a}})Song, Meng, and Ermon]{ddim}
Song, J., Meng, C., and Ermon, S.
\newblock Denoising diffusion implicit models.
\newblock \emph{arXiv preprint arXiv:2010.02502}, 2020{\natexlab{a}}.

\bibitem[Song \& Ermon(2019)Song and Ermon]{smld}
Song, Y. and Ermon, S.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Song et~al.(2020{\natexlab{b}})Song, Sohl-Dickstein, Kingma, Kumar,
  Ermon, and Poole]{sde}
Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole,
  B.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock \emph{arXiv preprint arXiv:2011.13456}, 2020{\natexlab{b}}.

\bibitem[Song et~al.(2021)Song, Durkan, Murray, and Ermon]{song2021maximum}
Song, Y., Durkan, C., Murray, I., and Ermon, S.
\newblock Maximum likelihood training of score-based diffusion models.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 1415--1428, 2021.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{transformer}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Watson et~al.(2021)Watson, Ho, Norouzi, and Chan]{dp}
Watson, D., Ho, J., Norouzi, M., and Chan, W.
\newblock Learning to efficiently sample from diffusion probabilistic models.
\newblock \emph{arXiv preprint arXiv:2106.03802}, 2021.

\bibitem[Watson et~al.(2022)Watson, Chan, Ho, and Norouzi]{ggdm}
Watson, D., Chan, W., Ho, J., and Norouzi, M.
\newblock Learning fast samplers for diffusion models by differentiating
  through sample quality.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Yang et~al.(2019)Yang, Akimoto, Kim, and Udell]{oboe}
Yang, C., Akimoto, Y., Kim, D.~W., and Udell, M.
\newblock Oboe: Collaborative filtering for automl model selection.
\newblock In \emph{Proceedings of the 25th ACM SIGKDD international conference
  on knowledge discovery \& data mining}, pp.\  1173--1183, 2019.

\bibitem[Yang et~al.(2022)Yang, Zhou, Feng, and Wang]{slim}
Yang, X., Zhou, D., Feng, J., and Wang, X.
\newblock Diffusion probabilistic model made slim.
\newblock \emph{arXiv preprint arXiv:2211.17106}, 2022.

\bibitem[Zhang \& Chen(2022)Zhang and Chen]{deis}
Zhang, Q. and Chen, Y.
\newblock Fast sampling of diffusion models with exponential integrator.
\newblock \emph{arXiv preprint arXiv:2204.13902}, 2022.

\bibitem[Zoph \& Le(2016)Zoph and Le]{rlnas}
Zoph, B. and Le, Q.~V.
\newblock Neural architecture search with reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.01578}, 2016.

\end{thebibliography}
