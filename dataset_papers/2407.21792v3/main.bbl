\begin{thebibliography}{144}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Tamkin et~al.(2023)Tamkin, Askell, Lovitt, Durmus, Joseph, Kravec, Nguyen, Kaplan, and Ganguli]{anthropic_discrim_eval}
Alex Tamkin, Amanda Askell, Liane Lovitt, Esin Durmus, Nicholas Joseph, Shauna Kravec, Karina Nguyen, Jared Kaplan, and Deep Ganguli.
\newblock Evaluating and mitigating discrimination in language model decisions.
\newblock \emph{arXiv preprint arXiv:2312.03689}, 2023.

\bibitem[Perez et~al.(2023)Perez, Ringer, Lukošiūtė, Nguyen, Chen, Heiner, Pettit, Olsson, Kundu, Kadavath, et~al.]{sycophancy}
Ethan Perez, Sam Ringer, Kamilė Lukošiūtė, Karina Nguyen, Edwin Chen, Scott Heiner, Craig Pettit, Catherine Olsson, Sandipan Kundu, Saurav Kadavath, et~al.
\newblock Discovering language model behaviors with model-written evaluations.
\newblock In \emph{ACL}, 2023.

\bibitem[Lin et~al.(2022)Lin, Hilton, and Evans]{truthfulqa}
Stephanie Lin, Jacob Hilton, and Owain Evans.
\newblock Truthfulqa: Measuring how models mimic human falsehoods.
\newblock In \emph{ACL}, 2022.

\bibitem[Li et~al.(2024{\natexlab{a}})Li, Pan, Gopal, Yue, Berrios, Gatti, Li, Dombrowski, Goel, Phan, et~al.]{wmdp}
Nathaniel Li, Alexander Pan, Anjali Gopal, Summer Yue, Daniel Berrios, Alice Gatti, Justin~D. Li, Ann-Kathrin Dombrowski, Shashwat Goel, Long Phan, et~al.
\newblock The wmdp benchmark: Measuring and reducing malicious use with unlearning.
\newblock \emph{arXiv preprint arXiv:2403.03218}, 2024{\natexlab{a}}.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin, Zhang, Agarwal, Slama, Ray, et~al.]{ouyang2022training}
Long Ouyang, Jeff Wu, Xu~Jiang, Diogo Almeida, Carroll~L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{arXiv preprint arXiv:2203.02155}, 2022.

\bibitem[Hendrycks et~al.(2021{\natexlab{a}})Hendrycks, Zhao, Basart, Steinhardt, and Song]{hendrycks2021natural}
Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song.
\newblock Natural adversarial examples.
\newblock In \emph{CVPR}, 2021{\natexlab{a}}.

\bibitem[Kaplan et~al.(2020{\natexlab{a}})Kaplan, McCandlish, Henighan, Brown, Chess, Child, Gray, Radford, Wu, and Amodei]{kaplan2020scaling}
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom~B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.
\newblock Scaling laws for neural language models.
\newblock \emph{arXiv preprint arXiv:2001.08361}, 2020{\natexlab{a}}.

\bibitem[McKenzie et~al.(2023)McKenzie, Lyzhov, Pieler, Parrish, Mueller, Prabhu, McLean, Kirtland, Ross, Liu, et~al.]{mckenzie2023inverse}
Ian~R McKenzie, Alexander Lyzhov, Michael Pieler, Alicia Parrish, Aaron Mueller, Ameya Prabhu, Euan McLean, Aaron Kirtland, Alexis Ross, Alisa Liu, et~al.
\newblock Inverse scaling: When bigger isn't better.
\newblock \emph{arXiv preprint arXiv:2306.09479}, 2023.

\bibitem[Gao et~al.(2023)Gao, Tow, Abbasi, Biderman, Black, DiPofi, Foster, Golding, Hsu, Le~Noac'h, Li, McDonell, Muennighoff, Ociepa, Phang, Reynolds, Schoelkopf, Skowron, Sutawika, Tang, Thite, Wang, Wang, and Zou]{eval-harness}
Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le~Noac'h, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, and Andy Zou.
\newblock A framework for few-shot language model evaluation.
\newblock \emph{doi:10.5281/zenodo.10256836}, 2023.

\bibitem[Liang et~al.(2023)Liang, Bommasani, Lee, Tsipras, Soylu, Yasunaga, Zhang, Narayanan, Wu, Kumar, et~al.]{liang2023holisticevaluationlanguagemodels}
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu, Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar, et~al.
\newblock Holistic evaluation of language models.
\newblock \emph{arXiv preprint arXiv:2211.09110}, 2023.

\bibitem[Hestness et~al.(2017{\natexlab{a}})Hestness, Narang, Ardalani, Diamos, Jun, Kianinejad, Patwary, Yang, and Zhou]{hestness2017deeplearningscalingpredictable}
Joel Hestness, Sharan Narang, Newsha Ardalani, Gregory Diamos, Heewoo Jun, Hassan Kianinejad, Md. Mostofa~Ali Patwary, Yang Yang, and Yanqi Zhou.
\newblock Deep learning scaling is predictable, empirically.
\newblock \emph{arXiv preprint arXiv:1712.00409}, 2017{\natexlab{a}}.

\bibitem[Kaplan et~al.(2020{\natexlab{b}})Kaplan, McCandlish, Henighan, Brown, Chess, Child, Gray, Radford, Wu, and Amodei]{kaplan2020scalinglawsneurallanguage}
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom~B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.
\newblock Scaling laws for neural language models.
\newblock \emph{arXiv preprint arXiv:2001.08361}, 2020{\natexlab{b}}.

\bibitem[Wei et~al.(2022{\natexlab{a}})Wei, Kim, Tay, and Le]{wei2022inverse}
Jason Wei, Najoung Kim, Yi~Tay, and Quoc~V Le.
\newblock Inverse scaling can become u-shaped.
\newblock \emph{arXiv preprint arXiv:2211.02011}, 2022{\natexlab{a}}.

\bibitem[Hestness et~al.(2017{\natexlab{b}})Hestness, Narang, Ardalani, Diamos, Jun, Kianinejad, Patwary, Yang, and Zhou]{hestness2017deep}
Joel Hestness, Sharan Narang, Newsha Ardalani, Gregory Diamos, Heewoo Jun, Hassan Kianinejad, Md~Mostofa~Ali Patwary, Yang Yang, and Yanqi Zhou.
\newblock Deep learning scaling is predictable, empirically.
\newblock \emph{arXiv preprint arXiv:1712.00409}, 2017{\natexlab{b}}.

\bibitem[Muennighoff et~al.(2024)Muennighoff, Rush, Barak, Le~Scao, Tazi, Piktus, Pyysalo, Wolf, and Raffel]{muennighoff2024scaling}
Niklas Muennighoff, Alexander Rush, Boaz Barak, Teven Le~Scao, Nouamane Tazi, Aleksandra Piktus, Sampo Pyysalo, Thomas Wolf, and Colin~A Raffel.
\newblock Scaling data-constrained language models.
\newblock \emph{NeurIPS}, 2024.

\bibitem[Hoffmann et~al.(2024)Hoffmann, Borgeaud, Mensch, Buchatskaya, Cai, Rutherford, de~Las~Casas, Hendricks, Welbl, Clark, et~al.]{hoffmann2024chincilla}
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de~Las~Casas, Lisa~Anne Hendricks, Johannes Welbl, Aidan Clark, et~al.
\newblock Training compute-optimal large language models.
\newblock In \emph{NeurIPS}, 2024.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, 2016.

\bibitem[Zhai et~al.(2022)Zhai, Kolesnikov, Houlsby, and Beyer]{zhai2022scaling}
Xiaohua Zhai, Alexander Kolesnikov, Neil Houlsby, and Lucas Beyer.
\newblock Scaling vision transformers.
\newblock In \emph{CVPR}, 2022.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Dollár, and Girshick]{he2022masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, and Ross Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{CVPR}, 2022.

\bibitem[Peebles and Xie(2023)]{peebles2023scalable}
William Peebles and Saining Xie.
\newblock Scalable diffusion models with transformers.
\newblock In \emph{ICCV}, 2023.

\bibitem[McKenzie et~al.(2022)McKenzie, Lyzhov, Parrish, Prabhu, Mueller, Kim, Bowman, and Perez]{mckenzie2022inverse}
Ian McKenzie, Alexander Lyzhov, Alicia Parrish, Ameya Prabhu, Aaron Mueller, Najoung Kim, Sam Bowman, and Ethan Perez.
\newblock The inverse scaling prize, 2022.

\bibitem[Ilić(2023)]{ilić2023unveilinggeneralintelligencefactor}
David Ilić.
\newblock Unveiling the general intelligence factor in language models: A psychometric approach.
\newblock \emph{arXiv preprint arXiv:2310.11616}, 2023.

\bibitem[Schaeffer et~al.(2024)Schaeffer, Schoelkopf, Miranda, Mukobi, Madan, Ibrahim, Bradley, Biderman, and Koyejo]{schaeffer2024predictingdownstreamcapabilitiesfrontier}
Rylan Schaeffer, Hailey Schoelkopf, Brando Miranda, Gabriel Mukobi, Varun Madan, Adam Ibrahim, Herbie Bradley, Stella Biderman, and Sanmi Koyejo.
\newblock Why has predicting downstream capabilities of frontier ai models with scale remained elusive?
\newblock \emph{arXiv preprint arXiv:2406.04391}, 2024.

\bibitem[Schaeffer et~al.(2023)Schaeffer, Miranda, and Koyejo]{schaeffer2023emergentabilitieslargelanguage}
Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo.
\newblock Are emergent abilities of large language models a mirage?
\newblock \emph{arXiv preprint arXiv:2304.15004}, 2023.

\bibitem[Villalobos(2023)]{villalobos2023scaling}
Pablo Villalobos.
\newblock Scaling laws literature review.
\newblock \emph{Epoch AI}, 2023.

\bibitem[Wei et~al.(2022{\natexlab{b}})Wei, Tay, Bommasani, Raffel, Zoph, Borgeaud, Yogatama, Bosma, Zhou, Metzler, et~al.]{wei2022emergent}
Jason Wei, Yi~Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et~al.
\newblock Emergent abilities of large language models.
\newblock \emph{arXiv preprint arXiv:2206.07682}, 2022{\natexlab{b}}.

\bibitem[Xia et~al.(2022)Xia, Artetxe, Zhou, Lin, Pasunuru, Chen, Zettlemoyer, and Stoyanov]{xia2022training}
Mengzhou Xia, Mikel Artetxe, Chunting Zhou, Xi~Victoria Lin, Ramakanth Pasunuru, Danqi Chen, Luke Zettlemoyer, and Ves Stoyanov.
\newblock Training trajectories of language models across scales.
\newblock \emph{arXiv preprint arXiv:2212.09803}, 2022.

\bibitem[Huang et~al.(2024)Huang, Zhang, Shan, and He]{huang2024compression}
Yuzhen Huang, Jinghan Zhang, Zifei Shan, and Junxian He.
\newblock Compression represents intelligence linearly.
\newblock \emph{arXiv preprint arXiv:2404.09937}, 2024.

\bibitem[He et~al.(2019)He, Girshick, and Dollar]{he2019imagenetpretraining}
Kaiming He, Ross Girshick, and Piotr Dollar.
\newblock Rethinking imagenet pre-training.
\newblock In \emph{ICCV}, 2019.

\bibitem[Goyal et~al.(2021)Goyal, Caron, Lefaudeux, Xu, Wang, Pai, Singh, Liptchinsky, Misra, Joulin, and Bojanowski]{goyal2021selfsupervised}
Priya Goyal, Mathilde Caron, Benjamin Lefaudeux, Min Xu, Pengchao Wang, Vivek Pai, Mannat Singh, Vitaliy Liptchinsky, Ishan Misra, Armand Joulin, and Piotr Bojanowski.
\newblock Self-supervised pretraining of visual features in the wild.
\newblock \emph{arXiv preprint arXiv:2103.01988}, 2021.

\bibitem[Ghorbani et~al.(2021)Ghorbani, Firat, Freitag, Bapna, Krikun, Garcia, Chelba, and Cherry]{ghorbani2021scaling}
Behrooz Ghorbani, Orhan Firat, Markus Freitag, Ankur Bapna, Maxim Krikun, Xavier Garcia, Ciprian Chelba, and Colin Cherry.
\newblock Scaling laws for neural machine translation.
\newblock \emph{arXiv preprint arXiv:2109.07740}, 2021.

\bibitem[Du et~al.(2024)Du, Zeng, Dong, and Tang]{du2024understanding}
Zhengxiao Du, Aohan Zeng, Yuxiao Dong, and Jie Tang.
\newblock Understanding emergent abilities of language models from the loss perspective.
\newblock \emph{arXiv preprint arXiv:2403.15796}, 2024.

\bibitem[Kornblith et~al.(2019)Kornblith, Shlens, and Le]{kornblith2019better}
Simon Kornblith, Jonathon Shlens, and Quoc~V Le.
\newblock Do better imagenet models transfer better?
\newblock In \emph{CVPR}, 2019.

\bibitem[Ruan et~al.(2024)Ruan, Maddison, and Hashimoto]{ruan2024observationalscalinglawspredictability}
Yangjun Ruan, Chris~J. Maddison, and Tatsunori Hashimoto.
\newblock Observational scaling laws and the predictability of language model performance.
\newblock \emph{arXiv preprint arXiv:2405.10938}, 2024.

\bibitem[Bostrom(2002)]{bostrom2002existential}
Nick Bostrom.
\newblock Existential risks: Analyzing human extinction scenarios and related hazards.
\newblock \emph{Journal of Evolution and Technology}, 2002.

\bibitem[Hendrycks et~al.(2022{\natexlab{a}})Hendrycks, Zou, Mazeika, Tang, Li, Song, and Steinhardt]{hendrycks2022pixmixdreamlikepicturescomprehensively}
Dan Hendrycks, Andy Zou, Mantas Mazeika, Leonard Tang, Bo~Li, Dawn Song, and Jacob Steinhardt.
\newblock Pixmix: Dreamlike pictures comprehensively improve safety measures.
\newblock \emph{CVPR}, 2022{\natexlab{a}}.

\bibitem[Hendrycks et~al.(2020)Hendrycks, Mu, Cubuk, Zoph, Gilmer, and Lakshminarayanan]{hendrycks2020augmixsimpledataprocessing}
Dan Hendrycks, Norman Mu, Ekin~D. Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshminarayanan.
\newblock Augmix: A simple data processing method to improve robustness and uncertainty.
\newblock \emph{arXiv preprint arXiv:1912.02781}, 2020.

\bibitem[Hendrycks et~al.(2021{\natexlab{b}})Hendrycks, Basart, Mu, Kadavath, Wang, Dorundo, Desai, Zhu, Parajuli, Guo, et~al.]{hendrycks2021facesrobustnesscriticalanalysis}
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et~al.
\newblock The many faces of robustness: A critical analysis of out-of-distribution generalization.
\newblock \emph{arXiv preprint arXiv:2006.16241}, 2021{\natexlab{b}}.

\bibitem[Hendrycks and Mazeika(2022)]{hendrycks2022xriskanalysisairesearch}
Dan Hendrycks and Mantas Mazeika.
\newblock X-risk analysis for ai research.
\newblock \emph{arXiv preprint arXiv:2206.05862}, 2022.

\bibitem[Hendrycks et~al.(2021{\natexlab{c}})Hendrycks, Burns, Basart, Zou, Mazeika, Song, and Steinhardt]{mmlu}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding.
\newblock \emph{ICLR}, 2021{\natexlab{c}}.

\bibitem[Sakaguchi et~al.(2019)Sakaguchi, Bras, Bhagavatula, and Choi]{winogrande}
Keisuke Sakaguchi, Ronan~Le Bras, Chandra Bhagavatula, and Yejin Choi.
\newblock Winogrande: An adversarial winograd schema challenge at scale.
\newblock \emph{arXiv preprint arXiv:1907.10641}, 2019.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser, Plappert, Tworek, Hilton, Nakano, et~al.]{gsm8k}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et~al.
\newblock Training verifiers to solve math word problems.
\newblock \emph{arXiv preprint arXiv:2110.14168}, 2021.

\bibitem[{Epoch AI}(2024)]{epochai_notable_models}
{Epoch AI}.
\newblock Notable {AI} models, July 2024.

\bibitem[Liu et~al.(2020)Liu, Cui, Liu, Huang, Wang, and Zhang]{logiqa}
Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang, Yile Wang, and Yue Zhang.
\newblock Logiqa: A challenge dataset for machine reading comprehension with logical reasoning.
\newblock \emph{arXiv preprint arXiv:2007.08124}, 2020.

\bibitem[Bisk et~al.(2020)Bisk, Zellers, Le~Bras, Gao, and Choi]{piqa}
Yonatan Bisk, Rowan Zellers, Ronan Le~Bras, Jianfeng Gao, and Yejin Choi.
\newblock Piqa: Reasoning about physical commonsense in natural language.
\newblock In \emph{AAAI}, 2020.

\bibitem[Zellers et~al.(2019)Zellers, Holtzman, Bisk, Farhadi, and Choi]{hellaswag}
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.
\newblock Hellaswag: Can a machine really finish your sentence?
\newblock In \emph{ACL}, 2019.

\bibitem[Roemmele et~al.(2011)Roemmele, Bejan, and Gordon]{copa}
Melissa Roemmele, Cosmin Bejan, and Andrew Gordon.
\newblock Choice of plausible alternatives: An evaluation of commonsense causal reasoning.
\newblock In \emph{AAAI Spring Symposium}, 2011.

\bibitem[Jin et~al.(2021)Jin, Pan, Oufattole, Weng, Fang, and Szolovits]{medqa}
Di~Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter Szolovits.
\newblock What disease does this patient have? a large-scale open domain question answering dataset from medical exams.
\newblock \emph{Applied Sciences}, 2021.

\bibitem[Clark et~al.(2018)Clark, Cowhey, Etzioni, Khot, Sabharwal, Schoenick, and Tafjord]{arcc}
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord.
\newblock Think you have solved question answering? try arc, the ai2 reasoning challenge.
\newblock \emph{arXiv preprint arXiv:1803.05457}, 2018.

\bibitem[Hendrycks et~al.(2021{\natexlab{d}})Hendrycks, Burns, Kadavath, Arora, Basart, Tang, Song, and Steinhardt]{hendrycksmath2021}
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt.
\newblock Measuring mathematical problem solving with the math dataset.
\newblock \emph{NeurIPS}, 2021{\natexlab{d}}.

\bibitem[Paperno et~al.(2016)Paperno, Kruszewski, Lazaridou, Pham, Bernardi, Pezzelle, Baroni, Boleda, and Fernandez]{paperno-lambada}
Denis Paperno, Germán Kruszewski, Angeliki Lazaridou, Ngoc~Quan Pham, Raffaella Bernardi, Sandro Pezzelle, Marco Baroni, Gemma Boleda, and Raquel Fernandez.
\newblock The lambada dataset: Word prediction requiring a broad discourse context.
\newblock In \emph{ACL}, 2016.

\bibitem[bench authors(2023)]{bbh}
BIG bench authors.
\newblock Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.
\newblock \emph{TMLR}, 2023.

\bibitem[Zheng et~al.(2023)Zheng, Chiang, Sheng, Zhuang, Wu, Zhuang, Lin, Li, Li, Xing, Zhang, Gonzalez, and Stoica]{mt-bench_and_lmsys}
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi~Lin, Zhuohan Li, Dacheng Li, Eric~P. Xing, Hao Zhang, Joseph~E. Gonzalez, and Ion Stoica.
\newblock Judging llm-as-a-judge with mt-bench and chatbot arena.
\newblock \emph{arXiv preprint arXiv:2306.05685}, 2023.

\bibitem[Russell(2019)]{russell2019human}
Stuart Russell.
\newblock \emph{Human Compatible: Artificial Intelligence and the Problem of Control}.
\newblock Viking, 2019.

\bibitem[Piper(2019)]{piper2019ai}
Kelsey Piper.
\newblock Ai could be a disaster for humanity. a top computer scientist thinks he has the solution.
\newblock \emph{Vox}, 2019.

\bibitem[Soares(2022)]{lesswrong_alignment_problem}
Nate Soares.
\newblock A central ai alignment problem: Capabilities generalization, 2022.

\bibitem[Shah et~al.(2022)Shah, Varma, Kumar, Phuong, Krakovna, Uesato, and Kenton]{shah2022goalmisgeneralizationcorrectspecifications}
Rohin Shah, Vikrant Varma, Ramana Kumar, Mary Phuong, Victoria Krakovna, Jonathan Uesato, and Zac Kenton.
\newblock Goal misgeneralization: Why correct specifications aren't enough for correct goals.
\newblock \emph{arXiv preprint arXiv:2210.01790}, 2022.

\bibitem[Bai et~al.(2022)Bai, Jones, Ndousse, Askell, Chen, DasSarma, Drain, Fort, Ganguli, Henighan, Joseph, Kadavath, Kernion, Conerly, El-Showk, Elhage, Hatfield-Dodds, Hernandez, Hume, Johnston, Kravec, Lovitt, Nanda, Olsson, Amodei, Brown, Clark, McCandlish, Olah, Mann, and Kaplan]{bai2022traininghelpfulharmlessassistant}
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared Kaplan.
\newblock Training a helpful and harmless assistant with reinforcement learning from human feedback.
\newblock \emph{arXiv preprint arXiv:2204.05862}, 2022.

\bibitem[Lee et~al.(2023)Lee, Phatale, Mansoor, Mesnard, Ferret, Lu, Bishop, Hall, Carbune, Rastogi, and Prakash]{rlaif}
Harrison Lee, Samrat Phatale, Hassan Mansoor, Thomas Mesnard, Johan Ferret, Kellie Lu, Colton Bishop, Ethan Hall, Victor Carbune, Abhinav Rastogi, and Sushant Prakash.
\newblock Rlaif: Scaling reinforcement learning from human feedback with ai feedback.
\newblock \emph{arXiv preprint arXiv:2309.00267}, 2023.

\bibitem[Rawls(1971)]{rawls1971theory}
John Rawls.
\newblock \emph{A Theory of Justice}.
\newblock Belknap Press, United States, 1971.
\newblock ISBN 978-0-674-00078-0.

\bibitem[Hendrycks(2025)]{aises}
Dan Hendrycks.
\newblock \emph{Introduction to AI Safety, Ethics and Society}.
\newblock Taylor \& Francis, 2025.

\bibitem[{Hanover Research}(2015)]{HanoverResearch2015}
{Hanover Research}.
\newblock Assessment correlations.
\newblock Technical report, Washtenaw Intermediate School District, 2015.

\bibitem[Hendrycks et~al.(2021{\natexlab{e}})Hendrycks, Burns, Basart, Critch, Li, Song, and Steinhardt]{ETHICS}
Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, and Jacob Steinhardt.
\newblock Aligning ai with shared human values.
\newblock \emph{ICLR}, 2021{\natexlab{e}}.

\bibitem[Pan et~al.(2023)Pan, Chan, Zou, Li, Basart, Woodside, Zhang, Emmons, and Hendrycks]{machiavelli}
Alexander Pan, Jun~Shern Chan, Andy Zou, Nathaniel Li, Steven Basart, Thomas Woodside, Hanlin Zhang, Scott Emmons, and Dan Hendrycks.
\newblock Do the rewards justify the means? measuring trade-offs between rewards and ethical behavior in the machiavelli benchmark.
\newblock In \emph{ICML}, 2023.

\bibitem[Hendrycks et~al.(2022{\natexlab{b}})Hendrycks, Carlini, Schulman, and Steinhardt]{hendrycks2022unsolvedproblemsmlsafety}
Dan Hendrycks, Nicholas Carlini, John Schulman, and Jacob Steinhardt.
\newblock Unsolved problems in ml safety.
\newblock \emph{arXiv preprint arXiv:2109.13916}, 2022{\natexlab{b}}.

\bibitem[Rogaway(2015)]{rogaway2015moral}
Phillip Rogaway.
\newblock The moral character of cryptographic work.
\newblock \emph{Cryptology ePrint Archive}, 2015.

\bibitem[Yudkowsky(2015)]{yudkowsky2015rationality}
Eliezer Yudkowsky.
\newblock \emph{Rationality: From AI to Zombies}.
\newblock Machine Intelligence Research Institute, 2015.

\bibitem[Guo et~al.(2019)Guo, Sun, Cai, Zhang, and Song]{GUO20191}
Qingke Guo, Peng Sun, Minghang Cai, Xiling Zhang, and Kexin Song.
\newblock Why are smarter individuals more prosocial? a study on the mediating roles of empathy and moral identity.
\newblock \emph{Intelligence}, 75:\penalty0 1--8, 2019.
\newblock ISSN 0160-2896.

\bibitem[Railton(2022)]{railton2022ethics}
Peter Railton.
\newblock Ethics and artificial intelligence.
\newblock \emph{Oxford Uehiro Centre for Practical Ethics Lecture Series, University of Oxford}, 2022.

\bibitem[Harman(1996)]{harman1996moral}
Gilbert Harman.
\newblock Moral relativism.
\newblock In Gilbert Harman and Judith~Jarvis Thompson, editors, \emph{Moral Relativism and Moral Objectivity}, pages 3--64. Blackwell Publishers, Cambridge, MA, 1996.

\bibitem[Parrish et~al.(2022)Parrish, Chen, Nangia, Padmakumar, Phang, Thompson, Htut, and Bowman]{bbq}
Alicia Parrish, Angelica Chen, Nikita Nangia, Vishakh Padmakumar, Jason Phang, Jana Thompson, Phu~Mon Htut, and Samuel Bowman.
\newblock Bbq: A hand-built bias benchmark for question answering.
\newblock In \emph{ACL}, 2022.

\bibitem[Nangia et~al.(2020)Nangia, Vania, Bhalerao, and Bowman]{crowspairs}
Nikita Nangia, Clara Vania, Rasika Bhalerao, and Samuel~R. Bowman.
\newblock Crows-pairs: A challenge dataset for measuring social biases in masked language models.
\newblock In \emph{EMNLP}, 2020.

\bibitem[Adler(2019)]{adler2019measuring}
Matthew~D. Adler.
\newblock \emph{Measuring Social Welfare: An Introduction}.
\newblock Oxford University Press, 2019.
\newblock ISBN 9780190643065.
\newblock \doi{10.1093/oso/9780190643027.001.0001}.

\bibitem[Rudinger et~al.(2018)Rudinger, Naradowsky, Leonard, and Van~Durme]{winogender}
Rachel Rudinger, Jason Naradowsky, Brian Leonard, and Benjamin Van~Durme.
\newblock Gender bias in coreference resolution.
\newblock In \emph{NAACL}, 2018.

\bibitem[Team et~al.(2024)Team, Mesnard, Hardin, Dadashi, Bhupatiraju, Pathak, Sifre, Rivière, Kale, Love, et~al.]{gemmateam2024gemma}
Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir~Sanjay Kale, Juliette Love, et~al.
\newblock Gemma: Open models based on gemini research and technology.
\newblock \emph{arXiv preprint arXiv:2403.08295}, 2024.

\bibitem[Evans et~al.(2021)Evans, Cotton-Barratt, Finnveden, Bales, Balwit, Wills, Righetti, and Saunders]{evans2021truthfulaidevelopinggoverning}
Owain Evans, Owen Cotton-Barratt, Lukas Finnveden, Adam Bales, Avital Balwit, Peter Wills, Luca Righetti, and William Saunders.
\newblock Truthful ai: Developing and governing ai that does not lie.
\newblock \emph{arXiv preprint arXiv:2110.06674}, 2021.

\bibitem[Amodei et~al.(2016)Amodei, Olah, Steinhardt, Christiano, Schulman, and Mané]{amodei2016concrete}
Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and Dan Mané.
\newblock Concrete problems in ai safety.
\newblock \emph{arXiv preprint arXiv:1606.06565}, 2016.

\bibitem[Bowman et~al.(2022)Bowman, Hyun, Perez, Chen, Pettit, Heiner, Lukošiūtė, Askell, Jones, Chen, Goldie, Mirhoseini, McKinnon, Olah, Amodei, Amodei, Drain, Li, Tran-Johnson, Kernion, Kerr, Mueller, Ladish, Landau, Ndousse, Lovitt, Elhage, Schiefer, Joseph, Mercado, DasSarma, Larson, McCandlish, Kundu, Johnston, Kravec, Showk, Fort, Telleen-Lawton, Brown, Henighan, Hume, Bai, Hatfield-Dodds, Mann, and Kaplan]{bowman2022measuringprogressscalableoversight}
Samuel~R. Bowman, Jeeyoon Hyun, Ethan Perez, Edwin Chen, Craig Pettit, Scott Heiner, Kamilė Lukošiūtė, Amanda Askell, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, Christopher Olah, Daniela Amodei, Dario Amodei, Dawn Drain, Dustin Li, Eli Tran-Johnson, Jackson Kernion, Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua Landau, Kamal Ndousse, Liane Lovitt, Nelson Elhage, Nicholas Schiefer, Nicholas Joseph, Noemí Mercado, Nova DasSarma, Robin Larson, Sam McCandlish, Sandipan Kundu, Scott Johnston, Shauna Kravec, Sheer~El Showk, Stanislav Fort, Timothy Telleen-Lawton, Tom Brown, Tom Henighan, Tristan Hume, Yuntao Bai, Zac Hatfield-Dodds, Ben Mann, and Jared Kaplan.
\newblock Measuring progress on scalable oversight for large language models.
\newblock \emph{arXiv preprint arXiv:2211.03540}, 2022.

\bibitem[Li et~al.(2024{\natexlab{b}})Li, Patel, Viégas, Pfister, and Wattenberg]{li2024inferencetimeinterventionelicitingtruthful}
Kenneth Li, Oam Patel, Fernanda Viégas, Hanspeter Pfister, and Martin Wattenberg.
\newblock Inference-time intervention: Eliciting truthful answers from a language model.
\newblock \emph{arXiv preprint arXiv:2306.03341}, 2024{\natexlab{b}}.

\bibitem[Krueger et~al.(2020)Krueger, Maharaj, and Leike]{krueger2020hiddenincentivesautoinduceddistributional}
David Krueger, Tegan Maharaj, and Jan Leike.
\newblock Hidden incentives for auto-induced distributional shift.
\newblock \emph{arXiv preprint arXiv:2009.09153}, 2020.

\bibitem[Rein et~al.(2023)Rein, Hou, Stickland, Petty, Pang, Dirani, Michael, and Bowman]{gpqa}
David Rein, Betty~Li Hou, Asa~Cooper Stickland, Jackson Petty, Richard~Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel~R. Bowman.
\newblock Gpqa: A graduate-level google-proof q\&a benchmark.
\newblock \emph{arXiv preprint arXiv:2311.12022}, 2023.

\bibitem[Pang et~al.(2022)Pang, Parrish, Joshi, Nangia, Phang, Chen, Padmakumar, Ma, Thompson, He, and Bowman]{QuALITY}
Richard~Yuanzhe Pang, Alicia Parrish, Nitish Joshi, Nikita Nangia, Jason Phang, Angelica Chen, Vishakh Padmakumar, Johnny Ma, Jana Thompson, He~He, and Samuel~R. Bowman.
\newblock Quality: Question answering with long input texts, yes!
\newblock \emph{arXiv preprint arXiv:2112.08608}, 2022.

\bibitem[Zou et~al.(2022)Zou, Xiao, Jia, Kwon, Mazeika, Li, Song, Steinhardt, Evans, and Hendrycks]{zou2022forecastingfutureworldevents}
Andy Zou, Tristan Xiao, Ryan Jia, Joe Kwon, Mantas Mazeika, Richard Li, Dawn Song, Jacob Steinhardt, Owain Evans, and Dan Hendrycks.
\newblock Forecasting future world events with neural networks.
\newblock \emph{arXiv preprint arXiv:2206.15474}, 2022.

\bibitem[Wang et~al.(2024)Wang, Li, Shao, Xu, Dai, Li, Chen, Wu, and Sui]{wang2024mathshepherdverifyreinforcellms}
Peiyi Wang, Lei Li, Zhihong Shao, R.~X. Xu, Damai Dai, Yifei Li, Deli Chen, Y.~Wu, and Zhifang Sui.
\newblock Math-shepherd: Verify and reinforce llms step-by-step without human annotations.
\newblock \emph{arXiv preprint arXiv:2312.08935}, 2024.

\bibitem[Shah et~al.(2024)Shah, Goyal, Yu, Lyu, Park, Ke, McClelland, Bengio, Arora, and Mozer]{shah2024ai}
Vedant Shah, Anirudh Goyal, Dingli Yu, Kaifeng Lyu, Simon Park, Nan~Rosemary Ke, James~Lloyd McClelland, Yoshua Bengio, Sanjeev Arora, and Michael~Curtis Mozer.
\newblock Ai-assisted generation of difficult math questions.
\newblock In \emph{AI for Math Workshop @ ICML}, 2024.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger.
\newblock On calibration of modern neural networks.
\newblock In \emph{ICML}, 2017.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Lee, and Mazeika]{hendrycks2019using}
Dan Hendrycks, Kimin Lee, and Mantas Mazeika.
\newblock Using pre-training can improve model robustness and uncertainty.
\newblock In \emph{ICML}, 2019.

\bibitem[Nie et~al.(2020)Nie, Williams, Dinan, Bansal, Weston, and Kiela]{anli}
Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe Kiela.
\newblock Adversarial nli: A new benchmark for natural language understanding.
\newblock In \emph{ACL}, 2020.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2019.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis, Zettlemoyer, and Stoyanov]{roberta}
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019.

\bibitem[Wang et~al.(2021)Wang, Xu, Wang, Gan, Cheng, Gao, Awadallah, and Li]{adversarial_glue}
Boxin Wang, Chejian Xu, Shuohang Wang, Zhe Gan, Yu~Cheng, Jianfeng Gao, Ahmed~Hassan Awadallah, and Bo~Li.
\newblock Adversarial glue: A multi-task benchmark for robustness evaluation of language models.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[Wang et~al.(2018)Wang, Singh, Michael, Hill, Levy, and Bowman]{glue}
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman.
\newblock Glue: A multi-task benchmark and analysis platform for natural language understanding.
\newblock In \emph{EMNLP}, 2018.

\bibitem[Wang et~al.(2023)Wang, Chen, Pei, Xie, Kang, Zhang, Xu, Xiong, Dutta, Schaeffer, et~al.]{wang2023decodingtrust}
Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang, Chenhui Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, et~al.
\newblock Decodingtrust: A comprehensive assessment of trustworthiness in gpt models.
\newblock \emph{NeurIPS}, 2023.

\bibitem[Taori et~al.(2023)Taori, Gulrajani, Zhang, Dubois, Li, Guestrin, Liang, and Hashimoto]{alpaca}
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori~B. Hashimoto.
\newblock Stanford alpaca: An instruction-following llama model, 2023.

\bibitem[Chiang et~al.(2023)Chiang, Li, Lin, Sheng, Wu, Zhang, Zheng, Zhuang, Zhuang, Gonzalez, Stoica, and Xing]{vicuna}
Wei-Lin Chiang, Zhuohan Li, Zi~Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph~E. Gonzalez, Ion Stoica, and Eric~P. Xing.
\newblock Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality, 2023.

\bibitem[Shen et~al.(2024)Shen, Chen, Backes, Shen, and Zhang]{do_anything_now}
Xinyue Shen, Zeyuan Chen, Michael Backes, Yun Shen, and Yang Zhang.
\newblock "do anything now": Characterizing and evaluating in-the-wild jailbreak prompts on large language models.
\newblock \emph{arXiv preprint arXiv:2308.03825}, 2024.

\bibitem[Mazeika et~al.(2024)Mazeika, Phan, Yin, Zou, Wang, Mu, Sakhaee, Li, Basart, Li, et~al.]{mazeika2024harmbench}
Mantas Mazeika, Long Phan, Xuwang Yin, Andy Zou, Zifan Wang, Norman Mu, Elham Sakhaee, Nathaniel Li, Steven Basart, Bo~Li, et~al.
\newblock Harmbench: A standardized evaluation framework for automated red teaming and robust refusal.
\newblock \emph{arXiv preprint arXiv:2402.04249}, 2024.

\bibitem[Mehrotra et~al.(2024)Mehrotra, Zampetakis, Kassianik, Nelson, Anderson, Singer, and Karbasi]{tree_of_attacks}
Anay Mehrotra, Manolis Zampetakis, Paul Kassianik, Blaine Nelson, Hyrum Anderson, Yaron Singer, and Amin Karbasi.
\newblock Tree of attacks: Jailbreaking black-box llms automatically.
\newblock \emph{arXiv preprint arXiv:2312.02119}, 2024.

\bibitem[Yao et~al.(2023)Yao, Yu, Zhao, Shafran, Griffiths, Cao, and Narasimhan]{tree_of_thought}
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas~L. Griffiths, Yuan Cao, and Karthik Narasimhan.
\newblock Tree of thoughts: Deliberate problem solving with large language models.
\newblock \emph{arXiv preprint arXiv:2305.10601}, 2023.

\bibitem[Zou et~al.(2023)Zou, Wang, Kolter, and Fredrikson]{gcg}
Andy Zou, Zifan Wang, J~Zico Kolter, and Matt Fredrikson.
\newblock Universal and transferable adversarial attacks on aligned language models.
\newblock \emph{arXiv preprint arXiv:2307.15043}, 2023.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and Vladu]{madry2018towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Hendrycks et~al.(2024)Hendrycks, Mazeika, Mann, Li, Steinhardt, Song, and Gilmer]{mlsafetycourse}
Dan Hendrycks, Mantas Mazeika, Thomas Mann, Bo~Li, Jacob Steinhardt, Dawn Song, and Justin Gilmer.
\newblock Ml safety course, 2024.

\bibitem[r/ControlProblem Community(2024)]{reddit_controlproblem_faq}
r/ControlProblem Community.
\newblock Faq - control problem, 2024.

\bibitem[{Executive Office of the President}(2023)]{EO14110_2023}
{Executive Office of the President}.
\newblock Safe, secure, and trustworthy development and use of artificial intelligence.
\newblock Federal Register, 2023.

\bibitem[Legislature(2024)]{CA_SB1047}
California~State Legislature.
\newblock Senate bill no. 1047 - safe and secure innovation for frontier artificial intelligence models act, 2024.

\bibitem[Thornley(2024)]{Thornley2024}
E.~Thornley.
\newblock The shutdown problem: an ai engineering puzzle for decision theorists.
\newblock \emph{Philos Stud}, 6 2024.
\newblock \doi{10.1007/s11098-024-02153-3}.

\bibitem[Soares et~al.(2015)Soares, Fallenstein, Yudkowsky, and Armstrong]{Soares2015Corrigibility}
Nate Soares, Benja Fallenstein, Eliezer Yudkowsky, and Stuart Armstrong.
\newblock Corrigibility.
\newblock In \emph{AAAI Publications}. Association for the Advancement of Artificial Intelligence, 2015.

\bibitem[Hendrycks and Dietterich(2019)]{hendrycks2019robustness}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and perturbations.
\newblock \emph{ICLR}, 2019.

\bibitem[Radford et~al.(2021{\natexlab{a}})Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learningtransferablevisualmodels}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock \emph{arXiv preprint arXiv:2103.00020}, 2021{\natexlab{a}}.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Yang, Wang, Wang, Lin, Zhang, Sun, Du, Zhou, Zhang, Li, Liu, Chen, and Li]{zhang2023openood}
Jingyang Zhang, Jingkang Yang, Pengyun Wang, Haoqi Wang, Yueqian Lin, Haoran Zhang, Yiyou Sun, Xuefeng Du, Kaiyang Zhou, Wayne Zhang, Yixuan Li, Ziwei Liu, Yiran Chen, and Hai Li.
\newblock Openood v1.5: Enhanced benchmark for out-of-distribution detection.
\newblock \emph{arXiv preprint arXiv:2306.09301}, 2023{\natexlab{a}}.

\bibitem[Sutton(2019)]{sutton2019bitter}
Rich Sutton.
\newblock The bitter lesson, 2019.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, et~al.]{llama2}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv:2307.09288}, 2023.

\bibitem[Team(2023)]{llama3}
Llama Team.
\newblock Llama 3: An open large language model.
\newblock \emph{Meta AI Blog}, 2023.

\bibitem[Jiang et~al.(2023)Jiang, Sablayrolles, Mensch, Bamford, Chaplot, de~las Casas, Bressand, Lengyel, Lample, Saulnier, et~al.]{jiang2023mistral}
Albert~Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra~Singh Chaplot, Diego de~las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et~al.
\newblock Mistral 7b.
\newblock \emph{arXiv preprint arXiv:2310.06825}, 2023.

\bibitem[Jiang et~al.(2024)Jiang, Sablayrolles, Roux, Mensch, Savary, Bamford, Chaplot, de~las Casas, Hanna, Bressand, et~al.]{jiang2024mixtral}
Albert~Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra~Singh Chaplot, Diego de~las Casas, Emma~Bou Hanna, Florian Bressand, et~al.
\newblock Mixtral of experts.
\newblock \emph{arXiv preprint arXiv:2401.04088}, 2024.

\bibitem[Almazrouei et~al.(2023)Almazrouei, Alobeidli, Alshamsi, Cappelli, Cojocaru, Debbah, Goffinet, Hesslow, Launay, Malartic, et~al.]{almazrouei2023falcon}
Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Mérouane Debbah, Étienne Goffinet, Daniel Hesslow, Julien Launay, Quentin Malartic, et~al.
\newblock The falcon series of open language models.
\newblock \emph{arXiv preprint arXiv:2311.16867}, 2023.

\bibitem[AI et~al.(2024)AI, :, Young, Chen, Li, Huang, Zhang, Zhang, Li, Zhu, Chen, Chang, Yu, Liu, Liu, Yue, Yang, Yang, Yu, Xie, Huang, Hu, Ren, Niu, Nie, Xu, Liu, Wang, Cai, Gu, Liu, and Dai]{ai2024yi}
01. AI, :, Alex Young, Bei Chen, Chao Li, Chengen Huang, Ge~Zhang, Guanwei Zhang, Heng Li, Jiangcheng Zhu, Jianqun Chen, Jing Chang, Kaidong Yu, Peng Liu, Qiang Liu, Shawn Yue, Senbin Yang, Shiming Yang, Tao Yu, Wen Xie, Wenhao Huang, Xiaohui Hu, Xiaoyi Ren, Xinyao Niu, Pengcheng Nie, Yuchi Xu, Yudong Liu, Yue Wang, Yuxuan Cai, Zhenyu Gu, Zhiyuan Liu, and Zonghong Dai.
\newblock Yi: Open foundation models by 01.ai.
\newblock \emph{arXiv preprint arXiv:2403.04652}, 2024.

\bibitem[Bai et~al.(2023)Bai, Bai, Chu, Cui, Dang, Deng, Fan, Ge, Han, Huang, et~al.]{qwen}
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu~Han, Fei Huang, et~al.
\newblock Qwen technical report.
\newblock \emph{arXiv preprint arXiv:2309.16609}, 2023.

\bibitem[DeepSeek-AI(2024)]{deepseek-llm}
DeepSeek-AI.
\newblock Deepseek llm: Scaling open-source language models with longtermism.
\newblock \emph{arXiv preprint arXiv:2401.02954}, 2024.

\bibitem[{The Mosaic Research Team}(2024)]{dbrx2024}
{The Mosaic Research Team}.
\newblock Introducing {DBRX}: A new state-of-the-art open {LLM}, 2024.

\bibitem[Oquab et~al.(2023)Oquab, Darcet, Moutakanni, Vo, Szafraniec, Khalidov, Fernandez, Haziza, Massa, El-Nouby, et~al.]{oquab2023dinov2}
Maxime Oquab, Timothée Darcet, Théo Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et~al.
\newblock Dinov2: Learning robust visual features without supervision.
\newblock \emph{arXiv preprint arXiv:2304.07193}, 2023.

\bibitem[Salman et~al.(2020)Salman, Ilyas, Engstrom, Kapoor, and Madry]{salman2020adversarially}
Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, and Aleksander Madry.
\newblock Do adversarially robust imagenet models transfer better?
\newblock \emph{NeurIPS}, 2020.

\bibitem[Liu et~al.(2022)Liu, Mao, Wu, Feichtenhofer, Darrell, and Xie]{liu2022convnet}
Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, and Saining Xie.
\newblock A convnet for the 2020s.
\newblock In \emph{CVPR}, 2022.

\bibitem[Woo et~al.(2023)Woo, Debnath, Hu, Chen, Liu, Kweon, and Xie]{woo2023convnext}
Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In~So Kweon, and Saining Xie.
\newblock Convnext v2: Co-designing and scaling convnets with masked autoencoders.
\newblock \emph{arXiv preprint arXiv:2301.00808}, 2023.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and Hinton]{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Advances in neural information processing systems}, 25, 2012.

\bibitem[Simonyan and Zisserman(2014)]{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Zagoruyko and Komodakis(2017)]{zagoruyko2016wide}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks, 2017.
\newblock URL \url{https://arxiv.org/abs/1605.07146}.

\bibitem[Xie et~al.(2017)Xie, Girshick, Doll{\'a}r, Tu, and He]{xie2017aggregated}
Saining Xie, Ross Girshick, Piotr Doll{\'a}r, Zhuowen Tu, and Kaiming He.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 1492--1500, 2017.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and Weinberger]{huang2017densely}
Gao Huang, Zhuang Liu, Laurens Van Der~Maaten, and Kilian~Q Weinberger.
\newblock Densely connected convolutional networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 4700--4708, 2017.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and Guo]{liu2021swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted windows.
\newblock In \emph{ICCV}, 2021.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, et~al.]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Steiner et~al.(2022)Steiner, Kolesnikov, Zhai, Wightman, Uszkoreit, and Beyer]{steiner2022how}
Andreas Steiner, Alexander Kolesnikov, Xiaohua Zhai, Ross Wightman, Jakob Uszkoreit, and Lucas Beyer.
\newblock How to train your vit? data, augmentation, and regularization in vision transformers.
\newblock \emph{TMLR}, 2022.

\bibitem[Radford et~al.(2021{\natexlab{b}})Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{ICML}, 2021{\natexlab{b}}.

\bibitem[Mangalam et~al.(2022)Mangalam, Fan, Li, Wu, Xiong, Feichtenhofer, and Malik]{mangalam2022reversible}
Karttikeya Mangalam, Haoqi Fan, Yanghao Li, Chao-Yuan Wu, Bo~Xiong, Christoph Feichtenhofer, and Jitendra Malik.
\newblock Reversible vision transformers.
\newblock In \emph{CVPR}, 2022.

\bibitem[Li et~al.(2023)Li, Cheng, Zhao, Nie, and Wen]{halueval}
Junyi Li, Xiaoxue Cheng, Wayne~Xin Zhao, Jian-Yun Nie, and Ji-Rong Wen.
\newblock Halueval: A large-scale hallucination evaluation benchmark for large language models.
\newblock \emph{arXiv preprint arXiv:2305.11747}, 2023.

\bibitem[Hughes and Bae(2023)]{vectara}
Simon Hughes and Minseok Bae.
\newblock Vectara hallucination leaderboard, 2023.

\bibitem[Scherrer et~al.(2023)Scherrer, Shi, Feder, and Blei]{moralchoice}
Nino Scherrer, Claudia Shi, Amir Feder, and David~M. Blei.
\newblock Evaluating the moral beliefs encoded in {LLM}s.
\newblock \emph{arXiv preprint arXiv:2307.14324}, 2023.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Lei, Wu, Sun, Huang, Long, Liu, Lei, Tang, and Huang]{zhang2023safetybench}
Zhexin Zhang, Leqi Lei, Lindong Wu, Rui Sun, Yongkang Huang, Chong Long, Xiao Liu, Xuanyu Lei, Jie Tang, and Minlie Huang.
\newblock Safetybench: Evaluating the safety of large language models with multiple choice questions.
\newblock \emph{arXiv preprint arXiv:2309.07045}, 2023{\natexlab{b}}.

\bibitem[Perez et~al.(2022)Perez, Ringer, Lukošiūtė, Nguyen, Chen, Heiner, Pettit, Olsson, Kundu, Kadavath, et~al.]{perez2022discovering}
Ethan Perez, Sam Ringer, Kamilė Lukošiūtė, Karina Nguyen, Edwin Chen, Scott Heiner, Craig Pettit, Catherine Olsson, Sandipan Kundu, Saurav Kadavath, et~al.
\newblock Discovering language model behaviors with model-written evaluations.
\newblock \emph{arXiv preprint arXiv:2212.09251}, 2022.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{gpt3}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Hartvigsen et~al.(2022)Hartvigsen, Gabriel, Palangi, Sap, Ray, and Kamar]{toxigen}
Thomas Hartvigsen, Saadia Gabriel, Hamid Palangi, Maarten Sap, Dipankar Ray, and Ece Kamar.
\newblock Toxigen: A large-scale machine-generated dataset for implicit and adversarial hate speech detection.
\newblock \emph{ACL}, 2022.

\bibitem[Bhatt et~al.(2024)Bhatt, Chennabasappa, Li, Nikolaidis, Song, Wan, Ahmad, Aschermann, Chen, Kapil, et~al.]{cyberseceval2}
Manish Bhatt, Sahana Chennabasappa, Yue Li, Cyrus Nikolaidis, Daniel Song, Shengye Wan, Faizan Ahmad, Cornelius Aschermann, Yaohui Chen, Dhaval Kapil, et~al.
\newblock Cyberseceval 2: A wide-ranging cybersecurity evaluation suite for large language models.
\newblock \emph{arXiv preprint arXiv:2404.13161}, 2024.

\bibitem[Zhou et~al.(2023)Zhou, Lu, Mishra, Brahma, Basu, Luan, Zhou, and Hou]{ifeval}
Jeffrey Zhou, Tianjian Lu, Swaroop Mishra, Siddhartha Brahma, Sujoy Basu, Yi~Luan, Denny Zhou, and Le~Hou.
\newblock Instruction-following evaluation for large language models.
\newblock \emph{arXiv preprint arXiv:2311.07911}, 2023.

\bibitem[Mu et~al.(2024)Mu, Chen, Wang, Chen, Karamardian, Aljeraisy, Alomair, Hendrycks, and Wagner]{rules}
Norman Mu, Sarah Chen, Zifan Wang, Sizhe Chen, David Karamardian, Lulwa Aljeraisy, Basel Alomair, Dan Hendrycks, and David Wagner.
\newblock Can {LLM}s follow simple rules?
\newblock \emph{arXiv preprint arXiv:2311.04235}, 2024.

\end{thebibliography}
