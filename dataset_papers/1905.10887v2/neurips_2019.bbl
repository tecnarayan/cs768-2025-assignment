\begin{thebibliography}{10}

\bibitem{Theis2015d}
L.~Theis, A.~van~den Oord, and M.~Bethge.
\newblock A note on the evaluation of generative models.
\newblock In {\em International Conference on Learning Representations}, 2016.
\newblock arXiv:1511.01844.

\bibitem{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In {\em Advances in neural information processing systems}, pages
  2672--2680, 2014.

\bibitem{brock2018large}
Andrew Brock, Jeff Donahue, and Karen Simonyan.
\newblock Large scale gan training for high fidelity natural image synthesis.
\newblock {\em arXiv preprint arXiv:1809.11096}, 2018.

\bibitem{karras2017progressive}
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
\newblock Progressive growing of gans for improved quality, stability, and
  variation.
\newblock {\em arXiv preprint arXiv:1710.10196}, 2017.

\bibitem{karras2018style}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock {\em arXiv preprint arXiv:1812.04948}, 2018.

\bibitem{salimans2016improved}
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and
  Xi~Chen.
\newblock Improved techniques for training gans.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2234--2242, 2016.

\bibitem{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6626--6637, 2017.

\bibitem{menick2018generating}
Jacob Menick and Nal Kalchbrenner.
\newblock Generating high fidelity images with subscale pixel networks and
  multidimensional upscaling.
\newblock {\em arXiv preprint arXiv:1812.01608}, 2018.

\bibitem{de2019hierarchical}
Jeffrey De~Fauw, Sander Dieleman, and Karen Simonyan.
\newblock Hierarchical autoregressive image models with auxiliary decoders.
\newblock {\em arXiv preprint arXiv:1903.04933}, 2019.

\bibitem{razavi2019generating}
Ali Razavi, Aaron van~den Oord, and Oriol Vinyals.
\newblock Generating diverse high-fidelity images with vq-vae-2.
\newblock {\em arXiv preprint arXiv:1906.00446}, 2019.

\bibitem{chen1998evaluation}
Stanley~F Chen, Douglas Beeferman, and Roni Rosenfeld.
\newblock Evaluation metrics for language models.
\newblock 1998.

\bibitem{yang2017lr}
Jianwei Yang, Anitha Kannan, Dhruv Batra, and Devi Parikh.
\newblock Lr-gan: Layered recursive generative adversarial networks for image
  generation.
\newblock {\em arXiv preprint arXiv:1703.01560}, 2017.

\bibitem{santurkar2017classification}
Shibani Santurkar, Ludwig Schmidt, and Aleksander M{\k{a}}dry.
\newblock A classification-based study of covariate shift in gan distributions.
\newblock {\em arXiv preprint arXiv:1711.00970}, 2017.

\bibitem{esteban2017real}
Crist{\'o}bal Esteban, Stephanie~L Hyland, and Gunnar R{\"a}tsch.
\newblock Real-valued (medical) time series generation with recurrent
  conditional gans.
\newblock {\em arXiv preprint arXiv:1706.02633}, 2017.

\bibitem{lesort2018training}
Timoth{\'e}e Lesort, Jean-Fran{\c{c}}ois Goudou, and David Filliat.
\newblock Training discriminative models to evaluate generative ones.
\newblock {\em arXiv preprint arXiv:1806.10840}, 2018.

\bibitem{shmelkov2018good}
Konstantin Shmelkov, Cordelia Schmid, and Karteek Alahari.
\newblock How good is my gan?
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 213--229, 2018.

\bibitem{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock {\em arXiv preprint arXiv:1401.4082}, 2014.

\bibitem{van2016conditional}
Aaron Van~den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex
  Graves, et~al.
\newblock Conditional image generation with pixelcnn decoders.
\newblock In {\em Advances in neural information processing systems}, pages
  4790--4798, 2016.

\bibitem{kingma2018glow}
Durk~P Kingma and Prafulla Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  10215--10224, 2018.

\bibitem{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real nvp.
\newblock {\em arXiv preprint arXiv:1605.08803}, 2016.

\bibitem{smolensky1986information}
Paul Smolensky.
\newblock Information processing in dynamical systems: Foundations of harmony
  theory.
\newblock Technical report, Colorado Univ at Boulder Dept of Computer Science,
  1986.

\bibitem{nalisnick2018deep}
Eric Nalisnick, Akihiro Matsukawa, Yee~Whye Teh, Dilan Gorur, and Balaji
  Lakshminarayanan.
\newblock Do deep generative models know what they don't know?
\newblock {\em arXiv preprint arXiv:1810.09136}, 2018.

\bibitem{binkowski2018demystifying}
Miko{\l}aj Bi{\'n}kowski, Dougal~J Sutherland, Michael Arbel, and Arthur
  Gretton.
\newblock Demystifying mmd gans.
\newblock {\em arXiv preprint arXiv:1801.01401}, 2018.

\bibitem{zhang2018unreasonable}
Richard Zhang, Phillip Isola, Alexei~A Efros, Eli Shechtman, and Oliver Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 586--595, 2018.

\bibitem{sajjadi2018assessing}
Mehdi~SM Sajjadi, Olivier Bachem, Mario Lucic, Olivier Bousquet, and Sylvain
  Gelly.
\newblock Assessing generative models via precision and recall.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5228--5237, 2018.

\bibitem{kynkaanniemi2019improved}
Tuomas Kynk{\"a}{\"a}nniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, and
  Timo Aila.
\newblock Improved precision and recall metric for assessing generative models.
\newblock {\em arXiv preprint arXiv:1904.06991}, 2019.

\bibitem{barratt2018note}
Shane Barratt and Rishi Sharma.
\newblock A note on the inception score.
\newblock {\em arXiv preprint arXiv:1801.01973}, 2018.

\bibitem{zhou2019hype}
Sharon Zhou, Mitchell Gordon, Ranjay Krishna, Austin Narcomey, Durim Morina,
  and Michael~S Bernstein.
\newblock Hype: Human eye perceptual evaluation of generative models.
\newblock {\em arXiv preprint arXiv:1904.01121}, 2019.

\bibitem{miyato2018cgans}
Takeru Miyato and Masanori Koyama.
\newblock cgans with projection discriminator.
\newblock {\em arXiv preprint arXiv:1802.05637}, 2018.

\bibitem{khrulkov2018geometry}
Valentin Khrulkov and Ivan Oseledets.
\newblock Geometry score: A method for comparing generative adversarial
  networks.
\newblock {\em arXiv preprint arXiv:1802.02664}, 2018.

\bibitem{arora2017gans}
Sanjeev Arora and Yi~Zhang.
\newblock Do gans actually learn the distribution? an empirical study.
\newblock {\em arXiv preprint arXiv:1706.08224}, 2017.

\bibitem{gretton2012kernel}
Arthur Gretton, Karsten~M Borgwardt, Malte~J Rasch, Bernhard Sch{\"o}lkopf, and
  Alexander Smola.
\newblock A kernel two-sample test.
\newblock {\em Journal of Machine Learning Research}, 13(Mar):723--773, 2012.

\bibitem{semeniuta2018accurate}
Stanislau Semeniuta, Aliaksei Severyn, and Sylvain Gelly.
\newblock On accurate evaluation of gans for language generation.
\newblock {\em arXiv preprint arXiv:1806.04936}, 2018.

\bibitem{hu2017toward}
Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric~P Xing.
\newblock Toward controlled generation of text.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 1587--1596. JMLR. org, 2017.

\bibitem{liu2018model}
Ruishan Liu, Nicolo Fusi, and Lester Mackey.
\newblock Model compression with generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1812.02271}, 2018.

\bibitem{he2015deep}
Kaiming He, XRSSJ Zhang, S~Ren, and J~Sun.
\newblock Deep residual learning for image recognition. eprint.
\newblock {\em arXiv preprint arXiv:0706.1234}, 2015.

\bibitem{gneiting2007strictly}
Tilmann Gneiting and Adrian~E Raftery.
\newblock Strictly proper scoring rules, prediction, and estimation.
\newblock {\em Journal of the American Statistical Association},
  102(477):359--378, 2007.

\bibitem{goyal2017accurate}
Priya Goyal, Piotr Doll{\'a}r, Ross Girshick, Pieter Noordhuis, Lukasz
  Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He.
\newblock Accurate, large minibatch sgd: Training imagenet in 1 hour.
\newblock {\em arXiv preprint arXiv:1706.02677}, 2017.

\bibitem{ostrovski2018autoregressive}
Georg Ostrovski, Will Dabney, and R{\'e}mi Munos.
\newblock Autoregressive quantile networks for generative modeling.
\newblock {\em arXiv preprint arXiv:1806.05575}, 2018.

\end{thebibliography}
