% original S4
@inproceedings{hippo,
 author = {Gu, Albert and Dao, Tri and Ermon, Stefano and Rudra, Atri and R\'{e}, Christopher},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {{HiPPO}: Recurrent Memory with Optimal Polynomial Projections},
 year = {2020}
}

@inproceedings{
lssl,
title={Combining Recurrent, Convolutional, and Continuous-time Models with Linear State Space Layers},
author={Albert Gu and Isys Johnson and Karan Goel and Khaled Kamal Saab and Tri Dao and Atri Rudra and Christopher R{\'e}},
booktitle={Advances in Neural Information Processing Systems},
year={2021}
}

@inproceedings{
s4,
title={Efficiently Modeling Long Sequences with Structured State Spaces},
author={Albert Gu and Karan Goel and Christopher R{\'e}},
booktitle={International Conference on Learning Representations},
year={2022}
}

% simplifying, understanding, and improving S4
@inproceedings{
dss,
title={Diagonal State Spaces are as Effective as Structured State Spaces},
author={Ankit Gupta and Albert Gu and Jonathan Berant},
booktitle={Advances in Neural Information Processing Systems},
year={2022}
}

@inproceedings{
s4d,
title={On the Parameterization and Initialization of Diagonal State Space Models},
author={Albert Gu and Karan Goel and Ankit Gupta and Christopher R{\'e}},
booktitle={Advances in Neural Information Processing Systems},
year={2022}
}

@inproceedings{
httyh,
title={How to Train your {HiPPO}: State Space Models with Generalized Orthogonal Basis Projections},
author={Albert Gu and Isys Johnson and Aman Timalsina and Atri Rudra and Christopher R{\'e}},
booktitle={International Conference on Learning Representations},
year={2023}
}

@inproceedings{
s5,
title={Simplified State Space Layers for Sequence Modeling},
author={Jimmy T.H. Smith and Andrew Warrington and Scott Linderman},
booktitle={International Conference on Learning Representations},
year={2023}
}

@techreport{blelloch1990prefix,
	author = {Blelloch, Guy},
	institution = {School of Computer Science, Carnegie Mellon University},
	title = {Prefix Sums and Their Applications},
	year = {1990}
}

@InProceedings{orvieto2023resurrecting,
  title = 	 {Resurrecting Recurrent Neural Networks for Long Sequences},
  author =       {Orvieto, Antonio and Smith, Samuel L and Gu, Albert and Fernando, Anushan and Gulcehre, Caglar and Pascanu, Razvan and De, Soham},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2023}
}

% comparing/combining with Transformer
@article{spade,
  title={Efficient Long Sequence Modeling via State Space Augmented {Transformer}},
  author={Zuo, Simiao and Liu, Xiaodong and Jiao, Jian and Charles, Denis and Manavoglu, Eren and Zhao, Tuo and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2212.08136},
  year={2022}
}

@inproceedings{
gss,
title={Long Range Language Modeling via Gated State Spaces},
author={Harsh Mehta and Ankit Gupta and Ashok Cutkosky and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2023}
}

@inproceedings{
h3,
title={{Hungry Hungry Hippos}: Towards Language Modeling with State Space Models},
author={Daniel Y Fu and Tri Dao and Khaled Kamal Saab and Armin W Thomas and Atri Rudra and Christopher R{\'e}},
booktitle={International Conference on Learning Representations},
year={2023}
}

@InProceedings{vis4mer,
author="Islam, Md Mohaiminul
and Bertasius, Gedas",
title="Long Movie Clip Classification with State-Space Video Models",
booktitle="ECCV",
year="2022"
}

@article{dlr,
  title={Simplifying and Understanding State Space Models with Diagonal Linear {RNN}s},
  author={Gupta, Ankit and Mehta, Harsh and Berant, Jonathan},
  journal={arXiv preprint arXiv:2212.00768},
  year={2022}
}

% applications
@InProceedings{sashimi,
  title = 	 {It’s Raw! {A}udio Generation with State-Space Models},
  author =       {Goel, Karan and Gu, Albert and Donahue, Chris and R{\'e}, Christopher},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2022}
}

@inproceedings{
s4nd,
title={{S4ND}: Modeling Images and Videos as Multidimensional Signals with State Spaces},
author={Eric Nguyen and Karan Goel and Albert Gu and Gordon Downs and Preey Shah and Tri Dao and Stephen Baccus and Christopher R{\'e}},
booktitle={Advances in Neural Information Processing Systems},
year={2022}
}

@inproceedings{
ccnn,
title={Modelling Long Range Dependencies in {$N$D}: From Task-Specific to a General Purpose {CNN}},
author={David M Knigge and David W Romero and Albert Gu and Efstratios Gavves and Erik J Bekkers and Jakub Mikolaj Tomczak and Mark Hoogendoorn and {Jan-jakob} Sonke},
booktitle={International Conference on Learning Representations},
year={2023}
}

@InProceedings{selective_s4,
author="Wang, Jue and Zhu, Wentao and Wang, Pichao and Yu, Xiang and Liu, Linda and Omar, Mohamed and Hamid, Raffay",
title="Selective Structured State-Spaces for Long-Form Video Understanding",
booktitle="CVPR",
year="2023"
}

@InProceedings{ls4,
  title = 	 {Deep Latent State Space Models for Time-Series Generation},
  author =       {Zhou, Linqi and Poli, Michael and Xu, Winnie and Massaroli, Stefano and Ermon, Stefano},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2023}
}

@inproceedings{
decision_s4,
title={Decision {S4}: Efficient Sequence-Based {RL} via State Spaces Layers},
author={Shmuel Bar David and Itamar Zimerman and Eliya Nachmani and Lior Wolf},
booktitle={International Conference on Learning Representations},
year={2023}
}

@article{lu2023structured,
  title={Structured State Space Models for In-Context Reinforcement Learning},
  author={Lu, Chris and Schroecker, Yannick and Gu, Albert and Parisotto, Emilio and Foerster, Jakob and Singh, Satinder and Behbahani, Feryal},
  journal={arXiv preprint arXiv:2303.03982},
  year={2023}
}

% memory
@inproceedings{
memory_gym,
title={Memory {Gym}: Partially Observable Challenges to Memory-Based Agents},
author={Marco Pleines and Matthias Pallasch and Frank Zimmer and Mike Preuss},
booktitle={International Conference on Learning Representations},
year={2023}
}

@misc{minigrid,
  author = {Chevalier-Boisvert, Maxime and Willems, Lucas and Pal, Suman},
  title = {Minimalistic Gridworld Environment for {Gymnasium}},
  url = {https://github.com/Farama-Foundation/Minigrid},
  year = {2018},
}

% world model
@InProceedings{rssm,
  title = 	 {Learning Latent Dynamics for Planning from Pixels},
  author =       {Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2019}
}

@inproceedings{
memory_maze,
title={Evaluating Long-Term Memory in {3D} Mazes},
author={Jurgis Pa{\v{s}}ukonis and Timothy Lillicrap and Danijar Hafner},
booktitle={International Conference on Learning Representations},
year={2023}
}

@inproceedings{
transdreamer,
title={{TransDreamer}: Reinforcement Learning with {Transformer} World Models},
author={Chang Chen and Yi-Fu Wu and Jaesik Yoon and Sungjin Ahn},
booktitle={Deep RL Workshop NeurIPS 2021},
year={2021}
}

@article{manning2021episodic,
  title={Episodic memory: Mental time travel or a quantum “memory wave” function?},
  author={Manning, Jeremy R},
  journal={Psychological review},
  volume={128},
  number={4},
  pages={711},
  year={2021},
  publisher={American Psychological Association}
}

@article{suddendorf2009mental,
  title={Mental time travel and the shaping of the human mind},
  author={Suddendorf, Thomas and Addis, Donna Rose and Corballis, Michael C},
  journal={Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume={364},
  number={1521},
  pages={1317--1324},
  year={2009},
  publisher={The Royal Society London}
}

@article{tulving1985memory,
  title={Memory and consciousness.},
  author={Tulving, Endel},
  journal={Canadian Psychology/Psychologie canadienne},
  volume={26},
  number={1},
  pages={1},
  year={1985},
  publisher={Canadian Psychological Association}
}

@article{gru,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.3555},
  year={2014}
}

@article{lstm,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT press}
}

@article{layernorm,
  title={Layer normalization},
  author={Ba, Jimmy and Kiros, Jamie Ryan and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{gelu,
  title={{Gaussian Error Linear Units (GELUs)}},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{silu,
  title={Searching for activation functions},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.05941},
  year={2017}
}

@article{bengio2013estimating,
  title={Estimating or propagating gradients through stochastic neurons for conditional computation},
  author={Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
  journal={arXiv preprint arXiv:1308.3432},
  year={2013}
}

@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  year={2013}
}

@inproceedings{
vit,
title={An Image is Worth 16x16 Words: {Transformers} for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021}
}

@article{pearson2019human,
  title={The human imagination: the cognitive neuroscience of visual mental imagery},
  author={Pearson, Joel},
  journal={Nature Reviews Neuroscience},
  volume={20},
  number={10},
  pages={624--634},
  year={2019}
}

@article{mattar22,
title = {Planning in the brain},
journal = {Neuron},
volume = {110},
number = {6},
pages = {914-934},
year = {2022},
author = {Marcelo G Mattar and Máté Lengyel}
}

@article{mbrlsurvey,
year = {2023},
volume = {16},
journal = {Foundations and Trends® in Machine Learning},
title = {Model-based Reinforcement Learning: A Survey},
number = {1},
pages = {1-118},
author = {Thomas M Moerland and Joost Broekens and Aske Plaat and Catholijn M Jonker}
}

@inproceedings{transformer,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Attention is All you Need},
 year = {2017}
}

@inproceedings{
longrangearena,
title={{Long Range Arena}: A Benchmark for Efficient {Transformers}},
author={Yi Tay and Mostafa Dehghani and Samira Abnar and Yikang Shen and Dara Bahri and Philip Pham and Jinfeng Rao and Liu Yang and Sebastian Ruder and Donald Metzler},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{worldmodels,
 author = {Ha, David and Schmidhuber, J\"{u}rgen},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Recurrent World Models Facilitate Policy Evolution},
 year = {2018}
}

@InProceedings{solar,
  title = 	 {{SOLAR}: Deep Structured Representations for Model-Based Reinforcement Learning},
  author =       {Zhang, Marvin and Vikram, Sharad and Smith, Laura and Abbeel, Pieter and Johnson, Matthew and Levine, Sergey},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2019}
}

@InProceedings{tia,
  title = 	 {Learning Task Informed Abstractions},
  author =       {Fu, Xiang and Yang, Ge and Agrawal, Pulkit and Jaakkola, Tommi},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2021}
}

@inproceedings{
dreamer,
title={Dream to Control: Learning Behaviors by Latent Imagination},
author={Danijar Hafner and Timothy Lillicrap and Jimmy Ba and Mohammad Norouzi},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{
dreamerv2,
title={Mastering {Atari} with Discrete World Models},
author={Danijar Hafner and Timothy Lillicrap and Mohammad Norouzi and Jimmy Ba},
booktitle={International Conference on Learning Representations},
year={2021}
}

@article{dreamerv3,
  title={Mastering Diverse Domains through World Models},
  author={Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap, Timothy},
  journal={arXiv preprint arXiv:2301.04104},
  year={2023}
}

@InProceedings{daydreamer,
  title = 	 {{D}ay{D}reamer: World Models for Physical Robot Learning},
  author =       {Wu, Philipp and Escontrela, Alejandro and Hafner, Danijar and Abbeel, Pieter and Goldberg, Ken},
  booktitle = 	 {CoRL},
  year = 	 {2023}
}

@InProceedings{seo2023masked,
  title = 	 {Masked World Models for Visual Control},
  author =       {Seo, Younggyo and Hafner, Danijar and Liu, Hao and Liu, Fangchen and James, Stephen and Lee, Kimin and Abbeel, Pieter},
  booktitle = 	 {CoRL},
  year = 	 {2023}
}

@inproceedings{dreamingv2,
  author={Okada, Masashi and Taniguchi, Tadahiro},
  booktitle={IROS}, 
  title={{DreamingV2}: Reinforcement Learning with Discrete World Models without Reconstruction}, 
  year={2022}
}

@inproceedings{dreaming,
  author={Okada, Masashi and Taniguchi, Tadahiro},
  booktitle={ICRA},
  title={Dreaming: Model-based Reinforcement Learning by Latent Imagination without Reconstruction},
  year={2021}
}

@InProceedings{tpc,
  title = 	 {Temporal Predictive Coding For Model-Based Planning In Latent Space},
  author =       {Nguyen, Tung D and Shu, Rui and Pham, Tuan and Bui, Hung and Ermon, Stefano},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2021}
}

@inproceedings{vsg,
 author = {Jain, Arnav Kumar and Sujit, Shivakanth and Joshi, Shruti and Michalski, Vincent and Hafner, Danijar and Ebrahimi Kahou, Samira},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Learning Robust Dynamics through Variational Sparse Gating},
 year = {2022}
}

@article{wu2023pre,
  title={Pre-training Contextualized World Models with In-the-wild Videos for Reinforcement Learning},
  author={Wu, Jialong and Ma, Haoyu and Deng, Chaoyi and Long, Mingsheng},
  journal={arXiv preprint arXiv:2305.18499},
  year={2023}
}

@inproceedings{drg,
  title={Dream to Generalize: Zero-Shot Model-Based Reinforcement Learning for Unseen Visual Distractions},
  booktitle={AAAI},
  author={Ha, Jeongsoo and Kim, Kyungsoo and Kim, Yusung},
  year={2023}
}

@article{wang2022prototypical,
  title={Prototypical context-aware dynamics generalization for high-dimensional model-based reinforcement learning},
  author={Wang, Junjie and Mu, Yao and Li, Dong and Zhang, Qichao and Zhao, Dongbin and Zhuang, Yuzheng and Luo, Ping and Wang, Bin and Hao, Jianye},
  journal={arXiv preprint arXiv:2211.12774},
  year={2022}
}

@article{ying2023reward,
  title={Reward Informed Dreamer for Task Generalization in Reinforcement Learning},
  author={Ying, Chengyang and Hao, Zhongkai and Zhou, Xinning and Su, Hang and Liu, Songming and Li, Jialian and Yan, Dong and Zhu, Jun},
  journal={arXiv preprint arXiv:2303.05092},
  year={2023}
}

@InProceedings{dreamerpro,
  title = 	 {{D}reamer{P}ro: Reconstruction-Free Model-Based Reinforcement Learning with Prototypical Representations},
  author =       {Deng, Fei and Jang, Ingook and Ahn, Sungjin},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2022}
}

@inproceedings{
iris,
title={{Transformers} are Sample-Efficient World Models},
author={Vincent Micheli and Eloi Alonso and Fran{\c{c}}ois Fleuret},
booktitle={International Conference on Learning Representations},
year={2023}
}

@inproceedings{
robine2023transformer,
title={{Transformer}-based World Models Are Happy With 100k Interactions},
author={Jan Robine and Marc H{\"o}ftmann and Tobias Uelwer and Stefan Harmeling},
booktitle={International Conference on Learning Representations},
year={2023}
}

% Memory Tasks
@InProceedings{cobbe2020leveraging,
  title = 	 {Leveraging Procedural Generation to Benchmark Reinforcement Learning},
  author =       {Cobbe, Karl and Hesse, Chris and Hilton, Jacob and Schulman, John},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2020}
}

@inproceedings{
lampinen2021towards,
title={Towards mental time travel: a hierarchical memory for reinforcement learning agents},
author={Andrew Kyle Lampinen and Stephanie C.Y. Chan and Andrea Banino and Felix Hill},
booktitle={Advances in Neural Information Processing Systems},
year={2021}
}

@article{wydmuch2018vizdoom,
  title={{ViZDoom} competitions: Playing {Doom} from pixels},
  author={Wydmuch, Marek and Kempka, Micha{\l} and Ja{\'s}kowski, Wojciech},
  journal={IEEE Transactions on Games},
  volume={11},
  number={3},
  pages={248--259},
  year={2018},
  publisher={IEEE}
}

@inproceedings{fortunato2019generalization,
 author = {Fortunato, Meire and Tan, Melissa and Faulkner, Ryan and Hansen, Steven and Puigdom\`{e}nech Badia, Adri\`{a} and Buttimore, Gavin and Deck, Charles and Leibo, Joel Z and Blundell, Charles},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Generalization of Reinforcement Learners with Working and Episodic Memory},
 year = {2019}
}

@article{beattie2016deepmind,
  title={{DeepMind Lab}},
  author={Beattie, Charles and Leibo, Joel Z and Teplyashin, Denis and Ward, Tom and Wainwright, Marcus and K{\"u}ttler, Heinrich and Lefrancq, Andrew and Green, Simon and Vald{\'e}s, V{\'\i}ctor and Sadik, Amir and others},
  journal={arXiv preprint arXiv:1612.03801},
  year={2016}
}

@InProceedings{parisotto2020stabilizing,
  title = 	 {Stabilizing {Transformers} for Reinforcement Learning},
  author =       {Parisotto, Emilio and Song, Francis and Rae, Jack and Pascanu, Razvan and Gulcehre, Caglar and Jayakumar, Siddhant and Jaderberg, Max and Kaufman, Rapha{\"e}l Lopez and Clark, Aidan and Noury, Seb and Botvinick, Matthew and Heess, Nicolas and Hadsell, Raia},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2020}
}

@inproceedings{
crafter,
title={Benchmarking the Spectrum of Agent Capabilities},
author={Danijar Hafner},
booktitle={International Conference on Learning Representations},
year={2022}
}

% backbones
@inproceedings{transformer-xl,
    title = "{Transformer-XL}: Attentive Language Models beyond a Fixed-Length Context",
    author = "Dai, Zihang  and
      Yang, Zhilin  and
      Yang, Yiming  and
      Carbonell, Jaime  and
      Le, Quoc  and
      Salakhutdinov, Ruslan",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    year = "2019"
}

@inproceedings{cwvae,
 author = {Saxena, Vaibhav and Ba, Jimmy and Hafner, Danijar},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Clockwork Variational Autoencoders},
 year = {2021}
}

@inproceedings{fdm,
 author = {Harvey, William and Naderiparizi, Saeid and Masrani, Vaden and Weilbach, Christian and Wood, Frank},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Flexible Diffusion Modeling of Long Videos},
 year = {2022}
}

@InProceedings{teco,
  title = 	 {Temporally Consistent {Transformers} for Video Generation},
  author =       {Yan, Wilson and Hafner, Danijar and James, Stephen and Abbeel, Pieter},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2023}
}

@article{hieros,
  title={Hieros: Hierarchical Imagination on Structured State Space Sequence World Models},
  author={Mattes, Paul and Schlosser, Rainer and Herbrich, Ralf},
  journal={arXiv preprint arXiv:2310.05167},
  year={2023}
}

@inproceedings{vqgan,
  title={Taming {Transformers} for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={CVPR},
  year={2021}
}
