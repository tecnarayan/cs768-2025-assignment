\begin{thebibliography}{10}

\bibitem{tensorflow2015-whitepaper}
Mart\'{\i}n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,
  Craig Citro, Greg~S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin,
  Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard,
  Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh
  Levenberg, Dan Man\'{e}, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah,
  Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar,
  Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi\'{e}gas, Oriol
  Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang
  Zheng.
\newblock {TensorFlow}: Large-scale machine learning on heterogeneous systems,
  2015.
\newblock Software available from tensorflow.org.

\bibitem{tsne_proof}
Sanjeev Arora, Wei Hu, and Pravesh K.~Kothari.
\newblock An analysis of the t-sne algorithm for data visualization.
\newblock In {\em COLT 2018}, 2018.

\bibitem{obfuscated}
Anish Athalye, Nicholas Carlini, and David~A. Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In {\em International Conference on Machine Learning}, pages
  274--283, 2018.

\bibitem{ther-encoding}
Jacob Buckman, Aurko Roy, Colin Raffel, and Ian~J. Goodfellow.
\newblock Thermometer encoding: One hot way to resist adversarial examples.
\newblock In {\em 6th International Conference on Learning Representations},
  2018.

\bibitem{CW}
Nicholas Carlini and David~A. Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In {\em 2017 {IEEE} Symposium on Security and Privacy}, pages 39--57,
  2017.

\bibitem{QuadrupletLoss}
Weihua Chen, Xiaotang Chen, Jianguo Zhang, and Kaiqi Huang.
\newblock Beyond triplet loss: a deep quadruplet network for person
  re-identification.
\newblock {\em CoRR}, abs/1704.01719, 2017.

\bibitem{parseval}
Moustapha Ciss{\'{e}}, Piotr Bojanowski, Edouard Grave, Yann Dauphin, and
  Nicolas Usunier.
\newblock Parseval networks: Improving robustness to adversarial examples.
\newblock In {\em International Conference on Machine Learning}, pages
  854--863, 2017.

\bibitem{SAP}
Guneet~S. Dhillon, Kamyar Azizzadenesheli, Zachary~C. Lipton, Jeremy Bernstein,
  Jean Kossaifi, Aran Khanna, and Animashree Anandkumar.
\newblock Stochastic activation pruning for robust adversarial defense.
\newblock In {\em 6th International Conference on Learning Representations},
  2018.

\bibitem{mim}
Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, and
  Jianguo Li.
\newblock Boosting adversarial attacks with momentum.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 9185--9193, 2018.

\bibitem{DAML}
Yueqi Duan, Wan qing Zheng, Xudong Lin, Jiwen Lu, and Jie Zhou.
\newblock Deep adversarial metric learning.
\newblock {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2780--2789, 2018.

\bibitem{eALP}
Logan Engstrom, Andrew Ilyas, and Anish Athalye.
\newblock Evaluating and understanding the robustness of adversarial logit
  pairing.
\newblock {\em CoRR}, abs/1807.10272, 2018.

\bibitem{corr/GoodfellowSS14}
Ian~J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em CoRR}, abs/1412.6572, 2014.

\bibitem{transform-defense}
Chuan Guo, Mayank Rana, Moustapha Ciss{\'{e}}, and Laurens van~der Maaten.
\newblock Countering adversarial images using input transformations.
\newblock {\em CoRR}, abs/1711.00117, 2017.

\bibitem{SpeechRecognition}
Awni~Y. Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich
  Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, and
  Andrew~Y. Ng.
\newblock Deep speech: Scaling up end-to-end speech recognition.
\newblock {\em CoRR}, abs/1412.5567, 2014.

\bibitem{Triplet2015DeepML}
Elad Hoffer and Nir Ailon.
\newblock Deep metric learning using triplet network.
\newblock In {\em ICLR}, 2015.

\bibitem{ALP}
Harini Kannan, Alexey Kurakin, and Ian~J. Goodfellow.
\newblock Adversarial logit pairing.
\newblock {\em CoRR}, abs/1803.06373, 2018.

\bibitem{Krizhevsky:2012:ICD:2999134.2999257}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em Proceedings of the 25th International Conference on Neural
  Information Processing Systems}, pages 1097--1105, 2012.

\bibitem{BIM}
Alexey Kurakin, Ian~J. Goodfellow, and Samy Bengio.
\newblock Adversarial examples in the physical world.
\newblock {\em CoRR}, abs/1607.02533, 2017.

\bibitem{madry}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In {\em ICLR}, 2018.

\bibitem{PMLUWB}
Chengzhi Mao, Kangbo Lin, Tiancheng Yu, and Yuan Shen.
\newblock A probabilistic learning approach to uwb ranging error mitigation.
\newblock In {\em 2018 IEEE Global Communications Conference (GLOBECOM)}, 2018.

\bibitem{word2vec}
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg~S Corrado, and Jeff Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In {\em Advances in Neural Information Processing Systems 26}, pages
  3111--3119, 2013.

\bibitem{LPfool}
Marius Mosbach, Maksym Andriushchenko, Thomas~Alexander Trost, Matthias Hein,
  and Dietrich Klakow.
\newblock Logit pairing methods can fool gradient-based attacks.
\newblock {\em CoRR}, abs/1810.12042, 2018.

\bibitem{deepfool}
Anh Nguyen, Jason Yosinski, and Jeff Clune.
\newblock Deep neural networks are easily fooled: High confidence predictions
  for unrecognizable images.
\newblock In {\em CVPR}, pages 427--436, 2015.

\bibitem{Lipschitz}
Adam~M. Oberman and Jeff Calder.
\newblock Lipschitz regularized deep neural networks converge and generalize.
\newblock {\em CoRR}, abs/1808.09540, 2018.

\bibitem{PED}
Tianyu Pang, Kun Xu, Chao Du, Ning Chen, and Jun Zhu.
\newblock Improving adversarial robustness via promoting ensemble diversity.
\newblock {\em CoRR}, abs/1901.08846, 2019.

\bibitem{BB_transfer}
Nicolas Papernot, Patrick~D. McDaniel, and Ian~J. Goodfellow.
\newblock Transferability in machine learning: from phenomena to black-box
  attacks using adversarial samples.
\newblock {\em CoRR}, abs/1605.07277, 2016.

\bibitem{JSMA}
Nicolas Papernot, Patrick~D. McDaniel, Somesh Jha, Matt Fredrikson, Z.~Berkay
  Celik, and Ananthram Swami.
\newblock The limitations of deep learning in adversarial settings.
\newblock {\em CoRR}, abs/1511.07528, 2015.

\bibitem{t-sne-medical}
Magdalini Paschali, Sailesh Conjeti, Fernando Navarro, and Nassir Navab.
\newblock Generalizability vs. robustness: Adversarial examples for medical
  imaging.
\newblock {\em CoRR}, abs/1804.00504, 2018.

\bibitem{DeepExplore}
Kexin Pei, Yinzhi Cao, Junfeng Yang, and Suman Jana.
\newblock Deepxplore: Automated whitebox testing of deep learning systems.
\newblock {\em CoRR}, abs/1705.06640, 2017.

\bibitem{t-sne-Quanti}
Adnan~Siraj Rakin, Jinfeng Yi, Boqing Gong, and Deliang Fan.
\newblock Defend deep neural networks against adversarial examples via fixed
  anddynamic quantized activation functions.
\newblock {\em CoRR}, abs/1807.06714, 2018.

\bibitem{DefenseGAN}
Pouya Samangouei, Maya Kabkab, and Rama Chellappa.
\newblock Defense-gan: Protecting classifiers against adversarial attacks using
  generative models.
\newblock {\em CoRR}, abs/1805.06605, 2018.

\bibitem{facenet}
Florian Schroff, Dmitry Kalenichenko, and James Philbin.
\newblock Facenet: {A} unified embedding for face recognition and clustering.
\newblock In {\em CVPR}, pages 815--823, 2015.

\bibitem{t-sne-domain-adaptation}
Chuanbiao Song, Kun He, Liwei Wang, and John~E. Hopcroft.
\newblock Improving the generalization of adversarial training with domain
  adaptation.
\newblock {\em CoRR}, abs/1810.00740, 2018.

\bibitem{liftedTri}
Hyun~Oh Song, Yu~Xiang, Stefanie Jegelka, and Silvio Savarese.
\newblock Deep metric learning via lifted structured feature embedding.
\newblock In {\em {CVPR}}, pages 4004--4012. {IEEE} Computer Society, 2016.

\bibitem{intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian~J. Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In {\em ICLR}, 2014.

\bibitem{deeptest}
Yuchi Tian, Kexin Pei, Suman Jana, and Baishakhi Ray.
\newblock Deeptest: Automated testing of deep-neural-network-driven autonomous
  cars.
\newblock {\em CoRR}, abs/1708.08559, 2017.

\bibitem{ensemble}
Florian Tram{\`{e}}r, Alexey Kurakin, Nicolas Papernot, Dan Boneh, and
  Patrick~D. McDaniel.
\newblock Ensemble adversarial training: Attacks and defenses.
\newblock {\em CoRR}, abs/1705.07204, 2017.

\bibitem{tsipras2018robustness}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
  Aleksander Madry.
\newblock Robustness may be at odds with accuracy.
\newblock {\em stat}, 1050:11, 2018.

\bibitem{unlabeled}
Jonathan Uesato, Jean{-}Baptiste Alayrac, Po{-}Sen Huang, Robert Stanforth,
  Alhussein Fawzi, and Pushmeet Kohli.
\newblock Are labels required for improving adversarial robustness?
\newblock {\em CoRR}, abs/1905.13725, 2019.

\bibitem{vanDerMaaten2008}
Laurens van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using {t-SNE}.
\newblock {\em Journal of Machine Learning Research}, 9:2579--2605, 2008.

\bibitem{BIN}
Hao Wang, Chengzhi Mao, Hao He, Mingmin Zhao, Tommi~S. Jaakkola, and Dina
  Katabi.
\newblock Bidirectional inference networks: {A} class of deep bayesian networks
  for health profiling.
\newblock In {\em The Thirty-Third {AAAI} Conference on Artificial
  Intelligence}, pages 766--773, 2019.

\bibitem{angularloss}
Jian Wang, Feng Zhou, Shilei Wen, Xiao Liu, and Yuanqing Lin.
\newblock Deep metric learning with angular loss.
\newblock In {\em {ICCV}}, pages 2612--2620, 2017.

\bibitem{IntervalAnalysis}
Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana.
\newblock Formal security analysis of neural networks using symbolic intervals.
\newblock {\em CoRR}, abs/1804.10829, 2018.

\bibitem{LMNN}
Kilian~Q. Weinberger and Lawrence~K. Saul.
\newblock Distance metric learning for large margin nearest neighbor
  classification.
\newblock {\em Journal of Machine Learning Research}, 10:207--244, 2009.

\bibitem{confidence}
Xi~Wu, Uyeong Jang, Jiefeng Chen, Lingjiao Chen, and Somesh Jha.
\newblock Reinforcing adversarial robustness using model confidence induced by
  adversarial training.
\newblock In {\em {ICML}}, volume~80, pages 5330--5338, 2018.

\bibitem{feature_denoising}
Cihang Xie, Yuxin Wu, Laurens van~der Maaten, Alan~L. Yuille, and Kaiming He.
\newblock Feature denoising for improving adversarial robustness.
\newblock {\em CoRR}, abs/1812.03411, 2018.

\bibitem{deepdefense}
Ziang Yan, Yiwen Guo, and Changshui Zhang.
\newblock Deep defense: Training dnns with improved adversarial robustness.
\newblock In {\em Proceedings of the 32Nd International Conference on Neural
  Information Processing Systems}, pages 417--426, 2018.

\bibitem{yang2019menet}
Yuzhe Yang, Guo Zhang, Dina Katabi, and Zhi Xu.
\newblock Me-net: Towards effective adversarial robustness with matrix
  estimation.
\newblock In {\em Proceedings of the 36th International Conference on Machine
  Learning, {ICML} 2019}, 2019.

\bibitem{TRADES}
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric~P. Xing, Laurent~El Ghaoui, and
  Michael~I. Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock {\em CoRR}, abs/1901.08573, 2019.

\bibitem{stability_training}
Stephan Zheng, Yang Song, Thomas Leung, and Ian~J. Goodfellow.
\newblock Improving the robustness of deep neural networks via stability
  training.
\newblock In {\em 2016 {IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR}}, pages 4480--4488, 2016.

\bibitem{HardnessAware}
Wenzhao Zheng, Zhaodong Chen, Jiwen Lu, and Jie Zhou.
\newblock Hardness-aware deep metric learning.
\newblock {\em CoRR}, abs/1903.05503, 2019.

\bibitem{NIPS2018_8016}
Zhihao Zheng and Pengyu Hong.
\newblock Robust detection of adversarial attacks by modeling the intrinsic
  properties of deep neural networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  7913--7922. 2018.

\end{thebibliography}
