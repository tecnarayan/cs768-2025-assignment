\begin{thebibliography}{10}

\bibitem{alayrac2022flamingo}
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et~al.
\newblock Flamingo: a visual language model for few-shot learning.
\newblock {\em Advances in Neural Information Processing Systems}, 35:23716--23736, 2022.

\bibitem{bengio2013representation}
Yoshua Bengio, Aaron Courville, and Pascal Vincent.
\newblock Representation learning: A review and new perspectives.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence}, 35(8):1798--1828, 2013.

\bibitem{bommasani2021opportunities}
Rishi Bommasani, Drew~A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael~S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et~al.
\newblock On the opportunities and risks of foundation models.
\newblock {\em arXiv preprint arXiv:2108.07258}, 2021.

\bibitem{bonatti2023pact}
Rogerio Bonatti, Sai Vemprala, Shuang Ma, Felipe Frujeri, Shuhang Chen, and Ashish Kapoor.
\newblock Pact: Perception-action causal transformer for autoregressive robotics pre-training.
\newblock In {\em 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, pages 3621--3627. IEEE, 2023.

\bibitem{brohan2023rt}
Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Xi~Chen, Krzysztof Choromanski, Tianli Ding, Danny Driess, Avinava Dubey, Chelsea Finn, et~al.
\newblock Rt-2: Vision-language-action models transfer web knowledge to robotic control.
\newblock {\em arXiv preprint arXiv:2307.15818}, 2023.

\bibitem{brohan2022rt}
Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Joseph Dabis, Chelsea Finn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Jasmine Hsu, et~al.
\newblock Rt-1: Robotics transformer for real-world control at scale.
\newblock {\em arXiv preprint arXiv:2212.06817}, 2022.

\bibitem{videoworldsimulators2024}
Tim Brooks, Bill Peebles, Connor Holmes, Will DePue, Yufei Guo, Li~Jing, David Schnurr, Joe Taylor, Troy Luhman, Eric Luhman, Clarence Ng, Ricky Wang, and Aditya Ramesh.
\newblock Video generation models as world simulators.
\newblock 2024.

\bibitem{cadene2024lerobot}
Remi Cadene, Simon Alibert, Alexander Soare, Quentin Gallouedec, Adil Zouitine, and Thomas Wolf.
\newblock Lerobot: State-of-the-art machine learning for real-world robotics in pytorch.
\newblock \url{https://github.com/huggingface/lerobot}, 2024.

\bibitem{carion2020end}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em European conference on computer vision}, pages 213--229. Springer, 2020.

\bibitem{caron2020unsupervised}
Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, and Armand Joulin.
\newblock Unsupervised learning of visual features by contrasting cluster assignments.
\newblock {\em Advances in Neural Information Processing Systems}, 33:9912--9924, 2020.

\bibitem{chen2024spatialvlm}
Boyuan Chen, Zhuo Xu, Sean Kirmani, Brian Ichter, Danny Driess, Pete Florence, Dorsa Sadigh, Leonidas Guibas, and Fei Xia.
\newblock Spatialvlm: Endowing vision-language models with spatial reasoning capabilities.
\newblock {\em arXiv preprint arXiv:2401.12168}, 2024.

\bibitem{chen2021exploring}
Xinlei Chen and Kaiming He.
\newblock Exploring simple siamese representation learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 15750--15758, 2021.

\bibitem{chi2023diffusion}
Cheng Chi, Siyuan Feng, Yilun Du, Zhenjia Xu, Eric Cousineau, Benjamin Burchfiel, and Shuran Song.
\newblock Diffusion policy: Visuomotor policy learning via action diffusion.
\newblock {\em arXiv preprint arXiv:2303.04137}, 2023.

\bibitem{open_x_embodiment_rt_x_2023}
Open X-Embodiment Collaboration.
\newblock Open {X-E}mbodiment: Robotic learning datasets and {RT-X} models.
\newblock \url{https://robotics-transformer-x.github.io}, 2023.

\bibitem{Damen2018EPICKITCHENS}
Dima Damen, Hazel Doughty, Giovanni~Maria Farinella, Sanja Fidler, Antonino Furnari, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, and Michael Wray.
\newblock Scaling egocentric vision: The epic-kitchens dataset.
\newblock In {\em European Conference on Computer Vision (ECCV)}, 2018.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern recognition}, pages 248--255. Ieee, 2009.

\bibitem{el2024scalable}
Alaaeldin El-Nouby, Michal Klein, Shuangfei Zhai, Miguel~Angel Bautista, Alexander Toshev, Vaishaal Shankar, Joshua~M Susskind, and Armand Joulin.
\newblock Scalable pre-training of large autoregressive image models.
\newblock {\em arXiv preprint arXiv:2401.08541}, 2024.

\bibitem{finn2017model}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In {\em International conference on machine learning}, pages 1126--1135. PMLR, 2017.

\bibitem{girdhar2023imagebind}
Rohit Girdhar, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan~Vasudev Alwala, Armand Joulin, and Ishan Misra.
\newblock Imagebind: One embedding space to bind them all.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 15180--15190, 2023.

\bibitem{gong2023arnold}
Ran Gong, Jiangyong Huang, Yizhou Zhao, Haoran Geng, Xiaofeng Gao, Qingyang Wu, Wensi Ai, Ziheng Zhou, Demetri Terzopoulos, Song-Chun Zhu, et~al.
\newblock Arnold: A benchmark for language-grounded task learning with continuous states in realistic 3d scenes.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, 2023.

\bibitem{grill2020bootstrap}
Jean-Bastien Grill, Florian Strub, Florent Altch{\'e}, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila~Pires, Zhaohan Guo, Mohammad Gheshlaghi~Azar, et~al.
\newblock Bootstrap your own latent-a new approach to self-supervised learning.
\newblock {\em Advances in Neural Information Processing Systems}, 33:21271--21284, 2020.

\bibitem{haldar2024baku}
Siddhant Haldar, Zhuoran Peng, and Lerrel Pinto.
\newblock Baku: An efficient transformer for multi-task policy learning.
\newblock {\em arXiv preprint arXiv:2406.07539}, 2024.

\bibitem{he2021masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock {\em arXiv preprint arXiv:2111.06377}, 2021.

\bibitem{he2020momentum}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 9729--9738, 2020.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 770--778, 2016.

\bibitem{henighan2020scaling}
Tom Henighan, Jared Kaplan, Mor Katz, Mark Chen, Christopher Hesse, Jacob Jackson, Heewoo Jun, Tom~B Brown, Prafulla Dhariwal, Scott Gray, et~al.
\newblock Scaling laws for autoregressive generative modeling.
\newblock {\em arXiv preprint arXiv:2010.14701}, 2020.

\bibitem{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock {\em Advances in neural information processing systems}, 33:6840--6851, 2020.

\bibitem{hoffmann2022training}
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de~Las Casas, Lisa~Anne Hendricks, Johannes Welbl, Aidan Clark, et~al.
\newblock Training compute-optimal large language models.
\newblock {\em arXiv preprint arXiv:2203.15556}, 2022.

\bibitem{huyen2023evaluation}
Chip Huyen.
\newblock Understanding evaluation metrics for language models.
\newblock {\em The Gradient}, 2023.

\bibitem{jaegle2021perceiver}
Andrew Jaegle, Sebastian Borgeaud, Jean-Baptiste Alayrac, Carl Doersch, Catalin Ionescu, David Ding, Skanda Koppula, Daniel Zoran, Andrew Brock, Evan Shelhamer, et~al.
\newblock Perceiver io: A general architecture for structured inputs \& outputs.
\newblock {\em arXiv preprint arXiv:2107.14795}, 2021.

\bibitem{jiang2024mixtral}
Albert~Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra~Singh Chaplot, Diego de~las Casas, Emma~Bou Hanna, Florian Bressand, et~al.
\newblock Mixtral of experts.
\newblock {\em arXiv preprint arXiv:2401.04088}, 2024.

\bibitem{jiang2023vima}
Yunfan Jiang, Agrim Gupta, Zichen Zhang, Guanzhi Wang, Yongqiang Dou, Yanjun Chen, Li~Fei-Fei, Anima Anandkumar, Yuke Zhu, and Linxi Fan.
\newblock Vima: Robot manipulation with multimodal prompts.
\newblock 2023.

\bibitem{kaplan2020scaling}
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom~B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.
\newblock Scaling laws for neural language models.
\newblock {\em arXiv preprint arXiv:2001.08361}, 2020.

\bibitem{karamcheti2023language}
Siddharth Karamcheti, Suraj Nair, Annie~S Chen, Thomas Kollar, Chelsea Finn, Dorsa Sadigh, and Percy Liang.
\newblock Language-driven representation learning for robotics.
\newblock {\em arXiv preprint arXiv:2302.12766}, 2023.

\bibitem{kim2024openvla}
Moo~Jin Kim, Karl Pertsch, Siddharth Karamcheti, Ted Xiao, Ashwin Balakrishna, Suraj Nair, Rafael Rafailov, Ethan Foster, Grace Lam, Pannag Sanketi, et~al.
\newblock Openvla: An open-source vision-language-action model.
\newblock {\em arXiv preprint arXiv:2406.09246}, 2024.

\bibitem{kirillov2023segment}
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander~C Berg, Wan-Yen Lo, et~al.
\newblock Segment anything.
\newblock {\em arXiv preprint arXiv:2304.02643}, 2023.

\bibitem{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock {\em Advances in neural information processing systems}, 25, 2012.

\bibitem{frodobots2024frodobots2k}
FrodoBots Lab.
\newblock Frodobots-2k dataset.
\newblock \url{https://huggingface.co/datasets/frodobots/FrodoBots-2K}, 2024.
\newblock Accessed: 2024-05-27.

\bibitem{lee2024behavior}
Seungjae Lee, Yibin Wang, Haritheja Etukuru, H~Jin Kim, Nur Muhammad~Mahi Shafiullah, and Lerrel Pinto.
\newblock Behavior generation with latent actions.
\newblock {\em arXiv preprint arXiv:2403.03181}, 2024.

\bibitem{levine2016end}
Sergey Levine, Chelsea Finn, Trevor Darrell, and Pieter Abbeel.
\newblock End-to-end training of deep visuomotor policies.
\newblock {\em The Journal of Machine Learning Research}, 17(1):1334--1373, 2016.

\bibitem{li2023blip}
Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.
\newblock Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models.
\newblock {\em arXiv preprint arXiv:2301.12597}, 2023.

\bibitem{li24simpler}
Xuanlin Li, Kyle Hsu, Jiayuan Gu, Karl Pertsch, Oier Mees, Homer~Rich Walke, Chuyuan Fu, Ishikaa Lunawat, Isabel Sieh, Sean Kirmani, Sergey Levine, Jiajun Wu, Chelsea Finn, Hao Su, Quan Vuong, and Ted Xiao.
\newblock Evaluating real-world robot manipulation policies in simulation.
\newblock {\em arXiv preprint arXiv:2405.05941}, 2024.

\bibitem{lin2024moma}
Xi~Victoria Lin, Akshat Shrivastava, Liang Luo, Srinivasan Iyer, Mike Lewis, Gargi Gosh, Luke Zettlemoyer, and Armen Aghajanyan.
\newblock Moma: Efficient early-fusion pre-training with mixture of modality-aware experts.
\newblock {\em arXiv preprint arXiv:2407.21770}, 2024.

\bibitem{liu2023visual}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock {\em arXiv preprint arXiv:2304.08485}, 2023.

\bibitem{liu2024visual}
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong~Jae Lee.
\newblock Visual instruction tuning.
\newblock {\em Advances in neural information processing systems}, 36, 2024.

\bibitem{loshchilov2017decoupled}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock {\em arXiv preprint arXiv:1711.05101}, 2017.

\bibitem{lynch2023interactive}
Corey Lynch, Ayzaan Wahid, Jonathan Tompson, Tianli Ding, James Betker, Robert Baruch, Travis Armstrong, and Pete Florence.
\newblock Interactive language: Talking to robots in real time.
\newblock {\em IEEE Robotics and Automation Letters}, 2023.

\bibitem{vc2023}
Arjun Majumdar, Karmesh Yadav, Sergio Arnaud, Yecheng~Jason Ma, Claire Chen, Sneha Silwal, Aryan Jain, Vincent-Pierre Berges, Pieter Abbeel, Jitendra Malik, Dhruv Batra, Yixin Lin, Oleksandr Maksymets, Aravind Rajeswaran, and Franziska Meier.
\newblock Where are we in the search for an artificial visual cortex for embodied intelligence?
\newblock 2023.

\bibitem{robomimic2021}
Ajay Mandlekar, Danfei Xu, Josiah Wong, Soroush Nasiriany, Chen Wang, Rohun Kulkarni, Li~Fei-Fei, Silvio Savarese, Yuke Zhu, and Roberto Mart\'{i}n-Mart\'{i}n.
\newblock What matters in learning from offline human demonstrations for robot manipulation.
\newblock In {\em Conference on Robot Learning (CoRL)}, 2021.

\bibitem{masoudnia2014mixture}
Saeed Masoudnia and Reza Ebrahimpour.
\newblock Mixture of experts: a literature survey.
\newblock {\em Artificial Intelligence Review}, 42:275--293, 2014.

\bibitem{mckinzie2024mm1}
Brandon McKinzie, Zhe Gan, Jean-Philippe Fauconnier, Sam Dodge, Bowen Zhang, Philipp Dufter, Dhruti Shah, Xianzhi Du, Futang Peng, Floris Weers, et~al.
\newblock Mm1: Methods, analysis \& insights from multimodal llm pre-training.
\newblock {\em arXiv preprint arXiv:2403.09611}, 2024.

\bibitem{mu2021maniskill}
Tongzhou Mu, Zhan Ling, Fanbo Xiang, Derek Yang, Xuanlin Li, Stone Tao, Zhiao Huang, Zhiwei Jia, and Hao Su.
\newblock Maniskill: Generalizable manipulation skill benchmark with large-scale demonstrations.
\newblock {\em arXiv preprint arXiv:2107.14483}, 2021.

\bibitem{nair2022r3m}
Suraj Nair, Aravind Rajeswaran, Vikash Kumar, Chelsea Finn, and Abhinav Gupta.
\newblock R3m: A universal visual representation for robot manipulation.
\newblock {\em arXiv preprint arXiv:2203.12601}, 2022.

\bibitem{nichol2018first}
Alex Nichol, Joshua Achiam, and John Schulman.
\newblock On first-order meta-learning algorithms.
\newblock {\em arXiv preprint arXiv:1803.02999}, 2018.

\bibitem{octo_2023}
{Octo Model Team}, Dibya Ghosh, Homer Walke, Karl Pertsch, Kevin Black, Oier Mees, Sudeep Dasari, Joey Hejna, Charles Xu, Jianlan Luo, Tobias Kreiman, {You Liang} Tan, Dorsa Sadigh, Chelsea Finn, and Sergey Levine.
\newblock Octo: An open-source generalist robot policy.
\newblock \url{https://octo-models.github.io}, 2023.

\bibitem{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock {\em arXiv preprint arXiv:1807.03748}, 2018.

\bibitem{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2023.

\bibitem{oquab2023dinov2}
Maxime Oquab, Timoth{\'e}e Darcet, Th{\'e}o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et~al.
\newblock Dinov2: Learning robust visual features without supervision.
\newblock {\em arXiv preprint arXiv:2304.07193}, 2023.

\bibitem{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.
\newblock {\em OpenAI blog}, 1(8):9, 2019.

\bibitem{radosavovic2023robot}
Ilija Radosavovic, Baifeng Shi, Letian Fu, Ken Goldberg, Trevor Darrell, and Jitendra Malik.
\newblock Robot learning with sensorimotor pre-training.
\newblock In {\em Conference on Robot Learning}, pages 683--693. PMLR, 2023.

\bibitem{radosavovic2023real}
Ilija Radosavovic, Tete Xiao, Stephen James, Pieter Abbeel, Jitendra Malik, and Trevor Darrell.
\newblock Real-world robot learning with masked visual pre-training.
\newblock In {\em Conference on Robot Learning}, pages 416--426. PMLR, 2023.

\bibitem{radosavovic2024humanoid}
Ilija Radosavovic, Bike Zhang, Baifeng Shi, Jathushan Rajasegaran, Sarthak Kamat, Trevor Darrell, Koushil Sreenath, and Jitendra Malik.
\newblock Humanoid locomotion as next token prediction.
\newblock {\em arXiv preprint arXiv:2402.19469}, 2024.

\bibitem{raffel2020exploring}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter~J Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text transformer.
\newblock {\em Journal of machine learning research}, 21(140):1--67, 2020.

\bibitem{reed2022generalist}
Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio~Gomez Colmenarejo, Alexander Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay, Jost~Tobias Springenberg, et~al.
\newblock A generalist agent.
\newblock {\em arXiv preprint arXiv:2205.06175}, 2022.

\bibitem{ruder2017overview}
Sebastian Ruder.
\newblock An overview of multi-task learning in deep neural networks.
\newblock {\em arXiv preprint arXiv:1706.05098}, 2017.

\bibitem{salhotra2022learning}
Gautam Salhotra, I-Chun~Arthur Liu, Marcus Dominguez-Kuhne, and Gaurav~S Sukhatme.
\newblock Learning deformable object manipulation from expert demonstrations.
\newblock {\em IEEE Robotics and Automation Letters}, 7(4):8775--8782, 2022.

\bibitem{saxena2023multi}
Saumya Saxena, Mohit Sharma, and Oliver Kroemer.
\newblock Multi-resolution sensing for real-time control with vision-language models.
\newblock In {\em 2nd Workshop on Language and Robot Learning: Language as Grounding}, 2023.

\bibitem{seminara2023hierarchical}
Lucia Seminara, Strahinja Dosen, Fulvio Mastrogiovanni, Matteo Bianchi, Simon Watt, Philipp Beckerle, Thrishantha Nanayakkara, Knut Drewing, Alessandro Moscatelli, Roberta~L Klatzky, et~al.
\newblock A hierarchical sensorimotor control framework for human-in-the-loop robotic hands.
\newblock {\em Science Robotics}, 8(78):eadd5434, 2023.

\bibitem{seo2023masked}
Younggyo Seo, Danijar Hafner, Hao Liu, Fangchen Liu, Stephen James, Kimin Lee, and Pieter Abbeel.
\newblock Masked world models for visual control.
\newblock In {\em Conference on Robot Learning}, pages 1332--1344. PMLR, 2023.

\bibitem{shah2023mutex}
Rutav Shah, Roberto Mart{\'\i}n-Mart{\'\i}n, and Yuke Zhu.
\newblock Mutex: Learning unified policies from multimodal task specifications.
\newblock {\em arXiv preprint arXiv:2309.14320}, 2023.

\bibitem{shazeer2017outrageously}
Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean.
\newblock Outrageously large neural networks: The sparsely-gated mixture-of-experts layer.
\newblock {\em arXiv preprint arXiv:1701.06538}, 2017.

\bibitem{shridhar2023perceiver}
Mohit Shridhar, Lucas Manuelli, and Dieter Fox.
\newblock Perceiver-actor: A multi-task transformer for robotic manipulation.
\newblock In {\em Conference on Robot Learning}, pages 785--799. PMLR, 2023.

\bibitem{tay2021omninet}
Yi~Tay, Mostafa Dehghani, Vamsi Aribandi, Jai Gupta, Philip~M Pham, Zhen Qin, Dara Bahri, Da-Cheng Juan, and Donald Metzler.
\newblock Omninet: Omnidirectional representations from transformers.
\newblock In {\em International Conference on Machine Learning}, pages 10193--10202. PMLR, 2021.

\bibitem{chameleonteam2024chameleon}
Chameleon Team.
\newblock Chameleon: Mixed-modal early-fusion foundation models, 2024.

\bibitem{khazatsky2024droid}
DROID Team.
\newblock Droid: A large-scale in-the-wild robot manipulation dataset.
\newblock 2024.

\bibitem{team2023gemini}
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew~M Dai, Anja Hauth, et~al.
\newblock Gemini: a family of highly capable multimodal models.
\newblock {\em arXiv preprint arXiv:2312.11805}, 2023.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{vilalta2002perspective}
Ricardo Vilalta and Youssef Drissi.
\newblock A perspective view and survey of meta-learning.
\newblock {\em Artificial intelligence review}, 18:77--95, 2002.

\bibitem{wang2023gensim}
Lirui Wang, Yiyang Ling, Zhecheng Yuan, Mohit Shridhar, Chen Bao, Yuzhe Qin, Bailin Wang, Huazhe Xu, and Xiaolong Wang.
\newblock Gensim: Generating robotic simulation tasks via large language models.
\newblock {\em arXiv preprint arXiv:2310.01361}, 2023.

\bibitem{wang2022goal}
Lirui Wang, Yu~Xiang, Wei Yang, Arsalan Mousavian, and Dieter Fox.
\newblock Goal-auxiliary actor-critic for 6d robotic grasping with point clouds.
\newblock In {\em Conference on Robot Learning}, pages 70--80. PMLR, 2022.

\bibitem{wang2023fleet}
Lirui Wang, Kaiqing Zhang, Allan Zhou, Max Simchowitz, and Russ Tedrake.
\newblock Fleet policy learning via weight merging and an application to robotic tool-use, 2024.

\bibitem{wang2023poco}
Lirui Wang, Jialiang Zhao, Yilun Du, Edward Adelson, and Russ Tedrake.
\newblock Poco: Policy composition from and for heterogeneous robot learning, 2024.

\bibitem{wang2020generalizing}
Yaqing Wang, Quanming Yao, James~T Kwok, and Lionel~M Ni.
\newblock Generalizing from a few examples: A survey on few-shot learning.
\newblock {\em ACM computing surveys (csur)}, 53(3):1--34, 2020.

\bibitem{wu2023masked}
Philipp Wu, Arjun Majumdar, Kevin Stone, Yixin Lin, Igor Mordatch, Pieter Abbeel, and Aravind Rajeswaran.
\newblock Masked trajectory models for prediction, representation, and control.
\newblock {\em arXiv preprint arXiv:2305.02968}, 2023.

\bibitem{wuthrich2020trifinger}
Manuel W{\"u}thrich, Felix Widmaier, Felix Grimminger, Joel Akpo, Shruti Joshi, Vaibhav Agrawal, Bilal Hammoud, Majid Khadiv, Miroslav Bogdanovic, Vincent Berenz, et~al.
\newblock Trifinger: An open-source robot for learning dexterity.
\newblock {\em arXiv preprint arXiv:2008.03596}, 2020.

\bibitem{yang2024pushing}
Jonathan Yang, Catherine Glossop, Arjun Bhorkar, Dhruv Shah, Quan Vuong, Chelsea Finn, Dorsa Sadigh, and Sergey Levine.
\newblock Pushing the limits of cross-embodiment learning for manipulation and navigation.
\newblock {\em arXiv preprint arXiv:2402.19432}, 2024.

\bibitem{yang2023polybot}
Jonathan Yang, Dorsa Sadigh, and Chelsea Finn.
\newblock Polybot: Training one policy across robots while embracing variability.
\newblock {\em arXiv preprint arXiv:2307.03719}, 2023.

\bibitem{ye2024x}
Hanrong Ye, De-An Huang, Yao Lu, Zhiding Yu, Wei Ping, Andrew Tao, Jan Kautz, Song Han, Dan Xu, Pavlo Molchanov, et~al.
\newblock X-vila: Cross-modality alignment for large language model.
\newblock {\em arXiv preprint arXiv:2405.19335}, 2024.

\bibitem{yu2020meta}
Tianhe Yu, Deirdre Quillen, Zhanpeng He, Ryan Julian, Karol Hausman, Chelsea Finn, and Sergey Levine.
\newblock Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning.
\newblock In {\em Conference on robot learning}, pages 1094--1100. PMLR, 2020.

\bibitem{zhao2024transferable}
Jialiang Zhao, Yuxiang Ma, Lirui Wang, and Edward~H Adelson.
\newblock Transferable tactile transformers for representation learning across diverse sensors and tasks.
\newblock {\em arXiv preprint arXiv:2406.13640}, 2024.

\bibitem{zhao2023learning}
Tony~Z Zhao, Vikash Kumar, Sergey Levine, and Chelsea Finn.
\newblock Learning fine-grained bimanual manipulation with low-cost hardware.
\newblock {\em arXiv preprint arXiv:2304.13705}, 2023.

\end{thebibliography}
