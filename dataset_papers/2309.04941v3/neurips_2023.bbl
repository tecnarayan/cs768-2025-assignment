\begin{thebibliography}{61}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abboud et~al.(2020)Abboud, Ceylan, Grohe, and
  Lukasiewicz]{abboud2020surprising}
Ralph Abboud, Ismail~Ilkan Ceylan, Martin Grohe, and Thomas Lukasiewicz.
\newblock The surprising power of graph neural networks with random node
  initialization.
\newblock \emph{arXiv preprint arXiv:2010.01179}, 2020.

\bibitem[Alon et~al.(1997)Alon, Yuster, and Zwick]{alon1997finding}
Noga Alon, Raphael Yuster, and Uri Zwick.
\newblock Finding and counting given length cycles.
\newblock \emph{Algorithmica}, 17\penalty0 (3):\penalty0 209--223, 1997.

\bibitem[Anderson et~al.(2019)Anderson, Hy, and Kondor]{anderson2019cormorant}
Brandon Anderson, Truong~Son Hy, and Risi Kondor.
\newblock Cormorant: Covariant molecular neural networks.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Arvind et~al.(2020{\natexlab{a}})Arvind, Fuhlbrück, Köbler, and
  Verbitsky]{ARVIND202042}
V.~Arvind, Frank Fuhlbrück, Johannes Köbler, and Oleg Verbitsky.
\newblock On weisfeiler-leman invariance: Subgraph counts and related graph
  properties.
\newblock \emph{Journal of Computer and System Sciences}, 113:\penalty0 42--59,
  2020{\natexlab{a}}.
\newblock ISSN 0022-0000.
\newblock \doi{https://doi.org/10.1016/j.jcss.2020.04.003}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S0022000020300386}.

\bibitem[Arvind et~al.(2020{\natexlab{b}})Arvind, Fuhlbr{\"u}ck, K{\"o}bler,
  and Verbitsky]{arvind2020weisfeiler}
Vikraman Arvind, Frank Fuhlbr{\"u}ck, Johannes K{\"o}bler, and Oleg Verbitsky.
\newblock On weisfeiler-leman invariance: Subgraph counts and related graph
  properties.
\newblock \emph{Journal of Computer and System Sciences}, 113:\penalty0 42--59,
  2020{\natexlab{b}}.

\bibitem[Balcilar et~al.(2021)Balcilar, H{\'e}roux, Gauzere, Vasseur, Adam, and
  Honeine]{balcilar2021breaking}
Muhammet Balcilar, Pierre H{\'e}roux, Benoit Gauzere, Pascal Vasseur,
  S{\'e}bastien Adam, and Paul Honeine.
\newblock Breaking the limits of message passing graph neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  599--608. PMLR, 2021.

\bibitem[Beaini et~al.(2021)Beaini, Passaro, L{\'e}tourneau, Hamilton, Corso,
  and Li{\`o}]{beaini2021directional}
Dominique Beaini, Saro Passaro, Vincent L{\'e}tourneau, Will Hamilton, Gabriele
  Corso, and Pietro Li{\`o}.
\newblock Directional graph networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  748--758. PMLR, 2021.

\bibitem[Bevilacqua et~al.(2022)Bevilacqua, Frasca, Lim, Srinivasan, Cai,
  Balamurugan, Bronstein, and Maron]{bevilacqua2022equivariant}
Beatrice Bevilacqua, Fabrizio Frasca, Derek Lim, Balasubramaniam Srinivasan,
  Chen Cai, Gopinath Balamurugan, Michael~M Bronstein, and Haggai Maron.
\newblock Equivariant subgraph aggregation networks.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Bodnar et~al.(2021)Bodnar, Frasca, Otter, Wang, Lio, Montufar, and
  Bronstein]{bodnar2021weisfeiler}
Cristian Bodnar, Fabrizio Frasca, Nina Otter, Yuguang Wang, Pietro Lio, Guido~F
  Montufar, and Michael Bronstein.
\newblock Weisfeiler and lehman go cellular: Cw networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 2625--2640, 2021.

\bibitem[Bouritsas et~al.(2022)Bouritsas, Frasca, Zafeiriou, and
  Bronstein]{bouritsas2022improving}
Giorgos Bouritsas, Fabrizio Frasca, Stefanos Zafeiriou, and Michael~M
  Bronstein.
\newblock Improving graph neural network expressivity via subgraph isomorphism
  counting.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 45\penalty0 (1):\penalty0 657--668, 2022.

\bibitem[Bresson and Laurent(2017)]{bresson2017residual}
Xavier Bresson and Thomas Laurent.
\newblock Residual gated graph convnets.
\newblock \emph{arXiv preprint arXiv:1711.07553}, 2017.

\bibitem[Cai et~al.(1992)Cai, F{\"u}rer, and Immerman]{cai1992optimal}
Jin-Yi Cai, Martin F{\"u}rer, and Neil Immerman.
\newblock An optimal lower bound on the number of variables for graph
  identification.
\newblock \emph{Combinatorica}, 12\penalty0 (4):\penalty0 389--410, 1992.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Wei, Huang, Ding, and
  Li]{chen2020simple}
Ming Chen, Zhewei Wei, Zengfeng Huang, Bolin Ding, and Yaliang Li.
\newblock Simple and deep graph convolutional networks.
\newblock In \emph{International conference on machine learning}, pages
  1725--1735. PMLR, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2019)Chen, Villar, Chen, and Bruna]{chen2019equivalence}
Zhengdao Chen, Soledad Villar, Lei Chen, and Joan Bruna.
\newblock On the equivalence between graph isomorphism testing and function
  approximation with gnns.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Chen, Villar, and
  Bruna]{chen2020can}
Zhengdao Chen, Lei Chen, Soledad Villar, and Joan Bruna.
\newblock Can graph neural networks count substructures?
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 10383--10395, 2020{\natexlab{b}}.

\bibitem[Corso et~al.(2020)Corso, Cavalleri, Beaini, Li{\`o}, and
  Veli{\v{c}}kovi{\'c}]{corso2020principal}
Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Li{\`o}, and Petar
  Veli{\v{c}}kovi{\'c}.
\newblock Principal neighbourhood aggregation for graph nets.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 13260--13271, 2020.

\bibitem[Cotta et~al.(2021)Cotta, Morris, and Ribeiro]{cotta2021reconstruction}
Leonardo Cotta, Christopher Morris, and Bruno Ribeiro.
\newblock Reconstruction for powerful graph representations.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 1713--1726, 2021.

\bibitem[Deshpande et~al.(2002)Deshpande, Kuramochi, and
  Karypis]{deshpande2002automated}
Mukund Deshpande, Michihiro Kuramochi, and George Karypis.
\newblock Automated approaches for classifying structures.
\newblock Technical report, MINNESOTA UNIV MINNEAPOLIS DEPT OF COMPUTER
  SCIENCE, 2002.

\bibitem[Dwivedi and Bresson(2020)]{dwivedi2020generalization}
Vijay~Prakash Dwivedi and Xavier Bresson.
\newblock A generalization of transformer networks to graphs.
\newblock \emph{arXiv preprint arXiv:2012.09699}, 2020.

\bibitem[Dwivedi et~al.(2020)Dwivedi, Joshi, Laurent, Bengio, and
  Bresson]{dwivedi2020benchmarking}
Vijay~Prakash Dwivedi, Chaitanya~K Joshi, Thomas Laurent, Yoshua Bengio, and
  Xavier Bresson.
\newblock Benchmarking graph neural networks.
\newblock 2020.

\bibitem[Dwivedi et~al.(2022)Dwivedi, Ramp{\'a}{\v{s}}ek, Galkin, Parviz, Wolf,
  Luu, and Beaini]{dwivedi2022long}
Vijay~Prakash Dwivedi, Ladislav Ramp{\'a}{\v{s}}ek, Michael Galkin, Ali Parviz,
  Guy Wolf, Anh~Tuan Luu, and Dominique Beaini.
\newblock Long range graph benchmark.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 22326--22340, 2022.

\bibitem[Fey and Lenssen(2019)]{fey2019fast}
Matthias Fey and Jan~Eric Lenssen.
\newblock Fast graph representation learning with pytorch geometric.
\newblock \emph{arXiv preprint arXiv:1903.02428}, 2019.

\bibitem[Fey et~al.(2020)Fey, Yuen, and Weichert]{fey2020hierarchical}
Matthias Fey, Jan-Gin Yuen, and Frank Weichert.
\newblock Hierarchical inter-message passing for learning on molecular graphs.
\newblock \emph{arXiv preprint arXiv:2006.12179}, 2020.

\bibitem[Frasca et~al.(2022)Frasca, Bevilacqua, Bronstein, and
  Maron]{frascaunderstanding2022}
Fabrizio Frasca, Beatrice Bevilacqua, Michael~M Bronstein, and Haggai Maron.
\newblock Understanding and extending subgraph gnns by rethinking their
  symmetries.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[F{\"u}rer(2017)]{furer2017combinatorial}
Martin F{\"u}rer.
\newblock On the combinatorial power of the weisfeiler-lehman algorithm.
\newblock In \emph{International Conference on Algorithms and Complexity},
  pages 260--271. Springer, 2017.

\bibitem[Gasteiger et~al.(2020)Gasteiger, Gro{\ss}, and
  G{\"u}nnemann]{gasteiger2020directional}
Johannes Gasteiger, Janek Gro{\ss}, and Stephan G{\"u}nnemann.
\newblock Directional message passing for molecular graphs.
\newblock \emph{arXiv preprint arXiv:2003.03123}, 2020.

\bibitem[Gilmer et~al.(2017)Gilmer, Schoenholz, Riley, Vinyals, and
  Dahl]{gilmer2017neural}
Justin Gilmer, Samuel~S Schoenholz, Patrick~F Riley, Oriol Vinyals, and
  George~E Dahl.
\newblock Neural message passing for quantum chemistry.
\newblock In \emph{International conference on machine learning}, pages
  1263--1272. PMLR, 2017.

\bibitem[Grohe and Otto(2015)]{grohe2015pebble}
Martin Grohe and Martin Otto.
\newblock Pebble games and linear equations.
\newblock \emph{The Journal of Symbolic Logic}, 80\penalty0 (3):\penalty0
  797--844, 2015.

\bibitem[Hermosilla et~al.(2020)Hermosilla, Sch{\"a}fer, Lang, Fackelmann,
  V{\'a}zquez, Kozl{\'\i}kov{\'a}, Krone, Ritschel, and
  Ropinski]{hermosilla2020intrinsic}
Pedro Hermosilla, Marco Sch{\"a}fer, Mat{\v{e}}j Lang, Gloria Fackelmann,
  Pere~Pau V{\'a}zquez, Barbora Kozl{\'\i}kov{\'a}, Michael Krone, Tobias
  Ritschel, and Timo Ropinski.
\newblock Intrinsic-extrinsic convolution and pooling for learning on 3d
  protein structures.
\newblock \emph{arXiv preprint arXiv:2007.06252}, 2020.

\bibitem[Hu et~al.(2019)Hu, Liu, Gomes, Zitnik, Liang, Pande, and
  Leskovec]{hu2019strategies}
Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande,
  and Jure Leskovec.
\newblock Strategies for pre-training graph neural networks.
\newblock \emph{arXiv preprint arXiv:1905.12265}, 2019.

\bibitem[Hu et~al.(2020)Hu, Fey, Zitnik, Dong, Ren, Liu, Catasta, and
  Leskovec]{hu2020open}
Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu,
  Michele Catasta, and Jure Leskovec.
\newblock Open graph benchmark: Datasets for machine learning on graphs.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 22118--22133, 2020.

\bibitem[Huang and Villar(2021)]{huang2021wltutorial}
Ningyuan~Teresa Huang and Soledad Villar.
\newblock A short tutorial on the weisfeiler-lehman test and its variants.
\newblock In \emph{ICASSP 2021 - 2021 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}, pages 8533--8537, 2021.
\newblock \doi{10.1109/ICASSP39728.2021.9413523}.

\bibitem[Huang et~al.(2023)Huang, Peng, Ma, and Zhang]{huang2023boosting}
Yinan Huang, Xingang Peng, Jianzhu Ma, and Muhan Zhang.
\newblock Boosting the cycle counting power of graph neural networks with
  i$^2$-gnns.
\newblock 2023.

\bibitem[Jiang et~al.(2010)Jiang, Coenen, and Zito]{jiang2010finding}
Chuntao Jiang, Frans Coenen, and Michele Zito.
\newblock Finding frequent subgraphs in longitudinal social network data using
  a weighted graph mining approach.
\newblock In \emph{Advanced Data Mining and Applications: 6th International
  Conference, ADMA 2010, Chongqing, China, November 19-21, 2010, Proceedings,
  Part I 6}, pages 405--416. Springer, 2010.

\bibitem[Jin et~al.(2018)Jin, Barzilay, and Jaakkola]{jin2018junction}
Wengong Jin, Regina Barzilay, and Tommi Jaakkola.
\newblock Junction tree variational autoencoder for molecular graph generation.
\newblock In \emph{International conference on machine learning}, pages
  2323--2332. PMLR, 2018.

\bibitem[Kipf and Welling(2016)]{kipf2016semi}
Thomas~N Kipf and Max Welling.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock \emph{arXiv preprint arXiv:1609.02907}, 2016.

\bibitem[Koyut{\"u}rk et~al.(2004)Koyut{\"u}rk, Grama, and
  Szpankowski]{koyuturk2004efficient}
Mehmet Koyut{\"u}rk, Ananth Grama, and Wojciech Szpankowski.
\newblock An efficient algorithm for detecting frequent subgraphs in biological
  networks.
\newblock \emph{Bioinformatics}, 20\penalty0 (suppl\_1):\penalty0 i200--i207,
  2004.

\bibitem[Kreuzer et~al.(2021)Kreuzer, Beaini, Hamilton, L{\'e}tourneau, and
  Tossou]{kreuzer2021rethinking}
Devin Kreuzer, Dominique Beaini, Will Hamilton, Vincent L{\'e}tourneau, and
  Prudencio Tossou.
\newblock Rethinking graph transformers with spectral attention.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 21618--21629, 2021.

\bibitem[Li et~al.(2020)Li, Wang, Wang, and Leskovec]{li2020distance}
Pan Li, Yanbang Wang, Hongwei Wang, and Jure Leskovec.
\newblock Distance encoding: Design provably more powerful neural networks for
  graph representation learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 4465--4478, 2020.

\bibitem[Liu et~al.(2021)Liu, Wang, Liu, Zhang, Oztekin, and
  Ji]{liu2021spherical}
Yi~Liu, Limei Wang, Meng Liu, Xuan Zhang, Bora Oztekin, and Shuiwang Ji.
\newblock Spherical message passing for 3d graph networks.
\newblock \emph{arXiv preprint arXiv:2102.05013}, 2021.

\bibitem[Maron et~al.(2018)Maron, Ben-Hamu, Shamir, and
  Lipman]{maron2018invariant}
Haggai Maron, Heli Ben-Hamu, Nadav Shamir, and Yaron Lipman.
\newblock Invariant and equivariant graph networks.
\newblock \emph{arXiv preprint arXiv:1812.09902}, 2018.

\bibitem[Maron et~al.(2019{\natexlab{a}})Maron, Ben-Hamu, Serviansky, and
  Lipman]{maron2019provably}
Haggai Maron, Heli Ben-Hamu, Hadar Serviansky, and Yaron Lipman.
\newblock Provably powerful graph networks.
\newblock \emph{Advances in neural information processing systems}, 32,
  2019{\natexlab{a}}.

\bibitem[Maron et~al.(2019{\natexlab{b}})Maron, Fetaya, Segol, and
  Lipman]{maron2019universality}
Haggai Maron, Ethan Fetaya, Nimrod Segol, and Yaron Lipman.
\newblock On the universality of invariant networks.
\newblock In \emph{International conference on machine learning}, pages
  4363--4371. PMLR, 2019{\natexlab{b}}.

\bibitem[Morris et~al.(2019)Morris, Ritzert, Fey, Hamilton, Lenssen, Rattan,
  and Grohe]{morris2019weisfeiler}
Christopher Morris, Martin Ritzert, Matthias Fey, William~L Hamilton, Jan~Eric
  Lenssen, Gaurav Rattan, and Martin Grohe.
\newblock Weisfeiler and leman go neural: Higher-order graph neural networks.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, pages 4602--4609, 2019.

\bibitem[Morris et~al.(2020)Morris, Rattan, and Mutzel]{morris2020weisfeiler}
Christopher Morris, Gaurav Rattan, and Petra Mutzel.
\newblock Weisfeiler and leman go sparse: Towards scalable higher-order graph
  embeddings.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 21824--21840, 2020.

\bibitem[Qian et~al.(2022)Qian, Rattan, Geerts, Niepert, and
  Morris]{qianordered2022}
Chendi Qian, Gaurav Rattan, Floris Geerts, Mathias Niepert, and Christopher
  Morris.
\newblock Ordered subgraph aggregation networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Qiao et~al.(2020)Qiao, Welborn, Anandkumar, Manby, and
  Miller~III]{qiao2020orbnet}
Zhuoran Qiao, Matthew Welborn, Animashree Anandkumar, Frederick~R Manby, and
  Thomas~F Miller~III.
\newblock Orbnet: Deep learning for quantum chemistry using symmetry-adapted
  atomic-orbital features.
\newblock \emph{The Journal of chemical physics}, 153\penalty0 (12):\penalty0
  124111, 2020.

\bibitem[Tahmasebi et~al.(2020)Tahmasebi, Lim, and
  Jegelka]{tahmasebi2020counting}
Behrooz Tahmasebi, Derek Lim, and Stefanie Jegelka.
\newblock Counting substructures with higher-order graph neural networks:
  Possibility and impossibility results.
\newblock \emph{arXiv preprint arXiv:2012.03174}, 2020.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Veli{\v{c}}kovi{\'c} et~al.(2017)Veli{\v{c}}kovi{\'c}, Cucurull,
  Casanova, Romero, Lio, and Bengio]{velivckovic2017graph}
Petar Veli{\v{c}}kovi{\'c}, Guillem Cucurull, Arantxa Casanova, Adriana Romero,
  Pietro Lio, and Yoshua Bengio.
\newblock Graph attention networks.
\newblock \emph{arXiv preprint arXiv:1710.10903}, 2017.

\bibitem[Wang and Zhang(2023)]{wang2023towards}
Yanbo Wang and Muhan Zhang.
\newblock Towards better evaluation of gnn expressiveness with brec dataset.
\newblock \emph{arXiv preprint arXiv:2304.07702}, 2023.

\bibitem[Weisfeiler and Leman(1968)]{weisfeiler1968reduction}
Boris Weisfeiler and Andrei Leman.
\newblock The reduction of a graph to canonical form and the algebra which
  appears therein.
\newblock \emph{NTI, Series}, 2\penalty0 (9):\penalty0 12--16, 1968.

\bibitem[Wu et~al.(2018)Wu, Ramsundar, Feinberg, Gomes, Geniesse, Pappu,
  Leswing, and Pande]{wu2018moleculenet}
Zhenqin Wu, Bharath Ramsundar, Evan~N Feinberg, Joseph Gomes, Caleb Geniesse,
  Aneesh~S Pappu, Karl Leswing, and Vijay Pande.
\newblock Moleculenet: a benchmark for molecular machine learning.
\newblock \emph{Chemical science}, 9\penalty0 (2):\penalty0 513--530, 2018.

\bibitem[Wu et~al.(2020)Wu, Pan, Chen, Long, Zhang, and
  Philip]{wu2020comprehensive}
Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S~Yu
  Philip.
\newblock A comprehensive survey on graph neural networks.
\newblock \emph{IEEE transactions on neural networks and learning systems},
  32\penalty0 (1):\penalty0 4--24, 2020.

\bibitem[Xu et~al.(2018)Xu, Hu, Leskovec, and Jegelka]{xu2018powerful}
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka.
\newblock How powerful are graph neural networks?
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Yan et~al.(2023)Yan, Zhou, Gao, Tang, and Zhang]{yan2023efficiently}
Zuoyu Yan, Junru Zhou, Liangcai Gao, Zhi Tang, and Muhan Zhang.
\newblock Efficiently counting substructures by subgraph gnns without running
  gnn on subgraphs.
\newblock \emph{arXiv preprint arXiv:2303.10576}, 2023.

\bibitem[You et~al.(2021)You, Gomes-Selman, Ying, and
  Leskovec]{you2021identity}
Jiaxuan You, Jonathan~M Gomes-Selman, Rex Ying, and Jure Leskovec.
\newblock Identity-aware graph neural networks.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pages 10737--10745, 2021.

\bibitem[Zhang et~al.(2023)Zhang, Feng, Du, He, and Wang]{zhang2023complete}
Bohang Zhang, Guhao Feng, Yiheng Du, Di~He, and Liwei Wang.
\newblock A complete expressiveness hierarchy for subgraph gnns via subgraph
  weisfeiler-lehman tests.
\newblock \emph{arXiv preprint arXiv:2302.07090}, 2023.

\bibitem[Zhang and Li(2021)]{zhang2021nested}
Muhan Zhang and Pan Li.
\newblock Nested graph neural networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 15734--15747, 2021.

\bibitem[Zhao et~al.(2022)Zhao, Jin, Akoglu, and Shah]{zhao2022stars}
Lingxiao Zhao, Wei Jin, Leman Akoglu, and Neil Shah.
\newblock From stars to subgraphs: Uplifting any gnn with local structure
  awareness.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Zhou et~al.(2020)Zhou, Cui, Hu, Zhang, Yang, Liu, Wang, Li, and
  Sun]{zhou2020graph}
Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu,
  Lifeng Wang, Changcheng Li, and Maosong Sun.
\newblock Graph neural networks: A review of methods and applications.
\newblock \emph{AI open}, 1:\penalty0 57--81, 2020.

\end{thebibliography}
