\begin{thebibliography}{75}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bajaj et~al.(2019)Bajaj, Wang, and Sigal]{bajaj2019g3raphground}
Bajaj, M., Wang, L., and Sigal, L.
\newblock G3raphground: Graph-based language grounding.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pp.\  4281--4290, 2019.

\bibitem[Chen et~al.(2019{\natexlab{a}})Chen, Jia, Lo, Chen, and Liu]{chen2019see}
Chen, D.-J., Jia, S., Lo, Y.-C., Chen, H.-T., and Liu, T.-L.
\newblock See-through-text grouping for referring image segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  7454--7463, 2019{\natexlab{a}}.

\bibitem[Chen et~al.(2023)Chen, Tao, Fan, Wang, Wang, Schiele, Xie, Raj, and Savvides]{chen2023softmatch}
Chen, H., Tao, R., Fan, Y., Wang, Y., Wang, J., Schiele, B., Xie, X., Raj, B., and Savvides, M.
\newblock Softmatch: Addressing the quantity-quality trade-off in semi-supervised learning.
\newblock \emph{arXiv preprint arXiv:2301.10921}, 2023.

\bibitem[Chen et~al.(2017)Chen, Kovvuri, and Nevatia]{chen2017query}
Chen, K., Kovvuri, R., and Nevatia, R.
\newblock Query-guided regression network with context policy for phrase grounding.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision}, pp.\  824--832, 2017.

\bibitem[Chen et~al.(2021)Chen, Yuan, Zeng, and Wang]{chen2021semi}
Chen, X., Yuan, Y., Zeng, G., and Wang, J.
\newblock Semi-supervised semantic segmentation with cross pseudo supervision.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  2613--2622, 2021.

\bibitem[Chen et~al.(2019{\natexlab{b}})Chen, Tsai, Wang, Lin, and Yang]{chen2019referring}
Chen, Y.-W., Tsai, Y.-H., Wang, T., Lin, Y.-Y., and Yang, M.-H.
\newblock Referring expression object segmentation with caption-aware consistency.
\newblock \emph{arXiv preprint arXiv:1910.04748}, 2019{\natexlab{b}}.

\bibitem[Cheng \& Cheng(2019)Cheng and Cheng]{cheng2019semi}
Cheng, Y. and Cheng, Y.
\newblock Semi-supervised learning for neural machine translation.
\newblock \emph{Joint training for neural machine translation}, pp.\  25--40, 2019.

\bibitem[Csisz{\'a}r(2008)]{csiszar2008axiomatic}
Csisz{\'a}r, I.
\newblock Axiomatic characterizations of information measures.
\newblock \emph{Entropy}, 10\penalty0 (3):\penalty0 261--273, 2008.

\bibitem[Cubuk et~al.(2019)Cubuk, Zoph, Mane, Vasudevan, and Le]{cubuk2019autoaugment}
Cubuk, E.~D., Zoph, B., Mane, D., Vasudevan, V., and Le, Q.~V.
\newblock Autoaugment: Learning augmentation strategies from data.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  113--123, 2019.

\bibitem[Deng et~al.(2021)Deng, Yang, Chen, Zhou, and Li]{deng2021transvg}
Deng, J., Yang, Z., Chen, T., Zhou, W., and Li, H.
\newblock Transvg: End-to-end visual grounding with transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  1769--1779, 2021.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Ding et~al.(2021)Ding, Liu, Wang, and Jiang]{ding2021vision}
Ding, H., Liu, C., Wang, S., and Jiang, X.
\newblock Vision-language transformer and query generation for referring segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  16321--16330, 2021.

\bibitem[Dogan et~al.(2019)Dogan, Sigal, and Gross]{dogan2019neural}
Dogan, P., Sigal, L., and Gross, M.
\newblock Neural sequential phrase grounding (seqground).
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  4175--4184, 2019.

\bibitem[French et~al.(2019)French, Laine, Aila, Mackiewicz, and Finlayson]{french2019semi}
French, G., Laine, S., Aila, T., Mackiewicz, M., and Finlayson, G.
\newblock Semi-supervised semantic segmentation needs strong, varied perturbations.
\newblock \emph{arXiv preprint arXiv:1906.01916}, 2019.

\bibitem[Grill et~al.(2020)Grill, Strub, Altch{\'e}, Tallec, Richemond, Buchatskaya, Doersch, Avila~Pires, Guo, Gheshlaghi~Azar, et~al.]{grill2020bootstrap}
Grill, J.-B., Strub, F., Altch{\'e}, F., Tallec, C., Richemond, P., Buchatskaya, E., Doersch, C., Avila~Pires, B., Guo, Z., Gheshlaghi~Azar, M., et~al.
\newblock Bootstrap your own latent-a new approach to self-supervised learning.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 21271--21284, 2020.

\bibitem[Guan et~al.(2023)Guan, Hu, Zhou, Zhang, Li, and Liu]{guan2023badsam}
Guan, Z., Hu, M., Zhou, Z., Zhang, J., Li, S., and Liu, N.
\newblock Badsam: Exploring security vulnerabilities of sam via backdoor attacks.
\newblock \emph{arXiv preprint arXiv:2305.03289}, 2023.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020momentum}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  9729--9738, 2020.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Mu, Cubuk, Zoph, Gilmer, and Lakshminarayanan]{hendrycks2019augmix}
Hendrycks, D., Mu, N., Cubuk, E.~D., Zoph, B., Gilmer, J., and Lakshminarayanan, B.
\newblock Augmix: A simple data processing method to improve robustness and uncertainty.
\newblock \emph{arXiv preprint arXiv:1912.02781}, 2019.

\bibitem[Hu et~al.(2016)Hu, Rohrbach, and Darrell]{hu2016segmentation}
Hu, R., Rohrbach, M., and Darrell, T.
\newblock Segmentation from natural language expressions.
\newblock In \emph{Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part I 14}, pp.\  108--124. Springer, 2016.

\bibitem[Hu et~al.(2023)Hu, Wang, Shao, Xie, Li, Han, and Luo]{hu2023beyond}
Hu, Y., Wang, Q., Shao, W., Xie, E., Li, Z., Han, J., and Luo, P.
\newblock Beyond one-to-one: Rethinking the referring image segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  4067--4077, 2023.

\bibitem[Hu et~al.(2020)Hu, Feng, Sun, Zhang, and Lu]{hu2020bi}
Hu, Z., Feng, G., Sun, J., Zhang, L., and Lu, H.
\newblock Bi-directional relationship inferring network for referring image segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  4424--4433, 2020.

\bibitem[Huang et~al.(2021)Huang, Lian, Luo, and Gao]{huang2021look}
Huang, B., Lian, D., Luo, W., and Gao, S.
\newblock Look before you leap: Learning landmark features for one-stage visual grounding.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  16888--16897, 2021.

\bibitem[Huang et~al.(2020)Huang, Hui, Liu, Li, Wei, Han, Liu, and Li]{huang2020referring}
Huang, S., Hui, T., Liu, S., Li, G., Wei, Y., Han, J., Liu, L., and Li, B.
\newblock Referring image segmentation via cross-modal progressive comprehension.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  10488--10497, 2020.

\bibitem[Hui et~al.(2020)Hui, Liu, Huang, Li, Yu, Zhang, and Han]{hui2020linguistic}
Hui, T., Liu, S., Huang, S., Li, G., Yu, S., Zhang, F., and Han, J.
\newblock Linguistic structure guided context modeling for referring image segmentation.
\newblock In \emph{European Conference on Computer Vision}, pp.\  59--75. Springer, 2020.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{ioffe2015batch}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing internal covariate shift.
\newblock In \emph{International conference on machine learning}, pp.\  448--456. pmlr, 2015.

\bibitem[Jiang et~al.(2022)Jiang, Li, Chen, He, Xu, Yang, Cao, and Huang]{jiang2022maxmatch}
Jiang, Y., Li, X., Chen, Y., He, Y., Xu, Q., Yang, Z., Cao, X., and Huang, Q.
\newblock Maxmatch: Semi-supervised learning with worst-case consistency.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 45\penalty0 (5):\penalty0 5970--5987, 2022.

\bibitem[Jin et~al.(2023)Jin, Luo, Zhou, Sun, Jiang, Shu, and Ji]{jin2023refclip}
Jin, L., Luo, G., Zhou, Y., Sun, X., Jiang, G., Shu, A., and Ji, R.
\newblock Refclip: A universal teacher for weakly supervised referring expression comprehension.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  2681--2690, 2023.

\bibitem[Kamath et~al.(2021)Kamath, Singh, LeCun, Synnaeve, Misra, and Carion]{kamath2021mdetr}
Kamath, A., Singh, M., LeCun, Y., Synnaeve, G., Misra, I., and Carion, N.
\newblock Mdetr-modulated detection for end-to-end multi-modal understanding.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  1780--1790, 2021.

\bibitem[Kim et~al.(2023{\natexlab{a}})Kim, Jeong, Han, and Hwang]{kim2023devil}
Kim, B., Jeong, J., Han, D., and Hwang, S.~J.
\newblock The devil is in the points: Weakly semi-supervised instance segmentation via point-guided mask representation.
\newblock \emph{arXiv preprint arXiv:2303.15062}, 2023{\natexlab{a}}.

\bibitem[Kim et~al.(2023{\natexlab{b}})Kim, Kim, Lan, and Kwak]{kim2023shatter}
Kim, D., Kim, N., Lan, C., and Kwak, S.
\newblock Shatter and gather: Learning referring image segmentation with text supervision.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  15547--15557, 2023{\natexlab{b}}.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kirillov et~al.(2023)Kirillov, Mintun, Ravi, Mao, Rolland, Gustafson, Xiao, Whitehead, Berg, Lo, et~al.]{kirillov2023segment}
Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao, T., Whitehead, S., Berg, A.~C., Lo, W.-Y., et~al.
\newblock Segment anything.
\newblock \emph{arXiv preprint arXiv:2304.02643}, 2023.

\bibitem[Kwon \& Kwak(2022)Kwon and Kwak]{kwon2022semi}
Kwon, D. and Kwak, S.
\newblock Semi-supervised semantic segmentation with error localization network.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  9957--9967, 2022.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan, Doll{\'a}r, and Zitnick]{lin2014microsoft}
Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll{\'a}r, P., and Zitnick, C.~L.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13}, pp.\  740--755. Springer, 2014.

\bibitem[Liu et~al.(2022)Liu, Jiang, and Ding]{liu2022instance}
Liu, C., Jiang, X., and Ding, H.
\newblock Instance-specific feature propagation for referring segmentation.
\newblock \emph{IEEE Transactions on Multimedia}, 2022.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Ding, and Jiang]{liu2023gres}
Liu, C., Ding, H., and Jiang, X.
\newblock Gres: Generalized referring expression segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  23592--23601, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2019)Liu, Zhang, Wu, and Zha]{liu2019learning}
Liu, D., Zhang, H., Wu, F., and Zha, Z.-J.
\newblock Learning to assemble neural module tree networks for visual grounding.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  4673--4682, 2019.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Ding, Cai, Zhang, Satzoda, Mahadevan, and Manmatha]{liu2023polyformer}
Liu, J., Ding, H., Cai, Z., Zhang, Y., Satzoda, R.~K., Mahadevan, V., and Manmatha, R.
\newblock Polyformer: Referring image segmentation as sequential polygon generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  18653--18663, 2023{\natexlab{b}}.

\bibitem[Liu et~al.(2021{\natexlab{a}})Liu, Zhi, Johns, and Davison]{liu2021bootstrapping}
Liu, S., Zhi, S., Johns, E., and Davison, A.~J.
\newblock Bootstrapping semantic segmentation with regional contrast.
\newblock \emph{arXiv preprint arXiv:2104.04465}, 2021{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{c}})Liu, Zhu, Li, Chen, Wang, and Shen]{liu2023matcher}
Liu, Y., Zhu, M., Li, H., Chen, H., Wang, X., and Shen, C.
\newblock Matcher: Segment anything with one shot using all-purpose feature matching.
\newblock \emph{arXiv preprint arXiv:2305.13310}, 2023{\natexlab{c}}.

\bibitem[Liu et~al.(2021{\natexlab{b}})Liu, Ma, He, Kuo, Chen, Zhang, Wu, Kira, and Vajda]{liu2021unbiased}
Liu, Y.-C., Ma, C.-Y., He, Z., Kuo, C.-W., Chen, K., Zhang, P., Wu, B., Kira, Z., and Vajda, P.
\newblock Unbiased teacher for semi-supervised object detection.
\newblock \emph{arXiv preprint arXiv:2102.09480}, 2021{\natexlab{b}}.

\bibitem[Liu et~al.(2021{\natexlab{c}})Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and Guo]{liu2021swin}
Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., and Guo, B.
\newblock Swin transformer: Hierarchical vision transformer using shifted windows.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pp.\  10012--10022, 2021{\natexlab{c}}.

\bibitem[Ma \& Wang(2023)Ma and Wang]{ma2023segment}
Ma, J. and Wang, B.
\newblock Segment anything in medical images.
\newblock \emph{arXiv preprint arXiv:2304.12306}, 2023.

\bibitem[Mao et~al.(2016)Mao, Huang, Toshev, Camburu, Yuille, and Murphy]{mao2016generation}
Mao, J., Huang, J., Toshev, A., Camburu, O., Yuille, A.~L., and Murphy, K.
\newblock Generation and comprehension of unambiguous object descriptions.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  11--20, 2016.

\bibitem[Miyato et~al.(2016)Miyato, Dai, and Goodfellow]{miyato2016adversarial}
Miyato, T., Dai, A.~M., and Goodfellow, I.
\newblock Adversarial training methods for semi-supervised text classification.
\newblock \emph{arXiv preprint arXiv:1605.07725}, 2016.

\bibitem[Nagaraja et~al.(2016)Nagaraja, Morariu, and Davis]{nagaraja2016modeling}
Nagaraja, V.~K., Morariu, V.~I., and Davis, L.~S.
\newblock Modeling context between objects for referring expression understanding.
\newblock In \emph{Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part IV 14}, pp.\  792--807. Springer, 2016.

\bibitem[Olsson et~al.(2021)Olsson, Tranheden, Pinto, and Svensson]{olsson2021classmix}
Olsson, V., Tranheden, W., Pinto, J., and Svensson, L.
\newblock Classmix: Segmentation-based data augmentation for semi-supervised learning.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pp.\  1369--1378, 2021.

\bibitem[Ouali et~al.(2020)Ouali, Hudelot, and Tami]{ouali2020semi}
Ouali, Y., Hudelot, C., and Tami, M.
\newblock Semi-supervised semantic segmentation with cross-consistency training.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  12674--12684, 2020.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan, Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Plummer et~al.(2015)Plummer, Wang, Cervantes, Caicedo, Hockenmaier, and Lazebnik]{plummer2015flickr30k}
Plummer, B.~A., Wang, L., Cervantes, C.~M., Caicedo, J.~C., Hockenmaier, J., and Lazebnik, S.
\newblock Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models.
\newblock In \emph{Proceedings of the IEEE international conference on computer vision}, pp.\  2641--2649, 2015.

\bibitem[Plummer et~al.(2017)Plummer, Mallya, Cervantes, Hockenmaier, and Lazebnik]{plummer2017phrase}
Plummer, B.~A., Mallya, A., Cervantes, C.~M., Hockenmaier, J., and Lazebnik, S.
\newblock Phrase localization and visual relationship detection with comprehensive image-language cues.
\newblock In \emph{Proceedings of the IEEE international conference on computer vision}, pp.\  1928--1937, 2017.

\bibitem[Shi et~al.(2023)Shi, Qiu, Abaxi, Wei, Lo, and Yuan]{shi2023generalist}
Shi, P., Qiu, J., Abaxi, S. M.~D., Wei, H., Lo, F. P.-W., and Yuan, W.
\newblock Generalist vision foundation models for medical imaging: A case study of segment anything model on zero-shot medical segmentation.
\newblock \emph{Diagnostics}, 13\penalty0 (11):\penalty0 1947, 2023.

\bibitem[Sohn et~al.(2020)Sohn, Berthelot, Carlini, Zhang, Zhang, Raffel, Cubuk, Kurakin, and Li]{sohn2020fixmatch}
Sohn, K., Berthelot, D., Carlini, N., Zhang, Z., Zhang, H., Raffel, C.~A., Cubuk, E.~D., Kurakin, A., and Li, C.-L.
\newblock Fixmatch: Simplifying semi-supervised learning with consistency and confidence.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 596--608, 2020.

\bibitem[Sun et~al.(2023)Sun, Luo, Zhou, Sun, Jiang, Wang, and Ji]{sun2023refteacher}
Sun, J., Luo, G., Zhou, Y., Sun, X., Jiang, G., Wang, Z., and Ji, R.
\newblock Refteacher: A strong baseline for semi-supervised referring expression comprehension.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  19144--19154, 2023.

\bibitem[Tarvainen \& Valpola(2017)Tarvainen and Valpola]{tarvainen2017mean}
Tarvainen, A. and Valpola, H.
\newblock Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Wang et~al.(2023)Wang, Zhang, Fei, Ge, Zheng, Tang, Li, Gao, Zhao, Shan, et~al.]{wang2023caption}
Wang, T., Zhang, J., Fei, J., Ge, Y., Zheng, H., Tang, Y., Li, Z., Gao, M., Zhao, S., Shan, Y., et~al.
\newblock Caption anything: Interactive image description with diverse multimodal controls.
\newblock \emph{arXiv preprint arXiv:2305.02677}, 2023.

\bibitem[Wang et~al.(2022)Wang, Wang, Shen, Fei, Li, Jin, Wu, Zhao, and Le]{wang2022semi}
Wang, Y., Wang, H., Shen, Y., Fei, J., Li, W., Jin, G., Wu, L., Zhao, R., and Le, X.
\newblock Semi-supervised semantic segmentation using unreliable pseudo-labels.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  4248--4257, 2022.

\bibitem[Wu et~al.(2021)Wu, Fan, Zhang, Lin, and Li]{wu2021semi}
Wu, J., Fan, H., Zhang, X., Lin, S., and Li, Z.
\newblock Semi-supervised semantic segmentation via entropy minimization.
\newblock In \emph{2021 IEEE International Conference on Multimedia and Expo (ICME)}, pp.\  1--6. IEEE, 2021.

\bibitem[Xie et~al.(2023)Xie, Wang, Ma, Chen, Lu, Yang, Shi, and Lin]{xie2023everything}
Xie, D., Wang, R., Ma, J., Chen, C., Lu, H., Yang, D., Shi, F., and Lin, X.
\newblock everything: A text-guided generative system for images editing.
\newblock \emph{arXiv preprint arXiv:2304.14006}, 2023.

\bibitem[Xu et~al.(2021)Xu, Shang, Ye, Qian, Li, Sun, Li, and Jin]{xu2021dash}
Xu, Y., Shang, L., Ye, J., Qian, Q., Li, Y.-F., Sun, B., Li, H., and Jin, R.
\newblock Dash: Semi-supervised learning with dynamic thresholding.
\newblock In \emph{International Conference on Machine Learning}, pp.\  11525--11536. PMLR, 2021.

\bibitem[Yang et~al.(2023)Yang, Ji, Sun, Wang, Li, Ma, and Ji]{yang2023semi}
Yang, D., Ji, J., Sun, X., Wang, H., Li, Y., Ma, Y., and Ji, R.
\newblock Semi-supervised panoptic narrative grounding.
\newblock In \emph{Proceedings of the 31st ACM International Conference on Multimedia}, pp.\  7164--7174, 2023.

\bibitem[Yang et~al.(2022{\natexlab{a}})Yang, Qi, Feng, Zhang, and Shi]{yang2022revisiting}
Yang, L., Qi, L., Feng, L., Zhang, W., and Shi, Y.
\newblock Revisiting weak-to-strong consistency in semi-supervised semantic segmentation.
\newblock \emph{arXiv preprint arXiv:2208.09910}, 2022{\natexlab{a}}.

\bibitem[Yang et~al.(2020)Yang, Chen, Wang, and Luo]{yang2020improving}
Yang, Z., Chen, T., Wang, L., and Luo, J.
\newblock Improving one-stage visual grounding by recursive sub-query construction.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XIV 16}, pp.\  387--404. Springer, 2020.

\bibitem[Yang et~al.(2022{\natexlab{b}})Yang, Wang, Tang, Chen, Zhao, and Torr]{yang2022lavt}
Yang, Z., Wang, J., Tang, Y., Chen, K., Zhao, H., and Torr, P.~H.
\newblock Lavt: Language-aware vision transformer for referring image segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  18155--18165, 2022{\natexlab{b}}.

\bibitem[Yu et~al.(2016)Yu, Poirson, Yang, Berg, and Berg]{yu2016modeling}
Yu, L., Poirson, P., Yang, S., Berg, A.~C., and Berg, T.~L.
\newblock Modeling context in referring expressions.
\newblock In \emph{Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14}, pp.\  69--85. Springer, 2016.

\bibitem[Yu et~al.(2018)Yu, Lin, Shen, Yang, Lu, Bansal, and Berg]{yu2018mattnet}
Yu, L., Lin, Z., Shen, X., Yang, J., Lu, X., Bansal, M., and Berg, T.~L.
\newblock Mattnet: Modular attention network for referring expression comprehension.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  1307--1315, 2018.

\bibitem[Yu et~al.(2023)Yu, Feng, Feng, Liu, Jin, Zeng, and Chen]{yu2023inpaint}
Yu, T., Feng, R., Feng, R., Liu, J., Jin, X., Zeng, W., and Chen, Z.
\newblock Inpaint anything: Segment anything meets image inpainting.
\newblock \emph{arXiv preprint arXiv:2304.06790}, 2023.

\bibitem[Zhang et~al.(2023{\natexlab{a}})Zhang, Zhang, Kang, Kim, Bae, and Kweon]{zhang2023attack}
Zhang, C., Zhang, C., Kang, T., Kim, D., Bae, S.-H., and Kweon, I.~S.
\newblock Attack-sam: Towards evaluating adversarial robustness of segment anything model.
\newblock \emph{arXiv preprint arXiv:2305.00866}, 2023{\natexlab{a}}.

\bibitem[Zhang et~al.(2017)Zhang, Cisse, Dauphin, and Lopez-Paz]{zhang2017mixup}
Zhang, H., Cisse, M., Dauphin, Y.~N., and Lopez-Paz, D.
\newblock mixup: Beyond empirical risk minimization.
\newblock \emph{arXiv preprint arXiv:1710.09412}, 2017.

\bibitem[Zhang et~al.(2023{\natexlab{b}})Zhang, Jiang, Guo, Yan, Pan, Ma, Dong, Gao, and Li]{zhang2023personalize}
Zhang, R., Jiang, Z., Guo, Z., Yan, S., Pan, J., Ma, X., Dong, H., Gao, P., and Li, H.
\newblock Personalize segment anything model with one shot.
\newblock \emph{arXiv preprint arXiv:2305.03048}, 2023{\natexlab{b}}.

\bibitem[Zhao et~al.(2023{\natexlab{a}})Zhao, Yang, Long, Pi, Zhou, and Wang]{zhao2023augmentation}
Zhao, Z., Yang, L., Long, S., Pi, J., Zhou, L., and Wang, J.
\newblock Augmentation matters: A simple-yet-effective approach to semi-supervised semantic segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  11350--11359, 2023{\natexlab{a}}.

\bibitem[Zhao et~al.(2023{\natexlab{b}})Zhao, Yang, Long, Pi, Zhou, and Wang]{zhen23augseg}
Zhao, Z., Yang, L., Long, S., Pi, J., Zhou, L., and Wang, J.
\newblock Augmentation matters: A simple-yet-effective approach to semi-supervised semantic segmentation.
\newblock In \emph{CVPR}, 2023{\natexlab{b}}.

\bibitem[Zou \& Caragea(2023)Zou and Caragea]{zou2023jointmatch}
Zou, H.~P. and Caragea, C.
\newblock Jointmatch: A unified approach for diverse and collaborative pseudo-labeling to semi-supervised text classification.
\newblock \emph{arXiv preprint arXiv:2310.14583}, 2023.

\bibitem[Zou et~al.(2024)Zou, Yang, Zhang, Li, Li, Wang, Wang, Gao, and Lee]{zou2024segment}
Zou, X., Yang, J., Zhang, H., Li, F., Li, L., Wang, J., Wang, L., Gao, J., and Lee, Y.~J.
\newblock Segment everything everywhere all at once.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Zou et~al.(2020)Zou, Zhang, Zhang, Li, Bian, Huang, and Pfister]{zou2020pseudoseg}
Zou, Y., Zhang, Z., Zhang, H., Li, C.-L., Bian, X., Huang, J.-B., and Pfister, T.
\newblock Pseudoseg: Designing pseudo labels for semantic segmentation.
\newblock \emph{arXiv preprint arXiv:2010.09713}, 2020.

\end{thebibliography}
