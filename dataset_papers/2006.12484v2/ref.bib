@book{jaeger1998discrete,
  title={Discrete-time, discrete-valued observable operator models: a tutorial},
  author={Jaeger, Herbert},
  year={1998},
  publisher={GMD-Forschungszentrum Informationstechnik}
}

@inproceedings{krishnamurthy2016pac,
  title={PAC reinforcement learning with rich observations},
  author={Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1840--1848},
  year={2016}
}

@article{bonet2012deterministic,
  title={Deterministic pomdps revisited},
  author={Bonet, Blai},
  journal={arXiv preprint arXiv:1205.2659},
  year={2012}
}
@inproceedings{bazinin2018iterative,
  title={Iterative Planning for Deterministic QDec-POMDPs.},
  author={Bazinin, Sagi and Shani, Guy},
  booktitle={GCAI},
  pages={15--28},
  year={2018}
}

@inproceedings{besse2009quasi,
  title={Quasi-deterministic partially observable Markov decision processes},
  author={Besse, Camille and Chaib-Draa, Brahim},
  booktitle={International Conference on Neural Information Processing},
  pages={237--246},
  year={2009},
  organization={Springer}
}

@article{hsu2012spectral,
  title={A spectral algorithm for learning hidden Markov models},
  author={Hsu, Daniel and Kakade, Sham M and Zhang, Tong},
  journal={Journal of Computer and System Sciences},
  volume={78},
  number={5},
  pages={1460--1480},
  year={2012},
  publisher={Elsevier}
}
@inproceedings{ross2008bayes,
  title={Bayes-adaptive pomdps},
  author={Ross, Stephane and Chaib-draa, Brahim and Pineau, Joelle},
  booktitle={Advances in neural information processing systems},
  pages={1225--1232},
  year={2008}
}
@inproceedings{poupart2008model,
  title={Model-based Bayesian reinforcement learning in partially observable domains},
  author={Poupart, Pascal and Vlassis, Nikos},
  booktitle={Proc Int. Symp. on Artificial Intelligence and Mathematics,},
  pages={1--2},
  year={2008}
}
@article{papadimitriou1987complexity,
  title={The complexity of Markov decision processes},
  author={Papadimitriou, Christos H and Tsitsiklis, John N},
  journal={Mathematics of operations research},
  volume={12},
  number={3},
  pages={441--450},
  year={1987},
  publisher={INFORMS}
}
@article{vlassis2012computational,
  title={On the computational complexity of stochastic controller optimization in POMDPs},
  author={Vlassis, Nikos and Littman, Michael L and Barber, David},
  journal={ACM Transactions on Computation Theory (TOCT)},
  volume={4},
  number={4},
  pages={1--8},
  year={2012},
  publisher={ACM New York, NY, USA}
}
@article{pineau2006anytime,
  title={Anytime point-based approximations for large POMDPs},
  author={Pineau, Joelle and Gordon, Geoffrey and Thrun, Sebastian},
  journal={Journal of Artificial Intelligence Research},
  volume={27},
  pages={335--380},
  year={2006}
}
@article{smith2012heuristic,
  title={Heuristic search value iteration for POMDPs},
  author={Smith, Trey and Simmons, Reid},
  journal={arXiv preprint arXiv:1207.4166},
  year={2012}
}
@article{kaelbling1998planning,
  title={Planning and acting in partially observable stochastic domains},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Cassandra, Anthony R},
  journal={Artificial intelligence},
  volume={101},
  number={1-2},
  pages={99--134},
  year={1998},
  publisher={Elsevier}
}
@article{song2010hilbert,
  title={Hilbert space embeddings of hidden Markov models},
  author={Song, Le and Boots, Byron and Siddiqi, Sajid and Gordon, Geoffrey J and Smola, Alex},
  year={2010}
}
@article{anandkumar2014tensor,
  title={Tensor decompositions for learning latent variable models},
  author={Anandkumar, Animashree and Ge, Rong and Hsu, Daniel and Kakade, Sham M and Telgarsky, Matus},
  journal={Journal of Machine Learning Research},
  volume={15},
  pages={2773--2832},
  year={2014},
  publisher={Journal of Machine Learning Research}
}
@inproceedings{anandkumar2012method,
  title={A method of moments for mixture models and hidden Markov models},
  author={Anandkumar, Animashree and Hsu, Daniel and Kakade, Sham M},
  booktitle={Conference on Learning Theory},
  pages={33--1},
  year={2012}
}
@article{azizzadenesheli2016reinforcement,
  title={Reinforcement learning of POMDPs using spectral methods},
  author={Azizzadenesheli, Kamyar and Lazaric, Alessandro and Anandkumar, Animashree},
  journal={29th Annual Conference on Learning Theory},
  year={2016}
}
@inproceedings{guo2016pac,
  title={A PAC RL algorithm for episodic POMDPs},
  author={Guo, Zhaohan Daniel and Doroudi, Shayan and Brunskill, Emma},
  booktitle={Artificial Intelligence and Statistics},
  pages={510--518},
  year={2016}
}
@article{even2005reinforcement,
  title={Reinforcement learning in POMDPs without resets},
  author={Even-Dar, Eyal and Kakade, Sham M and Mansour, Yishay},
  year={2005}
}
@inproceedings{mossel2005learning,
  title={Learning nonsingular phylogenies and hidden Markov models},
  author={Mossel, Elchanan and Roch, S{\'e}bastien},
  booktitle={Proceedings of the thirty-seventh annual ACM symposium on Theory of computing},
  pages={366--375},
  year={2005}
}
@inproceedings{sharan2017learning,
  title={Learning overcomplete hmms},
  author={Sharan, Vatsal and Kakade, Sham M and Liang, Percy S and Valiant, Gregory},
  booktitle={Advances in Neural Information Processing Systems},
  pages={940--949},
  year={2017}
}
@article{huang2015minimal,
  title={Minimal realization problems for hidden markov models},
  author={Huang, Qingqing and Ge, Rong and Kakade, Sham and Dahleh, Munther},
  journal={IEEE Transactions on Signal Processing},
  volume={64},
  number={7},
  pages={1896--1904},
  year={2015},
  publisher={IEEE}
}

@inproceedings{ng2000pegasus,
author = {Ng, Andrew Y. and Jordan, Michael},
title = {PEGASUS: A Policy Search Method for Large MDPs and POMDPs},
year = {2000},
booktitle = {Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence},
pages = {406–415},
series = {UAI’00}
}
@inproceedings{kolter2009near,
  title={Near-Bayesian exploration in polynomial time},
  author={Kolter, J Zico and Ng, Andrew Y},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={513--520},
  year={2009}
}
@article{schutzenberger1961definition,
  title={On the definition of a family of automata},
  author={Sch{\"u}tzenberger, Marcel Paul},
  journal={Information and control},
  volume={4},
  number={2-3},
  pages={245--270},
  year={1961}
}
@article{carlyle1971realizations,
  title={Realizations by stochastic finite automata},
  author={Carlyle, Jack W. and Paz, Azaria},
  journal={Journal of Computer and System Sciences},
  volume={5},
  number={1},
  pages={26--40},
  year={1971},
  publisher={Elsevier}
}
@article{jaeger2000observable,
  title={Observable operator models for discrete stochastic time series},
  author={Jaeger, Herbert},
  journal={Neural computation},
  volume={12},
  number={6},
  pages={1371--1398},
  year={2000},
  publisher={MIT Press}
}
@inproceedings{littman2002predictive,
  title={Predictive representations of state},
  author={Littman, Michael L and Sutton, Richard S},
  booktitle={Advances in neural information processing systems},
  pages={1555--1561},
  year={2002}
}
@article{singh2012predictive,
  title={Predictive state representations: A new theory for modeling dynamical systems},
  author={Singh, Satinder and James, Michael and Rudary, Matthew},
  journal={arXiv preprint arXiv:1207.4167},
  year={2012}
}
@article{boots2011closing,
  title={Closing the learning-planning loop with predictive state representations},
  author={Boots, Byron and Siddiqi, Sajid M and Gordon, Geoffrey J},
  journal={The International Journal of Robotics Research},
  volume={30},
  number={7},
  pages={954--966},
  year={2011},
  publisher={SAGE Publications Sage UK: London, England}
}
@article{mundhenk2000complexity,
  title={Complexity of finite-horizon Markov decision process problems},
  author={Mundhenk, Martin and Goldsmith, Judy and Lusena, Christopher and Allender, Eric},
  journal={Journal of the ACM (JACM)},
  volume={47},
  number={4},
  pages={681--720},
  year={2000},
  publisher={ACM New York, NY, USA}
}
@inproceedings{cassandra1996acting,
  title={Acting under uncertainty: Discrete Bayesian models for mobile-robot navigation},
  author={Cassandra, Anthony R and Kaelbling, Leslie Pack and Kurien, James A},
  booktitle={Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems. IROS'96},
  volume={2},
  pages={963--972},
  year={1996},
  organization={IEEE}
}
@article{brown2018superhuman,
  title={Superhuman AI for heads-up no-limit poker: Libratus beats top professionals},
  author={Brown, Noam and Sandholm, Tuomas},
  journal={Science},
  volume={359},
  number={6374},
  pages={418--424},
  year={2018},
  publisher={American Association for the Advancement of Science}
}
@article{hauskrecht2000planning,
  title={Planning treatment of ischemic heart disease with partially observable Markov decision processes},
  author={Hauskrecht, Milos and Fraser, Hamish},
  journal={Artificial Intelligence in Medicine},
  volume={18},
  number={3},
  pages={221--244},
  year={2000},
  publisher={Elsevier}
}
@inproceedings{rafferty2011faster,
  title={Faster teaching by POMDP planning},
  author={Rafferty, Anna N and Brunskill, Emma and Griffiths, Thomas L and Shafto, Patrick},
  booktitle={International Conference on Artificial Intelligence in Education},
  pages={280--287},
  year={2011},
  organization={Springer}
}
@article{jin2019short,
  title={A short note on concentration inequalities for random vectors with subgaussian norm},
  author={Jin, Chi and Netrapalli, Praneeth and Ge, Rong and Kakade, Sham M and Jordan, Michael I},
  journal={arXiv preprint arXiv:1902.03736},
  year={2019}
}

@article{Azizzadenesheli2018policy,
  title={Policy Gradient in Partially Observable Environments: Approximation and Convergence},
  author={Azizzadenesheli， Kamyar and Yue, Yisong and Anandkumar, Animashree},
  journal={arXiv preprint arXiv:1810.07900},
  year={2018}
}