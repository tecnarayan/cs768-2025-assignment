\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Berthelot et~al.(2019)Berthelot, Carlini, Goodfellow, Papernot,
  Oliver, and Raffel]{berthelot2019mixmatch}
Berthelot, D., Carlini, N., Goodfellow, I., Papernot, N., Oliver, A., and
  Raffel, C.
\newblock Mixmatch: A holistic approach to semi-supervised learning.
\newblock \emph{arXiv preprint arXiv:1905.02249}, 2019.

\bibitem[Bickerton et~al.(2012)Bickerton, Paolini, Besnard, Muresan, and
  Hopkins]{bickerton2012quantifying}
Bickerton, G.~R., Paolini, G.~V., Besnard, J., Muresan, S., and Hopkins, A.~L.
\newblock Quantifying the chemical beauty of drugs.
\newblock \emph{Nature chemistry}, 4\penalty0 (2):\penalty0 90, 2012.

\bibitem[Blum \& Mitchell(1998)Blum and Mitchell]{blum1998combining}
Blum, A. and Mitchell, T.
\newblock Combining labeled and unlabeled data with co-training.
\newblock In \emph{Proceedings of the eleventh annual conference on
  Computational learning theory}, pp.\  92--100. Citeseer, 1998.

\bibitem[Brookes et~al.(2019{\natexlab{a}})Brookes, Busia, Fannjiang, Murphy,
  and Listgarten]{brookes2019view}
Brookes, D.~H., Busia, A., Fannjiang, C., Murphy, K., and Listgarten, J.
\newblock A view of estimation of distribution algorithms through the lens of
  expectation-maximization.
\newblock \emph{arXiv preprint arXiv:1905.10474}, 2019{\natexlab{a}}.

\bibitem[Brookes et~al.(2019{\natexlab{b}})Brookes, Park, and
  Listgarten]{brookes2019conditioning}
Brookes, D.~H., Park, H., and Listgarten, J.
\newblock Conditioning by adaptive sampling for robust design.
\newblock \emph{arXiv preprint arXiv:1901.10060}, 2019{\natexlab{b}}.

\bibitem[Bunel et~al.(2018)Bunel, Hausknecht, Devlin, Singh, and
  Kohli]{bunel2018leveraging}
Bunel, R., Hausknecht, M., Devlin, J., Singh, R., and Kohli, P.
\newblock Leveraging grammar and reinforcement learning for neural program
  synthesis.
\newblock \emph{arXiv preprint arXiv:1805.04276}, 2018.

\bibitem[Celeux et~al.(1996)Celeux, Chauveau, and
  Diebolt]{celeux1996stochastic}
Celeux, G., Chauveau, D., and Diebolt, J.
\newblock Stochastic versions of the em algorithm: an experimental study in the
  mixture case.
\newblock \emph{Journal of statistical computation and simulation}, 55\penalty0
  (4):\penalty0 287--314, 1996.

\bibitem[Charniak et~al.(2016)]{charniak2016parsing}
Charniak, E. et~al.
\newblock Parsing as language modeling.
\newblock In \emph{Proceedings of the 2016 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  2331--2336, 2016.

\bibitem[Chen et~al.(2019)Chen, Liu, and Song]{chen2018execution}
Chen, X., Liu, C., and Song, D.
\newblock Execution-guided neural program synthesis.
\newblock \emph{International Conference on Learning Representations}, 2019.

\bibitem[Devlin et~al.(2017)Devlin, Bunel, Singh, Hausknecht, and
  Kohli]{devlin2017neural}
Devlin, J., Bunel, R.~R., Singh, R., Hausknecht, M., and Kohli, P.
\newblock Neural program meta-induction.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2080--2088, 2017.

\bibitem[Duvenaud et~al.(2015)Duvenaud, Maclaurin, Iparraguirre, Bombarell,
  Hirzel, Aspuru-Guzik, and Adams]{duvenaud2015convolutional}
Duvenaud, D.~K., Maclaurin, D., Iparraguirre, J., Bombarell, R., Hirzel, T.,
  Aspuru-Guzik, A., and Adams, R.~P.
\newblock Convolutional networks on graphs for learning molecular fingerprints.
\newblock \emph{Advances in Neural Information Processing Systems}, pp.\
  2224--2232, 2015.

\bibitem[Edunov et~al.(2018)Edunov, Ott, Auli, and
  Grangier]{edunov2018understanding}
Edunov, S., Ott, M., Auli, M., and Grangier, D.
\newblock Understanding back-translation at scale.
\newblock \emph{arXiv preprint arXiv:1808.09381}, 2018.

\bibitem[Gilmer et~al.(2017)Gilmer, Schoenholz, Riley, Vinyals, and
  Dahl]{gilmer2017neural}
Gilmer, J., Schoenholz, S.~S., Riley, P.~F., Vinyals, O., and Dahl, G.~E.
\newblock Neural message passing for quantum chemistry.
\newblock \emph{Proceedings of the 34th International Conference on Machine
  Learning}, 2017.

\bibitem[G{\'o}mez-Bombarelli et~al.(2018)G{\'o}mez-Bombarelli, Wei, Duvenaud,
  Hern{\'a}ndez-Lobato, S{\'a}nchez-Lengeling, Sheberla, Aguilera-Iparraguirre,
  Hirzel, Adams, and Aspuru-Guzik]{gomez2016automatic}
G{\'o}mez-Bombarelli, R., Wei, J.~N., Duvenaud, D., Hern{\'a}ndez-Lobato,
  J.~M., S{\'a}nchez-Lengeling, B., Sheberla, D., Aguilera-Iparraguirre, J.,
  Hirzel, T.~D., Adams, R.~P., and Aspuru-Guzik, A.
\newblock Automatic chemical design using a data-driven continuous
  representation of molecules.
\newblock \emph{ACS Central Science}, 2018.
\newblock \doi{10.1021/acscentsci.7b00572}.

\bibitem[Gulwani(2011)]{gulwani2011automating}
Gulwani, S.
\newblock Automating string processing in spreadsheets using input-output
  examples.
\newblock In \emph{ACM Sigplan Notices}, volume~46, pp.\  317--330. ACM, 2011.

\bibitem[Hastings(1970)]{hastings1970monte}
Hastings, W.~K.
\newblock Monte carlo sampling methods using markov chains and their
  applications.
\newblock 1970.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and
  Hochreiter]{heusel2017gans}
Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochreiter, S.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  6626--6637, 2017.

\bibitem[Hu et~al.(2019)Hu, Liu, Gomes, Zitnik, Liang, Pande, and
  Leskovec]{hu2019pre}
Hu, W., Liu, B., Gomes, J., Zitnik, M., Liang, P., Pande, V., and Leskovec, J.
\newblock Pre-training graph neural networks.
\newblock \emph{arXiv preprint arXiv:1905.12265}, 2019.

\bibitem[Jaques et~al.(2017)Jaques, Gu, Bahdanau, Hern{\'a}ndez-Lobato, Turner,
  and Eck]{jaques2017sequence}
Jaques, N., Gu, S., Bahdanau, D., Hern{\'a}ndez-Lobato, J.~M., Turner, R.~E.,
  and Eck, D.
\newblock Sequence tutor: Conservative fine-tuning of sequence generation
  models with kl-control.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  1645--1654. JMLR. org, 2017.

\bibitem[Jin et~al.(2019{\natexlab{a}})Jin, Barzilay, and
  Jaakkola]{jin2019multi}
Jin, W., Barzilay, R., and Jaakkola, T.
\newblock Multi-resolution autoregressive graph-to-graph translation for
  molecules.
\newblock \emph{arXiv preprint arXiv:1907.11223}, 2019{\natexlab{a}}.

\bibitem[Jin et~al.(2019{\natexlab{b}})Jin, Yang, Barzilay, and
  Jaakkola]{jin2018learning}
Jin, W., Yang, K., Barzilay, R., and Jaakkola, T.
\newblock Learning multimodal graph-to-graph translation for molecular
  optimization.
\newblock \emph{International Conference on Learning Representation},
  2019{\natexlab{b}}.

\bibitem[Kang \& Cho(2018)Kang and Cho]{kang2018conditional}
Kang, S. and Cho, K.
\newblock Conditional molecular design with deep generative models.
\newblock \emph{Journal of chemical information and modeling}, 59\penalty0
  (1):\penalty0 43--52, 2018.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{kingma2013auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kusner et~al.(2017)Kusner, Paige, and
  Hern{\'a}ndez-Lobato]{kusner2017grammar}
Kusner, M.~J., Paige, B., and Hern{\'a}ndez-Lobato, J.~M.
\newblock Grammar variational autoencoder.
\newblock \emph{arXiv preprint arXiv:1703.01925}, 2017.

\bibitem[Lee(2013)]{lee2013pseudo}
Lee, D.-H.
\newblock Pseudo-label: The simple and efficient semi-supervised learning
  method for deep neural networks.
\newblock In \emph{Workshop on challenges in representation learning, ICML},
  volume~3, pp.\ ~2, 2013.

\bibitem[McClosky et~al.(2006)McClosky, Charniak, and
  Johnson]{mcclosky2006effective}
McClosky, D., Charniak, E., and Johnson, M.
\newblock Effective self-training for parsing.
\newblock In \emph{Proceedings of the main conference on human language
  technology conference of the North American Chapter of the Association of
  Computational Linguistics}, pp.\  152--159. Association for Computational
  Linguistics, 2006.

\bibitem[Norouzi et~al.(2016)Norouzi, Bengio, Jaitly, Schuster, Wu, Schuurmans,
  et~al.]{norouzi2016reward}
Norouzi, M., Bengio, S., Jaitly, N., Schuster, M., Wu, Y., Schuurmans, D.,
  et~al.
\newblock Reward augmented maximum likelihood for neural structured prediction.
\newblock In \emph{Advances In Neural Information Processing Systems}, pp.\
  1723--1731, 2016.

\bibitem[Olivecrona et~al.(2017)Olivecrona, Blaschke, Engkvist, and
  Chen]{olivecrona2017molecular}
Olivecrona, M., Blaschke, T., Engkvist, O., and Chen, H.
\newblock Molecular de-novo design through deep reinforcement learning.
\newblock \emph{Journal of cheminformatics}, 9\penalty0 (1):\penalty0 48, 2017.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{paszke2017automatic}
Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z.,
  Desmaison, A., Antiga, L., and Lerer, A.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem[Pattis(1981)]{Pattis:1981:KRG:539521}
Pattis, R.~E.
\newblock \emph{Karel the Robot: A Gentle Introduction to the Art of
  Programming}.
\newblock John Wiley \& Sons, Inc., New York, NY, USA, 1st edition, 1981.
\newblock ISBN 0471089281.

\bibitem[Popova et~al.(2018)Popova, Isayev, and Tropsha]{popova2018deep}
Popova, M., Isayev, O., and Tropsha, A.
\newblock Deep reinforcement learning for de novo drug design.
\newblock \emph{Science advances}, 4\penalty0 (7):\penalty0 eaap7885, 2018.

\bibitem[Preuer et~al.(2018)Preuer, Renz, Unterthiner, Hochreiter, and
  Klambauer]{preuer2018frechet}
Preuer, K., Renz, P., Unterthiner, T., Hochreiter, S., and Klambauer, G.
\newblock Fr{\'e}chet chemnet distance: a metric for generative models for
  molecules in drug discovery.
\newblock \emph{Journal of chemical information and modeling}, 58\penalty0
  (9):\penalty0 1736--1741, 2018.

\bibitem[Rogers \& Hahn(2010)Rogers and Hahn]{rogers2010extended}
Rogers, D. and Hahn, M.
\newblock Extended-connectivity fingerprints.
\newblock \emph{J. Chem. Inf. Model.}, 50\penalty0 (5):\penalty0 742--754,
  2010.

\bibitem[Segler et~al.(2017)Segler, Kogej, Tyrchan, and
  Waller]{segler2017generating}
Segler, M.~H., Kogej, T., Tyrchan, C., and Waller, M.~P.
\newblock Generating focussed molecule libraries for drug discovery with
  recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1701.01329}, 2017.

\bibitem[Sennrich et~al.(2015)Sennrich, Haddow, and
  Birch]{sennrich2015improving}
Sennrich, R., Haddow, B., and Birch, A.
\newblock Improving neural machine translation models with monolingual data.
\newblock \emph{arXiv preprint arXiv:1511.06709}, 2015.

\bibitem[Sterling \& Irwin(2015)Sterling and Irwin]{sterling2015zinc}
Sterling, T. and Irwin, J.~J.
\newblock Zinc 15--ligand discovery for everyone.
\newblock \emph{Journal of chemical information and modeling}, 55\penalty0
  (11):\penalty0 2324--2337, 2015.

\bibitem[Sun et~al.(2019)Sun, Hoffmann, and Tang]{sun2019infograph}
Sun, F.-Y., Hoffmann, J., and Tang, J.
\newblock Infograph: Unsupervised and semi-supervised graph-level
  representation learning via mutual information maximization.
\newblock \emph{arXiv preprint arXiv:1908.01000}, 2019.

\bibitem[Weininger(1988)]{weininger1988smiles}
Weininger, D.
\newblock Smiles, a chemical language and information system. 1. introduction
  to methodology and encoding rules.
\newblock \emph{J. Chem. Inf. Model.}, 28\penalty0 (1):\penalty0 31--36, 1988.

\bibitem[Xie et~al.(2019)Xie, Dai, Hovy, Luong, and Le]{xie2019unsupervised}
Xie, Q., Dai, Z., Hovy, E., Luong, M.-T., and Le, Q.~V.
\newblock Unsupervised data augmentation.
\newblock \emph{arXiv preprint arXiv:1904.12848}, 2019.

\bibitem[Yang et~al.(2019)Yang, Swanson, Jin, Coley, Eiden, Gao, Guzman-Perez,
  Hopper, Kelley, Mathea, et~al.]{yang2019learned}
Yang, K., Swanson, K., Jin, W., Coley, C.~W., Eiden, P., Gao, H., Guzman-Perez,
  A., Hopper, T., Kelley, B., Mathea, M., et~al.
\newblock Analyzing learned molecular representations for property prediction.
\newblock \emph{Journal of chemical information and modeling}, 2019.

\bibitem[You et~al.(2018)You, Liu, Ying, Pande, and Leskovec]{you2018graph}
You, J., Liu, B., Ying, Z., Pande, V., and Leskovec, J.
\newblock Graph convolutional policy network for goal-directed molecular graph
  generation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6410--6421, 2018.

\bibitem[Zhang et~al.(2018)Zhang, Rosenblatt, Fetaya, Liao, Byrd, Urtasun, and
  Zemel]{zhang2018leveraging}
Zhang, L., Rosenblatt, G., Fetaya, E., Liao, R., Byrd, W.~E., Urtasun, R., and
  Zemel, R.
\newblock Leveraging constraint logic programming for neural guided program
  synthesis.
\newblock 2018.

\bibitem[Zhou \& Li(2005)Zhou and Li]{zhou2005tri}
Zhou, Z.-H. and Li, M.
\newblock Tri-training: Exploiting unlabeled data using three classifiers.
\newblock \emph{IEEE Transactions on Knowledge \& Data Engineering}, \penalty0
  (11):\penalty0 1529--1541, 2005.

\end{thebibliography}
