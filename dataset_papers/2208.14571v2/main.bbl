\begin{thebibliography}{53}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Al-Mohy and Higham(2009)]{Mohy2009scaling}
A.~Al-Mohy and N.~Higham.
\newblock A new scaling and squaring algorithm for the matrix exponential.
\newblock \emph{SIAM Journal on Matrix Analysis and Applications}, 31, 2009.

\bibitem[Bader et~al.(2019)Bader, Blanes, and Casas]{bader2019computing}
P.~Bader, S.~Blanes, and F.~Casas.
\newblock Computing the matrix exponential with an optimized taylor polynomial
  approximation.
\newblock \emph{Mathematics}, 7\penalty0 (12):\penalty0 1174, 2019.

\bibitem[Barab{\'a}si and Albert(1999)]{Barabasi1999emergence}
A.-L. Barab{\'a}si and R.~Albert.
\newblock Emergence of scaling in random networks.
\newblock \emph{Science}, 286\penalty0 (5439):\penalty0 509--512, 1999.

\bibitem[Bertsekas(1982)]{Bertsekas1982constrained}
D.~P. Bertsekas.
\newblock \emph{Constrained Optimization and {Lagrange} Multiplier Methods}.
\newblock Academic Press, 1982.

\bibitem[Bertsekas(1999)]{Bertsekas1999nonlinear}
D.~P. Bertsekas.
\newblock \emph{Nonlinear Programming}.
\newblock Athena Scientific, 2nd edition, 1999.

\bibitem[Bhattacharya et~al.(2021)Bhattacharya, Nagarajan, Malinsky, and
  Shpitser]{Bhattacharya2020differentiable}
R.~Bhattacharya, T.~Nagarajan, D.~Malinsky, and I.~Shpitser.
\newblock Differentiable causal discovery under unmeasured confounding.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2021.

\bibitem[Byrd et~al.(1995)Byrd, Lu, Nocedal, and Zhu]{byrd1995limited}
R.~H. Byrd, P.~Lu, J.~Nocedal, and C.~Zhu.
\newblock A limited memory algorithm for bound constrained optimization.
\newblock \emph{SIAM Journal on scientific computing}, 16\penalty0
  (5):\penalty0 1190--1208, 1995.

\bibitem[Chickering(1996)]{Chickering1996learning}
D.~M. Chickering.
\newblock Learning {Bayesian} networks is {NP}-complete.
\newblock In \emph{Learning from Data: Artificial Intelligence and Statistics
  V}. Springer, 1996.

\bibitem[Chickering(2002)]{chickering2002optimal}
D.~M. Chickering.
\newblock Optimal structure identification with greedy search.
\newblock \emph{Journal of machine learning research}, 3\penalty0
  (Nov):\penalty0 507--554, 2002.

\bibitem[Chickering et~al.(2004)Chickering, Heckerman, and
  Meek]{chickering2004large}
M.~Chickering, D.~Heckerman, and C.~Meek.
\newblock Large-sample learning of bayesian networks is np-hard.
\newblock \emph{Journal of Machine Learning Research}, 5, 2004.

\bibitem[Colombo et~al.(2012)Colombo, Maathuis, Kalisch, and
  Richardson]{colombo2012learning}
D.~Colombo, M.~H. Maathuis, M.~Kalisch, and T.~S. Richardson.
\newblock Learning high-dimensional directed acyclic graphs with latent and
  selection variables.
\newblock \emph{The Annals of Statistics}, pages 294--321, 2012.

\bibitem[Coppersmith and Winograd(1990)]{Coppersmith1990matrix}
D.~Coppersmith and S.~Winograd.
\newblock Matrix multiplication via arithmetic progressions.
\newblock \emph{Journal of Symbolic Computation}, 9\penalty0 (3):\penalty0
  251--280, 1990.
\newblock ISSN 0747--7171.
\newblock Computational algebraic complexity editorial.

\bibitem[Cussens(2011)]{Cussens2011bayesian}
J.~Cussens.
\newblock Bayesian network learning with cutting planes.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, 2011.

\bibitem[Erd\"os and R\'enyi(1959)]{Erdos1959random}
P.~Erd\"os and A.~R\'enyi.
\newblock On random graphs {I}.
\newblock \emph{Publicationes Mathematicae}, 6:\penalty0 290--297, 1959.

\bibitem[Fletcher(1987)]{Fletcher1987practical}
R.~Fletcher.
\newblock \emph{Practical Methods of Optimization}.
\newblock Wiley-Interscience, 1987.

\bibitem[Kalainathan and Goudet(2019)]{kalainathan2019causal}
D.~Kalainathan and O.~Goudet.
\newblock Causal discovery toolbox: Uncover causal relationships in python.
\newblock \emph{arXiv preprint arXiv:1903.02278}, 2019.

\bibitem[Knuth(1997)]{Knuth1997art}
D.~E. Knuth.
\newblock \emph{The Art of Computer Programming, Volume 1: (3rd Ed.) Sorting
  and Searching}.
\newblock 1997.

\bibitem[Koivisto and Sood(2004)]{Koivisto2004exact}
M.~Koivisto and K.~Sood.
\newblock Exact {Bayesian} structure discovery in {Bayesian} networks.
\newblock \emph{Journal of Machine Learning Research}, 5\penalty0
  (Dec):\penalty0 549--573, 2004.

\bibitem[Koller and Friedman(2009)]{koller2009probabilistic}
D.~Koller and N.~Friedman.
\newblock \emph{Probabilistic graphical models: principles and techniques}.
\newblock MIT press, 2009.

\bibitem[Lachapelle et~al.(2020)Lachapelle, Brouillard, Deleu, and
  Lacoste-Julien]{Lachapelle2020grandag}
S.~Lachapelle, P.~Brouillard, T.~Deleu, and S.~Lacoste-Julien.
\newblock Gradient-based neural {DAG} learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Lee et~al.(2019)Lee, Danieletto, Miotto, Cherng, and
  Dudley]{lee2019scaling}
H.-C. Lee, M.~Danieletto, R.~Miotto, S.~T. Cherng, and J.~T. Dudley.
\newblock Scaling structural learning with no-bears to infer causal
  transcriptome networks.
\newblock In \emph{PACIFIC SYMPOSIUM ON BIOCOMPUTING 2020}, pages 391--402.
  World Scientific, 2019.

\bibitem[Loh and Bühlmann(2013)]{Loh2013High}
P.~L. Loh and P.~Bühlmann.
\newblock High-dimensional learning of linear causal networks via inverse
  covariance estimation.
\newblock \emph{Journal of Machine Learning Research}, 2013.

\bibitem[Ng et~al.(2020)Ng, Ghassami, and Zhang]{ng2020role}
I.~Ng, A.~Ghassami, and K.~Zhang.
\newblock On the role of sparsity and {DAG} constraints for learning linear
  {DAGs}.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Ng et~al.(2022{\natexlab{a}})Ng, Lachapelle, Ke, Lacoste-Julien, and
  Zhang]{ng2022convergence}
I.~Ng, S.~Lachapelle, N.~R. Ke, S.~Lacoste-Julien, and K.~Zhang.
\newblock On the convergence of continuous constrained optimization for
  structure learning.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2022{\natexlab{a}}.

\bibitem[Ng et~al.(2022{\natexlab{b}})Ng, Zhu, Fang, Li, Chen, and
  Wang]{Ng2022masked}
I.~Ng, S.~Zhu, Z.~Fang, H.~Li, Z.~Chen, and J.~Wang.
\newblock Masked gradient-based causal structure learning.
\newblock In \emph{SIAM International Conference on Data Mining},
  2022{\natexlab{b}}.

\bibitem[Pamfil et~al.(2020)Pamfil, Sriwattanaworachai, Desai, Pilgerstorfer,
  Beaumont, Georgatzis, and Aragam]{Pamfil2020dynotears}
R.~Pamfil, N.~Sriwattanaworachai, S.~Desai, P.~Pilgerstorfer, P.~Beaumont,
  K.~Georgatzis, and B.~Aragam.
\newblock {DYNOTEARS}: Structure learning from time-series data.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2020.

\bibitem[Pearl(2000)]{pearl2000models}
J.~Pearl.
\newblock Models, reasoning and inference.
\newblock \emph{Cambridge, UK: Cambridge University Press}, 19, 2000.

\bibitem[Peters and Bühlmann(2013)]{Peters2013identifiability}
J.~Peters and P.~Bühlmann.
\newblock Identifiability of {Gaussian} structural equation models with equal
  error variances.
\newblock \emph{Biometrika}, 101\penalty0 (1):\penalty0 219--228, 2013.

\bibitem[Powell(1969)]{Powell1969nonlinear}
M.~J.~D. Powell.
\newblock Nonlinear programming—sequential unconstrained minimization
  techniques.
\newblock \emph{The Computer Journal}, 12\penalty0 (3), 1969.

\bibitem[Raskutti and Uhler(2018)]{Raskutti2018learning}
G.~Raskutti and C.~Uhler.
\newblock Learning directed acyclic graph models based on sparsest
  permutations.
\newblock \emph{Stat}, 7\penalty0 (1):\penalty0 e183, 2018.

\bibitem[Sachs et~al.(2005)Sachs, Perez, Pe'er, Lauffenburger, and
  Nolan]{sachs2005causal}
K.~Sachs, O.~Perez, D.~Pe'er, D.~A. Lauffenburger, and G.~P. Nolan.
\newblock Causal protein-signaling networks derived from multiparameter
  single-cell data.
\newblock \emph{Science}, 308\penalty0 (5721):\penalty0 523--529, 2005.

\bibitem[Schrijver(2003)]{schrijver2003combinatorial}
A.~Schrijver.
\newblock \emph{Combinatorial optimization: polyhedra and efficiency},
  volume~24.
\newblock Springer Science \& Business Media, 2003.

\bibitem[Shah and Peters(2020)]{shah2020hardness}
R.~D. Shah and J.~Peters.
\newblock The hardness of conditional independence testing and the generalised
  covariance measure.
\newblock \emph{The Annals of Statistics}, 48\penalty0 (3):\penalty0
  1514--1538, 2020.

\bibitem[Shimizu et~al.(2006)Shimizu, Hoyer, Hyv{\"a}rinen, and
  Kerminen]{Shimizu2006lingam}
S.~Shimizu, P.~O. Hoyer, A.~Hyv{\"a}rinen, and A.~Kerminen.
\newblock A linear {non-Gaussian} acyclic model for causal discovery.
\newblock \emph{Journal of Machine Learning Research}, 7\penalty0
  (Oct):\penalty0 2003--2030, 2006.

\bibitem[Silander and Myllymäki(2006)]{Silander2006simple}
T.~Silander and P.~Myllymäki.
\newblock A simple approach for finding the globally optimal {Bayesian} network
  structure.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, 2006.

\bibitem[Singh and Moore(2005)]{Singh2005finding}
A.~P. Singh and A.~W. Moore.
\newblock Finding optimal {Bayesian} networks by dynamic programming.
\newblock Technical report, Carnegie Mellon University, 2005.

\bibitem[Spirtes and Glymour(1991)]{spirtes1991algorithm}
P.~Spirtes and C.~Glymour.
\newblock An algorithm for fast recovery of sparse causal graphs.
\newblock \emph{Social science computer review}, 9\penalty0 (1):\penalty0
  62--72, 1991.

\bibitem[Spirtes et~al.(1995)Spirtes, Meek, and Richardson]{Spirtes1995causal}
P.~Spirtes, C.~Meek, and T.~Richardson.
\newblock Causal inference in the presence of latent variables and selection
  bias.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, 1995.

\bibitem[Spirtes et~al.(2000)Spirtes, Glymour, Scheines, and
  Heckerman]{spirtes2000causation}
P.~Spirtes, C.~N. Glymour, R.~Scheines, and D.~Heckerman.
\newblock \emph{Causation, prediction, and search}.
\newblock MIT press, 2000.

\bibitem[Strassen(1969)]{Strassen1969gaussian}
V.~Strassen.
\newblock Gaussian elimination is not optimal.
\newblock \emph{Numerische Mathematik}, 13:\penalty0 354--356, 1969.

\bibitem[Tsamardinos et~al.(2003)Tsamardinos, Aliferis, and
  Statnikov]{tsamardinos2003time}
I.~Tsamardinos, C.~F. Aliferis, and A.~Statnikov.
\newblock Time and sample efficient discovery of markov blankets and direct
  causal relations.
\newblock In \emph{Proceedings of the ninth ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pages 673--678, 2003.

\bibitem[Tsamardinos et~al.(2006)Tsamardinos, Brown, and
  Aliferis]{tsamardinos2006max}
I.~Tsamardinos, L.~E. Brown, and C.~F. Aliferis.
\newblock The max-min hill-climbing bayesian network structure learning
  algorithm.
\newblock \emph{Machine learning}, 65\penalty0 (1):\penalty0 31--78, 2006.

\bibitem[Vowels et~al.(2021)Vowels, Camgoz, and Bowden]{vowels2021d}
M.~J. Vowels, N.~C. Camgoz, and R.~Bowden.
\newblock D'ya like dags? a survey on structure learning and causal discovery.
\newblock \emph{arXiv preprint arXiv:2103.02582}, 2021.

\bibitem[Wei et~al.(2020)Wei, Gao, and Yu]{wei2020dags}
D.~Wei, T.~Gao, and Y.~Yu.
\newblock {DAGs} with no fears: A closer look at continuous optimization for
  learning bayesian networks.
\newblock \emph{arXiv preprint arXiv:2010.09133}, 2020.

\bibitem[Yu et~al.(2019)Yu, Chen, Gao, and Yu]{yu2019dag}
Y.~Yu, J.~Chen, T.~Gao, and M.~Yu.
\newblock {DAG-GNN}: Dag structure learning with graph neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  7154--7163. PMLR, 2019.

\bibitem[Yu et~al.(2021)Yu, Gao, Yin, and Ji]{yu2021dag}
Y.~Yu, T.~Gao, N.~Yin, and Q.~Ji.
\newblock {DAGs} with no curl: An efficient dag structure learning approach.
\newblock In \emph{Proceedings of the 38th International Conference on Machine
  Learning}, 2021.

\bibitem[Yuan and Malone(2013)]{Yuan2013learning}
C.~Yuan and B.~Malone.
\newblock Learning optimal {Bayesian} networks: A shortest path perspective.
\newblock \emph{Journal of Artificial Intelligence Research}, 48\penalty0
  (1):\penalty0 23--65, 2013.

\bibitem[Yuan et~al.(2011)Yuan, Malone, and Wu]{Yuan2011learning}
C.~Yuan, B.~Malone, and X.~Wu.
\newblock Learning optimal {Bayesian} networks using {A*} search.
\newblock In \emph{International Joint Conference on Artificial Intelligence},
  2011.

\bibitem[Zhang et~al.(2013)Zhang, Gaiteri, Bodea, Wang, McElwee,
  Podtelezhnikov, Zhang, Xie, Tran, Dobrin, et~al.]{zhang2013integrated}
B.~Zhang, C.~Gaiteri, L.-G. Bodea, Z.~Wang, J.~McElwee, A.~A. Podtelezhnikov,
  C.~Zhang, T.~Xie, L.~Tran, R.~Dobrin, et~al.
\newblock Integrated systems approach identifies genetic nodes and networks in
  late-onset alzheimer’s disease.
\newblock \emph{Cell}, 153\penalty0 (3):\penalty0 707--720, 2013.

\bibitem[Zheng et~al.(2018)Zheng, Aragam, Ravikumar, and Xing]{zheng2018dags}
X.~Zheng, B.~Aragam, P.~Ravikumar, and E.~P. Xing.
\newblock {DAGs} with {No} {Tears}: Continuous optimization for structure
  learning.
\newblock \emph{arXiv preprint arXiv:1803.01422}, 2018.

\bibitem[Zheng et~al.(2020)Zheng, Dan, Aragam, Ravikumar, and
  Xing]{zheng2020learning}
X.~Zheng, C.~Dan, B.~Aragam, P.~Ravikumar, and E.~Xing.
\newblock Learning sparse nonparametric dags.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 3414--3425. PMLR, 2020.

\bibitem[Zhu et~al.(2021)Zhu, Pfadler, Wu, Han, Yang, Ye, Qian, Zhou, and
  Cui]{zhu2021efficient}
R.~Zhu, A.~Pfadler, Z.~Wu, Y.~Han, X.~Yang, F.~Ye, Z.~Qian, J.~Zhou, and
  B.~Cui.
\newblock Efficient and scalable structure learning for bayesian networks:
  Algorithms and applications.
\newblock In \emph{2021 IEEE 37th International Conference on Data Engineering
  (ICDE)}, pages 2613--2624. IEEE, 2021.

\bibitem[Zhu et~al.(2020)Zhu, Ng, and Chen]{zhu2020causal}
S.~Zhu, I.~Ng, and Z.~Chen.
\newblock Causal discovery with reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\end{thebibliography}
