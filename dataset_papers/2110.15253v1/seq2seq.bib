@article{GRU,
  author    = {Kyunghyun Cho and
               Bart van Merrienboer and
               {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
               Fethi Bougares and
               Holger Schwenk and
               Yoshua Bengio},
  title     = {Learning Phrase Representations using {RNN} Encoder-Decoder for Statistical
               Machine Translation},
  journal   = {CoRR},
  volume    = {abs/1406.1078},
  year      = {2014},
  archivePrefix = {arXiv},
  eprint    = {1406.1078},
  timestamp = {Mon, 13 Aug 2018 16:46:44 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ChoMGBSB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{jain2019attention,
      title={Attention is not Explanation}, 
      author={Sarthak Jain and Byron C. Wallace},
      year={2019},
      eprint={1902.10186},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{serrano2019attention,
  title={Is attention interpretable?},
  author={Serrano, Sofia and Smith, Noah A},
  journal={arXiv preprint arXiv:1906.03731},
  year={2019}
}

@misc{wiegreffe2019attention,
      title={Attention is not not Explanation}, 
      author={Sarah Wiegreffe and Yuval Pinter},
      year={2019},
      eprint={1908.04626},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{banon-etal-2020-paracrawl,
    title = "{P}ara{C}rawl: Web-Scale Acquisition of Parallel Corpora",
    author = "Ba{\~n}{\'o}n, Marta  and
      Chen, Pinzhen  and
      Haddow, Barry  and
      Heafield, Kenneth  and
      Hoang, Hieu  and
      Espl{\`a}-Gomis, Miquel  and
      Forcada, Mikel L.  and
      Kamran, Amir  and
      Kirefu, Faheem  and
      Koehn, Philipp  and
      Ortiz Rojas, Sergio  and
      Pla Sempere, Leopoldo  and
      Ram{\'\i}rez-S{\'a}nchez, Gema  and
      Sarr{\'\i}as, Elsa  and
      Strelec, Marek  and
      Thompson, Brian  and
      Waites, William  and
      Wiggins, Dion  and
      Zaragoza, Jaume",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.417",
    doi = "10.18653/v1/2020.acl-main.417",
    pages = "4555--4567",
    abstract = "We report on methods to create the largest publicly available parallel corpora by crawling the web, using open source software. We empirically compare alternative methods and publish benchmark data sets for sentence alignment and sentence pair filtering. We also describe the parallel corpora released and evaluate their quality and their usefulness to create machine translation systems.",
}

@misc{chefer2020transformer,
      title={Transformer Interpretability Beyond Attention Visualization}, 
      author={Hila Chefer and Shir Gur and Lior Wolf},
      year={2020},
      eprint={2012.09838},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{bastings2020elephant,
      title={The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?}, 
      author={Jasmijn Bastings and Katja Filippova},
      year={2020},
      eprint={2010.05607},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{UGRNN,
    title={Capacity and Trainability in Recurrent Neural Networks},
    author={Jasmine Collins and Jascha Sohl-Dickstein and David Sussillo},
    year={2016},
    eprint={1611.09913},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@Article{HochSchm97,
  author      = {Sepp Hochreiter and JÃ¼rgen Schmidhuber},
  journal     = {Neural Computation},
  title       = {Long Short-Term Memory},
  year        = {1997},
  number      = {8},
  pages       = {1735--1780},
  volume      = {9},
  optdoi      = {10.1162/neco.1997.9.8.1735},
  opteprint   = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
  opturl      = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
}

@incollection{Maheswaranathan2019,
title = {Reverse engineering recurrent networks for sentiment classification reveals line attractor dynamics},
author = {Maheswaranathan, Niru and Williams, Alex and Golub, Matthew and Ganguli, Surya and Sussillo, David},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {15696--15705},
year = {2019},
publisher = {Curran Associates, Inc.},
}

@article{maheswaranathan2020recurrent,
  title={How recurrent networks implement contextual processing in sentiment analysis},
  author={Maheswaranathan, Niru and Sussillo, David},
  journal={arXiv preprint arXiv:2004.08013},
  year={2020}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{aitken2020geometry,
  title={The geometry of integration in text classification RNNs},
  author={Aitken, Kyle and Ramasesh, Vinay V and Garg, Ankush and Cao, Yuan and Sussillo, David and Maheswaranathan, Niru},
  journal={arXiv preprint arXiv:2010.15114},
  year={2020}
}

@inproceedings{scan,
  title={Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks},
  author={Lake, Brenden and Baroni, Marco},
  booktitle={International Conference on Machine Learning},
  pages={2873--2882},
  year={2018},
  organization={PMLR}
}

@article{ghader2017does,
  title={What does attention in neural machine translation pay attention to?},
  author={Ghader, Hamidreza and Monz, Christof},
  journal={arXiv preprint arXiv:1710.03348},
  year={2017}
}

@article{ding2019saliency,
  title={Saliency-driven word alignment interpretation for neural machine translation},
  author={Ding, Shuoyang and Xu, Hainan and Koehn, Philipp},
  journal={arXiv preprint arXiv:1906.10282},
  year={2019}
}

@article{luong2015effective,
  title={Effective approaches to attention-based neural machine translation},
  author={Luong, Minh-Thang and Pham, Hieu and Manning, Christopher D},
  journal={arXiv preprint arXiv:1508.04025},
  year={2015}
}

@article{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={arXiv preprint arXiv:1409.3215},
  year={2014}
}

@article{cho2014learning,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.1078},
  year={2014}
}

@article{mohankumar2020towards,
  title={Towards transparent and explainable attention models},
  author={Mohankumar, Akash Kumar and Nema, Preksha and Narasimhan, Sharan and Khapra, Mitesh M and Srinivasan, Balaji Vasan and Ravindran, Balaraman},
  journal={arXiv preprint arXiv:2004.14243},
  year={2020}
}

@misc{wu2016googles,
      title={Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation}, 
      author={Yonghui Wu and Mike Schuster and Zhifeng Chen and Quoc V. Le and Mohammad Norouzi and Wolfgang Macherey and Maxim Krikun and Yuan Cao and Qin Gao and Klaus Macherey et al.},
      year={2016},
      eprint={1609.08144},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{raffel2020exploring,
      title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}, 
      author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
      year={2020},
      eprint={1910.10683},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{chiu2018state,  author={C. {Chiu} and T. N. {Sainath} and Y. {Wu} and R. {Prabhavalkar} and P. {Nguyen} and Z. {Chen} and A. {Kannan} and R. J. {Weiss} and K. {Rao} and E. {Gonina} and N. {Jaitly} and B. {Li} and J. {Chorowski} and M. {Bacchiani}},  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={State-of-the-Art Speech Recognition with Sequence-to-Sequence Models},   year={2018},  volume={},  number={},  pages={4774-4778},  doi={10.1109/ICASSP.2018.8462105}}

@misc{chan2015listen,
      title={Listen, Attend and Spell}, 
      author={William Chan and Navdeep Jaitly and Quoc V. Le and Oriol Vinyals},
      year={2015},
      eprint={1508.01211},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{rohit2017comparison,
title	= {A Comparison of Sequence-to-Sequence Models for Speech Recognition},
author	= {Rohit Prabhavalkar and Kanishka Rao and Tara Sainath and Bo Li and Leif Johnson and Navdeep Jaitly},
year	= {2017},
URL	= {http://www.isca-speech.org/archive/Interspeech_2017/pdfs/0233.PDF}
}

@article{Adam,
author = {Kingma, Diederik and Ba, Jimmy},
year = {2014},
month = {12},
pages = {},
title = {Adam: A Method for Stochastic Optimization},
journal = {International Conference on Learning Representations}
}