\begin{thebibliography}{33}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2014)Agarwal, Chapelle, Dud{\'\i}k, and
  Langford]{agarwal2014reliable}
Agarwal, A., Chapelle, O., Dud{\'\i}k, M., and Langford, J.
\newblock A reliable effective terascale linear learning system.
\newblock \emph{The Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 1111--1133, 2014.

\bibitem[Agarwal et~al.(2018)Agarwal, Beygelzimer, Dud{\'\i}k, Langford, and
  Wallach]{agarwal2018reductions}
Agarwal, A., Beygelzimer, A., Dud{\'\i}k, M., Langford, J., and Wallach, H.
\newblock A reductions approach to fair classification.
\newblock In \emph{International Conference on Machine Learning}, pp.\  60--69.
  PMLR, 2018.

\bibitem[Balcan et~al.(2009)Balcan, Beygelzimer, and
  Langford]{balcan2009agnostic}
Balcan, M.-F., Beygelzimer, A., and Langford, J.
\newblock Agnostic active learning.
\newblock \emph{Journal of Computer and System Sciences}, 75\penalty0
  (1):\penalty0 78--89, 2009.

\bibitem[Bartlett \& Mendelson(2002)Bartlett and
  Mendelson]{bartlett2002rademacher}
Bartlett, P.~L. and Mendelson, S.
\newblock Rademacher and gaussian complexities: Risk bounds and structural
  results.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0
  (Nov):\penalty0 463--482, 2002.

\bibitem[Beygelzimer et~al.(2009)Beygelzimer, Dasgupta, and
  Langford]{beygelzimer2009importance}
Beygelzimer, A., Dasgupta, S., and Langford, J.
\newblock Importance weighted active learning.
\newblock In \emph{Proceedings of the 26th annual international conference on
  machine learning}, pp.\  49--56, 2009.

\bibitem[Beygelzimer et~al.(2010)Beygelzimer, Hsu, Langford, and
  Zhang]{beygelzimer2010agnostic}
Beygelzimer, A., Hsu, D.~J., Langford, J., and Zhang, T.
\newblock Agnostic active learning without constraints.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  199--207, 2010.

\bibitem[Boucheron et~al.(2005)Boucheron, Bousquet, and
  Lugosi]{boucheron2005theory}
Boucheron, S., Bousquet, O., and Lugosi, G.
\newblock Theory of classification: A survey of some recent advances.
\newblock \emph{ESAIM: probability and statistics}, 9:\penalty0 323--375, 2005.

\bibitem[Cao \& Krishnamurthy(2019)Cao and Krishnamurthy]{cao2019disagreement}
Cao, T. and Krishnamurthy, A.
\newblock Disagreement-based combinatorial pure exploration: Sample complexity
  bounds and an efficient algorithm.
\newblock In \emph{Conference on Learning Theory}, pp.\  558--588, 2019.

\bibitem[Castro \& Nowak(2008)Castro and Nowak]{castro2008minimax}
Castro, R.~M. and Nowak, R.~D.
\newblock Minimax bounds for active learning.
\newblock \emph{IEEE Transactions on Information Theory}, 54\penalty0
  (5):\penalty0 2339--2353, 2008.

\bibitem[Chen et~al.(2017)Chen, Gupta, Li, Qiao, and Wang]{chen2017nearly}
Chen, L., Gupta, A., Li, J., Qiao, M., and Wang, R.
\newblock Nearly optimal sampling algorithms for combinatorial pure
  exploration.
\newblock In \emph{Conference on Learning Theory}, pp.\  482--534, 2017.

\bibitem[Cohn et~al.(1994)Cohn, Atlas, and Ladner]{cohn1994improving}
Cohn, D., Atlas, L., and Ladner, R.
\newblock Improving generalization with active learning.
\newblock \emph{Machine learning}, 15\penalty0 (2):\penalty0 201--221, 1994.

\bibitem[Dasgupta et~al.(2007)Dasgupta, Hsu, and
  Monteleoni]{dasgupta2007general}
Dasgupta, S., Hsu, D.~J., and Monteleoni, C.
\newblock A general agnostic active learning algorithm.
\newblock \emph{Advances in neural information processing systems},
  20:\penalty0 353--360, 2007.

\bibitem[Fiez et~al.(2019)Fiez, Jain, Jamieson, and
  Ratliff]{fiez2019sequential}
Fiez, T., Jain, L., Jamieson, K.~G., and Ratliff, L.
\newblock Sequential experimental design for transductive linear bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  10666--10676, 2019.

\bibitem[Hanneke(2007)]{hanneke2007bound}
Hanneke, S.
\newblock A bound on the label complexity of agnostic active learning.
\newblock In \emph{Proceedings of the 24th international conference on Machine
  learning}, pp.\  353--360, 2007.

\bibitem[Hanneke(2009)]{hanneke2009adaptive}
Hanneke, S.
\newblock Adaptive rates of convergence in active learning.
\newblock In \emph{COLT}. Citeseer, 2009.

\bibitem[Hanneke et~al.(2011)]{hanneke2011rates}
Hanneke, S. et~al.
\newblock Rates of convergence in active learning.
\newblock \emph{The Annals of Statistics}, 39\penalty0 (1):\penalty0 333--361,
  2011.

\bibitem[Hanneke et~al.(2014)]{hanneke2014theory}
Hanneke, S. et~al.
\newblock Theory of disagreement-based active learning.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  7\penalty0 (2-3):\penalty0 131--309, 2014.

\bibitem[Hsu(2010)]{hsu2010algorithms}
Hsu, D.~J.
\newblock \emph{Algorithms for active learning}.
\newblock PhD thesis, UC San Diego, 2010.

\bibitem[Huang et~al.(2015)Huang, Agarwal, Hsu, Langford, and
  Schapire]{huang2015efficient}
Huang, T.-K., Agarwal, A., Hsu, D.~J., Langford, J., and Schapire, R.~E.
\newblock Efficient and parsimonious agnostic active learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2755--2763, 2015.

\bibitem[Jain \& Jamieson(2019)Jain and Jamieson]{jain2019new}
Jain, L. and Jamieson, K.~G.
\newblock A new perspective on pool-based active classification and
  false-discovery control.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  13992--14003, 2019.

\bibitem[Karampatziakis \& Langford(2010)Karampatziakis and
  Langford]{karampatziakis2010online}
Karampatziakis, N. and Langford, J.
\newblock Online importance weight aware updates.
\newblock \emph{arXiv preprint arXiv:1011.1576}, 2010.

\bibitem[Katz-Samuels et~al.(2020)Katz-Samuels, Jain, Karnin, and
  Jamieson]{katz2020empirical}
Katz-Samuels, J., Jain, L., Karnin, Z., and Jamieson, K.
\newblock An empirical process approach to the union bound: Practical
  algorithms for combinatorial and linear bandits.
\newblock \emph{arXiv preprint arXiv:2006.11685}, 2020.

\bibitem[Koltchinskii(2010)]{koltchinskii2010rademacher}
Koltchinskii, V.
\newblock Rademacher complexities and bounding the excess risk in active
  learning.
\newblock \emph{The Journal of Machine Learning Research}, 11:\penalty0
  2457--2485, 2010.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Ledoux(2001)]{ledoux2001concentration}
Ledoux, M.
\newblock \emph{The Concentration of Measure Phenomenon}.
\newblock Mathematical surveys and monographs. American Mathematical Society,
  2001.
\newblock ISBN 9780821837924.
\newblock URL \url{https://books.google.com/books?id=mCX\_cWL6rqwC}.

\bibitem[Mussmann \& Liang(2018)Mussmann and Liang]{mussmann2018uncertainty}
Mussmann, S. and Liang, P.
\newblock Uncertainty sampling is preconditioned stochastic gradient descent on
  zero-one loss.
\newblock \emph{arXiv preprint arXiv:1812.01815}, 2018.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Ng]{netzer2011reading}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock 2011.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos,
  Cournapeau, Brucher, Perrot, and Duchesnay]{scikit-learn}
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel,
  O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J.,
  Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2825--2830,
  2011.

\bibitem[Settles(2011)]{settles2011theories}
Settles, B.
\newblock From theories to queries: Active learning in practice.
\newblock In \emph{Active Learning and Experimental Design workshop In
  conjunction with AISTATS 2010}, pp.\  1--18, 2011.

\bibitem[Soare et~al.(2014)Soare, Lazaric, and Munos]{soare2014best}
Soare, M., Lazaric, A., and Munos, R.
\newblock Best-arm identification in linear bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  828--836, 2014.

\bibitem[Talagrand(2014)]{talagrand2014upper}
Talagrand, M.
\newblock \emph{Upper and lower bounds for stochastic processes: modern methods
  and classical problems}, volume~60.
\newblock Springer Science \& Business Media, 2014.

\bibitem[Vershynin(2019)]{vershynin2019high}
Vershynin, R.
\newblock \emph{High-Dimensional Probability}.
\newblock 2019.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017fashion}
Xiao, H., Rasul, K., and Vollgraf, R.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock \emph{arXiv preprint arXiv:1708.07747}, 2017.

\end{thebibliography}
