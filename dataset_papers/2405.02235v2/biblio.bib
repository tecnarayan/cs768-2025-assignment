@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{SEHNKE2010551,
    title = {Parameter-exploring policy gradients},
    journal = {Neural Networks},
    volume = {23},
    number = {4},
    pages = {551-559},
    year = {2010},
    note = {The International Conference on Artificial Neural Networks (ICANN)},
    author = {Frank Sehnke and Christian Osendorfer and Thomas Rückstieß and Alex Graves and Jan Peters and Jürgen Schmidhuber},
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={12},
  year={1999}
}

@article{deisenroth2013survey,
  author       = {Marc Peter Deisenroth and
                  Gerhard Neumann and
                  Jan Peters},
  title        = {A Survey on Policy Search for Robotics},
  journal      = {Foundations and Trends in Robotics},
  volume       = {2},
  number       = {1-2},
  pages        = {1--142},
  year         = {2013}
}

@article{baxter2001infinite,
  author       = {Jonathan Baxter and
                  Peter L. Bartlett},
  title        = {Infinite-Horizon Policy-Gradient Estimation},
  journal      = {Journal of Artificial Intelligence Research (JAIR)},
  volume       = {15},
  pages        = {319--350},
  year         = {2001}
}

@article{puterman1990markov,
  title={Markov decision processes},
  author={Puterman, Martin L},
  journal={Handbooks in operations research and management science},
  volume={2},
  pages={331--434},
  year={1990},
  publisher={Elsevier}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={387--395},
  year={2014},
  organization={PMLR}
}

@inproceedings{yuan2022general,
  title={A general sample complexity analysis of vanilla policy gradient},
  author={Yuan, Rui and Gower, Robert M and Lazaric, Alessandro},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={3332--3380},
  year={2022},
  organization={PMLR}
}

@article{papini2022smoothing,
  title={Smoothing policies and safe policy gradients},
  author={Papini, Matteo and Pirotta, Matteo and Restelli, Marcello},
  journal={Machine Learning},
  volume={111},
  number={11},
  pages={4081--4137},
  year={2022},
  publisher={Springer}
}

@inproceedings{papini2018stochastic,
  author       = {Matteo Papini and
                  Damiano Binaghi and
                  Giuseppe Canonaco and
                  Matteo Pirotta and
                  Marcello Restelli},
  title        = {Stochastic Variance-Reduced Policy Gradient},
  booktitle    = {International Conference on Machine Learning (ICML)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {80},
  pages        = {4023--4032},
  publisher    = {{PMLR}},
  year         = {2018}
}

@inproceedings{xu2019improved,
  author       = {Pan Xu and
                  Felicia Gao and
                  Quanquan Gu},
  title        = {An Improved Convergence Analysis of Stochastic Variance-Reduced Policy Gradient},
  booktitle    = {Uncertainty in Artificial Intelligence (UAI)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {115},
  pages        = {541--551},
  publisher    = {{AUAI} Press},
  year         = {2019}
}

@inproceedings{xu2020sample,
  author       = {Pan Xu and
                  Felicia Gao and
                  Quanquan Gu},
  title        = {Sample Efficient Policy Gradient Methods with Recursive Variance Reduction},
  booktitle    = {International Conference on Learning Representations (ICLR)},
  publisher    = {OpenReview.net},
  year         = {2020}
}

@article{bhandari2019global,
  title={Global optimality guarantees for policy gradient methods},
  author={Bhandari, Jalaj and Russo, Daniel},
  journal={Operations Research},
  year={2024},
  publisher={INFORMS}
}

@inproceedings{scherrer2014local,
  author       = {Bruno Scherrer and
                  Matthieu Geist},
  title        = {Local Policy Search in a Convex Space and Conservative Policy Iteration as Boosted Policy Search},
  booktitle    = {Machine Learning and Knowledge Discovery in Databases: European Conference (ECML PKDD)},
  series       = {Lecture Notes in Computer Science},
  volume       = {8726},
  pages        = {35--50},
  publisher    = {Springer},
  year         = {2014}
}

@inproceedings{fazel2018global,
  author       = {Maryam Fazel and
                  Rong Ge and
                  Sham M. Kakade and
                  Mehran Mesbahi},
  title        = {Global Convergence of Policy Gradient Methods for the Linear Quadratic
                  Regulator},
  booktitle    = {International Conference on Machine Learning (ICML)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {80},
  pages        = {1466--1475},
  publisher    = {{PMLR}},
  year         = {2018}
}

@article{agarwal2021theory,
  author       = {Alekh Agarwal and
                  Sham M. Kakade and
                  Jason D. Lee and
                  Gaurav Mahajan},
  title        = {On the Theory of Policy Gradient Methods: Optimality, Approximation,
                  and Distribution Shift},
  journal      = {Journal of Machine Learning Research (JMLR)},
  volume       = {22},
  pages        = {98:1--98:76},
  year         = {2021}
}

@article{lojasiewicz1963propriete,
  title={Une propri{\'e}t{\'e} topologique des sous-ensembles analytiques r{\'e}els},
  author={Lojasiewicz, Stanislaw},
  journal={Les {\'e}quations aux d{\'e}riv{\'e}es partielles},
  volume={117},
  pages={87--89},
  year={1963}
}

@article{polyak1963gradient,
  title={Gradient methods for minimizing functionals},
  author={Polyak, Boris Teodorovich and others},
  journal={Zhurnal vychislitel’noi matematiki i matematicheskoi fiziki},
  volume={3},
  number={4},
  pages={643--653},
  year={1963}
}

@inproceedings{kurdyka1998gradients,
  title={On gradients of functions definable in o-minimal structures},
  author={Kurdyka, Krzysztof},
  booktitle={Annales de l'institut Fourier},
  volume={48},
  number={3},
  pages={769--783},
  year={1998}
}

@inproceedings{karimi2016linear,
  title={Linear convergence of gradient and proximal-gradient methods under the polyak-{\l}ojasiewicz condition},
  author={Karimi, Hamed and Nutini, Julie and Schmidt, Mark},
  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference (ECML PKDD)},
  pages={795--811},
  year={2016},
  organization={Springer}
}

@inproceedings{mei2020global,
  author       = {Jincheng Mei and
                  Chenjun Xiao and
                  Csaba Szepesv{\'{a}}ri and
                  Dale Schuurmans},
  title        = {On the Global Convergence Rates of Softmax Policy Gradient Methods},
  booktitle    = {International Conference on Machine Learning (ICML)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {119},
  pages        = {6820--6829},
  publisher    = {{PMLR}},
  year         = {2020}
}

@inproceedings{lisoftmax2021,
  author       = {Gen Li and
                  Yuting Wei and
                  Yuejie Chi and
                  Yuantao Gu and
                  Yuxin Chen},
  title        = {Softmax Policy Gradient Methods Can Take Exponential Time to Converge},
  booktitle    = {Proceedings of the Annual Conference on Learning Theory (COLT)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {134},
  pages        = {3107--3110},
  publisher    = {{PMLR}},
  year         = {2021}
}

@inproceedings{liu2020improved,
  author       = {Yanli Liu and
                  Kaiqing Zhang and
                  Tamer Basar and
                  Wotao Yin},
  title        = {An Improved Analysis of (Variance-Reduced) Policy Gradient and Natural Policy Gradient Methods},
  booktitle    = {Advances in Neural Information Processing Systems (NeurIPS)},
  year         = {2020}
}

@inproceedings{fatkhullin2023stochastic,
  author       = {Ilyas Fatkhullin and
                  Anas Barakat and
                  Anastasia Kireeva and
                  Niao He},
  title        = {Stochastic Policy Gradient Methods: Improved Sample Complexity for
                  Fisher-non-degenerate Policies},
  booktitle    = {International Conference on Machine Learning (ICML)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {202},
  pages        = {9827--9869},
  publisher    = {{PMLR}},
  year         = {2023}
}

@inproceedings{shen2019hessian,
  author       = {Zebang Shen and
                  Alejandro Ribeiro and
                  Hamed Hassani and
                  Hui Qian and
                  Chao Mi},
  title        = {Hessian Aided Policy Gradient},
  booktitle    = {International Conference on Machine Learning (ICML)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {97},
  pages        = {5729--5738},
  publisher    = {{PMLR}},
  year         = {2019}
}

@article{yossi2023lower,
  author       = {Yossi Arjevani and
                  Yair Carmon and
                  John C. Duchi and
                  Dylan J. Foster and
                  Nathan Srebro and
                  Blake E. Woodworth},
  title        = {Lower bounds for non-convex stochastic optimization},
  journal      = {Math. Program.},
  volume       = {199},
  number       = {1},
  pages        = {165--214},
  year         = {2023}
}

@inproceedings{yossi2020second,
  author       = {Yossi Arjevani and
                  Yair Carmon and
                  John C. Duchi and
                  Dylan J. Foster and
                  Ayush Sekhari and
                  Karthik Sridharan},
  title        = {Second-Order Information in Non-Convex Stochastic Optimization: Power
                  and Limitations},
  booktitle    = {Proceedings of the Annual Conference on Learning Theory (COLT)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {125},
  pages        = {242--299},
  publisher    = {{PMLR}},
  year         = {2020}
}

@book{schwefel1993evolution,
  title={Evolution and optimum seeking: the sixth generation},
  author={Schwefel, Hans-Paul Paul},
  year={1993},
  publisher={John Wiley \& Sons, Inc.}
}

@inproceedings{deisenroth2011pilco,
  author       = {Marc Peter Deisenroth and
                  Carl Edward Rasmussen},
  title        = {{PILCO:} {A} Model-Based and Data-Efficient Approach to Policy Search},
  booktitle    = {International Conference on Machine Learning (ICML)},
  pages        = {465--472},
  publisher    = {Omnipress},
  year         = {2011}
}

@inproceedings{lillicrap2016continuous,
  author       = {Timothy P. Lillicrap and
                  Jonathan J. Hunt and
                  Alexander Pritzel and
                  Nicolas Heess and
                  Tom Erez and
                  Yuval Tassa and
                  David Silver and
                  Daan Wierstra},
  title        = {Continuous control with deep reinforcement learning},
  booktitle    = {International Conference on Learning Representations (ICLR)},
  year         = {2016}
}

@inproceedings{fujimoto2018addressing,
  author       = {Scott Fujimoto and
                  Herke van Hoof and
                  David Meger},
  title        = {Addressing Function Approximation Error in Actor-Critic Methods},
  booktitle    = {International Conference on Machine Learning (ICML)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {80},
  pages        = {1582--1591},
  publisher    = {{PMLR}},
  year         = {2018}
}

@inproceedings{saleh2022truly,
  author       = {Ehsan Saleh and
                  Saba Ghaffari and
                  Timothy Bretl and
                  Matthew West},
  title        = {Truly Deterministic Policy Optimization},
  booktitle    = {Advances in Neural Information Processing Systems (NeurIPS)},
  year         = {2022}
}

@inproceedings{papini2020balancing,
  author       = {Matteo Papini and
                  Andrea Battistello and
                  Marcello Restelli},
  title        = {Balancing Learning Speed and Stability in Policy Gradient via Adaptive
                  Exploration},
  booktitle    = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {108},
  pages        = {1188--1199},
  publisher    = {{PMLR}},
  year         = {2020}
}


@article{bolland2023policy,
title={Policy Gradient Algorithms Implicitly Optimize by Continuation},
author={Adrien Bolland and Gilles Louppe and Damien Ernst},
journal={Transactions on Machine Learning Research},
publisher={OpenReview.net},
year={2023}
}

@book{allgower1990numerical,
  author       = {Eugene L. Allgower and
                  Kurt Georg},
  title        = {Numerical continuation methods - an introduction},
  series       = {Springer series in computational mathematics},
  volume       = {13},
  publisher    = {Springer},
  year         = {1990}
}

@article{peters2008reinforcement,
  title={Reinforcement learning of motor skills with policy gradients},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neural Networks},
  volume={21},
  number={4},
  pages={682--697},
  year={2008},
  publisher={Elsevier}
}

@inproceedings{peters2006policy,
  title={Policy gradient methods for robotics},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={2219--2225},
  year={2006},
  organization={IEEE}
}

@article{gravell2020learning,
  title={Learning optimal controllers for linear systems with multiplicative noise via policy gradient},
  author={Gravell, Benjamin and Esfahani, Peyman Mohajerin and Summers, Tyler},
  journal={IEEE Transactions on Automatic Control},
  volume={66},
  number={11},
  pages={5283--5298},
  year={2020},
  publisher={IEEE}
}

@article{azizzadenesheli2018policy,
  title={Policy gradient in partially observable environments: Approximation and convergence},
  author={Azizzadenesheli, Kamyar and Yue, Yisong and Anandkumar, Animashree},
  journal={arXiv preprint arXiv:1810.07900},
  year={2018}
}

@article{ghavamzadeh2006bayesian,
  title={Bayesian policy gradient algorithms},
  author={Ghavamzadeh, Mohammad and Engel, Yaakov},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={19},
  year={2006}
}

@article{likmeta2020combining,
  title={Combining reinforcement learning with rule-based controllers for transparent and general decision-making in autonomous driving},
  author={Likmeta, Amarildo and Metelli, Alberto Maria and Tirinzoni, Andrea and Giol, Riccardo and Restelli, Marcello and Romano, Danilo},
  journal={Robotics and Autonomous Systems},
  volume={131},
  pages={103568},
  year={2020},
  publisher={Elsevier}
}

@article{agarwal2020pc,
  title={Pc-pg: Policy cover directed exploration for provable policy gradient learning},
  author={Agarwal, Alekh and Henaff, Mikael and Kakade, Sham and Sun, Wen},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={33},
  pages={13399--13412},
  year={2020}
}

@inproceedings{mutti2021task,
  title={Task-agnostic exploration via policy gradient of a non-parametric state entropy estimate},
  author={Mutti, Mirco and Pratissoli, Lorenzo and Restelli, Marcello},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  volume={35},
  number={10},
  pages={9028--9036},
  year={2021}
}

@inproceedings{xiong2022deterministic,
  title={Deterministic policy gradient: Convergence analysis},
  author={Xiong, Huaqing and Xu, Tengyu and Zhao, Lin and Liang, Yingbin and Zhang, Wei},
  booktitle={Uncertainty in Artificial Intelligence (UAI)},
  pages={2159--2169},
  year={2022},
  organization={PMLR}
}

@article{kumar2020zeroth,
  title={Zeroth-order deterministic policy gradient},
  author={Kumar, Harshat and Kalogerias, Dionysios S and Pappas, George J and Ribeiro, Alejandro},
  journal={arXiv preprint arXiv:2006.07314},
  year={2020}
}

@article{masiha2022stochastic,
  title={Stochastic second-order methods improve best-known sample complexity of sgd for gradient-dominated functions},
  author={Masiha, Saeed and Salehkaleybar, Saber and He, Niao and Kiyavash, Negar and Thiran, Patrick},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={35},
  pages={10862--10875},
  year={2022}
}

@article{pirotta2015policy,
  title={Policy gradient in lipschitz markov decision processes},
  author={Pirotta, Matteo and Restelli, Marcello and Bascetta, Luca},
  journal={Machine Learning},
  volume={100},
  pages={255--283},
  year={2015},
  publisher={Springer}
}

@inproceedings{ding2022global,
  author       = {Yuhao Ding and
                  Junzi Zhang and
                  Javad Lavaei},
  title        = {On the Global Optimum Convergence of Momentum-based Policy Gradient},
  booktitle    = {{International Conference on Artificial Intelligence and Statistics (AISTATS)}},
  series       = {Proceedings of Machine Learning Research},
  volume       = {151},
  pages        = {1910--1934},
  publisher    = {{PMLR}},
  year         = {2022}
}

@article{azar2013minimax,
  author       = {Mohammad Gheshlaghi Azar and
                  R{\'{e}}mi Munos and
                  Hilbert J. Kappen},
  title        = {Minimax {PAC} bounds on the sample complexity of reinforcement learning
                  with a generative model},
  journal      = {Machine Learning},
  volume       = {91},
  number       = {3},
  pages        = {325--349},
  year         = {2013}
}

@inproceedings{peters2005natural,
  author       = {Jan Peters and
                  Sethu Vijayakumar and
                  Stefan Schaal},
  title        = {Natural Actor-Critic},
  booktitle    = {{European Conference on Machine Learning (ECML)}},
  series       = {Lecture Notes in Computer Science},
  volume       = {3720},
  pages        = {280--291},
  publisher    = {Springer},
  year         = {2005}
}

@inproceedings{kakade2001natural,
  author       = {Sham M. Kakade},
  title        = {A Natural Policy Gradient},
  booktitle    = {{Advances in Neural Information Processing Systems (NeurIPS)}},
  pages        = {1531--1538},
  publisher    = {{MIT} Press},
  year         = {2001}
}

@inproceedings{SchulmanLAJM15,
  author       = {John Schulman and
                  Sergey Levine and
                  Pieter Abbeel and
                  Michael I. Jordan and
                  Philipp Moritz},
  editor       = {Francis R. Bach and
                  David M. Blei},
  title        = {Trust Region Policy Optimization},
  booktitle    = {Proceedings of the 32nd International Conference on Machine Learning,
                  (ICML) 2015, Lille, France, 6-11 July 2015},
  series       = {(JMLR) Workshop and Conference Proceedings},
  volume       = {37},
  pages        = {1889--1897},
  publisher    = {JMLR.org},
  year         = {2015},
}

@inproceedings{HaarnojaZAL18,
  author       = {Tuomas Haarnoja and
                  Aurick Zhou and
                  Pieter Abbeel and
                  Sergey Levine},
  editor       = {Jennifer G. Dy and
                  Andreas Krause},
  title        = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  booktitle    = {International Conference on Machine Learning (ICML)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {80},
  pages        = {1856--1865},
  publisher    = {{PMLR}},
  year         = {2018},
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@inproceedings{zhao2011analysis,
  author       = {Tingting Zhao and
                  Hirotaka Hachiya and
                  Gang Niu and
                  Masashi Sugiyama},
  title        = {Analysis and Improvement of Policy Gradient Estimation},
  booktitle    = {Advances in Neural Information Processing Systems (NeurIPS)},
  pages        = {262--270},
  year         = {2011}
}

@inproceedings{ahmed2019understanding,
  author       = {Zafarali Ahmed and
                  Nicolas Le Roux and
                  Mohammad Norouzi and
                  Dale Schuurmans},
  title        = {Understanding the Impact of Entropy on Policy Optimization},
  booktitle    = {International Conference on Machine Learning (ICML)},
  series       = {Proceedings of Machine Learning Research},
  volume       = {97},
  pages        = {151--160},
  publisher    = {{PMLR}},
  year         = {2019}
}

@inproceedings{metelli2018policy,
  author       = {Alberto Maria Metelli and
                  Matteo Papini and
                  Francesco Faccio and
                  Marcello Restelli},
  title        = {Policy Optimization via Importance Sampling},
  booktitle    = {Advances in Neural Information Processing Systems (NeurIPS)},
  pages        = {5447--5459},
  year         = {2018}
}

@inproceedings{MetelliPDR21,
  author       = {Alberto Maria Metelli and
                  Matteo Papini and
                  Pierluca D'Oro and
                  Marcello Restelli},
  title        = {Policy Optimization as Online Learning with Mediator Feedback},
  booktitle    = {{AAAI} Conference on Artificial Intelligence ({AAAI})},
  pages        = {8958--8966},
  publisher    = {{AAAI} Press},
  year         = {2021},
}

@article{MetelliPMR20,
  author       = {Alberto Maria Metelli and
                  Matteo Papini and
                  Nico Montali and
                  Marcello Restelli},
  title        = {Importance Sampling Techniques for Policy Optimization},
  journal      = {J. Mach. Learn. Res.},
  volume       = {21},
  pages        = {141:1--141:75},
  year         = {2020},
}

@article{SchulmanWDRK17,
  author       = {John Schulman and
                  Filip Wolski and
                  Prafulla Dhariwal and
                  Alec Radford and
                  Oleg Klimov},
  title        = {Proximal Policy Optimization Algorithms},
  journal      = {CoRR},
  volume       = {abs/1707.06347},
  year         = {2017},
}

@inproceedings{duan2016benchmarking,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1329--1338},
  year={2016},
  organization={PMLR}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{stable-baselines3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research (JMLR)},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1-8}
}

@misc{glp2020aaaitutorial,
    author       = {Mohammad Ghavamzadeh and
    Alessandro Lazaric and
    Matteo Pirotta},
    title        = {Exploration in Reinforcement Learning},
    howpublished = {Tutorial at AAAI'20},
    year         = {2020},
}

@inproceedings{shani2020adaptive,
  author       = {Lior Shani and
                  Yonathan Efroni and
                  Shie Mannor},
  title        = {Adaptive Trust Region Policy Optimization: Global Convergence and
                  Faster Rates for Regularized MDPs},
  booktitle    = {{AAAI}},
  pages        = {5668--5675},
  publisher    = {{AAAI} Press},
  year         = {2020}
}

@article{kucera1992optimal,
  author       = {Vladim{\'{\i}}r Kucera},
  title        = {Optimal control: Linear quadratic methods: Brian D. O. Anderson and
                  John B. Moore},
  journal      = {Autom.},
  volume       = {28},
  number       = {5},
  pages        = {1068--1069},
  year         = {1992}
}