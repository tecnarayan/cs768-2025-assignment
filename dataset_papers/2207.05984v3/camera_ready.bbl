% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{karalias2020erdos}
N.~Karalias and A.~Loukas, ``Erdos goes neural: an unsupervised learning
  framework for combinatorial optimization on graphs,'' \emph{Advances in
  Neural Information Processing Systems}, vol.~33, 2020.

\bibitem{papadimitriou1998combinatorial}
C.~H. Papadimitriou and K.~Steiglitz, \emph{Combinatorial optimization:
  algorithms and complexity}.\hskip 1em plus 0.5em minus 0.4em\relax Courier
  Corporation, 1998.

\bibitem{naseri2020application}
G.~Naseri and M.~A. Koffas, ``Application of combinatorial optimization
  strategies in synthetic biology,'' \emph{Nature communications}, vol.~11,
  no.~1, 2020.

\bibitem{crama1997combinatorial}
Y.~Crama, ``Combinatorial optimization models for production scheduling in
  automated manufacturing systems,'' \emph{European Journal of Operational
  Research}, vol.~99, no.~1, 1997.

\bibitem{hopfield1985neural}
J.~J. Hopfield and D.~W. Tank, ``“neural” computation of decisions in
  optimization problems,'' \emph{Biological Cybernetics}, vol.~52, no.~3, 1985.

\bibitem{smith1999neural}
K.~A. Smith, ``Neural networks for combinatorial optimization: a review of more
  than a decade of research,'' \emph{INFORMS Journal on Computing}, vol.~11,
  no.~1, 1999.

\bibitem{vinyals2015pointer}
O.~Vinyals, M.~Fortunato, and N.~Jaitly, ``Pointer networks,'' \emph{Advances
  in Neural Information Processing Systems}, vol.~28, 2015.

\bibitem{selsam2018learning}
D.~Selsam, M.~Lamm, B.~Benedikt, P.~Liang, L.~de~Moura, D.~L. Dill
  \emph{et~al.}, ``Learning a sat solver from single-bit supervision,'' in
  \emph{International Conference on Learning Representations}, 2018.

\bibitem{amizadeh2018learning}
S.~Amizadeh, S.~Matusevych, and M.~Weimer, ``Learning to solve circuit-sat: An
  unsupervised differentiable approach,'' in \emph{International Conference on
  Learning Representations}, 2018.

\bibitem{yolcu2019learning}
E.~Yolcu and B.~P{\'o}czos, ``Learning local search heuristics for boolean
  satisfiability,'' \emph{Advances in Neural Information Processing Systems},
  vol.~32, 2019.

\bibitem{khalil2016learning}
E.~Khalil, P.~Le~Bodic, L.~Song, G.~Nemhauser, and B.~Dilkina, ``Learning to
  branch in mixed integer programming,'' in \emph{Proceedings of the AAAI
  Conference on Artificial Intelligence}, vol.~30, no.~1, 2016.

\bibitem{gasse2019exact}
M.~Gasse, D.~Ch{\'e}telat, N.~Ferroni, L.~Charlin, and A.~Lodi, ``Exact
  combinatorial optimization with graph convolutional neural networks,''
  \emph{Advances in Neural Information Processing Systems}, vol.~32, 2019.

\bibitem{delarue2020reinforcement}
A.~Delarue, R.~Anderson, and C.~Tjandraatmadja, ``Reinforcement learning with
  combinatorial actions: An application to vehicle routing,'' \emph{Advances in
  Neural Information Processing Systems}, vol.~33, 2020.

\bibitem{khalil2017learning}
E.~Khalil, H.~Dai, Y.~Zhang, B.~Dilkina, and L.~Song, ``Learning combinatorial
  optimization algorithms over graphs,'' \emph{Advances in Neural Information
  Processing Systems}, vol.~30, 2017.

\bibitem{li2018combinatorial}
Z.~Li, Q.~Chen, and V.~Koltun, ``Combinatorial optimization with graph
  convolutional networks and guided tree search,'' \emph{Advances in Neural
  Information Processing Systems}, vol.~31, 2018.

\bibitem{bello2016neural}
I.~Bello, H.~Pham, Q.~V. Le, M.~Norouzi, and S.~Bengio, ``Neural combinatorial
  optimization with reinforcement learning,'' \emph{International Conference on
  Learning Representations (Workshop)}, 2017.

\bibitem{chen2019learning}
X.~Chen and Y.~Tian, ``Learning to perform local rewriting for combinatorial
  optimization,'' \emph{Advances in Neural Information Processing Systems},
  vol.~32, 2019.

\bibitem{kool2018attention}
W.~Kool, H.~van Hoof, and M.~Welling, ``Attention, learn to solve routing
  problems!'' in \emph{International Conference on Learning Representations},
  2018.

\bibitem{joshi2019efficient}
C.~K. Joshi, T.~Laurent, and X.~Bresson, ``An efficient graph convolutional
  network technique for the travelling salesman problem,'' \emph{arXiv preprint
  arXiv:1906.01227}, 2019.

\bibitem{hudson2021graph}
B.~Hudson, Q.~Li, M.~Malencia, and A.~Prorok, ``Graph neural network guided
  local search for the traveling salesperson problem,'' \emph{International
  Conference on Learning Representations}, 2022.

\bibitem{ma2021learning}
Y.~Ma, J.~Li, Z.~Cao, W.~Song, L.~Zhang, Z.~Chen, and J.~Tang, ``Learning to
  iteratively solve routing problems with dual-aspect collaborative
  transformer,'' \emph{Advances in Neural Information Processing Systems},
  vol.~34, 2021.

\bibitem{kwon2021matrix}
Y.-D. Kwon, J.~Choo, I.~Yoon, M.~Park, D.~Park, and Y.~Gwon, ``Matrix encoding
  networks for neural combinatorial optimization,'' \emph{Advances in Neural
  Information Processing Systems}, vol.~34, 2021.

\bibitem{kim2021learning}
M.~Kim, J.~Park \emph{et~al.}, ``Learning collaborative policies to solve
  np-hard routing problems,'' \emph{Advances in Neural Information Processing
  Systems}, vol.~34, 2021.

\bibitem{wu2022highlevel}
N.~Wu, H.~Yang, Y.~Xie, p.~Li, and C.~Hao, ``High-level synthesis performance
  prediction using gnns: Benchmarking, modeling, and advancing,'' in
  \emph{Proceedings of IEEE/ACM Design Automation Conference (DAC), 2022.},
  2022.

\bibitem{mendis2019ithemal}
C.~Mendis, A.~Renda, S.~Amarasinghe, and M.~Carbin, ``Ithemal: Accurate,
  portable and fast basic block throughput estimation using deep neural
  networks,'' in \emph{International Conference on Machine Learning}, 2019.

\bibitem{zhang2019circuit}
G.~Zhang, H.~He, and D.~Katabi, ``Circuit-gnn: Graph neural networks for
  distributed circuit design,'' in \emph{International Conference on Machine
  Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2019.

\bibitem{vasudevan2021learning}
S.~Vasudevan, W.~J. Jiang, D.~Bieber, R.~Singh, C.~R. Ho, C.~Sutton
  \emph{et~al.}, ``Learning semantic representations to verify hardware
  designs,'' \emph{Advances in Neural Information Processing Systems}, vol.~34,
  2021.

\bibitem{mishra2018caloree}
N.~Mishra, C.~Imes, J.~D. Lafferty, and H.~Hoffmann, ``Caloree: Learning
  control for predictable latency and low energy,'' in \emph{Proceedings of the
  Twenty-Third International Conference on Architectural Support for
  Programming Languages and Operating Systems}, 2018.

\bibitem{renda2020difftune}
A.~Renda, Y.~Chen, C.~Mendis, and M.~Carbin, ``Difftune: Optimizing cpu
  simulator parameters with learned differentiable surrogates,'' in \emph{2020
  53rd Annual IEEE/ACM International Symposium on Microarchitecture
  (MICRO)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2020.

\bibitem{wu2021ironman}
N.~Wu, Y.~Xie, and C.~Hao, ``Ironman: Gnn-assisted design space exploration in
  high-level synthesis via reinforcement learning,'' in \emph{Proceedings of
  the 2021 on Great Lakes Symposium on VLSI}, 2021.

\bibitem{mirhoseini2021graph}
A.~Mirhoseini, A.~Goldie, M.~Yazgan, J.~W. Jiang, E.~Songhori, S.~Wang, Y.-J.
  Lee, E.~Johnson, O.~Pathak, A.~Nazi \emph{et~al.}, ``A graph placement
  methodology for fast chip design,'' \emph{Nature}, vol. 594, no. 7862, 2021.

\bibitem{chen1991enzyme}
K.~Chen and F.~H. Arnold, ``Enzyme engineering for nonaqueous solvents: random
  mutagenesis to enhance activity of subtilisin e in polar organic media,''
  \emph{Bio/Technology}, vol.~9, no.~11, 1991.

\bibitem{angermueller2019model}
C.~Angermueller, D.~Dohan, D.~Belanger, R.~Deshpande, K.~Murphy, and
  L.~Colwell, ``Model-based reinforcement learning for biological sequence
  design,'' in \emph{International Conference on Learning Representations},
  2019.

\bibitem{gomez2018automatic}
R.~G{\'o}mez-Bombarelli, J.~N. Wei, D.~Duvenaud, J.~M. Hern{\'a}ndez-Lobato,
  B.~S{\'a}nchez-Lengeling, D.~Sheberla, J.~Aguilera-Iparraguirre, T.~D.
  Hirzel, R.~P. Adams, and A.~Aspuru-Guzik, ``Automatic chemical design using a
  data-driven continuous representation of molecules,'' \emph{ACS Central
  Science}, vol.~4, no.~2, 2018.

\bibitem{bertsimas1993simulated}
D.~Bertsimas and J.~Tsitsiklis, ``Simulated annealing,'' \emph{Statistical
  Science}, vol.~8, no.~1, 1993.

\bibitem{toenshoff2019run}
J.~Toenshoff, M.~Ritzert, H.~Wolf, and M.~Grohe, ``Run-csp: unsupervised
  learning of message passing networks for binary constraint satisfaction
  problems,'' 2019.

\bibitem{yao2019experimental}
W.~Yao, A.~S. Bandeira, and S.~Villar, ``Experimental performance of graph
  neural networks on random instances of max-cut,'' in \emph{Wavelets and
  Sparsity XVIII}, vol. 11138.\hskip 1em plus 0.5em minus 0.4em\relax
  International Society for Optics and Photonics, 2019.

\bibitem{yehuda2020s}
G.~Yehuda, M.~Gabel, and A.~Schuster, ``It’s not what machines can learn,
  it’s what we cannot teach,'' in \emph{International Conference on Machine
  Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2020.

\bibitem{mnih2015human}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~A. Rusu, J.~Veness, M.~G. Bellemare,
  A.~Graves, M.~Riedmiller, A.~K. Fidjeland, G.~Ostrovski \emph{et~al.},
  ``Human-level control through deep reinforcement learning,'' \emph{Nature},
  vol. 518, no. 7540, 2015.

\bibitem{gandhi2006dependent}
R.~Gandhi, S.~Khuller, S.~Parthasarathy, and A.~Srinivasan, ``Dependent
  rounding and its applications to approximation algorithms,'' \emph{Journal of
  the ACM (JACM)}, vol.~53, no.~3, 2006.

\bibitem{byrka2013steiner}
J.~Byrka, F.~Grandoni, T.~Rothvo{\ss}, and L.~Sanit{\`a}, ``Steiner tree
  approximation via iterative randomized rounding,'' \emph{Journal of the ACM
  (JACM)}, vol.~60, no.~1, 2013.

\bibitem{han2013approximate}
J.~Han and M.~Orshansky, ``Approximate computing: An emerging paradigm for
  energy-efficient design,'' in \emph{2013 18th IEEE European Test Symposium
  (ETS)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2013.

\bibitem{mittal2016survey}
S.~Mittal, ``A survey of techniques for approximate computing,'' \emph{ACM
  Computing Surveys (CSUR)}, vol.~48, no.~4, 2016.

\bibitem{venkatesan2011macaco}
R.~Venkatesan, A.~Agarwal, K.~Roy, and A.~Raghunathan, ``Macaco: Modeling and
  analysis of circuits for approximate computing,'' in \emph{2011 IEEE/ACM
  International Conference on Computer-Aided Design (ICCAD)}.\hskip 1em plus
  0.5em minus 0.4em\relax IEEE, 2011.

\bibitem{ma2021workload}
D.~Ma, R.~Thapa, X.~Wang, X.~Jiao, and C.~Hao, ``Workload-aware approximate
  computing configuration,'' in \emph{2021 Design, Automation \& Test in Europe
  Conference \& Exhibition (DATE)}.\hskip 1em plus 0.5em minus 0.4em\relax
  IEEE, 2021.

\bibitem{li2015joint}
C.~Li, W.~Luo, S.~S. Sapatnekar, and J.~Hu, ``Joint precision optimization and
  high level synthesis for approximate computing,'' in \emph{Proceedings of the
  52nd Annual Design Automation Conference}, 2015.

\bibitem{bengio2013estimating}
Y.~Bengio, N.~L{\'e}onard, and A.~Courville, ``Estimating or propagating
  gradients through stochastic neurons for conditional computation,''
  \emph{arXiv preprint arXiv:1308.3432}, 2013.

\bibitem{jang2016categorical}
E.~Jang, S.~Gu, and B.~Poole, ``Categorical reparameterization with
  gumbel-softmax,'' \emph{International Conference on Learning
  Representations}, 2017.

\bibitem{maddison2016concrete}
C.~J. Maddison, A.~Mnih, and Y.~W. Teh, ``The concrete distribution: A
  continuous relaxation of discrete random variables,'' \emph{International
  Conference on Learning Representations}, 2017.

\bibitem{kwon2020pomo}
Y.-D. Kwon, J.~Choo, B.~Kim, I.~Yoon, Y.~Gwon, and S.~Min, ``Pomo: Policy
  optimization with multiple optima for reinforcement learning,''
  \emph{Advances in Neural Information Processing Systems}, vol.~33, 2020.

\bibitem{wang2021bi}
R.~Wang, Z.~Hua, G.~Liu, J.~Zhang, J.~Yan, F.~Qi, S.~Yang, J.~Zhou, and
  X.~Yang, ``A bi-level framework for learning to solve combinatorial
  optimization on graphs,'' \emph{Advances in Neural Information Processing
  Systems}, vol.~34, 2021.

\bibitem{nandwani2021neural}
Y.~Nandwani, D.~Jindal, P.~Singla \emph{et~al.}, ``Neural learning of
  one-of-many solutions for combinatorial problems in structured output
  spaces,'' in \emph{International Conference on Learning Representations},
  2021.

\bibitem{duan2022augment}
H.~Duan, P.~Vaezipoor, M.~B. Paulus, Y.~Ruan, and C.~Maddison, ``Augment with
  care: Contrastive learning for combinatorial problems,'' in
  \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2022, pp. 5627--5642.

\bibitem{kumar2020model}
A.~Kumar and S.~Levine, ``Model inversion networks for model-based
  optimization,'' \emph{Advances in Neural Information Processing Systems},
  vol.~33, 2020.

\bibitem{brookes2019conditioning}
D.~Brookes, H.~Park, and J.~Listgarten, ``Conditioning by adaptive sampling for
  robust design,'' in \emph{International Conference on Machine
  Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2019.

\bibitem{trabucco2021conservative}
B.~Trabucco, A.~Kumar, X.~Geng, and S.~Levine, ``Conservative objective models
  for effective offline model-based optimization,'' in \emph{International
  Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR,
  2021.

\bibitem{kumar2021data}
A.~Kumar, A.~Yazdanbakhsh, M.~Hashemi, K.~Swersky, and S.~Levine, ``Data-driven
  offline optimization for architecting hardware accelerators,'' 2022.

\bibitem{anderson2020strong}
R.~Anderson, J.~Huchette, W.~Ma, C.~Tjandraatmadja, and J.~P. Vielma, ``Strong
  mixed-integer programming formulations for trained neural networks,''
  \emph{Mathematical Programming}, vol. 183, no.~1, pp. 3--39, 2020.

\bibitem{papalexopoulos2022constrained}
T.~P. Papalexopoulos, C.~Tjandraatmadja, R.~Anderson, J.~P. Vielma, and
  D.~Belanger, ``Constrained discrete black-box optimization using
  mixed-integer programming,'' in \emph{International Conference on Machine
  Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2022, pp.
  17\,295--17\,322.

\bibitem{konda1999actor}
V.~Konda and J.~Tsitsiklis, ``Actor-critic algorithms,'' \emph{Advances in
  Neural Information Processing Systems}, vol.~12, 1999.

\bibitem{mnih2016asynchronous}
V.~Mnih, A.~P. Badia, M.~Mirza, A.~Graves, T.~Lillicrap, T.~Harley, D.~Silver,
  and K.~Kavukcuoglu, ``Asynchronous methods for deep reinforcement learning,''
  in \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2016.

\bibitem{paulus2020gradient}
M.~Paulus, D.~Choi, D.~Tarlow, A.~Krause, and C.~J. Maddison, ``Gradient
  estimation with stochastic softmax tricks,'' \emph{Advances in Neural
  Information Processing Systems}, vol.~33, 2020.

\bibitem{struminsky2021leveraging}
K.~Struminsky, A.~Gadetsky, D.~Rakitin, D.~Karpushkin, and D.~P. Vetrov,
  ``Leveraging recursive gumbel-max trick for approximate inference in
  combinatorial spaces,'' \emph{Advances in Neural Information Processing
  Systems}, vol.~34, 2021.

\bibitem{leskovec2014snap}
J.~Leskovec and A.~Krevl, ``Snap datasets: Stanford large network dataset
  collection,'' 2014.

\bibitem{FeyPyG}
M.~Fey and J.~E. Lenssen, ``Fast graph representation learning with {PyTorch
  Geometric},'' in \emph{ICLR Workshop on Representation Learning on Graphs and
  Manifolds}, 2019.

\bibitem{wang2019dgl}
M.~Wang, D.~Zheng, Z.~Ye, Q.~Gan, M.~Li, X.~Song, J.~Zhou, C.~Ma, L.~Yu,
  Y.~Gai, T.~Xiao, T.~He, G.~Karypis, J.~Li, and Z.~Zhang, ``Deep graph
  library: A graph-centric, highly-performant package for graph neural
  networks,'' \emph{arXiv preprint arXiv:1909.01315}, 2019.

\bibitem{mirjalili2019genetic}
S.~Mirjalili, ``Genetic algorithm,'' in \emph{Evolutionary algorithms and
  neural networks}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2019.

\bibitem{whitley1994genetic}
D.~Whitley, ``A genetic algorithm tutorial,'' \emph{Statistics and computing},
  vol.~4, no.~2, 1994.

\bibitem{poganvcic2019differentiation}
M.~V. Pogan{\v{c}}i{\'c}, A.~Paulus, V.~Musil, G.~Martius, and M.~Rolinek,
  ``Differentiation of blackbox combinatorial solvers,'' in \emph{International
  Conference on Learning Representations}, 2019.

\bibitem{deng2012mnist}
L.~Deng, ``The mnist database of handwritten digit images for machine learning
  research,'' \emph{IEEE Signal Processing Magazine}, vol.~29, no.~6, 2012.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in \emph{Proceedings of the IEEE Conference on Computer Vision
  and Pattern Recognition}, 2016.

\bibitem{hamilton2017inductive}
W.~Hamilton, Z.~Ying, and J.~Leskovec, ``Inductive representation learning on
  large graphs,'' \emph{Advances in Neural Information Processing Systems},
  vol.~30, 2017.

\bibitem{VitisHLS}
AMD/Xilinx, ``Vitis ai development environment,''
  \url{https://www.xilinx.com/products/design-tools/vitis/vitis-ai.html}.

\bibitem{Vivado}
------, ``Vivado development tool,''
  \url{https://www.xilinx.com/products/design-tools/vivado.html}.

\bibitem{huber1992robust}
P.~J. Huber, ``Robust estimation of a location parameter,'' in
  \emph{Breakthroughs in statistics}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 1992, pp. 492--518.

\bibitem{paszke2019pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen,
  Z.~Lin, N.~Gimelshein, L.~Antiga \emph{et~al.}, ``Pytorch: An imperative
  style, high-performance deep learning library,'' \emph{Advances in Neural
  Information Processing Systems}, vol.~32, 2019.

\bibitem{fey2019fast}
M.~Fey and J.~E. Lenssen, ``Fast graph representation learning with pytorch
  geometric,'' \emph{arXiv preprint arXiv:1903.02428}, 2019.

\bibitem{kingma2015adam}
D.~P. Kingma and J.~Ba, ``Adam: A method for stochastic optimization,'' in
  \emph{International Conference on Learning Representations}, 2015.

\bibitem{gilmer2017neural}
J.~Gilmer, S.~S. Schoenholz, P.~F. Riley, O.~Vinyals, and G.~E. Dahl, ``Neural
  message passing for quantum chemistry,'' in \emph{International Conference on
  Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2017, pp.
  1263--1272.

\bibitem{corso2020principal}
G.~Corso, L.~Cavalleri, D.~Beaini, P.~Li{\`o}, and P.~Veli{\v{c}}kovi{\'c},
  ``Principal neighbourhood aggregation for graph nets,'' \emph{Advances in
  Neural Information Processing Systems}, vol.~33, 2020.

\end{thebibliography}
