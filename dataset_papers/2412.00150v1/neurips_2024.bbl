\begin{thebibliography}{10}

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 770--778, 2016.

\bibitem{girshick2015fast}
Ross Girshick.
\newblock Fast r-cnn.
\newblock In {\em Proceedings of the IEEE international conference on computer vision}, pages 1440--1448, 2015.

\bibitem{he2017mask}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Mask r-cnn.
\newblock In {\em Proceedings of the IEEE international conference on computer vision}, pages 2961--2969, 2017.

\bibitem{yuan2021tokens}
Li~Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Zi-Hang Jiang, Francis~EH Tay, Jiashi Feng, and Shuicheng Yan.
\newblock Tokens-to-token vit: Training vision transformers from scratch on imagenet.
\newblock In {\em Proceedings of the IEEE/CVF international conference on computer vision}, pages 558--567, 2021.

\bibitem{song2022learning}
Hwanjun Song, Minseok Kim, Dongmin Park, Yooju Shin, and Jae-Gil Lee.
\newblock Learning from noisy labels with deep neural networks: A survey.
\newblock {\em IEEE transactions on neural networks and learning systems}, 2022.

\bibitem{krause2016unreasonable}
Jonathan Krause, Benjamin Sapp, Andrew Howard, Howard Zhou, Alexander Toshev, Tom Duerig, James Philbin, and Li~Fei-Fei.
\newblock The unreasonable effectiveness of noisy data for fine-grained recognition.
\newblock In {\em Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part III 14}, pages 301--320. Springer, 2016.

\bibitem{arpit2017closer}
Devansh Arpit, Stanis{\l}aw Jastrz{\k{e}}bski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder~S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et~al.
\newblock A closer look at memorization in deep networks.
\newblock In {\em International conference on machine learning}, pages 233--242. PMLR, 2017.

\bibitem{xue2022robust}
Cheng Xue, Lequan Yu, Pengfei Chen, Qi~Dou, and Pheng-Ann Heng.
\newblock Robust medical image classification from noisy labeled data with global and local representation guided co-training.
\newblock {\em IEEE transactions on medical imaging}, 41(6):1371--1382, 2022.

\bibitem{ju2022improving}
Lie Ju, Xin Wang, Lin Wang, Dwarikanath Mahapatra, Xin Zhao, Quan Zhou, Tongliang Liu, and Zongyuan Ge.
\newblock Improving medical images classification with label noise using dual-uncertainty estimation.
\newblock {\em IEEE transactions on medical imaging}, 41(6):1533--1546, 2022.

\bibitem{jiang2018mentornet}
Lu~Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li~Fei-Fei.
\newblock Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels.
\newblock In {\em International conference on machine learning}, pages 2304--2313. PMLR, 2018.

\bibitem{han2018co}
Bo~Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi Sugiyama.
\newblock Co-teaching: Robust training of deep neural networks with extremely noisy labels.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{yu2019does}
Xingrui Yu, Bo~Han, Jiangchao Yao, Gang Niu, Ivor Tsang, and Masashi Sugiyama.
\newblock How does disagreement help generalization against label corruption?
\newblock In {\em International conference on machine learning}, pages 7164--7173. PMLR, 2019.

\bibitem{wei2020combating}
Hongxin Wei, Lei Feng, Xiangyu Chen, and Bo~An.
\newblock Combating noisy labels by agreement: A joint training method with co-regularization.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 13726--13735, 2020.

\bibitem{xia2023combating}
Xiaobo Xia, Bo~Han, Yibing Zhan, Jun Yu, Mingming Gong, Chen Gong, and Tongliang Liu.
\newblock Combating noisy labels with sample selection by mining high-discrepancy examples.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 1833--1843, 2023.

\bibitem{dosovitskiy2021an}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In {\em International conference on machine learning}, pages 8748--8763. PMLR, 2021.

\bibitem{he2022masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 16000--16009, 2022.

\bibitem{kirillov2023segment}
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander~C Berg, Wan-Yen Lo, et~al.
\newblock Segment anything.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 4015--4026, 2023.

\bibitem{oquab2023dinov2}
Maxime Oquab, Timoth{\'e}e Darcet, Th{\'e}o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et~al.
\newblock Dinov2: Learning robust visual features without supervision.
\newblock {\em arXiv preprint arXiv:2304.07193}, 2023.

\bibitem{chen2023anydoor}
Xi~Chen, Lianghua Huang, Yu~Liu, Yujun Shen, Deli Zhao, and Hengshuang Zhao.
\newblock Anydoor: Zero-shot object-level image customization.
\newblock {\em arXiv preprint arXiv:2307.09481}, 2023.

\bibitem{wei2023stronger}
Zhixiang Wei, Lin Chen, Yi~Jin, Xiaoxiao Ma, Tianle Liu, Pengyang Ling, Ben Wang, Huaian Chen, and Jinjin Zheng.
\newblock Stronger, fewer, \& superior: Harnessing vision foundation models for domain generalized semantic segmentation.
\newblock {\em arXiv preprint arXiv:2312.04265}, 2023.

\bibitem{qiao2023robustness}
Yu~Qiao, Chaoning Zhang, Taegoo Kang, Donghun Kim, Shehbaz Tariq, Chenshuang Zhang, and Choong~Seon Hong.
\newblock Robustness of sam: Segment anything under corruptions and beyond.
\newblock {\em arXiv preprint arXiv:2306.07713}, 2023.

\bibitem{sinhamahapatra2024finding}
Poulami Sinhamahapatra, Franziska Schwaiger, Shirsha Bose, Huiyu Wang, Karsten Roscher, and Stephan Guennemann.
\newblock Finding dino: A plug-and-play framework for unsupervised detection of out-of-distribution objects using prototypes.
\newblock {\em arXiv preprint arXiv:2404.07664}, 2024.

\bibitem{hu2022lora}
Edward~J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu~Wang, and Weizhu Chen.
\newblock Lo{RA}: Low-rank adaptation of large language models.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{jia2022visual}
Menglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie, Serge Belongie, Bharath Hariharan, and Ser-Nam Lim.
\newblock Visual prompt tuning.
\newblock In {\em European Conference on Computer Vision}, pages 709--727. Springer, 2022.

\bibitem{chen2022adaptformer}
Shoufa Chen, Chongjian Ge, Zhan Tong, Jiangliu Wang, Yibing Song, Jue Wang, and Ping Luo.
\newblock Adaptformer: Adapting vision transformers for scalable visual recognition.
\newblock {\em Advances in Neural Information Processing Systems}, 35:16664--16678, 2022.

\bibitem{liu2021swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted windows.
\newblock In {\em Proceedings of the IEEE/CVF international conference on computer vision}, pages 10012--10022, 2021.

\bibitem{touvron2021training}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herv{\'e} J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through attention.
\newblock In {\em International conference on machine learning}, pages 10347--10357. PMLR, 2021.

\bibitem{caron2021emerging}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv{\'e} J{\'e}gou, Julien Mairal, Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In {\em Proceedings of the IEEE/CVF international conference on computer vision}, pages 9650--9660, 2021.

\bibitem{duttparameter}
Raman Dutt, Linus Ericsson, Pedro Sanchez, Sotirios~A Tsaftaris, and Timothy Hospedales.
\newblock Parameter-efficient fine-tuning for medical image analysis: The missed opportunity.
\newblock In {\em Medical Imaging with Deep Learning}, 2023.

\bibitem{ghosh2017robust}
Aritra Ghosh, Himanshu Kumar, and P~Shanti Sastry.
\newblock Robust loss functions under label noise for deep neural networks.
\newblock In {\em Proceedings of the AAAI conference on artificial intelligence}, volume~31, 2017.

\bibitem{liu2020early}
Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda.
\newblock Early-learning regularization prevents memorization of noisy labels.
\newblock {\em Advances in neural information processing systems}, 33:20331--20342, 2020.

\bibitem{wang2019symmetric}
Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James Bailey.
\newblock Symmetric cross entropy for robust learning with noisy labels.
\newblock In {\em Proceedings of the IEEE/CVF international conference on computer vision}, pages 322--330, 2019.

\bibitem{zhang2018generalized}
Zhilu Zhang and Mert Sabuncu.
\newblock Generalized cross entropy loss for training deep neural networks with noisy labels.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{kim2021fine}
Taehyeon Kim, Jongwoo Ko, JinHwan Choi, Se-Young Yun, et~al.
\newblock Fine samples for learning with noisy labels.
\newblock {\em Advances in Neural Information Processing Systems}, 34:24137--24149, 2021.

\bibitem{li2020dividemix}
Junnan Li, Richard Socher, and Steven~CH Hoi.
\newblock Dividemix: Learning with noisy labels as semi-supervised learning.
\newblock {\em arXiv preprint arXiv:2002.07394}, 2020.

\bibitem{li2021learning}
Junnan Li, Caiming Xiong, and Steven~CH Hoi.
\newblock Learning from noisy data with robust representation learning.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 9485--9494, 2021.

\bibitem{malach2017decoupling}
Eran Malach and Shai Shalev-Shwartz.
\newblock Decoupling" when to update" from" how to update".
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{hendrycks2019using}
Dan Hendrycks, Kimin Lee, and Mantas Mazeika.
\newblock Using pre-training can improve model robustness and uncertainty.
\newblock In {\em International conference on machine learning}, pages 2712--2721. PMLR, 2019.

\bibitem{wu2023prompt}
Cheng-En Wu, Yu~Tian, Haichao Yu, Heng Wang, Pedro Morgado, Yu~Hen Hu, and Linjie Yang.
\newblock Why is prompt tuning for vision-language models robust to noisy labels?
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 15488--15497, 2023.

\bibitem{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock {\em arXiv preprint arXiv:1607.06450}, 2016.

\bibitem{tschandl2018ham10000}
Philipp Tschandl, Cliff Rosendahl, and Harald Kittler.
\newblock The ham10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions.
\newblock {\em Scientific data}, 5(1):1--9, 2018.

\bibitem{dekhil2019deep}
Omar Dekhil, Ahmed Naglah, Mohamed Shaban, Mohammed Ghazal, Fatma Taher, and Ayman Elbaz.
\newblock Deep learning based method for computer aided diagnosis of diabetic retinopathy.
\newblock In {\em 2019 IEEE International Conference on Imaging Systems and Techniques (IST)}, pages 1--4. IEEE, 2019.

\bibitem{acevedo2020dataset}
Andrea Acevedo, Anna Merino~Gonz{\'a}lez, Edwin~Santiago Alf{\'e}rez~Baquero, {\'A}ngel Molina~Borr{\'a}s, Laura Bold{\'u}~Nebot, and Jos{\'e} Rodellar~Bened{\'e}.
\newblock A dataset of microscopic peripheral blood cell images for development of automatic recognition systems.
\newblock {\em Data in brief}, 30(article 105474), 2020.

\bibitem{xu2019efficient}
Xuanang Xu, Fugen Zhou, Bo~Liu, Dongshan Fu, and Xiangzhi Bai.
\newblock Efficient multiple organ localization in ct image using 3d region proposal network.
\newblock {\em IEEE transactions on medical imaging}, 38(8):1885--1898, 2019.

\bibitem{eyepac}
Kaggle diabetic retinopathy detection competition.
\newblock \url{https://www.kaggle.com/c/diabetic-retinopathy-detection}.

\bibitem{isic}
Isic 2018 challenge.
\newblock \url{https://challenge.isic-archive.com/landing/2018/}.

\bibitem{wang2019retinal}
Xin Wang, Lie Ju, Xin Zhao, and Zongyuan Ge.
\newblock Retinal abnormalities recognition using regional multitask learning.
\newblock In {\em Medical Image Computing and Computer Assisted Intervention--MICCAI 2019: 22nd International Conference, Shenzhen, China, October 13--17, 2019, Proceedings, Part I 22}, pages 30--38. Springer, 2019.

\bibitem{zhou2020benchmark}
Yi~Zhou, Boyang Wang, Lei Huang, Shanshan Cui, and Ling Shao.
\newblock A benchmark for studying diabetic retinopathy: segmentation, grading, and transferability.
\newblock {\em IEEE Transactions on Medical Imaging}, 40(3):818--828, 2020.

\bibitem{xing2023gradient}
Xiaohan Xing, Zhen Chen, Zhifan Gao, and Yixuan Yuan.
\newblock Gradient and feature conformity-steered medical image classification with noisy labels.
\newblock In {\em International Conference on Medical Image Computing and Computer-Assisted Intervention}, pages 75--84. Springer, 2023.

\bibitem{chen2023combating}
Bingzhi Chen, Zhanhao Ye, Yishu Liu, Zheng Zhang, Jiahui Pan, Biqing Zeng, and Guangming Lu.
\newblock Combating medical label noise via robust semi-supervised contrastive learning.
\newblock In {\em International Conference on Medical Image Computing and Computer-Assisted Intervention}, pages 562--572. Springer, 2023.

\bibitem{Ansel_PyTorch_2_Faster_2024}
Jason Ansel, Edward Yang, Horace He, Natalia Gimelshein, Animesh Jain, Michael Voznesensky, Bin Bao, Peter Bell, David Berard, Evgeni Burovski, Geeta Chauhan, Anjali Chourdia, Will Constable, Alban Desmaison, Zachary DeVito, Elias Ellison, Will Feng, Jiong Gong, Michael Gschwind, Brian Hirsh, Sherlock Huang, Kshiteej Kalambarkar, Laurent Kirsch, Michael Lazos, Mario Lezcano, Yanbo Liang, Jason Liang, Yinghai Lu, CK~Luk, Bert Maher, Yunjie Pan, Christian Puhrsch, Matthias Reso, Mark Saroufim, Marcos~Yukio Siraichi, Helen Suk, Michael Suo, Phil Tillet, Eikan Wang, Xiaodong Wang, William Wen, Shunting Zhang, Xu~Zhao, Keren Zhou, Richard Zou, Ajit Mathews, Gregory Chanan, Peng Wu, and Soumith Chintala.
\newblock {PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation}.
\newblock In {\em 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24)}. ACM, April 2024.

\bibitem{medmnistv1}
Jiancheng Yang, Rui Shi, and Bingbing Ni.
\newblock Medmnist classification decathlon: A lightweight automl benchmark for medical image analysis.
\newblock In {\em IEEE 18th International Symposium on Biomedical Imaging (ISBI)}, pages 191--195, 2021.

\bibitem{medmnistv2}
Jiancheng Yang, Rui Shi, Donglai Wei, Zequan Liu, Lin Zhao, Bilian Ke, Hanspeter Pfister, and Bingbing Ni.
\newblock Medmnist v2-a large-scale lightweight benchmark for 2d and 3d biomedical image classification.
\newblock {\em Scientific Data}, 10(1):41, 2023.

\bibitem{Kingma2014AdamAM}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em CoRR}, abs/1412.6980, 2014.

\bibitem{liu2015classification}
Tongliang Liu and Dacheng Tao.
\newblock Classification with noisy labels by importance reweighting.
\newblock {\em IEEE Transactions on pattern analysis and machine intelligence}, 38(3):447--461, 2015.

\bibitem{medclip}
Sheng Zhang, Yanbo Xu, Naoto Usuyama, Jaspreet Bagga, Robert Tinn, Sam Preston, Rajesh Rao, Mu~Wei, Naveen Valluri, Cliff Wong, Matthew Lungren, Tristan Naumann, and Hoifung Poon.
\newblock Large-scale domain-specific pretraining for biomedical vision-language processing, 2023.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern recognition}, pages 248--255. Ieee, 2009.

\bibitem{song19b}
Hwanjun Song, Minseok Kim, and Jae-Gil Lee.
\newblock {SELFIE}: Refurbishing unclean samples for robust deep learning.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, {\em Proceedings of the 36th International Conference on Machine Learning}, volume~97 of {\em Proceedings of Machine Learning Research}, pages 5907--5915. PMLR, 09--15 Jun 2019.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\end{thebibliography}
