@inproceedings{kreutzer2020learning,
  title={Learning from Human Feedback: Challenges for Real-World Reinforcement Learning in NLP},
  author={Kreutzer, Julia and Riezler, Stefan and Lawrence, Carolin},
  booktitle=neurips,
  year={2020}
}

@inproceedings{dulac2019challenges,
  title={Challenges of real-world reinforcement learning},
  author={Dulac-Arnold, Gabriel and Mankowitz, Daniel and Hester, Todd},
  booktitle=icml,
  year={2019}
}

@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={ICML},
  volume={99},
  pages={278--287},
  year={1999}
}

@article{kurenkov2018reinforcementflaw,
    author = {Kurenkov, Andrey},
    title = {Reinforcement learning's foundational flaw},
    journal = {The Gradient},
    year = {2018},
    howpublished = {\url{https://thegradient.pub/why-rl-is-flawed/ }},
}

@inproceedings{choshen2020weaknesses,
  title={On the Weaknesses of Reinforcement Learning for Neural Machine Translation},
  author={Choshen, Leshem and Fox, Lior and Aizenbud, Zohar and Abend, Omri},
  booktitle=iclr,
  year={2020}
}

@article{osa2018algorithmic,
url = {http://dx.doi.org/10.1561/2300000053},
year = {2018},
volume = {7},
journal = {Foundations and Trends® in Robotics},
title = {An Algorithmic Perspective on Imitation Learning},
doi = {10.1561/2300000053},
issn = {1935-8253},
number = {1-2},
pages = {1-179},
author = {Takayuki Osa and Joni Pajarinen and Gerhard Neumann and J. Andrew Bagnell and Pieter Abbeel and Jan Peters}
}

@inproceedings{rajaraman2020toward,
  title={Toward the Fundamental Limits of Imitation Learning},
  author={Rajaraman, Nived and Yang, Lin F and Jiao, Jiantao and Ramachandran, Kannan},
  booktitle=neurips,
  year={2020}
}

@phdthesis{ross2013thesis,
  author       = {Stephane Ross}, 
  title        = {Interactive Learning for Sequential Decisions and Predictions},
  school       = {Carnegie Mellon University},
  year         = 2013,
  month        = 6,
  url = "https://kilthub.cmu.edu/articles/thesis/Interactive_Learning_for_Sequential_Decisions_and_Predictions/6720269",
  doi = "10.1184/R1/6720269.v1"
}

@phdthesis{minsky1954thesis,
  author       = {Marvin L. Minsky}, 
  title        = {Theory of Neural-Analog Reinforcement Systems and
Its Application to the Brain-Model Problem},
  school       = {Princeton University},
  year         = 1954,
}

@article{farley1954simulation,
  title={Simulation of self-organizing systems by digital computer},
  author={Farley, BWAC and Clark, W},
  journal={Transactions of the IRE Professional Group on Information Theory},
  volume={4},
  number={4},
  pages={76--84},
  year={1954},
  publisher={IEEE}
}

@article{minsky1961steps,
  title={Steps toward artificial intelligence},
  author={Minsky, Marvin},
  journal={Proceedings of the IRE},
  volume={49},
  number={1},
  pages={8--30},
  year={1961},
  publisher={IEEE}
}

@inproceedings{bain1995framework,
  title={A Framework for Behavioural Cloning.},
  author={Bain, Michael and Sammut, Claude},
  booktitle={Machine Intelligence 15},
  pages={103--129},
  year={1995}
}

@article{kalman1964irl,
    author = {Kalman, R. E.},
    title = "{When Is a Linear Control System Optimal?}",
    journal = {Journal of Basic Engineering},
    volume = {86},
    number = {1},
    pages = {51-60},
    year = {1964},
    month = {03},
    abstract = "{The purpose of this paper is to formulate, study, and (in certain cases) resolve the Inverse Problem of Optimal Control Theory, which is the following: Given a control law, find all performance indices for which this control law is optimal. Under the assumptions of (a) linear constant plant, (b) linear constant control law, (c) measurable state variables, (d) quadratic loss functions with constant coefficients, (e) single control variable, we give a complete analysis of this problem and obtain various explicit conditions for the optimality of a given control law. An interesting feature of the analysis is the central role of frequency-domain concepts, which have been ignored in optimal control theory until very recently. The discussion is presented in rigorous mathematical form. The central conclusion is the following (Theorem 6): A stable control law is optimal if and only if the absolute value of the corresponding return difference is at least equal to one at all frequencies. This provides a beautifully simple connecting link between modern control theory and the classical point of view which regards feedback as a means of reducing component variations.}",
    issn = {0021-9223},
    doi = {10.1115/1.3653115},
    url = {https://doi.org/10.1115/1.3653115},
    eprint = {https://asmedigitalcollection.asme.org/fluidsengineering/article-pdf/86/1/51/5763755/51\_1.pdf},
}

@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={1},
  year={2004}
}

% Go
@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

% DOTA OpenAI Five
@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

% GAN

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  volume={27},
  pages={2672--2680},
  year={2014}
}

@article{creswell2018generative,
  title={Generative adversarial networks: An overview},
  author={Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A},
  journal={IEEE Signal Processing Magazine},
  volume={35},
  number={1},
  pages={53--65},
  year={2018},
  publisher={IEEE}
}

% Chatbots

@inproceedings{gao2018neural,
  title={Neural approaches to conversational AI},
  author={Gao, Jianfeng and Galley, Michel and Li, Lihong},
  booktitle={The 41st International ACM SIGIR Conference on Research \& Development in Information Retrieval},
  pages={1371--1374},
  year={2018}
}

@article{adiwardana2020towards,
  title={Towards a human-like open-domain chatbot},
  author={Adiwardana, Daniel and Luong, Minh-Thang and So, David R and Hall, Jamie and Fiedel, Noah and Thoppilan, Romal and Yang, Zi and Kulshreshtha, Apoorv and Nemade, Gaurav and Lu, Yifeng and others},
  journal={arXiv preprint arXiv:2001.09977},
  year={2020}
}

@inproceedings{ponnusamy2020feedback,
  title={Feedback-based self-learning in large-scale conversational ai agents},
  author={Ponnusamy, Pragaash and Ghias, Alireza Roshan and Guo, Chenlei and Sarikaya, Ruhi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={08},
  pages={13180--13187},
  year={2020}
}

% Active learning

@techreport{settles2009active,
  title={Active learning literature survey},
  author={Settles, Burr},
  year={2009},
  institution={University of Wisconsin-Madison Department of Computer Sciences}
}

@article{angluin1988queries,
  title={Queries and concept learning},
  author={Angluin, Dana},
  journal={Machine learning},
  volume={2},
  number={4},
  pages={319--342},
  year={1988},
  publisher={Springer}
}

@article{cohn1994improving,
  title={Improving generalization with active learning},
  author={Cohn, David and Atlas, Les and Ladner, Richard},
  journal={Machine learning},
  volume={15},
  number={2},
  pages={201--221},
  year={1994},
  publisher={Springer}
}

@inproceedings{lewis1994sequential,
  title={A sequential algorithm for training text classifiers},
  author={Lewis, David D and Gale, William A},
  booktitle={SIGIR’94},
  pages={3--12},
  year={1994},
  organization={Springer}
}

@inproceedings{roy2001toward,
  title={Toward optimal active learning through sampling estimation of error reduction. Int. Conf. on Machine Learning},
  author={Roy, N and McCallum, A},
  year={2001},
  booktitle=icml
}

@inproceedings{culotta2005reducing,
  title={Reducing labeling effort for structured prediction tasks},
  author={Culotta, Aron and McCallum, Andrew},
  booktitle={AAAI},
  volume={5},
  pages={746--751},
  year={2005}
}

@article{gal2017deep,
  title={Deep bayesian active learning with image data},
  author={Gal, Yarin and Islam, Riashat and Ghahramani, Zoubin},
  journal=icml,
  year={2017}
}

% Active imitation learning

@article{judah2014active,
  title={Active imitation learning: Formal and practical reductions to iid learning},
  author={Judah, Kshitij and Fern, Alan P and Dietterich, Thomas G and Tadepalli, Prasad},
  journal={Journal of Machine Learning Research},
  volume={15},
  number={120},
  pages={4105--4143},
  year={2014}
}

@inproceedings{brantley2020active,
  title={Active Imitation Learning with Noisy Guidance},
  author={Brantley, Kiant{\'e} and Sharaf, Amr and Daum{\'e} III, Hal},
  booktitle=acl,
  year={2020}
}

@inproceedings{silver2012active,
  title={Active learning from demonstration for robust autonomous navigation},
  author={Silver, David and Bagnell, J Andrew and Stentz, Anthony},
  booktitle={2012 IEEE International Conference on Robotics and Automation},
  pages={200--207},
  year={2012},
  organization={IEEE}
}

@article{chernova2009interactive,
  title={Interactive policy learning through confidence-based autonomy},
  author={Chernova, Sonia and Veloso, Manuela},
  journal={Journal of Artificial Intelligence Research},
  volume={34},
  pages={1--25},
  year={2009}
}

% Active reinforcement learning

@inproceedings{krueger2020active,
  title={Active reinforcement learning: Observing rewards at a cost},
  author={Krueger, David and Leike, Jan and Evans, Owain and Salvatier, John},
  booktitle={FILM workshop (NeurIPS)},
  year={2020}
}

@inproceedings{daniel2014active,
  title={Active Reward Learning.},
  author={Daniel, Christian and Viering, Malte and Metz, Jan and Kroemer, Oliver and Peters, Jan},
  booktitle={Robotics: Science and systems},
  year={2014}
}

% Cobot

@article{colgate1996cobots,
  title={Cobots: Robots for collaboration with human operators},
  author={Colgate, J Edward and Edward, J and Peshkin, Michael A and Wannasuphoprasit, Witaya},
  year={1996},
  publisher={Citeseer}
}

@inproceedings{chandrasekaran2015human,
  title={Human-robot collaboration: A survey},
  author={Chandrasekaran, Balasubramaniyan and Conrad, James M},
  booktitle={SoutheastCon 2015},
  pages={1--8},
  year={2015},
  organization={IEEE}
}

@article{villani2018survey,
  title={Survey on human--robot collaboration in industrial settings: Safety, intuitive interfaces and applications},
  author={Villani, Valeria and Pini, Fabio and Leali, Francesco and Secchi, Cristian},
  journal={Mechatronics},
  volume={55},
  pages={248--266},
  year={2018},
  publisher={Elsevier}
}

@article{bauer2008human,
  title={Human--robot collaboration: a survey},
  author={Bauer, Andrea and Wollherr, Dirk and Buss, Martin},
  journal={International Journal of Humanoid Robotics},
  volume={5},
  number={01},
  pages={47--66},
  year={2008},
  publisher={World Scientific}
}


@article{fong2003survey,
  title={A survey of socially interactive robots},
  author={Fong, Terrence and Nourbakhsh, Illah and Dautenhahn, Kerstin},
  journal={Robotics and autonomous systems},
  volume={42},
  number={3-4},
  pages={143--166},
  year={2003},
  publisher={Elsevier}
}

% Ask for help

@book{fong2001collaborative,
  title={Collaborative control: A robot-centric model for vehicle teleoperation},
  author={Fong, Terrence and Thorpe, Charles and Baur, Charles},
  volume={1},
  year={2001},
  publisher={Carnegie Mellon University, The Robotics Institute Pittsburgh}
}

@article{fong2003robot,
  title={Robot, asker of questions},
  author={Fong, Terrence and Thorpe, Charles and Baur, Charles},
  journal={Robotics and Autonomous systems},
  volume={42},
  number={3-4},
  pages={235--243},
  year={2003},
  publisher={Elsevier}
}

% Robotics NL

@article{liu2019review,
  title={A review of methodologies for natural-language-facilitated human--robot cooperation},
  author={Liu, Rui and Zhang, Xiaoli},
  journal={International Journal of Advanced Robotic Systems},
  volume={16},
  number={3},
  pages={1729881419851402},
  year={2019},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{tangiuchi2019survey,
  title={Survey on frontiers of language and robotics},
  author={Tangiuchi, Tadahiro and Mochihashi, Daichi and Nagai, Takayuki and Uchida, Satoru and Inoue, Naoya and Kobayashi, Ichiro and Nakamura, Tomoaki and Hagiwara, Yoshinobu and Iwahashi, Naoto and Inamura, Tetsunari},
  journal={Advanced Robotics},
  volume={33},
  number={15-16},
  pages={700--730},
  year={2019},
  publisher={Taylor \& Francis}
}

@article{steels2001language,
  title={Language games for autonomous robots},
  author={Steels, Luc},
  journal={IEEE Intelligent systems},
  volume={16},
  number={5},
  pages={16--22},
  year={2001},
  publisher={IEEE}
}

@article{tellex2020robots,
  title={Robots that use language},
  author={Tellex, Stefanie and Gopalan, Nakul and Kress-Gazit, Hadas and Matuszek, Cynthia},
  journal={Annual Review of Control, Robotics, and Autonomous Systems},
  volume={3},
  pages={25--55},
  year={2020},
  publisher={Annual Reviews}
}

@article{weizenbaum1966eliza,
  title={ELIZA—a computer program for the study of natural language communication between man and machine},
  author={Weizenbaum, Joseph},
  journal={Communications of the ACM},
  volume={9},
  number={1},
  pages={36--45},
  year={1966},
  publisher={ACM New York, NY, USA}
}

% NL web nav

@article{mazumder2020flin,
  title={FLIN: A Flexible Natural Language Interface for Web Navigation},
  author={Mazumder, Sahisnu and Riva, Oriana},
  journal={arXiv preprint arXiv:2010.12844},
  year={2020}
}

@inproceedings{li-etal-2020-mapping,
    title = "Mapping Natural Language Instructions to Mobile {UI} Action Sequences",
    author = "Li, Yang  and
      He, Jiacong  and
      Zhou, Xin  and
      Zhang, Yuan  and
      Baldridge, Jason",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.729",
    doi = "10.18653/v1/2020.acl-main.729",
    pages = "8198--8210",
    abstract = "We present a new problem: grounding natural language instructions to mobile user interface actions, and create three new datasets for it. For full task evaluation, we create PixelHelp, a corpus that pairs English instructions with actions performed by people on a mobile UI emulator. To scale training, we decouple the language and action data by (a) annotating action phrase spans in How-To instructions and (b) synthesizing grounded descriptions of actions for mobile user interfaces. We use a Transformer to extract action phrase tuples from long-range natural language instructions. A grounding Transformer then contextually represents UI objects using both their content and screen position and connects them to object descriptions. Given a starting screen and instruction, our model achieves 70.59{\%} accuracy on predicting complete ground-truth action sequences in PixelHelp.",
}

@inproceedings{su2017building,
  title={Building natural language interfaces to web apis},
  author={Su, Yu and Awadallah, Ahmed Hassan and Khabsa, Madian and Pantel, Patrick and Gamon, Michael and Encarnacion, Mark},
  booktitle={Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
  pages={177--186},
  year={2017}
}

@inproceedings{su2018natural,
  title={Natural language interfaces with fine-grained user interaction: A case study on web apis},
  author={Su, Yu and Hassan Awadallah, Ahmed and Wang, Miaosen and White, Ryen W},
  booktitle={The 41st International ACM SIGIR Conference on Research \& Development in Information Retrieval},
  pages={855--864},
  year={2018}
}

@inproceedings{shi2017world,
  title={World of bits: An open-domain platform for web-based agents},
  author={Shi, Tianlin and Karpathy, Andrej and Fan, Linxi and Hernandez, Jonathan and Liang, Percy},
  booktitle={International Conference on Machine Learning},
  pages={3135--3144},
  year={2017}
}

@article{liu2018reinforcement,
  title={Reinforcement learning on web interfaces using workflow-guided exploration},
  author={Liu, Evan Zheran and Guu, Kelvin and Pasupat, Panupong and Shi, Tianlin and Liang, Percy},
  journal={arXiv preprint arXiv:1802.08802},
  year={2018}
}

% NL programming

@inproceedings{allen2007plow,
  title={Plow: A collaborative task learning agent},
  author={Allen, James and Chambers, Nathanael and Ferguson, George and Galescu, Lucian and Jung, Hyuckchul and Swift, Mary and Taysom, William},
  booktitle={AAAI},
  volume={7},
  pages={1514--1519},
  year={2007}
}

@incollection{lieberman2006feasibility,
  title={Feasibility studies for programming in natural language},
  author={Lieberman, Henry and Liu, Hugo},
  booktitle={End User Development},
  pages={459--473},
  year={2006},
  publisher={Springer}
}

@article{pane2001studying,
  title={Studying the language and structure in non-programmers' solutions to programming problems},
  author={Pane, John F and Myers, Brad A and others},
  journal={International Journal of Human-Computer Studies},
  volume={54},
  number={2},
  pages={237--264},
  year={2001},
  publisher={Elsevier}
}

@inproceedings{mihalcea2006nlp,
  title={NLP (natural language processing) for NLP (natural language programming)},
  author={Mihalcea, Rada and Liu, Hugo and Lieberman, Henry},
  booktitle={International Conference on Intelligent Text Processing and Computational Linguistics},
  pages={319--330},
  year={2006},
  organization={Springer}
}

@inproceedings{azaria2016instructable,
  title={Instructable Intelligent Personal Agent.},
  author={Azaria, Amos and Krishnamurthy, Jayant and Mitchell, Tom M},
  booktitle={AAAI},
  volume={4},
  year={2016}
}

@inproceedings{fast2018iris,
  title={Iris: A conversational agent for complex tasks},
  author={Fast, Ethan and Chen, Binbin and Mendelsohn, Julia and Bassen, Jonathan and Bernstein, Michael S},
  booktitle={Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  pages={1--12},
  year={2018}
}

@inproceedings{kate2005learning,
  title={Learning to transform natural to formal languages},
  author={Kate, Rohit J and Wong, Yuk Wah and Mooney, Raymond J},
  booktitle={AAAI},
  pages={1062--1068},
  year={2005}
}

@inproceedings{li2020interactive,
  title={Interactive Task and Concept Learning from Natural Language Instructions and GUI Demonstrations},
  author={Li, Toby Jia-Jun and Radensky, Marissa and Jia, Justin and Singarajah, Kirielle and Mitchell, Tom M and Myers, Brad A},
  booktitle={The AAAI-20 Workshop on Intelligent Process Automation (IPA-20)},
  year={2020}
}

% AI test

@article{turing1950computing,
  title={Computing machinery and intelligence-AM Turing},
  author={TURING, INTELLIGENCE BY AM},
  journal={Mind},
  volume={59},
  number={236},
  pages={433},
  year={1950}
}

@inproceedings{johnson2017clevr,
  title={Clevr: A diagnostic dataset for compositional language and elementary visual reasoning},
  author={Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2901--2910},
  year={2017}
}

@inproceedings{sakaguchi2020winogrande,
  title={Winogrande: An adversarial winograd schema challenge at scale},
  author={Sakaguchi, Keisuke and Le Bras, Ronan and Bhagavatula, Chandra and Choi, Yejin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={8732--8740},
  year={2020}
}

@inproceedings{levesque2012winograd,
  title={The winograd schema challenge},
  author={Levesque, Hector and Davis, Ernest and Morgenstern, Leora},
  booktitle={Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning},
  year={2012},
  organization={Citeseer}
}

@article{chollet2019measure,
  title={On the measure of intelligence},
  author={Chollet, Fran{\c{c}}ois},
  journal={arXiv preprint arXiv:1911.01547},
  year={2019}
}

%----------

@inproceedings{qi2020reverie,
  title={REVERIE: Remote Embodied Visual Referring Expression in Real Indoor Environments},
  author={Qi, Yuankai and Wu, Qi and Anderson, Peter and Wang, Xin and Wang, William Yang and Shen, Chunhua and Hengel, Anton van den},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9982--9991},
  year={2020}
}

@article{laird2017interactive,
  title={Interactive task learning},
  author={Laird, John E and Gluck, Kevin and Anderson, John and Forbus, Kenneth D and Jenkins, Odest Chadwicke and Lebiere, Christian and Salvucci, Dario and Scheutz, Matthias and Thomaz, Andrea and Trafton, Greg and others},
  journal={IEEE Intelligent Systems},
  volume={32},
  number={4},
  pages={6--21},
  year={2017},
  publisher={IEEE}
}

@inproceedings{chi2020just,
  title={Just ask: An interactive learning framework for vision and language navigation},
  author={Chi, Ta-Chung and Shen, Minmin and Eric, Mihail and Kim, Seokhwan and Hakkani-tur, Dilek},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={03},
  pages={2459--2466},
  year={2020}
}

% Grounded NLU

@article{brown1989situated,
  title={Situated cognition and the culture of learning},
  author={Brown, John Seely and Collins, Allan and Duguid, Paul},
  journal={Educational researcher},
  volume={18},
  number={1},
  pages={32--42},
  year={1989},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@book{miller1976language,
  title={Language and perception.},
  author={Miller, George A and Johnson-Laird, Philip N},
  year={1976},
  publisher={Belknap Press}
}

@techreport{winograd1971procedures,
  title={Procedures as a representation for data in a computer program for understanding natural language},
  author={Winograd, Terry},
  year={1971},
  institution={MASSACHUSETTS INST OF TECH CAMBRIDGE PROJECT MAC}
}

@article{harnad1990symbol,
  title={The symbol grounding problem},
  author={Harnad, Stevan},
  journal={Physica D: Nonlinear Phenomena},
  volume={42},
  number={1-3},
  pages={335--346},
  year={1990},
  publisher={Elsevier}
}

% vision language: words to images

@article{barnard2003matching,
  title={Matching words and pictures},
  author={Barnard, Kobus and Duygulu, Pinar and Forsyth, David and Freitas, Nando de and Blei, David M and Jordan, Michael I},
  journal={Journal of machine learning research},
  volume={3},
  number={Feb},
  pages={1107--1135},
  year={2003}
}

@inproceedings{berg2004names,
  title={Names and faces in the news},
  author={Berg, Tamara L and Berg, Alexander C and Edwards, Jaety and Maire, Michael and White, Ryan and Teh, Yee-Whye and Learned-Miller, Erik and Forsyth, David A},
  booktitle={Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.},
  volume={2},
  pages={II--II},
  year={2004},
  organization={IEEE}
}

@article{barnard2005word,
  title={Word sense disambiguation with pictures},
  author={Barnard, Kobus and Johnson, Matthew},
  journal={Artificial Intelligence},
  volume={167},
  number={1-2},
  pages={13--30},
  year={2005},
  publisher={Elsevier}
}

% Image captioning

@inproceedings{coyne2001wordseye,
  title={WordsEye: an automatic text-to-scene conversion system},
  author={Coyne, Bob and Sproat, Richard},
  booktitle={Proceedings of the 28th annual conference on Computer graphics and interactive techniques},
  pages={487--496},
  year={2001}
}

@inproceedings{zhu2007text,
  title={A text-to-picture synthesis system for augmenting communication},
  author={Zhu, Xiaojin and Goldberg, Andrew B and Eldawy, Mohamed and Dyer, Charles R and Strock, Bradley},
  booktitle={AAAI},
  volume={7},
  pages={1590--1595},
  year={2007}
}

% Interactive NL

@inproceedings{chen2008learning,
  title={Learning to sportscast: a test of grounded language acquisition},
  author={Chen, David L and Mooney, Raymond J},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={128--135},
  year={2008}
}

@inproceedings{matuszek2010following,
  title={Following directions using statistical machine translation},
  author={Matuszek, Cynthia and Fox, Dieter and Koscher, Karl},
  booktitle={2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  pages={251--258},
  year={2010},
  organization={IEEE}
}

@inproceedings{fan2020generating,
  title={Generating Interactive Worlds with Text.},
  author={Fan, Angela and Urbanek, Jack and Ringshia, Pratik and Dinan, Emily and Qian, Emma and Karamcheti, Siddharth and Prabhumoye, Shrimai and Kiela, Douwe and Rockt{\"a}schel, Tim and Szlam, Arthur and others},
  booktitle={AAAI},
  pages={1693--1700},
  year={2020}
}

% Grounded language learning tasks

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{gurari2020captioning,
  title={Captioning Images Taken by People Who Are Blind},
  author={Gurari, Danna and Zhao, Yinan and Zhang, Meng and Bhattacharya, Nilavra},
  journal={arXiv preprint arXiv:2002.08565},
  year={2020}
}

@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2425--2433},
  year={2015}
}

@inproceedings{das2017visual,
  title={Visual dialog},
  author={Das, Abhishek and Kottur, Satwik and Gupta, Khushi and Singh, Avi and Yadav, Deshraj and Moura, Jos{\'e} MF and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={326--335},
  year={2017}
}

@inproceedings{chang2014learning,
  title={Learning spatial knowledge for text to 3D scene generation},
  author={Chang, Angel and Savva, Manolis and Manning, Christopher D},
  booktitle={Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={2028--2038},
  year={2014}
}

@article{chang2015text,
  title={Text to 3d scene generation with rich lexical grounding},
  author={Chang, Angel and Monroe, Will and Savva, Manolis and Potts, Christopher and Manning, Christopher D},
  journal={arXiv preprint arXiv:1505.06289},
  year={2015}
}

@inproceedings{elliott-etal-2016-multi30k,
    title = "{M}ulti30{K}: Multilingual {E}nglish-{G}erman Image Descriptions",
    author = "Elliott, Desmond  and
      Frank, Stella  and
      Sima{'}an, Khalil  and
      Specia, Lucia",
    booktitle = "Proceedings of the 5th Workshop on Vision and Language",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W16-3210",
    doi = "10.18653/v1/W16-3210",
    pages = "70--74",
}

@inproceedings{wang2019vatex,
  title={Vatex: A large-scale, high-quality multilingual dataset for video-and-language research},
  author={Wang, Xin and Wu, Jiawei and Chen, Junkun and Li, Lei and Wang, Yuan-Fang and Wang, William Yang},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={4581--4591},
  year={2019}
}

% text-only fail

@inproceedings{hill2019environmental,
  title={Environmental drivers of systematicity and generalization in a situated agent},
  author={Hill, Felix and Lampinen, Andrew and Schneider, Rosalia and Clark, Stephen and Botvinick, Matthew and McClelland, James L and Santoro, Adam},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{mccoy-etal-2019-right,
    title = "Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference",
    author = "McCoy, Tom  and
      Pavlick, Ellie  and
      Linzen, Tal",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1334",
    doi = "10.18653/v1/P19-1334",
    pages = "3428--3448",
    abstract = "A machine learning system can score well on a given test set by relying on heuristics that are effective for frequent example types but break down in more challenging cases. We study this issue within natural language inference (NLI), the task of determining whether one sentence entails another. We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics: the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic. To determine whether models have adopted these heuristics, we introduce a controlled evaluation set called HANS (Heuristic Analysis for NLI Systems), which contains many examples where the heuristics fail. We find that models trained on MNLI, including BERT, a state-of-the-art model, perform very poorly on HANS, suggesting that they have indeed adopted these heuristics. We conclude that there is substantial room for improvement in NLI systems, and that the HANS dataset can motivate and measure progress in this area.",
}

@inproceedings{habernal-etal-2018-argument,
    title = "The Argument Reasoning Comprehension Task: Identification and Reconstruction of Implicit Warrants",
    author = "Habernal, Ivan  and
      Wachsmuth, Henning  and
      Gurevych, Iryna  and
      Stein, Benno",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-1175",
    doi = "10.18653/v1/N18-1175",
    pages = "1930--1940",
    abstract = "Reasoning is a crucial part of natural language argumentation. To comprehend an argument, one must analyze its warrant, which explains why its claim follows from its premises. As arguments are highly contextualized, warrants are usually presupposed and left implicit. Thus, the comprehension does not only require language understanding and logic skills, but also depends on common sense. In this paper we develop a methodology for reconstructing warrants systematically. We operationalize it in a scalable crowdsourcing process, resulting in a freely licensed dataset with warrants for 2k authentic arguments from news comments. On this basis, we present a new challenging task, the argument reasoning comprehension task. Given an argument with a claim and a premise, the goal is to choose the correct implicit warrant from two options. Both warrants are plausible and lexically close, but lead to contradicting claims. A solution to this task will define a substantial step towards automatic warrant reconstruction. However, experiments with several neural attention and language models reveal that current approaches do not suffice.",
}
@inproceedings{jia-liang-2017-adversarial,
    title = "Adversarial Examples for Evaluating Reading Comprehension Systems",
    author = "Jia, Robin  and
      Liang, Percy",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D17-1215",
    doi = "10.18653/v1/D17-1215",
    pages = "2021--2031",
    abstract = "Standard accuracy metrics indicate that reading comprehension systems are making rapid progress, but the extent to which these systems truly understand language remains unclear. To reward systems with real language understanding abilities, we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD). Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer or misleading humans. In this adversarial setting, the accuracy of sixteen published models drops from an average of 75{\%} F1 score to 36{\%}; when the adversary is allowed to add ungrammatical sequences of words, average accuracy on four models decreases further to 7{\%}. We hope our insights will motivate the development of new models that understand language more precisely.",
}

@inproceedings{wallace-etal-2019-universal,
    title = "Universal Adversarial Triggers for Attacking and Analyzing {NLP}",
    author = "Wallace, Eric  and
      Feng, Shi  and
      Kandpal, Nikhil  and
      Gardner, Matt  and
      Singh, Sameer",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1221",
    doi = "10.18653/v1/D19-1221",
    pages = "2153--2162",
    abstract = "Adversarial examples highlight model vulnerabilities and are useful for evaluation and interpretation. We define universal adversarial triggers: input-agnostic sequences of tokens that trigger a model to produce a specific prediction when concatenated to any input from a dataset. We propose a gradient-guided search over tokens which finds short trigger sequences (e.g., one word for classification and four words for language modeling) that successfully trigger the target prediction. For example, triggers cause SNLI entailment accuracy to drop from 89.94{\%} to 0.55{\%}, 72{\%} of {``}why{''} questions in SQuAD to be answered {``}to kill american people{''}, and the GPT-2 language model to spew racist output even when conditioned on non-racial contexts. Furthermore, although the triggers are optimized using white-box access to a specific model, they transfer to other models for all tasks we consider. Finally, since triggers are input-agnostic, they provide an analysis of global model behavior. For instance, they confirm that SNLI models exploit dataset biases and help to diagnose heuristics learned by reading comprehension models.",
}

% self-supervised

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@inproceedings{peters-etal-2018-deep,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-1202",
    doi = "10.18653/v1/N18-1202",
    pages = "2227--2237",
    abstract = "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
}

@inproceedings{howard-ruder-2018-universal,
    title = "Universal Language Model Fine-tuning for Text Classification",
    author = "Howard, Jeremy  and
      Ruder, Sebastian",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1031",
    doi = "10.18653/v1/P18-1031",
    pages = "328--339",
    abstract = "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24{\%} on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100 times more data. We open-source our pretrained models and code.",
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

% Multi-modal bert

@inproceedings{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13--23},
  year={2019}
}

@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@article{su2019vl,
  title={Vl-bert: Pre-training of generic visual-linguistic representations},
  author={Su, Weijie and Zhu, Xizhou and Cao, Yue and Li, Bin and Lu, Lewei and Wei, Furu and Dai, Jifeng},
  journal={arXiv preprint arXiv:1908.08530},
  year={2019}
}

@inproceedings{rahman2020integrating,
  title={Integrating multimodal information in large pretrained transformers},
  author={Rahman, Wasifur and Hasan, Md Kamrul and Lee, Sangwu and Zadeh, AmirAli Bagher and Mao, Chengfeng and Morency, Louis-Philippe and Hoque, Ehsan},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={2359--2369},
  year={2020}
}

@inproceedings{gan2020large,
  title={Large-Scale Adversarial Training for Vision-and-Language Representation Learning},
  author={Gan, Zhe and Chen, Yen-Chun and Li, Linjie and Zhu, Chen and Cheng, Yu and Liu, Jingjing},
  booktitle=neurips,
  year={2020}
}

@article{gordon2020watching,
  title={Watching the world go by: Representation learning from unlabeled videos},
  author={Gordon, Daniel and Ehsani, Kiana and Fox, Dieter and Farhadi, Ali},
  journal={arXiv preprint arXiv:2003.07990},
  year={2020}
}

@article{sun2019learning,
  title={Learning Video Representations using Contrastive Bidirectional Transformer},
  author={Sun, Chen and Baradel, Fabien and Murphy, Kevin and Schmid, Cordelia},
  journal={arXiv preprint arXiv:1906.05743},
  year={2019}
}

@article{tan2020vokenization,
  title={Vokenization: Improving Language Understanding with Contextualized, Visual-Grounded Supervision},
  author={Tan, Hao and Bansal, Mohit},
  journal={arXiv preprint arXiv:2010.06775},
  year={2020}
}

@article{qi2020imagebert,
  title={Imagebert: Cross-modal pre-training with large-scale weak-supervised image-text data},
  author={Qi, Di and Su, Lin and Song, Jia and Cui, Edward and Bharti, Taroon and Sacheti, Arun},
  journal={arXiv preprint arXiv:2001.07966},
  year={2020}
}

@inproceedings{zhou2020unified,
  title={Unified Vision-Language Pre-Training for Image Captioning and VQA.},
  author={Zhou, Luowei and Palangi, Hamid and Zhang, Lei and Hu, Houdong and Corso, Jason J and Gao, Jianfeng},
  booktitle={AAAI},
  pages={13041--13049},
  year={2020}
}

% General pre-training

@inproceedings{hao2020towards,
  title={Towards learning a generic agent for vision-and-language navigation via pre-training},
  author={Hao, Weituo and Li, Chunyuan and Li, Xiujun and Carin, Lawrence and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13137--13146},
  year={2020}
}

@inproceedings{li2020unicoder,
  title={Unicoder-VL: A Universal Encoder for Vision and Language by Cross-Modal Pre-Training.},
  author={Li, Gen and Duan, Nan and Fang, Yuejian and Gong, Ming and Jiang, Daxin and Zhou, Ming},
  booktitle={AAAI},
  pages={11336--11344},
  year={2020}
}

% First instruction-following

@article{woods1972lunar,
  title={The lunar sciences natural language information system},
  author={Woods, William},
  journal={BBN report},
  year={1972},
  publisher={Bolt Beranek and Newman}
}

@article{warren1982efficient,
  title={An efficient easily adaptable system for interpreting natural language queries},
  author={Warren, David HD and Pereira, Fernando CN},
  journal={American journal of computational linguistics},
  volume={8},
  number={3-4},
  pages={110--122},
  year={1982}
}

% New objective instruction-following

@article{parvaneh2020counterfactual,
  title={Counterfactual Vision-and-Language Navigation: Unravelling the Unseen},
  author={Parvaneh, Amin and Abbasnejad, Ehsan and Teney, Damien and Shi, Qinfeng and van den Hengel, Anton},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{wang2020environment,
  title={Environment-agnostic Multitask Learning for Natural Language Grounded Navigation},
  author={Wang, Xin and Jain, Vihan and Ie, Eugene and Wang, William Yang and Kozareva, Zornitsa and Ravi, Sujith},
  journal={arXiv preprint arXiv:2003.00443},
  year={2020}
}


@inproceedings{hao2020towards,
  title={Towards learning a generic agent for vision-and-language navigation via pre-training},
  author={Hao, Weituo and Li, Chunyuan and Li, Xiujun and Carin, Lawrence and Gao, Jianfeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13137--13146},
  year={2020}
}

% New architecture instruction-following

@article{hong2020recurrent,
  title={A Recurrent Vision-and-Language BERT for Navigation},
  author={Hong, Yicong and Wu, Qi and Qi, Yuankai and Rodriguez-Opazo, Cristian and Gould, Stephen},
  journal={arXiv preprint arXiv:2011.13922},
  year={2020}
}

% More data instruction-following

@article{majumdar2020improving,
  title={Improving Vision-and-Language Navigation with Image-Text Pairs from the Web},
  author={Majumdar, Arjun and Shrivastava, Ayush and Lee, Stefan and Anderson, Peter and Parikh, Devi and Batra, Dhruv},
  journal={arXiv preprint arXiv:2004.14973},
  year={2020}
}

% ask for help

@inproceedings{shiomi2008semi,
  title={A semi-autonomous communication robot—a field trial at a train station},
  author={Shiomi, Masahiro and Sakamoto, Daisuke and Kanda, Takayuki and Ishi, Carlos Toshinori and Ishiguro, Hiroshi and Hagita, Norihiro},
  booktitle={2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  pages={303--310},
  year={2008},
  organization={IEEE}
}

@inproceedings{cha2016using,
  title={Using nonverbal signals to request help during human-robot collaboration},
  author={Cha, Elizabeth and Matari{\'c}, Maja},
  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5070--5076},
  year={2016},
  organization={IEEE}
}

@inproceedings{kwon2018expressing,
  title={Expressing robot incapability},
  author={Kwon, Minae and Huang, Sandy H and Dragan, Anca D},
  booktitle={Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction},
  pages={87--95},
  year={2018}
}

@inproceedings{asoh1997socially,
  title={Socially embedded learning of the office-conversant mobile robot jijo-2},
  author={Asoh, Hideki and Hayamizu, Satoru and Hara, Isao and Motomura, Yoichi and Akaho, Shotaro and Matsui, Toshihiro},
  booktitle={IJCAI (2)},
  pages={880--887},
  year={1997}
}

@article{michalowski2007socially,
  title={Socially distributed perception: Grace plays social tag at aaai 2005},
  author={Michalowski, Marek P and {\v{S}}abanovi{\'c}, Selma and DiSalvo, Carl and Busquets, Didac and Hiatt, Laura M and Melchior, Nik A and Simmons, Reid},
  journal={Autonomous Robots},
  volume={22},
  number={4},
  pages={385--397},
  year={2007},
  publisher={Springer}
}

% how to design to ask for help

@inproceedings{rosenthal2012mobile,
  title={Mobile Robot Planning to Seek Help with Spatially-Situated Tasks.},
  author={Rosenthal, Stephanie and Veloso, Manuela M},
  booktitle={AAAI},
  volume={4},
  number={5.3},
  pages={1},
  year={2012}
}

@article{huttenrauch2006help,
  title={To help or not to help a service robot: Bystander intervention as a resource in human--robot collaboration},
  author={H{\"u}ttenrauch, Helge and Severinson-Eklundh, Kerstin},
  journal={Interaction Studies},
  volume={7},
  number={3},
  pages={455--477},
  year={2006},
  publisher={John Benjamins}
}

@inproceedings{weiss2010robots,
  title={Robots asking for directions—The willingness of passers-by to support robots},
  author={Weiss, Astrid and Igelsb{\"o}ck, Judith and Tscheligi, Manfred and Bauer, Andrea and K{\"u}hnlenz, Kolja and Wollherr, Dirk and Buss, Martin},
  booktitle={2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  pages={23--30},
  year={2010},
  organization={IEEE}
}

@inproceedings{cameron2015help,
  title={Help! I can’t reach the buttons: Facilitating helping behaviors towards robots},
  author={Cameron, David and Collins, Emily C and Chua, Adriel and Fernando, Samuel and McAree, Owen and Martinez-Hernandez, Uriel and Aitken, Jonathan M and Boorman, Luke and Law, James},
  booktitle={Conference on Biomimetic and Biohybrid Systems},
  pages={354--358},
  year={2015},
  organization={Springer}
}

@article{bajones2016help,
  title={Help, anyone? a user study for modeling robotic behavior to mitigate malfunctions with the help of the user},
  author={Bajones, Markus and Weiss, Astrid and Vincze, Markus},
  journal={arXiv preprint arXiv:1606.02547},
  year={2016}
}

@inproceedings{cha2016using,
  title={Using nonverbal signals to request help during human-robot collaboration},
  author={Cha, Elizabeth and Matari{\'c}, Maja},
  booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5070--5076},
  year={2016},
  organization={IEEE}
}

@article{cameron2016robot,
  title={Robot-stated limitations but not intentions promote user assistance},
  author={Cameron, David and Loh, Ee Jing and Chua, Adriel and Collins, Emily and Aitken, Jonathan M and Law, James},
  journal={arXiv preprint arXiv:1606.02603},
  year={2016}
}

@inproceedings{bajones2016enabling,
  title={Enabling long-term human-robot interaction through adaptive behavior coordination},
  author={Bajones, Markus},
  booktitle={2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  pages={597--598},
  year={2016},
  organization={IEEE}
}

@inproceedings{backhaus2018somebody,
  title={Somebody help me, please?!” Interaction Design Framework for Needy Mobile Service Robots},
  author={Backhaus, Nils and Rosen, Patricia H and Scheidig, Andrea and Gross, Horst-Michael and Wischniewski, Sascha},
  booktitle={2018 IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO)},
  pages={54--61},
  year={2018},
  organization={IEEE}
}

@inproceedings{morales2019interaction,
  title={Interaction Needs and Opportunities for Failing Robots},
  author={Morales, Cecilia G and Carter, Elizabeth J and Tan, Xiang Zhi and Steinfeld, Aaron},
  booktitle={Proceedings of the 2019 on Designing Interactive Systems Conference},
  pages={659--670},
  year={2019}
}

@article{vanzo2020willing,
  title={Who is willing to help robots? a user study on collaboration attitude},
  author={Vanzo, Andrea and Riccio, Francesco and Sharf, Mahmoud and Mirabella, Valeria and Catarci, Tiziana and Nardi, Daniele},
  journal={International Journal of Social Robotics},
  volume={12},
  number={2},
  pages={589--598},
  year={2020},
  publisher={Springer}
}

% interactive learning algorithm surveys

@article{arulkumaran2017deep,
  title={Deep reinforcement learning: A brief survey},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={6},
  pages={26--38},
  year={2017},
  publisher={IEEE}
}

@article{hussein2017imitation,
  title={Imitation learning: A survey of learning methods},
  author={Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
  journal={ACM Computing Surveys (CSUR)},
  volume={50},
  number={2},
  pages={1--35},
  year={2017},
  publisher={ACM New York, NY, USA}
}

% misc

@inproceedings{nguyen2017banditnmt,
    title = "Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback",
    author = "Nguyen, Khanh  and
      Daum{\'e} III, Hal  and
      Boyd-Graber, Jordan",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D17-1153",
    doi = "10.18653/v1/D17-1153",
    pages = "1464--1474",
    abstract = "Machine translation is a natural candidate problem for reinforcement learning from human feedback: users provide quick, dirty ratings on candidate translations to guide a system to improve. Yet, current neural machine translation training focuses on expensive human-generated reference translations. We describe a reinforcement learning algorithm that improves neural machine translation systems from simulated human feedback. Our algorithm combines the advantage actor-critic algorithm (Mnih et al., 2016) with the attention-based neural encoder-decoder architecture (Luong et al., 2015). This algorithm (a) is well-designed for problems with a large action space and delayed rewards, (b) effectively optimizes traditional corpus-level machine translation metrics, and (c) is robust to skewed, high-variance, granular feedback modeled after actual human behaviors.",
}


% observational IL

@inproceedings{torabi2019recent,
  title={Recent advances in imitation learning from observation},
  author={Torabi, Faraz and Warnell, Garrett and Stone, Peter},
  booktitle=ijcai,
  year={2019}
}

% proposed work

@inproceedings{miryoosefi2019reinforcement,
  title={Reinforcement learning with convex constraints},
  author={Miryoosefi, Sobhan and Brantley, Kiant{\'e} and Daume III, Hal and Dudik, Miro and Schapire, Robert E},
  booktitle={Advances in Neural Information Processing Systems},
  pages={14093--14102},
  year={2019}
}

@article{mei2015listen,
  title={Listen, attend, and walk: Neural mapping of navigational instructions to action sequences},
  author={Mei, Hongyuan and Bansal, Mohit and Walter, Matthew R},
  journal={arXiv preprint arXiv:1506.04089},
  year={2015}
}

@inproceedings{jain2015planit,
  title={Planit: A crowdsourcing approach for learning to plan paths from large scale preference feedback},
  author={Jain, Ashesh and Das, Debarghya and Gupta, Jayesh K and Saxena, Ashutosh},
  booktitle={2015 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={877--884},
  year={2015},
  organization={IEEE}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

% Learning from language (RL reduction)

@inproceedings{fidler2017teaching,
  title={Teaching machines to describe images with natural language feedback},
  author={Fidler, Sanja and others},
  booktitle=neurips,
  year={2017}
}

@inproceedings{sumers2020learning,
  title={Learning rewards from linguistic feedback},
  author={Sumers, Theodore R and Ho, Mark K and Hawkins, Robert D and Narasimhan, Karthik and Griffiths, Thomas L},
  booktitle=aaai,
  year={2020}
}

@inproceedings{macglashan2015grounding,
  title={Grounding English Commands to Reward Functions.},
  author={MacGlashan, James and Babes-Vroman, Monica and Marie desJardins and Littman, Michael L and Muresan, Smaranda and Squire, Shawn and Tellex, Stefanie and Arumugam, Dilip and Yang, Lei},
  booktitle={Robotics: Science and Systems},
  year={2015}
}

@inproceedings{fu2019language,
  title={From language to goals: Inverse reinforcement learning for vision-based instruction following},
  author={Fu, Justin and Korattikara, Anoop and Levine, Sergey and Guadarrama, Sergio},
  booktitle=iclr,
  year={2019}
}

@inproceedings{goyal2019using,
  title={Using natural language for reward shaping in reinforcement learning},
  author={Goyal, Prasoon and Niekum, Scott and Mooney, Raymond J},
  booktitle=ijcai,
  year={2019}
}

% Learning from language (grounding)

@article{li2020towards,
  title={Towards Effective Human-AI Collaboration in GUI-Based Interactive Task Learning Agents},
  author={Li, Toby Jia-Jun and Chen, Jingya and Mitchell, Tom M and Myers, Brad A},
  journal={Workshop on Artificial Intelligence for HCI: A Modern Approach (AI4HCI)},
  year={2020}
}

@inproceedings{li2017programming,
  title={Programming IoT devices by demonstration using mobile apps},
  author={Li, Toby Jia-Jun and Li, Yuanchun and Chen, Fanglin and Myers, Brad A},
  booktitle={International Symposium on End User Development},
  pages={3--17},
  year={2017},
  organization={Springer}
}

@article{wang2016learning,
  title={Learning language games through interaction},
  author={Wang, Sida I and Liang, Percy and Manning, Christopher D},
  journal={arXiv preprint arXiv:1606.02447},
  year={2016}
}

@article{goldwasser2014learning,
  title={Learning from natural instructions},
  author={Goldwasser, Dan and Roth, Dan},
  journal={Machine learning},
  volume={94},
  number={2},
  pages={205--232},
  year={2014},
  publisher={Springer}
}

% Learning from language (instruction interpretation

%-------------

@inproceedings{yao-etal-2020-imitation,
    title = "An Imitation Game for Learning Semantic Parsers from User Interaction",
    author = "Yao, Ziyu  and
      Tang, Yiqi  and
      Yih, Wen-tau  and
      Sun, Huan  and
      Su, Yu",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.559",
    doi = "10.18653/v1/2020.emnlp-main.559",
    pages = "6883--6902",
    abstract = "Despite the widely successful applications, bootstrapping and fine-tuning semantic parsers are still a tedious process with challenges such as costly data annotation and privacy risks. In this paper, we suggest an alternative, human-in-the-loop methodology for learning semantic parsers directly from users. A semantic parser should be introspective of its uncertainties and prompt for user demonstrations when uncertain. In doing so it also gets to imitate the user behavior and continue improving itself autonomously with the hope that eventually it may become as good as the user in interpreting their questions. To combat the sparsity of demonstrations, we propose a novel annotation-efficient imitation learning algorithm, which iteratively collects new datasets by mixing demonstrated states and confident predictions and retrains the semantic parser in a Dataset Aggregation fashion (Ross et al., 2011). We provide a theoretical analysis of its cost bound and also empirically demonstrate its promising performance on the text-to-SQL problem. Code will be available at https://github.com/sunlab-osu/MISP.",
}

