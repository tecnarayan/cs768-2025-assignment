% Generated by IEEEtranSN.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{27}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtranSN.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem[Asanović and Morgan(1991)]{asanovic1991experimental}
K.~Asanović and N.~Morgan, ``Experimental determination of precision
  requirements for back-propagation training of artificial neural networks,''
  International Computer Science Institute, Tech. Rep., 1991.

\bibitem[Ba and Caruana(2014)]{Jimmy2014lowRankSNN}
J.~Ba and R.~Caruana, ``Do deep nets really need to be deep?'' in
  \emph{Advances in Neural Information Processing Systems 27 (NIPS)}, 2014, pp.
  2654--2662.

\bibitem[Caroll and Chang(1970)]{caroll70}
J.~D. Caroll and J.~J. Chang, ``Analysis of individual differences in
  multidimensional scaling via n-way generalization of {E}ckart-{Y}oung
  decomposition,'' \emph{Psychometrika}, vol.~35, pp. 283--319, 1970.

\bibitem[Chen et~al.(2015)Chen, Wilson, Tyree, Weinberger, and
  Chen]{chen2015compressing}
W.~Chen, J.~T. Wilson, S.~Tyree, K.~Q. Weinberger, and Y.~Chen, ``Compressing
  neural networks with the hashing trick,'' in \emph{International Conference
  on Machine Learning (ICML)}, 2015, pp. 2285--2294.

\bibitem[Cybenko(1989)]{cybenko1989universalApproximator}
G.~Cybenko, ``Approximation by superpositions of a sigmoidal function,''
  \emph{Mathematics of control, signals and systems}, pp. 303--314, 1989.

\bibitem[Denil et~al.(2013)Denil, Shakibi, Dinh, Ranzato, and
  de~Freitas]{Denil2013predicting}
M.~Denil, B.~Shakibi, L.~Dinh, M.~Ranzato, and N.~de~Freitas, ``Predicting
  parameters in deep learning,'' in \emph{Advances in Neural Information
  Processing Systems 26 (NIPS)}, 2013, pp. 2148--2156.

\bibitem[Denton et~al.(2014)Denton, Zaremba, Bruna, LeCun, and
  Fergus]{Denil2014speedup}
E.~Denton, W.~Zaremba, J.~Bruna, Y.~LeCun, and R.~Fergus, ``Exploiting linear
  structure within convolutional networks for efficient evaluation,'' in
  \emph{Advances in Neural Information Processing Systems 27 (NIPS)}, 2014, pp.
  1269--1277.

\bibitem[Gilboa et~al.(2012)Gilboa, Saatçi, and Cunningham]{gilboa2012gp}
E.~Gilboa, Y.~Saatçi, and J.~P. Cunningham, ``Scaling multidimensional
  inference for structured gaussian processes,'' \emph{{arXiv} preprint}, no.
  1209.4120, 2012.

\bibitem[Gong et~al.(2014)Gong, Liu, Yang, and Bourdev]{gong2014PQcompressing}
Y.~Gong, L.~Liu, M.~Yang, and L.~Bourdev, ``Compressing deep convolutional
  networks using vector quantization,'' \emph{{arXiv} preprint}, no. 1412.6115,
  2014.

\bibitem[Goodfellow et~al.(2013)Goodfellow, Warde-Farley, Mirza, Courville, and
  Bengio]{goodfellow2013maxout}
I.~J. Goodfellow, D.~Warde-Farley, M.~Mirza, A.~Courville, and Y.~Bengio,
  ``Maxout networks,'' in \emph{International Conference on Machine Learning
  (ICML)}, 2013, pp. 1319--1327.

\bibitem[Hackbusch and K\"{u}hn(2009)]{hackbush09hierahical}
W.~Hackbusch and S.~K\"{u}hn, ``A new scheme for the tensor representation,''
  \emph{J. Fourier Anal. Appl.}, vol.~15, pp. 706--722, 2009.

\bibitem[Krizhevsky(2009)]{krizhevsky2009Cifar}
A.~Krizhevsky, ``Learning multiple layers of features from tiny images,''
  Master's thesis, Computer Science Department, University of Toronto, 2009.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{Krizhevsky2012AlexNet}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton, ``Imagenet classification with
  deep convolutional neural networks,'' in \emph{Advances in Neural Information
  Processing Systems 25 (NIPS)}, 2012, pp. 1097--1105.

\bibitem[Lebedev et~al.(2014)Lebedev, Ganin, Rakhuba, Oseledets, and
  Lempitsky]{lebedev2014speeding}
V.~Lebedev, Y.~Ganin, M.~Rakhuba, I.~Oseledets, and V.~Lempitsky, ``Speeding-up
  convolutional neural networks using fine-tuned {CP}-decomposition,'' in
  \emph{International Conference on Learning Representations (ICLR)}, 2014.

\bibitem[LeCun et~al.(1998)LeCun, Cortes, and Burges]{lecun1998mnist}
Y.~LeCun, C.~Cortes, and C.~J.~C. Burges, ``The {MNIST} database of handwritten
  digits,'' 1998.

\bibitem[Novikov et~al.(2014)Novikov, Rodomanov, Osokin, and
  Vetrov]{novikov2014putting}
A.~Novikov, A.~Rodomanov, A.~Osokin, and D.~Vetrov, ``Putting {MRF}s on a
  {T}ensor {T}rain,'' in \emph{International Conference on Machine Learning
  (ICML)}, 2014, pp. 811--819.

\bibitem[Oseledets(2011)]{oseledets2011ttMain}
I.~V. Oseledets, ``{T}ensor-{T}rain decomposition,'' \emph{SIAM J. Scientific
  Computing}, vol.~33, no.~5, pp. 2295--2317, 2011.

\bibitem[Rumelhart et~al.(1986)Rumelhart, Hinton, and Williams]{rumelhart1986}
D.~E. Rumelhart, G.~E. Hinton, and R.~J. Williams, ``Learning representations
  by back-propagating errors,'' \emph{Nature}, vol. 323, no. 6088, pp.
  533–--536, 1986.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and
  Fei-Fei]{Russakovsky2015ImageNet}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang,
  A.~Karpathy, A.~Khosla, M.~Bernstein, A.~C. Berg, and L.~Fei-Fei, ``Imagenet
  large scale visual recognition challenge,'' \emph{International Journal of
  Computer Vision (IJCV)}, 2015.

\bibitem[Sainath et~al.(2013)Sainath, Kingsbury, Sindhwani, Arisoy, and
  Ramabhadran]{sainath2013low}
T.~N. Sainath, B.~Kingsbury, V.~Sindhwani, E.~Arisoy, and B.~Ramabhadran,
  ``Low-rank matrix factorization for deep neural network training with
  high-dimensional output targets,'' in \emph{International Conference of
  Acoustics, Speech, and Signal Processing (ICASSP)}, 2013, pp. 6655--6659.

\bibitem[Simonyan and Zisserman(2015)]{simonyan15}
K.~Simonyan and A.~Zisserman, ``Very deep convolutional networks for
  large-scale image recognition,'' in \emph{International Conference on
  Learning Representations (ICLR)}, 2015.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{snoek2012cifarQuick}
J.~Snoek, H.~Larochelle, and R.~P. Adams, ``Practical bayesian optimization of
  machine learning algorithms,'' in \emph{Advances in Neural Information
  Processing Systems 25 (NIPS)}, 2012, pp. 2951--2959.

\bibitem[Tucker(1966)]{tucker66}
L.~R. Tucker, ``Some mathematical notes on three-mode factor analysis,''
  \emph{Psychometrika}, vol.~31, no.~3, pp. 279--311, 1966.

\bibitem[Vedaldi and Lenc(2015)]{matconvnet}
A.~Vedaldi and K.~Lenc, ``Matconvnet -- convolutional neural networks for
  {MATLAB},'' in \emph{Proceeding of the {ACM} Int. Conf. on Multimedia}, 2015.

\bibitem[Xue et~al.(2013)Xue, Li, and Gong]{xue2013restructuring}
J.~Xue, J.~Li, and Y.~Gong, ``Restructuring of deep neural network acoustic
  models with singular value decomposition,'' in \emph{Interspeech}, 2013, pp.
  2365--2369.

\bibitem[Yang et~al.(2014)Yang, Moczulski, Denil, de~Freitas, Smola, Song, and
  Wang]{yang2014deep}
Z.~Yang, M.~Moczulski, M.~Denil, N.~de~Freitas, A.~Smola, L.~Song, and Z.~Wang,
  ``Deep fried convnets,'' \emph{{arXiv} preprint}, no. 1412.7149, 2014.

\bibitem[Zhang et~al.(2014)Zhang, Yang, Oseledets, Karniadakis, and
  Daniel]{zhang2015enabling}
Z.~Zhang, X.~Yang, I.~V. Oseledets, G.~E. Karniadakis, and L.~Daniel,
  ``Enabling high-dimensional hierarchical uncertainty quantification by
  {ANOVA} and tensor-train decomposition,'' \emph{Computer-Aided Design of
  Integrated Circuits and Systems, IEEE Transactions on}, pp. 63--76, 2014.

\end{thebibliography}
