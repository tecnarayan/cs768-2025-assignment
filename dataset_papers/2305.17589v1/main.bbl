\begin{thebibliography}{61}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alon \& Yahav(2020)Alon and Yahav]{alon2020BottleneckGraphNeural}
Alon, U. and Yahav, E.
\newblock On the {{Bottleneck}} of {{Graph Neural Networks}} and its
  {{Practical Implications}}.
\newblock In \emph{Proc. Int. {{Conf.}} {{Learn. Representations}}}, September
  2020.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016LayerNormalization}
Ba, J.~L., Kiros, J.~R., and Hinton, G.~E.
\newblock Layer {{Normalization}}.
\newblock In \emph{{{NIPS}} 2016 {{Deep Learning Symposium}}}, August 2016.

\bibitem[Beani et~al.(2021)Beani, Passaro, Létourneau, Hamilton, Corso, and
  Lió]{beani2021DirectionalGraphNetworks}
Beani, D., Passaro, S., Létourneau, V., Hamilton, W., Corso, G., and Lió, P.
\newblock Directional {{Graph Networks}}.
\newblock In \emph{Proc. {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}.}, pp.\
  748--758. {PMLR}, July 2021.

\bibitem[Bevilacqua et~al.(2022)Bevilacqua, Frasca, Lim, Srinivasan, Cai,
  Balamurugan, Bronstein, and
  Maron]{bevilacqua2022EquivariantSubgraphAggregation}
Bevilacqua, B., Frasca, F., Lim, D., Srinivasan, B., Cai, C., Balamurugan, G.,
  Bronstein, M.~M., and Maron, H.
\newblock Equivariant {{Subgraph Aggregation Networks}}.
\newblock In \emph{Proc. {{Int}}. {{Conf}}. {{Learn}}. {{Representations}}},
  March 2022.

\bibitem[Bodnar et~al.(2021)Bodnar, Frasca, Wang, Otter, Montufar, Lió, and
  Bronstein]{bodnar2021WeisfeilerLehmanGo}
Bodnar, C., Frasca, F., Wang, Y., Otter, N., Montufar, G.~F., Lió, P., and
  Bronstein, M.
\newblock Weisfeiler and {{Lehman Go Topological}}: {{Message Passing
  Simplicial Networks}}.
\newblock In \emph{Proc. {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}.}, pp.\
  1026--1037. {PMLR}, July 2021.

\bibitem[Bouritsas et~al.(2022)Bouritsas, Frasca, Zafeiriou, and
  Bronstein]{bouritsas2022ImprovingGraphNeural}
Bouritsas, G., Frasca, F., Zafeiriou, S.~P., and Bronstein, M.
\newblock Improving {{Graph Neural Network Expressivity}} via {{Subgraph
  Isomorphism Counting}}.
\newblock \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, pp.\  1--1, 2022.
\newblock ISSN 1939-3539.
\newblock \doi{10.1109/TPAMI.2022.3154319}.

\bibitem[Bresson \& Laurent(2018)Bresson and
  Laurent]{bresson2018ResidualGatedGraph}
Bresson, X. and Laurent, T.
\newblock Residual {{Gated Graph ConvNets}}.
\newblock \emph{arXiv}, April 2018.

\bibitem[Brody et~al.(2022)Brody, Alon, and Yahav]{brody2021HowAttentiveAre}
Brody, S., Alon, U., and Yahav, E.
\newblock How {{Attentive}} are {{Graph Attention Networks}}?
\newblock In \emph{Proc. Int. {{Conf.}} {{Learn. Representations}})}, 2022.

\bibitem[Bronstein et~al.(2021)Bronstein, Bruna, Cohen, and
  Veličković]{bronstein2021GeometricDeepLearning}
Bronstein, M.~M., Bruna, J., Cohen, T., and Veličković, P.
\newblock \emph{Geometric {{Deep Learning}}: {{Grids}}, {{Groups}}, {{Graphs}},
  {{Geodesics}}, and {{Gauges}}}.
\newblock May 2021.

\bibitem[Chen et~al.(2022)Chen, O’Bray, and
  Borgwardt]{chen2022StructureAwareTransformerGraph}
Chen, D., O’Bray, L., and Borgwardt, K.
\newblock Structure-{{Aware Transformer}} for {{Graph Representation
  Learning}}.
\newblock In \emph{Proc. {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}.}, pp.\
  3469--3489, June 2022.

\bibitem[Corso et~al.(2020)Corso, Cavalleri, Beaini, Liò, and
  Veličković]{corso2020PrincipalNeighbourhoodAggregation}
Corso, G., Cavalleri, L., Beaini, D., Liò, P., and Veličković, P.
\newblock Principal {{Neighbourhood Aggregation}} for {{Graph Nets}}.
\newblock In \emph{Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.}, December 2020.

\bibitem[Dai et~al.(2019)Dai, Yang, Yang, Carbonell, Le, and
  Salakhutdinov]{dai2019TransformerXLAttentiveLanguage}
Dai, Z., Yang, Z., Yang, Y., Carbonell, J., Le, Q., and Salakhutdinov, R.
\newblock Transformer-{{XL}}: {{Attentive Language Models}} beyond a
  {{Fixed-Length Context}}.
\newblock In \emph{Proc. Annu. Meeting Assoc. Comput. Linguist.}, pp.\
  2978--2988, July 2019.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova]{devlin2019BERTPretrainingDeep}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock {{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for
  {{Language Understanding}}.
\newblock In \emph{Proc. {{Annu}}. {{Conf}}. {{North Am}}. {{Chapter Assoc}}.
  {{Comput}}. {{Linguist}}. {{Hum}}. {{Lang}}. {{Technol}}. ({{NAACL-HILT}})},
  May 2019.

\bibitem[Diao \& Loynd(2022)Diao and Loynd]{diao2022relational}
Diao, C. and Loynd, R.
\newblock Relational attention: Generalizing transformers for graph-structured
  tasks.
\newblock \emph{arXiv preprint arXiv:2210.05062}, 2022.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{dosovitskiy2020ImageWorth16x16}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S.,
  Uszkoreit, J., and Houlsby, N.
\newblock An {{Image}} is {{Worth}} 16x16 {{Words}}: {{Transformers}} for
  {{Image Recognition}} at {{Scale}}.
\newblock In \emph{Proc. {{Int}}. {{Conf}}. {{Learn}}. {{Representations}}},
  September 2020.

\bibitem[Dwivedi \& Bresson(2021)Dwivedi and
  Bresson]{dwivedi2021GeneralizationTransformerNetworks}
Dwivedi, V.~P. and Bresson, X.
\newblock A {{Generalization}} of {{Transformer Networks}} to {{Graphs}}.
\newblock In \emph{Proc. {{AAAI Workshop Deep Learn}}. {{Graphs}}: {{Methods
  Appl}}.}, January 2021.

\bibitem[Dwivedi et~al.(2021)Dwivedi, Luu, Laurent, Bengio, and
  Bresson]{dwivedi2021GraphNeuralNetworks}
Dwivedi, V.~P., Luu, A.~T., Laurent, T., Bengio, Y., and Bresson, X.
\newblock Graph {{Neural Networks}} with {{Learnable Structural}} and
  {{Positional Representations}}.
\newblock In \emph{Proc. {{Int}}. {{Conf}}. {{Learn}}. {{Representations}}},
  September 2021.

\bibitem[Dwivedi et~al.(2022{\natexlab{a}})Dwivedi, Joshi, Laurent, Bengio, and
  Bresson]{dwivedi2020BenchmarkingGraphNeural}
Dwivedi, V.~P., Joshi, C.~K., Laurent, T., Bengio, Y., and Bresson, X.
\newblock Benchmarking {{Graph Neural Networks}}.
\newblock \emph{J. Mach. Learn. Res.}, December 2022{\natexlab{a}}.

\bibitem[Dwivedi et~al.(2022{\natexlab{b}})Dwivedi, Rampášek, Galkin, Parviz,
  Wolf, Luu, and Beaini]{dwivedi2022LongRangeGraph}
Dwivedi, V.~P., Rampášek, L., Galkin, M., Parviz, A., Wolf, G., Luu, A.~T.,
  and Beaini, D.
\newblock Long {{Range Graph Benchmark}}.
\newblock In \emph{Adv. Neural Inf. Process. Syst.}, December
  2022{\natexlab{b}}.

\bibitem[Feldman et~al.(2022)Feldman, Boyarski, Feldman, Kogan, Mendelson, and
  Baskin]{feldman2022weisfeiler}
Feldman, O., Boyarski, A., Feldman, S., Kogan, D., Mendelson, A., and Baskin,
  C.
\newblock Weisfeiler and leman go infinite: Spectral and combinatorial
  pre-colorings.
\newblock In \emph{Proc. Int. Conf. Learn. Representations Workshop Geom.
  topol. Representation Learn.}, 2022.

\bibitem[Gasteiger et~al.(2019)Gasteiger, {Weiß enberger}, and
  Günnemann]{gasteiger2019DiffusionImprovesGraph}
Gasteiger, J., {Weiß enberger}, S., and Günnemann, S.
\newblock Diffusion {{Improves Graph Learning}}.
\newblock In \emph{Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.}, volume~32.
  {Curran Associates, Inc.}, 2019.

\bibitem[Gilmer et~al.(2017)Gilmer, Schoenholz, Riley, Vinyals, and
  Dahl]{gilmer2017NeuralMessagePassing}
Gilmer, J., Schoenholz, S.~S., Riley, P.~F., Vinyals, O., and Dahl, G.~E.
\newblock Neural {{Message Passing}} for {{Quantum Chemistry}}.
\newblock In \emph{Proc. Int. {{Conf.}} {{Mach. Learn.}}}, June 2017.

\bibitem[Hornik et~al.(1989)Hornik, Stinchcombe, and
  White]{hornik1989multilayer}
Hornik, K., Stinchcombe, M., and White, H.
\newblock Multilayer feedforward networks are universal approximators.
\newblock \emph{Neural Netw.}, 2\penalty0 (5):\penalty0 359--366, 1989.

\bibitem[Hu et~al.(2020)Hu, Liu*, Gomes, Zitnik, Liang, Pande, and
  Leskovec]{hu2020StrategiesPretrainingGraph}
Hu, W., Liu*, B., Gomes, J., Zitnik, M., Liang, P., Pande, V., and Leskovec, J.
\newblock Strategies for {{Pre-training Graph Neural Networks}}.
\newblock In \emph{Proc. {{Int}}. {{Conf}}. {{Learn}}. {{Representations}}},
  March 2020.

\bibitem[Hu et~al.(2021)Hu, Fey, Ren, Nakata, Dong, and Leskovec]{hu2021ogblsc}
Hu, W., Fey, M., Ren, H., Nakata, M., Dong, Y., and Leskovec, J.
\newblock Ogb-lsc: A large-scale challenge for machine learning on graphs.
\newblock In \emph{Adv. Neural Inf. Process. Syst. Datasets Benchmarks Track},
  2021.

\bibitem[Hussain et~al.(2022)Hussain, Zaki, and
  Subramanian]{hussain2022GlobalSelfAttentionReplacement}
Hussain, M.~S., Zaki, M.~J., and Subramanian, D.
\newblock Global {{Self-Attention}} as a {{Replacement}} for {{Graph
  Convolution}}.
\newblock In \emph{Proc. {{ACM SIGKDD Int}}. {{Conf}}. {{Knowl Discov}}. {{Data
  Min}}. ({{KDD}})}, August 2022.
\newblock \doi{10.1145/3534678.3539296}.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and
  Szegedy]{ioffe2015BatchNormalizationAccelerating}
Ioffe, S. and Szegedy, C.
\newblock Batch {{Normalization}}: {{Accelerating Deep Network Training}} by
  {{Reducing Internal Covariate Shift}}.
\newblock In \emph{Proc. {{Int}}. {{Conf}}. {{Mach}}. {{Learn}}.}, pp.\
  448--456. {PMLR}, June 2015.

\bibitem[Irwin et~al.(2012)Irwin, Sterling, Mysinger, Bolstad, and
  Coleman]{irwin2012ZINCFreeTool}
Irwin, J.~J., Sterling, T., Mysinger, M.~M., Bolstad, E.~S., and Coleman, R.~G.
\newblock {{ZINC}}: {{A Free Tool}} to {{Discover Chemistry}} for {{Biology}}.
\newblock \emph{J. Chem. Inf. Model.}, 52\penalty0 (7):\penalty0 1757--1768,
  July 2012.
\newblock ISSN 1549-9596.
\newblock \doi{10.1021/ci3001277}.

\bibitem[Kim et~al.(2022)Kim, Nguyen, Min, Cho, Lee, Lee, and
  Hong]{kim2022PureTransformersAre}
Kim, J., Nguyen, D.~T., Min, S., Cho, S., Lee, M., Lee, H., and Hong, S.
\newblock Pure {{Transformers}} are {{Powerful Graph Learners}}.
\newblock In \emph{Adv. {{Neural Inf}}. {{Process}} {{Syst.}}}, October 2022.

\bibitem[Kipf \& Welling(2017)Kipf and
  Welling]{kipf2017SemiSupervisedClassificationGraph}
Kipf, T.~N. and Welling, M.
\newblock Semi-{{Supervised Classification}} with {{Graph Convolutional
  Networks}}.
\newblock In \emph{Proc. {{Int}}. {{Conf}}. {{Learn}}. {{Representations}}},
  2017.

\bibitem[Kreuzer et~al.(2021)Kreuzer, Beaini, Hamilton, Létourneau, and
  Tossou]{kreuzer2021RethinkingGraphTransformers}
Kreuzer, D., Beaini, D., Hamilton, W.~L., Létourneau, V., and Tossou, P.
\newblock Rethinking {{Graph Transformers}} with {{Spectral Attention}}.
\newblock In \emph{Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.}, May 2021.

\bibitem[Li et~al.(2020)Li, Wang, Wang, and
  Leskovec]{li2020DistanceEncodingDesign}
Li, P., Wang, Y., Wang, H., and Leskovec, J.
\newblock Distance {{Encoding}}: {{Design Provably More Powerful Neural
  Networks}} for {{Graph Representation Learning}}.
\newblock In \emph{Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.}, 2020.

\bibitem[Li et~al.(2018)Li, Han, and Wu]{li2018DeeperInsightsGraph}
Li, Q., Han, Z., and Wu, X.-M.
\newblock Deeper {{Insights}} into {{Graph Convolutional Networks}} for
  {{Semi-Supervised Learning}}.
\newblock In \emph{Proc. {{AAAI Conf}}. {{Artif}}. {{Intell}}.}, pp.\ ~9, 2018.

\bibitem[Lim et~al.(2023)Lim, Robinson, Zhao, Smidt, Sra, Maron, and
  Jegelka]{lim2022SignBasisInvariant}
Lim, D., Robinson, J.~D., Zhao, L., Smidt, T., Sra, S., Maron, H., and Jegelka,
  S.
\newblock Sign and {{Basis Invariant Networks}} for {{Spectral Graph
  Representation Learning}}.
\newblock In \emph{Proc. Int. Conf. Learn. Representations}, 2023.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and
  Guo]{liu2021SwinTransformerHierarchical}
Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., and Guo, B.
\newblock Swin {{Transformer}}: {{Hierarchical Vision Transformer Using Shifted
  Windows}}.
\newblock In \emph{Proc. {{IEEE}}/{{CVF Int. Conf.}} {{Comput. Vis.}}}, pp.\
  10012--10022, 2021.

\bibitem[Loukas(2020)]{loukas2020WhatGraphNeural}
Loukas, A.
\newblock What graph neural networks cannot learn: Depth vs width.
\newblock In \emph{Proc. {{Int}}. {{Conf}}. {{Learn}}. {{Representations}}},
  March 2020.

\bibitem[Luo et~al.(2022)Luo, Li, Zheng, Liu, Wang, and He]{luo2022your}
Luo, S., Li, S., Zheng, S., Liu, T.-Y., Wang, L., and He, D.
\newblock Your transformer may not be as powerful as you expect.
\newblock In \emph{Adv. {{Neural Inf.}} {{Process.}} {{Syst.}}}, 2022.

\bibitem[Ma et~al.(2021)Ma, Rabbany, and Romero-Soriano]{ma2021graph}
Ma, L., Rabbany, R., and Romero-Soriano, A.
\newblock Graph attention networks with positional embeddings.
\newblock In \emph{Pacific-Asia Conf. Knowl. Discov. and Data Min.}, pp.\
  514--527. Springer, 2021.

\bibitem[Masters et~al.(2022)Masters, Dean, Klaser, Li, {Maddrell-Mander},
  Sanders, Helal, Beker, Rampášek, and Beaini]{masters2022GPSOptimisedHybrid}
Masters, D., Dean, J., Klaser, K., Li, Z., {Maddrell-Mander}, S., Sanders, A.,
  Helal, H., Beker, D., Rampášek, L., and Beaini, D.
\newblock {{GPS}}++: {{An Optimised Hybrid MPNN}}/{{Transformer}} for
  {{Molecular Property Prediction}}, December 2022.

\bibitem[Mialon et~al.(2021)Mialon, Chen, Selosse, and
  Mairal]{mialon2021GraphiTEncodingGraph}
Mialon, G., Chen, D., Selosse, M., and Mairal, J.
\newblock {{GraphiT}}: {{Encoding Graph Structure}} in {{Transformers}}, June
  2021.

\bibitem[Morris et~al.(2019)Morris, Ritzert, Fey, Hamilton, Lenssen, Rattan,
  and Grohe]{morris2019WeisfeilerLemanGo}
Morris, C., Ritzert, M., Fey, M., Hamilton, W.~L., Lenssen, J.~E., Rattan, G.,
  and Grohe, M.
\newblock Weisfeiler and {{Leman Go Neural}}: {{Higher-Order Graph Neural
  Networks}}.
\newblock In \emph{Proc. {{AAAI Conf.}} {{Artif. Intell.}}}, volume~33, pp.\
  4602--4609, July 2019.
\newblock \doi{10.1609/aaai.v33i01.33014602}.

\bibitem[Morris et~al.(2020)Morris, Rattan, and Mutzel]{morris2020weisfeiler}
Morris, C., Rattan, G., and Mutzel, P.
\newblock Weisfeiler and leman go sparse: towards scalable higher-order graph
  embeddings.
\newblock In \emph{Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.}, pp.\
  21824--21840, 2020.

\bibitem[Oono \& Suzuki(2020)Oono and Suzuki]{oono2020graph}
Oono, K. and Suzuki, T.
\newblock Graph neural networks exponentially lose expressive power for node
  classification.
\newblock In \emph{Proc. Int. Conf. Learn. Representations}, 2020.

\bibitem[Park \& Kim(2021)Park and Kim]{park2021HowVisionTransformers}
Park, N. and Kim, S.
\newblock How {{Do Vision Transformers Work}}?
\newblock In \emph{Proc. {{Int. Conf.}} {{Learn. Representations}}}, September
  2021.

\bibitem[Park et~al.(2022)Park, Chang, Lee, Kim, and
  Hwang]{park2022GRPERelativePositional}
Park, W., Chang, W., Lee, D., Kim, J., and Hwang, S.-w.
\newblock {{GRPE}}: {{Relative Positional Encoding}} for {{Graph Transformer}}.
\newblock In \emph{Proc. {{Int. Conf.}} {{Learn. Representations}} Workshop
  Mach. Learn. Drug Discov.}, 2022.

\bibitem[Perez et~al.(2018)Perez, Strub, De~Vries, Dumoulin, and
  Courville]{perez2018film}
Perez, E., Strub, F., De~Vries, H., Dumoulin, V., and Courville, A.
\newblock Film: Visual reasoning with a general conditioning layer.
\newblock In \emph{Proc. AAAI Conf. Artif. Intell.}, volume~32, 2018.

\bibitem[Rampášek et~al.(2022)Rampášek, Galkin, Dwivedi, Luu, Wolf, and
  Beaini]{rampasek2022RecipeGeneralPowerful}
Rampášek, L., Galkin, M., Dwivedi, V.~P., Luu, A.~T., Wolf, G., and Beaini,
  D.
\newblock Recipe for a {{General}}, {{Powerful}}, {{Scalable Graph
  Transformer}}.
\newblock In \emph{Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.}, May 2022.

\bibitem[Srinivasan \& Ribeiro(2020)Srinivasan and
  Ribeiro]{srinivasan2019EquivalencePositionalNode}
Srinivasan, B. and Ribeiro, B.
\newblock On the {{Equivalence}} between {{Positional Node Embeddings}} and
  {{Structural Graph Representations}}.
\newblock In \emph{Proc. Int. {{Conf.}} {{Learn. Representations}}}, 2020.

\bibitem[Toenshoff et~al.(2021)Toenshoff, Ritzert, Wolf, and
  Grohe]{toenshoff2021graph}
Toenshoff, J., Ritzert, M., Wolf, H., and Grohe, M.
\newblock Graph learning with 1d convolutions on random walks.
\newblock \emph{arXiv preprint arXiv:2102.08786}, 2021.

\bibitem[Topping et~al.(2022)Topping, Giovanni, Chamberlain, Dong, and
  Bronstein]{topping2022UnderstandingOversquashingBottlenecks}
Topping, J., Giovanni, F.~D., Chamberlain, B.~P., Dong, X., and Bronstein,
  M.~M.
\newblock Understanding over-squashing and bottlenecks on graphs via curvature.
\newblock In \emph{Proc. {{Int}}. {{Conf}}. {{Learn}}. {{Representations}}},
  March 2022.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, {Aidan
  N Gomez}, Kaiser, and Polosukhin]{vaswani2017AttentionAllYou}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., {Aidan N
  Gomez}, Kaiser, L., and Polosukhin, I.
\newblock Attention is {{All}} you {{Need}}.
\newblock In \emph{Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.}, volume~30.
  {Curran Associates, Inc.}, 2017.

\bibitem[Veličković et~al.(2018)Veličković, Cucurull, Casanova, Romero,
  Liò, and Bengio]{velickovic2018GraphAttentionNetworks}
Veličković, P., Cucurull, G., Casanova, A., Romero, A., Liò, P., and Bengio,
  Y.
\newblock Graph {{Attention Networks}}.
\newblock In \emph{Proc. {{Int}}. {{Conf}}. {{Learn}}. {{Representations}}},
  February 2018.

\bibitem[Wang et~al.(2022)Wang, Yin, Zhang, and
  Li]{wang2022EquivariantStablePositional}
Wang, H., Yin, H., Zhang, M., and Li, P.
\newblock Equivariant and {{Stable Positional Encoding}} for {{More Powerful
  Graph Neural Networks}}.
\newblock In \emph{Proc. {{Int}}. {{Conf}}. {{Learn}}. {{Representations}}},
  May 2022.

\bibitem[Xu et~al.(2019)Xu, Hu, Leskovec, and Jegelka]{xu2019HowPowerfulAre}
Xu, K., Hu, W., Leskovec, J., and Jegelka, S.
\newblock How {{Powerful}} are {{Graph Neural Networks}}?
\newblock In \emph{Proc. {{Int}}. {{Conf}}. {{Learn}}. {{Representations}}},
  February 2019.

\bibitem[Ying et~al.(2021)Ying, Cai, Luo, Zheng, Ke, He, Shen, and
  Liu]{ying2021TransformersReallyPerform}
Ying, C., Cai, T., Luo, S., Zheng, S., Ke, G., He, D., Shen, Y., and Liu, T.-Y.
\newblock Do {{Transformers Really Perform Badly}} for {{Graph
  Representation}}?
\newblock In \emph{Adv. {{Neural Inf}}. {{Process}}. {{Syst}}.}, 2021.

\bibitem[You et~al.(2019)You, Ying, and
  Leskovec]{you2019PositionawareGraphNeural}
You, J., Ying, R., and Leskovec, J.
\newblock Position-aware {{Graph Neural Networks}}.
\newblock In \emph{Proc. {{Int. Conf.}} {{Mach. Learn.}}}, pp.\  7134--7143.
  {PMLR}, May 2019.

\bibitem[You et~al.(2021)You, {Gomes-Selman}, Ying, and
  Leskovec]{you2021IdentityawareGraphNeural}
You, J., {Gomes-Selman}, J., Ying, R., and Leskovec, J.
\newblock Identity-aware {{Graph Neural Networks}}.
\newblock In \emph{Proc. {{AAAI Conf.}} {{Artif. Intell.}}}, February 2021.

\bibitem[Zhang et~al.(2023)Zhang, Luo, Wang, and He]{zhang2023rethinking}
Zhang, B., Luo, S., Wang, L., and He, D.
\newblock Rethinking the expressive power of {GNN}s via graph biconnectivity.
\newblock In \emph{Proc. Int. Conf. Learn. Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=r9hNv76KoT3}.

\bibitem[Zhang et~al.(2021)Zhang, Cui, Pei, Wang, and
  Zhu]{zhang2021EigenGNNGraphStructure}
Zhang, Z., Cui, P., Pei, J., Wang, X., and Zhu, W.
\newblock Eigen-{{GNN}}: A {{Graph Structure Preserving Plug-in}} for {{GNNs}}.
\newblock \emph{IEEE Trans. Knowl. Data Eng.}, pp.\  1--1, 2021.
\newblock ISSN 1558-2191.
\newblock \doi{10.1109/TKDE.2021.3112746}.

\bibitem[Zhao et~al.(2021{\natexlab{a}})Zhao, Dong, Ding, Kharlamov, and
  Tang]{zhao2021AdaptiveDiffusionGraph}
Zhao, J., Dong, Y., Ding, M., Kharlamov, E., and Tang, J.
\newblock Adaptive {{Diffusion}} in {{Graph Neural Networks}}.
\newblock In \emph{Adv. {{Neural Inf. Process. Syst.}}}, volume~34, pp.\
  23321--23333. {Curran Associates, Inc.}, 2021{\natexlab{a}}.

\bibitem[Zhao et~al.(2021{\natexlab{b}})Zhao, Jin, Akoglu, and
  Shah]{zhao2021stars}
Zhao, L., Jin, W., Akoglu, L., and Shah, N.
\newblock From stars to subgraphs: Uplifting any gnn with local structure
  awareness.
\newblock In \emph{Proc. Int. Conf. Learn. Representations},
  2021{\natexlab{b}}.

\end{thebibliography}
