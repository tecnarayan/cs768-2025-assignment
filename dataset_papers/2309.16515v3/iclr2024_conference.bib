
@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{demystifying_inductive_biases,
  title={Demystifying Inductive Biases for $\beta$-VAE Based Architectures},
  author={Dominik Zietlow and Michal Rolinek and Georg Martius},
  journal={ArXiv},
  year={2021},
  volume={abs/2102.06822},
  url={https://api.semanticscholar.org/CorpusID:231924564}
}

@article{VAE_pursues_pca,
  author={Rolínek, Michal and Zietlow, Dominik and Martius, Georg},
  journal={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Variational Autoencoders Pursue PCA Directions (by Accident)}, 
  year={2019},
  volume={},
  number={},
  pages={12398-12407},
  doi={10.1109/CVPR.2019.01269}}

@article{linear_ae_pca,
  title={From principal subspaces to principal components with linear autoencoders},
  author={Plaut, Elad},
  journal={arXiv preprint arXiv:1804.10253},
  year={2018}
}

@article{joseph2022,
  title={Predictive coding, variational autoencoders, and biological connections},
  author={Marino, Joseph},
  journal={Neural Computation},
  volume={34},
  number={1},
  pages={1--44},
  year={2022},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{mazzaglia2022,
	doi = {10.3390/e24020301},
	url = {https://doi.org/10.3390%2Fe24020301},
	year = {2022},
	month = {feb},
	publisher = {{MDPI} {AG}},
	volume = {24},
	number = {2},
	pages = {301},
	author = {Pietro Mazzaglia and Tim Verbelen and Ozan {\c{C}}atal and Bart Dhoedt},
	title = {The Free Energy Principle for Perception and Action: A Deep Learning Perspective},
	journal = {Entropy}
}


@article{liu2015,
	title = {Deep {Learning} {Face} {Attributes} in the {Wild}},
	journal = {Proceedings of {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
	month = dec,
	year = {2015},
}


@article{friston2010,
	title = {The free-energy principle: a unified brain theory?},
	volume = {11},
	copyright = {2010 Springer Nature Limited},
	issn = {1471-0048},
	shorttitle = {The free-energy principle},
	url = {https://www.nature.com/articles/nrn2787},
	doi = {10.1038/nrn2787},
	abstract = {Adaptive agents must occupy a limited repertoire of states and therefore minimize the long-term average of surprise associated with sensory exchanges with the world. Minimizing surprise enables them to resist a natural tendency to disorder.Surprise rests on predictions about sensations, which depend on an internal generative model of the world. Although surprise cannot be measured directly, a free-energy bound on surprise can be, suggesting that agents minimize free energy by changing their predictions (perception) or by changing the predicted sensory inputs (action).Perception optimizes predictions by minimizing free energy with respect to synaptic activity (perceptual inference), efficacy (learning and memory) and gain (attention and salience). This furnishes Bayes-optimal (probabilistic) representations of what caused sensations (providing a link to the Bayesian brain hypothesis).Bayes-optimal perception is mathematically equivalent to predictive coding and maximizing the mutual information between sensations and the representations of their causes. This is a probabilistic generalization of the principle of efficient coding (the infomax principle) or the minimum-redundancy principle.Learning under the free-energy principle can be formulated in terms of optimizing the connection strengths in hierarchical models of the sensorium. This rests on associative plasticity to encode causal regularities and appeals to the same synaptic mechanisms as those underlying cell assembly formation.Action under the free-energy principle reduces to suppressing sensory prediction errors that depend on predicted (expected or desired) movement trajectories. This provides a simple account of motor control, in which action is enslaved by perceptual (proprioceptive) predictions.Perceptual predictions rest on prior expectations about the trajectory or movement through the agent's state space. These priors can be acquired (as empirical priors during hierarchical inference) or they can be innate (epigenetic) and therefore subject to selective pressure.Predicted motion or state transitions realized by action correspond to policies in optimal control theory and reinforcement learning. In this context, value is inversely proportional to surprise (and implicitly free energy), and rewards correspond to innate priors that constrain policies.},
	language = {en},
	number = {2},
	urldate = {2023-09-27},
	journal = {Nature Reviews Neuroscience},
	author = {Friston, Karl},
	month = feb,
	year = {2010},
	note = {Number: 2
Publisher: Nature Publishing Group},
	keywords = {Control theory, Neural encoding},
	pages = {127--138},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\WGISJNKL\\Friston - 2010 - The free-energy principle a unified brain theory.pdf:application/pdf},
}



@article{mcinnes2018,
	title = {{UMAP}: {Uniform} {Manifold} {Approximation} and {Projection} for {Dimension} {Reduction}},
	shorttitle = {{UMAP}},
	url = {http://arxiv.org/abs/1802.03426},
	abstract = {UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
	number = {arXiv:1802.03426},
	urldate = {2023-09-27},
	institution = {arXiv},
	author = {McInnes, Leland and Healy, John and Melville, James},
	year = {2018},
    journal = {ArXiv pre-print},
	note = {arXiv:1802.03426 [cs, stat]
type: article},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computational Geometry},
	annote = {Comment: Reference implementation available at http://github.com/lmcinnes/umap},
	file = {arXiv Fulltext PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\V7ZDUU5K\\McInnes et al. - 2020 - UMAP Uniform Manifold Approximation and Projectio.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\MXAD3KDD\\1802.html:text/html},
}


@article{kramer1991,
	title = {Nonlinear principal component analysis using autoassociative neural networks},
	volume = {37},
	copyright = {Copyright © 1991 American Institute of Chemical Engineers},
	issn = {1547-5905},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/aic.690370209},
	doi = {10.1002/aic.690370209},
	abstract = {Nonlinear principal component analysis is a novel technique for multivariate data analysis, similar to the well-known method of principal component analysis. NLPCA, like PCA, is used to identify and remove correlations among problem variables as an aid to dimensionality reduction, visualization, and exploratory data analysis. While PCA identifies only linear correlations between variables, NLPCA uncovers both linear and nonlinear correlations, without restriction on the character of the nonlinearities present in the data. NLPCA operates by training a feedforward neural network to perform the identity mapping, where the network inputs are reproduced at the output layer. The network contains an internal “bottleneck” layer (containing fewer nodes than input or output layers), which forces the network to develop a compact representation of the input data, and two additional hidden layers. The NLPCA method is demonstrated using time-dependent, simulated batch reaction data. Results show that NLPCA successfully reduces dimensionality and produces a feature space map resembling the actual distribution of the underlying system parameters.},
	language = {en},
	number = {2},
	urldate = {2023-09-28},
	journal = {AIChE Journal},
	author = {Kramer, Mark A.},
	year = {1991},
	pages = {233--243},
	file = {Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\6KIX6XU4\\aic.html:text/html},
}


@article{wang2022freesolo,
      title={FreeSOLO: Learning to Segment Objects without Annotations}, 
      author={Xinlong Wang and Zhiding Yu and Shalini De Mello and Jan Kautz and Anima Anandkumar and Chunhua Shen and Jose M. Alvarez},
      year={2022},
      eprint={2202.12181},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@article{bear2023,
	title = {Unifying ({Machine}) {Vision} via {Counterfactual} {World} {Modeling}},
	url = {http://arxiv.org/abs/2306.01828},
	abstract = {Leading approaches in machine vision employ different architectures for different tasks, trained on costly task-specific labeled datasets. This complexity has held back progress in areas, such as robotics, where robust task-general perception remains a bottleneck. In contrast, "foundation models" of natural language have shown how large pre-trained neural networks can provide zero-shot solutions to a broad spectrum of apparently distinct tasks. Here we introduce Counterfactual World Modeling (CWM), a framework for constructing a visual foundation model: a unified, unsupervised network that can be prompted to perform a wide variety of visual computations. CWM has two key components, which resolve the core issues that have hindered application of the foundation model concept to vision. The first is structured masking, a generalization of masked prediction methods that encourages a prediction model to capture the low-dimensional structure in visual data. The model thereby factors the key physical components of a scene and exposes an interface to them via small sets of visual tokens. This in turn enables CWM's second main idea -- counterfactual prompting -- the observation that many apparently distinct visual representations can be computed, in a zero-shot manner, by comparing the prediction model's output on real inputs versus slightly modified ("counterfactual") inputs. We show that CWM generates high-quality readouts on real-world images and videos for a diversity of tasks, including estimation of keypoints, optical flow, occlusions, object segments, and relative depth. Taken together, our results show that CWM is a promising path to unifying the manifold strands of machine vision in a conceptually simple foundation.},
	number = {arXiv:2306.01828},
	urldate = {2023-09-26},
	institution = {arXiv},
    journal = {ArXiv pre-print},
	author = {Bear, Daniel M. and Feigelis, Kevin and Chen, Honglin and Lee, Wanhee and Venkatesh, Rahul and Kotar, Klemen and Durango, Alex and Yamins, Daniel L. K.},
	month = jun,
	year = {2023},
	note = {arXiv:2306.01828 [cs]
type: article},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, I.2.10, I.4.8},
	file = {arXiv Fulltext PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\R7F7IHAB\\Bear et al. - 2023 - Unifying (Machine) Vision via Counterfactual World.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\43KGUGGZ\\2306.html:text/html},
}

@article{destexhe2012,
	series = {Springer {Series} in {Computational} {Neuroscience}},
	title = {Neuronal {Noise}},
	isbn = {978-0-387-79020-6},
	url = {https://books.google.ch/books?id=ZZJcWvg2HUgC},
    journal = {Springer US},
	publisher = {Springer US},
	author = {Destexhe, A. and Rudolph-Lilith, M.},
	year = {2012},
	lccn = {2011944121},
}

@article{miller2002,
	title = {Neural {Noise} {Can} {Explain} {Expansive}, {Power}-{Law} {Nonlinearities} in {Neural} {Response} {Functions}},
	volume = {87},
	issn = {0022-3077},
	url = {https://journals.physiology.org/doi/full/10.1152/jn.00425.2001},
	doi = {10.1152/jn.00425.2001},
	abstract = {Many phenomenological models of the responses of simple cells in primary visual cortex have concluded that a cell's firing rate should be given by its input raised to a power greater than one. This is known as an expansive power-law nonlinearity. However, intracellular recordings have shown that a different nonlinearity, a linear-threshold function, appears to give a good prediction of firing rate from a cell's low-pass-filtered voltage response. Using a model based on a linear-threshold function, Anderson et al. showed that voltage noise was critical to converting voltage responses with contrast-invariant orientation tuning into spiking responses with contrast-invariant tuning. We present two separate results clarifying the connection between noise-smoothed linear-threshold functions and power-law nonlinearities. First, we prove analytically that a power-law nonlinearity is the only input-output function that converts contrast-invariant input tuning into contrast-invariant spike tuning. Second, we examine simulations of a simple model that assumes instantaneous spike rate is given by a linear-threshold function of voltage and voltage responses include significant noise. We show that the resulting average spike rate is well described by an expansive power law of the average voltage (averaged over multiple trials), provided that average voltage remains less than about 1.5 SDs of the noise above threshold. Finally, we use this model to show that the noise levels recorded by Anderson et al. are consistent with the degree to which the orientation tuning of spiking responses is more sharply tuned relative to the orientation tuning of voltage responses. Thus neuronal noise can robustly generate power-law input-output functions of the form frequently postulated for simple cells.},
	number = {2},
	urldate = {2023-09-26},
	journal = {Journal of Neurophysiology},
	author = {Miller, Kenneth D. and Troyer, Todd W.},
	month = feb,
	year = {2002},
	note = {Publisher: American Physiological Society},
	pages = {653--659},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\LWGUTYWG\\Miller and Troyer - 2002 - Neural Noise Can Explain Expansive, Power-Law Nonl.pdf:application/pdf},
}

@article{stein2005,
	title = {Neuronal variability: noise or part of the signal?},
	volume = {6},
	copyright = {2005 Springer Nature Limited},
	issn = {1471-0048},
	shorttitle = {Neuronal variability},
	url = {https://www.nature.com/articles/nrn1668},
	doi = {10.1038/nrn1668},
	abstract = {Traditionally, the rate of nerve impulses (spikes) over time was considered to be the main carrier of information in the nervous system. Therefore, any variability in the rate of response to a steady stimulus would reduce the information conveyed by a nerve cell. Many nerve cells fire with considerable variability, which would limit their ability to carry information to 2 or 3 bits in 1 s.With time-varying inputs containing the range of frequencies that the neuron responds to, values of information transmission of approximately 1 bit per spike have been calculated. For a neuron that fires tens or hundreds of spikes per second, much higher bit rates are possible than with steady inputs.Variability might also offer distinct advantages in preventing the entrainment of neurons to high-frequency signals. Enhanced sensitivity to weak signals has been proposed, which is known as 'stochastic resonance', as well as a role of variability in the method of Bayesian inference. Recent work on various sensory systems has emphasized the importance of timing, particularly that of first spikes, rather than the rate of firing over time.Rate coding might be more important in the motor system than precise timing. The variability in rate fluctuates with the mean rate (signal-dependent noise). The variability in the motor output in the presence of this noise can be minimized using optimal control theory.Optimal control theory predicts the form of many movements if a specific rule is assumed that relates the standard deviation in rate to the mean rate. This rule is not observed experimentally for either motor neurons or the motor cortex. However, the relationship between the standard deviation in muscle force and the mean force obeys the rule.The reason for the difference between the neural responses and the force output arises from the Henneman size principle. This states that the first recruited motor units are small and, hence, produce minor variations in force. Later motor units are larger and produce greater variations with the magnitude required by the optimal control theory.In the central nervous system, large excitatory postsynaptic potentials (EPSPs) can cause the near synchronous firing of groups of cells that might be important in attention, as well as learning and memory. Interactions in some areas, such as the hippocampus, between ongoing oscillations and spike activity might be used by 'place neurons' to locate the position of the body in external space. Therefore, variability in the firing rate of individual neurons is not simply noise, but might have a range of functions in neurons throughout the nervous system.},
	language = {en},
	number = {5},
	urldate = {2023-09-26},
	journal = {Nature Reviews Neuroscience},
	author = {Stein, Richard B. and Gossen, E. Roderich and Jones, Kelvin E.},
	month = may,
	year = {2005},
	note = {Number: 5
Publisher: Nature Publishing Group},
	keywords = {Animal Genetics and Genomics, Behavioral Sciences, Biological Techniques, Biomedicine, general, Neurobiology, Neurosciences},
	pages = {389--397},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\ESZVVFLS\\Stein et al. - 2005 - Neuronal variability noise or part of the signal.pdf:application/pdf},
}

@article{guo2018,
	title = {Functional importance of noise in neuronal information processing},
	volume = {124},
	issn = {0295-5075},
	url = {https://dx.doi.org/10.1209/0295-5075/124/50001},
	doi = {10.1209/0295-5075/124/50001},
	abstract = {Noise is an inherent part of neuronal dynamics, and thus of the brain. It can be observed in neuronal activity at different spatiotemporal scales, including in neuronal membrane potentials, local field potentials, electroencephalography, and magnetoencephalography. A central research topic in contemporary neuroscience is to elucidate the functional role of noise in neuronal information processing. Experimental studies have shown that a suitable level of noise may enhance the detection of weak neuronal signals by means of stochastic resonance. In response, theoretical research, based on the theory of stochastic processes, nonlinear dynamics, and statistical physics, has made great strides in elucidating the mechanism and the many benefits of stochastic resonance in neuronal systems. In this perspective, we review recent research dedicated to neuronal stochastic resonance in biophysical mathematical models. We also explore the regulation of neuronal stochastic resonance, and we outline important open questions and directions for future research. A deeper understanding of neuronal stochastic resonance may afford us new insights into the highly impressive information processing in the brain.},
	language = {en},
	number = {5},
	urldate = {2023-09-26},
	journal = {Europhysics Letters},
	author = {Guo, Daqing and Perc, Matjaž and Liu, Tiejun and Yao, Dezhong},
	month = dec,
	year = {2018},
	note = {Publisher: EDP Sciences, IOP Publishing and Società Italiana di Fisica},
	pages = {50001},
	file = {IOP Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\2XT26GQM\\Guo et al. - 2018 - Functional importance of noise in neuronal informa.pdf:application/pdf},
}

@article{benzi1981,
	title = {The mechanism of stochastic resonance},
	volume = {14},
	issn = {0305-4470},
	url = {https://dx.doi.org/10.1088/0305-4470/14/11/006},
	doi = {10.1088/0305-4470/14/11/006},
	abstract = {It is shown that a dynamical system subject to both periodic forcing and random perturbation may show a resonance (peak in the power spectrum) which is absent when either the forcing or the perturbation is absent.},
	language = {en},
	number = {11},
	urldate = {2023-09-26},
	journal = {Journal of Physics A: Mathematical and General},
	author = {Benzi, R. and Sutera, A. and Vulpiani, A.},
	month = nov,
	year = {1981},
	pages = {L453},
	file = {IOP Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\3FBFRQZD\\Benzi et al. - 1981 - The mechanism of stochastic resonance.pdf:application/pdf},
}

@article{kitajo2003,
	title = {Behavioral {Stochastic} {Resonance} within the {Human} {Brain}},
	volume = {90},
	url = {https://link.aps.org/doi/10.1103/PhysRevLett.90.218103},
	doi = {10.1103/PhysRevLett.90.218103},
	abstract = {We provide the first evidence that stochastic resonance within the human brain can enhance behavioral responses to weak sensory inputs. We asked subjects to adjust handgrip force to a slowly changing, subthreshold gray level signal presented to their right eye. Behavioral responses were optimized by presenting randomly changing gray levels separately to the left eye. The results indicate that observed behavioral stochastic resonance was mediated by neural activity within the human brain where the information from both eyes converges.},
	number = {21},
	urldate = {2023-09-26},
	journal = {Physical Review Letters},
	author = {Kitajo, Keiichi and Nozaki, Daichi and Ward, Lawrence M. and Yamamoto, Yoshiharu},
	month = may,
	year = {2003},
	note = {Publisher: American Physical Society},
	pages = {218103},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\EQWREY7L\\Kitajo et al. - 2003 - Behavioral Stochastic Resonance within the Human B.pdf:application/pdf;APS Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\943I778S\\PhysRevLett.90.html:text/html},
}

@article{mcdonnell2011,
	title = {The benefits of noise in neural systems: bridging theory and experiment},
	volume = {12},
	copyright = {2011 Springer Nature Limited},
	issn = {1471-0048},
	shorttitle = {The benefits of noise in neural systems},
	url = {https://www.nature.com/articles/nrn3061},
	doi = {10.1038/nrn3061},
	abstract = {Both theoretical and experimental approaches have demonstrated that noise can improve information processing, but there is substantial scope for new biologically appropriate computational hypotheses and noise sources to be investigated. McDonnell and Ward propose a unifying framework for reconciling theory with experiment.},
	language = {en},
	number = {7},
	urldate = {2023-09-26},
	journal = {Nature Reviews Neuroscience},
	author = {McDonnell, Mark D. and Ward, Lawrence M.},
	month = jul,
	year = {2011},
	note = {Number: 7
Publisher: Nature Publishing Group},
	keywords = {Computational neuroscience, Nonlinear dynamics, Stochastic modelling, Synaptic transmission},
	pages = {415--425},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\L2VUNAAR\\McDonnell and Ward - 2011 - The benefits of noise in neural systems bridging .pdf:application/pdf},
}

@article{buchin2016,
	title = {Inverse {Stochastic} {Resonance} in {Cerebellar} {Purkinje} {Cells}},
	volume = {12},
	issn = {1553-734X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4991839/},
	doi = {10.1371/journal.pcbi.1005000},
	number = {8},
	urldate = {2023-09-26},
	journal = {PLoS Computational Biology},
	author = {Buchin, Anatoly and Rieubland, Sarah and Häusser, Michael and Gutkin, Boris S. and Roth, Arnd},
	month = aug,
	year = {2016},
	pmid = {27541958},
	pmcid = {PMC4991839},
	pages = {e1005000},
	file = {PubMed Central Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\85K4LY95\\Buchin et al. - 2016 - Inverse Stochastic Resonance in Cerebellar Purkinj.pdf:application/pdf},
}

@article{boutin2020,
	title = {Iterative {VAE} as a predictive brain model for out-of-distribution generalization},
	url = {http://arxiv.org/abs/2012.00557},
	abstract = {Our ability to generalize beyond training data to novel, out-of-distribution, image degradations is a hallmark of primate vision. The predictive brain, exemplified by predictive coding networks (PCNs), has become a prominent neuroscience theory of neural computation. Motivated by the recent successes of variational autoencoders (VAEs) in machine learning, we rigorously derive a correspondence between PCNs and VAEs. This motivates us to consider iterative extensions of VAEs (iVAEs) as plausible variational extensions of the PCNs. We further demonstrate that iVAEs generalize to distributional shifts significantly better than both PCNs and VAEs. In addition, we propose a novel measure of recognizability for individual samples which can be tested against human psychophysical data. Overall, we hope this work will spur interest in iVAEs as a promising new direction for modeling in neuroscience.},
	number = {arXiv:2012.00557},
	urldate = {2023-09-25},
	institution = {arXiv},
    journal = {ArXiv pre-print},
	author = {Boutin, Victor and Zerroug, Aimen and Jung, Minju and Serre, Thomas},
	month = dec,
	year = {2020},
	note = {arXiv:2012.00557 [cs]
type: article},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\MFAV76H3\\Boutin et al. - 2020 - Iterative VAE as a predictive brain model for out-.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\CPTQHNKE\\2012.html:text/html},
}

@article{kingma2013,
	title = {Auto-{Encoding} {Variational} {Bayes}},
	url = {http://arxiv.org/abs/1312.6114},
	abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
	urldate = {2023-09-19},
	institution = {arXiv},
	author = {Kingma, Diederik P. and Welling, Max},
	month = dec,
	year = {2014},
    journal = {International Conference on Learning Representations},
	note = {arXiv:1312.6114 [cs, stat]
type: article},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Fixes a typo in the abstract, no other changes},
	file = {arXiv Fulltext PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\QPC2783L\\Kingma and Welling - 2022 - Auto-Encoding Variational Bayes.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\BN3M4LFJ\\1312.html:text/html},
}

@article{engelcke2022,
	title = {{GENESIS}-{V2}: {Inferring} {Unordered} {Object} {Representations} without {Iterative} {Refinement}},
	shorttitle = {{GENESIS}-{V2}},
	url = {http://arxiv.org/abs/2104.09958},
	abstract = {Advances in unsupervised learning of object-representations have culminated in the development of a broad range of methods for unsupervised object segmentation and interpretable object-centric scene generation. These methods, however, are limited to simulated and real-world datasets with limited visual complexity. Moreover, object representations are often inferred using RNNs which do not scale well to large images or iterative refinement which avoids imposing an unnatural ordering on objects in an image but requires the a priori initialisation of a fixed number of object representations. In contrast to established paradigms, this work proposes an embedding-based approach in which embeddings of pixels are clustered in a differentiable fashion using a stochastic stick-breaking process. Similar to iterative refinement, this clustering procedure also leads to randomly ordered object representations, but without the need of initialising a fixed number of clusters a priori. This is used to develop a new model, GENESIS-v2, which can infer a variable number of object representations without using RNNs or iterative refinement. We show that GENESIS-v2 performs strongly in comparison to recent baselines in terms of unsupervised image segmentation and object-centric scene generation on established synthetic datasets as well as more complex real-world datasets.},
	number = {arXiv:2104.09958},
	urldate = {2023-09-20},
    journal = {ArXiv pre-print},
	institution = {arXiv},
	author = {Engelcke, Martin and Jones, Oiwi Parker and Posner, Ingmar},
	month = jan,
	year = {2022},
	note = {arXiv:2104.09958 [cs, stat]
type: article},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: NeurIPS 2021 camera-ready version; 26 pages, 19 figures},
	file = {arXiv Fulltext PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\RXY75XDA\\Engelcke et al. - 2022 - GENESIS-V2 Inferring Unordered Object Representat.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\6YWQAHTS\\2104.html:text/html},
}

@inproceedings{engelcke2020genesis,
  title={{GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations}},
  author={Engelcke, Martin and Kosiorek, Adam R and Parker Jones, Oiwi and Posner, Ingmar},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}
@article{engelcke2020reconstruction,
  title={{Reconstruction Bottlenecks in Object-Centric Generative Models}},
  author={Engelcke, Martin and Parker Jones, Oiwi and Posner, Ingmar},
  journal={ICML Workshop on Object-Oriented Learning},
  year={2020}
}

@article{hamilton2022,
	title = {Unsupervised {Semantic} {Segmentation} by {Distilling} {Feature} {Correspondences}},
	url = {http://arxiv.org/abs/2203.08414},
	abstract = {Unsupervised semantic segmentation aims to discover and localize semantically meaningful categories within image corpora without any form of annotation. To solve this task, algorithms must produce features for every pixel that are both semantically meaningful and compact enough to form distinct clusters. Unlike previous works which achieve this with a single end-to-end framework, we propose to separate feature learning from cluster compactification. Empirically, we show that current unsupervised feature learning frameworks already generate dense features whose correlations are semantically consistent. This observation motivates us to design STEGO (\${\textbackslash}textbf\{S\}\$elf-supervised \${\textbackslash}textbf\{T\}\$ransformer with \${\textbackslash}textbf\{E\}\$nergy-based \${\textbackslash}textbf\{G\}\$raph \${\textbackslash}textbf\{O\}\$ptimization), a novel framework that distills unsupervised features into high-quality discrete semantic labels. At the core of STEGO is a novel contrastive loss function that encourages features to form compact clusters while preserving their relationships across the corpora. STEGO yields a significant improvement over the prior state of the art, on both the CocoStuff (\${\textbackslash}textbf\{+14 mIoU\}\$) and Cityscapes (\${\textbackslash}textbf\{+9 mIoU\}\$) semantic segmentation challenges.},
	number = {arXiv:2203.08414},
	urldate = {2023-09-20},
	institution = {arXiv},
    journal = {ArXiv pre-print},
	author = {Hamilton, Mark and Zhang, Zhoutong and Hariharan, Bharath and Snavely, Noah and Freeman, William T.},
	month = mar,
	year = {2022},
	note = {arXiv:2203.08414 [cs, stat]
type: article},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\2QZD8ZNC\\Hamilton et al. - 2022 - Unsupervised Semantic Segmentation by Distilling F.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\TTCEQLVH\\2203.html:text/html},
}

@article{stanic2023,
	title = {Contrastive {Training} of {Complex}-{Valued} {Autoencoders} for {Object} {Discovery}},
	url = {http://arxiv.org/abs/2305.15001},
	abstract = {Current state-of-the-art object-centric models use slots and attention-based routing for binding. However, this class of models has several conceptual limitations: the number of slots is hardwired; all slots have equal capacity; training has high computational cost; there are no object-level relational factors within slots. Synchrony-based models in principle can address these limitations by using complex-valued activations which store binding information in their phase components. However, working examples of such synchrony-based models have been developed only very recently, and are still limited to toy grayscale datasets and simultaneous storage of less than three objects in practice. Here we introduce architectural modifications and a novel contrastive learning method that greatly improve the state-of-the-art synchrony-based model. For the first time, we obtain a class of synchrony-based models capable of discovering objects in an unsupervised manner in multi-object color datasets and simultaneously representing more than three objects},
	number = {arXiv:2305.15001},
	urldate = {2023-09-20},
	institution = {arXiv},
    journal = {ArXiv pre-print},
	author = {Stanić, Aleksandar and Gopalakrishnan, Anand and Irie, Kazuki and Schmidhuber, Jürgen},
	month = may,
	year = {2023},
	note = {arXiv:2305.15001 [cs]
type: article},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	annote = {Comment: 26 pages, 14 figures},
	file = {arXiv Fulltext PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\PMXK8KSC\\Stanić et al. - 2023 - Contrastive Training of Complex-Valued Autoencoder.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\S97KW3BU\\2305.html:text/html},
}

@article{jakel2016,
	series = {Quantitative {Approaches} in {Gestalt} {Perception}},
	title = {An overview of quantitative approaches in {Gestalt} perception},
	volume = {126},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698916300475},
	doi = {10.1016/j.visres.2016.06.004},
	abstract = {Gestalt psychology is often criticized as lacking quantitative measurements and precise mathematical models. While this is true of the early Gestalt school, today there are many quantitative approaches in Gestalt perception and the special issue of Vision Research “Quantitative Approaches in Gestalt Perception” showcases the current state-of-the-art. In this article we give an overview of these current approaches. For example, ideal observer models are one of the standard quantitative tools in vision research and there is a clear trend to try and apply this tool to Gestalt perception and thereby integrate Gestalt perception into mainstream vision research. More generally, Bayesian models, long popular in other areas of vision research, are increasingly being employed to model perceptual grouping as well. Thus, although experimental and theoretical approaches to Gestalt perception remain quite diverse, we are hopeful that these quantitative trends will pave the way for a unified theory.},
	urldate = {2023-09-21},
	journal = {Vision Research},
	author = {Jäkel, Frank and Singh, Manish and Wichmann, Felix A. and Herzog, Michael H.},
	month = sep,
	year = {2016},
	keywords = {Bayesian models, Gestalt, Grouping, Ideal observer, Perception, Perceptual organization, Prägnanz},
	pages = {3--8},
	file = {ScienceDirect Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\5BBU6RV9\\S0042698916300475.html:text/html},
}

@article{wagemans2012a,
	title = {A century of {Gestalt} psychology in visual perception: {I}. {Perceptual} grouping and figure–ground organization},
	volume = {138},
	issn = {1939-1455},
	shorttitle = {A century of {Gestalt} psychology in visual perception},
	doi = {10.1037/a0029333},
	abstract = {In 1912, Max Wertheimer published his paper on phi motion, widely recognized as the start of Gestalt psychology. Because of its continued relevance in modern psychology, this centennial anniversary is an excellent opportunity to take stock of what Gestalt psychology has offered and how it has changed since its inception. We first introduce the key findings and ideas in the Berlin school of Gestalt psychology, and then briefly sketch its development, rise, and fall. Next, we discuss its empirical and conceptual problems, and indicate how they are addressed in contemporary research on perceptual grouping and figure–ground organization. In particular, we review the principles of grouping, both classical (e.g., proximity, similarity, common fate, good continuation, closure, symmetry, parallelism) and new (e.g., synchrony, common region, element and uniform connectedness), and their role in contour integration and completion. We then review classic and new image-based principles of figure–ground organization, how it is influenced by past experience and attention, and how it relates to shape and depth perception. After an integrated review of the neural mechanisms involved in contour grouping, border ownership, and figure–ground perception, we conclude by evaluating what modern vision science has offered compared to traditional Gestalt psychology, whether we can speak of a Gestalt revival, and where the remaining limitations and challenges lie. A better integration of this research tradition with the rest of vision science requires further progress regarding the conceptual and theoretical foundations of the Gestalt approach, which is the focus of a second review article. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {6},
	journal = {Psychological Bulletin},
	author = {Wagemans, Johan and Elder, James H. and Kubovy, Michael and Palmer, Stephen E. and Peterson, Mary A. and Singh, Manish and von der Heydt, Rüdiger},
	year = {2012},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Figure Ground Discrimination, Form and Shape Perception, Gestalt Psychology, Visual Perception},
	pages = {1172--1217},
	file = {Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\ZMGIPNLK\\2012-20167-001.html:text/html;Full Text:C\:\\Users\\loennqvi\\Zotero\\storage\\J5TE52KJ\\Wagemans et al. - 2012 - A century of Gestalt psychology in visual percepti.pdf:application/pdf},
}

@article{wagemans2012b,
	title = {A century of {Gestalt} psychology in visual perception: {II}. {Conceptual} and theoretical foundations},
	volume = {138},
	issn = {1939-1455},
	shorttitle = {A century of {Gestalt} psychology in visual perception},
	doi = {10.1037/a0029334},
	abstract = {Our first review article (Wagemans et al., 2012) on the occasion of the centennial anniversary of Gestalt psychology focused on perceptual grouping and figure–ground organization. It concluded that further progress requires a reconsideration of the conceptual and theoretical foundations of the Gestalt approach, which is provided here. In particular, we review contemporary formulations of holism within an information-processing framework, allowing for operational definitions (e.g., integral dimensions, emergent features, configural superiority, global precedence, primacy of holistic/configural properties) and a refined understanding of its psychological implications (e.g., at the level of attention, perception, and decision). We also review 4 lines of theoretical progress regarding the law of Prägnanz—the brain's tendency of being attracted towards states corresponding to the simplest possible organization, given the available stimulation. The first considers the brain as a complex adaptive system and explains how self-organization solves the conundrum of trading between robustness and flexibility of perceptual states. The second specifies the economy principle in terms of optimization of neural resources, showing that elementary sensors working independently to minimize uncertainty can respond optimally at the system level. The third considers how Gestalt percepts (e.g., groups, objects) are optimal given the available stimulation, with optimality specified in Bayesian terms. Fourth, structural information theory explains how a Gestaltist visual system that focuses on internal coding efficiency yields external veridicality as a side effect. To answer the fundamental question of why things look as they do, a further synthesis of these complementary perspectives is required. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {6},
	journal = {Psychological Bulletin},
	author = {Wagemans, Johan and Feldman, Jacob and Gepshtein, Sergei and Kimchi, Ruth and Pomerantz, James R. and van der Helm, Peter A. and van Leeuwen, Cees},
	year = {2012},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Gestalt Psychology, History of Psychology, Information Theory, Visual Perception},
	pages = {1218--1252},
	file = {Accepted Version:C\:\\Users\\loennqvi\\Zotero\\storage\\CRLG26BC\\Wagemans et al. - 2012 - A century of Gestalt psychology in visual percepti.pdf:application/pdf;Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\GFR2T5PT\\2012-20168-001.html:text/html},
}

@article{roelfsema2006,
	title = {Cortical {Algorithms} for {Perceptual} {Grouping}},
	volume = {29},
	url = {https://doi.org/10.1146/annurev.neuro.29.051605.112939},
	doi = {10.1146/annurev.neuro.29.051605.112939},
	abstract = {AbstractA fundamental task of vision is to group the image elements that belong to one object and to segregate them from other objects and the background. This review provides a conceptual framework of how perceptual grouping may be implemented in the visual cortex. According to this framework, two mechanisms are responsible for perceptual grouping: base-grouping and incremental grouping. Base-groupings are coded by single neurons tuned to multiple features, like the combination of a color and an orientation. They are computed rapidly because they reflect the selectivity of feedforward connections. However, not all conceivable feature combinations are coded by dedicated neurons. Therefore, a second, flexible form of grouping is required called incremental grouping. Incremental grouping enhances the responses of neurons coding features that are bound in perception, but it takes more time than does base-grouping because it relies also on horizontal and feedback connections. The modulation of neuronal response strength during incremental grouping has a correlate in psychology because attention is directed to those features that are labeled by the enhanced neuronal response.},
	number = {1},
	urldate = {2023-09-22},
	journal = {Annual Review of Neuroscience},
	author = {Roelfsema, Pieter R.},
	year = {2006},
	pmid = {16776584},
	note = {\_eprint: https://doi.org/10.1146/annurev.neuro.29.051605.112939},
	keywords = {binding, contextual modulation, contour grouping, grandmother cell, visual attention, visual cortex},
	pages = {203--227},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\A9JA8DP9\\Roelfsema - 2006 - Cortical Algorithms for Perceptual Grouping.pdf:application/pdf},
}

@article{geirhos2018,
	title = {Generalisation in humans and deep neural networks},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper_files/paper/2018/hash/0937fb5864ed06ffb59ae5f9b5ed67a9-Abstract.html},
	abstract = {We compare the robustness of humans and current convolutional deep neural networks (DNNs) on object recognition under twelve different types of image degradations. First, using three well known DNNs (ResNet-152, VGG-19, GoogLeNet) we find the human visual system to be more robust to nearly all of the tested image manipulations, and we observe progressively diverging classification error-patterns between humans and DNNs when the signal gets weaker. Secondly, we show that DNNs trained directly on distorted images consistently surpass human performance on the exact distortion types they were trained on, yet they display extremely poor generalisation abilities when tested on other distortion types. For example, training on salt-and-pepper noise does not imply robustness on uniform white noise and vice versa. Thus, changes in the noise distribution between training and testing constitutes a crucial challenge to deep learning vision systems that can be systematically addressed in a lifelong machine learning approach. Our new dataset consisting of 83K carefully measured human psychophysical trials provide a useful reference for lifelong robustness against image degradations set by the human visual system.},
	urldate = {2023-09-22},
	journal = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Geirhos, Robert and Temme, Carlos R. M. and Rauber, Jonas and Schütt, Heiko H. and Bethge, Matthias and Wichmann, Felix A.},
	year = {2018},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\GVA4DC72\\Geirhos et al. - 2018 - Generalisation in humans and deep neural networks.pdf:application/pdf},
}

@article{geirhos2019,
	title = {{ImageNet}-trained {CNNs} are biased towards texture; increasing shape bias improves accuracy and robustness.},
	url = {https://openreview.net/forum?id=Bygh9j09KX},
	journal = {International {Conference} on {Learning} {Representations}},
	author = {Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A. and Brendel, Wieland},
	year = {2019},
}

@article{manassi2012,
	title = {Grouping, pooling, and when bigger is better in visual crowding},
	volume = {12},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/12.10.13},
	doi = {10.1167/12.10.13},
	abstract = {In crowding, perception of a target is strongly deteriorated by nearby elements. Crowding is often explained by pooling models predicting that adding flankers increases crowding. In contrast, the centroid hypothesis proposes that adding flankers decreases crowding—“bigger is better.” In foveal vision, we have recently shown that adding flankers can increase or decrease crowding depending on whether the target groups or ungroups from the flankers. We have further shown how configural effects, such as good and global Gestalt, determine crowding. Foveal and peripheral crowding do not always reveal the same characteristics. Here, we show that the very same grouping and Gestalt results of foveal vision are also found in the periphery. These results can neither be explained by simple pooling nor by centroid models. We discuss when bigger is better and how grouping might shape crowding.},
	number = {10},
	urldate = {2023-09-22},
	journal = {Journal of Vision},
	author = {Manassi, Mauro and Sayim, Bilge and Herzog, Michael H.},
	month = sep,
	year = {2012},
	pages = {13},
	file = {Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\WCTSPXEJ\\article.html:text/html},
}

@article{herzog2015,
	title = {Crowding, grouping, and object recognition: {A} matter of appearance},
	volume = {15},
	issn = {1534-7362},
	shorttitle = {Crowding, grouping, and object recognition},
	url = {https://doi.org/10.1167/15.6.5},
	doi = {10.1167/15.6.5},
	abstract = {In crowding, the perception of a target strongly deteriorates when neighboring elements are presented. Crowding is usually assumed to have the following characteristics. (a) Crowding is determined only by nearby elements within a restricted region around the target (Bouma's law). (b) Increasing the number of flankers can only deteriorate performance.  (c) Target-flanker interference is feature-specific. These characteristics are usually explained by pooling models, which are well in the spirit of classic models of object recognition. In this review, we summarize recent findings showing that crowding is not determined by the above characteristics, thus, challenging most models of crowding. We propose that the spatial configuration across the entire visual field determines crowding. Only when one understands how all elements of a visual scene group with each other, can one determine crowding strength. We put forward the hypothesis that appearance (i.e., how stimuli look) is a good predictor for crowding, because both crowding and appearance reflect the output of recurrent processing rather than interactions during the initial phase of visual processing.},
	number = {6},
	urldate = {2023-09-22},
	journal = {Journal of Vision},
	author = {Herzog, Michael H. and Sayim, Bilge and Chicherov, Vitaly and Manassi, Mauro},
	month = may,
	year = {2015},
	pages = {5},
	file = {Full Text:C\:\\Users\\loennqvi\\Zotero\\storage\\KPHKTABU\\Herzog et al. - 2015 - Crowding, grouping, and object recognition A matt.pdf:application/pdf;Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\V5EKMYI6\\article.html:text/html},
}

@article{holcombe2001,
	title = {Early binding of feature pairs for visual perception},
	volume = {4},
	copyright = {2001 Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn0201_127},
	doi = {10.1038/83945},
	abstract = {If features such as color and orientation are processed separately by the brain at early stages1,2, how does the brain subsequently match the correct color and orientation? We found that spatially superposed pairings of orientation with either color or luminance could be reported even for extremely high rates of presentation, which suggests that these features are coded in combination explicitly by early stages, thus eliminating the need for any subsequent binding of information. In contrast, reporting the pairing of spatially separated features required rates an order of magnitude slower, suggesting that perceiving these pairs requires binding at a slow, attentional stage.},
	language = {en},
	number = {2},
	urldate = {2023-09-22},
	journal = {Nature Neuroscience},
	author = {Holcombe, Alex O. and Cavanagh, Patrick},
	month = feb,
	year = {2001},
	note = {Number: 2
Publisher: Nature Publishing Group},
	keywords = {Animal Genetics and Genomics, Behavioral Sciences, Biological Techniques, Biomedicine, general, Neurobiology, Neurosciences},
	pages = {127--128},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\C6UZRW2D\\Holcombe and Cavanagh - 2001 - Early binding of feature pairs for visual percepti.pdf:application/pdf},
}

@article{todorovic2008,
	title = {Gestalt principles},
	volume = {3},
	issn = {1941-6016},
	url = {http://www.scholarpedia.org/article/Gestalt_principles},
	doi = {10.4249/scholarpedia.5345},
	language = {en},
	number = {12},
	urldate = {2023-09-22},
	journal = {Scholarpedia},
	author = {Todorovic, Dejan},
	month = dec,
	year = {2008},
	pages = {5345},
	file = {Submitted Version:C\:\\Users\\loennqvi\\Zotero\\storage\\SHDX4MRB\\Todorovic - 2008 - Gestalt principles.pdf:application/pdf;Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\HTEYAT4I\\Gestalt_principles.html:text/html},
}

@article{bowers2022,
	title = {Deep {Problems} with {Neural} {Network} {Models} of {Human} {Vision}},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/deep-problems-with-neural-network-models-of-human-vision/ABCE483EE95E80315058BB262DCA26A9},
	doi = {10.1017/S0140525X22002813},
	abstract = {Deep neural networks (DNNs) have had extraordinary successes in classifying photographic images of objects and are often described as the best models of biological vision. This conclusion is largely based on three sets of findings: (1) DNNs are more accurate than any other model in classifying images taken from various datasets, (2) DNNs do the best job in predicting the pattern of human errors in classifying objects taken from various behavioral datasets, and (3) DNNs do the best job in predicting brain signals in response to images taken from various brain datasets (e.g., single cell responses or fMRI data). However, these behavioral and brain datasets do not test hypotheses regarding what features are contributing to good predictions and we show that the predictions may be mediated by DNNs that share little overlap with biological vision. More problematically, we show that DNNs account for almost no results from psychological research. This contradicts the common claim that DNNs are good, let alone the best, models of human object recognition. We argue that theorists interested in developing biologically plausible models of human vision need to direct their attention to explaining psychological findings. More generally, theorists need to build models that explain the results of experiments that manipulate independent variables designed to test hypotheses rather than compete on making the best predictions. We conclude by briefly summarizing various promising modelling approaches that focus on psychological data.},
	language = {en},
	urldate = {2023-09-22},
	journal = {Behavioral and Brain Sciences},
	author = {Bowers, Jeffrey S. and Malhotra, Gaurav and Dujmović, Marin and Montero, Milton Llera and Tsvetkov, Christian and Biscione, Valerio and Puebla, Guillermo and Adolfi, Federico and Hummel, John E. and Heaton, Rachel F. and Evans, Benjamin D. and Mitchell, Jeffrey and Blything, Ryan},
	month = dec,
	year = {2022},
	note = {Publisher: Cambridge University Press},
	keywords = {Brain-Score, Computational Neuroscience, Deep Neural Networks, Human Vision, Object recognition},
	pages = {1--74},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\8RGKPRZ3\\Bowers et al. - 2022 - Deep Problems with Neural Network Models of Human .pdf:application/pdf},
}

@article{linsley2018,
	title = {Learning long-range spatial dependencies with horizontal gated recurrent units},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/ec8956637a99787bd197eacd77acce5e-Paper.pdf},
	journal = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Linsley, Drew and Kim, Junkyung and Veerabadran, Vijay and Windolf, Charles and Serre, Thomas},
	editor = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
	year = {2018},
}

@article{doerig2020,
	title = {Crowding reveals fundamental differences in local vs. global processing in humans and machines},
	volume = {167},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698919302299},
	doi = {10.1016/j.visres.2019.12.006},
	abstract = {Feedforward Convolutional Neural Networks (ffCNNs) have become state-of-the-art models both in computer vision and neuroscience. However, human-like performance of ffCNNs does not necessarily imply human-like computations. Previous studies have suggested that current ffCNNs do not make use of global shape information. However, it is currently unclear whether this reflects fundamental differences between ffCNN and human processing or is merely an artefact of how ffCNNs are trained. Here, we use visual crowding as a well-controlled, specific probe to test global shape computations. Our results provide evidence that ffCNNs cannot produce human-like global shape computations for principled architectural reasons. We lay out approaches that may address shortcomings of ffCNNs to provide better models of the human visual system.},
	urldate = {2023-09-22},
	journal = {Vision Research},
	author = {Doerig, A. and Bornet, A. and Choung, O. H. and Herzog, M. H.},
	month = feb,
	year = {2020},
	keywords = {Convolutional Neural Networks, Crowding, Deep Neural Networks, Global processing, Grouping, Segmentation},
	pages = {39--45},
	file = {ScienceDirect Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\WYM33VTV\\S0042698919302299.html:text/html;Submitted Version:C\:\\Users\\loennqvi\\Zotero\\storage\\5GWPK3CA\\Doerig et al. - 2020 - Crowding reveals fundamental differences in local .pdf:application/pdf},
}

@article{biscione2023,
	title = {Mixed {Evidence} for {Gestalt} {Grouping} in {Deep} {Neural} {Networks}},
	volume = {6},
	issn = {2522-087X},
	url = {https://doi.org/10.1007/s42113-023-00169-2},
	doi = {10.1007/s42113-023-00169-2},
	abstract = {Gestalt psychologists have identified a range of conditions in which humans organize elements of a scene into a group or whole, and perceptual grouping principles play an essential role in scene perception and object identification. Recently, Deep Neural Networks (DNNs) trained on natural images (ImageNet) have been proposed as compelling models of human vision based on reports that they perform well on various brain and behavioural benchmarks. Here we test a total of 16 networks covering a variety of architectures and learning paradigms (convolutional, attention-based, supervised and self-supervised, feed-forward and recurrent) on dots (Experiment 1) and more complex shapes (Experiment 2) stimuli that produce strong Gestalts effects in humans. In Experiment 1 we found that convolutional networks were indeed sensitive in a human-like fashion to the principles of proximity, linearity, and orientation, but only at the output layer. In Experiment 2, we found that most networks exhibited Gestalt effects only for a few sets, and again only at the latest stage of processing. Overall, self-supervised and Vision Transformer appeared to perform worse than convolutional networks in terms of human similarity. Remarkably, no model presented a grouping effect at the early or intermediate stages of processing. This is at odds with the widespread assumption that Gestalts occur prior to object recognition, and indeed, serve to organize the visual scene for the sake of object recognition. Our overall conclusion is that, albeit noteworthy that networks trained on simple 2D images support a form of Gestalt grouping for some stimuli at the output layer, this ability does not seem to transfer to more complex features. Additionally, the fact that this grouping only occurs at the last layer suggests that networks learn fundamentally different perceptual properties than humans.},
	language = {en},
	number = {3},
	urldate = {2023-09-22},
	journal = {Computational Brain \& Behavior},
	author = {Biscione, Valerio and Bowers, Jeffrey S.},
	month = sep,
	year = {2023},
	keywords = {Deep neural networks, Emergent features, Gestalt grouping, Visual perception},
	pages = {438--456},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\3NPHAZM8\\Biscione and Bowers - 2023 - Mixed Evidence for Gestalt Grouping in Deep Neural.pdf:application/pdf},
}

@article{madry2018,
	title = {Towards {Deep} {Learning} {Models} {Resistant} to {Adversarial} {Attacks}},
	url = {https://openreview.net/forum?id=rJzIBfZAb},
	journal = {International {Conference} on {Learning} {Representations}},
	author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	year = {2018}
}

@article{moosavi-dezfooli2016,
	title = {{DeepFool}: {A} {Simple} and {Accurate} {Method} to {Fool} {Deep} {Neural} {Networks}},
	journal = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
	month = jun,
	year = {2016},
}

@article{greff2020,
	title = {On the {Binding} {Problem} in {Artificial} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2012.05208},
	abstract = {Contemporary neural networks still fall short of human-level generalization, which extends far beyond our direct experiences. In this paper, we argue that the underlying cause for this shortcoming is their inability to dynamically and flexibly bind information that is distributed throughout the network. This binding problem affects their capacity to acquire a compositional understanding of the world in terms of symbol-like entities (like objects), which is crucial for generalizing in predictable and systematic ways. To address this issue, we propose a unifying framework that revolves around forming meaningful entities from unstructured sensory inputs (segregation), maintaining this separation of information at a representational level (representation), and using these entities to construct new inferences, predictions, and behaviors (composition). Our analysis draws inspiration from a wealth of research in neuroscience and cognitive psychology, and surveys relevant mechanisms from the machine learning literature, to help identify a combination of inductive biases that allow symbolic information processing to emerge naturally in neural networks. We believe that a compositional approach to AI, in terms of grounded symbol-like representations, is of fundamental importance for realizing human-level generalization, and we hope that this paper may contribute towards that goal as a reference and inspiration.},
	number = {arXiv:2012.05208},
	urldate = {2023-09-25},
    journal = {ArXiv pre-print},
	institution = {arXiv},
	author = {Greff, Klaus and van Steenkiste, Sjoerd and Schmidhuber, Jürgen},
	month = dec,
	year = {2020},
	note = {arXiv:2012.05208 [cs]
type: article},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, I.2.6},
	file = {arXiv Fulltext PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\ZMVRKK3A\\Greff et al. - 2020 - On the Binding Problem in Artificial Neural Networ.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\PJ982A9H\\2012.html:text/html},
}

@article{hinton2023,
	title = {How to {Represent} {Part}-{Whole} {Hierarchies} in a {Neural} {Network}},
	volume = {35},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco_a_01557},
	doi = {10.1162/neco_a_01557},
	abstract = {This article does not describe a working system. Instead, it presents a single idea about representation that allows advances made by several different groups to be combined into an imaginary system called GLOM.1 The advances include transformers, neural fields, contrastive representation learning, distillation, and capsules. GLOM answers the question: How can a neural network with a fixed architecture parse an image into a part-whole hierarchy that has a different structure for each image? The idea is simply to use islands of identical vectors to represent the nodes in the parse tree. If GLOM can be made to work, it should significantly improve the interpretability of the representations produced by transformer-like systems when applied to vision or language.},
	number = {3},
	urldate = {2023-09-25},
	journal = {Neural Computation},
	author = {Hinton, Geoffrey},
	month = feb,
	year = {2023},
	pages = {413--452},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\4BHHH2W7\\Hinton - 2023 - How to Represent Part-Whole Hierarchies in a Neura.pdf:application/pdf;Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\IC8AZPP5\\How-to-Represent-Part-Whole-Hierarchies-in-a.html:text/html},
}

@article{sabour2017,
	title = {Dynamic {Routing} {Between} {Capsules}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/2cad8fa47bbef282badbb8de5374b894-Paper.pdf},
	journal = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E},
	editor = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	year = {2017},
}

@article{long2015,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	journal = {Proceedings of the {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	month = jun,
	year = {2015},
}

@article{ronneberger2015,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	isbn = {978-3-319-24574-4},
	shorttitle = {U-{Net}},
	doi = {10.1007/978-3-319-24574-4_28},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
	language = {en},
	journal = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2015},
	publisher = {Springer International Publishing},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	year = {2015},
	keywords = {Convolutional Layer, Data Augmentation, Deep Network, Ground Truth Segmentation, Training Image},
	pages = {234--241},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\QYIKC89W\\Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:application/pdf},
}

@article{kirillov2023,
	title = {Segment {Anything}},
	url = {http://arxiv.org/abs/2304.02643},
	abstract = {We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive -- often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at https://segment-anything.com to foster research into foundation models for computer vision.},
	number = {arXiv:2304.02643},
	urldate = {2023-09-25},
	institution = {arXiv},
    journal = {ArXiv pre-print},
	author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollár, Piotr and Girshick, Ross},
	month = apr,
	year = {2023},
	note = {arXiv:2304.02643 [cs]
type: article},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence},
	annote = {Comment: Project web-page: https://segment-anything.com},
	file = {arXiv Fulltext PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\IMYLHDEE\\Kirillov et al. - 2023 - Segment Anything.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\7LSK3YP8\\2304.html:text/html},
}

@article{lowe2022,
	title = {Complex-{Valued} {Autoencoders} for {Object} {Discovery}},
	issn = {2835-8856},
	url = {https://openreview.net/forum?id=1PfcmFTXoa},
	abstract = {Object-centric representations form the basis of human perception, and enable us to reason about the world and to systematically generalize to new settings. Currently, most works on unsupervised object discovery focus on slot-based approaches, which explicitly separate the latent representations of individual objects. While the result is easily interpretable, it usually requires the design of involved architectures. In contrast to this, we propose a comparatively simple approach – the Complex AutoEncoder (CAE) – that creates distributed object-centric representations. Following a coding scheme theorized to underlie object representations in biological neurons, its complex-valued activations represent two messages: their magnitudes express the presence of a feature, while the relative phase differences between neurons express which features should be bound together to create joint object representations. In contrast to previous approaches using complex-valued activations for object discovery, we present a fully unsupervised approach that is trained end-to-end – resulting in significant improvements in performance and efficiency. Further, we show that the CAE achieves competitive or better unsupervised object discovery performance on simple multi-object datasets compared to a state-of-the-art slot-based approach while being up to 100 times faster to train.},
	language = {en},
	urldate = {2023-09-25},
	journal = {Transactions on Machine Learning Research},
	author = {Löwe, Sindy and Lippe, Phillip and Rudolph, Maja and Welling, Max},
	month = sep,
	year = {2022},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\HS7RXYFZ\\Löwe et al. - 2022 - Complex-Valued Autoencoders for Object Discovery.pdf:application/pdf},
}

@article{manwani1998,
	title = {Signal {Detection} in {Noisy} {Weakly}-{Active} {Dendrites}},
	volume = {11},
	url = {https://papers.nips.cc/paper_files/paper/1998/hash/21fe5b8ba755eeaece7a450849876228-Abstract.html},
	abstract = {Here we derive measures quantifying the information loss of a synaptic  signal due to the presence of neuronal noise sources, as it electrotonically  propagates along a weakly-active dendrite. We model the dendrite as an  infinite linear cable, with noise sources distributed along its length.  The  noise sources we consider are thermal noise, channel noise arising from  the stochastic nature of voltage-dependent ionic channels (K+ and Na+)  and synaptic noise due to spontaneous background activity. We assess the  efficacy of information transfer using a signal detection paradigm where  the objective is to detect the presence/absence of a presynaptic spike from  the post-synaptic membrane voltage. This allows us to analytically assess  the role of each of these noise sources in  information transfer.  For our  choice  of parameters,  we find  that the  synaptic  noise  is  the  dominant  noise source which limits the maximum length over which information  be reliably transmitted.},
	urldate = {2023-09-26},
	journal = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Manwani, Amit and Koch, Christof},
	year = {1998},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\IKK482VY\\Manwani and Koch - 1998 - Signal Detection in Noisy Weakly-Active Dendrites.pdf:application/pdf},
}

@article{koffka1922,
	title = {Perception: {An} introduction to the {Gestalt}-theorie},
	volume = {19},
	number = {10},
	journal = {Psychological bulletin},
	author = {Koffka, Kurt},
	year = {1922},
	pages = {531--585},
}


@article{kwon2016,
	series = {Quantitative {Approaches} in {Gestalt} {Perception}},
	title = {Spatially-global integration of closed, fragmented contours by finding the shortest-path in a log-polar representation},
	volume = {126},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698915002564},
	doi = {10.1016/j.visres.2015.06.007},
	abstract = {Finding the occluding contours of objects in real 2D retinal images of natural 3D scenes is done by determining, which contour fragments are relevant, and the order in which they should be connected. We developed a model that finds the closed contour represented in the image by solving a shortest path problem that uses a log-polar representation of the image; the kind of representation known to exist in area V1 of the primate cortex. The shortest path in a log-polar representation favors the smooth, convex and closed contours in the retinal image that have the smallest number of gaps. This approach is practical because finding a globally-optimal solution to a shortest path problem is computationally easy. Our model was tested in four psychophysical experiments. In the first two experiments, the subject was presented with a fragmented convex or concave polygon target among a large number of unrelated pieces of contour (distracters). The density of these pieces of contour was uniform all over the screen to minimize spatially-local cues. The orientation of each target contour fragment was randomly perturbed by varying the levels of jitter. Subjects drew a closed contour that represented the target’s contour on a screen. The subjects’ performance was nearly perfect when the jitter-level was low. Their performance deteriorated as jitter-levels were increased. The performance of our model was very similar to our subjects’. In two subsequent experiments, the subject was asked to discriminate a briefly-presented egg-shaped object while maintaining fixation at several different positions relative to the closed contour of the shape. The subject’s discrimination performance was affected by the fixation position in much the same way as the model’s.},
	urldate = {2023-09-22},
	journal = {Vision Research},
	author = {Kwon, TaeKyu and Agrawal, Kunal and Li, Yunfeng and Pizlo, Zygmunt},
	month = sep,
	year = {2016},
	keywords = {Closed contour, Figure Ground Organization, Log-polar representation, Shortest path},
	pages = {143--163},
	file = {Accepted Version:C\:\\Users\\loennqvi\\Zotero\\storage\\6M4CYMTN\\Kwon et al. - 2016 - Spatially-global integration of closed, fragmented.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\P9PILB6Y\\S0042698915002564.html:text/html},
}

@article{kovacs1993,
	title = {A closed curve is much more than an incomplete one: effect of closure in figure-ground segmentation.},
	volume = {90},
	shorttitle = {A closed curve is much more than an incomplete one},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.90.16.7495},
	doi = {10.1073/pnas.90.16.7495},
	abstract = {Detection of fragmented closed contours against a cluttered background occurs much beyond the local coherence distance (maximal separation between segments) of nonclosed contours. This implies that the extent of interaction between locally connected detectors is boosted according to the global stimulus structure. We further show that detection of a target probe is facilitated when the probe is positioned inside a closed circle. To explain the striking contour segregation ability found here, and performance enhancement inside closed boundaries, we propose the existence of a synergetic process in early vision.},
	number = {16},
	urldate = {2023-09-22},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Kovács, I and Julesz, B},
	month = aug,
	year = {1993},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {7495--7497},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\TLLX9JRU\\Kovács and Julesz - 1993 - A closed curve is much more than an incomplete one.pdf:application/pdf},
}

@article{field1993,
	title = {Contour integration by the human visual system: {Evidence} for a local “association field”},
	volume = {33},
	issn = {0042-6989},
	shorttitle = {Contour integration by the human visual system},
	url = {https://www.sciencedirect.com/science/article/pii/004269899390156Q},
	doi = {10.1016/0042-6989(93)90156-Q},
	abstract = {The Gestalt law of “good continuation” has been used to describe a variety of phenomena demonstrating the importance of continuity in human perception. In this study, we consider how continuity may be represented by a visual system that filters spatial data using arrays of cells selective for orientation and spatial frequency. Many structures (e.g. fractal contours) show a form of redundancy which is well represented by the continuity of features as they vary across space and frequency. We suggest that it is possible to take advantage of the redundancy in continuous, but non-aligned features by associating the outputs of filters with similar tuning. Five experiments were performed, to determine the rules that govern the perception of continuity. Observers were presented with arrays of oriented, band-pass elements (Gabor patches) in which a subset of the elements was aligned along a “jagged” path. Using a forced-choice procedure, observers were found to be capable of identifying the path within a field of randomly-oriented elements even when the spacing between the elements was considerably larger than the size of any of the individual elements. Furthermore, when the elements were oriented at angles up to ± 60 deg relative to one another, the path was reliably identified. Alignment of the elements along the path was found to play a large role in the ability to detect the path. Small variations in the alignment or aligning the elements orthogonally (i.e. “side-to-side” as opposed to “end-to-end”) significantly reduced the observer's ability to detect the presence of a path. The results are discussed in terms of an “association field” which integrates information across neighboring filters tuned to similar orientations. We suggest that some of the processes involved in texture segregation may have a similar explanation.},
	number = {2},
	urldate = {2023-09-22},
	journal = {Vision Research},
	author = {Field, David J. and Hayes, Anthony and Hess, Robert F.},
	month = jan,
	year = {1993},
	keywords = {Contours, Fractal, Orientation, Psychophysics, Spatial vision, Texture perception, Visual coding},
	pages = {173--193},
	file = {ScienceDirect Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\2LZCIADM\\004269899390156Q.html:text/html},
}

@article{kubovy2008,
	title = {The whole is equal to the sum of its parts: {A} probabilistic model of grouping by proximity and similarity in regular patterns},
	volume = {115},
	issn = {1939-1471},
	shorttitle = {The whole is equal to the sum of its parts},
	doi = {10.1037/0033-295X.115.1.131},
	abstract = {The authors investigated whether the gestalt grouping principles can be quantified and whether the conjoint effects of two grouping principles operating at the same time on the same stimuli differ from the sum of their individual effects. After reviewing earlier attempts to discover how grouping principles interact, they developed a probabilistic model of grouping by proximity, which allows measurement of strength on a ratio scale. Then, in 3 experiments using dot lattices, they showed that the strength of the conjoint effect of 2 grouping principles--grouping by proximity and grouping by similarity--is equal to the sum of their separate effects. They propose a physiologically plausible model of this law. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
	number = {1},
	journal = {Psychological Review},
	author = {Kubovy, Michael and van den Berg, Martin},
	year = {2008},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Cognitive Processes, Gestalt Psychology, Perceptual Organization, Spatial Organization, Visual Perception},
	pages = {131--154},
	file = {Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\9D2R2U2E\\2008-00265-006.html:text/html},
}

@article{quinlan1998,
	title = {Grouping by {Proximity} or {Similarity}? {Competition} between the {Gestalt} {Principles} in {Vision}},
	volume = {27},
	issn = {0301-0066},
	shorttitle = {Grouping by {Proximity} or {Similarity}?},
	url = {https://doi.org/10.1068/p270417},
	doi = {10.1068/p270417},
	abstract = {The nature of the psychological processes that underlie the Gestalt principles of grouping by proximity and grouping by similarity is examined. Similarity was defined relative to the principles of grouping by common colour and grouping by common shape. Subjects were presented with displays comprising a row of seven coloured shapes and were asked to rate the degree to which the central target shape grouped with either the right or the left flanking shapes. Across the displays the proximal and featural relationships between the target and flankers were varied.
These ratings reflected persuasive effects of grouping by proximity and common colour; there was only weak evidence for grouping by common shape. Nevertheless, both common colour and common shape were shown to override grouping by proximity, under certain conditions. The data also show that to understand how the Gestalt principles operate it appears necessary to consider processes that operate within and between groups of elements that are initially identified on the basis of proximity. Whether such groups survive further analysis depends critically on the featural content of the constituent elements.},
	language = {en},
	number = {4},
	urldate = {2023-09-22},
	journal = {Perception},
	author = {Quinlan, Philip T and Wilton, Richard N},
	month = apr,
	year = {1998},
	note = {Publisher: SAGE Publications Ltd STM},
	pages = {417--430},
}

@article{kanizsa1979,
	address = {New York},
	title = {Organization in {Vision}: {Essays} on {Gestalt} {Perception}},
	publisher = {Praeger},
    journal = {Praeger, New York},
	author = {Kanizsa, Gaetano},
	year = {1979},
}

@article{wang2012,
	title = {Perceptual {Grouping} without {Awareness}: {Superiority} of {Kanizsa} {Triangle} in {Breaking} {Interocular} {Suppression}},
	volume = {7},
	issn = {1932-6203},
	shorttitle = {Perceptual {Grouping} without {Awareness}},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0040106},
	doi = {10.1371/journal.pone.0040106},
	abstract = {Much information could be processed unconsciously. However, there is no direct evidence on whether perceptual grouping could occur without awareness. To answer this question, we investigated whether a Kanizsa triangle (an example of perceptual grouping) is processed differently from stimuli with the same local components but are ungrouped or weakly grouped. Specifically, using a suppression time paradigm we tested whether a Kanizsa triangle would emerge from interocular continuous flash suppression sooner than control stimuli. Results show a significant advantage of the Kanizsa triangle: the Kanizsa triangle emerged from suppression noise significantly faster than the control stimulus with the local Pacmen randomly rotated (t(9) = −2.78, p = 0.02); and also faster than the control stimulus with all Pacmen rotated 180° (t(11) = −3.20, p{\textless}0.01). Additional results demonstrated that the advantage of the grouped Kanizsa triangle could not be accounted for by the faster detection speed at the conscious level for the Kanizsa figures on a dynamic noise background. Our results indicate that certain properties supporting perceptual grouping could be processed in the absence of awareness.},
	language = {en},
	number = {6},
	urldate = {2023-09-22},
	journal = {PLOS ONE},
	author = {Wang, Lan and Weng, Xuchu and He, Sheng},
	month = jun,
	year = {2012},
	note = {Publisher: Public Library of Science},
	keywords = {Attention, Eyes, Information processing, Luminance, Sensory perception, Time measurement, Vision, Visual cortex},
	pages = {e40106},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\7IRY4SML\\Wang et al. - 2012 - Perceptual Grouping without Awareness Superiority.pdf:application/pdf},
}

@article{lesher1995,
	title = {Illusory contours: {Toward} a neurally based perceptual theory},
	volume = {2},
	issn = {1531-5320},
	shorttitle = {Illusory contours},
	url = {https://doi.org/10.3758/BF03210970},
	doi = {10.3758/BF03210970},
	abstract = {Although illusory contours were first described nearly a century ago, researchers have only recently begun to approach a consensus on the processes underlying their formation. Neurophysiological and psychophysical evidence indicate that neural mechanisms of the early visual cortex subserve illusory contour generation, although cognitive factors play important roles in determining the final percept. I summarize experiments concerning the determinants of illusory contour strength and form, concentrating on findings particularly relevant to modeling. After establishing arguments for the early generation of illusory contours, I provide an overview of formation theories, culminating with descriptions of neural models. The constraints that experimental data place on models are outlined, and neural models are evaluated with respect to these constraints. Throughout the review, I indicate where further experimental and modeling research are critical.},
	language = {en},
	number = {3},
	urldate = {2023-09-22},
	journal = {Psychonomic Bulletin \& Review},
	author = {Lesher, Gregory W.},
	month = sep,
	year = {1995},
	keywords = {Amodal Completion, Boundary Contour System, Illusory Contour, Illusory Figure, Subjective Contour},
	pages = {279--321},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\XSF52C3N\\Lesher - 1995 - Illusory contours Toward a neurally based percept.pdf:application/pdf},
}

@article{wertheimer1923,
	title = {Laws of {Organization} in {Perceptual} {Forms}},
	volume = {4},
	journal = {Psycologische Forschung},
	author = {Wertheimer, Max},
	year = {1923},
	pages = {301--350},
}

@article{kimchi1992,
	title = {Primacy of wholistic processing and global/local paradigm: a critical review},
	volume = {112},
	issn = {0033-2909},
	shorttitle = {Primacy of wholistic processing and global/local paradigm},
	doi = {10.1037/0033-2909.112.1.24},
	abstract = {The question of whether perception is analytic or wholistic is an enduring issue in psychology. The global-precedence hypothesis, considered by many as a modern version of the Gestaltist claim about the perceptual primacy of wholes, has generated a large body of research, but the debate still remains very active. This article reviews the research within the global/local paradigm, and critically analyzes the assumptions underlying this paradigm. The extent to which this line of research contributes to understanding the role of wholistic processing in object perception is discussed. It is concluded that one should be very cautious in making inferences about wholistic processing from the processing advantage of the global level of stimulus structure. A distinction is proposed between global properties, defined by their position in the hierarchical structure of the stimulus, and wholistic properties, defined as a function of interrelations among component parts. It is suggested that a direct comparison between processing of wholistic and component properties is needed to support the hypothesis about the perceptual primacy of wholistic processing.},
	language = {eng},
	number = {1},
	journal = {Psychological Bulletin},
	author = {Kimchi, R.},
	month = jul,
	year = {1992},
	pmid = {1529037},
	keywords = {Attention, Gestalt Theory, Humans, Visual Perception},
	pages = {24--38},
}

@article{elder1993,
	title = {The effect of contour closure on the rapid discrimination of two-dimensional shapes},
	volume = {33},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/004269899390080G},
	doi = {10.1016/0042-6989(93)90080-G},
	abstract = {An outline drawing often serves as an excellent depiction of a visual scene. Somehow, our visual system can form two- and three-dimensional percepts solely from one-dimensional contour information. In mathematics, contour closure plays a key role in bridging this dimensional gap, however in perception the link between closure and shape is unclear. To better understand this relationship, we devised a set of visual search experiments in which subjects discriminate outline figures by means of their two-dimensional shape. By modulating the degree of closure of the outlines, we show that two-dimensional shape processing is rapid for closed stimuli but slow for open stimuli. We further show that search can be characterized as a smooth, monotonie function of the degree of closure, supporting the notion of a perceptual closure continuum.},
	number = {7},
	urldate = {2023-09-22},
	journal = {Vision Research},
	author = {Elder, James and Zucker, Steven},
	month = may,
	year = {1993},
	keywords = {Contour, Perceptual organization, Shape, Topology, Visual search},
	pages = {981--991},
	file = {ScienceDirect Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\CFV7ALQK\\004269899390080G.html:text/html},
}

@article{pomerantz1977,
	title = {Perception of wholes and of their component parts: {Some} configural superiority effects},
	volume = {3},
	issn = {1939-1277},
	shorttitle = {Perception of wholes and of their component parts},
	doi = {10.1037/0096-1523.3.3.422},
	abstract = {Theories of visual pattern recognition frequently assume that processing begins with an analysis of the pattern into component parts, which are often assumed to be line segments of particular orientations, lengths, positions, and curvatures. The present 5 experiments, each using 8 undergraduates, measured discriminability of these simple parts when presented either in isolation or within configural contexts that provided no formal information useful for the discrimination. Certain contexts either impaired or did not affect performance. Other contexts were found, however, which dramatically improved discriminability. Thus, 2 patterns which differed only in a single part could be discriminated from each other more quickly than could their distinguishing parts shown in isolation. Further experiments suggested that this "configural superiority" effect influenced perceptual components of processing rather than memorial components. The mechanism underlying configural superiority appears to be the detection of novel and distinguishing features, such as corners and intersections, which emerge when parts are placed in close proximity to each other. The outlines of a model for preattentive feature discrimination are presented. (32 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {3},
	journal = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Pomerantz, James R. and Sager, Lawrence C. and Stoever, Robert J.},
	year = {1977},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Figure Ground Discrimination, Form and Shape Perception, Memory, Pattern Discrimination, Visual Discrimination},
	pages = {422--435},
	file = {Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\CJLZL9IL\\1978-11512-001.html:text/html},
}

@article{marini2016,
	title = {Gestalt {Perceptual} {Organization} of {Visual} {Stimuli} {Captures} {Attention} {Automatically}: {Electrophysiological} {Evidence}},
	volume = {10},
	issn = {1662-5161},
	shorttitle = {Gestalt {Perceptual} {Organization} of {Visual} {Stimuli} {Captures} {Attention} {Automatically}},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2016.00446},
	abstract = {The visual system leverages organizational regularities of perceptual elements to create meaningful representations of the world. One clear example of such function, which has been formalized in the Gestalt psychology principles, is the perceptual grouping of simple visual elements (e.g., lines and arcs) into unitary objects (e.g., forms and shapes). The present study sought to characterize automatic attentional capture and related cognitive processing of Gestalt-like visual stimuli at the psychophysiological level by using event-related potentials (ERPs). We measured ERPs during a simple visual reaction time task with bilateral presentations of physically matched elements with or without a Gestalt organization. Results showed that Gestalt (vs. non-Gestalt) stimuli are characterized by a larger N2pc together with enhanced ERP amplitudes of non-lateralized components (N1, N2, P3) starting around 150 ms post-stimulus onset. Thus, we conclude that Gestalt stimuli capture attention automatically and entail characteristic psychophysiological signatures at both early and late processing stages.HighlightsWe studied the neural signatures of the automatic processes of visual attention elicited by Gestalt stimuli. We found that a reliable early correlate of attentional capture turned out to be the N2pc component. Perceptual and cognitive processing of Gestalt stimuli is associated with larger N1, N2, and P3},
	urldate = {2023-09-22},
	journal = {Frontiers in Human Neuroscience},
	author = {Marini, Francesco and Marzi, Carlo A.},
	year = {2016},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\SIC3M4CX\\Marini and Marzi - 2016 - Gestalt Perceptual Organization of Visual Stimuli .pdf:application/pdf},
}

@article{elder2002,
	title = {Ecological statistics of {Gestalt} laws for the perceptual organization of contours},
	volume = {2},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/2.4.5},
	doi = {10.1167/2.4.5},
	abstract = {Although numerous studies have measured the strength of visual grouping cues for controlled psychophysical stimuli, little is known about the statistical utility of these various cues for natural images. In this study, we conducted experiments in which human participants trace perceived contours in natural images. These contours are automatically mapped to sequences of discrete tangent elements detected in the image. By examining relational properties between pairs of successive tangents on these traced curves, and between randomly selected pairs of tangents, we are able to estimate the likelihood distributions required to construct an optimal Bayesian model for contour grouping. We employed this novel methodology to investigate the inferential power of three classical Gestalt cues for contour grouping: proximity, good continuation, and luminance similarity. The study yielded a number of important results: (1) these cues, when appropriately defined, are approximately uncorrelated, suggesting a simple factorial model for statistical inference; (2) moderate image-to-image variation of the statistics indicates the utility of general probabilistic models for perceptual organization; (3) these cues differ greatly in their inferential power, proximity being by far the most powerful; and (4) statistical modeling of the proximity cue indicates a scale-invariant power law in close agreement with prior psychophysics.},
	number = {4},
	urldate = {2023-09-22},
	journal = {Journal of Vision},
	author = {Elder, James H. and Goldberg, Richard M.},
	month = aug,
	year = {2002},
	pages = {5},
	file = {Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\RY8RDC4H\\article.html:text/html},
}

@article{geisler2001,
	title = {Edge co-occurrence in natural images predicts contour grouping performance},
	volume = {41},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698900002777},
	doi = {10.1016/S0042-6989(00)00277-7},
	abstract = {The human brain manages to correctly interpret almost every visual image it receives from the environment. Underlying this ability are contour grouping mechanisms that appropriately link local edge elements into global contours. Although a general view of how the brain achieves effective contour grouping has emerged, there have been a number of different specific proposals and few successes at quantitatively predicting performance. These previous proposals have been developed largely by intuition and computational trial and error. A more principled approach is to begin with an examination of the statistical properties of contours that exist in natural images, because it is these statistics that drove the evolution of the grouping mechanisms. Here we report measurements of both absolute and Bayesian edge co-occurrence statistics in natural images, as well as human performance for detecting natural-shaped contours in complex backgrounds. We find that contour detection performance is quantitatively predicted by a local grouping rule derived directly from the co-occurrence statistics, in combination with a very simple integration rule (a transitivity rule) that links the locally grouped contour elements into longer contours.},
	number = {6},
	urldate = {2023-09-22},
	journal = {Vision Research},
	author = {Geisler, W. S. and Perry, J. S. and Super, B. J. and Gallogly, D. P.},
	month = mar,
	year = {2001},
	keywords = {Contour perception, Form perception, Grouping, Natural images},
	pages = {711--724},
	file = {ScienceDirect Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\VXPK9WCD\\S0042698900002777.html:text/html},
}

@article{sigman2001,
	title = {On a common circle: {Natural} scenes and {Gestalt} rules},
	volume = {98},
	shorttitle = {On a common circle},
	url = {https://www.pnas.org/doi/abs/10.1073/pnas.98.4.1935},
	doi = {10.1073/pnas.98.4.1935},
	abstract = {To understand how the human visual system analyzes images, it is essential to know the structure of the visual environment. In particular, natural images display consistent statistical properties that distinguish them from random luminance distributions. We have studied the geometric regularities of oriented elements (edges or line segments) present in an ensemble of visual scenes, asking how much information the presence of a segment in a particular location of the visual scene carries about the presence of a second segment at different relative positions and orientations. We observed strong long-range correlations in the distribution of oriented segments that extend over the whole visual field. We further show that a very simple geometric rule, cocircularity, predicts the arrangement of segments in natural scenes, and that different geometrical arrangements show relevant differences in their scaling properties. Our results show similarities to geometric features of previous physiological and psychophysical studies. We discuss the implications of these findings for theories of early vision.},
	number = {4},
	urldate = {2023-09-22},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Sigman, Mariano and Cecchi, Guillermo A. and Gilbert, Charles D. and Magnasco, Marcelo O.},
	month = feb,
	year = {2001},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {1935--1940},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\TLGUXMRV\\Sigman et al. - 2001 - On a common circle Natural scenes and Gestalt rul.pdf:application/pdf},
}

@article{higgins2017,
	title = {beta-{VAE}: {Learning} {Basic} {Visual} {Concepts} with a {Constrained} {Variational} {Framework}},
	url = {https://openreview.net/forum?id=Sy2fzU9gl},
	journal = {International {Conference} on {Learning} {Representations}},
	author = {Higgins, Irina and Matthey, Loic and Pal, Arka and Burgess, Christopher and Glorot, Xavier and Botvinick, Matthew and Mohamed, Shakir and Lerchner, Alexander},
	year = {2017},
}


@article{kellman1983,
	title = {Perception of partly occluded objects in infancy},
	volume = {15},
	issn = {1095-5623},
	doi = {10.1016/0010-0285(83)90017-8},
	abstract = {In 6 experiments, 224 3–4 mo olds were habituated to 1 object whose top and bottom were visible but whose center was occluded by a nearer object. They were then tested with a fully visible continuous object and with 2 fully visible object pieces with a gap where the occluder had been. A 7th experiment with 10 undergraduates investigated how infants' perception of partly occluded objects compared with that of adults. Patterns of dishabituation suggested that infants perceived the boundaries of a partly hidden object by analyzing the movements of its surfaces: Infants perceived a connected object when its ends moved in a common translation behind the occluder. Infants did not appear to perceive a connected object by analyzing the colors and forms of surfaces: They did not perceive a connected object when its visible parts were stationary, its color was homogeneous, its edges were aligned, and its shape was simple and regular. Findings do not support the thesis from gestalt psychology that object perception first arises as a consequence of a tendency to perceive the simplest, most regular configuration, or the Piagetian thesis that object perception depends on the prior coordination of action. Perception of objects may depend on an inherent conception of what an object is. (40 ref) (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
	number = {4},
	journal = {Cognitive Psychology},
	author = {Kellman, Philip J. and Spelke, Elizabeth S.},
	year = {1983},
	note = {Place: Netherlands
Publisher: Elsevier Science},
	keywords = {Gestalt Psychology, Perceptual Closure, Perceptual Development, Piaget (Jean)},
	pages = {483--524},
	file = {Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\B4XB64RK\\1984-06382-001.html:text/html},
}

@article{spelke1990,
	title = {Principles of object perception},
	volume = {14},
	issn = {0364-0213},
	url = {https://www.sciencedirect.com/science/article/pii/036402139090025R},
	doi = {10.1016/0364-0213(90)90025-R},
	abstract = {Research on human infants has begun to shed light on early-developing processes for segmenting perceptual arrays Into objects. Infants appear to perceive objects by analyzing three-dimensional surface arrangements and motions. Their perception does not accord with a general tendency to maximize flgural goodness or to attend to nonaccidental geometric relations in visual arrays. Object perception does accord with principles governing the motions of material bodies: Infants divide perceptual arrays into units that move as connected wholes, that move separately from one another, that tend to maintain their size and shape over motion, and that tend to act upon each other only on contact. These findings suggest that a general representation of object unity and boundaries is interposed between representations of surfaces and representations of objects of familiar kinds. The processes that construct this representation may be related to processes of physical reasoning.},
	number = {1},
	urldate = {2023-09-26},
	journal = {Cognitive Science},
	author = {Spelke, Elizabeth S.},
	month = jan,
	year = {1990},
	pages = {29--56},
	file = {ScienceDirect Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\ST4RVPX5\\036402139090025R.html:text/html},
}


@article{ringach1996,
	title = {Spatial and {Temporal} {Properties} of {Illusory} {Contours} and {Amodal} {Boundary} {Completion}},
	volume = {36},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/0042698996000624},
	doi = {10.1016/0042-6989(96)00062-4},
	abstract = {Spatial and temporal properties of illusory contours and amodal completion were investigated using a shape discrimination task. Performance was characterized as accuracy of angular discrimination of the inducing figures (‘pacmen”) in a two-alternative forced choice (2AFC) paradigm. First, we compared performance when four “pacmen” were organized into Kanizsa-like figures (squares and small deformations of squares) which produced the percept of illusory contours (ICs), with performance obtained with all four “pacmen” facing in the same direction, when no illusory contours were seen. Then, we found that it was possible to interfere with boundary completion and degrade performance with masking lines placed between the inducers of a Kanizsa figure. From these experiments we concluded that performance in the shape discrimination task depended on boundary completion. Next, the dependence of contour-dependent performance on the spatial scale of the figures was examined. Threshold angular discrimination was approximately scale-invariant and subjects were able to integrate visual information across gaps as large as 13 deg of visual angle. Performance in the shape recognition task for illusory and amodally completed figures was also measured. Similar accuracy was obtained either when the boundaries were modally or amodally completed. Finally, we used shape discrimination in conjunction with backward masking to explore the dynamics of boundary completion. Two different phases of the boundary completion process were observed. The first phase was revealed when the inducers were locally masked, and took ≈ 117 msec. A second phase lasted an additional 140–200 msec after the inducers were masked. Copyright © 1996 Elsevier Science Ltd.},
	number = {19},
	urldate = {2023-09-27},
	journal = {Vision Research},
	author = {Ringach, Dario L. and Shapley, Robert},
	month = oct,
	year = {1996},
	keywords = {Amodal completion, Boundary integration, Illusory contours},
	pages = {3037--3050},
	file = {ScienceDirect Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\IX88YXUK\\0042698996000624.html:text/html},
}


@article{hubert1985,
	title = {Comparing partitions},
	volume = {2},
	issn = {1432-1343},
	url = {https://doi.org/10.1007/BF01908075},
	doi = {10.1007/BF01908075},
	abstract = {The problem of comparing two different partitions of a finite set of objects reappears continually in the clustering literature. We begin by reviewing a well-known measure of partition correspondence often attributed to Rand (1971), discuss the issue of correcting this index for chance, and note that a recent normalization strategy developed by Morey and Agresti (1984) and adopted by others (e.g., Miligan and Cooper 1985) is based on an incorrect assumption. Then, the general problem of comparing partitions is approached indirectly by assessing the congruence of two proximity matrices using a simple cross-product measure. They are generated from corresponding partitions using various scoring rules. Special cases derivable include traditionally familiar statistics and/or ones tailored to weight certain object pairs differentially. Finally, we propose a measure based on the comparison of object triples having the advantage of a probabilistic interpretation in addition to being corrected for chance (i.e., assuming a constant value under a reasonable null hypothesis) and bounded between ±1.},
	language = {en},
	number = {1},
	urldate = {2023-09-26},
	journal = {Journal of Classification},
	author = {Hubert, Lawrence and Arabie, Phipps},
	month = dec,
	year = {1985},
	keywords = {Consensus indices, Measures of agreement, Measures of association},
	pages = {193--218},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\SVGBZMC5\\Hubert and Arabie - 1985 - Comparing partitions.pdf:application/pdf},
}

@article{locatello2020,
	title = {Object-{Centric} {Learning} with {Slot} {Attention}},
	volume = {33},
	url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/8511df98c02ab60aea1b2356c013bc0f-Paper.pdf},
	journal = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Locatello, Francesco and Weissenborn, Dirk and Unterthiner, Thomas and Mahendran, Aravindh and Heigold, Georg and Uszkoreit, Jakob and Dosovitskiy, Alexey and Kipf, Thomas},
	editor = {Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M. F. and Lin, H.},
	year = {2020},
	pages = {11525--11538},
}


@article{milner1974,
	title = {A model for visual shape recognition},
	volume = {81},
	issn = {1939-1471},
	doi = {10.1037/h0037149},
	abstract = {Suggests that many examples of stimulus equivalence may be explained by angle and length-ratio feature detectors whose outputs are generalized over the visual field. Problems of interference between a number of figures simultaneously present, and of localizing the figure that is being recognized, require a mechanism of selective attention. This could involve the temporal segregation of signals from different figures as they pass through the recognition circuits. The figure to which attention is directed feeds a signal back to an earlier stage to enhance the corresponding input before the generalization process deprives it of its spatial information. (22 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {6},
	journal = {Psychological Review},
	author = {Milner, Peter M.},
	year = {1974},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Form and Shape Perception, Selective Attention, Stimulus Generalization, Visual Perception},
	pages = {521--535},
	file = {Snapshot:C\:\\Users\\loennqvi\\Zotero\\storage\\IS2C4XJR\\doiLanding.html:text/html},
}

@article{rezende2018,
	title = {Taming {VAEs}},
	url = {http://arxiv.org/abs/1810.00597},
	abstract = {In spite of remarkable progress in deep latent variable generative modeling, training still remains a challenge due to a combination of optimization and generalization issues. In practice, a combination of heuristic algorithms (such as hand-crafted annealing of KL-terms) is often used in order to achieve the desired results, but such solutions are not robust to changes in model architecture or dataset. The best settings can often vary dramatically from one problem to another, which requires doing expensive parameter sweeps for each new case. Here we develop on the idea of training VAEs with additional constraints as a way to control their behaviour. We first present a detailed theoretical analysis of constrained VAEs, expanding our understanding of how these models work. We then introduce and analyze a practical algorithm termed Generalized ELBO with Constrained Optimization, GECO. The main advantage of GECO for the machine learning practitioner is a more intuitive, yet principled, process of tuning the loss. This involves defining of a set of constraints, which typically have an explicit relation to the desired model performance, in contrast to tweaking abstract hyper-parameters which implicitly affect the model behavior. Encouraging experimental results in several standard datasets indicate that GECO is a very robust and effective tool to balance reconstruction and compression constraints.},
	number = {arXiv:1810.00597},
	urldate = {2023-09-26},
    journal = {ArXiv pre-print},
	institution = {arXiv},
	author = {Rezende, Danilo Jimenez and Viola, Fabio},
	month = oct,
	year = {2018},
	note = {arXiv:1810.00597 [cs, stat]
type: article},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{higgins2021,
	title = {Unsupervised deep learning identifies semantic disentanglement in single inferotemporal face patch neurons},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-26751-5},
	doi = {10.1038/s41467-021-26751-5},
	abstract = {In order to better understand how the brain perceives faces, it is important to know what objective drives learning in the ventral visual stream. To answer this question, we model neural responses to faces in the macaque inferotemporal (IT) cortex with a deep self-supervised generative model, β-VAE, which disentangles sensory data into interpretable latent factors, such as gender or age. Our results demonstrate a strong correspondence between the generative factors discovered by β-VAE and those coded by single IT neurons, beyond that found for the baselines, including the handcrafted state-of-the-art model of face perception, the Active Appearance Model, and deep classifiers. Moreover, β-VAE is able to reconstruct novel face images using signals from just a handful of cells. Together our results imply that optimising the disentangling objective leads to representations that closely resemble those in the IT at the single unit level. This points at disentangling as a plausible learning objective for the visual brain.},
	language = {en},
	number = {1},
	urldate = {2023-09-26},
	journal = {Nature Communications},
	author = {Higgins, Irina and Chang, Le and Langston, Victoria and Hassabis, Demis and Summerfield, Christopher and Tsao, Doris and Botvinick, Matthew},
	month = nov,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Computational neuroscience, Neuroscience, Object vision, Visual system},
	pages = {6456},
	file = {Full Text PDF:C\:\\Users\\loennqvi\\Zotero\\storage\\5GUTHSW2\\Higgins et al. - 2021 - Unsupervised deep learning identifies semantic dis.pdf:application/pdf},
}

@ARTICLE{creswell2018,
  author={Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A.},
  journal={IEEE Signal Processing Magazine}, 
  title={Generative Adversarial Networks: An Overview}, 
  year={2018},
  volume={35},
  number={1},
  pages={53-65},
  doi={10.1109/MSP.2017.2765202}
}

@article{goodfellow2014,
 author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Generative Adversarial Nets},
 url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf},
 volume = {27},
 year = {2014}
}

@article{rombach2022,
    author    = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj\"orn},
    title     = {High-Resolution Image Synthesis With Latent Diffusion Models},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {10684-10695}
}


@article{sohl-dickstein2015,
  title = 	 {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  author = 	 {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {2256--2265},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/sohl-dickstein15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/sohl-dickstein15.html},
  abstract = 	 {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.}
}
