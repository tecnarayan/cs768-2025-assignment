\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Balocchi and Jensen(2019)]{BalocchiJensen2019}
C.~Balocchi and S.~T. Jensen.
\newblock Spatial modeling of trends in crime over time in {P}hiladelphia.
\newblock \emph{The Annals of Applied Statistics}, 13\penalty0 (4):\penalty0
  2235--2259, 2019.

\bibitem[Balocchi et~al.(2019)Balocchi, Deshpande, George, and
  Jensen]{Balocchi2020}
C.~Balocchi, S.~K. Deshpande, E.~I. George, and S.~T. Jensen.
\newblock Crime in {P}hiladelphia: {B}ayesian clustering with particle
  optimization.
\newblock \emph{arXiv preprint arXiv:1912.00111}, 2019.

\bibitem[Bartholomew-Biggs et~al.(2000)Bartholomew-Biggs, Brown, Christianson,
  and Dixon]{biggs2000AD}
M.~Bartholomew-Biggs, S.~Brown, B.~Christianson, and L.~Dixon.
\newblock Automatic differentiation of algorithms.
\newblock \emph{Journal of Computational and Applied Mathematics}, 124, 2000.

\bibitem[Baydin et~al.(2018)Baydin, Pearlmutter, Radul, and
  Siskind]{baydin2015automatic}
A.~G. Baydin, B.~A. Pearlmutter, A.~A. Radul, and J.~M. Siskind.
\newblock Automatic differentiation in machine learning: {A} survey.
\newblock \emph{arXiv Preprint arXiv:1502.05767v4}, 2018.

\bibitem[Beirami et~al.(2017)Beirami, Razaviyayn, Shahin, and
  Tarokh]{beirami2017firstALOO}
A.~Beirami, M.~Razaviyayn, S.~Shahin, and V.~Tarokh.
\newblock On optimal generalizability in parametric learning.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 3458--3468, 2017.

\bibitem[Bellare and McCallum(2007)]{bellare2007learning}
K.~Bellare and A.~McCallum.
\newblock Learning extractors from unlabeled text using relevant databases.
\newblock In \emph{Sixth {I}nternational {W}orkshop on {I}nformation
  {I}ntegration on the {W}eb}, 2007.

\bibitem[B{\"u}rkner et~al.(2020)B{\"u}rkner, Gabry, and
  Vehtari]{burkner2019approximate}
P.-C. B{\"u}rkner, J.~Gabry, and A.~Vehtari.
\newblock Approximate leave-future-out cross-validation for {B}ayesian time
  series models.
\newblock \emph{arXiv preprint arXiv:1902.06281}, may 2020.

\bibitem[Celeux and Durand(2008)]{celeux2008selecting}
G.~Celeux and J.-B. Durand.
\newblock Selecting hidden {M}arkov model state number with cross-validated
  likelihood.
\newblock \emph{Computational Statistics}, 23\penalty0 (4):\penalty0 541--564,
  2008.

\bibitem[DeCaprio et~al.(2007)DeCaprio, Vinson, Pearson, Montgomery, Doherty,
  and Galagan]{decaprio2007conrad}
D.~DeCaprio, J.~P. Vinson, M.~D. Pearson, P.~Montgomery, M.~Doherty, and J.~E.
  Galagan.
\newblock Conrad: {G}ene prediction using conditional random fields.
\newblock \emph{Genome research}, 17\penalty0 (9):\penalty0 1389--1398, 2007.

\bibitem[Dempster et~al.(1977)Dempster, Laird, and Rubin]{dempster1977maximum}
A.~P. Dempster, N.~M. Laird, and D.~B. Rubin.
\newblock Maximum likelihood from incomplete data via the {EM} algorithm.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 39\penalty0 (1):\penalty0 1--22, 1977.

\bibitem[Efron(1981)]{efron1981nonparametric}
B.~Efron.
\newblock Nonparametric estimates of standard error: {T}he jackknife, the
  bootstrap and other methods.
\newblock \emph{Biometrika}, 68\penalty0 (3):\penalty0 589--599, 1981.

\bibitem[Fox et~al.(2009)Fox, Jordan, Sudderth, and Willsky]{fox2009}
E.~Fox, M.~I. Jordan, E.~B. Sudderth, and A.~S. Willsky.
\newblock Sharing features among dynamical systems with {B}eta processes.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 549--557, 2009.

\bibitem[Fox et~al.(2014)Fox, Hughes, Sudderth, and Jordan]{fox2014}
E.~B. Fox, M.~C. Hughes, E.~B. Sudderth, and M.~I. Jordan.
\newblock Joint modeling of multiple time series via the {B}eta process with
  application to motion capture segmentation.
\newblock \emph{The Annals of Applied Statistics}, 8\penalty0 (3):\penalty0
  1281--1313, 2014.

\bibitem[Geisser(1975)]{geisser1975earlyCV}
S.~Geisser.
\newblock The predictive sample reuse method with applications.
\newblock \emph{Journal of the American Statistical Association}, 70\penalty0
  (350):\penalty0 320--328, June 1975.

\bibitem[Giordano et~al.(2019)Giordano, Stephenson, Liu, Jordan, and
  Broderick]{giordano2018swiss}
R.~Giordano, W.~T. Stephenson, R.~Liu, M.~I. Jordan, and T.~Broderick.
\newblock A {S}wiss {A}rmy infinitesimal jackknife.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, 2019.

\bibitem[Huang et~al.(2015)Huang, Xu, and Yu]{huang2015bidirectional}
Z.~Huang, W.~Xu, and K.~Yu.
\newblock Bidirectional {LSTM-CRF} models for sequence tagging.
\newblock \emph{arXiv preprint arXiv:1508.01991}, 2015.

\bibitem[Hughes and Sudderth(2014)]{bnpy}
M.~C. Hughes and E.~B. Sudderth.
\newblock Bnpy: {R}eliable and scalable variational inference for {B}ayesian
  nonparametric models.
\newblock In \emph{NIPS Probabilistic Programimming Workshop}, pages 8--13,
  2014.

\bibitem[Hughes et~al.(2012)Hughes, Fox, and Sudderth]{hughes2012}
M.~C. Hughes, E.~Fox, and E.~B. Sudderth.
\newblock Effective split-merge {M}onte {C}arlo methods for nonparametric
  models of sequential data.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 1295--1303, 2012.

\bibitem[Huh et~al.(2016)Huh, Agrawal, and Efros]{huh2016makes}
M.~Huh, P.~Agrawal, and A.~A. Efros.
\newblock What makes imagenet good for transfer learning?
\newblock \emph{arXiv preprint arXiv:1608.08614}, 2016.

\bibitem[Hyndman and Athanasopoulos(2018)]{hyndman2018forecasting}
R.~J. Hyndman and G.~Athanasopoulos.
\newblock \emph{Forecasting: {P}rinciples and practice}.
\newblock OTexts: Melbourne, Australia, 2018.

\bibitem[Ihler et~al.(2006)Ihler, Hutchins, and Smyth]{ihler2006adaptive}
A.~Ihler, J.~Hutchins, and P.~Smyth.
\newblock Adaptive event detection with time-varying {P}oisson processes.
\newblock In \emph{ACM SIGKDD International Conference on Knowledge Discovery
  and Data Mining}, pages 207--216, 2006.

\bibitem[Jaeckel(1972)]{jaeckel1972infinitesimal}
L.~Jaeckel.
\newblock The infinitesimal jackknife, memorandum.
\newblock Technical report, MM 72-1215-11, Bell Lab. Murray Hill, NJ, 1972.

\bibitem[Koh and Liang(2017)]{koh2017understanding}
P.~W. Koh and P.~Liang.
\newblock Understanding black-box predictions via influence functions.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pages
  1885--1894. JMLR. org, 2017.

\bibitem[Koh et~al.(2019)Koh, Ang, Teo, and Liang]{koh2019accuracy}
P.~W.~W. Koh, K.-S. Ang, H.~Teo, and P.~S. Liang.
\newblock On the accuracy of influence functions for measuring group effects.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5255--5265, 2019.

\bibitem[Koller and Friedman(2009)]{koller2009probabilistic}
D.~Koller and N.~Friedman.
\newblock \emph{Probabilistic graphical models: {P}rinciples and techniques -
  adaptive computation and machine learning}.
\newblock The MIT Press, 2009.
\newblock ISBN 0262013193.

\bibitem[Lample et~al.(2016)Lample, Ballesteros, Subramanian, Kawakami, and
  Dyer]{lample2016neural}
G.~Lample, M.~Ballesteros, S.~Subramanian, K.~Kawakami, and C.~Dyer.
\newblock Neural architectures for named entity recognition.
\newblock \emph{arXiv preprint arXiv:1603.01360}, 2016.

\bibitem[Ma and Hovy(2016)]{ma2016end}
X.~Ma and E.~Hovy.
\newblock End-to-end sequence labeling via bi-directional {LSTM-CNNs-CRF}.
\newblock \emph{arXiv preprint arXiv:1603.01354}, 2016.

\bibitem[Musgrave et~al.(2020)Musgrave, Belongie, and Lim]{musgrave2020metric}
K.~Musgrave, S.~Belongie, and S.-N. Lim.
\newblock A metric learning reality check.
\newblock \emph{arXiv preprint arXiv:2003.08505}, 2020.

\bibitem[Obuchi and Kabashima(2016)]{obuchi2016linearALOO}
T.~Obuchi and Y.~Kabashima.
\newblock Cross validation in {LASSO} and its acceleration.
\newblock \emph{Journal of Statistical Mechanics}, May 2016.

\bibitem[Obuchi and Kabashima(2018)]{obuchi2018logisticALOO}
T.~Obuchi and Y.~Kabashima.
\newblock Accelerating cross-validation in multinomial logistic regression with
  l1-regularization.
\newblock \emph{Journal of Machine Learning Research}, Sept. 2018.

\bibitem[Pennington et~al.(2014)Pennington, Socher, and
  Manning]{pennington2014glove}
J.~Pennington, R.~Socher, and C.~D. Manning.
\newblock {G}love: {G}lobal vectors for word representation.
\newblock In \emph{Conference on Empirical Methods in Natural Language
  Processing (EMNLP)}, pages 1532--1543, 2014.

\bibitem[Rad and Maleki(2020)]{rad2018detailedALOO}
K.~R. Rad and A.~Maleki.
\newblock {A scalable estimate of the extra-sample prediction error via
  approximate leave-one-out}.
\newblock \emph{arXiv Preprint arXiv:1801.10243v4}, Jan. 2020.

\bibitem[Rangel et~al.(2004)Rangel, Angus, Ghahramani, Lioumi, Sotheran, Gaiba,
  Wild, and Falciani]{rangel2004modeling}
C.~Rangel, J.~Angus, Z.~Ghahramani, M.~Lioumi, E.~Sotheran, A.~Gaiba, D.~L.
  Wild, and F.~Falciani.
\newblock Modeling {T}-cell activation using gene expression profiling and
  state-space models.
\newblock \emph{Bioinformatics}, 20\penalty0 (9):\penalty0 1361--1372, 2004.

\bibitem[Reimers and Gurevych(2017)]{reimers2017optimal}
N.~Reimers and I.~Gurevych.
\newblock Optimal hyperparameters for deep {LSTM}-networks for sequence
  labeling tasks.
\newblock \emph{arXiv preprint arXiv:1707.06799v2}, 2017.

\bibitem[Sang and De~Meulder(2003)]{sang2003introduction}
E.~T.~K. Sang and F.~De~Meulder.
\newblock {Introduction to the CoNLL-2003 Shared Task: Language-Independent
  Named Entity Recognition}.
\newblock In \emph{Conference on Natural Language Learning at HLT-NAACL 2003},
  pages 142--147, 2003.

\bibitem[Stephenson and Broderick(2020)]{stephenson2019sparse}
W.~T. Stephenson and T.~Broderick.
\newblock Approximate cross-validation in high dimensions with guarantees.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, 2020.

\bibitem[Stone(1974)]{stone1974earlyCV}
M.~Stone.
\newblock Cross-validatory choice and assessment of statistical predictions.
\newblock \emph{Journal of the American Statistical Association}, 36\penalty0
  (2):\penalty0 111--147, 1974.

\bibitem[Sukkar et~al.(2012)Sukkar, Katz, Zhang, Raunig, and Wyman]{sukkar12}
R.~Sukkar, E.~Katz, Y.~Zhang, D.~Raunig, and B.~T. Wyman.
\newblock Disease progression modeling using hidden {M}arkov models.
\newblock In \emph{2012 Annual International Conference of the IEEE Engineering
  in Medicine and Biology Society}, pages 2845--2848. IEEE, 2012.

\bibitem[Sun et~al.(2019)Sun, Ghosh, Li, Cheng, Mohan, Sampaio, and Hu]{sun19}
Z.~Sun, S.~Ghosh, Y.~Li, Y.~Cheng, A.~Mohan, C.~Sampaio, and J.~Hu.
\newblock A probabilistic disease progression modeling approach and its
  application to integrated {H}untington's disease observational data.
\newblock \emph{JAMIA Open}, 2\penalty0 (1):\penalty0 123--130, 2019.

\bibitem[Tsuboi et~al.(2008)Tsuboi, Kashima, Mori, Oda, and
  Matsumoto]{tsuboi2008training}
Y.~Tsuboi, H.~Kashima, S.~Mori, H.~Oda, and Y.~Matsumoto.
\newblock Training conditional random fields using incomplete annotations.
\newblock In \emph{International Conference on Computational Linguistics
  (Coling 2008)}, pages 897--904, 2008.

\bibitem[Vehtari et~al.(2017)Vehtari, Gelman, and Gabry]{vehtari2017practical}
A.~Vehtari, A.~Gelman, and J.~Gabry.
\newblock Practical {Bayesian} model evaluation using leave-one-out
  cross-validation and {WAIC}.
\newblock \emph{Statistics and Computing}, 27\penalty0 (5):\penalty0
  1413--1432, 2017.

\bibitem[Vershynin(2018)]{vershynin2017hdpBook}
R.~Vershynin.
\newblock \emph{High-dimensional probability: {A}n introduction with
  applications in data science}.
\newblock Cambridge University Press, August 2018.

\bibitem[Wang et~al.(2018)Wang, Zhou, Lu, Maleki, and
  Mirrokni]{wang2018primalDualALOO}
S.~Wang, W.~Zhou, H.~Lu, A.~Maleki, and V.~Mirrokni.
\newblock Approximate leave-one-out for fast parameter tuning in high
  dimensions.
\newblock In \emph{International Conference in Machine Learning (ICML)}, 2018.

\bibitem[Wang et~al.(2014)Wang, Sontag, and Wang]{wang14}
X.~Wang, D.~Sontag, and F.~Wang.
\newblock Unsupervised learning of disease progression models.
\newblock In \emph{Proceedings of the 20th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pages 85--94, 2014.

\bibitem[Wilson et~al.(2020)Wilson, Kasy, and
  Mackey]{wilson2020modelSelectionALOO}
A.~Wilson, M.~Kasy, and L.~Mackey.
\newblock Approximate cross-validation: {G}uarantees for model assessment and
  selection.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, 2020.

\bibitem[Zheng and Liu(2017)]{zheng2017estimating}
J.~Zheng and H.~X. Liu.
\newblock Estimating traffic volumes for signalized intersections using
  connected vehicle data.
\newblock \emph{Transportation Research Part C: Emerging Technologies},
  79:\penalty0 347--362, 2017.

\end{thebibliography}
