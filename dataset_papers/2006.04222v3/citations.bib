@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Research}
}

@article{heess2017emergence,
  title={Emergence of locomotion behaviours in rich environments},
  author={Heess, Nicolas and Sriram, Srinivasan and Lemmon, Jay and Merel, Josh and Wayne, Greg and Tassa, Yuval and Erez, Tom and Wang, Ziyu and Eslami, Ali and Riedmiller, Martin and others},
  journal={arXiv preprint arXiv:1707.02286},
  year={2017}
}

@inproceedings{tan1993multi,
  title={Multi-agent reinforcement learning: independent versus cooperative agents},
  author={Tan, Ming},
  booktitle={Proceedings of the Tenth International Conference on Machine Learning},
  pages={330--337},
  year={1993},
  organization={Morgan Kaufmann Publishers Inc.}
}

@inproceedings{mordatch2017emergence,
    author = {Igor Mordatch and Pieter Abbeel},
    title = {Emergence of Grounded Compositional Language in Multi-Agent Populations},
    booktitle = {AAAI Conference on Artificial Intelligence},
    year = {2018},
    keywords = {Humans and AI; Multiagent Communication; Language Emergence},

}

@inproceedings{heess2015learning,
  title={Learning continuous control policies by stochastic value gradients},
  author={Heess, Nicolas and Wayne, Gregory and Silver, David and Lillicrap, Tim and Erez, Tom and Tassa, Yuval},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2944--2952},
  year={2015}
}

@inproceedings{maddison2016concrete,
  title={The concrete distribution: A continuous relaxation of discrete random variables},
  author={Maddison, Chris J and Mnih, Andriy and Teh, Yee Whye},
  booktitle={International Conference on Learning Representations},
  year={2017}
}

@inproceedings{jang2016categorical,
  title={Categorical reparameterization with gumbel-softmax},
  author={Jang, Eric and Gu, Shixiang and Poole, Ben},
  booktitle={International Conference on Learning Representations},
  year={2017}
}

@inproceedings{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  booktitle={International Conference on Learning Representations},
  year={2016}
}

@InProceedings{haarnoja2018soft,
  title =    {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author =   {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle =    {Proceedings of the 35th International Conference on Machine Learning},
  pages =    {1861--1870},
  year =     {2018},
  volume =   {80},
  series =   {Proceedings of Machine Learning Research},
  address =      {Stockholmsmässan, Stockholm Sweden},
  month =    {10--15 Jul},
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6000--6010},
  year={2017}
}

@inproceedings{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={International Conference on Learning Representations},
  year={2014}
}

@incollection{bucsoniu2010multi,
  title={Multi-agent reinforcement learning: An overview},
  author={Bu{\c{s}}oniu, Lucian and Babu{\v{s}}ka, Robert and De Schutter, Bart},
  booktitle={Innovations in multi-agent systems and applications-1},
  pages={183--221},
  year={2010},
  publisher={Springer}
}

@inproceedings{fischer2004hierarchical,
  title={Hierarchical reinforcement learning in communication-mediated multiagent coordination},
  author={Fischer, Felix and Rovatsos, Michael and Weiss, Gerhard},
  booktitle={Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems-Volume 3},
  pages={1334--1335},
  year={2004},
  organization={IEEE Computer Society}
}

@incollection{littman1994markov,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={Machine Learning Proceedings 1994},
  pages={157--163},
  year={1994},
  publisher={Elsevier}
}

@inproceedings{he2016opponent,
  title={Opponent modeling in deep reinforcement learning},
  author={He, He and Boyd-Graber, Jordan and Kwok, Kevin and Daum{\'e} III, Hal},
  booktitle={International Conference on Machine Learning},
  pages={1804--1813},
  year={2016}
}

@inproceedings{sukhbaatar2016learning,
  title={Learning multiagent communication with backpropagation},
  author={Sukhbaatar, Sainbayar and Fergus, Rob and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2244--2252},
  year={2016}
}

@InProceedings{rashid2018qmix,
  title =    {{QMIX}: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning},
  author =   {Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  booktitle =    {Proceedings of the 35th International Conference on Machine Learning},
  pages =    {4295--4304},
  year =     {2018},
  volume =   {80},
  series =   {Proceedings of Machine Learning Research},
  address =      {Stockholmsmässan, Stockholm Sweden},
  month =    {10--15 Jul}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{sunehag2017value,
 author = {Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z. and Tuyls, Karl and Graepel, Thore},
 title = {Value-Decomposition Networks For Cooperative Multi-Agent Learning Based On Team Reward},
 booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
 series = {AAMAS '18},
 year = {2018},
 location = {Stockholm, Sweden},
 pages = {2085--2087},
 numpages = {3},

 acmid = {3238080},
 publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
 address = {Richland, SC},
}

@inproceedings{ba2014multiple,
  title={Multiple object recognition with visual attention},
  author={Ba, Jimmy and Mnih, Volodymyr and Kavukcuoglu, Koray},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@inproceedings{mnih2014recurrent,
  title={Recurrent models of visual attention},
  author={Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and others},
  booktitle={Advances in neural information processing systems},
  pages={2204--2212},
  year={2014}
}

@inproceedings{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@article{graves2014neural,
  title={Neural turing machines},
  author={Graves, Alex and Wayne, Greg and Danihelka, Ivo},
  journal={arXiv preprint arXiv:1410.5401},
  year={2014}
}

@inproceedings{oh2016control,
  title={Control of Memory, Active Perception, and Action in Minecraft},
  author={Oh, Junhyuk and Chockalingam, Valliappa and Lee, Honglak and others},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2016}
}

@ARTICLE{Choi2017-ef,
  title         = "Multi-focus Attention Network for Efficient Deep
                   Reinforcement Learning",
  author        = "Choi, Jinyoung and Lee, Beom-Jin and Zhang, Byoung-Tak",
  month         =  dec,
  year          =  2017,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "1712.04603",
  journal       = {arXiv preprint arXiv:1712.04603}
}

@ARTICLE{Espeholt2018-ub,
  title         = "{IMPALA}: Scalable Distributed {Deep-RL} with Importance
                   Weighted {Actor-Learner} Architectures",
  author        = "Espeholt, Lasse and Soyer, Hubert and Munos, Remi and
                   Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron,
                   Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and
                   Legg, Shane and Kavukcuoglu, Koray",
  month         =  feb,
  year          =  2018,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "1802.01561",
  journal       = {arXiv preprint arXiv:1802.01561}
}

@INCOLLECTION{La2013-ax,
  title     = "{Actor-Critic} Algorithms for {Risk-Sensitive} {MDPs}",
  booktitle = "Advances in Neural Information Processing Systems 26",
  author    = "L.a., Prashanth and Ghavamzadeh, Mohammad",
  editor    = "Burges, C J C and Bottou, L and Welling, M and Ghahramani, Z and
               Weinberger, K Q",
  publisher = "Curran Associates, Inc.",
  pages     = "252--260",
  year      =  2013
}

@InProceedings{Foerster2017-xt,
  title =    {Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning},
  author =   {Jakob Foerster and Nantas Nardelli and Gregory Farquhar and Triantafyllos Afouras and Philip H. S. Torr and Pushmeet Kohli and Shimon Whiteson},
  booktitle =    {Proceedings of the 34th International Conference on Machine Learning},
  pages =    {1146--1155},
  year =     {2017},
  volume =   {70},
  series =   {Proceedings of Machine Learning Research},
  address =      {International Convention Centre, Sydney, Australia},
  month =    {06--11 Aug}
}

@inproceedings{Foerster2017-do,
    author = {Jakob Foerster and Gregory Farquhar and Triantafyllos Afouras and Nantas Nardelli and Shimon Whiteson},
    title = {Counterfactual Multi-Agent Policy Gradients},
    booktitle = {AAAI Conference on Artificial Intelligence},
    year = {2018},
    keywords = {deep reinforcement learning; multi-­agent learning; actor­critic},

}

@InProceedings{Wang2015-ss,
  title =    {Dueling Network Architectures for Deep Reinforcement Learning},
  author =   {Ziyu Wang and Tom Schaul and Matteo Hessel and Hado Hasselt and Marc Lanctot and Nando Freitas},
  booktitle =    {Proceedings of The 33rd International Conference on Machine Learning},
  pages =    {1995--2003},
  year =     {2016},
  volume =   {48},
  series =   {Proceedings of Machine Learning Research},
  address =      {New York, New York, USA},
  month =    {20--22 Jun}
}

@inproceedings{Al-Shedivat2017-rh,
title={Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments},
author={Maruan Al-Shedivat and Trapit Bansal and Yura Burda and Ilya Sutskever and Igor Mordatch and Pieter Abbeel},
booktitle={International Conference on Learning Representations},
year={2018},
}

@ARTICLE{Stone2000-ue,
  title     = "Multiagent Systems: A Survey from a Machine Learning Perspective",
  author    = "Stone, Peter and Veloso, Manuela",
  journal   = "Auton. Robots",
  publisher = "Kluwer Academic Publishers",
  volume    =  8,
  number    =  3,
  pages     = "345--383",
  month     =  jun,
  year      =  2000,
  language  = "en"
}

@ARTICLE{Tampuu2017-dq,
  title    = "Multiagent cooperation and competition with deep reinforcement
              learning",
  author   = "Tampuu, Ardi and Matiisen, Tambet and Kodelja, Dorian and
              Kuzovkin, Ilya and Korjus, Kristjan and Aru, Juhan and Aru, Jaan
              and Vicente, Raul",
  journal  = "PLoS One",
  volume   =  12,
  number   =  4,
  pages    = "e0172395",
  month    =  apr,
  year     =  2017,
  language = "en"
}

@inproceedings{Bansal2017-qm,
title={Emergent Complexity via Multi-Agent Competition},
author={Trapit Bansal and Jakub Pachocki and Szymon Sidor and Ilya Sutskever and Igor Mordatch},
booktitle={International Conference on Learning Representations},
year={2018},
}

@INCOLLECTION{Lanctot2017-gr,
  title     = "A Unified {Game-Theoretic} Approach to Multiagent Reinforcement
               Learning",
  booktitle = "Advances in Neural Information Processing Systems 30",
  author    = "Lanctot, Marc and Zambaldi, Vinicius and Gruslys, Audrunas and
               Lazaridou, Angeliki and Tuyls, Karl and Perolat, Julien and
               Silver, David and Graepel, Thore",
  editor    = "Guyon, I and Luxburg, U V and Bengio, S and Wallach, H and
               Fergus, R and Vishwanathan, S and Garnett, R",
  publisher = "Curran Associates, Inc.",
  pages     = "4193--4206",
  year      =  2017
}

@inproceedings{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, OpenAI Pieter and Mordatch, Igor},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6382--6393},
  year={2017}
}

@INPROCEEDINGS{Gupta2017-cq,
  title      = "Cooperative Multi-agent Control Using Deep Reinforcement
                Learning",
  booktitle  = "Autonomous Agents and Multiagent Systems",
  author     = "Gupta, Jayesh K and Egorov, Maxim and Kochenderfer, Mykel",
  publisher  = "Springer, Cham",
  pages      = "66--83",
  series     = "Lecture Notes in Computer Science",
  month      =  may,
  year       =  2017,
  language   = "en",
  conference = "International Conference on Autonomous Agents and Multiagent
                Systems"
}

@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@incollection{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  booktitle={Reinforcement Learning},
  pages={5--32},
  year={1992},
  publisher={Springer}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000}
}

@inproceedings{lin2017structured,
  title={A structured self-attentive sentence embedding},
  author={Lin, Zhouhan and Feng, Minwei and Santos, Cicero Nogueira dos and Yu, Mo and Xiang, Bing and Zhou, Bowen and Bengio, Yoshua},
  booktitle={International Conference on Learning Representations},
  year={2017}
}

@inproceedings{foerster2016learning,
  title={Learning to communicate with deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Assael, Ioannis Alexandros and de Freitas, Nando and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2137--2145},
  year={2016}
}

@article{wei2018multiagent,
  title={Multiagent Soft Q-Learning},
  author={Wei, Ermo and Wicke, Drew and Freelan, David and Luke, Sean},
  journal={arXiv preprint arXiv:1804.09817},
  year={2018}
}

@inproceedings{jiang2018learning,
 author = {Jiang, Jiechuan and Lu, Zongqing},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {7254--7264},
 publisher = {Curran Associates, Inc.},
 title = {Learning Attentional Communication for Multi-Agent Cooperation},
 volume = {31},
 year = {2018}
}

@book{oliehoek2016concise,
  title={A concise introduction to decentralized POMDPs},
  author={Oliehoek, Frans A and Amato, Christopher and others},
  volume={1},
  year={2016},
  publisher={Springer}
}

@InProceedings{haarnoja2018soft,
  title =    {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author =   {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle =    {Proceedings of the 35th International Conference on Machine Learning},
  pages =    {1861--1870},
  year =     {2018},
  volume =   {80},
  series =   {Proceedings of Machine Learning Research},
  address =      {Stockholmsmässan, Stockholm Sweden},
  month =    {10--15 Jul},
}

@InProceedings{pmlr-v97-iqbal19a,
  title =    {Actor-Attention-Critic for Multi-Agent Reinforcement Learning},
  author =   {Iqbal, Shariq and Sha, Fei},
  booktitle =    {Proceedings of the 36th International Conference on Machine Learning},
  pages =    {2961--2970},
  year =     {2019},
  editor =   {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume =   {97},
  series =   {Proceedings of Machine Learning Research},
  address =      {Long Beach, California, USA},
  month =    {09--15 Jun},
  publisher =    {PMLR},
  pdf =      {http://proceedings.mlr.press/v97/iqbal19a/iqbal19a.pdf},
}

@inproceedings{burda2018exploration,
title={Exploration by random network distillation},
author={Yuri Burda and Harrison Edwards and Amos Storkey and Oleg Klimov},
booktitle={International Conference on Learning Representations},
year={2019},
}


@ARTICLE{Khan2018-qx,
  title   = "Toward Computational Motivation for {Multi-Agent} Systems and
             Swarms",
  author  = "Khan, Md Mohiuddin and Kasmarik, Kathryn and Barlow, Michael",
  journal = "Frontiers in Robotics and AI",
  volume  =  5,
  pages   = "134",
  year    =  2018
}

@ARTICLE{Jaques2018-gu,
  title         = "Social Influence as Intrinsic Motivation for {Multi-Agent}
                   Deep Reinforcement Learning",
  author        = "Jaques, Natasha and Lazaridou, Angeliki and Hughes, Edward
                   and Gulcehre, Caglar and Ortega, Pedro A and Strouse, D J
                   and Leibo, Joel Z and de Freitas, Nando",
  month         =  oct,
  year          =  2018,
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG",
  eprint        = "1810.08647",
  journal = {arXiv preprint arXiv:1810.08647},
}


@InProceedings{pmlr-v70-pathak17a,
  title =    {Curiosity-driven Exploration by Self-supervised Prediction},
  author =   {Deepak Pathak and Pulkit Agrawal and Alexei A. Efros and Trevor Darrell},
  booktitle =    {Proceedings of the 34th International Conference on Machine Learning},
  pages =    {2778--2787},
  year =     {2017},
  editor =   {Doina Precup and Yee Whye Teh},
  volume =   {70},
  series =   {Proceedings of Machine Learning Research},
  address =      {International Convention Centre, Sydney, Australia},
  month =    {06--11 Aug},
  publisher =    {PMLR},
  pdf =      {http://proceedings.mlr.press/v70/pathak17a/pathak17a.pdf},
  abstract =     {In many real-world scenarios, rewards extrinsic to the agent are extremely sparse, or absent altogether. In such cases, curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. We formulate curiosity as the error in an agent’s ability to predict the consequence of its own actions in a visual feature space learned by a self-supervised inverse dynamics model. Our formulation scales to high-dimensional continuous state spaces like images, bypasses the difficulties of directly predicting pixels, and, critically, ignores the aspects of the environment that cannot affect the agent. The proposed approach is evaluated in two environments: VizDoom and Super Mario Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where curiosity allows for far fewer interactions with the environment to reach the goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent to explore more efficiently; and 3) generalization to unseen scenarios (e.g. new levels of the same game) where the knowledge gained from earlier experience helps the agent explore new places much faster than starting from scratch.}
}

@article{STREHL20081309,
title = "An analysis of model-based Interval Estimation for Markov Decision Processes",
journal = "Journal of Computer and System Sciences",
volume = "74",
number = "8",
pages = "1309 - 1331",
year = "2008",
note = "Learning Theory 2005",
issn = "0022-0000",
doi = "https://doi.org/10.1016/j.jcss.2007.08.009",
author = "Alexander L. Strehl and Michael L. Littman",
keywords = "Reinforcement learning, Learning theory, Markov Decision Processes",
abstract = "Several algorithms for learning near-optimal policies in Markov Decision Processes have been analyzed and proven efficient. Empirical results have suggested that Model-based Interval Estimation (MBIE) learns efficiently in practice, effectively balancing exploration and exploitation. This paper presents a theoretical analysis of MBIE and a new variation called MBIE-EB, proving their efficiency even under worst-case conditions. The paper also introduces a new performance metric, average loss, and relates it to its less “online” cousins from the literature."
}

@inproceedings{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1471--1479},
  year={2016}
}

@inproceedings{ostrovski2017count,
  title={Count-based exploration with neural density models},
  author={Ostrovski, Georg and Bellemare, Marc G and van den Oord, A{\"a}ron and Munos, R{\'e}mi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2721--2730},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{tang2017exploration,
  title={\# Exploration: A study of count-based exploration for deep reinforcement learning},
  author={Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, OpenAI Xi and Duan, Yan and Schulman, John and DeTurck, Filip and Abbeel, Pieter},
  booktitle={Advances in neural information processing systems},
  pages={2753--2762},
  year={2017}
}

@article{oudeyer2009intrinsic,
  title={What is intrinsic motivation? A typology of computational approaches},
  author={Oudeyer, Pierre-Yves and Kaplan, Frederic},
  journal={Frontiers in neurorobotics},
  volume={1},
  pages={6},
  year={2009},
  publisher={Frontiers}
}

@inproceedings{houthooft2016vime,
  title={Vime: Variational information maximizing exploration},
  author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1109--1117},
  year={2016}
}

@article{DBLP:journals/corr/AchiamS17,
  author    = {Joshua Achiam and
               Shankar Sastry},
  title     = {Surprise-Based Intrinsic Motivation for Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1703.01732},
  year      = {2017},
  archivePrefix = {arXiv},
  eprint    = {1703.01732},
  timestamp = {Mon, 13 Aug 2018 16:46:25 +0200},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{verbeeck2005coordinated,
  title={Coordinated exploration in multi-agent reinforcement learning: an application to load-balancing},
  author={Verbeeck, Katja and Now{\'e}, Ann and Tuyls, Karl},
  booktitle={Proceedings of the fourth international joint conference on Autonomous agents and multiagent systems},
  pages={1105--1106},
  year={2005},
  organization={ACM}
}

@inproceedings{carmel1997exploration,
  title={Exploration and adaptation in multiagent systems: A model-based approach},
  author={Carmel, David and Markovitch, Shaul},
  booktitle={IJCAI (1)},
  pages={606--611},
  year={1997}
}

@article{khadka2019collaborative,
  title={Collaborative Evolutionary Reinforcement Learning},
  author={Khadka, Shauharda and Majumdar, Somdeb and Miret, Santiago and Tumer, Evren and Nassar, Tarek and Dwiel, Zach and Liu, Yinyin and Tumer, Kagan},
  journal={arXiv preprint arXiv:1905.00976},
  year={2019}
}

@inproceedings{Kempka2016ViZDoom,
  author    = {Micha{\l} Kempka and Marek Wydmuch and Grzegorz Runc and Jakub Toczek and Wojciech Ja\'skowski},
  title     = {{ViZDoom}: A {D}oom-based {AI} Research Platform for Visual Reinforcement Learning},
  booktitle = {IEEE Conference on Computational Intelligence and Games},  
  year      = {2016},
  address   = {Santorini, Greece},
  Month     = {Sep},
  Pages     = {341--348},
  Publisher = {IEEE},
  Note      = {The best paper award}
}

@article{agogino2008analyzing,
  title={Analyzing and visualizing multiagent rewards in dynamic and stochastic domains},
  author={Agogino, Adrian K and Tumer, Kagan},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={17},
  number={2},
  pages={320--338},
  year={2008},
  publisher={Springer}
}

@article{schmidhuber2010formal,
  title={Formal theory of creativity, fun, and intrinsic motivation (1990--2010)},
  author={Schmidhuber, J{\"u}rgen},
  journal={IEEE Transactions on Autonomous Mental Development},
  volume={2},
  number={3},
  pages={230--247},
  year={2010},
  publisher={IEEE}
}

@inproceedings{wang2020influencebased,
title={Influence-Based Multi-Agent Exploration},
author={Tonghan Wang and Jianhao Wang and Yi Wu and Chongjie Zhang},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{zheng2018learning,
  title={On learning intrinsic rewards for policy gradient methods},
  author={Zheng, Zeyu and Oh, Junhyuk and Singh, Satinder},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4644--4654},
  year={2018}
}

@inproceedings{Long2020Evolutionary,
title={Evolutionary Population Curriculum for Scaling Multi-Agent Reinforcement Learning},
author={Qian Long and Zihan Zhou and Abhinav Gupta and Fei Fang and Yi Wu and Xiaolong Wang},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{carion2019structured,
  title={A Structured Prediction Approach for Generalization in Cooperative Multi-Agent Reinforcement Learning},
  author={Carion, Nicolas and Usunier, Nicolas and Synnaeve, Gabriel and Lazaric, Alessandro},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8128--8138},
  year={2019}
}

@inproceedings{samvelyan2019starcraft,
  title={The starcraft multi-agent challenge},
  author={Samvelyan, Mikayel and Rashid, Tabish and Schroeder de Witt, Christian and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  booktitle={Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={2186--2188},
  year={2019},
  organization={International Foundation for Autonomous Agents and Multiagent Systems}
}

@article{agarwal2019learning,
  title={Learning transferable cooperative behavior in multi-agent teams},
  author={Agarwal, Akshat and Kumar, Sumit and Sycara, Katia},
  journal={arXiv preprint arXiv:1906.01202},
  year={2019}
}

@inproceedings{wang2020few,
  title={From Few to More: Large-scale Dynamic Multiagent Curriculum Learning},
  author={Wang, Weixun and Yang, Tianpei and Liu, Yong and Hao, Jianye and Hao, Xiaotian and Hu, Yujing and Chen, Yingfeng and Fan, Changjie and Gao, Yang},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2020}
}

@inproceedings{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle={NIPS 2014 Workshop on Deep Learning, December 2014},
  year={2014}
}

@incollection{NIPS2019_9184,
title = {Multi-Agent Common Knowledge Reinforcement Learning},
author = {Schroeder de Witt, Christian and Foerster, Jakob and Farquhar, Gregory and Torr, Philip and Boehmer, Wendelin and Whiteson, Shimon},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {9927--9939},
year = {2019},
publisher = {Curran Associates, Inc.},
}

@inproceedings{ha2016hypernetworks,
  title={HyperNetworks},
  author={Ha, David and Dai, Andrew M and Le, Quoc V},
  booktitle={International Conference on Learning Representations},
  year={2017}
}

@InProceedings{pmlr-v97-lee19d,
  title =    {Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks},
  author =   {Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
  booktitle =    {Proceedings of the 36th International Conference on Machine Learning},
  pages =    {3744--3753},
  year =     {2019},
  editor =   {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume =   {97},
  series =   {Proceedings of Machine Learning Research},
  address =      {Long Beach, California, USA},
  month =    {09--15 Jun},
  publisher =    {PMLR},
  pdf =      {http://proceedings.mlr.press/v97/lee19d/lee19d.pdf},
}

@InProceedings{Hasselt16,
 author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
 title = {Deep Reinforcement Learning with Double Q-Learning},
 booktitle = {Proceedings of the 13th AAAI Conference 
 				on Artificial Intelligence},
 OPTseries = {AAAI'16},
 year = {2016},
 pages = {2094--2100},
 numpages = {7},
}

@Article{Lin92,
	author="Lin, Long-Ji",
	title="Self-improving reactive agents based on reinforcement learning, planning and teaching",
	journal="Machine Learning",
	year="1992",
	volume="8",
	number="3",
	pages="293--321",
}

@inproceedings{Hausknecht15,
  author    = {Matthew J. Hausknecht and
               Peter Stone},
  title     = {Deep Recurrent Q-Learning for Partially Observable MDPs},
  booktitle = {2015 {AAAI} Fall Symposia},
  pages     = {29--37},
  year      = {2015},
}

@inproceedings{igl2019generalization,
  title={Generalization in reinforcement learning with selective noise injection and information bottleneck},
  author={Igl, Maximilian and Ciosek, Kamil and Li, Yingzhen and Tschiatschek, Sebastian and Zhang, Cheng and Devlin, Sam and Hofmann, Katja},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13956--13968},
  year={2019}
}

@inproceedings{cobbe2019quantifying,
  title={Quantifying Generalization in Reinforcement Learning},
  author={Cobbe, Karl and Klimov, Oleg and Hesse, Chris and Kim, Taehoon and Schulman, John},
  booktitle={International Conference on Machine Learning},
  pages={1282--1289},
  year={2019}
}

@article{clevert2015fast,
  title={Fast and accurate deep network learning by exponential linear units (elus)},
  author={Clevert, Djork-Arn{\'e} and Unterthiner, Thomas and Hochreiter, Sepp},
  journal={arXiv preprint arXiv:1511.07289},
  year={2015}
}

@inproceedings{stone2010ad,
  title={Ad hoc autonomous agent teams: Collaboration without pre-coordination},
  author={Stone, Peter and Kaminka, Gal A and Kraus, Sarit and Rosenschein, Jeffrey S},
  booktitle={Twenty-Fourth AAAI Conference on Artificial Intelligence},
  year={2010}
}

@inproceedings{barrett2011empirical,
  title={Empirical evaluation of ad hoc teamwork in the pursuit domain.},
  author={Barrett, Samuel and Stone, Peter and Kraus, Sarit},
  booktitle={AAMAS},
  pages={567--574},
  year={2011}
}

@article{hu2020other,
  title={" Other-Play" for Zero-Shot Coordination},
  author={Hu, Hengyuan and Lerer, Adam and Peysakhovich, Alex and Foerster, Jakob},
  journal={arXiv preprint arXiv:2003.02979},
  year={2020}
}

@inproceedings{oliehoek2008exploiting,
  title={Exploiting locality of interaction in factored Dec-POMDPs},
  author={Oliehoek, Frans A and Spaan, Matthijs TJ and Vlassis, Nikos and Whiteson, Shimon},
  booktitle={Int. Joint Conf. on Autonomous Agents and Multi-Agent Systems},
  pages={517--524},
  year={2008}
}

@inproceedings{ioffe2015batch,
  title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International Conference on Machine Learning},
  pages={448--456},
  year={2015}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@mastersthesis{burden_deep_2020,
	title = {Deep {Multi}-{Agent} {Reinforcement} {Learning} in {Starcraft} {II}},
	school = {University of Oxford},
	author = {Burden, Nicholas},
	year = {2020}
}

@InProceedings{boehmer2019dcg,
  author    = {Wendelin B{\"{o}}hmer and
               Vitaly Kurin and
               Shimon Whiteson},
  title     = {Deep Coordination Graphs},
  booktitle = {Proceedings of Machine Learning and Systems (ICML)}, 
  pages 		= {2611--2622},
  year      = {2020},
}

@article{kraemer2016multi,
  title={Multi-agent reinforcement learning as a rehearsal for decentralized planning},
  author={Kraemer, Landon and Banerjee, Bikramjit},
  journal={Neurocomputing},
  volume={190},
  pages={82--94},
  year={2016},
  publisher={Elsevier}
}

@article{tieleman2012lecture,
  title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, Tijmen and Hinton, Geoffrey},
  journal={COURSERA: Neural networks for machine learning},
  volume={4},
  number={2},
  pages={26--31},
  year={2012}
}

@inproceedings{son2019qtran,
  title={QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning},
  author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
  booktitle={International Conference on Machine Learning},
  pages={5887--5896},
  year={2019}
}

@inproceedings{koller1999computing,
  title={Computing factored value functions for policies in structured MDPs},
  author={Koller, Daphne and Parr, Ronald},
  booktitle={IJCAI},
  volume={99},
  pages={1332--1339},
  year={1999}
}

@inproceedings{baker2019emergent,
  title={Emergent Tool Use From Multi-Agent Autocurricula},
  author={Baker, Bowen and Kanitscheider, Ingmar and Markov, Todor and Wu, Yi and Powell, Glenn and McGrew, Bob and Mordatch, Igor},
  booktitle={International Conference on Learning Representations},
  year={2019}
}


@inproceedings{schneider_distributed_1999,
	title = {Distributed {Value} {Functions}},
	booktitle = {In {Proceedings} of the {Sixteenth} {International} {Conference} on {Machine} {Learning}},
	publisher = {Morgan Kaufmann},
	author = {Schneider, Jeff and Wong, Weng-Keen and Moore, Andrew and Riedmiller, Martin},
	year = {1999},
	pages = {371--378},
	file = {Citeseer - Full Text PDF:/Users/cs/Zotero/storage/GIRPX4TU/Schneider et al. - 1999 - Distributed Value Functions.pdf:application/pdf;Citeseer - Snapshot:/Users/cs/Zotero/storage/I58S6LX5/summary.html:text/html}
}

@inproceedings{guestrin_coordinated_2002,
	address = {San Francisco, CA, USA},
	series = {{ICML} '02},
	title = {Coordinated {Reinforcement} {Learning}},
	isbn = {978-1-55860-873-3},
	booktitle = {Proceedings of the {Nineteenth} {International} {Conference} on {Machine} {Learning}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Guestrin, Carlos and Lagoudakis, Michail G. and Parr, Ronald},
	month = jul,
	year = {2002},
	pages = {227--234}
}

@article{kok_collaborative_2006,
	title = {Collaborative {Multiagent} {Reinforcement} {Learning} by {Payoff} {Propagation}},
	volume = {7},
	issn = {1532-4435},
	journal = {The Journal of Machine Learning Research},
	author = {Kok, Jelle R. and Vlassis, Nikos},
	month = dec,
	year = {2006},
	pages = {1789--1828},
	file = {Full Text PDF:/Users/cs/Zotero/storage/EAWBDTJL/Kok and Vlassis - 2006 - Collaborative Multiagent Reinforcement Learning by.pdf:application/pdf}
}

@inproceedings{russell_q-decomposition_2003,
	address = {Washington, DC, USA},
	series = {{ICML}'03},
	title = {Q-decomposition for reinforcement learning agents},
	isbn = {978-1-57735-189-4},
	booktitle = {Proceedings of the {Twentieth} {International} {Conference} on {International} {Conference} on {Machine} {Learning}},
	publisher = {AAAI Press},
	author = {Russell, Stuart and Zimdars, Andrew L.},
	month = aug,
	year = {2003},
	pages = {656--663}
}


@phdthesis{hausknecht_cooperation_2016,
	type = {{PhD} thesis},
	title = {Cooperation and {Communication} in {Multiagent} {Deep} {Reinforcement} {Learning}},
	school = {The University of Texas at Austin},
	author = {Hausknecht, Matthew John},
	year = {2016}
}


@inproceedings{kuyer_multiagent_2008,
	address = {Berlin, Heidelberg},
	series = {{ECMLPKDD}'08},
	title = {Multiagent reinforcement learning for urban traffic control using coordination graphs},
	isbn = {978-3-540-87478-2},
	booktitle = {Proceedings of the 2008th {European} {Conference} on {Machine} {Learning} and {Knowledge} {Discovery} in {Databases} - {Volume} {Part} {I}},
	publisher = {Springer-Verlag},
	author = {Kuyer, Lior and Whiteson, Shimon and Bakker, Bram and Vlassis, Nikos},
	month = sep,
	year = {2008},
	keywords = {coordination graphs, max-plus, multiagent systems, reinforcement learning, traffic control},
	pages = {656--671}
}

@misc{pol_coordinated_2016,
	title = {Coordinated {Deep} {Reinforcement} {Learners} for {Traffic} {Light} {Control}},
	language = {en},
	author = {Pol, Elise van der and Oliehoek, Frans A.},
	year = {2016},
	file = {Snapshot:/Users/cs/Zotero/storage/V3UGWJFP/47632b66387d00d19b66e71560ba462847b78006.html:text/html}
}

@article{claus1998dynamics,
  title={The dynamics of reinforcement learning in cooperative multiagent systems},
  author={Claus, Caroline and Boutilier, Craig},
  journal={AAAI/IAAI},
  volume={1998},
  number={746-752},
  pages={2},
  year={1998}
}

@inproceedings{wang2020roma,
  title={Roma: Multi-agent reinforcement learning with emergent roles},
  author={Wang, Tonghan and Dong, Heng and Lesser, Victor and Zhang, Chongjie},
  booktitle={Proceedings of the 37th International Conference on Machine Learning},
  year={2020}
}

@inproceedings{wang2020action,
title={Action Semantics Network: Considering the Effects of Actions in Multiagent Systems},
author={Weixun Wang and Tianpei Yang and Yong Liu and Jianye Hao and Xiaotian Hao and Yujing Hu and Yingfeng Chen and Changjie Fan and Yang Gao},
booktitle={International Conference on Learning Representations},
year={2020},
}

@article{yang2020qatten,
  title={Qatten: A General Framework for Cooperative Multiagent Reinforcement Learning},
  author={Yang, Yaodong and Hao, Jianye and Liao, Ben and Shao, Kun and Chen, Guangyong and Liu, Wulong and Tang, Hongyao},
  journal={arXiv preprint arXiv:2002.03939},
  year={2020}
}

@inproceedings{mahajan2019maven,
  title={Maven: Multi-agent variational exploration},
  author={Mahajan, Anuj and Rashid, Tabish and Samvelyan, Mikayel and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7613--7624},
  year={2019}
}

@inproceedings{hu2021updet,
title={{\{}UPD{\}}eT: Universal Multi-agent {\{}RL{\}} via Policy Decoupling with Transformers},
author={Siyi Hu and Fengda Zhu and Xiaojun Chang and Xiaodan Liang},
booktitle={International Conference on Learning Representations},
year={2021},
}

@article{prorok2017impact,
  title={The impact of diversity on optimal control policies for heterogeneous robot swarms},
  author={Prorok, Amanda and Hsieh, M Ani and Kumar, Vijay},
  journal={IEEE Transactions on Robotics},
  volume={33},
  number={2},
  pages={346--358},
  year={2017},
  publisher={IEEE}
}

@article{JMLR:v21:20-081,
  author  = {Tabish Rashid and Mikayel Samvelyan and Christian Schroeder de Witt and Gregory Farquhar and Jakob Foerster and Shimon Whiteson},
  title   = {Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {178},
  pages   = {1-51},
}

@inproceedings{wang2021rode,
title={{\{}RODE{\}}: Learning Roles to Decompose Multi-Agent Tasks},
author={Tonghan Wang and Tarun Gupta and Anuj Mahajan and Bei Peng and Shimon Whiteson and Chongjie Zhang},
booktitle={International Conference on Learning Representations},
year={2021},
}
