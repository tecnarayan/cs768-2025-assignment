\begin{thebibliography}{10}

\bibitem{Szegedy2014IntriguingPO}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, D.~Erhan,
  Ian~J. Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{Hendrycks2019BenchmarkingNN}
Dan Hendrycks and Thomas~G. Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{geirhos2018imagenet}
Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix~A
  Wichmann, and Wieland Brendel.
\newblock Imagenet-trained cnns are biased towards texture; increasing shape
  bias improves accuracy and robustness.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{shamsabadi2020colorfool}
Ali~Shahin Shamsabadi, Ricardo Sanchez-Matilla, and Andrea Cavallaro.
\newblock Colorfool: Semantic adversarial colorization.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 1151--1160, 2020.

\bibitem{madry2018towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{engstrom2019learning}
Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Brandon
  Tran, and Aleksander Madry.
\newblock Learning perceptually-aligned representations via adversarial
  robustness.
\newblock {\em arXiv preprint arXiv:1906.00945}, 2(3):5, 2019.

\bibitem{ross2018improving}
Andrew Ross and Finale Doshi-Velez.
\newblock Improving the adversarial robustness and interpretability of deep
  neural networks by regularizing their input gradients.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem{ilyas2019adversarial}
Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon
  Tran, and Aleksander Madry.
\newblock Adversarial examples are not bugs, they are features.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{salman2020adversarially}
Hadi Salman, Andrew Ilyas, Logan Engstrom, Ashish Kapoor, and Aleksander Madry.
\newblock Do adversarially robust imagenet models transfer better?
\newblock {\em Advances in Neural Information Processing Systems},
  33:3533--3545, 2020.

\bibitem{wen2020towards}
Yuxin Wen, Shuai Li, and Kui Jia.
\newblock Towards understanding the regularization of adversarial robustness on
  neural networks.
\newblock In {\em International Conference on Machine Learning}, pages
  10225--10235. PMLR, 2020.

\bibitem{zhu2019freelb}
Chen Zhu, Yu~Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, and Jingjing Liu.
\newblock Freelb: Enhanced adversarial training for natural language
  understanding.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{ivgi2021achieving}
Maor Ivgi and Jonathan Berant.
\newblock Achieving model robustness through discrete adversarial training.
\newblock In {\em Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 1529--1544, 2021.

\bibitem{esser2021taming}
Patrick Esser, Robin Rombach, and Bjorn Ommer.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12873--12883, 2021.

\bibitem{jin2020bert}
Di~Jin, Zhijing Jin, Joey~Tianyi Zhou, and Peter Szolovits.
\newblock Is bert really robust? a strong baseline for natural language attack
  on text classification and entailment.
\newblock In {\em Proceedings of the AAAI conference on artificial
  intelligence}, volume~34, pages 8018--8025, 2020.

\bibitem{zang2020word}
Yuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Meng Zhang, Qun Liu, and
  Maosong Sun.
\newblock Word-level textual adversarial attacking as combinatorial
  optimization.
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}, pages 6066--6080, 2020.

\bibitem{alzantot2018generating}
Moustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani Srivastava,
  and Kai-Wei Chang.
\newblock Generating natural language adversarial examples.
\newblock In {\em Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pages 2890--2896, 2018.

\bibitem{duan2021advdrop}
Ranjie Duan, Yuefeng Chen, Dantong Niu, Yun Yang, A~Kai Qin, and Yuan He.
\newblock Advdrop: Adversarial attack to dnns by dropping information.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 7506--7515, 2021.

\bibitem{zhao2020towards}
Zhengyu Zhao, Zhuoran Liu, and Martha Larson.
\newblock Towards large yet imperceptible adversarial image perturbations with
  perceptual color distance.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 1039--1048, 2020.

\bibitem{he2021masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross
  Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 2022.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{tsipras2018robustness}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
  Aleksander Madry.
\newblock Robustness may be at odds with accuracy.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{zhang2019theoretically}
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El~Ghaoui, and
  Michael Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In {\em International conference on machine learning}, pages
  7472--7482. PMLR, 2019.

\bibitem{raghunathan2020understanding}
Aditi Raghunathan, Sang~Michael Xie, Fanny Yang, John Duchi, and Percy Liang.
\newblock Understanding and mitigating the tradeoff between robustness and
  accuracy.
\newblock In {\em International Conference on Machine Learning}, pages
  7909--7919. PMLR, 2020.

\bibitem{rade2021reducing}
Rahul Rade and Seyed-Mohsen Moosavi-Dezfooli.
\newblock Reducing excessive margin to achieve a better accuracy vs. robustness
  trade-off.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{lamb2019interpolated}
Alex Lamb, Vikas Verma, Juho Kannala, and Yoshua Bengio.
\newblock Interpolated adversarial training: Achieving robust neural networks
  without sacrificing too much accuracy.
\newblock In {\em Proceedings of the 12th ACM Workshop on Artificial
  Intelligence and Security}, pages 95--103, 2019.

\bibitem{xie2020adversarial}
Cihang Xie, Mingxing Tan, Boqing Gong, Jiang Wang, Alan~L Yuille, and Quoc~V
  Le.
\newblock Adversarial examples improve image recognition.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 819--828, 2020.

\bibitem{mei2021fast}
Jieru Mei, Yucheng Han, Yutong Bai, Yixiao Zhang, Yingwei Li, Xianhang Li, Alan
  Yuille, and Cihang Xie.
\newblock Fast advprop.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{herrmann2021pyramid}
Charles Herrmann, Kyle Sargent, Lu~Jiang, Ramin Zabih, Huiwen Chang, Ce~Liu,
  Dilip Krishnan, and Deqing Sun.
\newblock Pyramid adversarial training improves vit performance.
\newblock {\em arXiv preprint arXiv:2111.15121}, 2021.

\bibitem{gan2020large}
Zhe Gan, Yen-Chun Chen, Linjie Li, Chen Zhu, Yu~Cheng, and Jingjing Liu.
\newblock Large-scale adversarial training for vision-and-language
  representation learning.
\newblock In {\em NeurIPS}, 2020.

\bibitem{gokhale2021attribute}
Tejas Gokhale, Rushil Anirudh, Bhavya Kailkhura, Jayaraman~J Thiagarajan,
  Chitta Baral, and Yezhou Yang.
\newblock Attribute-guided adversarial training for robustness to natural
  perturbations.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 7574--7582, 2021.

\bibitem{zhang2019adversarial}
Xinyu Zhang, Qiang Wang, Jian Zhang, and Zhao Zhong.
\newblock Adversarial autoaugment.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{wang2021augmax}
Haotao Wang, Chaowei Xiao, Jean Kossaifi, Zhiding Yu, Anima Anandkumar, and
  Zhangyang Wang.
\newblock Augmax: Adversarial composition of random augmentations for robust
  training.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{calian2021defending}
Dan~Andrei Calian, Florian Stimberg, Olivia Wiles, Sylvestre-Alvise Rebuffi,
  Andr{\'a}s Gy{\"o}rgy, Timothy~A Mann, and Sven Gowal.
\newblock Defending against image corruptions through adversarial
  augmentations.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{hendrycks2019augmix}
Dan Hendrycks, Norman Mu, Ekin~Dogus Cubuk, Barret Zoph, Justin Gilmer, and
  Balaji Lakshminarayanan.
\newblock Augmix: A simple data processing method to improve robustness and
  uncertainty.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{gong2021maxup}
Chengyue Gong, Tongzheng Ren, Mao Ye, and Qiang Liu.
\newblock Maxup: Lightweight adversarial training with data augmentation
  improves neural network training.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 2474--2483, 2021.

\bibitem{sivic2003video}
Josef Sivic and Andrew Zisserman.
\newblock Video google: A text retrieval approach to object matching in videos.
\newblock In {\em Computer Vision, IEEE International Conference on}, volume~3,
  pages 1470--1470. IEEE Computer Society, 2003.

\bibitem{csurka2004visual}
Gabriella Csurka, Christopher Dance, Lixin Fan, Jutta Willamowski, and
  C{\'e}dric Bray.
\newblock Visual categorization with bags of keypoints.
\newblock In {\em Workshop on statistical learning in computer vision, ECCV},
  volume~1, pages 1--2. Prague, 2004.

\bibitem{van2017neural}
Aaron Van Den~Oord, Oriol Vinyals, et~al.
\newblock Neural discrete representation learning.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{bao2021beit}
Hangbo Bao, Li~Dong, and Furu Wei.
\newblock Beit: Bert pre-training of image transformers.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{zhou2021ibot}
Jinghao Zhou, Chen Wei, Huiyu Wang, Wei Shen, Cihang Xie, Alan Yuille, and Tao
  Kong.
\newblock ibot: Image bert pre-training with online tokenizer.
\newblock {\em arXiv preprint arXiv:2111.07832}, 2021.

\bibitem{mao2021discrete}
Chengzhi Mao, Lu~Jiang, Mostafa Dehghani, Carl Vondrick, Rahul Sukthankar, and
  Irfan Essa.
\newblock Discrete representations strengthen vision transformer robustness.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{rombach2021high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock {\em arXiv preprint arXiv:2112.10752}, 2021.

\bibitem{bengio2013estimating}
Yoshua Bengio, Nicholas L{\'e}onard, and Aaron Courville.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock {\em arXiv preprint arXiv:1308.3432}, 2013.

\bibitem{yin2019understanding}
Penghang Yin, Jiancheng Lyu, Shuai Zhang, Stanley Osher, Yingyong Qi, and Jack
  Xin.
\newblock Understanding straight-through estimator in training activation
  quantized neural nets.
\newblock {\em arXiv preprint arXiv:1903.05662}, 2019.

\bibitem{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In {\em International conference on machine learning}, pages
  448--456. PMLR, 2015.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{hendrycks2021many}
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan
  Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et~al.
\newblock The many faces of robustness: A critical analysis of
  out-of-distribution generalization.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 8340--8349, 2021.

\bibitem{steiner2021train}
Andreas Steiner, Alexander Kolesnikov, Xiaohua Zhai, Ross Wightman, Jakob
  Uszkoreit, and Lucas Beyer.
\newblock How to train your vit? data, augmentation, and regularization in
  vision transformers.
\newblock {\em arXiv preprint arXiv:2106.10270}, 2021.

\bibitem{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em arXiv preprint arXiv:1412.6572}, 2014.

\bibitem{chen2020universal}
Sizhe Chen, Zhengbao He, Chengjin Sun, Jie Yang, and Xiaolin Huang.
\newblock Universal adversarial attack on attention and the resulting dataset
  damagenet.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  2020.

\bibitem{hendrycks2021natural}
Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song.
\newblock Natural adversarial examples.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15262--15271, 2021.

\bibitem{hendrycks2018benchmarking}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{wang2019learning}
Haohan Wang, Songwei Ge, Zachary Lipton, and Eric~P Xing.
\newblock Learning robust global representations by penalizing local predictive
  power.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{zhang2018mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{yun2019cutmix}
Sangdoo Yun, Dongyoon Han, Seong~Joon Oh, Sanghyuk Chun, Junsuk Choe, and
  Youngjoon Yoo.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 6023--6032, 2019.

\bibitem{cubuk2020randaugment}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition Workshops}, pages 702--703, 2020.

\bibitem{li2020shape}
Yingwei Li, Qihang Yu, Mingxing Tan, Jieru Mei, Peng Tang, Wei Shen, Alan
  Yuille, et~al.
\newblock Shape-texture debiased neural network training.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In {\em International conference on machine learning}, pages
  1597--1607. PMLR, 2020.

\bibitem{chen2021exploring}
Xinlei Chen and Kaiming He.
\newblock Exploring simple siamese representation learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15750--15758, 2021.

\bibitem{chen2021empirical}
Xinlei Chen, Saining Xie, and Kaiming He.
\newblock An empirical study of training self-supervised vision transformers.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9640--9649, 2021.

\bibitem{ericsson2021well}
Linus Ericsson, Henry Gouk, and Timothy~M Hospedales.
\newblock How well do self-supervised models transfer?
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 5414--5423, 2021.

\bibitem{kim2020adversarial}
Minseon Kim, Jihoon Tack, and Sung~Ju Hwang.
\newblock Adversarial self-supervised contrastive learning.
\newblock {\em Advances in Neural Information Processing Systems},
  33:2983--2994, 2020.

\bibitem{everingham2010pascal}
Mark Everingham, Luc Van~Gool, Christopher~KI Williams, John Winn, and Andrew
  Zisserman.
\newblock The pascal visual object classes (voc) challenge.
\newblock {\em International journal of computer vision}, 88(2):303--338, 2010.

\bibitem{zhou2017scene}
Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio
  Torralba.
\newblock Scene parsing through ade20k dataset.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 633--641, 2017.

\bibitem{tan2020efficientdet}
Mingxing Tan, Ruoming Pang, and Quoc~V Le.
\newblock Efficientdet: Scalable and efficient object detection.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 10781--10790, 2020.

\bibitem{redmon2018yolov3}
Joseph Redmon and Ali Farhadi.
\newblock Yolov3: An incremental improvement.
\newblock {\em arXiv preprint arXiv:1804.02767}, 2018.

\bibitem{chen2021robust}
Xiangning Chen, Cihang Xie, Mingxing Tan, Li~Zhang, Cho-Jui Hsieh, and Boqing
  Gong.
\newblock Robust and accurate object detection via adversarial learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 16622--16631, 2021.

\bibitem{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em European conference on computer vision}, pages 740--755.
  Springer, 2014.

\bibitem{michaelis2019benchmarking}
Claudio Michaelis, Benjamin Mitzkus, Robert Geirhos, Evgenia Rusak, Oliver
  Bringmann, Alexander~S Ecker, Matthias Bethge, and Wieland Brendel.
\newblock Benchmarking robustness in object detection: Autonomous driving when
  winter is coming.
\newblock {\em arXiv preprint arXiv:1907.07484}, 2019.

\bibitem{kuznetsova2020open}
Alina Kuznetsova, Hassan Rom, Neil Alldrin, Jasper Uijlings, Ivan Krasin, Jordi
  Pont-Tuset, Shahab Kamali, Stefan Popov, Matteo Malloci, Alexander
  Kolesnikov, et~al.
\newblock The open images dataset v4.
\newblock {\em International Journal of Computer Vision}, 128(7):1956--1981,
  2020.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem{ramesh2021zero}
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec
  Radford, Mark Chen, and Ilya Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock In {\em International Conference on Machine Learning}, pages
  8821--8831. PMLR, 2021.

\bibitem{croce2020reliable}
Francesco Croce and Matthias Hein.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In {\em International conference on machine learning}, pages
  2206--2216. PMLR, 2020.

\bibitem{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock {\em Advances in neural information processing systems}, 27, 2014.

\end{thebibliography}
