\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{MMS{\etalchar{+}}18b}

\bibitem[ACW18]{athalye2018obfuscated}
Anish Athalye, Nicholas Carlini, and David Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock {\em arXiv preprint arXiv:1802.00420, International Conference on
  Machine Learning}, 2018.

\bibitem[BCM{\etalchar{+}}13]{biggio2013evasion}
Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim
  {{S}}rndi{\'c}, Pavel Laskov, Giorgio Giacinto, and Fabio Roli.
\newblock Evasion attacks against machine learning at test time.
\newblock In {\em Joint European conference on machine learning and knowledge
  discovery in databases}, pages 387--402. Springer, 2013.

\bibitem[BDOW20]{bartl2020robust}
Daniel Bartl, Samuel Drapeau, Jan Obloj, and Johannes Wiesel.
\newblock Robust uncertainty sensitivity analysis.
\newblock {\em arXiv preprint arXiv:2006.12022}, 2020.

\bibitem[CBG{\etalchar{+}}17]{cisse2017parseval}
Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, and Nicolas
  Usunier.
\newblock Parseval networks: Improving robustness to adversarial examples.
\newblock {\em arXiv preprint arXiv:1704.08847, International Conference on
  Machine Learning}, 2017.

\bibitem[CMV{\etalchar{+}}16]{carlini2016hidden}
Nicholas Carlini, Pratyush Mishra, Tavish Vaidya, Yuankai Zhang, Micah Sherr,
  Clay Shields, David Wagner, and Wenchao Zhou.
\newblock Hidden voice commands.
\newblock In {\em 25th $\{$USENIX$\}$ Security Symposium ($\{$USENIX$\}$
  Security 16)}, pages 513--530, 2016.

\bibitem[CW17]{carlini2017adversarial}
Nicholas Carlini and David Wagner.
\newblock Adversarial examples are not easily detected: Bypassing ten detection
  methods.
\newblock In {\em Proceedings of the 10th ACM Workshop on Artificial
  Intelligence and Security}, pages 3--14, 2017.

\bibitem[CYB17]{chen2017adversarial}
Lingwei Chen, Yanfang Ye, and Thirimachos Bourlai.
\newblock Adversarial machine learning in malware detection: Arms race between
  evasion attack and defense.
\newblock In {\em 2017 European Intelligence and Security Informatics
  Conference (EISIC)}, pages 99--106. IEEE, 2017.

\bibitem[Dan17]{daniely2017sgd}
Amit Daniely.
\newblock Sgd learns the conjugate kernel class of the network.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2422--2430, 2017.

\bibitem[DFS16]{daniely2016toward}
Amit Daniely, Roy Frostig, and Yoram Singer.
\newblock Toward deeper understanding of neural networks: The power of
  initialization and a dual view on expressivity.
\newblock In {\em Advances In Neural Information Processing Systems}, pages
  2253--2261, 2016.

\bibitem[DHHR20]{dobriban2020provable}
Edgar Dobriban, Hamed Hassani, David Hong, and Alexander Robey.
\newblock Provable tradeoffs in adversarially robust classification.
\newblock {\em arXiv preprint arXiv:2006.05161}, 2020.

\bibitem[GCK20]{gao2017wasserstein}
Rui Gao, Xi~Chen, and Anton~J Kleywegt.
\newblock Wasserstein distributionally robust optimization and variation
  regularization.
\newblock {\em arXiv preprint arXiv:1712.06050v3}, 2020.

\bibitem[GK16]{gao2016distributionally}
Rui Gao and Anton~J Kleywegt.
\newblock Distributionally robust stochastic optimization with wasserstein
  distance.
\newblock {\em arXiv preprint arXiv:1604.02199}, 2016.

\bibitem[GSS15a]{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em arXiv preprint arXiv:1412.6572, International Conference on
  Learning Representations}, 2015.

\bibitem[GSS15b]{DBLP:journals/corr/GoodfellowSS14}
Ian~J. Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In {\em 3rd International Conference on Learning Representations,
  {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track
  Proceedings}, 2015.

\bibitem[JGH18]{jacot2018neural}
Arthur Jacot, Franck Gabriel, and Cl{\'e}ment Hongler.
\newblock Neural tangent kernel: Convergence and generalization in neural
  networks.
\newblock In {\em Advances in neural information processing systems}, pages
  8571--8580, 2018.

\bibitem[JS20]{javanmard2020precise}
Adel Javanmard and Mahdi Soltanolkotabi.
\newblock Precise statistical analysis of classification accuracies for
  adversarial training.
\newblock {\em arXiv preprint arXiv:2010.11213}, 2020.

\bibitem[JSH20]{pmlr-v125-javanmard20a}
Adel Javanmard, Mahdi Soltanolkotabi, and Hamed Hassani.
\newblock Precise tradeoffs in adversarial training for linear regression.
\newblock volume 125 of {\em Proceedings of Machine Learning Research,
  Conference of Learning Theory (COLT)}, pages 2034--2078. PMLR, 09--12 Jul
  2020.

\bibitem[KGB16]{kurakin2016adversarial}
Alexey Kurakin, Ian Goodfellow, and Samy Bengio.
\newblock Adversarial machine learning at scale.
\newblock {\em arXiv preprint arXiv:1611.01236}, 2016.

\bibitem[LL18]{li2018learning}
Yuanzhi Li and Yingyu Liang.
\newblock Learning overparameterized neural networks via stochastic gradient
  descent on structured data.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  8157--8166, 2018.

\bibitem[MM19]{mei2019generalization}
Song Mei and Andrea Montanari.
\newblock The generalization error of random features regression: Precise
  asymptotics and double descent curve.
\newblock {\em arXiv preprint arXiv:1908.05355}, 2019.

\bibitem[MMS{\etalchar{+}}18a]{DBLP:conf/iclr/MadryMSTV18}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In {\em 6th International Conference on Learning Representations,
  {ICLR} 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track
  Proceedings}, 2018.

\bibitem[MMS{\etalchar{+}}18b]{madry2017towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em arXiv preprint arXiv:1706.06083, International Conference on
  Learning Representations}, 2018.

\bibitem[PMG{\etalchar{+}}17]{papernot2017practical}
Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z~Berkay Celik,
  and Ananthram Swami.
\newblock Practical black-box attacks against machine learning.
\newblock In {\em Proceedings of the 2017 ACM on Asia conference on computer
  and communications security}, pages 506--519, 2017.

\bibitem[PMSH16]{papernot2016crafting}
Nicolas Papernot, Patrick McDaniel, Ananthram Swami, and Richard Harang.
\newblock Crafting adversarial input sequences for recurrent neural networks.
\newblock In {\em MILCOM 2016-2016 IEEE Military Communications Conference},
  pages 49--54. IEEE, 2016.

\bibitem[PMW{\etalchar{+}}16]{papernot2016distillation}
Nicolas Papernot, Patrick McDaniel, Xi~Wu, Somesh Jha, and Ananthram Swami.
\newblock Distillation as a defense to adversarial perturbations against deep
  neural networks.
\newblock In {\em 2016 IEEE Symposium on Security and Privacy (SP)}, pages
  582--597. IEEE, 2016.

\bibitem[RR07]{rahimi2007random}
Ali Rahimi and Benjamin Recht.
\newblock Random features for large-scale kernel machines.
\newblock {\em Advances in neural information processing systems},
  20:1177--1184, 2007.

\bibitem[RSL18]{DBLP:conf/iclr/RaghunathanSL18}
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
\newblock Certified defenses against adversarial examples.
\newblock In {\em 6th International Conference on Learning Representations,
  {ICLR} 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track
  Proceedings}, 2018.

\bibitem[RXY{\etalchar{+}}19]{raghunathan2019adversarial}
Aditi Raghunathan, Sang~Michael Xie, Fanny Yang, John~C Duchi, and Percy Liang.
\newblock Adversarial training can hurt generalization.
\newblock {\em arXiv preprint arXiv:1906.06032}, 2019.

\bibitem[SJL18]{soltanolkotabi2018theoretical}
Mahdi Soltanolkotabi, Adel Javanmard, and Jason~D Lee.
\newblock Theoretical insights into the optimization landscape of
  over-parameterized shallow neural networks.
\newblock {\em IEEE Transactions on Information Theory}, 65(2):742--769, 2018.

\bibitem[SZS{\etalchar{+}}14]{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock {\em International Conference on Learning Representations (ICLR)},
  2014.

\bibitem[TPT20]{taheri2020asymptotic}
Hossein Taheri, Ramtin Pedarsani, and Christos Thrampoulidis.
\newblock Asymptotic behavior of adversarial training in binary classification.
\newblock {\em arXiv preprint arXiv:2010.13275}, 2020.

\bibitem[TSE{\etalchar{+}}18]{tsipras2018robustness}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
  Aleksander Madry.
\newblock Robustness may be at odds with accuracy.
\newblock {\em arXiv preprint arXiv:1805.12152}, 2018.

\bibitem[VZSS15]{vaidya2015cocaine}
Tavish Vaidya, Yuankai Zhang, Micah Sherr, and Clay Shields.
\newblock Cocaine noodles: exploiting the gap between human and machine speech
  recognition.
\newblock In {\em 9th $\{$USENIX$\}$ Workshop on Offensive Technologies
  ($\{$WOOT$\}$ 15)}, 2015.

\bibitem[WK18]{DBLP:conf/icml/WongK18}
Eric Wong and J.~Zico Kolter.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In {\em Proceedings of the 35th International Conference on Machine
  Learning, {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15,
  2018}, pages 5283--5292, 2018.

\bibitem[ZYJ{\etalchar{+}}17]{zhang2017dolphinattack}
Guoming Zhang, Chen Yan, Xiaoyu Ji, Tianchen Zhang, Taimin Zhang, and Wenyuan
  Xu.
\newblock Dolphinattack: Inaudible voice commands.
\newblock In {\em Proceedings of the 2017 ACM SIGSAC Conference on Computer and
  Communications Security}, pages 103--117, 2017.

\end{thebibliography}
