\begin{thebibliography}{34}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andreas et~al.(2016)Andreas, Rohrbach, Darrell, and
  Klein]{andreas2016neural}
Andreas, J., Rohrbach, M., Darrell, T., and Klein, D.
\newblock Neural module networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  39--48, 2016.

\bibitem[Baars(1997)]{baars1997theatre}
Baars, B.~J.
\newblock In the theatre of consciousness. global workspace theory, a rigorous
  scientific theory of consciousness.
\newblock \emph{Journal of Consciousness Studies}, 4\penalty0 (4):\penalty0
  292--309, 1997.

\bibitem[Bahdanau et~al.(2015)Bahdanau, Cho, and Bengio]{Bahdanau2015NeuralMT}
Bahdanau, D., Cho, K., and Bengio, Y.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock \emph{ICLR'2015}, arXiv:1409.0473, 2015.

\bibitem[Battaglia et~al.(2018)Battaglia, Hamrick, Bapst, Sanchez-Gonzalez,
  Zambaldi, Malinowski, Tacchetti, Raposo, Santoro, Faulkner,
  et~al.]{battaglia2018relational}
Battaglia, P.~W., Hamrick, J.~B., Bapst, V., Sanchez-Gonzalez, A., Zambaldi,
  V., Malinowski, M., Tacchetti, A., Raposo, D., Santoro, A., Faulkner, R.,
  et~al.
\newblock Relational inductive biases, deep learning, and graph networks.
\newblock \emph{arXiv preprint arXiv:1806.01261}, 2018.

\bibitem[Bengio(2013)]{bengio2013deep}
Bengio, Y.
\newblock Deep learning of representations: Looking forward.
\newblock In \emph{International conference on statistical language and speech
  processing}, pp.\  1--37. Springer, 2013.

\bibitem[Bengio(2017)]{bengio2017consciousness}
Bengio, Y.
\newblock The consciousness prior.
\newblock \emph{arXiv preprint arXiv:1709.08568}, 2017.

\bibitem[Bengio et~al.(2019)Bengio, Deleu, Rahaman, Ke, Lachapelle, Bilaniuk,
  Goyal, and Pal]{bengio2019meta}
Bengio, Y., Deleu, T., Rahaman, N., Ke, N.~R., Lachapelle, S., Bilaniuk, O.,
  Goyal, A., and Pal, C.
\newblock A meta-transfer objective for learning to disentangle causal
  mechanisms.
\newblock In \emph{ICLR'2020, arXiv:1901.10912}, 2019.

\bibitem[Csord{\'a}s et~al.(2020)Csord{\'a}s, van Steenkiste, and
  Schmidhuber]{csordas2020neural}
Csord{\'a}s, R., van Steenkiste, S., and Schmidhuber, J.
\newblock Are neural nets modular? inspecting functional modularity through
  differentiable weight masks.
\newblock \emph{arXiv preprint arXiv:2010.02066}, 2020.

\bibitem[Cui \& Jaech(2020)Cui and Jaech]{cui2020re}
Cui, L. and Jaech, A.
\newblock Re-examining routing networks for multi-task learning.
\newblock 2020.

\bibitem[Dehaene et~al.(2017)Dehaene, Lau, and Kouider]{Dehaene-et-al-2017}
Dehaene, S., Lau, H., and Kouider, S.
\newblock What is consciousness, and could machines have it?
\newblock \emph{Science}, 358\penalty0 (6362):\penalty0 486--492, 2017.

\bibitem[Du et~al.(2021)Du, Huang, Dai, Tong, Lepikhin, Xu, Krikun, Zhou, Yu,
  Firat, et~al.]{du2021glam}
Du, N., Huang, Y., Dai, A.~M., Tong, S., Lepikhin, D., Xu, Y., Krikun, M.,
  Zhou, Y., Yu, A.~W., Firat, O., et~al.
\newblock Glam: Efficient scaling of language models with mixture-of-experts.
\newblock \emph{arXiv preprint arXiv:2112.06905}, 2021.

\bibitem[Fedus et~al.(2021)Fedus, Zoph, and Shazeer]{fedus2021switch}
Fedus, W., Zoph, B., and Shazeer, N.
\newblock Switch transformers: Scaling to trillion parameter models with simple
  and efficient sparsity.
\newblock \emph{arXiv preprint arXiv:2101.03961}, 2021.

\bibitem[Goyal \& Bengio(2020)Goyal and Bengio]{goyal2020inductive}
Goyal, A. and Bengio, Y.
\newblock Inductive biases for deep learning of higher-level cognition.
\newblock \emph{arXiv preprint arXiv:2011.15091}, 2020.

\bibitem[Goyal et~al.(2019)Goyal, Lamb, Hoffmann, Sodhani, Levine, Bengio, and
  Sch{\"o}lkopf]{goyal2019recurrent}
Goyal, A., Lamb, A., Hoffmann, J., Sodhani, S., Levine, S., Bengio, Y., and
  Sch{\"o}lkopf, B.
\newblock Recurrent independent mechanisms.
\newblock \emph{arXiv preprint arXiv:1909.10893}, 2019.

\bibitem[Goyal et~al.(2021)Goyal, Didolkar, Ke, Blundell, Beaudoin, Heess,
  Mozer, and Bengio]{goyal2021neural}
Goyal, A., Didolkar, A., Ke, N.~R., Blundell, C., Beaudoin, P., Heess, N.,
  Mozer, M., and Bengio, Y.
\newblock Neural production systems.
\newblock \emph{arXiv preprint arXiv:2103.01937}, 2021.

\bibitem[Graves et~al.(2014)Graves, Wayne, and Danihelka]{graves2014neural}
Graves, A., Wayne, G., and Danihelka, I.
\newblock Neural turing machines.
\newblock \emph{arXiv preprint arXiv:1410.5401}, 2014.

\bibitem[Higgins et~al.(2016)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{higgins2016beta}
Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M.,
  Mohamed, S., and Lerchner, A.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock 2016.

\bibitem[Hu et~al.(2017)Hu, Andreas, Rohrbach, Darrell, and
  Saenko]{hu2017learning}
Hu, R., Andreas, J., Rohrbach, M., Darrell, T., and Saenko, K.
\newblock Learning to reason: End-to-end module networks for visual question
  answering.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  804--813, 2017.

\bibitem[Ke et~al.(2021)Ke, Didolkar, Mittal, Goyal, Lajoie, Bauer, Rezende,
  Mozer, Bengio, and Pal]{ke2021systematic}
Ke, N.~R., Didolkar, A.~R., Mittal, S., Goyal, A., Lajoie, G., Bauer, S.,
  Rezende, D.~J., Mozer, M.~C., Bengio, Y., and Pal, C.
\newblock Systematic evaluation of causal discovery in visual model based
  reinforcement learning.
\newblock 2021.

\bibitem[Kim \& Mnih(2018)Kim and Mnih]{kim2018disentangling}
Kim, H. and Mnih, A.
\newblock Disentangling by factorising.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2649--2658. PMLR, 2018.

\bibitem[Kipf et~al.(2018)Kipf, Fetaya, Wang, Welling, and
  Zemel]{kipf2018neural}
Kipf, T., Fetaya, E., Wang, K.-C., Welling, M., and Zemel, R.
\newblock Neural relational inference for interacting systems.
\newblock \emph{arXiv preprint arXiv:1802.04687}, 2018.

\bibitem[Kuhn(1955)]{kuhn1955hungarian}
Kuhn, H.~W.
\newblock The hungarian method for the assignment problem.
\newblock \emph{Naval research logistics quarterly}, 2\penalty0 (1-2):\penalty0
  83--97, 1955.

\bibitem[Locatello et~al.(2020)Locatello, Weissenborn, Unterthiner, Mahendran,
  Heigold, Uszkoreit, Dosovitskiy, and Kipf]{locatello2020object}
Locatello, F., Weissenborn, D., Unterthiner, T., Mahendran, A., Heigold, G.,
  Uszkoreit, J., Dosovitskiy, A., and Kipf, T.
\newblock Object-centric learning with slot attention.
\newblock \emph{arXiv preprint arXiv:2006.15055}, 2020.

\bibitem[Madan et~al.(2021)Madan, Ke, Goyal, Sch{\"o}lkopf, and
  Bengio]{madan2021fast}
Madan, K., Ke, R.~N., Goyal, A., Sch{\"o}lkopf, B.~B., and Bengio, Y.
\newblock Fast and slow learning of recurrent independent mechanisms.
\newblock \emph{arXiv preprint arXiv:2105.08710}, 2021.

\bibitem[Masoudnia \& Ebrahimpour(2014)Masoudnia and
  Ebrahimpour]{masoudnia2014mixture}
Masoudnia, S. and Ebrahimpour, R.
\newblock Mixture of experts: a literature survey.
\newblock \emph{Artificial Intelligence Review}, 42\penalty0 (2):\penalty0
  275--293, 2014.

\bibitem[Maziarz et~al.(2019)Maziarz, Kokiopoulou, Gesmundo, Sbaiz, Bartok, and
  Berent]{maziarz2019flexible}
Maziarz, K., Kokiopoulou, E., Gesmundo, A., Sbaiz, L., Bartok, G., and Berent,
  J.
\newblock Flexible multi-task networks by learning parameter allocation.
\newblock \emph{arXiv preprint arXiv:1910.04915}, 2019.

\bibitem[Mittal et~al.(2020)Mittal, Lamb, Goyal, Voleti, Shanahan, Lajoie,
  Mozer, and Bengio]{mittal2020learning}
Mittal, S., Lamb, A., Goyal, A., Voleti, V., Shanahan, M., Lajoie, G., Mozer,
  M., and Bengio, Y.
\newblock Learning to combine top-down and bottom-up signals in recurrent
  neural networks with attention over modules.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  6972--6986. PMLR, 2020.

\bibitem[Mittal et~al.(2021)Mittal, Raparthy, Rish, Bengio, and
  Lajoie]{mittal2021compositional}
Mittal, S., Raparthy, S.~C., Rish, I., Bengio, Y., and Lajoie, G.
\newblock Compositional attention: Disentangling search and retrieval.
\newblock \emph{arXiv preprint arXiv:2110.09419}, 2021.

\bibitem[Peters et~al.(2017)Peters, Janzing, and
  Sch{\"o}lkopf]{peters2017elements}
Peters, J., Janzing, D., and Sch{\"o}lkopf, B.
\newblock \emph{Elements of causal inference: foundations and learning
  algorithms}.
\newblock The MIT Press, 2017.

\bibitem[Rahaman et~al.(2021)Rahaman, Gondal, Joshi, Gehler, Bengio, Locatello,
  and Sch{\"o}lkopf]{rahaman2021dynamic}
Rahaman, N., Gondal, M.~W., Joshi, S., Gehler, P., Bengio, Y., Locatello, F.,
  and Sch{\"o}lkopf, B.
\newblock Dynamic inference with neural interpreters.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Rosenbaum et~al.(2019)Rosenbaum, Cases, Riemer, and
  Klinger]{rosenbaum2019routing}
Rosenbaum, C., Cases, I., Riemer, M., and Klinger, T.
\newblock Routing networks and the challenges of modular and compositional
  computation.
\newblock \emph{arXiv preprint arXiv:1904.12774}, 2019.

\bibitem[Santoro et~al.(2018)Santoro, Faulkner, Raposo, Rae, Chrzanowski,
  Weber, Wierstra, Vinyals, Pascanu, and Lillicrap]{santoro2018relational}
Santoro, A., Faulkner, R., Raposo, D., Rae, J., Chrzanowski, M., Weber, T.,
  Wierstra, D., Vinyals, O., Pascanu, R., and Lillicrap, T.
\newblock Relational recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1806.01822}, 2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  5998--6008, 2017.

\bibitem[Yuksel et~al.(2012)Yuksel, Wilson, and Gader]{yuksel2012twenty}
Yuksel, S.~E., Wilson, J.~N., and Gader, P.~D.
\newblock Twenty years of mixture of experts.
\newblock \emph{IEEE transactions on neural networks and learning systems},
  23\penalty0 (8):\penalty0 1177--1193, 2012.

\end{thebibliography}
