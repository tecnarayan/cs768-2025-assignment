\begin{thebibliography}{91}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Yi et~al.(2020)Yi, Gan, Li, Kohli, Wu, Torralba, and
  Tenenbaum]{yi2019clevrer}
Kexin Yi, Chuang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio Torralba,
  and Joshua~B Tenenbaum.
\newblock {CLEVRER}: Collision events for video representation and reasoning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Kulkarni et~al.(2019)Kulkarni, Gupta, Ionescu, Borgeaud, Reynolds,
  Zisserman, and Mnih]{kulkarni2019unsupervised}
Tejas~D Kulkarni, Ankush Gupta, Catalin Ionescu, Sebastian Borgeaud, Malcolm
  Reynolds, Andrew Zisserman, and Volodymyr Mnih.
\newblock Unsupervised learning of object keypoints for perception and control.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  10723--10733, 2019.

\bibitem[Sun et~al.(2019)Sun, Karlsson, Wu, Tenenbaum, and
  Murphy]{sun2019stochastic}
Chen Sun, Per Karlsson, Jiajun Wu, Joshua~B Tenenbaum, and Kevin Murphy.
\newblock Stochastic prediction of multi-agent interactions from partial
  observations.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Berner et~al.(2019)Berner, Brockman, Chan, Cheung, D{\k{e}}biak,
  Dennison, Farhi, Fischer, Hashme, Hesse, et~al.]{berner2019dota}
Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemys{\l}aw
  D{\k{e}}biak, Christy Dennison, David Farhi, Quirin Fischer, Shariq Hashme,
  Chris Hesse, et~al.
\newblock Dota 2 with large scale deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1912.06680}, 2019.

\bibitem[Vinyals et~al.(2019)Vinyals, Babuschkin, Czarnecki, Mathieu, Dudzik,
  Chung, Choi, Powell, Ewalds, Georgiev, et~al.]{vinyals2019grandmaster}
Oriol Vinyals, Igor Babuschkin, Wojciech~M Czarnecki, Micha{\"e}l Mathieu,
  Andrew Dudzik, Junyoung Chung, David~H Choi, Richard Powell, Timo Ewalds,
  Petko Georgiev, et~al.
\newblock Grandmaster level in {StarCraft II} using multi-agent reinforcement
  learning.
\newblock \emph{Nature}, 575\penalty0 (7782):\penalty0 350--354, 2019.

\bibitem[Battaglia et~al.(2016)Battaglia, Pascanu, Lai, Rezende,
  et~al.]{battaglia2016interaction}
Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo~Jimenez Rezende, et~al.
\newblock Interaction networks for learning about objects, relations and
  physics.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4502--4510, 2016.

\bibitem[Mrowca et~al.(2018)Mrowca, Zhuang, Wang, Haber, Fei-Fei, Tenenbaum,
  and Yamins]{mrowca2018flexible}
Damian Mrowca, Chengxu Zhuang, Elias Wang, Nick Haber, Li~Fei-Fei, Josh
  Tenenbaum, and Daniel L~K Yamins.
\newblock Flexible neural representation for physics prediction.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  8799--8810, 2018.

\bibitem[Sanchez-Gonzalez et~al.(2020)Sanchez-Gonzalez, Godwin, Pfaff, Ying,
  Leskovec, and Battaglia]{sanchez2020learning}
Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure
  Leskovec, and Peter~W Battaglia.
\newblock Learning to simulate complex physics with graph networks.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Watters et~al.(2017)Watters, Zoran, Weber, Battaglia, Pascanu, and
  Tacchetti]{watters2017visual}
Nicholas Watters, Daniel Zoran, Theophane Weber, Peter Battaglia, Razvan
  Pascanu, and Andrea Tacchetti.
\newblock Visual interaction networks: Learning a physics simulator from video.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4539--4547, 2017.

\bibitem[Knyazev et~al.(2020)Knyazev, de~Vries, Cangea, Taylor, Courville, and
  Belilovsky]{knyazev2020graph}
Boris Knyazev, Harm de~Vries, Cătălina Cangea, Graham~W Taylor, Aaron
  Courville, and Eugene Belilovsky.
\newblock Graph density-aware losses for novel compositions in scene graph
  generation.
\newblock \emph{arXiv preprint arXiv:2005.08230}, 2020.

\bibitem[Devin et~al.(2018)Devin, Abbeel, Darrell, and Levine]{devin2018deep}
Coline Devin, Pieter Abbeel, Trevor Darrell, and Sergey Levine.
\newblock Deep object-centric representations for generalizable robot learning.
\newblock In \emph{2018 IEEE International Conference on Robotics and
  Automation}, pages 7111--7118. IEEE, 2018.

\bibitem[Sabour et~al.(2017)Sabour, Frosst, and Hinton]{sabour2017dynamic}
Sara Sabour, Nicholas Frosst, and Geoffrey~E Hinton.
\newblock Dynamic routing between capsules.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3856--3866, 2017.

\bibitem[Hinton et~al.(2018)Hinton, Sabour, and Frosst]{hinton2018matrix}
Geoffrey~E Hinton, Sara Sabour, and Nicholas Frosst.
\newblock Matrix capsules with em routing.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Kahneman et~al.(1992)Kahneman, Treisman, and
  Gibbs]{kahneman1992reviewing}
Daniel Kahneman, Anne Treisman, and Brian~J Gibbs.
\newblock The reviewing of object files: Object-specific integration of
  information.
\newblock \emph{Cognitive psychology}, 24\penalty0 (2):\penalty0 175--219,
  1992.

\bibitem[LeCun et~al.(1995)LeCun, Bengio, et~al.]{lecun1995convolutional}
Yann LeCun, Yoshua Bengio, et~al.
\newblock Convolutional networks for images, speech, and time series.
\newblock \emph{The handbook of brain theory and neural networks}, 1995.

\bibitem[Greff et~al.(2019)Greff, Kaufman, Kabra, Watters, Burgess, Zoran,
  Matthey, Botvinick, and Lerchner]{greff2019multi}
Klaus Greff, Rapha{\"e}l~Lopez Kaufman, Rishabh Kabra, Nick Watters,
  Christopher Burgess, Daniel Zoran, Loic Matthey, Matthew Botvinick, and
  Alexander Lerchner.
\newblock Multi-object representation learning with iterative variational
  inference.
\newblock In \emph{International Conference on Machine Learning}, pages
  2424--2433, 2019.

\bibitem[Burgess et~al.(2019)Burgess, Matthey, Watters, Kabra, Higgins,
  Botvinick, and Lerchner]{burgess2019monet}
Christopher~P Burgess, Loic Matthey, Nicholas Watters, Rishabh Kabra, Irina
  Higgins, Matt Botvinick, and Alexander Lerchner.
\newblock {MONet}: Unsupervised scene decomposition and representation.
\newblock \emph{arXiv preprint arXiv:1901.11390}, 2019.

\bibitem[Bahdanau et~al.(2015)Bahdanau, Cho, and Bengio]{bahdanau2014neural}
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Luong et~al.(2015)Luong, Pham, and Manning]{luong2015effective}
Minh-Thang Luong, Hieu Pham, and Christopher~D Manning.
\newblock Effective approaches to attention-based neural machine translation.
\newblock In \emph{Proceedings of the 2015 Conference on Empirical Methods in
  Natural Language Processing}, pages 1412--1421, 2015.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5998--6008, 2017.

\bibitem[Cho et~al.(2014)Cho, van Merri{\"e}nboer, Gulcehre, Bahdanau,
  Bougares, Schwenk, and Bengio]{cho2014learning}
Kyunghyun Cho, Bart van Merri{\"e}nboer, Caglar Gulcehre, Dzmitry Bahdanau,
  Fethi Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock Learning phrase representations using rnn encoder--decoder for
  statistical machine translation.
\newblock In \emph{Proceedings of the 2014 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 1724--1734, 2014.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, pages 770--778, 2016.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Greff et~al.(2016)Greff, Rasmus, Berglund, Hao, Valpola, and
  Schmidhuber]{greff2016tagger}
Klaus Greff, Antti Rasmus, Mathias Berglund, Tele Hao, Harri Valpola, and
  J{\"u}rgen Schmidhuber.
\newblock Tagger: Deep unsupervised perceptual grouping.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4484--4492, 2016.

\bibitem[Greff et~al.(2017)Greff, {van Steenkiste}, and
  Schmidhuber]{greff2017neural}
Klaus Greff, Sjoerd {van Steenkiste}, and J{\"u}rgen Schmidhuber.
\newblock Neural expectation maximization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6691--6701, 2017.

\bibitem[Eslami et~al.(2016)Eslami, Heess, Weber, Tassa, Szepesvari, Hinton,
  et~al.]{eslami2016attend}
SM~Ali Eslami, Nicolas Heess, Theophane Weber, Yuval Tassa, David Szepesvari,
  Geoffrey~E Hinton, et~al.
\newblock Attend, infer, repeat: Fast scene understanding with generative
  models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3225--3233, 2016.

\bibitem[Engelcke et~al.(2020)Engelcke, Kosiorek, Jones, and
  Posner]{engelcke2019genesis}
Martin Engelcke, Adam~R Kosiorek, Oiwi~Parker Jones, and Ingmar Posner.
\newblock {GENESIS}: Generative scene inference and sampling with
  object-centric latent representations.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Watters et~al.(2019{\natexlab{a}})Watters, Matthey, Burgess, and
  Lerchner]{watters2019spatial}
Nicholas Watters, Loic Matthey, Christopher~P Burgess, and Alexander Lerchner.
\newblock Spatial broadcast decoder: A simple architecture for learning
  disentangled representations in {VAEs}.
\newblock \emph{arXiv preprint arXiv:1901.07017}, 2019{\natexlab{a}}.

\bibitem[Achlioptas et~al.(2018)Achlioptas, Diamanti, Mitliagkas, and
  Guibas]{achlioptas2018learning}
Panos Achlioptas, Olga Diamanti, Ioannis Mitliagkas, and Leonidas Guibas.
\newblock Learning representations and generative models for {3D} point clouds.
\newblock In \emph{International Conference on Machine Learning}, pages 40--49,
  2018.

\bibitem[Fan et~al.(2017)Fan, Su, and Guibas]{fan2017point}
Haoqiang Fan, Hao Su, and Leonidas~J Guibas.
\newblock A point set generation network for {3D} object reconstruction from a
  single image.
\newblock In \emph{Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, pages 605--613, 2017.

\bibitem[Zhang et~al.(2019)Zhang, Hare, and Prugel-Bennett]{zhang2019deep}
Yan Zhang, Jonathon Hare, and Adam Prugel-Bennett.
\newblock Deep set prediction networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3207--3217, 2019.

\bibitem[De~Cao and Kipf(2018)]{de2018molgan}
Nicola De~Cao and Thomas Kipf.
\newblock {MolGAN}: An implicit generative model for small molecular graphs.
\newblock \emph{arXiv preprint arXiv:1805.11973}, 2018.

\bibitem[Simonovsky and Komodakis(2018)]{simonovsky2018graphvae}
Martin Simonovsky and Nikos Komodakis.
\newblock {GraphVAE}: Towards generation of small graphs using variational
  autoencoders.
\newblock In \emph{International Conference on Artificial Neural Networks},
  pages 412--422. Springer, 2018.

\bibitem[Zhang et~al.(2020)Zhang, Hare, and
  Pr{\"u}gel-Bennett]{zhang2019fspool}
Yan Zhang, Jonathon Hare, and Adam Pr{\"u}gel-Bennett.
\newblock {FSPool}: Learning set representations with featurewise sort pooling.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Kuhn(1955)]{kuhn1955hungarian}
Harold~W Kuhn.
\newblock The {Hungarian} method for the assignment problem.
\newblock \emph{Naval research logistics quarterly}, 2\penalty0 (1-2):\penalty0
  83--97, 1955.

\bibitem[Cuturi(2013)]{cuturi2013sinkhorn}
Marco Cuturi.
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2292--2300, 2013.

\bibitem[Zeng et~al.(2019)Zeng, Liao, Gu, Xiong, Fidler, and
  Urtasun]{zeng2019dmm}
Xiaohui Zeng, Renjie Liao, Li~Gu, Yuwen Xiong, Sanja Fidler, and Raquel
  Urtasun.
\newblock Dmm-net: Differentiable mask-matching network for video object
  segmentation.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pages 3929--3938, 2019.

\bibitem[Nash et~al.(2017)Nash, Eslami, Burgess, Higgins, Zoran, Weber, and
  Battaglia]{nash2017multi}
Charlie Nash, SM~Ali Eslami, Chris Burgess, Irina Higgins, Daniel Zoran,
  Theophane Weber, and Peter Battaglia.
\newblock The multi-entity variational autoencoder.
\newblock In \emph{NIPS Workshops}, 2017.

\bibitem[{van Steenkiste} et~al.(2018){van Steenkiste}, Chang, Greff, and
  Schmidhuber]{van2018relational}
Sjoerd {van Steenkiste}, Michael Chang, Klaus Greff, and J{\"u}rgen
  Schmidhuber.
\newblock Relational neural expectation maximization: Unsupervised discovery of
  objects and their interactions.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Kosiorek et~al.(2018)Kosiorek, Kim, Teh, and
  Posner]{kosiorek2018sequential}
Adam Kosiorek, Hyunjik Kim, Yee~Whye Teh, and Ingmar Posner.
\newblock Sequential attend, infer, repeat: Generative modelling of moving
  objects.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  8606--8616, 2018.

\bibitem[Stelzner et~al.(2019)Stelzner, Peharz, and
  Kersting]{stelzner2019faster}
Karl Stelzner, Robert Peharz, and Kristian Kersting.
\newblock Faster attend-infer-repeat with tractable probabilistic models.
\newblock In \emph{International Conference on Machine Learning}, pages
  5966--5975, 2019.

\bibitem[Crawford and Pineau(2019)]{crawford2019spatially}
Eric Crawford and Joelle Pineau.
\newblock Spatially invariant unsupervised object detection with convolutional
  neural networks.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 3412--3420, 2019.

\bibitem[Jiang et~al.(2020)Jiang, Janghorbani, de~Melo, and
  Ahn]{jiang2019scalable}
Jindong Jiang, Sepehr Janghorbani, Gerard de~Melo, and Sungjin Ahn.
\newblock {SCALOR}: Generative world models with scalable object
  representations.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Lin et~al.(2020)Lin, Wu, Peri, Sun, Singh, Deng, Jiang, and
  Ahn]{lin2020space}
Zhixuan Lin, Yi-Fu Wu, Skand~Vishwanath Peri, Weihao Sun, Gautam Singh, Fei
  Deng, Jindong Jiang, and Sungjin Ahn.
\newblock {SPACE}: Unsupervised object-oriented scene representation via
  spatial attention and decomposition.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Marino et~al.(2018)Marino, Yue, and Mandt]{marino2018iterative}
Joe Marino, Yisong Yue, and Stephan Mandt.
\newblock Iterative amortized inference.
\newblock In \emph{International Conference on Machine Learning}, pages
  3403--3412, 2018.

\bibitem[Kipf et~al.(2020)Kipf, van~der Pol, and Welling]{kipf2019contrastive}
Thomas Kipf, Elise van~der Pol, and Max Welling.
\newblock Contrastive learning of structured world models.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[{van Steenkiste} et~al.(2020){van Steenkiste}, Kurach, Schmidhuber,
  and Gelly]{van2018case}
Sjoerd {van Steenkiste}, Karol Kurach, Jürgen Schmidhuber, and Sylvain Gelly.
\newblock Investigating object compositionality in generative adversarial
  networks.
\newblock \emph{Neural Networks}, 130:\penalty0 309 -- 325, 2020.

\bibitem[Chen et~al.(2019)Chen, Arti{\`e}res, and
  Denoyer]{chen2019unsupervised}
Micka{\"e}l Chen, Thierry Arti{\`e}res, and Ludovic Denoyer.
\newblock Unsupervised object segmentation by redrawing.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  12705--12716, 2019.

\bibitem[Yang et~al.(2020)Yang, Chen, and Soatto]{yang2020learning}
Yanchao Yang, Yutong Chen, and Stefano Soatto.
\newblock Learning to manipulate individual objects in an image.
\newblock \emph{arXiv preprint arXiv:2004.05495}, 2020.

\bibitem[Lin et~al.(2017)Lin, Feng, Santos, Yu, Xiang, Zhou, and
  Bengio]{lin2017structured}
Zhouhan Lin, Minwei Feng, Cicero Nogueira~dos Santos, Mo~Yu, Bing Xiang, Bowen
  Zhou, and Yoshua Bengio.
\newblock A structured self-attentive sentence embedding.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Zaheer et~al.(2017)Zaheer, Kottur, Ravanbakhsh, Poczos, Salakhutdinov,
  and Smola]{zaheer2017deep}
Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Russ~R
  Salakhutdinov, and Alexander~J Smola.
\newblock Deep sets.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3391--3401, 2017.

\bibitem[Rezatofighi et~al.(2020)Rezatofighi, Kaskman, Motlagh, Shi, Milan,
  Cremers, Leal-Taix{\'e}, and Reid]{rezatofighi2020learn}
Hamid Rezatofighi, Roman Kaskman, Farbod~T Motlagh, Qinfeng Shi, Anton Milan,
  Daniel Cremers, Laura Leal-Taix{\'e}, and Ian Reid.
\newblock Learn to predict sets using feed-forward neural networks.
\newblock \emph{arXiv preprint arXiv:2001.11845}, 2020.

\bibitem[Lee et~al.(2019)Lee, Lee, Kim, Kosiorek, Choi, and Teh]{lee2018set}
Juho Lee, Yoonho Lee, Jungtaek Kim, Adam Kosiorek, Seungjin Choi, and Yee~Whye
  Teh.
\newblock Set transformer: A framework for attention-based
  permutation-invariant neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  3744--3753, 2019.

\bibitem[Scarselli et~al.(2008)Scarselli, Gori, Tsoi, Hagenbuchner, and
  Monfardini]{scarselli2008graph}
Franco Scarselli, Marco Gori, Ah~Chung Tsoi, Markus Hagenbuchner, and Gabriele
  Monfardini.
\newblock The graph neural network model.
\newblock \emph{IEEE Transactions on Neural Networks}, 20\penalty0
  (1):\penalty0 61--80, 2008.

\bibitem[Li et~al.(2016)Li, Tarlow, Brockschmidt, and Zemel]{li2015gated}
Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel.
\newblock Gated graph sequence neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2016.

\bibitem[Kipf and Welling(2017)]{kipf2016semi}
Thomas~N Kipf and Max Welling.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Battaglia et~al.(2018)Battaglia, Hamrick, Bapst, Sanchez-Gonzalez,
  Zambaldi, Malinowski, Tacchetti, Raposo, Santoro, Faulkner,
  et~al.]{battaglia2018relational}
Peter~W Battaglia, Jessica~B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez,
  Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam
  Santoro, Ryan Faulkner, et~al.
\newblock Relational inductive biases, deep learning, and graph networks.
\newblock \emph{arXiv preprint arXiv:1806.01261}, 2018.

\bibitem[Huang et~al.(2020)Huang, He, Singh, Zhang, Lim, and
  Benson]{huang2020set}
Qian Huang, Horace He, Abhay Singh, Yan Zhang, Ser-Nam Lim, and Austin Benson.
\newblock Better set representations for relational reasoning.
\newblock \emph{arXiv preprint arXiv:2003.04448}, 2020.

\bibitem[Carion et~al.(2020)Carion, Massa, Synnaeve, Usunier, Kirillov, and
  Zagoruyko]{carion2020detr}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In \emph{European Conference on Computer Vision}, 2020.

\bibitem[Kosiorek et~al.(2020)Kosiorek, Kim, and
  Rezende]{kosiorek2020conditional}
Adam~R Kosiorek, Hyunjik Kim, and Danilo~J Rezende.
\newblock Conditional set generation with transformers.
\newblock \emph{arXiv preprint arXiv:2006.16841}, 2020.

\bibitem[Ying et~al.(2018)Ying, You, Morris, Ren, Hamilton, and
  Leskovec]{ying2018hierarchical}
Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and
  Jure Leskovec.
\newblock Hierarchical graph representation learning with differentiable
  pooling.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4800--4810, 2018.

\bibitem[Tsai et~al.(2020)Tsai, Srivastava, Goh, and
  Salakhutdinov]{tsai2020capsules}
Yao-Hung~Hubert Tsai, Nitish Srivastava, Hanlin Goh, and Ruslan Salakhutdinov.
\newblock Capsules with inverted dot-product attention routing.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Santoro et~al.(2018)Santoro, Faulkner, Raposo, Rae, Chrzanowski,
  Weber, Wierstra, Vinyals, Pascanu, and Lillicrap]{santoro2018relational}
Adam Santoro, Ryan Faulkner, David Raposo, Jack Rae, Mike Chrzanowski,
  Theophane Weber, Daan Wierstra, Oriol Vinyals, Razvan Pascanu, and Timothy
  Lillicrap.
\newblock Relational recurrent neural networks.
\newblock In \emph{Advances in neural information processing systems}, pages
  7299--7310, 2018.

\bibitem[Zambaldi et~al.(2018)Zambaldi, Raposo, Santoro, Bapst, Li, Babuschkin,
  Tuyls, Reichert, Lillicrap, Lockhart, et~al.]{zambaldi2018relational}
Vinicius Zambaldi, David Raposo, Adam Santoro, Victor Bapst, Yujia Li, Igor
  Babuschkin, Karl Tuyls, David Reichert, Timothy Lillicrap, Edward Lockhart,
  et~al.
\newblock Relational deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1806.01830}, 2018.

\bibitem[Watters et~al.(2019{\natexlab{b}})Watters, Matthey, Bosnjak, Burgess,
  and Lerchner]{watters2019cobra}
Nicholas Watters, Loic Matthey, Matko Bosnjak, Christopher~P Burgess, and
  Alexander Lerchner.
\newblock Cobra: Data-efficient model-based rl through unsupervised object
  discovery and curiosity-driven exploration.
\newblock \emph{arXiv preprint arXiv:1905.09275}, 2019{\natexlab{b}}.

\bibitem[Stani{\'c} and Schmidhuber(2019)]{stanic2019r}
Aleksandar Stani{\'c} and J{\"u}rgen Schmidhuber.
\newblock R-sqair: relational sequential attend, infer, repeat.
\newblock \emph{arXiv preprint arXiv:1910.05231}, 2019.

\bibitem[Goyal et~al.(2019)Goyal, Lamb, Hoffmann, Sodhani, Levine, Bengio, and
  Sch{\"o}lkopf]{goyal2019recurrent}
Anirudh Goyal, Alex Lamb, Jordan Hoffmann, Shagun Sodhani, Sergey Levine,
  Yoshua Bengio, and Bernhard Sch{\"o}lkopf.
\newblock Recurrent independent mechanisms.
\newblock \emph{arXiv preprint arXiv:1909.10893}, 2019.

\bibitem[Veerapaneni et~al.(2020)Veerapaneni, Co-Reyes, Chang, Janner, Finn,
  Wu, Tenenbaum, and Levine]{veerapaneni2020entity}
Rishi Veerapaneni, John~D Co-Reyes, Michael Chang, Michael Janner, Chelsea
  Finn, Jiajun Wu, Joshua Tenenbaum, and Sergey Levine.
\newblock Entity abstraction in visual model-based reinforcement learning.
\newblock In \emph{Conference on Robot Learning}, pages 1439--1456, 2020.

\bibitem[Jacobs et~al.(1991)Jacobs, Jordan, Nowlan, and
  Hinton]{jacobs1991adaptive}
Robert~A Jacobs, Michael~I Jordan, Steven~J Nowlan, and Geoffrey~E Hinton.
\newblock Adaptive mixtures of local experts.
\newblock \emph{Neural Computation}, 3\penalty0 (1):\penalty0 79--87, 1991.

\bibitem[Parascandolo et~al.(2018)Parascandolo, Kilbertus, Rojas-Carulla, and
  Sch{\"o}lkopf]{parascandolo2018learning}
Giambattista Parascandolo, Niki Kilbertus, Mateo Rojas-Carulla, and Bernhard
  Sch{\"o}lkopf.
\newblock Learning independent causal mechanisms.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Locatello et~al.(2018)Locatello, Vincent, Tolstikhin, R{\"a}tsch,
  Gelly, and Sch{\"o}lkopf]{locatello2018competitive}
Francesco Locatello, Damien Vincent, Ilya Tolstikhin, Gunnar R{\"a}tsch,
  Sylvain Gelly, and Bernhard Sch{\"o}lkopf.
\newblock Competitive training of mixtures of independent deep generative
  models.
\newblock \emph{arXiv preprint arXiv:1804.11130}, 2018.

\bibitem[von K{\"u}gelgen et~al.(2020)von K{\"u}gelgen, Ustyuzhaninov, Gehler,
  Bethge, and Sch{\"o}lkopf]{von2020towards}
Julius von K{\"u}gelgen, Ivan Ustyuzhaninov, Peter Gehler, Matthias Bethge, and
  Bernhard Sch{\"o}lkopf.
\newblock Towards causal generative scene models via competition of experts.
\newblock \emph{arXiv preprint arXiv:2004.12906}, 2020.

\bibitem[Bauckhage(2015)]{bauckhage2015lecture}
Christian Bauckhage.
\newblock Lecture notes on data science: Soft k-means clustering, 2015.

\bibitem[Arandjelovic et~al.(2016)Arandjelovic, Gronat, Torii, Pajdla, and
  Sivic]{arandjelovic2016netvlad}
Relja Arandjelovic, Petr Gronat, Akihiko Torii, Tomas Pajdla, and Josef Sivic.
\newblock Netvlad: Cnn architecture for weakly supervised place recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 5297--5307, 2016.

\bibitem[Cai et~al.(2018)Cai, Cai, Zhang, Wang, and Li]{cai2018novel}
Weicheng Cai, Zexin Cai, Xiang Zhang, Xiaoqi Wang, and Ming Li.
\newblock A novel learnable dictionary encoding layer for end-to-end language
  identification.
\newblock In \emph{2018 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pages 5189--5193. IEEE, 2018.

\bibitem[Mnih et~al.(2014)Mnih, Heess, Graves, et~al.]{mnih2014recurrent}
Volodymyr Mnih, Nicolas Heess, Alex Graves, et~al.
\newblock Recurrent models of visual attention.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2204--2212, 2014.

\bibitem[Gregor et~al.(2015)Gregor, Danihelka, Graves, Rezende, and
  Wierstra]{gregor2015draw}
Karol Gregor, Ivo Danihelka, Alex Graves, Danilo Rezende, and Daan Wierstra.
\newblock Draw: A recurrent neural network for image generation.
\newblock In \emph{International Conference on Machine Learning}, pages
  1462--1471, 2015.

\bibitem[Ren and Zemel(2017)]{ren2017end}
Mengye Ren and Richard~S Zemel.
\newblock End-to-end instance segmentation with recurrent attention.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2017.

\bibitem[Welleck et~al.(2017)Welleck, Mao, Cho, and Zhang]{welleck2017saliency}
Sean Welleck, Jialin Mao, Kyunghyun Cho, and Zheng Zhang.
\newblock Saliency-based sequential image attention with multiset prediction.
\newblock In \emph{Advances in neural information processing systems}, pages
  5173--5183, 2017.

\bibitem[Stewart et~al.(2016)Stewart, Andriluka, and Ng]{stewart2016end}
Russell Stewart, Mykhaylo Andriluka, and Andrew~Y Ng.
\newblock End-to-end people detection in crowded scenes.
\newblock In \emph{Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, 2016.

\bibitem[Romera-Paredes and Torr(2016)]{romera2016recurrent}
Bernardino Romera-Paredes and Philip Hilaire~Sean Torr.
\newblock Recurrent instance segmentation.
\newblock In \emph{European Conference on Computer Vision}, pages 312--329.
  Springer, 2016.

\bibitem[Welleck et~al.(2018)Welleck, Yao, Gai, Mao, Zhang, and
  Cho]{welleck2018loss}
Sean Welleck, Zixin Yao, Yu~Gai, Jialin Mao, Zheng Zhang, and Kyunghyun Cho.
\newblock Loss functions for multiset prediction.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5783--5792, 2018.

\bibitem[Kabra et~al.(2019)Kabra, Burgess, Matthey, Kaufman, Greff, Reynolds,
  and Lerchner]{multiobjectdatasets19}
Rishabh Kabra, Chris Burgess, Loic Matthey, Raphael~Lopez Kaufman, Klaus Greff,
  Malcolm Reynolds, and Alexander Lerchner.
\newblock Multi-object datasets.
\newblock https://github.com/deepmind/multi\_object\_datasets/, 2019.

\bibitem[Johnson et~al.(2017)Johnson, Hariharan, van~der Maaten, Fei-Fei,
  Lawrence~Zitnick, and Girshick]{johnson2017clevr}
Justin Johnson, Bharath Hariharan, Laurens van~der Maaten, Li~Fei-Fei,
  C~Lawrence~Zitnick, and Ross Girshick.
\newblock {CLEVR}: A diagnostic dataset for compositional language and
  elementary visual reasoning.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2017.

\bibitem[Kingma and Ba(2015)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Goyal et~al.(2017)Goyal, Doll{\'a}r, Girshick, Noordhuis, Wesolowski,
  Kyrola, Tulloch, Jia, and He]{goyal2017accurate}
Priya Goyal, Piotr Doll{\'a}r, Ross Girshick, Pieter Noordhuis, Lukasz
  Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He.
\newblock Accurate, large minibatch {SGD}: Training imagenet in 1 hour.
\newblock \emph{arXiv preprint arXiv:1706.02677}, 2017.

\bibitem[Rand(1971)]{rand1971objective}
William~M Rand.
\newblock Objective criteria for the evaluation of clustering methods.
\newblock \emph{Journal of the American Statistical Association}, 66\penalty0
  (336):\penalty0 846--850, 1971.

\bibitem[Hubert and Arabie(1985)]{hubert1985comparing}
Lawrence Hubert and Phipps Arabie.
\newblock Comparing partitions.
\newblock \emph{Journal of Classification}, 2\penalty0 (1):\penalty0 193--218,
  1985.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2672--2680, 2014.

\bibitem[Everingham et~al.(2015)Everingham, Eslami, Van~Gool, Williams, Winn,
  and Zisserman]{everingham2015pascal}
Mark Everingham, SM~Ali Eslami, Luc Van~Gool, Christopher~KI Williams, John
  Winn, and Andrew Zisserman.
\newblock The {PASCAL} visual object classes challenge: A retrospective.
\newblock \emph{International Journal of Computer Vision}, 111\penalty0
  (1):\penalty0 98--136, 2015.

\bibitem[Shaw et~al.(2018)Shaw, Uszkoreit, and Vaswani]{shaw2018self}
Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani.
\newblock Self-attention with relative position representations.
\newblock In \emph{Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 2 (Short Papers)}, pages 464--468, 2018.

\end{thebibliography}
