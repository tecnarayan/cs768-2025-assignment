\begin{thebibliography}{55}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alvarez and Petersson(2016)]{decomposeMe}
Jose~M. Alvarez and Lars Petersson.
\newblock Decomposeme: Simplifying convnets for end-to-end learning.
\newblock \emph{CoRR}, abs/1606.05426, 2016.

\bibitem[Alvarez and Salzmann(2016)]{Alvarez:NIPS2016}
Jose~M. Alvarez and Mathieu Salzmann.
\newblock Learning the number of neurons in deep networks.
\newblock In \emph{NIPS}, 2016.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{layernorm}
Lei~Jimmy Ba, Ryan Kiros, and Geoffrey~E. Hinton.
\newblock Layer normalization.
\newblock \emph{CoRR}, abs/1607.06450, 2016.
\newblock URL \url{http://arxiv.org/abs/1607.06450}.

\bibitem[Babaeizadeh et~al.(2016)Babaeizadeh, Smaragdis, and
  Campbell]{NoiseOut}
Mohammad Babaeizadeh, Paris Smaragdis, and Roy~H. Campbell.
\newblock Noiseout: A simple way to prune neural networks.
\newblock In \emph{emdnn Nips workshops}, 2016.

\bibitem[Bengio and Bergstra(2009)]{BengioDeCorr:NIPS2009}
Yoshua Bengio and James~S. Bergstra.
\newblock Slow, decorrelated features for pretraining complex cell-like
  networks.
\newblock In \emph{NIPS}, pages 99--107. 2009.

\bibitem[Cai et~al.(2010)Cai, Cand\`{e}s, and Shen]{Cai:2010:TSVT}
Jian-Feng Cai, Emmanuel~J. Cand\`{e}s, and Zuowei Shen.
\newblock A singular value thresholding algorithm for matrix completion.
\newblock \emph{SIAM J. on Optimization}, 20\penalty0 (4):\penalty0 1956--1982,
  March 2010.
\newblock ISSN 1052-6234.

\bibitem[Cand{\`{e}}s and Recht(2008)]{Candes08}
Emmanuel~J. Cand{\`{e}}s and Benjamin Recht.
\newblock Exact matrix completion via convex optimization.
\newblock \emph{CoRR}, abs/0805.4471, 2008.
\newblock URL \url{http://arxiv.org/abs/0805.4471}.

\bibitem[Clevert et~al.(2015)Clevert, Unterthiner, and Hochreiter]{ELU}
Djork{-}Arn{\'{e}} Clevert, Thomas Unterthiner, and Sepp Hochreiter.
\newblock Fast and accurate deep network learning by exponential linear units
  (elus).
\newblock \emph{CoRR}, abs/1511.07289, 2015.

\bibitem[Cogswell et~al.(2016)Cogswell, Ahmed, Girshick, Zitnick, and
  Batra]{Batra:ICLR2016}
Michael Cogswell, Faruk Ahmed, Ross Girshick, Larry Zitnick, and Dhruv Batra.
\newblock Reducing overfitting in deep networks by decorrelating
  representations.
\newblock In \emph{ICLR}, 2016.

\bibitem[Collins and Kohli(2014)]{CollinsKMemoryBounded14}
Maxwell~D. Collins and Pushmeet Kohli.
\newblock {Memory Bounded Deep Convolutional Networks}.
\newblock In \emph{CoRR}, volume abs/1412.1442, 2014.

\bibitem[Collobert et~al.(2011)Collobert, Kavukcuoglu, and
  Farabet]{Collobert_NIPSWORKSHOP_2011}
Ronan Collobert, Koray Kavukcuoglu, and Cl{\'{e}}ment Farabet.
\newblock Torch7: A matlab-like environment for machine learning.
\newblock In \emph{BigLearn, NIPS Workshop}, 2011.

\bibitem[Courbariaux and Bengio(2016)]{CourbariauxB16}
Matthieu Courbariaux and Yoshua Bengio.
\newblock Binarynet: Training deep neural networks with weights and activations
  constrained to +1 or -1.
\newblock \emph{CoRR}, abs/1602.02830, 2016.
\newblock URL \url{http://arxiv.org/abs/1602.02830}.

\bibitem[Denil et~al.(2013)Denil, Shakibi, Dinh, Ranzato, and
  de~Freitas]{DenilSDRF13}
Misha Denil, Babak Shakibi, Laurent Dinh, Marc'Aurelio Ranzato, and Nando
  de~Freitas.
\newblock Predicting parameters in deep learning.
\newblock \emph{CoRR}, abs/1306.0543, 2013.

\bibitem[Denton et~al.(2014)Denton, Zaremba, Bruna, LeCun, and
  Fergus]{Fergus:NIPS2014}
Emily~L Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus.
\newblock Exploiting linear structure within convolutional networks for
  efficient evaluation.
\newblock In \emph{NIPS}. 2014.

\bibitem[Duchi et~al.(2010)Duchi, Hazan, and Singer]{Duchi:EECS-2010-24}
John Duchi, Elad Hazan, and Yoram Singer.
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock Technical Report UCB/EECS-2010-24, EECS Department, University of
  California, Berkeley, Mar 2010.
\newblock URL
  \url{http://www2.eecs.berkeley.edu/Pubs/TechRpts/2010/EECS-2010-24.html}.

\bibitem[Goodfellow et~al.(2013)Goodfellow, Warde-farley, Mirza, Courville, and
  Bengio]{Goodfellow13maxoutnetworks}
Ian~J. Goodfellow, David Warde-farley, Mehdi Mirza, Aaron Courville, and Yoshua
  Bengio.
\newblock Maxout networks.
\newblock In \emph{ICML}, 2013.

\bibitem[Graves(2011)]{variational}
Alex Graves.
\newblock Practical variational inference for neural networks.
\newblock In \emph{NIPS}, 2011.

\bibitem[Gupta et~al.(2015)Gupta, Agrawal, Gopalakrishnan, and
  Narayanan]{GuptaAGN15}
Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, and Pritish Narayanan.
\newblock Deep learning with limited numerical precision.
\newblock \emph{CoRR}, abs/1502.02551, 2015.
\newblock URL \url{http://arxiv.org/abs/1502.02551}.

\bibitem[Han et~al.(2015)Han, Pool, Tran, and Dally]{han2015learning}
Song Han, Jeff Pool, John Tran, and William Dally.
\newblock Learning both weights and connections for efficient neural network.
\newblock In \emph{NIPS}, 2015.

\bibitem[Han et~al.(2016)Han, Mao, and Dally]{han2015deep_compression}
Song Han, Huizi Mao, and William~J Dally.
\newblock Deep compression: Compressing deep neural networks with pruning,
  trained quantization and huffman coding.
\newblock \emph{ICLR}, 2016.

\bibitem[Harandi and Fernando(2016)]{Mehrtash16}
Mehrtash Harandi and Basura Fernando.
\newblock Generalized backpropagation, {\'{e}}tude de cas: Orthogonality.
\newblock \emph{CoRR}, abs/1611.05927, 2016.
\newblock URL \url{http://arxiv.org/abs/1611.05927}.

\bibitem[Hassibi et~al.(1993)Hassibi, Stork, and Wolff]{BrainSurgeon}
B.~Hassibi, D.~G. Stork, and G.~J. Wolff.
\newblock Optimal brain surgeon and general network pruning.
\newblock In \emph{ICNN}, 1993.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{ResNet2015}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock {Deep Residual Learning for Image Recognition}.
\newblock In \emph{CoRR}, volume abs/1512.03385, 2015.

\bibitem[Hinton and Dean(2014)]{distNets}
Vinyals~O. Hinton, G.~E. and J.~Dean.
\newblock Distilling the knowledge in a neural network.
\newblock In \emph{arXiv}, 2014.

\bibitem[Ioannou et~al.(2015)Ioannou, Robertson, Shotton, Cipolla, and
  Criminisi]{IoannouRSCC15}
Yani Ioannou, Duncan~P. Robertson, Jamie Shotton, Roberto Cipolla, and Antonio
  Criminisi.
\newblock Training cnns with low-rank filters for efficient image
  classification.
\newblock \emph{CoRR}, abs/1511.06744, 2015.
\newblock URL \url{http://arxiv.org/abs/1511.06744}.

\bibitem[Ioffe and Szegedy(2015)]{IoffeS15}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{CoRR}, 2015.

\bibitem[Jaderberg et~al.(2014{\natexlab{a}})Jaderberg, Vedaldi, and
  Zisserman]{Jaderberg148}
M.~Jaderberg, A.~Vedaldi, and Zisserman.
\newblock Deep features for text spotting.
\newblock In \emph{ECCV}, 2014{\natexlab{a}}.

\bibitem[Jaderberg et~al.(2014{\natexlab{b}})Jaderberg, Vedaldi, and
  Zisserman]{Jaderberg14b}
M.~Jaderberg, A.~Vedaldi, and A.~Zisserman.
\newblock Speeding up convolutional neural networks with low rank expansions.
\newblock In \emph{British Machine Vision Conference}, 2014{\natexlab{b}}.

\bibitem[Ji et~al.(1990)Ji, Snapp, and Psaltis]{JiNeuronPruning:90}
C.~Ji, R.~R. Snapp, and D.~Psaltis.
\newblock Generalizing smoothness constraints from discrete samples.
\newblock \emph{Neural Computation}, 2\penalty0 (2):\penalty0 188--197, June
  1990.
\newblock ISSN 0899-7667.

\bibitem[Kingma and Ba(2014)]{adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock \emph{CoRR}, abs/1412.6980, 2014.
\newblock URL \url{http://arxiv.org/abs/1412.6980}.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{Krizhevsky_imagenetclassification}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{NIPS}, 2012.

\bibitem[Lebedev et~al.(2014)Lebedev, Ganin, Rakhuba, Oseledets, and
  Lempitsky]{LebedevGROL14}
Vadim Lebedev, Yaroslav Ganin, Maksim Rakhuba, Ivan~V. Oseledets, and Victor~S.
  Lempitsky.
\newblock Speeding-up convolutional neural networks using fine-tuned
  cp-decomposition.
\newblock \emph{CoRR}, abs/1412.6553, 2014.
\newblock URL \url{http://arxiv.org/abs/1412.6553}.

\bibitem[LeCun et~al.(1990)LeCun, Denker, Solla, Howard, and Jackel]{damage}
Yann LeCun, J.~S. Denker, S.~Solla, R.~E. Howard, and L.~D. Jackel.
\newblock Optimal brain damage.
\newblock In \emph{NIPS}, 1990.

\bibitem[Liu et~al.(2015)Liu, Wang, Foroosh, Tappen, and
  Penksy]{Liu:CVPR2015_SparseNets}
B.~Liu, M.~Wang, H.~Foroosh, M.~Tappen, and M.~Penksy.
\newblock Sparse convolutional neural networks.
\newblock In \emph{CVPR}, 2015.

\bibitem[Molchanov et~al.(2016)Molchanov, Tyree, Karras, Aila, and
  Kautz]{PruningICLR2017}
Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila, and Jan Kautz.
\newblock Pruning convolutional neural networks for resource efficient transfer
  learning.
\newblock \emph{CoRR}, abs/1611.06440, 2016.

\bibitem[Mozer and Smolensky(1988)]{MozerS88:Skeleton}
Michael Mozer and Paul Smolensky.
\newblock Skeletonization: {A} technique for trimming the fat from a network
  via relevance assessment.
\newblock In \emph{NIPS}, 1988.

\bibitem[Pan and Jiang(2016)]{HOPE2}
Hengyue Pan and Hui Jiang.
\newblock Learning convolutional neural networks using hybrid orthogonal
  projection and estimation.
\newblock \emph{CoRR}, abs/1606.05929, 2016.

\bibitem[Reed(1993)]{PruningSurvey}
R.~Reed.
\newblock Pruning algorithms-a survey.
\newblock \emph{IEEE Transactions on Neural Networks}, 4\penalty0 (5):\penalty0
  740--747, Sep 1993.

\bibitem[Richard et~al.(2012)Richard, andre Savalle, and Vayatis]{ICML2012}
Emile Richard, Pierre andre Savalle, and Nicolas Vayatis.
\newblock Estimation of simultaneously sparse and low rank matrices.
\newblock In \emph{ICML}, 2012.

\bibitem[Rodrıguez et~al.(2017)Rodrıguez, Gonzalez, Cucurull, and andXavier
  Roca]{Rodriguez:ICLR2017}
Pau Rodrıguez, Jordi Gonzalez, Guillem Cucurull, and Josep M.~Gonfaus
  andXavier Roca.
\newblock Regularizing cnns with locally constrained decorrelations.
\newblock In \emph{ICLR}, 2017.

\bibitem[Russakovsky et~al.(2014)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and Li]{ImageNet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael~S. Bernstein,
  Alexander~C. Berg, and Fei-Fei Li.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{CoRR}, abs/1409.0575, 2014.

\bibitem[Salimans and Kingma(2016)]{weightnorm}
Tim Salimans and Diederik~P. Kingma.
\newblock Weight normalization: {A} simple reparameterization to accelerate
  training of deep neural networks.
\newblock \emph{CoRR}, abs/1602.07868, 2016.
\newblock URL \url{http://arxiv.org/abs/1602.07868}.

\bibitem[Simon et~al.(2013)Simon, Friedman, Hastie, and
  Tibshirani]{Simon13asparse-group}
Noah Simon, Jerome Friedman, Trevor Hastie, and Rob Tibshirani.
\newblock A sparse-group lasso.
\newblock \emph{Journal of Computational and Graphical Statistics}, 2013.

\bibitem[Simonyan and Zisserman(2014)]{Simonyan14c}
K.~Simonyan and A.~Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{CoRR}, abs/1409.1556, 2014.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{HintonDropOut}
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
  Salakhutdinov.
\newblock Dropout: A simple way to prevent neural networks from overfitting.
\newblock \emph{Journal of Machine Learning Research}, 15:\penalty0 1929--1958,
  2014.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{GoogLeNet_CVPR2015}
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
  Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
\newblock Going deeper with convolutions.
\newblock In \emph{CVPR}, 2015.

\bibitem[Tai et~al.(2015)Tai, Xiao, Wang, and E]{TaiXWE15}
Cheng Tai, Tong Xiao, Xiaogang Wang, and Weinan E.
\newblock Convolutional neural networks with low-rank regularization.
\newblock \emph{CoRR}, abs/1511.06067, 2015.
\newblock URL \url{http://arxiv.org/abs/1511.06067}.

\bibitem[Ullrich et~al.(2016)Ullrich, Meeds, and Welling]{Ullrich2016SoftWF}
Karen Ullrich, Edward Meeds, and Max Welling.
\newblock Soft weight-sharing for neural network compression.
\newblock \emph{CoRR}, abs/1702.04008, 2016.

\bibitem[Weigend et~al.(1991)Weigend, Rumelhart, and
  Huberman]{WeightElimination}
Andreas~S. Weigend, David~E. Rumelhart, and Bernardo~A. Huberman.
\newblock Generalization by weight-elimination with application to forecasting.
\newblock In \emph{NIPS}, 1991.

\bibitem[Wen et~al.(2016)Wen, Wu, Wang, Chen, and Li]{StructuredSparsity}
Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li.
\newblock Learning structured sparsity in deep neural networks.
\newblock In \emph{NIPS}, 2016.

\bibitem[Wen et~al.(2017)Wen, Xu, Wu, Wang, Chen, and Li]{CoordinatingFilters}
Wei Wen, Cong Xu, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li.
\newblock Coordinating filters for faster deep neural networks.
\newblock \emph{CoRR}, abs/1703.09746, 2017.

\bibitem[Xiong et~al.(2016)Xiong, Du, Zhang, Hu, and Tao]{Xiong:2016}
W.~Xiong, B.~Du, L.~Zhang, R.~Hu, and D.~Tao.
\newblock Regularizing deep convolutional neural networks with a structured
  decorrelation constraint.
\newblock In \emph{IEEE Int. Conf. on Data Mining (ICDM)}, 2016.

\bibitem[Zeiler(2012)]{adadelta}
Matthew~D. Zeiler.
\newblock {ADADELTA:} an adaptive learning rate method.
\newblock \emph{CoRR}, abs/1212.5701, 2012.
\newblock URL \url{http://arxiv.org/abs/1212.5701}.

\bibitem[Zhang and Jiang(2015)]{HOPE1}
Shiliang Zhang and Hui Jiang.
\newblock Hybrid orthogonal projection and estimation {(HOPE):} {A} new
  framework to probe and learn neural networks.
\newblock \emph{CoRR}, abs/1502.00702, 2015.

\bibitem[Zhou et~al.(2006)Zhou, Alvarez, and Porikli]{Zhou:ECCV2006}
Hao Zhou, Jose~M. Alvarez, and Fatih Porikli.
\newblock Less is more: Towards compact cnns.
\newblock In \emph{ECCV}, 2006.

\end{thebibliography}
