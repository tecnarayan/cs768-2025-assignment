\begin{thebibliography}{24}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Singh et~al.(2010)Singh, Lewis, Barto, and
  Sorg]{singh2010intrinsically}
Satinder Singh, Richard~L Lewis, Andrew~G Barto, and Jonathan Sorg.
\newblock Intrinsically motivated reinforcement learning: An evolutionary
  perspective.
\newblock \emph{IEEE Transactions on Autonomous Mental Development}, 2\penalty0
  (2):\penalty0 70--82, 2010.

\bibitem[Ng et~al.(1999)Ng, Harada, and Russell]{ng1999policy}
Andrew~Y Ng, Daishi Harada, and Stuart~J Russell.
\newblock Policy invariance under reward transformations: Theory and
  application to reward shaping.
\newblock In \emph{Proceedings of the Sixteenth International Conference on
  Machine Learning}, pages 278--287. Morgan Kaufmann Publishers Inc., 1999.

\bibitem[Rajeswaran et~al.(2017)Rajeswaran, Lowrey, Todorov, and
  Kakade]{rajeswaran2017towards}
Aravind Rajeswaran, Kendall Lowrey, Emanuel~V Todorov, and Sham~M Kakade.
\newblock Towards generalization and simplicity in continuous control.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6553--6564, 2017.

\bibitem[Bellemare et~al.(2016)Bellemare, Srinivasan, Ostrovski, Schaul,
  Saxton, and Munos]{bellemare2016unifying}
Marc Bellemare, Sriram Srinivasan, Georg Ostrovski, Tom Schaul, David Saxton,
  and Remi Munos.
\newblock Unifying count-based exploration and intrinsic motivation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1471--1479, 2016.

\bibitem[Ostrovski et~al.(2017)Ostrovski, Bellemare, Oord, and
  Munos]{ostrovski2017count}
Georg Ostrovski, Marc~G Bellemare, A{\"a}ron Oord, and R{\'e}mi Munos.
\newblock Count-based exploration with neural density models.
\newblock In \emph{International Conference on Machine Learning}, pages
  2721--2730, 2017.

\bibitem[Tang et~al.(2017)Tang, Houthooft, Foote, Stooke, Chen, Duan, Schulman,
  DeTurck, and Abbeel]{tang2017exploration}
Haoran Tang, Rein Houthooft, Davis Foote, Adam Stooke, OpenAI~Xi Chen, Yan
  Duan, John Schulman, Filip DeTurck, and Pieter Abbeel.
\newblock \# exploration: A study of count-based exploration for deep
  reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2750--2759, 2017.

\bibitem[Amodei et~al.(2016)Amodei, Olah, Steinhardt, Christiano, Schulman, and
  Man{\'e}]{amodei2016concrete}
Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and
  Dan Man{\'e}.
\newblock Concrete problems in ai safety.
\newblock \emph{arXiv preprint arXiv:1606.06565}, 2016.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{mnih2016asynchronous}
Volodymyr Mnih, Adria~Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy
  Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  1928--1937, 2016.

\bibitem[Duan et~al.(2016)Duan, Chen, Houthooft, Schulman, and
  Abbeel]{duan2016benchmarking}
Yan Duan, Xi~Chen, Rein Houthooft, John Schulman, and Pieter Abbeel.
\newblock Benchmarking deep reinforcement learning for continuous control.
\newblock In \emph{International Conference on Machine Learning}, pages
  1329--1338, 2016.

\bibitem[Sorg et~al.(2010)Sorg, Lewis, and Singh]{sorg2010reward}
Jonathan Sorg, Richard~L Lewis, and Satinder Singh.
\newblock Reward design via online gradient ascent.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2190--2198, 2010.

\bibitem[Guo et~al.(2016)Guo, Singh, Lewis, and Lee]{guo2016deep}
Xiaoxiao Guo, Satinder Singh, Richard Lewis, and Honglak Lee.
\newblock Deep learning for reward design to improve monte carlo tree search in
  atari games.
\newblock \emph{arXiv preprint arXiv:1604.07095}, 2016.

\bibitem[Jaderberg et~al.(2016)Jaderberg, Mnih, Czarnecki, Schaul, Leibo,
  Silver, and Kavukcuoglu]{jaderberg2016reinforcement}
Max Jaderberg, Volodymyr Mnih, Wojciech~Marian Czarnecki, Tom Schaul, Joel~Z
  Leibo, David Silver, and Koray Kavukcuoglu.
\newblock Reinforcement learning with unsupervised auxiliary tasks.
\newblock \emph{arXiv preprint arXiv:1611.05397}, 2016.

\bibitem[Pathak et~al.(2017)Pathak, Agrawal, Efros, and
  Darrell]{pathak2017curiosity}
Deepak Pathak, Pulkit Agrawal, Alexei~A Efros, and Trevor Darrell.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In \emph{International Conference on Machine Learning (ICML)}, volume
  2017, 2017.

\bibitem[Schmidhuber(2010)]{schmidhuber2010formal}
J{\"u}rgen Schmidhuber.
\newblock Formal theory of creativity, fun, and intrinsic motivation
  (1990--2010).
\newblock \emph{IEEE Transactions on Autonomous Mental Development}, 2\penalty0
  (3):\penalty0 230--247, 2010.

\bibitem[Stadie et~al.(2015)Stadie, Levine, and
  Abbeel]{stadie2015incentivizing}
Bradly~C Stadie, Sergey Levine, and Pieter Abbeel.
\newblock Incentivizing exploration in reinforcement learning with deep
  predictive models.
\newblock \emph{arXiv preprint arXiv:1507.00814}, 2015.

\bibitem[Oudeyer and Kaplan(2009)]{Oudeyer}
Pierre-Yves Oudeyer and Frederic Kaplan.
\newblock What is intrinsic motivation? a typology of computational approaches.
\newblock \emph{Frontiers in Neurorobotics}, 1:\penalty0 6, 2009.

\bibitem[Vezhnevets et~al.(2017)Vezhnevets, Osindero, Schaul, Heess, Jaderberg,
  Silver, and Kavukcuoglu]{vezhnevets2017feudal}
Alexander~Sasha Vezhnevets, Simon Osindero, Tom Schaul, Nicolas Heess, Max
  Jaderberg, David Silver, and Koray Kavukcuoglu.
\newblock Feudal networks for hierarchical reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  3540--3549, 2017.

\bibitem[Sutton et~al.(2000)Sutton, McAllester, Singh, and
  Mansour]{sutton2000policy}
Richard~S Sutton, David~A McAllester, Satinder Singh, and Yishay Mansour.
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock In \emph{Advances in neural information processing systems}, pages
  1057--1063, 2000.

\bibitem[Bellemare et~al.(2013)Bellemare, Naddaf, Veness, and
  Bowling]{bellemare2013arcade}
Marc~G Bellemare, Yavar Naddaf, Joel Veness, and Michael Bowling.
\newblock The arcade learning environment: An evaluation platform for general
  agents.
\newblock \emph{J. Artif. Intell. Res.(JAIR)}, 47:\penalty0 253--279, 2013.

\bibitem[Dhariwal et~al.(2017)Dhariwal, Hesse, Klimov, Nichol, Plappert,
  Radford, Schulman, Sidor, and Wu]{baselines}
Prafulla Dhariwal, Christopher Hesse, Oleg Klimov, Alex Nichol, Matthias
  Plappert, Alec Radford, John Schulman, Szymon Sidor, and Yuhuai Wu.
\newblock Openai baselines.
\newblock \url{https://github.com/openai/baselines}, 2017.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529, 2015.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Schulman et~al.(2015)Schulman, Moritz, Levine, Jordan, and
  Abbeel]{schulman2015high}
John Schulman, Philipp Moritz, Sergey Levine, Michael Jordan, and Pieter
  Abbeel.
\newblock High-dimensional continuous control using generalized advantage
  estimation.
\newblock \emph{arXiv preprint arXiv:1506.02438}, 2015.

\end{thebibliography}
