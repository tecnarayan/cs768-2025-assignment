\begin{thebibliography}{}

\bibitem[Abadi {\em et~al.}(2016)Abadi, Barham, Chen, Chen, Davis, Dean, Devin,
  Ghemawat, Irving, Isard, {\em et~al.}]{abadi2016tensorflow}
Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M.,
  Ghemawat, S., Irving, G., Isard, M., {\em et~al.} (2016).
\newblock Tensorflow: A system for large-scale machine learning.
\newblock In {\em 12th $\{$USENIX$\}$ Symposium on Operating Systems Design and
  Implementation ($\{$OSDI$\}$ 16)\/}, pages 265--283.

\bibitem[Ak{\c{c}}ay and Roughgarden(2011)Ak{\c{c}}ay and
  Roughgarden]{akccay2011evolution}
Ak{\c{c}}ay, E. and Roughgarden, J. (2011).
\newblock The evolution of payoff matrices: providing incentives to cooperate.
\newblock {\em Proceedings of the Royal Society B: Biological Sciences\/}, {\bf
  278}(1715), 2198--2206.

\bibitem[Albrecht and Stone(2018)Albrecht and Stone]{albrecht2018autonomous}
Albrecht, S.~V. and Stone, P. (2018).
\newblock Autonomous agents modelling other agents: A comprehensive survey and
  open problems.
\newblock {\em Artificial Intelligence\/}, {\bf 258}, 66--95.

\bibitem[Balduzzi {\em et~al.}(2018)Balduzzi, Racaniere, Martens, Foerster,
  Tuyls, and Graepel]{balduzzi2018mechanics}
Balduzzi, D., Racaniere, S., Martens, J., Foerster, J., Tuyls, K., and Graepel,
  T. (2018).
\newblock The mechanics of n-player differentiable games.
\newblock In {\em International Conference on Machine Learning\/}, pages
  354--363.

\bibitem[Baumann {\em et~al.}(2018)Baumann, Graepel, and
  Shawe-Taylor]{baumann2018adaptive}
Baumann, T., Graepel, T., and Shawe-Taylor, J. (2018).
\newblock Adaptive mechanism design: Learning to promote cooperation.
\newblock {\em arXiv preprint arXiv:1806.04067\/}.

\bibitem[Berner {\em et~al.}(2019)Berner, Brockman, Chan, Cheung, D{\k{e}}biak,
  Dennison, Farhi, Fischer, Hashme, Hesse, {\em et~al.}]{berner2019dota}
Berner, C., Brockman, G., Chan, B., Cheung, V., D{\k{e}}biak, P., Dennison, C.,
  Farhi, D., Fischer, Q., Hashme, S., Hesse, C., {\em et~al.} (2019).
\newblock Dota 2 with large scale deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1912.06680\/}.

\bibitem[Colson {\em et~al.}(2007)Colson, Marcotte, and
  Savard]{colson2007overview}
Colson, B., Marcotte, P., and Savard, G. (2007).
\newblock An overview of bilevel optimization.
\newblock {\em Annals of operations research\/}, {\bf 153}(1), 235--256.

\bibitem[Delfgaauw and Dur(2008)Delfgaauw and Dur]{delfgaauw2008incentives}
Delfgaauw, J. and Dur, R. (2008).
\newblock Incentives and workers’ motivation in the public sector.
\newblock {\em The Economic Journal\/}, {\bf 118}(525), 171--191.

\bibitem[Doxey(1980)Doxey]{doxey1980economic}
Doxey, M.~P. (1980).
\newblock {\em Economic sanctions and international enforcement\/}.
\newblock Springer.

\bibitem[Eccles {\em et~al.}(2019)Eccles, Hughes, Kram{\'a}r, Wheelwright, and
  Leibo]{eccles2019learning}
Eccles, T., Hughes, E., Kram{\'a}r, J., Wheelwright, S., and Leibo, J.~Z.
  (2019).
\newblock Learning reciprocity in complex sequential social dilemmas.
\newblock {\em arXiv preprint arXiv:1903.08082\/}.

\bibitem[Everitt and Hutter(2019)Everitt and Hutter]{everitt2019reward}
Everitt, T. and Hutter, M. (2019).
\newblock Reward tampering problems and solutions in reinforcement learning: A
  causal influence diagram perspective.
\newblock {\em arXiv preprint arXiv:1908.04734\/}.

\bibitem[Foerster {\em et~al.}(2018a)Foerster, Chen, Al-Shedivat, Whiteson,
  Abbeel, and Mordatch]{foerster2018learning}
Foerster, J., Chen, R.~Y., Al-Shedivat, M., Whiteson, S., Abbeel, P., and
  Mordatch, I. (2018a).
\newblock Learning with opponent-learning awareness.
\newblock In {\em Proceedings of the 17th International Conference on
  Autonomous Agents and MultiAgent Systems\/}, pages 122--130. International
  Foundation for Autonomous Agents and Multiagent Systems.

\bibitem[Foerster {\em et~al.}(2018b)Foerster, Farquhar, Afouras, Nardelli, and
  Whiteson]{foerster2018counterfactual}
Foerster, J.~N., Farquhar, G., Afouras, T., Nardelli, N., and Whiteson, S.
  (2018b).
\newblock Counterfactual multi-agent policy gradients.
\newblock In {\em Thirty-second AAAI conference on artificial intelligence\/}.

\bibitem[Fong and Surti(2009)Fong and Surti]{fong2009optimal}
Fong, Y.-f. and Surti, J. (2009).
\newblock The optimal degree of cooperation in the repeated prisoners' dilemma
  with side payments.
\newblock {\em Games and Economic Behavior\/}, {\bf 67}(1), 277--291.

\bibitem[G{\"u}th(1995)G{\"u}th]{guth1995evolutionary}
G{\"u}th, W. (1995).
\newblock An evolutionary approach to explaining cooperative behavior by
  reciprocal incentives.
\newblock {\em International Journal of Game Theory\/}, {\bf 24}(4), 323--344.

\bibitem[Harstad(2008)Harstad]{harstad2008side}
Harstad, B. (2008).
\newblock Do side payments help? collective decisions and strategic delegation.
\newblock {\em Journal of the European Economic Association\/}, {\bf 6}(2-3),
  468--477.

\bibitem[Hostallero {\em et~al.}(2020)Hostallero, Kim, Moon, Son, Kang, and
  Yi]{hostallero2020inducing}
Hostallero, D.~E., Kim, D., Moon, S., Son, K., Kang, W.~J., and Yi, Y. (2020).
\newblock Inducing cooperation through reward reshaping based on peer
  evaluations in deep multi-agent reinforcement learning.
\newblock In {\em Proceedings of the 19th International Conference on
  Autonomous Agents and MultiAgent Systems\/}, pages 520--528.

\bibitem[Hughes {\em et~al.}(2018)Hughes, Leibo, Phillips, Tuyls,
  Due{\~n}ez-Guzman, Casta{\~n}eda, Dunning, Zhu, McKee, Koster, {\em
  et~al.}]{hughes2018inequity}
Hughes, E., Leibo, J.~Z., Phillips, M., Tuyls, K., Due{\~n}ez-Guzman, E.,
  Casta{\~n}eda, A.~G., Dunning, I., Zhu, T., McKee, K., Koster, R., {\em
  et~al.} (2018).
\newblock Inequity aversion improves cooperation in intertemporal social
  dilemmas.
\newblock In {\em Advances in neural information processing systems\/}, pages
  3326--3336.

\bibitem[Jackson and Wilkie(2005)Jackson and Wilkie]{jackson2005endogenous}
Jackson, M.~O. and Wilkie, S. (2005).
\newblock Endogenous games and mechanisms: Side payments among players.
\newblock {\em The Review of Economic Studies\/}, {\bf 72}(2), 543--566.

\bibitem[Jaderberg {\em et~al.}(2019)Jaderberg, Czarnecki, Dunning, Marris,
  Lever, Castaneda, Beattie, Rabinowitz, Morcos, Ruderman, {\em
  et~al.}]{jaderberg2019human}
Jaderberg, M., Czarnecki, W.~M., Dunning, I., Marris, L., Lever, G., Castaneda,
  A.~G., Beattie, C., Rabinowitz, N.~C., Morcos, A.~S., Ruderman, A., {\em
  et~al.} (2019).
\newblock Human-level performance in 3d multiplayer games with population-based
  reinforcement learning.
\newblock {\em Science\/}, {\bf 364}(6443), 859--865.

\bibitem[Jaques {\em et~al.}(2019)Jaques, Lazaridou, Hughes, Gulcehre, Ortega,
  Strouse, Leibo, and De~Freitas]{jaques2019social}
Jaques, N., Lazaridou, A., Hughes, E., Gulcehre, C., Ortega, P., Strouse, D.,
  Leibo, J.~Z., and De~Freitas, N. (2019).
\newblock Social influence as intrinsic motivation for multi-agent deep
  reinforcement learning.
\newblock In {\em International Conference on Machine Learning\/}, pages
  3040--3049. PMLR.

\bibitem[Kingma and Ba(2015)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J. (2015).
\newblock Adam: A method for stochastic optimization.
\newblock In {\em International Conference on Learning Representations\/}.

\bibitem[Leibo {\em et~al.}(2017)Leibo, Zambaldi, Lanctot, Marecki, and
  Graepel]{leibo2017multi}
Leibo, J.~Z., Zambaldi, V., Lanctot, M., Marecki, J., and Graepel, T. (2017).
\newblock Multi-agent reinforcement learning in sequential social dilemmas.
\newblock In {\em Proceedings of the 16th Conference on Autonomous Agents and
  MultiAgent Systems\/}, pages 464--473. International Foundation for
  Autonomous Agents and Multiagent Systems.

\bibitem[Lerer and Peysakhovich(2017)Lerer and
  Peysakhovich]{lerer2017maintaining}
Lerer, A. and Peysakhovich, A. (2017).
\newblock Maintaining cooperation in complex social dilemmas using deep
  reinforcement learning.
\newblock {\em arXiv preprint arXiv:1707.01068\/}.

\bibitem[Letcher {\em et~al.}(2019)Letcher, Foerster, Balduzzi,
  Rockt{\"a}schel, and Whiteson]{letcher2019stable}
Letcher, A., Foerster, J., Balduzzi, D., Rockt{\"a}schel, T., and Whiteson, S.
  (2019).
\newblock Stable opponent shaping in differentiable games.
\newblock In {\em International Conference on Learning Representations\/}.

\bibitem[Littman(1994)Littman]{littman1994markov}
Littman, M.~L. (1994).
\newblock Markov games as a framework for multi-agent reinforcement learning.
\newblock In {\em Machine Learning Proceedings 1994\/}, pages 157--163.
  Elsevier.

\bibitem[Lupu and Precup(2020)Lupu and Precup]{lupu2020gifting}
Lupu, A. and Precup, D. (2020).
\newblock Gifting in multi-agent reinforcement learning.
\newblock In {\em Proceedings of the 19th Conference on Autonomous Agents and
  MultiAgent Systems\/}, pages 789--797. International Foundation for
  Autonomous Agents and Multiagent Systems.

\bibitem[Mnih {\em et~al.}(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness,
  Bellemare, Graves, Riedmiller, Fidjeland, Ostrovski, {\em
  et~al.}]{mnih2015human}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., {\em
  et~al.} (2015).
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature\/}, {\bf 518}(7540), 529--533.

\bibitem[Olson(1965)Olson]{olson1965logic}
Olson, M. (1965).
\newblock {\em The Logic of Collective Action\/}.
\newblock Harvard University Press.

\bibitem[Rapoport(1974)Rapoport]{rapoport1974prisoner}
Rapoport, A. (1974).
\newblock Prisoner’s dilemma—recollections and observations.
\newblock In {\em Game Theory as a Theory of a Conflict Resolution\/}, pages
  17--34. Springer.

\bibitem[Rashid {\em et~al.}(2018)Rashid, Samvelyan, Schroeder, Farquhar,
  Foerster, and Whiteson]{rashid2018a}
Rashid, T., Samvelyan, M., Schroeder, C., Farquhar, G., Foerster, J., and
  Whiteson, S. (2018).
\newblock {QMIX}: Monotonic value function factorisation for deep multi-agent
  reinforcement learning.
\newblock In {\em Proceedings of the 35th International Conference on Machine
  Learning\/}, pages 4295--4304.

\bibitem[Silver {\em et~al.}(2017)Silver, Schrittwieser, Simonyan, Antonoglou,
  Huang, Guez, Hubert, Baker, Lai, Bolton, {\em et~al.}]{silver2017mastering}
Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez,
  A., Hubert, T., Baker, L., Lai, M., Bolton, A., {\em et~al.} (2017).
\newblock Mastering the game of go without human knowledge.
\newblock {\em Nature\/}, {\bf 550}(7676), 354--359.

\bibitem[Singh {\em et~al.}(2009)Singh, Lewis, and Barto]{singh2009rewards}
Singh, S., Lewis, R.~L., and Barto, A.~G. (2009).
\newblock Where do rewards come from.
\newblock In {\em Proceedings of the annual conference of the cognitive science
  society\/}, pages 2601--2606. Cognitive Science Society.

\bibitem[Sodomka {\em et~al.}(2013)Sodomka, Hilliard, Littman, and
  Greenwald]{sodomka2013coco}
Sodomka, E., Hilliard, E., Littman, M., and Greenwald, A. (2013).
\newblock Coco-q: Learning in stochastic games with side payments.
\newblock In {\em International Conference on Machine Learning\/}, pages
  1471--1479.

\bibitem[Sunehag {\em et~al.}(2018)Sunehag, Lever, Gruslys, Czarnecki,
  Zambaldi, Jaderberg, Lanctot, Sonnerat, Leibo, Tuyls, {\em
  et~al.}]{sunehag2018value}
Sunehag, P., Lever, G., Gruslys, A., Czarnecki, W.~M., Zambaldi, V., Jaderberg,
  M., Lanctot, M., Sonnerat, N., Leibo, J.~Z., Tuyls, K., {\em et~al.} (2018).
\newblock Value-decomposition networks for cooperative multi-agent learning
  based on team reward.
\newblock In {\em Proceedings of the 17th International Conference on
  Autonomous Agents and MultiAgent Systems\/}, pages 2085--2087. International
  Foundation for Autonomous Agents and Multiagent Systems.

\bibitem[Sutton(1992)Sutton]{sutton1992adapting}
Sutton, R.~S. (1992).
\newblock Adapting bias by gradient descent: An incremental version of
  delta-bar-delta.
\newblock In {\em AAAI\/}, pages 171--176.

\bibitem[Sutton and Barto(2018)Sutton and Barto]{sutton2018reinforcement}
Sutton, R.~S. and Barto, A.~G. (2018).
\newblock {\em Reinforcement learning: An introduction\/}.
\newblock MIT press.

\bibitem[Sutton {\em et~al.}(2000)Sutton, McAllester, Singh, and
  Mansour]{sutton2000policy}
Sutton, R.~S., McAllester, D.~A., Singh, S.~P., and Mansour, Y. (2000).
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock In {\em Advances in neural information processing systems\/}, pages
  1057--1063.

\bibitem[Veroff and Veroff(2016)Veroff and Veroff]{veroff2016social}
Veroff, J. and Veroff, J.~B. (2016).
\newblock {\em Social incentives: A life-span developmental approach\/}.
\newblock Elsevier.

\bibitem[Vinitsky(2020)Vinitsky]{vinitsky2020}
Vinitsky, E. (2020).
\newblock {\em Sequential Social Dilemma Games\/}.
\newblock
  \url{https://github.com/eugenevinitsky/sequential_social_dilemma_games}.

\bibitem[Vinyals {\em et~al.}(2019)Vinyals, Babuschkin, Czarnecki, Mathieu,
  Dudzik, Chung, Choi, Powell, Ewalds, Georgiev, {\em
  et~al.}]{vinyals2019grandmaster}
Vinyals, O., Babuschkin, I., Czarnecki, W.~M., Mathieu, M., Dudzik, A., Chung,
  J., Choi, D.~H., Powell, R., Ewalds, T., Georgiev, P., {\em et~al.} (2019).
\newblock Grandmaster level in starcraft ii using multi-agent reinforcement
  learning.
\newblock {\em Nature\/}, {\bf 575}(7782), 350--354.

\bibitem[Wang {\em et~al.}(2019)Wang, Hughes, Fernando, Czarnecki,
  Du{\'e}{\~n}ez-Guzm{\'a}n, and Leibo]{wang2019evolving}
Wang, J.~X., Hughes, E., Fernando, C., Czarnecki, W.~M.,
  Du{\'e}{\~n}ez-Guzm{\'a}n, E.~A., and Leibo, J.~Z. (2019).
\newblock Evolving intrinsic motivations for altruistic behavior.
\newblock In {\em Proceedings of the 18th International Conference on
  Autonomous Agents and MultiAgent Systems\/}, pages 683--692. International
  Foundation for Autonomous Agents and Multiagent Systems.

\bibitem[Xu {\em et~al.}(2018)Xu, van Hasselt, and Silver]{xu2018meta}
Xu, Z., van Hasselt, H.~P., and Silver, D. (2018).
\newblock Meta-gradient reinforcement learning.
\newblock In {\em Advances in neural information processing systems\/}, pages
  2396--2407.

\bibitem[Zheng {\em et~al.}(2018)Zheng, Oh, and Singh]{zheng2018learning}
Zheng, Z., Oh, J., and Singh, S. (2018).
\newblock On learning intrinsic rewards for policy gradient methods.
\newblock In {\em Advances in Neural Information Processing Systems\/}, pages
  4644--4654.

\end{thebibliography}
