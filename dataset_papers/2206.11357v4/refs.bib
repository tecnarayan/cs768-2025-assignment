@article{shelhamer2017fully,
  title={Fully convolutional networks for semantic segmentation},
  author={Shelhamer, Evan and Long, Jonathan and Darrell, Trevor},
  journal={TPAMI},
  year={2017},
}

@article{wang2020deep,
  title={Deep high-resolution representation learning for visual recognition},
  author={Wang, Jingdong and Sun, Ke and Cheng, Tianheng and Jiang, Borui and Deng, Chaorui and Zhao, Yang and Liu, Dong and Mu, Yadong and Tan, Mingkui and Wang, Xinggang and Liu, Wenyu and Xiao Bin},
  journal={TPAMI},
  year={2020}
}

@inproceedings{kirillov2019panoptic,
  title={Panoptic feature pyramid networks},
  author={Kirillov, Alexander and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={6399--6408},
  year={2019}
}

@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={International Conference on Computer Vision (ICCV)},
  pages={2980--2988},
  year={2017}
}

@inproceedings{peng2018megdet,
  title={Megdet: A large mini-batch object detector},
  author={Peng, Chao and Xiao, Tete and Li, Zeming and Jiang, Yuning and Zhang, Xiangyu and Jia, Kai and Yu, Gang and Sun, Jian},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={6181--6189},
  year={2018}
}

@inproceedings{zhu2019towards,
  title={Towards unified {INT8} training for convolutional neural network},
  author={Zhu, Feng and Gong, Ruihao and Yu, Fengwei and Liu, Xianglong and Wang, Yanfei and Li, Zhelong and Yang, Xiuqi and Yan, Junjie},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={1969--1979},
  year={2020}
}

@article{zhou2016dorefa,
  title={Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients},
  author={Zhou, Shuchang and Wu, Yuxin and Ni, Zekun and Zhou, Xinyu and Wen, He and Zou, Yuheng},
  journal={arXiv preprint arXiv:1606.06160},
  year={2016}
}

@inproceedings{banner2018scalable,
  title={Scalable methods for 8-bit training of neural networks},
  author={Banner, Ron and Hubara, Itay and Hoffer, Elad and Soudry, Daniel},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5145--5153},
  year={2018}
}

@inproceedings{wu2018training,
  title={Training and Inference with Integers in Deep Neural Networks},
  author={Wu, Shuang and Li, Guoqi and Chen, Feng and Shi, Luping},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{yang2020training,
  title={Training high-performance and large-scale deep neural networks with full 8-bit integers},
  author={Yang, Yukuan and Deng, Lei and Wu, Shuang and Yan, Tianyi and Xie, Yuan and Li, Guoqi},
  journal={Neural Networks},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{wang2018training,
  title={Training deep neural networks with 8-bit floating point numbers},
  author={Wang, Naigang and Choi, Jungwook and Brand, Daniel and Chen, Chia-Yu and Gopalakrishnan, Kailash},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7675--7684},
  year={2018}
}

@inproceedings{sakr2019per,
  title={Per-tensor fixed-point quantization of the back-propagation algorithm},
  author={Sakr, Charbel and Shanbhag, Naresh R},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{drumond2018training,
  title={Training DNNs with hybrid block floating point},
  author={Drumond, Mario and Tao, LIN and Jaggi, Martin and Falsafi, Babak},
  booktitle={Advances in Neural Information Processing Systems},
  pages={453--463},
  year={2018}
}

@inproceedings{cambier2020shifted,
  title={Shifted and Squeezed 8-bit Floating Point format for Low-Precision Training of Deep Neural Networks},
  author={Cambier, L{\'e}opold and Bhiwandiwalla, Anahita and Gong, Ting and Nekuii, Mehran and Elibol, Oguz H and Tang, Hanlin},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{sun2019hybrid,
  title={Hybrid 8-bit Floating Point (HFP8) Training and Inference for Deep Neural Networks},
  author={Sun, Xiao and Choi, Jungwook and Chen, Chia-Yu and Wang, Naigang and Venkataramani, Swagath and Srinivasan, Vijayalakshmi Viji and Cui, Xiaodong and Zhang, Wei and Gopalakrishnan, Kailash},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4901--4910},
  year={2019}
}

@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc V},
  booktitle={International Conference on Machine LEarning},
  year={2019}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI Blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{rissanen1978modeling,
  title={Modeling by shortest data description},
  author={Rissanen, Jorma},
  journal={Automatica},
  volume={14},
  number={5},
  pages={465--471},
  year={1978},
  publisher={Elsevier}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@InProceedings{simonyan2014very,
  author       = "Simonyan, K. and Zisserman, A.",
  title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
  booktitle    = "International Conference on Learning Representations",
  year         = "2015",
}

@inproceedings{han2015learning,
  title={Learning both weights and connections for efficient neural network},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William},
  booktitle={Advances in neural information processing systems},
  pages={1135--1143},
  year={2015}
}


@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

@inproceedings{ma2018shufflenet,
  title={Shufflenet v2: Practical guidelines for efficient cnn architecture design},
  author={Ma, Ningning and Zhang, Xiangyu and Zheng, Hai-Tao and Sun, Jian},
  booktitle={ European Conference on Computer Vision (ECCV)},
  pages={116--131},
  year={2018}
}

@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={4510--4520},
  year={2018}
}


@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{he2016identity,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={European conference on computer vision},
  pages={630--645},
  year={2016},
  organization={Springer}
}

@article{han2015deep,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={International Conference on Learning Representations},
  year={2016}
}

@article{zhou2017incremental,
  title={Incremental network quantization: Towards lossless cnns with low-precision weights},
  author={Zhou, Aojun and Yao, Anbang and Guo, Yiwen and Xu, Lin and Chen, Yurong},
  journal={International Conference on Learning Representations},
  year={2017}
}

@article{choi2018pact,
  title={Pact: Parameterized clipping activation for quantized neural networks},
  author={Choi, Jungwook and Wang, Zhuo and Venkataramani, Swagath and Chuang, Pierce I-Jen and Srinivasan, Vijayalakshmi and Gopalakrishnan, Kailash},
  journal={arXiv preprint arXiv:1805.06085},
  year={2018}
}

@article{krishnamoorthi2018quantizing,
  title={Quantizing deep convolutional networks for efficient inference: A whitepaper},
  author={Krishnamoorthi, Raghuraman},
  journal={arXiv preprint arXiv:1806.08342},
  year={2018}
}

@inproceedings{jacob2018quantization,
  title={Quantization and training of neural networks for efficient integer-arithmetic-only inference},
  author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={2704--2713},
  year={2018}
}

@article{iandola2016squeezenet,
  title={SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and $<$0.5 {MB} model size},
  author={Iandola, Forrest N and Han, Song and Moskewicz, Matthew W and Ashraf, Khalid and Dally, William J and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1602.07360},
  year={2016}
}

@article{polino2018model,
  title={Model compression via distillation and quantization},
  author={Polino, Antonio and Pascanu, Razvan and Alistarh, Dan},
  journal={arXiv preprint arXiv:1802.05668},
  year={2018}
}

@article{howard2017mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@inproceedings{zhang2018shufflenet,
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={6848--6856},
  year={2018}
}

@inproceedings{chollet2017xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Fran{\c{c}}ois},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={1251--1258},
  year={2017}
}

@inproceedings{rastegari2016xnor,
  title={{Xnor-net}: Imagenet classification using binary convolutional neural networks},
  author={Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali},
  booktitle={European Conference on Computer Vision},
  pages={525--542},
  year={2016},
  organization={Springer}
}

@inproceedings{courbariaux2015binaryconnect,
  title={Binaryconnect: Training deep neural networks with binary weights during propagations},
  author={Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
  booktitle={Advances in neural information processing systems},
  pages={3123--3131},
  year={2015}
}

@InProceedings{Zhang_2018_ECCV,
author = {Zhang, Dongqing and Yang, Jiaolong and Ye, Dongqiangzi and Hua, Gang},
title = {{LQ-Nets}: Learned Quantization for Highly Accurate and Compact Deep Neural Networks},
booktitle = {The European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}

@inproceedings{krogh1992simple,
  title={A simple weight decay can improve generalization},
  author={Krogh, Anders and Hertz, John A},
  booktitle={Advances in neural information processing systems},
  pages={950--957},
  year={1992}
}

@article{romero2014fitnets,
  title={Fitnets: Hints for thin deep nets},
  author={Romero, Adriana and Ballas, Nicolas and Kahou, Samira Ebrahimi and Chassang, Antoine and Gatta, Carlo and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.6550},
  year={2014}
}

@inproceedings{grosse2016kronecker,
  title={A Kronecker-factored approximate Fisher matrix for convolution layers},
  author={Grosse, Roger and Martens, James},
  booktitle={International Conference on Machine Learning},
  pages={573--582},
  year={2016}
}

@inproceedings{redmon2017yolo9000,
  title={YOLO9000: better, faster, stronger},
  author={Redmon, Joseph and Farhadi, Ali},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={7263--7271},
  year={2017}
}


@inproceedings{sharma2018bit,
  title={Bit fusion: Bit-level dynamically composable architecture for accelerating deep neural networks},
  author={Sharma, Hardik and Park, Jongse and Suda, Naveen and Lai, Liangzhen and Chau, Benson and Chandra, Vikas and Esmaeilzadeh, Hadi},
  booktitle={ 45th Annual International Symposium on Computer Architecture},
  pages={764--775},
  year={2018},
  organization={IEEE Press}
}

@inproceedings{bismo,
author = {Umuroglu, Yaman and Rasnayake, Lahiru and Sjalander, Magnus},
title = {BISMO: A Scalable Bit-Serial Matrix Multiplication Overlay for Reconfigurable Computing},
booktitle = {Field Programmable Logic and Applications (FPL), 2018 28th International Conference on},
series = {FPL '18},
year = {2018}
}

@article{li2016pruning,
  title={Pruning filters for efficient convnets},
  author={Li, Hao and Kadav, Asim and Durdanovic, Igor and Samet, Hanan and Graf, Hans Peter},
  journal={arXiv preprint arXiv:1608.08710},
  year={2016}
}

@article{molchanov2016pruning,
  title={Pruning convolutional neural networks for resource efficient inference},
  author={Molchanov, Pavlo and Tyree, Stephen and Karras, Tero and Aila, Timo and Kautz, Jan},
  journal={arXiv preprint arXiv:1611.06440},
  year={2016}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={Workshop paper in NIPS},
  year={2014}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={ IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Taipei, Taiwan}
}

@article{shallue2018measuring,
  title={Measuring the effects of data parallelism on neural network training},
  author={Shallue, Christopher J and Lee, Jaehoon and Antognini, Joe and Sohl-Dickstein, Jascha and Frostig, Roy and Dahl, George E},
  journal={arXiv preprint arXiv:1811.03600},
  year={2018}
}

@article{osawa2018second,
  title={Second-order Optimization Method for Large Mini-batch: Training ResNet-50 on ImageNet in 35 Epochs},
  author={Osawa, Kazuki and Tsuji, Yohei and Ueno, Yuichiro and Naruse, Akira and Yokota, Rio and Matsuoka, Satoshi},
  journal={arXiv preprint arXiv:1811.12019},
  year={2018}
}

@article{ba2016distributed,
  title={Distributed second-order optimization using Kronecker-factored approximations},
  author={Ba, Jimmy and Grosse, Roger and Martens, James},
  year={2016}
}

@article{KFAC-G15,
  author    = {James Martens and
               Roger B. Grosse},
  title     = {Optimizing Neural Networks with Kronecker-factored Approximate Curvature},
  journal   = {CoRR},
  volume    = {abs/1503.05671},
  year      = {2015},
  url       = {http://arxiv.org/abs/1503.05671},
  archivePrefix = {arXiv},
  eprint    = {1503.05671},
  timestamp = {Mon, 13 Aug 2018 16:47:40 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MartensG15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
wd-kfac,
title={Three Mechanisms of Weight Decay Regularization},
author={Guodong Zhang and Chaoqi Wang and Bowen Xu and Roger Grosse},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=B1lz-3Rct7},
}

@article{FACEBOOK-IMAGENET-1H,
  author    = {Priya Goyal and
               Piotr Doll{\'{a}}r and
               Ross B. Girshick and
               Pieter Noordhuis and
               Lukasz Wesolowski and
               Aapo Kyrola and
               Andrew Tulloch and
               Yangqing Jia and
               Kaiming He},
  title     = {Accurate, Large Minibatch {SGD:} Training ImageNet in 1 Hour},
  journal   = {CoRR},
  volume    = {abs/1706.02677},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.02677},
  archivePrefix = {arXiv},
  eprint    = {1706.02677},
  timestamp = {Mon, 13 Aug 2018 16:49:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/GoyalDGNWKTJH17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{GOOG-2M-IMAGENET,
  author    = {Yang You and
               Zhao Zhang and
               Cho{-}Jui Hsieh and
               James Demmel},
  title     = {100-epoch ImageNet Training with AlexNet in 24 Minutes},
  journal   = {CoRR},
  volume    = {abs/1709.05011},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.05011},
  archivePrefix = {arXiv},
  eprint    = {1709.05011},
  timestamp = {Mon, 13 Aug 2018 16:47:54 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1709-05011},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ma2017power,
  title={The power of interpolation: Understanding the effectiveness of SGD in modern over-parametrized learning},
  author={Ma, Siyuan and Bassily, Raef and Belkin, Mikhail},
  journal={arXiv preprint arXiv:1712.06559},
  year={2017}
}

@article{OpenAI-EMP-LBS,
  author    = {Sam McCandlish and
               Jared Kaplan and
               Dario Amodei and
               OpenAI Dota Team},
  title     = {An Empirical Model of Large-Batch Training},
  journal   = {CoRR},
  volume    = {abs/1812.06162},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.06162},
  archivePrefix = {arXiv},
  eprint    = {1812.06162},
  timestamp = {Tue, 01 Jan 2019 15:01:25 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1812-06162},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Noah-EMP-CRIT-BS,
  author    = {Noah Golmant and
               Nikita Vemuri and
               Zhewei Yao and
               Vladimir Feinberg and
               Amir Gholami and
               Kai Rothauge and
               Michael W. Mahoney and
               Joseph Gonzalez},
  title     = {On the Computational Inefficiency of Large Batch Sizes for Stochastic
               Gradient Descent},
  journal   = {CoRR},
  volume    = {abs/1811.12941},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.12941},
  archivePrefix = {arXiv},
  eprint    = {1811.12941},
  timestamp = {Mon, 03 Dec 2018 07:50:28 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-12941},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{szegedy2017inception,
  title={Inception-v4, inception-resnet and the impact of residual connections on learning},
  author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander A},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}


@article{GOOG-LB-KFAC-HYPO,
  author    = {Christopher J. Shallue and
               Jaehoon Lee and
               Joseph M. Antognini and
               Jascha Sohl{-}Dickstein and
               Roy Frostig and
               George E. Dahl},
  title     = {Measuring the Effects of Data Parallelism on Neural Network Training},
  journal   = {CoRR},
  volume    = {abs/1811.03600},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.03600},
  archivePrefix = {arXiv},
  eprint    = {1811.03600},
  timestamp = {Fri, 23 Nov 2018 12:43:51 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-03600},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{gholami2017integrated,
  title={Integrated Model, Batch and Domain Parallelism in Training Neural Networks},
  author={Gholami, Amir and Azad, Ariful and Jin, Peter and Keutzer, Kurt and Buluc, Aydin},
  journal={ACM Symposium on Parallelism in Algorithms and Architectures(SPAA'18)},
note={\href{https://arxiv.org/pdf/1712.04432.pdf}{[PDF]}},
  year={2018}
}

@inproceedings{zhang2015deep,
  title={Deep learning with elastic averaging SGD},
  author={Zhang, Sixin and Choromanska, Anna E and LeCun, Yann},
  booktitle={Advances in Neural Information Processing Systems},
  pages={685--693},
  year={2015}
}

@article{jia2018highly,
  title={Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes},
  author={Jia, Xianyan and Song, Shutao and He, Wei and Wang, Yangzihao and Rong, Haidong and Zhou, Feihu and Xie, Liqiang and Guo, Zhenyu and Yang, Yuanzhou and Yu, Liwei and Chen, Tiegang and Hu, Guangxiao and Shi, Shaohuai and Chu, Xiaowen},
  journal={arXiv preprint arXiv:1807.11205},
  year={2018}
}


@article{bertsimas2011theory,
  title={Theory and applications of robust optimization},
  author={Bertsimas, Dimitris and Brown, David B and Caramanis, Constantine},
  journal={SIAM review},
  volume={53},
  number={3},
  pages={464--501},
  year={2011},
  publisher={SIAM}
}

@article{maleki2017parallel,
  title={Parallel Stochastic Gradient Descent with Sound Combiners},
  author={Maleki, Saeed and Musuvathi, Madanlal and Mytkowicz, Todd},
  journal={arXiv preprint arXiv:1705.08030},
  year={2017}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{smith2018bayesian,
  title={A bayesian perspective on generalization and stochastic gradient descent},
  author={Smith, Samuel L and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.06451},
  year={2018}
}

@article{smith2017don,
  title={Don't Decay the Learning Rate, Increase the Batch Size},
  author={Smith, Samuel L and Kindermans, Pieter-Jan and Le, Quoc V},
  journal={arXiv preprint arXiv:1711.00489},
  year={2017}
}

@article{goyal2017accurate,
  title={Accurate, large minibatch SGD: training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}

@article{yao2018hessian,
  title={Hessian-based Analysis of Large Batch Training and Robustness to Adversaries},
  author={Yao, Zhewei and Gholami, Amir and Lei, Qi and Keutzer, Kurt and Mahoney, Michael W},
  journal={Advances in Neural Information Processing Systems},
  year={2018}
}

@article{keskar2016large,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1609.04836},
  year={2016}
}

@article{dinh2017sharp,
  title={Sharp minima can generalize for deep nets},
  author={Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1703.04933},
  year={2017}
}

@inproceedings{smith2017cyclical,
  title={Cyclical learning rates for training neural networks},
  author={Smith, Leslie N},
  booktitle={Applications of Computer Vision (WACV), 2017 IEEE Winter Conference on},
  pages={464--472},
  year={2017},
  organization={IEEE}
}

@article{huang2017snapshot,
  title={Snapshot ensembles: Train 1, get M for free},
  author={Huang, Gao and Li, Yixuan and Pleiss, Geoff and Liu, Zhuang and Hopcroft, John E and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:1704.00109},
  year={2017}
}

@techreport{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey},
  year={2009},
  institution={Citeseer}
}

@article{lin2013network,
  title={Network in network},
  author={Lin, Min and Chen, Qiang and Yan, Shuicheng},
  journal={arXiv preprint arXiv:1312.4400},
  year={2013}
}

@inproceedings{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  booktitle={NIPS workshop on deep learning and unsupervised feature learning},
  volume={2011},
  pages={5},
  year={2011}
}

@inproceedings{imagenet_cvpr09,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

@article{shwartz2017opening,
  title={Opening the black box of deep neural networks via information},
  author={Shwartz-Ziv, Ravid and Tishby, Naftali},
  journal={arXiv preprint arXiv:1703.00810},
  year={2017}
}

@incollection{bottou2010large,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}

@inproceedings{dauphin2014identifying,
  title={Identifying and attacking the saddle point problem in high-dimensional non-convex optimization},
  author={Dauphin, Yann N and Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Ganguli, Surya and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2933--2941},
  year={2014}
}

@article{devarakonda2017adabatch,
  title={AdaBatch: Adaptive Batch Sizes for Training Deep Neural Networks},
  author={Devarakonda, Aditya and Naumov, Maxim and Garland, Michael},
  journal={arXiv preprint arXiv:1712.02029},
  year={2017}
}


@article{zhu2018anisotropic,
  title={The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Minima and Regularization Effects},
  author={Zhu, Zhanxing and Wu, Jingfeng and Yu, Bing and Wu, Lei and Ma, Jinwen},
  journal={arXiv preprint arXiv:1803.00195},
  year={2018}
}

@article{friedlander2012hybrid,
  title={Hybrid deterministic-stochastic methods for data fitting},
  author={Friedlander, Michael P and Schmidt, Mark},
  journal={SIAM Journal on Scientific Computing},
  volume={34},
  number={3},
  pages={A1380--A1405},
  year={2012},
  publisher={SIAM}
}

@article{balles2016coupling,
  title={Coupling adaptive batch sizes with learning rates},
  author={Balles, Lukas and Romero, Javier and Hennig, Philipp},
  journal={arXiv preprint arXiv:1612.05086},
  year={2016}
}

@inproceedings{hoffer2017train,
  title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  author={Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1731--1741},
  year={2017}
}

@article{you2017scaling,
  title={Scaling sgd batch size to 32k for imagenet training},
  author={You, Yang and Gitman, Igor and Ginsburg, Boris},
  journal={arXiv preprint arXiv:1708.03888},
  year={2017}
}

@article{dong2017learning,
  title={Learning accurate low-bit deep neural networks with stochastic quantization},
  author={Dong, Yinpeng and Ni, Renkun and Li, Jianguo and Chen, Yurong and Zhu, Jun and Su, Hang},
  journal={British Machine Vision Conference},
  year={2017}
}

@article{puri2018large,
  title={Large Scale Language Modeling: Converging on 40GB of Text in Four Hours},
  author={Puri, Raul and Kirby, Robert and Yakovenko, Nikolai and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1808.01371},
  year={2018}
}

@article{goodfellow6572explaining,
  title={Explaining and harnessing adversarial examples (2014)},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}


@article{bottou2018optimization,
  title={Optimization methods for large-scale machine learning},
  author={Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
  journal={SIAM Review},
  volume={60},
  number={2},
  pages={223--311},
  year={2018},
  publisher={SIAM}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{gholami2018squeezenext,
  title={SqueezeNext: Hardware-Aware Neural Network Design},
  author={Gholami, Amir and Kwon, Kiseok and Wu, Bichen and Tai, Zizheng and Yue, Xiangyu and Jin, Peter and Zhao, Sicheng and Keutzer, Kurt},
  journal={Workshop paper in CVPR},
  year={2018}
}

@article{thakur2005optimization,
  title={Optimization of collective communication operations in MPICH},
  author={Thakur, Rajeev and Rabenseifner, Rolf and Gropp, William},
  journal={The International Journal of High Performance Computing Applications},
  volume={19},
  number={1},
  pages={49--66},
  year={2005},
  publisher={Sage Publications Sage CA: Thousand Oaks, CA}
}

@article{zheng2016asynchronous,
  title={Asynchronous stochastic gradient descent with delay compensation},
  author={Zheng, Shuxin and Meng, Qi and Wang, Taifeng and Chen, Wei and Yu, Nenghai and Ma, Zhi-Ming and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1609.08326},
  year={2016}
}

@inproceedings{agarwal2011distributed,
  title={Distributed delayed stochastic optimization},
  author={Agarwal, Alekh and Duchi, John C},
  booktitle={Advances in Neural Information Processing Systems},
  pages={873--881},
  year={2011}
}

@article{el1997robust,
  title={Robust solutions to least-squares problems with uncertain data},
  author={El Ghaoui, Laurent and Lebret, Herv{\'e}},
  journal={SIAM Journal on matrix analysis and applications},
  volume={18},
  number={4},
  pages={1035--1064},
  year={1997},
  publisher={SIAM}
}

@inproceedings{xu2009robust,
  title={Robust regression and lasso},
  author={Xu, Huan and Caramanis, Constantine and Mannor, Shie},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1801--1808},
  year={2009}
}

@inproceedings{schaul2013no,
  title={No more pesky learning rates},
  author={Schaul, Tom and Zhang, Sixin and LeCun, Yann},
  booktitle={International Conference on Machine Learning},
  pages={343--351},
  year={2013}
}

@article{xu2017second,
  title={Second-order optimization for non-convex machine learning: An empirical study},
  author={Xu, Peng and Roosta-Khorasan, Farbod and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1708.07827},
  year={2017}
}

@article{chen2018comparison,
  title={A comparison of second-order methods for deep convolutional neural networks},
  author={Chen, Patrick H and Hsieh, Cho-jui},
  journal={openreview under ICLR 2018},
  year={2018}
}

@inproceedings{martens2010deep,
  title={Deep learning via Hessian-free optimization.},
  author={Martens, James},
  booktitle={International Conference on Machine Learning},
  volume={27},
  pages={735--742},
  year={2010}
}

@inproceedings{moosavi2016deepfool,
  title={Deepfool: a simple and accurate method to fool deep neural networks},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={2574--2582},
  year={2016}
}

@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2017 IEEE Symposium on Security and Privacy (SP)},
  pages={39--57},
  year={2017},
  organization={IEEE}
}

@article{kurakin2016adversarial,
  title={Adversarial examples in the physical world},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  journal={arXiv preprint arXiv:1607.02533},
  year={2016}
}

@article{xu2017newton,
  title={Newton-type methods for non-convex optimization under inexact hessian information},
  author={Xu, Peng and Roosta-Khorasani, Farbod and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1708.07164},
  year={2017}
}

@inproceedings{yang2019synetgy,
  title={Synetgy: Algorithm-hardware co-design for convnet accelerators on embedded fpgas},
  author={Yang, Yifan and Huang, Qijing and Wu, Bichen and Zhang, Tianjun and Ma, Liang and Gambardella, Giulio and Blott, Michaela and Lavagno, Luciano and Vissers, Kees and Wawrzynek, John and Keutzer, Kurt},
  booktitle={ 2019 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
  pages={23--32},
  year={2019},
  organization={ACM}
}

@article{ward2018adagrad,
  title={AdaGrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization},
  author={Ward, Rachel and Wu, Xiaoxia and Bottou, Leon},
  journal={arXiv preprint arXiv:1806.01811},
  year={2018}
}

@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}

@article{shaham2015understanding,
  title={Understanding adversarial training: Increasing local stability of neural nets through robust optimization},
  author={Shaham, Uri and Yamada, Yutaro and Negahban, Sahand},
  journal={arXiv preprint arXiv:1511.05432},
  year={2015}
}

@inproceedings{shrivastava2017learning,
  title={Learning from Simulated and Unsupervised Images through Adversarial Training.},
  author={Shrivastava, Ashish and Pfister, Tomas and Tuzel, Oncel and Susskind, Joshua and Wang, Wenda and Webb, Russell},
  booktitle={IEEE conference on computer vision and pattern recognition},
  volume={2},
  pages={5},
  year={2017}
}

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@article{yao2018large,
  title={Large batch size training of neural networks with adversarial training and second-order information},
  author={Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael},
  journal={arXiv preprint arXiv:1810.01021},
  year={2018}
}

@misc{ginsburg2017tensor,
  title={Tensor processing using low precision format},
  author={Ginsburg, Boris and Nikolaev, Sergei and Kiswani, Ahmad and Wu, Hao and Gholaminejad, Amir and Kierat, Slawomir and Houston, Michael and Fit-Florea, Alex},
  year={2017},
  month=dec # "~28",
  publisher={Google Patents},
  note={US Patent App. 15/624,577}
}



@article{hubara2017quantized,
  title={Quantized neural networks: Training neural networks with low precision weights and activations},
  author={Hubara, Itay and Courbariaux, Matthieu and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={6869--6898},
  year={2017},
  publisher={JMLR. org}
}

@article{miyashita2016convolutional,
  title={Convolutional neural networks using logarithmic data representation},
  author={Miyashita, Daisuke and Lee, Edward H and Murmann, Boris},
  journal={arXiv preprint arXiv:1603.01025}
}


@article{zhu2016trained,
  title={Trained ternary quantization},
  author={Zhu, Chenzhuo and Han, Song and Mao, Huizi and Dally, William J},
  journal={International Conference on Learning Representations (ICLR)},
  year={2017}
}


@article{li2016ternary,
  title={Ternary weight networks},
  author={Li, Fengfu and Zhang, Bo and Liu, Bin},
  journal={arXiv preprint arXiv:1605.04711},
  year={2016}
}


@inproceedings{wu2016quantized,
  title={Quantized convolutional neural networks for mobile devices},
  author={Wu, Jiaxiang and Leng, Cong and Wang, Yuhang and Hu, Qinghao and Cheng, Jian},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={4820--4828},
  year={2016}
}


@inproceedings{son2018clustering,
  title={Clustering convolutional kernels to compress deep neural networks},
  author={Son, Sanghyun and Nah, Seungjun and Mu Lee, Kyoung},
  booktitle={ European Conference on Computer Vision (ECCV)},
  pages={216--232},
  year={2018}
}

@inproceedings{denton2014exploiting,
  title={Exploiting linear structure within convolutional networks for efficient evaluation},
  author={Denton, Emily L and Zaremba, Wojciech and Bruna, Joan and LeCun, Yann and Fergus, Rob},
  booktitle={Advances in neural information processing systems},
  pages={1269--1277},
  year={2014}
}

@article{wu2018mixed,
  title={Mixed Precision Quantization of ConvNets via Differentiable Neural Architecture Search},
  author={Wu, Bichen and Wang, Yanghan and Zhang, Peizhao and Tian, Yuandong and Vajda, Peter and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1812.00090},
  year={2018}
}

@inproceedings{zhou2018adaptive,
  title={Adaptive quantization for deep neural network},
  author={Zhou, Yiren and Moosavi-Dezfooli, Seyed-Mohsen and Cheung, Ngai-Man and Frossard, Pascal},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{hubara2016binarized,
  title={Binarized neural networks},
  author={Hubara, Itay and Courbariaux, Matthieu and Soudry, Daniel and El-Yaniv, Ran and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={4107--4115},
  year={2016}
}
@book{asanovic1991experimental,
  title={Experimental determination of precision requirements for back-propagation training of artificial neural networks},
  author={Asanovic, Krste and Morgan, Nelson},
  year={1991},
  publisher={International Computer Science Institute}
}
@inproceedings{xnornet,
  title={Xnor-net: Imagenet classification using binary convolutional neural networks},
  author={Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali},
  booktitle={European Conference on Computer Vision},
  pages={525--542},
  year={2016},
  organization={Springer}
}


@article{yang2019xlnet,
  title={XLNet: Generalized Autoregressive Pretraining for Language Understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V},
  journal={arXiv preprint arXiv:1906.08237},
  year={2019}
}


@article{hochreiter1997flat,
  title={Flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={9},
  number={1},
  pages={1--42},
  year={1997},
  publisher={MIT Press}
}

@article{wang2018haq,
  title={{HAQ}: Hardware-Aware Automated Quantization},
  author={Wang, Kuan and Liu, Zhijian and Lin, Yujun and Lin, Ji and Han, Song},
  journal={In Proceedings of  the IEEE  conference  on  computer  vision  and  pattern  recognition},
  year={2019}
}

@article{mao2017exploring,
  title={Exploring the regularity of sparse structure in convolutional neural networks},
  author={Mao, Huizi and Han, Song and Pool, Jeff and Li, Wenshuo and Liu, Xingyu and Wang, Yu and Dally, William J},
  journal={Workshop paper in CVPR},
  year={2017}
}

@article{paszke2017automatic,
  title={Automatic differentiation in PyTorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}



@inproceedings{park2018value,
  title={Value-aware quantization for training and inference of neural networks},
  author={Park, Eunhyeok and Yoo, Sungjoo and Vajda, Peter},
  booktitle={ European Conference on Computer Vision (ECCV)},
  pages={580--595},
  year={2018}
}

@article{dong2019hawq,
  title={HAWQ: Hessian AWare Quantization of Neural Networks with Mixed-Precision},
  author={Dong, Zhen and Yao, Zhewei and Gholami, Amir and Mahoney, Michael and Keutzer, Kurt},
  journal={ICCV},
  year={2019}
}


@article{dong2019hawqv2,
  title={HAWQ-V2: Hessian Aware trace-Weighted Quantization of Neural Networks},
  author={Dong, Zhen and Yao, Zhewei and Cai, Yaohui and Arfeen, Daiyaan and Gholami, Amir and Mahoney, Michael W and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1911.03852},
  year={2019}
}


@article{shen2019q,
  title={Q-bert: Hessian based ultra low precision quantization of bert},
  author={Shen, Sheng and Dong, Zhen and Ye, Jiayu and Ma, Linjian and Yao, Zhewei and Gholami, Amir and Mahoney, Michael W and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1909.05840},
  year={2019}
}


@InProceedings{Kravchik_2019_ICCV,
author = {Kravchik, Eli and Yang, Fan and Kisilev, Pavel and Choukroun, Yoni},
title = {Low-bit Quantization of Neural Networks for Efficient Inference},
booktitle = {International Conference on Computer Vision (ICCV) (ICCV) Workshops},
month = {Oct},
year = {2019}
}


@article{banner2018post,
  title={Post training 4-bit quantization of convolution networks for rapid-deployment},
  author={Banner, Ron and Nahshan, Yury and Hoffer, Elad and Soudry, Daniel},
  journal={CoRR, abs/1810.05723},
  volume={1},
  number={2},
  year={2018}
}

@InProceedings{zhao2019improving,
  title = 	 {Improving Neural Network Quantization without Retraining using Outlier Channel Splitting},
  author = 	 {Zhao, Ritchie and Hu, Yuwei and Dotzel, Jordan and De Sa, Chris and Zhang, Zhiru},
  booktitle = 	 { 36th International Conference on Machine Learning},
  pages = 	 {7543--7552},
  year = 	 {2019}
}

@article{nagel2019data,
  title={Data-Free Quantization through Weight Equalization and Bias Correction},
  author={Nagel, Markus and van Baalen, Mart and Blankevoort, Tijmen and Welling, Max},
  journal={ICCV},
  year={2019}
}

@inproceedings{lin2016fixed,
  title={Fixed point quantization of deep convolutional networks},
  author={Lin, Darryl and Talathi, Sachin and Annapureddy, Sreekanth},
  booktitle={International Conference on Machine Learning},
  pages={2849--2858},
  year={2016}
}

@article{meller2019same,
  title={Same, same but different-recovering neural network quantization error through weight factorization},
  author={Meller, Eldad and Finkelstein, Alexander and Almog, Uri and Grobman, Mark},
  journal={arXiv preprint arXiv:1902.01917},
  year={2019}
}

@article{lee2018quantization,
  title={Quantization for rapid deployment of deep neural networks},
  author={Lee, Jun Haeng and Ha, Sangwon and Choi, Saerom and Lee, Won-Jo and Lee, Seungwon},
  journal={arXiv preprint arXiv:1810.05488},
  year={2018}
}

@article{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  journal={arXiv preprint arXiv:1502.03167},
  year={2015}
}

@inproceedings{santurkar2018does,
  title={How does batch normalization help optimization?},
  author={Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2483--2493},
  year={2018}
}


@article{DBLP:journals/corr/LinDGHHB16,
  author    = {Tsung{-}Yi Lin and
               Piotr Doll{\'{a}}r and
               Ross B. Girshick and
               Kaiming He and
               Bharath Hariharan and
               Serge J. Belongie},
  title     = {Feature Pyramid Networks for Object Detection},
  journal   = {CoRR},
  volume    = {abs/1612.03144},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.03144},
  archivePrefix = {arXiv},
  eprint    = {1612.03144},
  timestamp = {Mon, 13 Aug 2018 16:48:50 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LinDGHHB16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@inproceedings{li2019fully,
  title={Fully Quantized Network for Object Detection},
  author={Li, Rundong and Wang, Yan and Liang, Feng and Qin, Hongwei and Yan, Junjie and Fan, Rui},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={2810--2819},
  year={2019}
}

@article{haroush2019knowledge,
    title={The Knowledge Within: Methods for Data-Free Model Compression},
    author={Matan Haroush and Itay Hubara and Elad Hoffer and Daniel Soudry},
    journal={arXiv preprint arXiv: 1912.01274},
    year={2019},
}

@msic{Inceptionism,
title	= {Inceptionism: Going Deeper into Neural Networks},
author	= {Alexander Mordvintsev and Christopher Olah and Mike Tyka},
year	= {2015},
URL	= {https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html}
}


@inproceedings{horowitz20141,
  title={Computing's energy problem (and what we can do about it)},
  author={Horowitz, Mark},
  booktitle={2014 IEEE International Solid-State Circuits Conference Digest of Technical Papers (ISSCC)},
  pages={10--14},
  year={2014},
  organization={IEEE}
}



@inproceedings{kwon2018co,
  title={Co-design of deep neural nets and neural net accelerators for embedded vision applications},
  author={Kwon, Kiseok and Amid, Alon and Gholami, Amir and Wu, Bichen and Asanovic, Krste and Keutzer, Kurt},
  booktitle={2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}


@article{mordvintsev2015inceptionism,
  title={Inceptionism: Going deeper into neural networks},
  author={Mordvintsev, Alexander and Olah, Christopher and Tyka, Mike},
  year={2015}
}

@article{baskin2019cat,
  title={CAT: Compression-Aware Training for bandwidth reduction},
  author={Baskin, Chaim and Chmiel, Brian and Zheltonozhskii, Evgenii and Banner, Ron and Bronstein, Alex M and Mendelson, Avi},
  journal={arXiv preprint arXiv:1909.11481},
  year={2019}
}


@ONLINE{gemmlowp,
  title = {https://github.com/google/gemmlowp},
}

@ONLINE{tensorcore,
  title = {https://www.nvidia.com/en-us/data-center/a100/},
}


@ONLINE{fbgemm,
  title = {https://github.com/pytorch/FBGEMM},
}


@ONLINE{rn50v1.5,
  title = {https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Classification/ConvNets/resnet50v1.5},
}

@article{cai2020zeroq,
  title={ZeroQ: A Novel Zero Shot Quantization Framework},
  author={Cai, Yaohui and Yao, Zhewei and Dong, Zhen and Gholami, Amir and Mahoney, Michael W and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2001.00281},
  year={2020}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{gupta2015deep,
  title={Deep learning with limited numerical precision},
  author={Gupta, Suyog and Agrawal, Ankur and Gopalakrishnan, Kailash and Narayanan, Pritish},
  booktitle={International Conference on Machine Learning},
  pages={1737--1746},
  year={2015}
}

@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@article{bengio2013estimating,
  title={Estimating or propagating gradients through stochastic neurons for conditional computation},
  author={Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
  journal={arXiv preprint arXiv:1308.3432},
  year={2013}
}

@book{kushner2003stochastic,
  title={Stochastic approximation and recursive algorithms and applications},
  author={Kushner, Harold and Yin, G George},
  volume={35},
  year={2003},
  publisher={Springer Science \&amp; Business Media}
}

@article{ghadimi2013stochastic,
  title={Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={4},
  pages={2341--2368},
  year={2013},
  publisher={SIAM}
}

@inproceedings{ott2019fairseq,
  title = {fairseq: A Fast, Extensible Toolkit for Sequence Modeling},
  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},
  booktitle = {Proceedings of NAACL-HLT 2019: Demonstrations},
  year = {2019},
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{abadi2016tensorflow,
  title={Tensorflow: A system for large-scale machine learning},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
  booktitle={12th $\{$USENIX$\}$ symposium on operating systems design and implementation ($\{$OSDI$\}$ 16)},
  pages={265--283},
  year={2016}
}

@article{deutsch1996deflate,
  title={DEFLATE compressed data format specification version 1.3},
  author={Deutsch, Peter},
  journal={IETF RFC 1951},
  year={1996}
}

@article{jain2019checkmate,
  title={Checkmate: Breaking the memory wall with optimal tensor rematerialization},
  author={Jain, Paras and Jain, Ajay and Nrusimha, Aniruddha and Gholami, Amir and Abbeel, Pieter and Keutzer, Kurt and Stoica, Ion and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:1910.02653},
  year={2019}
}

@inproceedings{huang2020swapadvisor,
  title={SwapAdvisor: Pushing deep learning beyond the GPU memory limit via smart swapping},
  author={Huang, Chien-Chin and Jin, Gu and Li, Jinyang},
  booktitle={ Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems},
  pages={1341--1355},
  year={2020}
}

@article{kirisame2020dynamic,
  title={Dynamic tensor rematerialization},
  author={Kirisame, Marisa and Lyubomirsky, Steven and Haan, Altan and Brennan, Jennifer and He, Mike and Roesch, Jared and Chen, Tianqi and Tatlock, Zachary},
  journal={arXiv preprint arXiv:2006.09616},
  year={2020}
}

@article{chakrabarti2019backprop,
  title={Backprop with approximate activations for memory-efficient network training},
  author={Chakrabarti, Ayan and Moseley, Benjamin},
  journal={arXiv preprint arXiv:1901.07988},
  year={2019}
}


@inproceedings{allen2019learning,
  title={Learning and generalization in overparameterized neural networks, going beyond two layers},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Liang, Yingyu},
  booktitle={Advances in neural information processing systems},
  pages={6158--6169},
  year={2019}
}

@inproceedings{du2019gradient,
  title={Gradient descent finds global minima of deep neural networks},
  author={Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
  booktitle={International Conference on Machine Learning},
  pages={1675--1685},
  year={2019},
  organization={PMLR}
}

@inproceedings{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  booktitle={Advances in neural information processing systems},
  year={2020}
}

@inproceedings{brock2018large,
  title={Large Scale GAN Training for High Fidelity Natural Image Synthesis},
  author={Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}


@inproceedings{grill2020bootstrap,
  title={Bootstrap your own latent: A new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch\'{e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and Piot, Bilal and kavukcuoglu, koray and Munos, Remi and Valko, Michal},
  booktitle={Advances in neural information processing systems},
  year={2020}
}

@inproceedings{fu2020don,
  title={Don’t waste your bits! squeeze activations and gradients for deep neural networks via TINYSCRIPT},
  author={Fu, Fangcheng and Hu, Yuzheng and He, Yihan and Jiang, Jiawei and Shao, Yingxia and Zhang, Ce and Cui, Bin},
  booktitle={International Conference on Machine Learning},
  pages={3304--3314},
  year={2020},
  organization={PMLR}
}

@inproceedings{yang2017mean,
  title={Mean field residual networks: on the edge of chaos},
  author={Yang, Greg and Schoenholz, Samuel S},
  booktitle={ 31st International Conference on Neural Information Processing Systems},
  pages={2865--2873},
  year={2017}
}

@inproceedings{meng2017training,
  title={Training deeper models by GPU memory optimization on TensorFlow},
  author={Meng, Chen and Sun, Minmin and Yang, Jun and Qiu, Minghui and Gu, Yang},
  booktitle={Proc. of ML Systems Workshop in NIPS},
  volume={7},
  year={2017}
}


@inproceedings{peng2020capuchin,
  title={Capuchin: Tensor-based GPU memory management for deep learning},
  author={Peng, Xuan and Shi, Xuanhua and Dai, Hulin and Jin, Hai and Ma, Weiliang and Xiong, Qian and Yang, Fan and Qian, Xuehai},
  booktitle={ Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems},
  pages={891--905},
  year={2020}
}

@article{yao2020hawqv3,
  title={HAWQV3: Dyadic Neural Network Quantization},
  author={Yao, Zhewei and Dong, Zhen and Zheng, Zhangcheng and Gholami, Amir and Yu, Jiali and Tan, Eric and Wang, Leyuan and Huang, Qijing and Wang, Yida and Mahoney, Michael W and Keutzer, Kurt},
  journal={arXiv preprint arXiv:2011.10680},
  year={2020}
}

@inproceedings{micikevicius2018mixed,
  title={Mixed Precision Training},
  author={Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and Wu, Hao},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{chen2020statistical,
  title={A Statistical Framework for Low-bitwidth Training of Deep Neural Networks},
  author={Chen, Jianfei and Gai, Yu and Yao, Zhewei and Mahoney, Michael W and Gonzalez, Joseph E},
  booktitle={Advances in neural information processing systems},
  year={2020}
}

@inproceedings{sun2020ultra,
  title={Ultra-Low Precision 4-bit Training of Deep Neural Networks},
  author={Sun, Xiao and Wang, Naigang and Chen, Chia-Yu and Ni, Jiamin and Agrawal, Ankur and Cui, Xiaodong and Venkataramani, Swagath and El Maghraoui, Kaoutar and Srinivasan, Vijayalakshmi Viji and Gopalakrishnan, Kailash},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{han2015deep_compression,
  title={Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2016}
}

@inproceedings{lin2017deep,
  title={Deep gradient compression: Reducing the communication bandwidth for distributed training},
  author={Lin, Yujun and Han, Song and Mao, Huizi and Wang, Yu and Dally, William J},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@article{fedus2021switch,
	title={Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
	author={Fedus, William and Zoph, Barret and Shazeer, Noam},
	journal={arXiv preprint arXiv:2101.03961},
	year={2021}
}

@article{chen2016training,
	title={Training deep nets with sublinear memory cost},
	author={Chen, Tianqi and Xu, Bing and Zhang, Chiyuan and Guestrin, Carlos},
	journal={arXiv preprint arXiv:1604.06174},
	year={2016}
}

@inproceedings{wang2018superneurons,
	title={Superneurons: Dynamic {GPU} memory management for training deep neural networks},
	author={Wang, Linnan and Ye, Jinmian and Zhao, Yiyang and Wu, Wei and Li, Ang and Song, Shuaiwen Leon and Xu, Zenglin and Kraska, Tim},
	booktitle={ 23rd ACM SIGPLAN symposium on principles and practice of parallel programming},
	pages={41--53},
	year={2018}
}

@article{shah2020memory,
  title={Memory Optimization for Deep Networks},
  author={Shah, Aashaka and Wu, Chao-Yuan and Mohan, Jayashree and Chidambaram, Vijay and Kr{\"a}henb{\"u}hl, Philipp},
  journal={arXiv preprint arXiv:2010.14501},
  year={2020}
}


@article{ren2021zero,
  title={ZeRO-Offload: Democratizing Billion-Scale Model Training},
  author={Ren, Jie and Rajbhandari, Samyam and Aminabadi, Reza Yazdani and Ruwase, Olatunji and Yang, Shuangyan and Zhang, Minjia and Li, Dong and He, Yuxiong},
  journal={arXiv preprint arXiv:2101.06840},
  year={2021}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@inproceedings{stock2020and,
  title={And the Bit Goes Down: Revisiting the Quantization of Neural Networks},
  author={Stock, Pierre and Joulin, Armand and Gribonval, R{\'e}mi and Graham, Benjamin and J{\'e}gou, Herv{\'e}},
  booktitle={International Conference on Learning Representations},
  pages={1--11},
  year={2020}
}

@inproceedings{cordts2016cityscapes,
	title={The cityscapes dataset for semantic urban scene understanding},
	author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
	booktitle={IEEE conference on computer vision and pattern recognition},
	pages={3213--3223},
	year={2016}
}

@inproceedings{paszke2019pytorch,
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
    url = {https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf},
    volume = {32},
    year = {2019}
}


@article{shoeybi2019megatron,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@article{lepikhin2020gshard,
  title={Gshard: Scaling giant models with conditional computation and automatic sharding},
  author={Lepikhin, Dmitry and Lee, HyoukJoong and Xu, Yuanzhong and Chen, Dehao and Firat, Orhan and Huang, Yanping and Krikun, Maxim and Shazeer, Noam and Chen, Zhifeng},
  journal={arXiv preprint arXiv:2006.16668},
  year={2020}
}

@inproceedings{wang2019supporting,
  title={Supporting very large models using automatic dataflow graph partitioning},
  author={Wang, Minjie and Huang, Chien-chin and Li, Jinyang},
  booktitle={ Fourteenth EuroSys Conference 2019},
  pages={1--17},
  year={2019}
}

@misc{mmseg2020,
	title={MMSegmentation, an Open Source Semantic Segmentation Toolbox},
	author={MMSegmentation Contributors},
	howpublished = {\url{https://github.com/open-mmlab/mmsegmentation}},
	year={2020}
}

@misc{amp,
	title={apex.amp},
	author={Nvidia},
	howpublished = {\url{https://nvidia.github.io/apex/amp.html}},
	year={2019}
}

@article{mmdetection,
	title   = {{MMDetection}: Open MMLab Detection Toolbox and Benchmark},
	author  = {Chen, Kai and Wang, Jiaqi and Pang, Jiangmiao and Cao, Yuhang and
	Xiong, Yu and Li, Xiaoxiao and Sun, Shuyang and Feng, Wansen and
	Liu, Ziwei and Xu, Jiarui and Zhang, Zheng and Cheng, Dazhi and
	Zhu, Chenchen and Cheng, Tianheng and Zhao, Qijie and Li, Buyu and
	Lu, Xin and Zhu, Rui and Wu, Yue and Dai, Jifeng and Wang, Jingdong
	and Shi, Jianping and Ouyang, Wanli and Loy, Chen Change and Lin, Dahua},
	journal= {arXiv preprint arXiv:1906.07155},
	year={2019}
}

@Article{chen2020mocov2,
  author  = {Xinlei Chen and Haoqi Fan and Ross Girshick and Kaiming He},
  title   = {Improved Baselines with Momentum Contrastive Learning},
  journal = {arXiv preprint arXiv:2003.04297},
  year    = {2020},
}

@article{beaumont2021efficient,
  title={Efficient Combination of Rematerialization and Offloading for Training DNNs},
  author={Beaumont, Olivier and Eyraud-Dubois, Lionel and Shilova, Alena},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{li2017training,
  title={Training quantized nets: A deeper understanding},
  author={Li, Hao and De, Soham and Xu, Zheng and Studer, Christoph and Samet, Hanan and Goldstein, Tom},
  booktitle={ 31st International Conference on Neural Information Processing Systems},
  pages={5813--5823},
  year={2017}
}

@article{li2021terapipe,
  title={TeraPipe: Token-Level Pipeline Parallelism for Training Large-Scale Language Models},
  author={Li, Zhuohan and Zhuang, Siyuan and Guo, Shiyuan and Zhuo, Danyang and Zhang, Hao and Song, Dawn and Stoica, Ion},
  journal={arXiv preprint arXiv:2102.07988},
  year={2021}
}

@article{evans2021ac,
  title={{AC-GC}: Lossy Activation Compression with Guaranteed Convergence},
  author={Evans, R David and Aamodt, Tor},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{pan2021mesa,
  title={Mesa: A Memory-saving Training Framework for Transformers},
  author={Pan, Zizheng and Chen, Peng and He, Haoyu and Liu, Jing and Cai, Jianfei and Zhuang, Bohan},
  journal={arXiv preprint arXiv:2111.11124},
  year={2021}
}

@inproceedings{chen2021actnn,
  title={ActNN: Reducing Training Memory Footprint via 2-Bit Activation Compressed Training},
  author={Chen, Jianfei and Zheng, Lianmin and Yao, Zhewei and Wang, Dequan and Stoica, Ion and Mahoney, Michael W and Gonzalez, Joseph E},
  booktitle={International Conference on Machine Learning},
  year={2021}
}

@inproceedings{jin2021novel,
  title={A novel memory-efficient deep learning training framework via error-bounded lossy compression},
  author={Jin, Sian and Li, Guanpeng and Song, Shuaiwen Leon and Tao, Dingwen},
  booktitle={ 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
  pages={485--487},
  year={2021}
}

@inproceedings{evans2020jpeg,
  title={Jpeg-act: accelerating deep learning via transform-based lossy compression},
  author={Evans, R David and Liu, Lufei and Aamodt, Tor M},
  booktitle={2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)},
  pages={860--873},
  year={2020},
  organization={IEEE}
}

@inproceedings{
anonymous2022exact,
title={{EXACT}: Scalable Graph Neural Networks Training via Extreme Activation Compression},
author={Anonymous},
booktitle={Submitted to The Tenth International Conference on Learning Representations },
year={2022},
url={https://openreview.net/forum?id=vkaMaq95_rX},
note={under review}
}

@article{hu2020open,
  title={Open graph benchmark: Datasets for machine learning on graphs},
  author={Hu, Weihua and Fey, Matthias and Zitnik, Marinka and Dong, Yuxiao and Ren, Hongyu and Liu, Bowen and Catasta, Michele and Leskovec, Jure},
  journal={arXiv preprint arXiv:2005.00687},
  year={2020}
}

@article{zeng2019graphsaint,
  title={Graphsaint: Graph sampling based inductive learning method},
  author={Zeng, Hanqing and Zhou, Hongkuan and Srivastava, Ajitesh and Kannan, Rajgopal and Prasanna, Viktor},
  journal={arXiv preprint arXiv:1907.04931},
  year={2019}
}

@article{kipf2016semi,
  title={Semi-supervised classification with graph convolutional networks},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1609.02907},
  year={2016}
}

@article{velivckovic2017graph,
  title={Graph attention networks},
  author={Veli{\v{c}}kovi{\'c}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio, Pietro and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.10903},
  year={2017}
}

@inproceedings{chen2020simple_gcnii,
  title={Simple and deep graph convolutional networks},
  author={Chen, Ming and Wei, Zhewei and Huang, Zengfeng and Ding, Bolin and Li, Yaliang},
  booktitle={International Conference on Machine Learning},
  pages={1725--1735},
  year={2020},
  organization={PMLR}
}

@article{cen2021cogdl,
    title={CogDL: Toolkit for Deep Learning on Graphs},
    author={Yukuo Cen and Zhenyu Hou and Yan Wang and Qibin Chen and Yizhen Luo and Xingcheng Yao and Aohan Zeng and Shiguang Guo and Peng Zhang and Guohao Dai and Yu Wang and Chang Zhou and Hongxia Yang and Jie Tang},
    journal={arXiv preprint arXiv:2103.00959},
    year={2021}
}

@article{rabe2021self,
  title={Self-attention Does Not Need $O(n^2)$ Memory},
  author={Rabe, Markus N and Staats, Charles},
  journal={arXiv preprint arXiv:2112.05682},
  year={2021}
}

@misc{pytorchhook,
  author = {PyTorch Dev Team},
  title = {Save Tensor Hook Document},
  url = {https://pytorch.org/docs/stable/autograd.html#torch.autograd.graph.saved_tensors_hooks},
  year = {2022},
}

@inproceedings{wang2018glue,
  title={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  booktitle={ 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP},
  pages={353--355},
  year={2018}
}

@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={ 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={4171--4186},
  year={2019}
}

@article{liu2021Swin,
  title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  journal={International Conference on Computer Vision (ICCV)},
  year={2021}
}

@article{ren2015faster,
  title={Faster {R-CNN}: Towards real-time object detection with region proposal networks},
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={Advances in neural information processing systems},
  volume={28},
  pages={91--99},
  year={2015}
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = " 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@article{redmon2018yolov3,
  title={Yolov3: An incremental improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  journal={arXiv preprint arXiv:1804.02767},
  year={2018}
}

@article{bochkovskiy2020yolov4,
  title={Yolov4: Optimal speed and accuracy of object detection},
  author={Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2004.10934},
  year={2020}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year={2018}
}


@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={IEEE conference on computer vision and pattern recognition},
  pages={4510--4520},
  year={2018}
}

