

@article{liao2020random,
  title={A random matrix analysis of random fourier features: beyond the gaussian kernel, a precise phase transition, and the corresponding double descent},
  author={Liao, Zhenyu and Couillet, Romain and Mahoney, Michael W},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13939--13950},
  year={2020}
}

@article{nakkiran2021deep,
  title={Deep double descent: Where bigger models and more data hurt},
  author={Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2021},
  number={12},
  pages={124003},
  year={2021},
  publisher={IOP Publishing}
}

@article{derezinski2020exact,
  title={Exact expressions for double descent and implicit regularization via surrogate random design},
  author={Derezinski, Michal and Liang, Feynman T and Mahoney, Michael W},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5152--5164},
  year={2020}
}

@article{Ballard2017PerspectiveEL,
  title={Perspective: Energy Landscapes for Machine Learning},
  author={Andrew J. Ballard and Ritankar Das and Stefano Martiniani and Dhagash Mehta and Levent Sagun and Jacob D. Stevenson and David J. Wales},
  journal={Physical chemistry chemical physics : PCCP},
  year={2017},
  volume={19 20},
  pages={
          12585-12603
        }
}

@inproceedings{
evci2019the,
title={The Difficulty of Training Sparse Neural Networks},
author={Utku Evci and Fabian Pedregosa and Aidan Gomez and Erich Elsen},
booktitle={International Conference on Machine Learning 2019 Workshop on Identifying and Understanding Deep Learning Phenomena},
year={2019},
}

@inproceedings{garipov2018loss,
  title={{Loss surfaces, mode connectivity, and fast ensembling of DNNs}},
  author={Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry P and Wilson, Andrew G},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}


@inproceedings{liu2021sparse,
  title={Sparse training via boosting pruning plasticity with neuroregeneration},
  author={Liu, Shiwei and Chen, Tianlong and Chen, Xiaohan and Atashgahi, Zahra and Yin, Lu and Kou, Huanyu and Shen, Li and Pechenizkiy, Mykola and Wang, Zhangyang and Mocanu, Decebal Constantin},
  booktitle={Advances in Neural Information Processing Systems},
  year={2021}
}

@Techreport{Krizhevsky_2009_17719,
  author = {Krizhevsky, Alex and Hinton, Geoffrey},
 address = {Toronto, Ontario},
 institution = {University of Toronto},
 number = {0},
 publisher = {Technical report, University of Toronto},
 title = {Learning multiple layers of features from tiny images},
 year = {2009},
 title_with_no_special_chars = {Learning multiple layers of features from tiny images}
}

@inproceedings{bojar-etal-2014-findings,
    title = "Findings of the 2014 Workshop on Statistical Machine Translation",
    author = "Bojar, Ond{\v{r}}ej  and
      Buck, Christian  and
      Federmann, Christian  and
      Haddow, Barry  and
      Koehn, Philipp  and
      Leveling, Johannes  and
      Monz, Christof  and
      Pecina, Pavel  and
      Post, Matt  and
      Saint-Amand, Herve  and
      Soricut, Radu  and
      Specia, Lucia  and
      Tamchyna, Ale{\v{s}}",
    booktitle = "Proceedings of the Ninth Workshop on Statistical Machine Translation",
    year = "2014",
}


@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}




@article{Li2017PruningFF,
  title={Pruning Filters for Efficient ConvNets},
  author={Hao Li and Asim Kadav and Igor Durdanovic and Hanan Samet and Hans Peter Graf},
  journal={ICLR},
  year={2017}
}

@inproceedings{
you2020drawing,
title={Drawing Early-Bird Tickets: Toward More Efficient Training of Deep Networks},
author={Haoran You and Chaojian Li and Pengfei Xu and Yonggan Fu and Yue Wang and Xiaohan Chen and Yingyan Lin and Zhangyang Wang and Richard G. Baraniuk},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{DBLP:conf/naacl/DevlinCLT19,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  editor    = {Jill Burstein and
               Christy Doran and
               Thamar Solorio},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of
               the Association for Computational Linguistics: Human Language Technologies},
  pages     = {4171--4186},
  year      = {2019},
  timestamp = {Wed, 16 Mar 2022 23:55:36 +0100},
}



@inproceedings{
liu2018rethinking,
title={Rethinking the Value of Network Pruning},
author={Zhuang Liu and Mingjie Sun and Tinghui Zhou and Gao Huang and Trevor Darrell},
booktitle={International Conference on Learning Representations},
year={2019},
}

@ARTICLE{martin2018implicit_JMLRversion,
  author =       {Martin, Charles H and Mahoney, Michael W},
  title =        {Implicit Self-Regularization in Deep Neural Networks: Evidence from Random Matrix Theory and Implications for Learning},
  journal =      {Journal of Machine Learning Research},
  year =         {2021},
  volume =       {22},
  number =       {165},
  pages =        {1--73},
}

@inproceedings{
yang2021taxonomizing,
title={Taxonomizing local versus global structure in neural network loss landscapes},
author={Yaoqing Yang and Liam Hodgkinson and Ryan Theisen and Joe Zou and Joseph E. Gonzalez and Kannan Ramchandran and Michael W. Mahoney},
booktitle={Advances in Neural Information Processing Systems},
year={2021},
}
  
@inproceedings{kornblith2019similarity,
  title={Similarity of neural network representations revisited},
  author={Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  booktitle={International Conference on Machine Learning},
  year={2019}
}



@inproceedings{jiang2019fantastic,
  title={Fantastic Generalization Measures and Where to Find Them},
  author={Jiang, Yiding and Neyshabur, Behnam and Mobahi, Hossein and Krishnan, Dilip and Bengio, Samy},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{yang2022evaluating,
  title={Evaluating natural language processing models with generalization metrics that do not need access to any training or testing data},
  author={Yang, Yaoqing and Theisen, Ryan and Hodgkinson, Liam and Gonzalez, Joseph E and Ramchandran, Kannan and Martin, Charles H and Mahoney, Michael W},
  journal={arXiv preprint arXiv:2202.02842},
  year={2022}
}




@article{zhao2019object,
  title={Object detection with deep learning: A review},
  author={Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-tao and Wu, Xindong},
  journal={IEEE transactions on neural networks and learning systems},
  volume={30},
  number={11},
  pages={3212--3232},
  year={2019},
  publisher={IEEE}
}

@article{fujiyoshi2019deep,
  title={Deep learning-based image recognition for autonomous driving},
  author={Fujiyoshi, Hironobu and Hirakawa, Tsubasa and Yamashita, Takayoshi},
  journal={IATSS research},
  volume={43},
  number={4},
  pages={244--252},
  year={2019},
  publisher={Elsevier}
}


@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@article{van2016wavenet,
  title={WaveNet: A generative model for raw audio.},
  author={Van Den Oord, A{\"a}ron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew W and Kavukcuoglu, Koray},
  journal={SSW},
  volume={125},
  pages={2},
  year={2016}
}

@inproceedings{chen2019deep,
  title={Deep Learning for Video Captioning: A Review.},
  author={Chen, Shaoxiang and Yao, Ting and Jiang, Yu-Gang},
  booktitle={IJCAI},
  volume={1},
  pages={2},
  year={2019}
}

@inproceedings{gavat2015deep,
  title={Deep learning in acoustic modeling for automatic speech recognition and understanding-an overview},
  author={Gavat, Inge and Militaru, Diana},
  booktitle={2015 International Conference on Speech Technology and Human-Computer Dialogue (SpeD)},
  pages={1--8},
  year={2015}
}

@inproceedings{koskinen2019reverse,
  title={Reverse imaging pipeline for raw RGB image augmentation},
  author={Koskinen, Samu and Yang, Dan and K{\"a}m{\"a}r{\"a}inen, Joni-Kristian},
  booktitle={2019 IEEE International Conference on Image Processing (ICIP)},
  pages={2896--2900},
  year={2019}
}

@inproceedings{wu2020lite,
  title={Lite Transformer with Long-Short Range Attention},
  author={Zhanghao Wu* and Zhijian Liu* and Ji Lin and Yujun Lin and Song Han},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@inproceedings{wang2020apq,
  title={Apq: Joint search for network architecture, pruning and quantization policy},
  author={Wang, Tianzhe and Wang, Kuan and Cai, Han and Lin, Ji and Liu, Zhijian and Wang, Hanrui and Lin, Yujun and Han, Song},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2078--2087},
  year={2020}
}

@inproceedings{DBLP:journals/corr/HanMD15,
  author    = {Song Han and
               Huizi Mao and
               William J. Dally},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Deep Compression: Compressing Deep Neural Network with Pruning, Trained
               Quantization and Huffman Coding},
  booktitle = {4th International Conference on Learning Representations, {ICLR} 2016,
               San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
  year      = {2016},
  timestamp = {Fri, 20 Nov 2020 16:16:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/HanMD15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{draxler2018essentially,
  title={Essentially no barriers in neural network energy landscape},
  author={Draxler, Felix and Veschgini, Kambis and Salmhofer, Manfred and Hamprecht, Fred},
  booktitle={International Conference on Machine Learning},
  year={2018}
}

@inproceedings{evci2020rigging,
  title={Rigging the lottery: Making all tickets winners},
  author={Evci, Utku and Gale, Trevor and Menick, Jacob and Castro, Pablo Samuel and Elsen, Erich},
  booktitle={International Conference on Machine Learning},
  year={2020}
}

@article{garcia2019estimation,
  title={Estimation of energy consumption in machine learning},
  author={Garc{\'\i}a-Mart{\'\i}n, Eva and Rodrigues, Crefeda Faviola and Riley, Graham and Grahn, H{\aa}kan},
  journal={Journal of Parallel and Distributed Computing},
  volume={134},
  pages={75--88},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{ryu2021performance,
  title={Performance Analysis of Applying Deep Learning for Virtual Background of WebRTC-based Video Conferencing System},
  author={Ryu, Sangwoo and Ko, Kyungchan and Hong, James Won-Ki},
  booktitle={2021 22nd Asia-Pacific Network Operations and Management Symposium (APNOMS)},
  pages={53--56},
  year={2021}
}

@inproceedings{DBLP:conf/iclr/ZhuG18,
  author    = {Michael Zhu and
               Suyog Gupta},
  title     = {To Prune, or Not to Prune: Exploring the Efficacy of Pruning for Model
               Compression},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Workshop Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2018},
  url       = {https://openreview.net/forum?id=Sy1iIDkPM},
  timestamp = {Thu, 04 Apr 2019 13:20:09 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/ZhuG18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{o2015introduction,
  title={An introduction to convolutional neural networks},
  author={O'Shea, Keiron and Nash, Ryan},
  journal={arXiv preprint arXiv:1511.08458},
  year={2015}
}





@inproceedings{han2015learning,
  title={Learning both weights and connections for efficient neural network},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William},
  booktitle={Advances in Neural Information Processing Systems},
  year={2015}
}

@inproceedings{
lee2021layeradaptive,
title={Layer-adaptive Sparsity for the Magnitude-based Pruning},
author={Jaeho Lee and Sejun Park and Sangwoo Mo and Sungsoo Ahn and Jinwoo Shin},
booktitle={International Conference on Learning Representations},
year={2021}
}





@inproceedings{
lee2018snip,
title={{SNIP}: SINGLE-SHOT NETWORK PRUNING BASED ON CONNECTION SENSITIVITY},
author={Namhoon Lee and Thalaiyasingam Ajanthan and Philip Torr},
booktitle={International Conference on Learning Representations},
year={2019},
}

@article{zhu2017prune,
  title={To prune, or not to prune: exploring the efficacy of pruning for model compression},
  author={Zhu, Michael and Gupta, Suyog},
  journal={arXiv preprint arXiv:1710.01878},
  year={2017}
}


@InProceedings{Shen_2022_CVPR,
    author    = {Shen, Maying and Molchanov, Pavlo and Yin, Hongxu and Alvarez, Jose M.},
    title     = {When To Prune? A Policy Towards Early Structural Pruning},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
    year      = {2022}
}



@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@article{gale2019state,
  title={The state of sparsity in deep neural networks},
  author={Gale, Trevor and Elsen, Erich and Hooker, Sara},
  journal={arXiv preprint arXiv:1902.09574},
  year={2019}
}


@article{su2020sanity,
  title={Sanity-checking pruning methods: Random tickets can win the jackpot},
  author={Su, Jingtong and Chen, Yihang and Cai, Tianle and Wu, Tianhao and Gao, Ruiqi and Wang, Liwei and Lee, Jason D},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{NIPS1992_303ed4c6,
 author = {Hassibi, Babak and Stork, David},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Second order derivatives for network pruning: Optimal Brain Surgeon},
 year = {1992}
}

@inproceedings{blalock2020state,
  title={What is the state of neural network pruning?},
  author={Blalock, Davis and Gonzalez Ortiz, Jose Javier and Frankle, Jonathan and Guttag, John},
  booktitle={Proceedings of Machine Learning and Systems},
  year={2020}
}


@inproceedings{NIPS1988_07e1cd7d,
 author = {Mozer, Michael C and Smolensky, Paul},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 title = {Skeletonization: A Technique for Trimming the Fat from a Network via Relevance Assessment},
 year = {1988}
}






@article{lin2022landscape,
  title={On the landscape of one-hidden-layer sparse networks and beyond},
  author={Lin, Dachao and Sun, Ruoyu and Zhang, Zhihua},
  journal={Artificial Intelligence},
  year={2022},
}

@article{sun2020global,
  title={The global landscape of neural networks: An overview},
  author={Sun, Ruoyu and Li, Dawei and Liang, Shiyu and Ding, Tian and Srikant, Rayadurgam},
  journal={IEEE Signal Processing Magazine},
  year={2020},
  publisher={IEEE}
}

@inproceedings{visualloss,
  title={Visualizing the Loss Landscape of Neural Nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}




@inproceedings{
Renda2020Comparing,
title={Comparing Rewinding and Fine-tuning in Neural Network Pruning},
author={Alex Renda and Jonathan Frankle and Michael Carbin},
booktitle={International Conference on Learning Representations},
year={2020},
}

@inproceedings{hodgkinson2021multiplicative,
  title={Multiplicative noise and heavy tails in stochastic optimization},
  author={Hodgkinson, Liam and Mahoney, Michael},
  booktitle={International Conference on Machine Learning},
  year={2021}
}


@article{martin2017rethinking,
  title={Rethinking generalization requires revisiting old ideas: statistical mechanics approaches and complex learning behavior},
  author={Martin, Charles H and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1710.09553},
  year={2017}
}



@inproceedings{he2022sparse,
  title={Sparse Double Descent: Where Network Pruning Aggravates Overfitting},
  author={He, Zheng and Xie, Zeke and Zhu, Quanzhi and Qin, Zengchang},
  booktitle={International Conference on Machine Learning},
  pages={8635--8659},
  year={2022}
}

@inproceedings{mostafa2019parameter,
  title={Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization},
  author={Mostafa, Hesham and Wang, Xin},
  booktitle={International Conference on Machine Learning},
  year={2019}
}

@article{zhu2017prune,
  title={To prune, or not to prune: exploring the efficacy of pruning for model compression},
  author={Zhu, Michael and Gupta, Suyog},
  journal={arXiv preprint arXiv:1710.01878},
  year={2017}
}




@inproceedings{
Wang2020Picking,
title={Picking Winning Tickets Before Training by Preserving Gradient Flow},
author={Chaoqi Wang and Guodong Zhang and Roger Grosse},
booktitle={International Conference on Learning Representations},
year={2020},
}

@article{tanaka2020pruning,
  title={Pruning neural networks without any data by iteratively conserving synaptic flow},
  author={Tanaka, Hidenori and Kunin, Daniel and Yamins, Daniel L and Ganguli, Surya},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}



@inproceedings{
zhang2017understanding,
title={Understanding deep learning requires rethinking generalization},
author={Chiyuan Zhang and Samy Bengio and Moritz Hardt and Benjamin Recht and Oriol Vinyals},
booktitle={International Conference on Learning Representations},
year={2017}
}

@article{xing2018walk,
  title={A walk with sgd},
  author={Xing, Chen and Arpit, Devansh and Tsirigotis, Christos and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1802.08770},
  year={2018}
}






@article{cooper2018loss,
  title={The loss landscape of overparameterized neural networks},
  author={Cooper, Yaim},
  journal={arXiv preprint arXiv:1804.10200},
  year={2018}
}


@inproceedings{yao2020pyhessian,
  title={Py{H}essian: Neural networks through the lens of the {H}essian},
  author={Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael W},
  booktitle={IEEE International Conference on Big Data},
  year={2020}
}


@TECHREPORT{MM21a_simpsons_TR,
  author =    {Charles H Martin and Michael W Mahoney},
  title =     {Post-mortem on a deep learning contest: a {S}impson's paradox and the complementary roles of scale metrics versus shape metrics},
  number =    {Preprint: arXiv:2106.00734},
  year =      {2021},
}

@article{martin2020predicting_NatComm,
  title={Predicting trends in the quality of state-of-the-art neural networks without access to training or testing data},
  author={Martin, Charles H and Peng, Tongsu Serena and Mahoney, Michael W},
  journal={Nature Communications},
  year={2021},
  publisher={Nature Publishing Group}
}


@inproceedings{martin2019traditional,
  title={Traditional and heavy tailed self regularization in neural network models},
  author={Martin, Charles H and Mahoney, Michael W},
  booktitle={International Conference on Machine Learning},
  year={2019}
}


@inproceedings{chen2021earlybert,
  title={EarlyBERT: Efficient BERT Training via Early-bird Lottery Tickets},
  author={Chen, Xiaohan and Cheng, Yu and Wang, Shuohang and Gan, Zhe and Wang,
  Zhangyang and Liu, Jingjing},
  booktitle={Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing},
  year={2021}
}


@inproceedings{37648,
title	= {Reading Digits in Natural Images with Unsupervised Feature Learning},
author	= {Yuval Netzer and Tao Wang and Adam Coates and Alessandro Bissacco and Bo Wu and Andrew Y. Ng},
year	= {2011},
booktitle	= {NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011}
}



@inproceedings{
frankle2018the,
title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
author={Jonathan Frankle and Michael Carbin},
booktitle={International Conference on Learning Representations},
year={2019},
}

@inproceedings{frankle2020linear,
  title={Linear mode connectivity and the lottery ticket hypothesis},
  author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel and Carbin, Michael},
  booktitle={International Conference on Machine Learning},
  year={2020}
}




@inproceedings{
le2021network,
title={Network Pruning That Matters:  A Case Study on Retraining Variants},
author={Duong Hoang Le and Binh-Son Hua},
booktitle={International Conference on Learning Representations},
year={2021}
}



@inproceedings{NIPS1989_6c9882bb,
 author = {LeCun, Yann and Denker, John and Solla, Sara},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Optimal Brain Damage},
 year = {1989}
}


@inproceedings{molchanov2019pruning,
  title={Pruning convolutional neural networks for resource efficient inference},
  author={Molchanov, P and Tyree, S and Karras, T and Aila, T and Kautz, J},
  booktitle={International Conference on Learning Representations},
  year={2017}
}

@inproceedings{li2020train,
  title={Train big, then compress: Rethinking model size for efficient training and inference of transformers},
  author={Li, Zhuohan and Wallace, Eric and Shen, Sheng and Lin, Kevin and Keutzer, Kurt and Klein, Dan and Gonzalez, Joey},
  booktitle={International Conference on Machine Learning},
  year={2020}
}

@inproceedings{keskar2017large,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Nocedal, Jorge and Tang, Ping Tak Peter and Mudigere, Dheevatsa and Smelyanskiy, Mikhail},
  booktitle={International Conference on Learning Representations},
  year={2017}
}

@inproceedings{43404,
title	= {Qualitatively Characterizing Neural Network Optimization Problems},
author	= {Ian Goodfellow and Oriol Vinyals and Andrew Saxe},
year	= {2015},
booktitle	= {International Conference on Learning Representations}
}




@inproceedings{na-etal-2022-train,
    author = {Clara Na and Sanket Vaibhav Mehta and Emma Strubell},
    title = {{Train Flat, Then Compress: Sharpness-Aware Minimization Learns More Compressible Models}},
    booktitle = {Findings of the Conference on Empirical Methods in Natural Language Processing},
    year = {2022}
} 



@inproceedings{freeman2017topology,
  title={Topology and geometry of half-rectified network optimization},
  author={Freeman, C Daniel and Bruna, Joan},
  booktitle={International Conference on Learning Representations},
  year={2017}
}


@inproceedings{bellec2018deep,
  title={Deep Rewiring: Training very sparse deep networks},
  author={Bellec, Guillaume and Kappel, David and Maass, Wolfgang and Legenstein, Robert},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{
frankle2021pruning,
title={Pruning Neural Networks at Initialization: Why Are We Missing the Mark?},
author={Jonathan Frankle and Gintare Karolina Dziugaite and Daniel Roy and Michael Carbin},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{obd1989,
author = {Lecun, Yann and Denker, John and Solla, Sara},
year = {1989},
title = {Optimal Brain Damage},
booktitle = {Advances in Neural Information Processing Systems}
}


@article{morcos2019one,
  title={One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers},
  author={Morcos, Ari and Yu, Haonan and Paganini, Michela and Tian, Yuandong},
  journal={Advances in neural information processing systems},
  year={2019}
}





@inproceedings{yu2022hessian,
  title={Hessian-aware pruning and optimal neural implant},
  author={Yu, Shixing and Yao, Zhewei and Gholami, Amir and Dong, Zhen and Kim, Sehoon and Mahoney, Michael W and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3880--3891},
  year={2022}
}

@ARTICLE{SST92,
  author =       {H. S. Seung and H. Sompolinsky and N. Tishby},
  title =        {Statistical mechanics of learning from examples},
  journal =      {Physical Review A},
  year =         {1992},
  volume =       {45},
  number =       {8},
  pages =        {6056--6091},
}

@ARTICLE{WRB93,
  author =       {T. L. H. Watkin and A. Rau and M. Biehl},
  title =        {The statistical mechanics of learning a rule},
  journal =      {Rev. Mod. Phys.},
  year =         {1993},
  volume =       {65},
  number =       {2},
  pages =        {499--556}
}

@ARTICLE{DKST96,
  author =       {D. Haussler and M. Kearns and H. S. Seung and N. Tishby},
  title =        {Rigorous Learning Curve Bounds from Statistical Mechanics},
  journal =      {Machine Learning},
  year =         {1996},
  volume =       {25},
  number =       {2},
  pages =        {195--236},
}

@BOOK{EB01_BOOK,
  author =       {A. Engel and C. P. L. Van den Broeck},
  title =        {Statistical mechanics of learning},
  publisher =    {Cambridge University Press},
  year =         {2001},
  address =      {New York, NY, USA},
  series =       {},
}

@ARTICLE{BKPx20,
  author =       {Y. Bahri and J. Kadmon and J. Pennington and S. Schoenholz and J. Sohl-Dickstein and S. Ganguli},
  title =        {Statistical Mechanics of Deep Learning},
  journal =      {Annual Review of Condensed Matter Physics},
  year =         {2020},
  volume =       {11},
  number =       {},
  pages =        {501--528},
}

@inproceedings{
foret2021sharpnessaware,
title={Sharpness-aware Minimization for Efficiently Improving Generalization},
author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2021},
}


@inproceedings{barsbey2021heavy,
  title={Heavy tails in SGD and compressibility of overparametrized neural networks},
  author={Barsbey, Melih and Sefidgaran, Milad and Erdogdu, Murat A and Richard, Gael and Simsekli, Umut},
  booktitle={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{article,
author = {Hopfield, John},
year = {1982},
month = {05},
pages = {2554-8},
title = {Neural Networks and Physical Systems with Emergent Collective Computational Abilities},
volume = {79},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
}


@article{barra2012equivalence,
  title={On the equivalence of {H}opfield networks and {B}oltzmann machines},
  author={Barra, Adriano and Bernacchia, Alberto and Santucci, Enrica and Contucci, Pierluigi},
  journal={Neural Networks},
  volume={34},
  pages={1--9},
  year={2012},
  publisher={Elsevier}
}

@article{barra2008ergodic,
  title={About the ergodic regime in the analogical {H}opfield neural networks: moments of the partition function},
  author={Barra, Adriano and Guerra, Francesco},
  journal={Journal of mathematical physics},
  volume={49},
  number={12},
  pages={125217},
  year={2008},
  publisher={American Institute of Physics}
}

@article{huang2017statistical,
  title={Statistical mechanics of unsupervised feature learning in a restricted Boltzmann machine with binary synapses},
  author={Huang, Haiping},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2017},
  number={5},
  pages={053302},
  year={2017},
  publisher={IOP Publishing}
}
@article{Brush1967HistoryOT,
  title={History of the {L}enz-{I}sing Model},
  author={Stephen G. Brush},
  journal={Reviews of Modern Physics},
  year={1967},
  volume={39},
  pages={883-893}
}
@article{mccandlish2018empirical,
  title={An empirical model of large-batch training},
  author={McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Team, OpenAI Dota},
  journal={arXiv preprint arXiv:1812.06162},
  year={2018}
}

@book{wales2003energy,
  title={Energy Landscapes: Applications to Clusters, Biomolecules and Glasses},
  author={Wales, D.},
  series={Cambridge Molecular Science},
  year={2003},
  publisher={Cambridge University Press}
}

@article{brooks2001,
author = {Brooks, Charles and Onuchic, Jos√© and Wales, David},
year = {2001},
month = {08},
pages = {612-3},
title = {Statistical thermodynamics - Taking a walk on a landscape},
volume = {293},
journal = {Science (New York, N.Y.)},
}

@article{ballard2017energy,
  title={Energy landscapes for machine learning},
  author={Ballard, Andrew J and Das, Ritankar and Martiniani, Stefano and Mehta, Dhagash and Sagun, Levent and Stevenson, Jacob D and Wales, David J},
  journal={Physical Chemistry Chemical Physics},
  volume={19},
  number={20},
  pages={12585--12603},
  year={2017},
  publisher={Royal Society of Chemistry}
}

@book{stillinger2015energy,
  title={Energy Landscapes, Inherent Structures, and Condensed-Matter Phenomena},
  author={Stillinger, F.H.},
  year={2015},
  publisher={Princeton University Press}
}

@inproceedings{rosenfeld2021predictability,
  title={On the predictability of pruning across scales},
  author={Rosenfeld, Jonathan S and Frankle, Jonathan and Carbin, Michael and Shavit, Nir},
  booktitle={International Conference on Machine Learning},
  year={2021},
}

@inproceedings{baity2018comparing,
  title={Comparing dynamics: Deep neural networks versus glassy systems},
  author={Baity-Jesi, Marco and Sagun, Levent and Geiger, Mario and Spigler, Stefano and Arous, G{\'e}rard Ben and Cammarota, Chiara and LeCun, Yann and Wyart, Matthieu and Biroli, Giulio},
  booktitle={International Conference on Machine Learning},
  year={2018}
}

@article{barbier2019optimal,
  title={Optimal errors and phase transitions in high-dimensional generalized linear models},
  author={Barbier, Jean and Krzakala, Florent and Macris, Nicolas and Miolane, L{\'e}o and Zdeborov{\'a}, Lenka},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={12},
  pages={5451--5460},
  year={2019},
  publisher={National Acad Sciences}
}

@inproceedings{sorscher2022beyond,
  title={Beyond neural scaling laws: beating power law scaling via data pruning},
  author={Sorscher, Ben and Geirhos, Robert and Shekhar, Shashank and Ganguli, Surya and Morcos, Ari},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@inproceedings{he2016identity,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={European Conference on Computer Vision},
  year={2016}
}




@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year={2017}
}

@inproceedings{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  booktitle={International Conference on Learning Representations},
  year={2014}
}


@article{krizhevsky2009cifar,
  title={Cifar-10 and cifar-100 datasets},
  author={Krizhevsky, Alex and Nair, Vinod and Hinton, Geoffrey},
  year={2009}
}

@inproceedings{sermanet2011traffic,
  title={Traffic signs and pedestrians vision with multi-scale convolutional networks},
  author={Sermanet, Pierre and Kavukcuoglu, Koray and LeCun, Yann},
  booktitle={Snowbird Machine Learning Workshop},
  year={2011}
}