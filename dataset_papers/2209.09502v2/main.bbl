\begin{thebibliography}{105}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock {Intriguing Properties of Neural Networks}.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock {Explaining and Harnessing Adversarial Examples}.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Jiang et~al.(2019)Jiang, Ma, Chen, Bailey, and Jiang]{jiang2019black}
Linxi Jiang, Xingjun Ma, Shaoxiang Chen, James Bailey, and Yu-Gang Jiang.
\newblock Black-box adversarial attacks on video recognition models.
\newblock In \emph{Proceedings of the 27th ACM International Conference on
  Multimedia}, pages 864--872, 2019.

\bibitem[Yan et~al.(2020)Yan, Wei, and Li]{yan2020sparse}
Huanqian Yan, Xingxing Wei, and Bo~Li.
\newblock Sparse black-box video attack with reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2001.03754}, 2020.

\bibitem[Wei et~al.(2020)Wei, Chen, Wei, Jiang, Chua, Zhou, and
  Jiang]{wei2020heuristic}
Zhipeng Wei, Jingjing Chen, Xingxing Wei, Linxi Jiang, Tat-Seng Chua, Fengfeng
  Zhou, and Yu-Gang Jiang.
\newblock Heuristic black-box adversarial attacks on video recognition models.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pages 12338--12345, 2020.

\bibitem[Li et~al.(2021{\natexlab{a}})Li, Aich, Zhu, Asif, Song, Roy-Chowdhury,
  and Krishnamurthy]{li2021adversarial}
Shasha Li, Abhishek Aich, Shitong Zhu, Salman Asif, Chengyu Song, Amit
  Roy-Chowdhury, and Srikanth Krishnamurthy.
\newblock Adversarial attacks on black box video classifiers: Leveraging the
  power of geometric transformations.
\newblock \emph{Advances in Neural Information Processing Systems}, 34,
  2021{\natexlab{a}}.

\bibitem[Zhang et~al.(2020)Zhang, Zhu, Zhu, and Yang]{zhang2020motion}
Hu~Zhang, Linchao Zhu, Yi~Zhu, and Yi~Yang.
\newblock Motion-excited sampler: Video adversarial attack with sparked prior.
\newblock In \emph{European Conference on Computer Vision}. Springer, 2020.

\bibitem[Carlini and Wagner(2017)]{carlini2017towards}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{2017 IEEE symposium on security and privacy (sp)}, pages
  39--57. IEEE, 2017.

\bibitem[Moosavi-Dezfooli et~al.(2016)Moosavi-Dezfooli, Fawzi, and
  Frossard]{moosavi2016deepfool}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard.
\newblock {Deepfool: A Simple and Accurate Method to Fool Deep Neural
  Networks}.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2574--2582. IEEE, 2016.

\bibitem[Poursaeed et~al.(2018)Poursaeed, Katsman, Gao, and
  Belongie]{poursaeed2018generative}
Omid Poursaeed, Isay Katsman, Bicheng Gao, and Serge Belongie.
\newblock {Generative Adversarial Perturbations}.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 4422--4431. IEEE, 2018.

\bibitem[Naseer et~al.(2019)Naseer, Khan, Khan, Khan, and
  Porikli]{naseer2019cross}
Muzammal Naseer, Salman~H Khan, Harris Khan, Fahad~Shahbaz Khan, and Fatih
  Porikli.
\newblock {Cross-Domain Transferability of Adversarial Perturbations}.
\newblock \emph{arXiv preprint arXiv:1905.11736}, 2019.

\bibitem[Salzmann et~al.(2021)]{salzmann2021learning}
Mathieu Salzmann et~al.
\newblock Learning transferable adversarial perturbations.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Zhang et~al.(2022)Zhang, Li, Chen, Song, Gao, He, and
  Xue']{zhang2022beyond}
Qilong Zhang, Xiaodan Li, YueFeng Chen, Jingkuan Song, Lianli Gao, Yuan He, and
  Hui Xue'.
\newblock Beyond imagenet attack: Towards crafting adversarial examples for
  black-box domains.
\newblock In \emph{International Conference on Learning Representations}.
  International Conference on Learning Representations (ICLR), 2022.

\bibitem[Kurakin et~al.(2016)Kurakin, Goodfellow, and
  Bengio]{kurakin2016adversarial}
Alexey Kurakin, Ian Goodfellow, and Samy Bengio.
\newblock Adversarial machine learning at scale.
\newblock \emph{arXiv preprint arXiv:1611.01236}, 2016.

\bibitem[Nguyen et~al.(2015)Nguyen, Yosinski, and Clune]{nguyen2015deep}
Anh Nguyen, Jason Yosinski, and Jeff Clune.
\newblock {Deep Neural Networks are Easily Fooled: High Confidence Predictions
  for Unrecognizable Images}.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 427--436. IEEE, 2015.

\bibitem[Song et~al.(2018)Song, Jin, Huang, and Hu]{song2018multi}
Qingquan Song, Haifeng Jin, Xiao Huang, and Xia Hu.
\newblock Multi-label adversarial perturbations.
\newblock In \emph{2018 IEEE International Conference on Data Mining (ICDM)},
  pages 1242--1247. IEEE, 2018.

\bibitem[Zhou et~al.(2020)Zhou, Luo, Lin, Xu, and Zhang]{zhou2020generating}
Nan Zhou, Wenjian Luo, Xin Lin, Peilan Xu, and Zhenya Zhang.
\newblock Generating multi-label adversarial examples by linear programming.
\newblock In \emph{2020 International Joint Conference on Neural Networks
  (IJCNN)}, pages 1--8. IEEE, 2020.

\bibitem[Lu et~al.(2021)Lu, Xian, Yan, Hu, Sun, Guo, Huang, and
  Zheng]{lu2021discriminator}
Shaohao Lu, Yuqiao Xian, Ke~Yan, Yi~Hu, Xing Sun, Xiaowei Guo, Feiyue Huang,
  and Wei-Shi Zheng.
\newblock Discriminator-free generative adversarial attack.
\newblock In \emph{Proceedings of the 29th ACM International Conference on
  Multimedia}, pages 1544--1552. ACM, 2021.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Advances in neural information processing systems}, 25, 2012.

\bibitem[Boutell et~al.(2004)Boutell, Luo, Shen, and
  Brown]{boutell2004learning}
Matthew~R Boutell, Jiebo Luo, Xipeng Shen, and Christopher~M Brown.
\newblock Learning multi-label scene classification.
\newblock \emph{Pattern recognition}, 37\penalty0 (9):\penalty0 1757--1771,
  2004.

\bibitem[Zhang and Zhou(2007)]{zhang2007ml}
Min-Ling Zhang and Zhi-Hua Zhou.
\newblock Ml-knn: A lazy learning approach to multi-label learning.
\newblock \emph{Pattern recognition}, 40\penalty0 (7):\penalty0 2038--2048,
  2007.

\bibitem[Read et~al.(2011)Read, Pfahringer, Holmes, and
  Frank]{read2011classifier}
Jesse Read, Bernhard Pfahringer, Geoff Holmes, and Eibe Frank.
\newblock Classifier chains for multi-label classification.
\newblock \emph{Machine learning}, page 333, 2011.

\bibitem[Chen et~al.(2018{\natexlab{a}})Chen, Chen, Yeh, and
  Wang]{chen2018order}
Shang-Fu Chen, Yi-Chen Chen, Chih-Kuan Yeh, and Yu-Chiang Wang.
\newblock Order-free rnn with visual attention for multi-label classification.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}. AAAI, 2018{\natexlab{a}}.

\bibitem[Allwein et~al.(2000)Allwein, Schapire, and
  Singer]{allwein2000reducing}
Erin~L Allwein, Robert~E Schapire, and Yoram Singer.
\newblock Reducing multiclass to binary: A unifying approach for margin
  classifiers.
\newblock \emph{Journal of machine learning research}, 1\penalty0
  (Dec):\penalty0 113--141, 2000.

\bibitem[Chen et~al.(2019{\natexlab{a}})Chen, Wei, Wang, and
  Guo]{MLGCN_CVPR_2019}
Zhao-Min Chen, Xiu-Shen Wei, Peng Wang, and Yanwen Guo.
\newblock {Multi-Label Image Recognition with Graph Convolutional Networks}.
\newblock In \emph{The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}. IEEE, 2019{\natexlab{a}}.

\bibitem[Cai et~al.(2022)Cai, Rane, Brito, Song, Krishnamurthy, Roy-Chowdhury,
  and Asif]{cai2022zero}
Zikui Cai, Shantanu Rane, Alejandro~E Brito, Chengyu Song, Srikanth~V
  Krishnamurthy, Amit~K Roy-Chowdhury, and M~Salman Asif.
\newblock Zero-query transfer attacks on context-aware object detectors.
\newblock \emph{arXiv preprint arXiv:2203.15230}, 2022.

\bibitem[Cai et~al.(2021)Cai, Xie, Li, Yin, Song, Krishnamurthy, Roy-Chowdhury,
  and Asif]{cai2021context}
Zikui Cai, Xinxin Xie, Shasha Li, Mingjun Yin, Chengyu Song, Srikanth~V
  Krishnamurthy, Amit~K Roy-Chowdhury, and M~Salman Asif.
\newblock Context-aware transfer attacks for object detection.
\newblock \emph{arXiv preprint arXiv:2112.03223}, 2021.

\bibitem[Sitawarin et~al.(2018)Sitawarin, Bhagoji, Mosenia, Chiang, and
  Mittal]{sitawarin2018darts}
Chawin Sitawarin, Arjun~Nitin Bhagoji, Arsalan Mosenia, Mung Chiang, and
  Prateek Mittal.
\newblock Darts: Deceiving autonomous cars with toxic signs.
\newblock \emph{arXiv preprint arXiv:1802.06430}, 2018.

\bibitem[Chen et~al.(2018{\natexlab{b}})Chen, Cornelius, Martin, and
  Chau]{chen2018shapeshifter}
Shang-Tse Chen, Cory Cornelius, Jason Martin, and Duen Horng~Polo Chau.
\newblock Shapeshifter: Robust physical adversarial attack on faster r-cnn
  object detector.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 52--68. Springer, 2018{\natexlab{b}}.

\bibitem[Yin et~al.(2021)Yin, Li, Cai, Song, Asif, Roy-Chowdhury, and
  Krishnamurthy]{yin2021exploiting}
Mingjun Yin, Shasha Li, Zikui Cai, Chengyu Song, M~Salman Asif, Amit~K
  Roy-Chowdhury, and Srikanth~V Krishnamurthy.
\newblock Exploiting multi-object relationships for detecting adversarial
  attacks in complex scenes.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 7858--7867, 2021.

\bibitem[Xiao et~al.(2018{\natexlab{a}})Xiao, Li, Zhu, He, Liu, and
  Song]{xiao2018generating}
Chaowei Xiao, Bo~Li, Jun-Yan Zhu, Warren He, Mingyan Liu, and Dawn Song.
\newblock {Generating Adversarial Examples with Adversarial Networks}.
\newblock \emph{arXiv preprint arXiv:1801.02610}, 2018{\natexlab{a}}.

\bibitem[Wah et~al.(2011)Wah, Branson, Welinder, Perona, and
  Belongie]{wah2011caltech}
Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge
  Belongie.
\newblock The caltech-ucsd birds-200-2011 dataset.
\newblock 2011.

\bibitem[PyTorch(2022)]{imagenet2022task}
PyTorch.
\newblock Imagenet models and pre-trained weights.
\newblock PyTorch, 2022.
\newblock URL \url{https://pytorch.org/vision/stable/models.html}.

\bibitem[Badue et~al.(2021)Badue, Guidolini, Carneiro, Azevedo, Cardoso,
  Forechi, Jesus, Berriel, Paixao, Mutz, et~al.]{badue2021self}
Claudine Badue, R{\^a}nik Guidolini, Raphael~Vivacqua Carneiro, Pedro Azevedo,
  Vinicius~B Cardoso, Avelino Forechi, Luan Jesus, Rodrigo Berriel, Thiago~M
  Paixao, Filipe Mutz, et~al.
\newblock Self-driving cars: A survey.
\newblock \emph{Expert Systems with Applications}, 165:\penalty0 113816, 2021.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and
  Duerig]{jia2021scaling}
Chao Jia, Yinfei Yang, Ye~Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le,
  Yun-Hsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock In \emph{International Conference on Machine Learning}, pages
  4904--4916. PMLR, 2021.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International Conference on Machine Learning}, pages
  8748--8763. PMLR, 2021.

\bibitem[Mu et~al.(2021)Mu, Kirillov, Wagner, and Xie]{mu2021slip}
Norman Mu, Alexander Kirillov, David Wagner, and Saining Xie.
\newblock Slip: Self-supervision meets language-image pre-training.
\newblock \emph{arXiv preprint arXiv:2112.12750}, 2021.

\bibitem[Li et~al.(2021{\natexlab{b}})Li, Liang, Zhao, Cui, Ouyang, Shao, Yu,
  and Yan]{li2021supervision}
Yangguang Li, Feng Liang, Lichen Zhao, Yufeng Cui, Wanli Ouyang, Jing Shao,
  Fengwei Yu, and Junjie Yan.
\newblock Supervision exists everywhere: A data efficient contrastive
  language-image pre-training paradigm.
\newblock \emph{arXiv preprint arXiv:2110.05208}, 2021{\natexlab{b}}.

\bibitem[Yao et~al.(2021)Yao, Huang, Hou, Lu, Niu, Xu, Liang, Li, Jiang, and
  Xu]{yao2021filip}
Lewei Yao, Runhui Huang, Lu~Hou, Guansong Lu, Minzhe Niu, Hang Xu, Xiaodan
  Liang, Zhenguo Li, Xin Jiang, and Chunjing Xu.
\newblock Filip: Fine-grained interactive language-image pre-training.
\newblock \emph{arXiv preprint arXiv:2111.07783}, 2021.

\bibitem[Luo et~al.(2021)Luo, Ji, Zhong, Chen, Lei, Duan, and
  Li]{luo2021clip4clip}
Huaishao Luo, Lei Ji, Ming Zhong, Yang Chen, Wen Lei, Nan Duan, and Tianrui Li.
\newblock Clip4clip: An empirical study of clip for end to end video clip
  retrieval.
\newblock \emph{arXiv preprint arXiv:2104.08860}, 2021.

\bibitem[Patashnik et~al.(2021)Patashnik, Wu, Shechtman, Cohen-Or, and
  Lischinski]{patashnik2021styleclip}
Or~Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, and Dani Lischinski.
\newblock Styleclip: Text-driven manipulation of stylegan imagery.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 2085--2094, 2021.

\bibitem[Khandelwal et~al.(2021)Khandelwal, Weihs, Mottaghi, and
  Kembhavi]{khandelwal2021simple}
Apoorv Khandelwal, Luca Weihs, Roozbeh Mottaghi, and Aniruddha Kembhavi.
\newblock Simple but effective: Clip embeddings for embodied ai.
\newblock \emph{arXiv preprint arXiv:2111.09888}, 2021.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and
  Chen]{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 2022.

\bibitem[Ramesh et~al.(2021)Ramesh, Pavlov, Goh, Gray, Voss, Radford, Chen, and
  Sutskever]{ramesh2021zero}
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec
  Radford, Mark Chen, and Ilya Sutskever.
\newblock Zero-shot text-to-image generation.
\newblock In \emph{International Conference on Machine Learning}, pages
  8821--8831. PMLR, 2021.

\bibitem[Conde and Turgutlu(2021)]{conde2021clip}
Marcos~V Conde and Kerem Turgutlu.
\newblock Clip-art: contrastive pre-training for fine-grained art
  classification.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 3956--3960, 2021.

\bibitem[Gal et~al.(2021)Gal, Patashnik, Maron, Chechik, and
  Cohen-Or]{gal2021stylegan}
Rinon Gal, Or~Patashnik, Haggai Maron, Gal Chechik, and Daniel Cohen-Or.
\newblock Stylegan-nada: Clip-guided domain adaptation of image generators.
\newblock \emph{arXiv preprint arXiv:2108.00946}, 2021.

\bibitem[Sanghi et~al.(2021)Sanghi, Chu, Lambourne, Wang, Cheng, and
  Fumero]{sanghi2021clip}
Aditya Sanghi, Hang Chu, Joseph~G Lambourne, Ye~Wang, Chin-Yi Cheng, and Marco
  Fumero.
\newblock Clip-forge: Towards zero-shot text-to-shape generation.
\newblock \emph{arXiv preprint arXiv:2110.02624}, 2021.

\bibitem[Kim and Ye(2021)]{kim2021diffusionclip}
Gwanghyun Kim and Jong~Chul Ye.
\newblock Diffusionclip: Text-guided image manipulation using diffusion models.
\newblock \emph{arXiv preprint arXiv:2110.02711}, 2021.

\bibitem[Kwon and Ye(2021)]{kwon2021clipstyler}
Gihyun Kwon and Jong~Chul Ye.
\newblock Clipstyler: Image style transfer with a single text condition.
\newblock \emph{arXiv preprint arXiv:2112.00374}, 2021.

\bibitem[Rao et~al.(2022)Rao, Zhao, Chen, Tang, Zhu, Huang, Zhou, and
  Lu]{rao2021denseclip}
Yongming Rao, Wenliang Zhao, Guangyi Chen, Yansong Tang, Zheng Zhu, Guan Huang,
  Jie Zhou, and Jiwen Lu.
\newblock Denseclip: Language-guided dense prediction with context-aware
  prompting.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2022.

\bibitem[Li et~al.(2022)Li, Xu, Wang, Zhou, Lin, Zhu, Zeng, Ji, and
  Chang]{li2022clip}
Manling Li, Ruochen Xu, Shuohang Wang, Luowei Zhou, Xudong Lin, Chenguang Zhu,
  Michael Zeng, Heng Ji, and Shih-Fu Chang.
\newblock Clip-event: Connecting text and images with event structures.
\newblock \emph{arXiv preprint arXiv:2201.05078}, 2022.

\bibitem[Fawzi et~al.(2018)Fawzi, Fawzi, and Frossard]{fawzi2018analysis}
Alhussein Fawzi, Omar Fawzi, and Pascal Frossard.
\newblock {Analysis of Classifiers’ Robustness to Adversarial Perturbations}.
\newblock \emph{Machine Learning}, pages 481--508, 2018.

\bibitem[Liu et~al.(2019)Liu, Liu, Fan, Ma, Zhang, Xie, and
  Tao]{liu2019perceptual}
Aishan Liu, Xianglong Liu, Jiaxin Fan, Yuqing Ma, Anlan Zhang, Huiyuan Xie, and
  Dacheng Tao.
\newblock {Perceptual-Sensitive GAN for Generating Adversarial Patches}.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, pages 1028--1035. AAAI, 2019.

\bibitem[Han et~al.(2019)Han, Dong, Zhang, Chen, Zhang, Yu, Luo, and
  Wang]{han2019once}
Jiangfan Han, Xiaoyi Dong, Ruimao Zhang, Dongdong Chen, Weiming Zhang, Nenghai
  Yu, Ping Luo, and Xiaogang Wang.
\newblock {Once a MAN: Towards Multi-Target Attack via Learning Multi-Target
  Adversarial Network Once}.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 5158--5167. IEEE, 2019.

\bibitem[Xiao et~al.(2018{\natexlab{b}})Xiao, Zhu, Li, He, Liu, and
  Song]{xiao2018spatially}
Chaowei Xiao, Jun-Yan Zhu, Bo~Li, Warren He, Mingyan Liu, and Dawn Song.
\newblock Spatially transformed adversarial examples.
\newblock \emph{arXiv preprint arXiv:1801.02612}, 2018{\natexlab{b}}.

\bibitem[Nakka and Salzmann(2020)]{nakka2020indirect}
Krishna~Kanth Nakka and Mathieu Salzmann.
\newblock Indirect local attacks for context-aware semantic segmentation
  networks.
\newblock In \emph{European Conference on Computer Vision}, pages 611--628.
  Springer, 2020.

\bibitem[Hu et~al.(2021)Hu, Ke, Wang, and Lyu]{hu2021tkml}
Shu Hu, Lipeng Ke, Xin Wang, and Siwei Lyu.
\newblock Tkml-ap: Adversarial attacks to top-k multi-label learning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 7649--7657. IEEE, 2021.

\bibitem[Dong et~al.(2018)Dong, Liao, Pang, Su, Zhu, Hu, and
  Li]{dong2018boosting}
Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, and
  Jianguo Li.
\newblock {Boosting Adversarial Attacks with Momentum}.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 9185--9193. IEEE, 2018.

\bibitem[Fan et~al.(2020)Fan, Wu, Li, Zhang, Li, Li, and Yang]{fan2020sparse}
Yanbo Fan, Baoyuan Wu, Tuanhui Li, Yong Zhang, Mingyang Li, Zhifeng Li, and
  Yujiu Yang.
\newblock Sparse adversarial attack via perturbation factorization.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part XXII 16}, pages 35--50.
  Springer, 2020.

\bibitem[Bhattad et~al.(2019)Bhattad, Chong, Liang, Li, and
  Forsyth]{bhattad2019unrestricted}
Anand Bhattad, Min~Jin Chong, Kaizhao Liang, Bo~Li, and David~A Forsyth.
\newblock Unrestricted adversarial examples via semantic manipulation.
\newblock \emph{arXiv preprint arXiv:1904.06347}, 2019.

\bibitem[Qiu et~al.(2020)Qiu, Xiao, Yang, Yan, Lee, and Li]{qiu2020semanticadv}
Haonan Qiu, Chaowei Xiao, Lei Yang, Xinchen Yan, Honglak Lee, and Bo~Li.
\newblock Semanticadv: Generating adversarial examples via
  attribute-conditioned image editing.
\newblock In \emph{European Conference on Computer Vision}, pages 19--37.
  Springer, 2020.

\bibitem[Jolicoeur-Martineau(2018)]{jolicoeur2018relativistic}
Alexia Jolicoeur-Martineau.
\newblock The relativistic discriminator: a key element missing from standard
  gan.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Fang et~al.(2021)Fang, Xiong, Xu, and Chen]{fang2021clip2video}
Han Fang, Pengfei Xiong, Luhui Xu, and Yu~Chen.
\newblock Clip2video: Mastering video-text retrieval via image clip.
\newblock \emph{arXiv preprint arXiv:2106.11097}, 2021.

\bibitem[Simonyan and Zisserman(2014)]{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock {Very Deep Convolutional Networks for Large-Scale Image Recognition}.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Johnson et~al.(2016)Johnson, Alahi, and
  Fei-Fei]{johnson2016perceptual}
Justin Johnson, Alexandre Alahi, and Li~Fei-Fei.
\newblock {Perceptual Losses for Real-Time Style Transfer and
  Super-Resolution}.
\newblock In \emph{European conference on computer vision}, pages 694--711.
  Springer, 2016.

\bibitem[Mechrez et~al.(2018)Mechrez, Talmi, and
  Zelnik-Manor]{mechrez2018contextual}
Roey Mechrez, Itamar Talmi, and Lihi Zelnik-Manor.
\newblock The contextual loss for image transformation with non-aligned data.
\newblock In \emph{Proceedings of the European conference on computer vision
  (ECCV)}, pages 768--783, 2018.

\bibitem[Hessel et~al.(2021)Hessel, Holtzman, Forbes, Bras, and
  Choi]{hessel2021clipscore}
Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan~Le Bras, and Yejin Choi.
\newblock {CLIPScore:} a reference-free evaluation metric for image captioning.
\newblock In \emph{EMNLP}, 2021.

\bibitem[Zhou et~al.(2022)Zhou, Yang, Loy, and Liu]{zhou2022cocoop}
Kaiyang Zhou, Jingkang Yang, Chen~Change Loy, and Ziwei Liu.
\newblock Conditional prompt learning for vision-language models.
\newblock In \emph{CVPR}, 2022.

\bibitem[Chen et~al.(2019{\natexlab{b}})Chen, Wei, Wang, and
  Guo]{chen2019multi}
Zhao-Min Chen, Xiu-Shen Wei, Peng Wang, and Yanwen Guo.
\newblock Multi-label image recognition with graph convolutional networks.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 5177--5186, 2019{\natexlab{b}}.

\bibitem[Islam et~al.(2021)Islam, Kowal, Derpanis, and Bruce]{islam2021segmix}
Md~Amirul Islam, Matthew Kowal, Konstantinos~G Derpanis, and Neil~DB Bruce.
\newblock Segmix: Co-occurrence driven mixup for semantic segmentation and
  adversarial robustness.
\newblock \emph{arXiv preprint arXiv:2108.09929}, 2021.

\bibitem[Zhang et~al.(2019)Zhang, Zhang, Wang, and Xie]{zhang2019co}
Hang Zhang, Han Zhang, Chenguang Wang, and Junyuan Xie.
\newblock Co-occurrent features in semantic segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 548--557, 2019.

\bibitem[Islam et~al.(2020)Islam, Kowal, Derpanis, and Bruce]{islam2020feature}
Md~Amirul Islam, Matthew Kowal, Konstantinos~G Derpanis, and Neil~DB Bruce.
\newblock Feature binding with category-dependant mixup for semantic
  segmentation and adversarial robustness.
\newblock \emph{arXiv preprint arXiv:2008.05667}, 2020.

\bibitem[Hadsell et~al.(2006)Hadsell, Chopra, and
  LeCun]{hadsell2006dimensionality}
Raia Hadsell, Sumit Chopra, and Yann LeCun.
\newblock Dimensionality reduction by learning an invariant mapping.
\newblock In \emph{2006 IEEE Computer Society Conference on Computer Vision and
  Pattern Recognition (CVPR'06)}, volume~2, pages 1735--1742. IEEE, 2006.

\bibitem[Chuang et~al.(2020)Chuang, Robinson, Lin, Torralba, and
  Jegelka]{chuang2020debiased}
Ching-Yao Chuang, Joshua Robinson, Yen-Chen Lin, Antonio Torralba, and Stefanie
  Jegelka.
\newblock Debiased contrastive learning.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 8765--8775, 2020.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock {Adam: A Method for Stochastic Optimization}.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Naseer et~al.(2020)Naseer, Khan, Hayat, Khan, and
  Porikli]{naseer2020self}
Muzammal Naseer, Salman Khan, Munawar Hayat, Fahad~Shahbaz Khan, and Fatih
  Porikli.
\newblock A self-supervised approach for adversarial robustness.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 262--271, 2020.

\bibitem[Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \emph{arXiv preprint arXiv:1706.06083}, 2017.

\bibitem[Everingham et~al.(2010)Everingham, Van~Gool, Williams, Winn, and
  Zisserman]{everingham2010pascal}
Mark Everingham, Luc Van~Gool, Christopher~KI Williams, John Winn, and Andrew
  Zisserman.
\newblock {The Pascal Visual Object Classes (VOC) Challenge}.
\newblock \emph{International journal of computer vision}, 88\penalty0
  (2):\penalty0 303--338, 2010.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock {Microsoft COCO: Common Objects in Context}.
\newblock In \emph{European conference on computer vision}, pages 740--755.
  Springer, 2014.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock {Deep Residual Learning for Image Recognition}.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778. IEEE, 2016.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and
  Weinberger]{huang2017densely}
Gao Huang, Zhuang Liu, Laurens Van Der~Maaten, and Kilian~Q Weinberger.
\newblock {Densely Connected Convolutional Networks}.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4700--4708. IEEE, 2017.

\bibitem[Godbole and Sarawagi(2004)]{godbole2004discriminative}
Shantanu Godbole and Sunita Sarawagi.
\newblock Discriminative methods for multi-labeled classification.
\newblock In \emph{Pacific-Asia conference on knowledge discovery and data
  mining}, pages 22--30. Springer, 2004.

\bibitem[Sorower(2010)]{sorower2010literature}
Mohammad~S Sorower.
\newblock A literature survey on algorithms for multi-label learning.
\newblock \emph{Oregon State University, Corvallis}, 18:\penalty0 1--25, 2010.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Krause et~al.(2013)Krause, Deng, Stark, and
  Fei-Fei]{krause2013collecting}
Jonathan Krause, Jia Deng, Michael Stark, and Li~Fei-Fei.
\newblock Collecting a large-scale dataset of fine-grained cars.
\newblock 2013.

\bibitem[Maji et~al.(2013)Maji, Rahtu, Kannala, Blaschko, and
  Vedaldi]{maji2013fine}
Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew Blaschko, and Andrea Vedaldi.
\newblock Fine-grained visual classification of aircraft.
\newblock \emph{arXiv preprint arXiv:1306.5151}, 2013.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. IEEE, 2009.

\bibitem[Chen(2022)]{coarse2022task}
Aaron Chen.
\newblock Coarse-grain models and pre-trained weights.
\newblock GitHub link, 2022.
\newblock URL \url{https://github.com/aaron-xichen/pytorch-playground}.

\bibitem[Hu et~al.(2018)Hu, Shen, and Sun]{hu2018squeeze}
Jie Hu, Li~Shen, and Gang Sun.
\newblock Squeeze-and-excitation networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 7132--7141. IEEE, 2018.

\bibitem[Alibaba-AAIG(2022)]{fine2022task}
Alibaba-AAIG.
\newblock Fine-grain models and pre-trained weights.
\newblock GitHub link, 2022.
\newblock URL
  \url{https://github.com/Alibaba-AAIG/Beyond-ImageNet-Attack/releases/download/Pretrained_DCL_model/model.zip}.

\bibitem[Girshick(2015)]{girshick2015fast}
Ross Girshick.
\newblock Fast r-cnn.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, 2015.

\bibitem[Lin et~al.(2017)Lin, Goyal, Girshick, He, and
  Doll{\'a}r]{lin2017focal}
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
\newblock Focal loss for dense object detection.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, 2017.

\bibitem[Carion et~al.(2020)Carion, Massa, Synnaeve, Usunier, Kirillov, and
  Zagoruyko]{detr}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In \emph{ECCV}, 2020.

\bibitem[Zhu et~al.(2021)Zhu, Su, Lu, Li, Wang, and Dai]{zhu2021deformable}
Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang Wang, and Jifeng Dai.
\newblock Deformable detr: Deformable transformers for end-to-end object
  detection.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=gZ9hCDWe6ke}.

\bibitem[Chen et~al.(2019{\natexlab{c}})Chen, Wang, Pang, Cao, Xiong, Li, Sun,
  Feng, Liu, Xu, Zhang, Cheng, Zhu, Cheng, Zhao, Li, Lu, Zhu, Wu, Dai, Wang,
  Shi, Ouyang, Loy, and Lin]{mmdetection}
Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, Yu~Xiong, Xiaoxiao Li,
  Shuyang Sun, Wansen Feng, Ziwei Liu, Jiarui Xu, Zheng Zhang, Dazhi Cheng,
  Chenchen Zhu, Tianheng Cheng, Qijie Zhao, Buyu Li, Xin Lu, Rui Zhu, Yue Wu,
  Jifeng Dai, Jingdong Wang, Jianping Shi, Wanli Ouyang, Chen~Change Loy, and
  Dahua Lin.
\newblock {MMDetection}: Open mmlab detection toolbox and benchmark.
\newblock \emph{arXiv preprint arXiv:1906.07155}, 2019{\natexlab{c}}.

\bibitem[Li et~al.(2020)Li, Zhu, Paul, Roy-Chowdhury, Song, Krishnamurthy,
  Swami, and Chan]{li2020connecting}
Shasha Li, Shitong Zhu, Sudipta Paul, Amit Roy-Chowdhury, Chengyu Song,
  Srikanth Krishnamurthy, Ananthram Swami, and Kevin~S Chan.
\newblock {Connecting the Dots: Detecting Adversarial Perturbations Using
  Context Inconsistency}.
\newblock In \emph{European Conference on Computer Vision}, pages 396--413.
  Springer, 2020.

\bibitem[Aich et~al.(2021)Aich, Zheng, Karanam, Chen, Roy-Chowdhury, and
  Wu]{Aich_2021_ICCV}
Abhishek Aich, Meng Zheng, Srikrishna Karanam, Terrence Chen, Amit~K.
  Roy-Chowdhury, and Ziyan Wu.
\newblock Spatio-temporal representation factorization for video-based person
  re-identification.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 152--162, October 2021.

\bibitem[Aich et~al.(2020)Aich, Gupta, Panda, Hyder, Asif, and
  Roy-Chowdhury]{Aich_2020_CVPR}
Abhishek Aich, Akash Gupta, Rameswar Panda, Rakib Hyder, M.~Salman Asif, and
  Amit~K. Roy-Chowdhury.
\newblock Non-adversarial video synthesis with learned priors.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, June 2020.

\bibitem[Gupta et~al.(2020)Gupta, Aich, and Roy-Chowdhury]{gupta2020alanet}
Akash Gupta, Abhishek Aich, and Amit~K Roy-Chowdhury.
\newblock Alanet: Adaptive latent attention network for joint video deblurring
  and interpolation.
\newblock In \emph{Proceedings of the 28th ACM International Conference on
  Multimedia}, pages 256--264, 2020.

\bibitem[Abid et~al.(2018)Abid, Zhang, Bagaria, and Zou]{abid2018exploring}
Abubakar Abid, Martin~J Zhang, Vivek~K Bagaria, and James Zou.
\newblock Exploring patterns enriched in a dataset with contrastive principal
  component analysis.
\newblock \emph{Nature communications}, 9\penalty0 (1):\penalty0 1--7, 2018.

\bibitem[Fujiwara et~al.(2019)Fujiwara, Kwon, and Ma]{fujiwara2019supporting}
Takanori Fujiwara, Oh-Hyun Kwon, and Kwan-Liu Ma.
\newblock Supporting analysis of dimensionality reduction results with
  contrastive learning.
\newblock \emph{IEEE transactions on visualization and computer graphics},
  26\penalty0 (1):\penalty0 45--55, 2019.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Nair and Hinton(2010)]{nair2010rectified}
Vinod Nair and Geoffrey~E Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In \emph{ICML}. ICML, 2010.

\bibitem[Karras et~al.(2019)Karras, Laine, and Aila]{karras2019style}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 4401--4410. IEEE, 2019.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock {PyTorch: An Imperative Style, High-Performance Deep Learning
  Library}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  8026--8037. NeurIPS, 2019.

\end{thebibliography}
