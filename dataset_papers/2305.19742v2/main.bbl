% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nty/global//global/global}
    \entry{Athey.2021}{article}{}
      \name{author}{2}{}{%
        {{hash=cab7b4f39472e6c01dc0fc30a32c6d89}{%
           family={Athey},
           familyi={A\bibinitperiod},
           given={Susan},
           giveni={S\bibinitperiod}}}%
        {{hash=e22c2c3bb1bd12e43f46c07ea788b581}{%
           family={Wager},
           familyi={W\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{3bc6821e6b1df2328c0ecb9ca4ae3911}
      \strng{fullhash}{3bc6821e6b1df2328c0ecb9ca4ae3911}
      \strng{bibnamehash}{3bc6821e6b1df2328c0ecb9ca4ae3911}
      \strng{authorbibnamehash}{3bc6821e6b1df2328c0ecb9ca4ae3911}
      \strng{authornamehash}{3bc6821e6b1df2328c0ecb9ca4ae3911}
      \strng{authorfullhash}{3bc6821e6b1df2328c0ecb9ca4ae3911}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In many areas, practitioners seek to use observational data to learn a treatment assignment policy that satisfies application-specific constraints, such as budget, fairness, simplicity, or other functional form constraints. For example, policies may be restricted to take the form of decision trees based on a limited set of easily observable individual characteristics. We propose a new approach to this problem motivated by the theory of semiparametrically efficient estimation. Our method can be used to optimize either binary treatments or infinitesimal nudges to continuous treatments, and can leverage observational data where causal effects are identified using a variety of strategies, including selection on observables and instrumental variables. Given a doubly robust estimator of the causal effect of assigning everyone to treatment, we develop an algorithm for choosing whom to treat, and establish strong guarantees for the asymptotic utilitarian regret of the resulting policy.}
      \field{journaltitle}{{Econometrica}}
      \field{number}{1}
      \field{title}{{Policy learning with observational data}}
      \field{volume}{89}
      \field{year}{2021}
      \field{pages}{133\bibrangedash 161}
      \range{pages}{29}
      \verb{file}
      \verb 1702.02896:Attachments/1702.02896.pdf:application/pdf
      \endverb
      \keyw{Computer Science - Learning;Mathematics - Statistics;Statistics - Machine Learning;Statistics - Theory}
    \endentry
    \entry{Bellot.2022}{article}{}
      \name{author}{3}{}{%
        {{hash=7b5fda20efafe886a32847418d6f7035}{%
           family={Bellot},
           familyi={B\bibinitperiod},
           given={Alexis},
           giveni={A\bibinitperiod}}}%
        {{hash=4365e6624d80ba500448c738a47e75dd}{%
           family={Dhir},
           familyi={D\bibinitperiod},
           given={Anish},
           giveni={A\bibinitperiod}}}%
        {{hash=faf614da816c14d8c268d6fe3378f2bc}{%
           family={Prando},
           familyi={P\bibinitperiod},
           given={Giulia},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{76084bb0bf5a4c28f09a3ece69513a2b}
      \strng{fullhash}{76084bb0bf5a4c28f09a3ece69513a2b}
      \strng{bibnamehash}{76084bb0bf5a4c28f09a3ece69513a2b}
      \strng{authorbibnamehash}{76084bb0bf5a4c28f09a3ece69513a2b}
      \strng{authornamehash}{76084bb0bf5a4c28f09a3ece69513a2b}
      \strng{authorfullhash}{76084bb0bf5a4c28f09a3ece69513a2b}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We investigate the task of estimating the conditional average causal effect of treatment-dosage pairs from a combination of observational data and assumptions on the causal relationships in the underlying system. This has been a longstanding challenge for fields of study such as epidemiology or economics that require a treatment-dosage pair to make decisions but may not be able to run randomized trials to precisely quantify their effect and heterogeneity across individuals. In this paper, we extend (Shalit et al, 2017) to give new bounds on the counterfactual generalization error in the context of a continuous dosage parameter which relies on a different approach to defining counterfactuals and assignment bias adjustment. This result then guides the definition of new learning objectives that can be used to train representation learning algorithms for which we show empirically new state-of-the-art performance results across several benchmark datasets for this problem, including in comparison to doubly-robust estimation methods.}
      \field{journaltitle}{{arXiv preprint}}
      \field{title}{{Generalization bounds and algorithms for estimating conditional average treatment effect of dosage}}
      \field{volume}{arXiv:2205.14692}
      \field{year}{2022}
      \verb{file}
      \verb 2205.14692:Attachments/2205.14692.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/pdf/2205.14692v1
      \endverb
      \verb{url}
      \verb http://arxiv.org/pdf/2205.14692v1
      \endverb
      \keyw{Computer Science - Learning}
    \endentry
    \entry{Bennett.2020}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=ce06b176cf03957a91d812c1a41e9e90}{%
           family={Bennett},
           familyi={B\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
        {{hash=2db96cc54afe3fe8c684be53af54a7bf}{%
           family={Kallus},
           familyi={K\bibinitperiod},
           given={Nathan},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{c5846d0ff2841fc9c9bae7da3b0b1ca1}
      \strng{fullhash}{c5846d0ff2841fc9c9bae7da3b0b1ca1}
      \strng{bibnamehash}{c5846d0ff2841fc9c9bae7da3b0b1ca1}
      \strng{authorbibnamehash}{c5846d0ff2841fc9c9bae7da3b0b1ca1}
      \strng{authornamehash}{c5846d0ff2841fc9c9bae7da3b0b1ca1}
      \strng{authorfullhash}{c5846d0ff2841fc9c9bae7da3b0b1ca1}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recent work on policy learning from observational data has highlighted the importance of efficient policy evaluation and has proposed reductions to weighted (cost-sensitive) classification. But, efficient policy evaluation need not yield efficient estimation of policy parameters. We consider the estimation problem given by a weighted surrogate-loss classification reduction of policy learning with any score function, either direct, inverse-propensity weighted, or doubly robust. We show that, under a correct specification assumption, the weighted classification formulation need not be efficient for policy parameters. We draw a contrast to actual (possibly weighted) binary classification, where correct specification implies a parametric model, while for policy learning it only implies a semiparametric model. In light of this, we instead propose an estimation approach based on generalized method of moments, which is efficient for the policy parameters. We propose a particular method based on recent developments on solving moment problems using neural networks and demonstrate the efficiency and regret benefits of this method empirically.}
      \field{booktitle}{{ICML}}
      \field{title}{{Efficient policy learning from surrogate-loss classification reductions}}
      \field{year}{2020}
      \verb{file}
      \verb 2002.05153:Attachments/2002.05153.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/pdf/2002.05153v1
      \endverb
      \verb{url}
      \verb http://arxiv.org/pdf/2002.05153v1
      \endverb
      \keyw{Computer Science - Learning;Mathematics - Statistics;Statistics - Machine Learning;Statistics - Theory}
    \endentry
    \entry{Bennett.2019b}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=ce06b176cf03957a91d812c1a41e9e90}{%
           family={Bennett},
           familyi={B\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
        {{hash=2db96cc54afe3fe8c684be53af54a7bf}{%
           family={Kallus},
           familyi={K\bibinitperiod},
           given={Nathan},
           giveni={N\bibinitperiod}}}%
        {{hash=73e823955ee5c9194126b4598743a619}{%
           family={Schnabel},
           familyi={S\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{efa34f812af84a9c71232aaf9745a670}
      \strng{fullhash}{efa34f812af84a9c71232aaf9745a670}
      \strng{bibnamehash}{efa34f812af84a9c71232aaf9745a670}
      \strng{authorbibnamehash}{efa34f812af84a9c71232aaf9745a670}
      \strng{authornamehash}{efa34f812af84a9c71232aaf9745a670}
      \strng{authorfullhash}{efa34f812af84a9c71232aaf9745a670}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Instrumental variable analysis is a powerful tool for estimating causal effects when randomization or full control of confounders is not possible. The application of standard methods such as 2SLS, GMM, and more recent variants are significantly impeded when the causal effects are complex, the instruments are high-dimensional, and/or the treatment is high-dimensional. In this paper, we propose the DeepGMM algorithm to overcome this. Our algorithm is based on a new variational reformulation of GMM with optimal inverse-covariance weighting that allows us to efficiently control very many moment conditions. We further develop practical techniques for optimization and model selection that make it particularly successful in practice. Our algorithm is also computationally tractable and can handle large-scale datasets. Numerical results show our algorithm matches the performance of the best tuned methods in standard settings and continues to work in high-dimensional settings where even recent methods break.}
      \field{booktitle}{{NeurIPS}}
      \field{title}{{Deep generalized method of moments for instrumental variable analysis}}
      \field{year}{2019}
      \verb{file}
      \verb 1905.12495:Attachments/1905.12495.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/pdf/1905.12495v2
      \endverb
      \verb{url}
      \verb http://arxiv.org/pdf/1905.12495v2
      \endverb
      \keyw{Computer Science - Learning;Statistics - Machine Learning}
    \endentry
    \entry{Bica.2020c}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=dc7ee06cb0ad6c8c1fc2c4c8fa7cfb95}{%
           family={Bica},
           familyi={B\bibinitperiod},
           given={Ioana},
           giveni={I\bibinitperiod}}}%
        {{hash=dc1b699df1b7fc62600a7ab386ec0982}{%
           family={Jordon},
           familyi={J\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod}}}%
        {{hash=d44f2d413b2e6dcde01be4d1392763dd}{%
           family={{van der Schaar}},
           familyi={v\bibinitperiod},
           given={Mihaela},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{452455ffe4b6beedf96246fe057d6f0b}
      \strng{fullhash}{452455ffe4b6beedf96246fe057d6f0b}
      \strng{bibnamehash}{452455ffe4b6beedf96246fe057d6f0b}
      \strng{authorbibnamehash}{452455ffe4b6beedf96246fe057d6f0b}
      \strng{authornamehash}{452455ffe4b6beedf96246fe057d6f0b}
      \strng{authorfullhash}{452455ffe4b6beedf96246fe057d6f0b}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{While much attention has been given to the problem of estimating the effect of discrete interventions from observational data, relatively little work has been done in the setting of continuous-valued interventions, such as treatments associated with a dosage parameter. In this paper, we tackle this problem by building on a modification of the generative adversarial networks (GANs) framework. Our model, SCIGAN, is flexible and capable of simultaneously estimating counterfactual outcomes for several different continuous interventions. The key idea is to use a significantly modified GAN model to learn to generate counterfactual outcomes, which can then be used to learn an inference model, using standard supervised methods, capable of estimating these counterfactuals for a new sample. To address the challenges presented by shifting to continuous interventions, we propose a novel architecture for our discriminator - we build a hierarchical discriminator that leverages the structure of the continuous intervention setting. Moreover, we provide theoretical results to support our use of the GAN framework and of the hierarchical discriminator. In the experiments section, we introduce a new semi-synthetic data simulation for use in the continuous intervention setting and demonstrate improvements over the existing benchmark models.}
      \field{booktitle}{{NeurIPS}}
      \field{title}{{Estimating the effects of continuous-valued interventions using generative adversarial networks}}
      \field{year}{2020}
      \verb{file}
      \verb 2002.12326:Attachments/2002.12326.pdf:application/pdf;Bica, Jordon et al. 2020 - Estimating the effects of continuous-valued:Attachments/Bica, Jordon et al. 2020 - Estimating the effects of continuous-valued.pdf:application/pdf
      \endverb
      \keyw{Computer Science - Learning;Statistics - Machine Learning}
    \endentry
    \entry{Chen.2016}{article}{}
      \name{author}{3}{}{%
        {{hash=deff38b3f2a543d7745a0b04b8d1f0b8}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Guanhua},
           giveni={G\bibinitperiod}}}%
        {{hash=ce0a9ea17981f2299c47fe765bcb3837}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Donglin},
           giveni={D\bibinitperiod}}}%
        {{hash=d653dd3a37437858f943234057f10858}{%
           family={Kosorok},
           familyi={K\bibinitperiod},
           given={Michael\bibnamedelima R.},
           giveni={M\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
      }
      \strng{namehash}{97697ece45c802e0f3ee633151b46ba1}
      \strng{fullhash}{97697ece45c802e0f3ee633151b46ba1}
      \strng{bibnamehash}{97697ece45c802e0f3ee633151b46ba1}
      \strng{authorbibnamehash}{97697ece45c802e0f3ee633151b46ba1}
      \strng{authornamehash}{97697ece45c802e0f3ee633151b46ba1}
      \strng{authorfullhash}{97697ece45c802e0f3ee633151b46ba1}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In dose-finding clinical trials, it is becoming increasingly important to account for individual level heterogeneity while searching for optimal doses to ensure an optimal individualized dose rule (IDR) maximizes the expected beneficial clinical outcome for each individual. In this paper, we advocate a randomized trial design where candidate dose levels assigned to study subjects are randomly chosen from a continuous distribution within a safe range. To estimate the optimal IDR using such data, we propose an outcome weighted learning method based on a nonconvex loss function, which can be solved efficiently using a difference of convex functions algorithm. The consistency and convergence rate for the estimated IDR are derived, and its small-sample performance is evaluated via simulation studies. We demonstrate that the proposed method outperforms competing approaches. Finally, we illustrate this method using data from a cohort study for Warfarin (an anti-thrombotic drug) dosing.}
      \field{journaltitle}{{Journal of the American Statistical Association}}
      \field{number}{516}
      \field{title}{{Personalized Dose Finding Using Outcome Weighted Learning}}
      \field{volume}{111}
      \field{year}{2016}
      \field{pages}{1509\bibrangedash 1521}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1080/01621459.2016.1148611
      \endverb
      \verb{file}
      \verb Chen, Zeng et al. 2016 - Personalized Dose Finding Using Outcome:Attachments/Chen, Zeng et al. 2016 - Personalized Dose Finding Using Outcome.pdf:application/pdf
      \endverb
    \endentry
    \entry{Cochran.1974}{article}{}
      \name{author}{2}{}{%
        {{hash=f21b5f41015e98404119f2e8d70092a5}{%
           family={Cochran},
           familyi={C\bibinitperiod},
           given={W.\bibnamedelimi G.},
           giveni={W\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=49a367b6280de8a239f8bbdd573f996f}{%
           family={Rubin},
           familyi={R\bibinitperiod},
           given={Donald\bibnamedelima B.},
           giveni={D\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
      }
      \strng{namehash}{206c9783b7aaf492c35a9f55cba49adb}
      \strng{fullhash}{206c9783b7aaf492c35a9f55cba49adb}
      \strng{bibnamehash}{206c9783b7aaf492c35a9f55cba49adb}
      \strng{authorbibnamehash}{206c9783b7aaf492c35a9f55cba49adb}
      \strng{authornamehash}{206c9783b7aaf492c35a9f55cba49adb}
      \strng{authorfullhash}{206c9783b7aaf492c35a9f55cba49adb}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Abstract : This paper reviews work on the effectiveness of different methods of matched sampling and statistical adjustment, alone and in combination, in reducing bias due to confounding x-variables when comparing two populations. The adjustment methods were linear regression adjustment for x continuous and direct standardization for x categorical.}
      \field{journaltitle}{{Sankhyā: The Indian Journal of Statistics, Series A}}
      \field{title}{{Controlling bias in observational studies: A review}}
      \field{year}{1973}
      \field{pages}{417\bibrangedash 446}
      \range{pages}{30}
      \verb{file}
      \verb W. G. Cochran, D. Rubin 1974 - Controlling Bias in Observational Studies:Attachments/W. G. Cochran, D. Rubin 1974 - Controlling Bias in Observational Studies.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.semanticscholar.org/paper/Controlling-Bias-in-Observational-Studies%3A-A-Cochran-Rubin/d39f857d13044809d169e9311a228e081de5f21e
      \endverb
      \verb{url}
      \verb https://www.semanticscholar.org/paper/Controlling-Bias-in-Observational-Studies%3A-A-Cochran-Rubin/d39f857d13044809d169e9311a228e081de5f21e
      \endverb
    \endentry
    \entry{Curth.2021}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=be4caf6e3994dcbe4e11bc11c8a6a437}{%
           family={Curth},
           familyi={C\bibinitperiod},
           given={Alicia},
           giveni={A\bibinitperiod}}}%
        {{hash=f1d9a08ac4ba7614934cfadf1df256c2}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Changhee},
           giveni={C\bibinitperiod}}}%
        {{hash=d44f2d413b2e6dcde01be4d1392763dd}{%
           family={{van der Schaar}},
           familyi={v\bibinitperiod},
           given={Mihaela},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{c4ad6d8a93bd9d3e22351c8aa5080401}
      \strng{fullhash}{c4ad6d8a93bd9d3e22351c8aa5080401}
      \strng{bibnamehash}{c4ad6d8a93bd9d3e22351c8aa5080401}
      \strng{authorbibnamehash}{c4ad6d8a93bd9d3e22351c8aa5080401}
      \strng{authornamehash}{c4ad6d8a93bd9d3e22351c8aa5080401}
      \strng{authorfullhash}{c4ad6d8a93bd9d3e22351c8aa5080401}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{{NeurIPS}}
      \field{title}{{Surv{ITE}: Learning heterogeneous treatment effects from time-to-event data}}
      \field{year}{2021}
      \verb{file}
      \verb NeurIPS-2021-survite-learning-heterogeneous-treatment-effects-from-time-to-event-data-Paper:Attachments/NeurIPS-2021-survite-learning-heterogeneous-treatment-effects-from-time-to-event-data-Paper.pdf:application/pdf
      \endverb
    \endentry
    \entry{DAmour.2021}{article}{}
      \name{author}{5}{}{%
        {{hash=6feece63ac4a69ad78dcf486fd29724d}{%
           family={D'Amour},
           familyi={D\bibinitperiod},
           given={Alexander},
           giveni={A\bibinitperiod}}}%
        {{hash=284b1660e81956ee8b9e73c17795c851}{%
           family={Ding},
           familyi={D\bibinitperiod},
           given={Peng},
           giveni={P\bibinitperiod}}}%
        {{hash=bd01724f6ff8de6f73c9c78729610ea7}{%
           family={Feller},
           familyi={F\bibinitperiod},
           given={Avi},
           giveni={A\bibinitperiod}}}%
        {{hash=3e3cd2d3ab9b4af63076a908a5d6505c}{%
           family={Lei},
           familyi={L\bibinitperiod},
           given={Lihua},
           giveni={L\bibinitperiod}}}%
        {{hash=408ec2b208cc2e38d1abcb3baf2b75b0}{%
           family={Sekhon},
           familyi={S\bibinitperiod},
           given={Jasjeet},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{6c8a05e1c35fbdb18bc9253c63772a83}
      \strng{fullhash}{8a0b0b8a3d414bb2f6b472b4718c4007}
      \strng{bibnamehash}{6c8a05e1c35fbdb18bc9253c63772a83}
      \strng{authorbibnamehash}{6c8a05e1c35fbdb18bc9253c63772a83}
      \strng{authornamehash}{6c8a05e1c35fbdb18bc9253c63772a83}
      \strng{authorfullhash}{8a0b0b8a3d414bb2f6b472b4718c4007}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{03044076}
      \field{journaltitle}{{Journal of Econometrics}}
      \field{number}{2}
      \field{title}{{Overlap in observational studies with high-dimensional covariates}}
      \field{volume}{221}
      \field{year}{2021}
      \field{pages}{644\bibrangedash 654}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1016/j. jeconom.2019.10.014
      \endverb
    \endentry
    \entry{Demirer.2019}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=d3c2cc443c71254678269de10d61d61c}{%
           family={Demirer},
           familyi={D\bibinitperiod},
           given={Mert},
           giveni={M\bibinitperiod}}}%
        {{hash=342033b26b8f8c243380f2343a53e1fa}{%
           family={Syrgkanis},
           familyi={S\bibinitperiod},
           given={Vasilis},
           giveni={V\bibinitperiod}}}%
        {{hash=aaab2d46d427908668fc97c86171164b}{%
           family={Lewis},
           familyi={L\bibinitperiod},
           given={Greg},
           giveni={G\bibinitperiod}}}%
        {{hash=c75cbe2cefd1e532f636a50892605d06}{%
           family={Chernozhukov},
           familyi={C\bibinitperiod},
           given={Victor},
           giveni={V\bibinitperiod}}}%
      }
      \strng{namehash}{01033b48e49d34db843ab0957dc57127}
      \strng{fullhash}{5717655b876c051cd5dcb2c8400ded8a}
      \strng{bibnamehash}{01033b48e49d34db843ab0957dc57127}
      \strng{authorbibnamehash}{01033b48e49d34db843ab0957dc57127}
      \strng{authornamehash}{01033b48e49d34db843ab0957dc57127}
      \strng{authorfullhash}{5717655b876c051cd5dcb2c8400ded8a}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We consider off-policy evaluation and optimization with continuous action spaces. We focus on observational data where the data collection policy is unknown and needs to be estimated. We take a semi-parametric approach where the value function takes a known parametric form in the treatment, but we are agnostic on how it depends on the observed contexts. We propose a doubly robust off-policy estimate for this setting and show that off-policy optimization based on this estimate is robust to estimation errors of the policy function or the regression model. Our results also apply if the model does not satisfy our semi-parametric form, but rather we measure regret in terms of the best projection of the true value function to this functional space. Our work extends prior approaches of policy optimization from observational data that only considered discrete actions. We provide an experimental evaluation of our method in a synthetic data example motivated by optimal personalized pricing and costly resource allocation.}
      \field{booktitle}{{NeurIPS}}
      \field{title}{{Semi-Parametric Efficient Policy Learning with Continuous Actions}}
      \field{year}{2019}
      \verb{file}
      \verb Demirer, Syrgkanis et al. 24 05 2019 - Semi-Parametric Efficient Policy Learning:Attachments/Demirer, Syrgkanis et al. 24 05 2019 - Semi-Parametric Efficient Policy Learning.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/pdf/1905.10116
      \endverb
      \verb{url}
      \verb https://arxiv.org/pdf/1905.10116
      \endverb
    \endentry
    \entry{dinh2014nice}{article}{}
      \name{author}{3}{}{%
        {{hash=0976c27ff012c9556f4206afd4b48c1f}{%
           family={Dinh},
           familyi={D\bibinitperiod},
           given={Laurent},
           giveni={L\bibinitperiod}}}%
        {{hash=e7f73df1af7c68ac1fa70ee32d1da619}{%
           family={Krueger},
           familyi={K\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=40a8e4774982146adc2688546f54efb2}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Yoshua},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{fab8fbfa8fcad0ce655d99d0a578d28f}
      \strng{fullhash}{fab8fbfa8fcad0ce655d99d0a578d28f}
      \strng{bibnamehash}{fab8fbfa8fcad0ce655d99d0a578d28f}
      \strng{authorbibnamehash}{fab8fbfa8fcad0ce655d99d0a578d28f}
      \strng{authornamehash}{fab8fbfa8fcad0ce655d99d0a578d28f}
      \strng{authorfullhash}{fab8fbfa8fcad0ce655d99d0a578d28f}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{arXiv preprint arXiv:1410.8516}
      \field{title}{{NICE}: Non-linear independent components estimation}
      \field{year}{2014}
    \endentry
    \entry{dinh2017density}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=0976c27ff012c9556f4206afd4b48c1f}{%
           family={Dinh},
           familyi={D\bibinitperiod},
           given={Laurent},
           giveni={L\bibinitperiod}}}%
        {{hash=529bdf392a3471f000ce33ec88c41bd5}{%
           family={Sohl-Dickstein},
           familyi={S\bibinithyphendelim D\bibinitperiod},
           given={Jascha},
           giveni={J\bibinitperiod}}}%
        {{hash=02404a92b0be3f52ec5ac08e41c13445}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Samy},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{8dfecb9e01eaa912afc81a7b63975730}
      \strng{fullhash}{8dfecb9e01eaa912afc81a7b63975730}
      \strng{bibnamehash}{8dfecb9e01eaa912afc81a7b63975730}
      \strng{authorbibnamehash}{8dfecb9e01eaa912afc81a7b63975730}
      \strng{authornamehash}{8dfecb9e01eaa912afc81a7b63975730}
      \strng{authorfullhash}{8dfecb9e01eaa912afc81a7b63975730}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{International Conference on Learning Representations}
      \field{title}{Density estimation using Real {NVP}}
      \field{year}{2017}
    \endentry
    \entry{dolatabadi2020invertible}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=d431a288485055916b50fc05d849bf87}{%
           family={Dolatabadi},
           familyi={D\bibinitperiod},
           given={Hadi\bibnamedelima Mohaghegh},
           giveni={H\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=46ddea762ec834251f2c41d5a138541c}{%
           family={Erfani},
           familyi={E\bibinitperiod},
           given={Sarah},
           giveni={S\bibinitperiod}}}%
        {{hash=ca68b3ca9b0efe6a415326392e0e8920}{%
           family={Leckie},
           familyi={L\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{7c174c5f7e457896a27cb83adfe8c620}
      \strng{fullhash}{7c174c5f7e457896a27cb83adfe8c620}
      \strng{bibnamehash}{7c174c5f7e457896a27cb83adfe8c620}
      \strng{authorbibnamehash}{7c174c5f7e457896a27cb83adfe8c620}
      \strng{authornamehash}{7c174c5f7e457896a27cb83adfe8c620}
      \strng{authorfullhash}{7c174c5f7e457896a27cb83adfe8c620}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{AISTATS}
      \field{title}{Invertible generative modeling using linear rational splines}
      \field{year}{2020}
    \endentry
    \entry{Dudik.2014}{article}{}
      \name{author}{4}{}{%
        {{hash=f22170ade97bd945149242679a0c806c}{%
           family={Dudík},
           familyi={D\bibinitperiod},
           given={Miroslav},
           giveni={M\bibinitperiod}}}%
        {{hash=8bbc4c5d96f205bada839e74e0202146}{%
           family={Erhan},
           familyi={E\bibinitperiod},
           given={Dumitru},
           giveni={D\bibinitperiod}}}%
        {{hash=3b32f20ce03981cb315259a6fd0a3068}{%
           family={Langford},
           familyi={L\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod}}}%
        {{hash=09b19a7bef3ca63e5cf4af03d2b00ea0}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Lihong},
           giveni={L\bibinitperiod}}}%
      }
      \strng{namehash}{8048d1f8fa6b1f370b0e223ffb797df9}
      \strng{fullhash}{60b285078844d259afff4a8bbffcd7d5}
      \strng{bibnamehash}{8048d1f8fa6b1f370b0e223ffb797df9}
      \strng{authorbibnamehash}{8048d1f8fa6b1f370b0e223ffb797df9}
      \strng{authornamehash}{8048d1f8fa6b1f370b0e223ffb797df9}
      \strng{authorfullhash}{60b285078844d259afff4a8bbffcd7d5}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We study sequential decision making in environments where rewards are only partially observed, but can be modeled as a function of observed contexts and the chosen action by the decision maker. This setting, known as contextual bandits, encompasses a wide variety of applications such as health care, content recommendation and Internet advertising. A central task is evaluation of a new policy given historic data consisting of contexts, actions and received rewards. The key challenge is that the past data typically does not faithfully represent proportions of actions taken by a new policy. Previous approaches rely either on models of rewards or models of the past policy. The former are plagued by a large bias whereas the latter have a large variance. In this work, we leverage the strengths and overcome the weaknesses of the two approaches by applying the doubly robust estimation technique to the problems of policy evaluation and optimization. We prove that this approach yields accurate value estimates when we have either a good (but not necessarily consistent) model of rewards or a good (but not necessarily consistent) model of past policy. Extensive empirical comparison demonstrates that the doubly robust estimation uniformly improves over existing techniques, achieving both lower variance in value estimation and better policies. As such, we expect the doubly robust approach to become common practice in policy evaluation and optimization.}
      \field{issn}{0883-4237}
      \field{journaltitle}{{Statistical Science}}
      \field{number}{4}
      \field{title}{{Doubly Robust Policy Evaluation and Optimization}}
      \field{volume}{29}
      \field{year}{2014}
      \verb{doi}
      \verb 10.1214/14- STS500
      \endverb
      \verb{file}
      \verb Dud{\'i}k, Erhan et al. 2014 - Doubly Robust Policy Evaluation:Attachments/Dud{\'i}k, Erhan et al. 2014 - Doubly Robust Policy Evaluation.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/pdf/1503.02834
      \endverb
      \verb{url}
      \verb https://arxiv.org/pdf/1503.02834
      \endverb
    \endentry
    \entry{durkan2019neural}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=08439cf1d9cfff317a25afa9fd3255ac}{%
           family={Durkan},
           familyi={D\bibinitperiod},
           given={Conor},
           giveni={C\bibinitperiod}}}%
        {{hash=98ff4693d66d28b3d46026e325e7d15d}{%
           family={Bekasov},
           familyi={B\bibinitperiod},
           given={Artur},
           giveni={A\bibinitperiod}}}%
        {{hash=237c383069f29d1d1ffe672359e89d38}{%
           family={Murray},
           familyi={M\bibinitperiod},
           given={Iain},
           giveni={I\bibinitperiod}}}%
        {{hash=eab39f18cad46e4abd05bb4d62b340cd}{%
           family={Papamakarios},
           familyi={P\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{d4be1a98b18d2d2bf154c23218ea59b7}
      \strng{fullhash}{03ae148b2160762bb2d3453fd6555a99}
      \strng{bibnamehash}{d4be1a98b18d2d2bf154c23218ea59b7}
      \strng{authorbibnamehash}{d4be1a98b18d2d2bf154c23218ea59b7}
      \strng{authornamehash}{d4be1a98b18d2d2bf154c23218ea59b7}
      \strng{authorfullhash}{03ae148b2160762bb2d3453fd6555a99}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{NeurIPS}
      \field{title}{Neural spline flows}
      \field{year}{2019}
    \endentry
    \entry{Fisusi.2019}{article}{}
      \name{author}{2}{}{%
        {{hash=26137acd5a930da08f39888d5614f5bc}{%
           family={Fisusi},
           familyi={F\bibinitperiod},
           given={Funmilola\bibnamedelima A.},
           giveni={F\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=de3395ec234821eb81748dc1a849759c}{%
           family={Akala},
           familyi={A\bibinitperiod},
           given={Emmanuel\bibnamedelima O.},
           giveni={E\bibinitperiod\bibinitdelim O\bibinitperiod}}}%
      }
      \strng{namehash}{9cd65a04906e84f0472c415b87dce35a}
      \strng{fullhash}{9cd65a04906e84f0472c415b87dce35a}
      \strng{bibnamehash}{9cd65a04906e84f0472c415b87dce35a}
      \strng{authorbibnamehash}{9cd65a04906e84f0472c415b87dce35a}
      \strng{authornamehash}{9cd65a04906e84f0472c415b87dce35a}
      \strng{authorfullhash}{9cd65a04906e84f0472c415b87dce35a}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Breast cancer therapy involves a multidisciplinary approach comprising surgery, radiotherapy, neoadjuvant and adjuvant therapy. Effective therapy of breast cancer requires maximum therapeutic efficacy, with minimal undesirable effects to ensure a good quality of life for patients. The carefully selected combination of therapeutic interventions provides patients with the opportunity to derive maximum benefit from therapy while minimizing or eliminating recurrence, resistance and toxic effects, as well as ensuring that patients have a good quality of life. This review discusses therapeutic options for breast cancer treatments and various combinations that had been previously exploited. The review will also give an insight into the potential application of the nanotechnology platform for codelivery of therapeutics in breast cancer therapy.}
      \field{journaltitle}{{Pharmaceutical Nanotechnology}}
      \field{number}{1}
      \field{title}{{Drug combinations in breast cancer therapy}}
      \field{volume}{7}
      \field{year}{2019}
      \field{pages}{3\bibrangedash 23}
      \range{pages}{21}
      \verb{doi}
      \verb 10.2174/2211738507666190122111224
      \endverb
      \verb{file}
      \verb Fisusi, Akala 2019 - Drug Combinations in Breast Cancer:Attachments/Fisusi, Akala 2019 - Drug Combinations in Breast Cancer.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6691849/
      \endverb
      \verb{url}
      \verb https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6691849/
      \endverb
    \endentry
    \entry{Foster.2019}{article}{}
      \name{author}{2}{}{%
        {{hash=e1895c37408f04506a1f802c2de87b02}{%
           family={Foster},
           familyi={F\bibinitperiod},
           given={Dylan\bibnamedelima J.},
           giveni={D\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=342033b26b8f8c243380f2343a53e1fa}{%
           family={Syrgkanis},
           familyi={S\bibinitperiod},
           given={Vasilis},
           giveni={V\bibinitperiod}}}%
      }
      \strng{namehash}{04b451ddeaa99a759c259aca6cdbc7d6}
      \strng{fullhash}{04b451ddeaa99a759c259aca6cdbc7d6}
      \strng{bibnamehash}{04b451ddeaa99a759c259aca6cdbc7d6}
      \strng{authorbibnamehash}{04b451ddeaa99a759c259aca6cdbc7d6}
      \strng{authornamehash}{04b451ddeaa99a759c259aca6cdbc7d6}
      \strng{authorfullhash}{04b451ddeaa99a759c259aca6cdbc7d6}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We provide non-asymptotic excess risk guarantees for statistical learning in a setting where the population risk with respect to which we evaluate the target parameter depends on an unknown nuisance parameter that must be estimated from data. We analyze a two-stage sample splitting meta-algorithm that takes as input two arbitrary estimation algorithms: one for the target parameter and one for the nuisance parameter. We show that if the population risk satisfies a condition called Neyman orthogonality, the impact of the nuisance estimation error on the excess risk bound achieved by the meta-algorithm is of second order. Our theorem is agnostic to the particular algorithms used for the target and nuisance and only makes an assumption on their individual performance. This enables the use of a plethora of existing results from statistical learning and machine learning to give new guarantees for learning with a nuisance component. Moreover, by focusing on excess risk rather than parameter estimation, we can give guarantees under weaker assumptions than in previous works and accommodate settings in which the target parameter belongs to a complex nonparametric class. We provide conditions on the metric entropy of the nuisance and target classes such that oracle rates---rates of the same order as if we knew the nuisance parameter---are achieved. We also derive new rates for specific estimation algorithms such as variance-penalized empirical risk minimization, neural network estimation and sparse high-dimensional linear model estimation. We highlight the applicability of our results in four settings of central importance: 1) heterogeneous treatment effect estimation, 2) offline policy optimization, 3) domain adaptation, and 4) learning with missing data.}
      \field{journaltitle}{{arXiv preprint}}
      \field{title}{{Orthogonal statistical learning}}
      \field{volume}{arXiv:1901.09036}
      \field{year}{2019}
      \verb{file}
      \verb Foster, Syrgkanis 25.01.2019 - Orthogonal Statistical Learning:Attachments/Foster, Syrgkanis 25.01.2019 - Orthogonal Statistical Learning.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/pdf/1901.09036v3
      \endverb
      \verb{url}
      \verb http://arxiv.org/pdf/1901.09036v3
      \endverb
    \endentry
    \entry{Frauen.2023}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=3b64fc0fa23681b890b424e43960e051}{%
           family={Frauen},
           familyi={F\bibinitperiod},
           given={Dennis},
           giveni={D\bibinitperiod}}}%
        {{hash=31caa17115fb0437a5cce78c102b1058}{%
           family={Hatt},
           familyi={H\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
        {{hash=39196972594bfb6c0ffb951c333ee25c}{%
           family={Melnychuk},
           familyi={M\bibinitperiod},
           given={Valentyn},
           giveni={V\bibinitperiod}}}%
        {{hash=d276dae900e4bb8a8a125633e0277484}{%
           family={Feuerriegel},
           familyi={F\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{e9709a2a487212e3098418321f69af17}
      \strng{fullhash}{9aa8dabd05425cba6c7cec5c966659fb}
      \strng{bibnamehash}{e9709a2a487212e3098418321f69af17}
      \strng{authorbibnamehash}{e9709a2a487212e3098418321f69af17}
      \strng{authornamehash}{e9709a2a487212e3098418321f69af17}
      \strng{authorfullhash}{9aa8dabd05425cba6c7cec5c966659fb}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In medical practice, treatments are selected based on the expected causal effects on patient outcomes. Here, the gold standard for estimating causal effects are randomized controlled trials; however, such trials are costly and sometimes even unethical. Instead, medical practice is increasingly interested in estimating causal effects among patient subgroups from electronic health records, that is, observational data. In this paper, we aim at estimating the average causal effect (ACE) from observational data (patient trajectories) that are collected over time. For this, we propose DeepACE: an end-to-end deep learning model. DeepACE leverages the iterative G-computation formula to adjust for the bias induced by time-varying confounders. Moreover, we develop a novel sequential targeting procedure which ensures that DeepACE has favorable theoretical properties, i.e., is doubly robust and asymptotically efficient. To the best of our knowledge, this is the first work that proposes an end-to-end deep learning model for estimating time-varying ACEs. We compare DeepACE in an extensive number of experiments, confirming that it achieves state-of-the-art performance. We further provide a case study for patients suffering from low back pain to demonstrate that DeepACE generates important and meaningful findings for clinical practice. Our work enables medical practitioners to develop effective treatment recommendations tailored to patient subgroups.}
      \field{booktitle}{{AAAI}}
      \field{title}{{Estimating average causal effects from patient trajectories}}
      \field{year}{2023}
      \verb{file}
      \verb Frauen, Hatt et al. 02.03.2022 - Estimating average causal effects:Attachments/Frauen, Hatt et al. 02.03.2022 - Estimating average causal effects.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb ´
      \endverb
      \verb{url}
      \verb %C2%B4
      \endverb
    \endentry
    \entry{fujimoto2019off}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=064fb8795fb3fe6537e4d29fc8578ec4}{%
           family={Fujimoto},
           familyi={F\bibinitperiod},
           given={Scott},
           giveni={S\bibinitperiod}}}%
        {{hash=a5137015bf373eff6cd1b6a96b145c3c}{%
           family={Meger},
           familyi={M\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=4428b76e1301b2db58587fb18bb59a38}{%
           family={Precup},
           familyi={P\bibinitperiod},
           given={Doina},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{04b40842280a3beaadf77bdf09453160}
      \strng{fullhash}{04b40842280a3beaadf77bdf09453160}
      \strng{bibnamehash}{04b40842280a3beaadf77bdf09453160}
      \strng{authorbibnamehash}{04b40842280a3beaadf77bdf09453160}
      \strng{authornamehash}{04b40842280a3beaadf77bdf09453160}
      \strng{authorfullhash}{04b40842280a3beaadf77bdf09453160}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{ICML}
      \field{title}{Off-policy deep reinforcement learning without exploration}
      \field{year}{2019}
    \endentry
    \entry{Grasselli.2021}{article}{}
      \name{author}{9}{}{%
        {{hash=0cd49c2f1103957230551e345b487120}{%
           family={Grasselli},
           familyi={G\bibinitperiod},
           given={Giacomo},
           giveni={G\bibinitperiod}}}%
        {{hash=656e4c4e49f02c83a411e087773fb7c5}{%
           family={Cattaneo},
           familyi={C\bibinitperiod},
           given={Emanuele},
           giveni={E\bibinitperiod}}}%
        {{hash=6ad0da081a43190c02e1eea3d9474ce2}{%
           family={Florio},
           familyi={F\bibinitperiod},
           given={Gaetano},
           giveni={G\bibinitperiod}}}%
        {{hash=2a0a28dc4c6c327978abcab47c35ff45}{%
           family={Ippolito},
           familyi={I\bibinitperiod},
           given={Mariachiara},
           giveni={M\bibinitperiod}}}%
        {{hash=b79b599b6f34378244c7fce0825c4fb5}{%
           family={Zanella},
           familyi={Z\bibinitperiod},
           given={Alberto},
           giveni={A\bibinitperiod}}}%
        {{hash=54445b1d5ad99165295c2c8313fcd26c}{%
           family={Cortegiani},
           familyi={C\bibinitperiod},
           given={Andrea},
           giveni={A\bibinitperiod}}}%
        {{hash=81cefec6b1a1f5b7e53428a0989ed3f5}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Jianbo},
           giveni={J\bibinitperiod}}}%
        {{hash=4a063293fef22a3d0a097dca2f69a572}{%
           family={Pesenti},
           familyi={P\bibinitperiod},
           given={Antonio},
           giveni={A\bibinitperiod}}}%
        {{hash=70f0da0d80d4c1ce2fef97d1b47a97f3}{%
           family={Einav},
           familyi={E\bibinitperiod},
           given={Sharon},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{5618415ea2b6203e30147bad93a93428}
      \strng{fullhash}{6851cb3a7cd979d93d94977e32333cee}
      \strng{bibnamehash}{5618415ea2b6203e30147bad93a93428}
      \strng{authorbibnamehash}{5618415ea2b6203e30147bad93a93428}
      \strng{authornamehash}{5618415ea2b6203e30147bad93a93428}
      \strng{authorfullhash}{6851cb3a7cd979d93d94977e32333cee}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{BACKGROUND The mortality of critically ill patients with COVID-19 is high, particularly among those receiving mechanical ventilation (MV). Despite the high number of patients treated worldwide, data on respiratory mechanics are currently scarce and the optimal setting of MV remains to be defined. This scoping review aims to provide an overview of available data about respiratory mechanics, gas exchange and MV settings in patients admitted to intensive care units (ICUs) for COVID-19-associated acute respiratory failure, and to identify knowledge gaps. MAIN TEXT PubMed, EMBASE, and MEDLINE databases were searched from inception to October 30, 2020 for studies providing at least one ventilatory parameter collected within 24~h from the ICU admission. The quality of the studies was independently assessed using the Newcastle-Ottawa Quality Assessment Form for Cohort Studies. A total of 26 studies were included for a total of 14,075 patients. At ICU admission, positive end expiratory pressure (PEEP) values ranged from 9 to 16.5~cm of water (cmH2O), suggesting that high levels of PEEP were commonly used for setting MV for these patients. Patients with COVID-19 are severely hypoxemic at ICU admission and show a median ratio of partial pressure of arterial oxygen to fraction of inspired oxygen (PaO2/FiO2) ranging from 102 to 198~mmHg. Static respiratory system compliance (Crs) values at ICU admission were highly heterogenous, ranging between 24 and 49~ml/cmH2O. Prone positioning and neuromuscular blocking agents were widely used, ranging from 17 to 81 and 22 to 88{\%}, respectively; both rates were higher than previously reported in patients with {"}classical{"} acute respiratory distress syndrome (ARDS). CONCLUSIONS Available data show that, in mechanically ventilated patients with COVID-19, respiratory mechanics and MV settings within 24~h from ICU admission are heterogeneous but similar to those reported for {"}classical{"} ARDS. However, to date, complete data regarding mechanical properties of respiratory system, optimal setting of MV and the role of rescue treatments for refractory hypoxemia are still lacking in the medical literature.}
      \field{issn}{1466-609X}
      \field{journaltitle}{{Critical Care}}
      \field{number}{1}
      \field{title}{{Mechanical ventilation parameters in critically ill COVID-19 patients: a scoping review}}
      \field{volume}{25}
      \field{year}{2021}
      \field{pages}{115}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1186/s13054-021-03536-2
      \endverb
      \verb{file}
      \verb Grasselli, Cattaneo et al. 2021 - Mechanical ventilation parameters in critically:Attachments/Grasselli, Cattaneo et al. 2021 - Mechanical ventilation parameters in critically.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://pubmed.ncbi.nlm.nih.gov/33743812/
      \endverb
      \verb{url}
      \verb https://pubmed.ncbi.nlm.nih.gov/33743812/
      \endverb
    \endentry
    \entry{Harada.2021}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=9f929c51afec113f25eea058050b4bde}{%
           family={Harada},
           familyi={H\bibinitperiod},
           given={Shonosuke},
           giveni={S\bibinitperiod}}}%
        {{hash=32fc6ae468e6012f7822868c12d9c044}{%
           family={Kashima},
           familyi={K\bibinitperiod},
           given={Hisashi},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{da460832a2ba8464b34d148b3e20a07f}
      \strng{fullhash}{da460832a2ba8464b34d148b3e20a07f}
      \strng{bibnamehash}{da460832a2ba8464b34d148b3e20a07f}
      \strng{authorbibnamehash}{da460832a2ba8464b34d148b3e20a07f}
      \strng{authornamehash}{da460832a2ba8464b34d148b3e20a07f}
      \strng{authorfullhash}{da460832a2ba8464b34d148b3e20a07f}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Outcome estimation of treatments for target individuals is an important foundation for decision making based on causal relations. Most existing outcome estimation methods deal with binary or multiple-choice treatments; however, in some applications, the number of treatments can be significantly large, while the treatments themselves have rich information. In this study, we considered one important instance of such cases: the outcome estimation problem of graph-structured treatments such as drugs. Owing to the large number of possible treatments, the counterfactual nature of observational data that appears in conventional treatment effect estimation becomes more of a concern for this problem. Our proposed method, GraphITE (pronounced {"}graphite{"}) learns the representations of graph-structured treatments using graph neural networks while mitigating observation biases using Hilbert-Schmidt Independence Criterion regularization, which increases the independence of the representations of the targets and treatments. Experiments on two real-world datasets show that GraphITE outperforms baselines, especially in cases with a large number of treatments.}
      \field{booktitle}{{CIKM}}
      \field{title}{{GraphITE: Estimating individual effects of graph-structured treatments}}
      \field{year}{2021}
      \verb{file}
      \verb Harada, Kashima 29 09 2020 - GraphITE Estimating Individual Effects:Attachments/Harada, Kashima 29 09 2020 - GraphITE Estimating Individual Effects.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/pdf/2009.14061
      \endverb
      \verb{url}
      \verb https://arxiv.org/pdf/2009.14061
      \endverb
    \endentry
    \entry{hassanpour2019counterfactual}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=9113310decad2b1a43178319b4681efc}{%
           family={Hassanpour},
           familyi={H\bibinitperiod},
           given={Negar},
           giveni={N\bibinitperiod}}}%
        {{hash=4a770d3fea9e460171ec3bbb23b8fceb}{%
           family={Greiner},
           familyi={G\bibinitperiod},
           given={Russell},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{db9d4788dfe9b08bd30176323d772b4f}
      \strng{fullhash}{db9d4788dfe9b08bd30176323d772b4f}
      \strng{bibnamehash}{db9d4788dfe9b08bd30176323d772b4f}
      \strng{authorbibnamehash}{db9d4788dfe9b08bd30176323d772b4f}
      \strng{authornamehash}{db9d4788dfe9b08bd30176323d772b4f}
      \strng{authorfullhash}{db9d4788dfe9b08bd30176323d772b4f}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{IJCAI}
      \field{title}{Counterfactual regression with importance sampling weights}
      \field{year}{2019}
    \endentry
    \entry{Hatt.2022b}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=31caa17115fb0437a5cce78c102b1058}{%
           family={Hatt},
           familyi={H\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
        {{hash=896d2fff81615ea74a0e4a2856da8df6}{%
           family={Tschernutter},
           familyi={T\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=d276dae900e4bb8a8a125633e0277484}{%
           family={Feuerriegel},
           familyi={F\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{2890be94186743443436a317e2c9e83f}
      \strng{fullhash}{2890be94186743443436a317e2c9e83f}
      \strng{bibnamehash}{2890be94186743443436a317e2c9e83f}
      \strng{authorbibnamehash}{2890be94186743443436a317e2c9e83f}
      \strng{authornamehash}{2890be94186743443436a317e2c9e83f}
      \strng{authorfullhash}{2890be94186743443436a317e2c9e83f}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Learning personalized decision policies that generalize to the target population is of great relevance. Since training data is often not representative of the target population, standard policy learning methods may yield policies that do not generalize target population. To address this challenge, we propose a novel framework for learning policies that generalize to the target population. For this, we characterize the difference between the training data and the target population as a sample selection bias using a selection variable. Over an uncertainty set around this selection variable, we optimize the minimax value of a policy to achieve the best worst-case policy value on the target population. In order to solve the minimax problem, we derive an efficient algorithm based on a convex-concave procedure and prove convergence for parametrized spaces of policies such as logistic policies. We prove that, if the uncertainty set is well-specified, our policies generalize to the target population as they can not do worse than on the training data. Using simulated data and a clinical trial, we demonstrate that, compared to standard policy learning methods, our framework improves the generalizability of policies substantially.}
      \field{booktitle}{{UAI}}
      \field{title}{{Generalizing off-policy learning under sample selection bias}}
      \field{year}{2022}
      \verb{file}
      \verb 2112.01387:Attachments/2112.01387.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/pdf/2112.01387v1
      \endverb
      \verb{url}
      \verb http://arxiv.org/pdf/2112.01387v1
      \endverb
      \keyw{Computer Science - Learning;Statistics - Machine Learning}
    \endentry
    \entry{Heckman.1997}{article}{}
      \name{author}{3}{}{%
        {{hash=31a1496cdbf5dc77b32758042c61ba9c}{%
           family={Heckman},
           familyi={H\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod}}}%
        {{hash=d0d261351e2d86ceaf41d62b7d7308f9}{%
           family={Ichimura},
           familyi={I\bibinitperiod},
           given={Hidehiko.},
           giveni={H\bibinitperiod}}}%
        {{hash=24654531fff06b35dca1039b558200e8}{%
           family={Todd},
           familyi={T\bibinitperiod},
           given={Petra.},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{746e2f80eb7e9df43c67d1ac4155cdff}
      \strng{fullhash}{746e2f80eb7e9df43c67d1ac4155cdff}
      \strng{bibnamehash}{746e2f80eb7e9df43c67d1ac4155cdff}
      \strng{authorbibnamehash}{746e2f80eb7e9df43c67d1ac4155cdff}
      \strng{authornamehash}{746e2f80eb7e9df43c67d1ac4155cdff}
      \strng{authorfullhash}{746e2f80eb7e9df43c67d1ac4155cdff}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Abstract. This paper considers whether it is possible to devise a nonexperimental procedure for evaluating a prototypical job training programme. Using rich non}
      \field{issn}{0034-6527}
      \field{journaltitle}{{The Review of Economic Studies}}
      \field{number}{4}
      \field{title}{{Matching As An Econometric Evaluation Estimator: Evidence from Evaluating a Job Training Programme}}
      \field{volume}{64}
      \field{year}{1997}
      \field{pages}{605\bibrangedash 654}
      \range{pages}{50}
      \verb{doi}
      \verb 10.2307/2971733
      \endverb
      \verb{file}
      \verb Heckman, Ichimura et al. 1997 - Matching As An Econometric Evaluation:Attachments/Heckman, Ichimura et al. 1997 - Matching As An Econometric Evaluation.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://academic.oup.com/restud/article/64/4/605/1603767
      \endverb
      \verb{url}
      \verb https://academic.oup.com/restud/article/64/4/605/1603767
      \endverb
    \endentry
    \entry{hess2023bayesian}{article}{}
      \name{author}{4}{}{%
        {{hash=d5d42e66ce170bcb7f9c473a632cf6e0}{%
           family={Heß},
           familyi={H\bibinitperiod},
           given={Konstantin},
           giveni={K\bibinitperiod}}}%
        {{hash=39196972594bfb6c0ffb951c333ee25c}{%
           family={Melnychuk},
           familyi={M\bibinitperiod},
           given={Valentyn},
           giveni={V\bibinitperiod}}}%
        {{hash=3b64fc0fa23681b890b424e43960e051}{%
           family={Frauen},
           familyi={F\bibinitperiod},
           given={Dennis},
           giveni={D\bibinitperiod}}}%
        {{hash=d276dae900e4bb8a8a125633e0277484}{%
           family={Feuerriegel},
           familyi={F\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{5bd5e8242ad1c590fdc5756da8b4eedc}
      \strng{fullhash}{6231c85f56b4ef981ec2abccc1675f29}
      \strng{bibnamehash}{5bd5e8242ad1c590fdc5756da8b4eedc}
      \strng{authorbibnamehash}{5bd5e8242ad1c590fdc5756da8b4eedc}
      \strng{authornamehash}{5bd5e8242ad1c590fdc5756da8b4eedc}
      \strng{authorfullhash}{6231c85f56b4ef981ec2abccc1675f29}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{arXiv preprint}}
      \field{title}{Bayesian neural controlled differential equations for treatment effect estimation}
      \field{volume}{arXiv:2310.17463}
      \field{year}{2023}
      \verb{urlraw}
      \verb https://arxiv.org/abs/2310.17463
      \endverb
      \verb{url}
      \verb https://arxiv.org/abs/2310.17463
      \endverb
    \endentry
    \entry{Hirano.2004}{incollection}{}
      \name{author}{2}{}{%
        {{hash=cbb67bb2b3f968f74efd46fbca0bd660}{%
           family={Hirano},
           familyi={H\bibinitperiod},
           given={Keisuke},
           giveni={K\bibinitperiod}}}%
        {{hash=9f4fa8d00c0311b9cdad0f20ad429e57}{%
           family={Imbens},
           familyi={I\bibinitperiod},
           given={Guido\bibnamedelima W.},
           giveni={G\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
      }
      \strng{namehash}{8882f9384135d1afc5dbd2ef900df8ee}
      \strng{fullhash}{8882f9384135d1afc5dbd2ef900df8ee}
      \strng{bibnamehash}{8882f9384135d1afc5dbd2ef900df8ee}
      \strng{authorbibnamehash}{8882f9384135d1afc5dbd2ef900df8ee}
      \strng{authornamehash}{8882f9384135d1afc5dbd2ef900df8ee}
      \strng{authorfullhash}{8882f9384135d1afc5dbd2ef900df8ee}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{{Applied Bayesian Modeling and Causal Inference from Incomplete-Data Perspectives}}
      \field{title}{{The propensity score with continuous treatments}}
      \field{year}{2004}
    \endentry
    \entry{huang2018neural}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=e8ea5b32927bd11be26ca20a679ca632}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Chin-Wei},
           giveni={C\bibinithyphendelim W\bibinitperiod}}}%
        {{hash=e7f73df1af7c68ac1fa70ee32d1da619}{%
           family={Krueger},
           familyi={K\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=c84276698f0ba64d181bc35c48f6a2dd}{%
           family={Lacoste},
           familyi={L\bibinitperiod},
           given={Alexandre},
           giveni={A\bibinitperiod}}}%
        {{hash=ccec1ccd2e1aa86960eb2e872c6b7020}{%
           family={Courville},
           familyi={C\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{dae603ea89aa2089b202f4bf91d7d7c8}
      \strng{fullhash}{f8c184ce877a527a108117d7118ba839}
      \strng{bibnamehash}{dae603ea89aa2089b202f4bf91d7d7c8}
      \strng{authorbibnamehash}{dae603ea89aa2089b202f4bf91d7d7c8}
      \strng{authornamehash}{dae603ea89aa2089b202f4bf91d7d7c8}
      \strng{authorfullhash}{f8c184ce877a527a108117d7118ba839}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{International Conference on Machine Learning}
      \field{title}{Neural autoregressive flows}
      \field{year}{2018}
    \endentry
    \entry{Imai.2004}{article}{}
      \name{author}{2}{}{%
        {{hash=3fb69a8c942c769b74775b484c82bbe9}{%
           family={Imai},
           familyi={I\bibinitperiod},
           given={Kosuke},
           giveni={K\bibinitperiod}}}%
        {{hash=019c25387f597473880d5c2d244e17f2}{%
           family={{van Dyk}},
           familyi={v\bibinitperiod},
           given={David\bibnamedelima A.},
           giveni={D\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
      }
      \strng{namehash}{87403704b70ea981663b618dd34e036b}
      \strng{fullhash}{87403704b70ea981663b618dd34e036b}
      \strng{bibnamehash}{87403704b70ea981663b618dd34e036b}
      \strng{authorbibnamehash}{87403704b70ea981663b618dd34e036b}
      \strng{authornamehash}{87403704b70ea981663b618dd34e036b}
      \strng{authorfullhash}{87403704b70ea981663b618dd34e036b}
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this article we develop the theoretical properties of the propensity function, which is a generalization of the propensity score of Rosenbaum and Rubin. Methods based on the propensity score have long been used for causal inference in observational studies; they are easy to use and can effectively reduce the bias caused by nonrandom treatment assignment. Although treatment regimes need not be binary in practice, the propensity score methods are generally confined to binary treatment scenarios. Two possible exceptions have been suggested for ordinal and categorical treatments. In this article we develop theory and methods that encompass all of these techniques and widen their applicability by allowing for arbitrary treatment regimes. We illustrate our propensity function methods by applying them to two datasets; we estimate the effect of smoking on medical expenditure and the effect of schooling on wages. We also conduct simulation studies to investigate the performance of our methods.}
      \field{journaltitle}{{Journal of the American Statistical Association}}
      \field{number}{467}
      \field{title}{{Causal inference with general treatment regimes}}
      \field{volume}{99}
      \field{year}{2004}
      \field{pages}{854\bibrangedash 866}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1198/016214504000001187
      \endverb
    \endentry
    \entry{Imbens.2000}{article}{}
      \name{author}{1}{}{%
        {{hash=db531792b2ef0cf92c00b056b0a5da1a}{%
           family={Imbens},
           familyi={I\bibinitperiod},
           given={G.},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{db531792b2ef0cf92c00b056b0a5da1a}
      \strng{fullhash}{db531792b2ef0cf92c00b056b0a5da1a}
      \strng{bibnamehash}{db531792b2ef0cf92c00b056b0a5da1a}
      \strng{authorbibnamehash}{db531792b2ef0cf92c00b056b0a5da1a}
      \strng{authornamehash}{db531792b2ef0cf92c00b056b0a5da1a}
      \strng{authorfullhash}{db531792b2ef0cf92c00b056b0a5da1a}
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Abstract. Estimation of average treatment effects in observational studies often requires adjustment for differences in pre-treatment variables. If the number o}
      \field{issn}{0006-3444}
      \field{journaltitle}{{Biometrika}}
      \field{number}{3}
      \field{title}{{The role of the propensity score in estimating dose-response functions}}
      \field{volume}{87}
      \field{year}{2000}
      \field{pages}{706\bibrangedash 710}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1093/biomet/87.3.706
      \endverb
      \verb{file}
      \verb Imbens 2000 - The role of the propensity:Attachments/Imbens 2000 - The role of the propensity.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://academic.oup.com/biomet/article/87/3/706/293734
      \endverb
      \verb{url}
      \verb https://academic.oup.com/biomet/article/87/3/706/293734
      \endverb
    \endentry
    \entry{Ionides.2008}{article}{}
      \name{author}{1}{}{%
        {{hash=c2862ccddb08f912fe8f1f5917d5a6f5}{%
           family={Ionides},
           familyi={I\bibinitperiod},
           given={Edward\bibnamedelima L.},
           giveni={E\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
      }
      \strng{namehash}{c2862ccddb08f912fe8f1f5917d5a6f5}
      \strng{fullhash}{c2862ccddb08f912fe8f1f5917d5a6f5}
      \strng{bibnamehash}{c2862ccddb08f912fe8f1f5917d5a6f5}
      \strng{authorbibnamehash}{c2862ccddb08f912fe8f1f5917d5a6f5}
      \strng{authornamehash}{c2862ccddb08f912fe8f1f5917d5a6f5}
      \strng{authorfullhash}{c2862ccddb08f912fe8f1f5917d5a6f5}
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Importance sampling is a fundamental Monte Carlo technique. It involves generating a sample from a proposal distribution in order to estimate some property of a target distribution. Importance sampling can be highly sensitive to the choice of proposal distribution, and fails if the proposal distribution does not sufficiently well approximate the target. Procedures that involve truncation of large importance sampling weights are shown theoretically to improve on standard importance sampling by being less sensitive to the proposal distribution and having lower mean squared estimation error.Consistency is shown under weak conditions, and optimal truncation rates found under more specific conditions. Truncation at rate n1/2 is shown to be a good general choice. An adaptive truncation threshold, based on minimizing an unbiased risk estimate, is also presented. As an example, truncation is found to be effective for calculating the likelihood of partially observed multivariate diffusions. It is demonstrated as a component of a sequential importance sampling scheme for a continuous time population disease model. Truncation is most valuable for computationally intensive, multidimensional situations in which finding a proposal distribution that is everywhere a good approximation to the target distribution is challenging.}
      \field{issn}{1061-8600}
      \field{journaltitle}{{Journal of Computational and Graphical Statistics}}
      \field{number}{2}
      \field{title}{{Truncated Importance Sampling}}
      \field{volume}{17}
      \field{year}{2008}
      \field{pages}{295\bibrangedash 311}
      \range{pages}{17}
      \verb{doi}
      \verb 10.1198/106186008X320456
      \endverb
      \verb{file}
      \verb Ionides 2008 - Truncated Importance Sampling:Attachments/Ionides 2008 - Truncated Importance Sampling.pdf:application/pdf
      \endverb
    \endentry
    \entry{Jesson.2020}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=348c1b1b317f5fd0c0931b6b962db45c}{%
           family={Jesson},
           familyi={J\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
        {{hash=f956cfff5f91902bb7611d217dee7fe3}{%
           family={Mindermann},
           familyi={M\bibinitperiod},
           given={Sören},
           giveni={S\bibinitperiod}}}%
        {{hash=c39ea9ea2b55e1753c555a453a610aec}{%
           family={Shalit},
           familyi={S\bibinitperiod},
           given={Uri},
           giveni={U\bibinitperiod}}}%
        {{hash=d4f394bd4030e20e7b1399e0abe7dc6a}{%
           family={Gal},
           familyi={G\bibinitperiod},
           given={Yarin},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{489213ea994b011660f31bd0e177d369}
      \strng{fullhash}{f04dddf010d455ccd19f61744544e876}
      \strng{bibnamehash}{489213ea994b011660f31bd0e177d369}
      \strng{authorbibnamehash}{489213ea994b011660f31bd0e177d369}
      \strng{authornamehash}{489213ea994b011660f31bd0e177d369}
      \strng{authorfullhash}{f04dddf010d455ccd19f61744544e876}
      \field{extraname}{1}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recommending the best course of action for an individual is a major application of individual-level causal effect estimation. This application is often needed in safety-critical domains such as healthcare, where estimating and communicating uncertainty to decision-makers is crucial. We introduce a practical approach for integrating uncertainty estimation into a class of state-of-the-art neural network methods used for individual-level causal estimates. We show that our methods enable us to deal gracefully with situations of {"}no-overlap{"}, common in high-dimensional data, where standard applications of causal effect approaches fail. Further, our methods allow us to handle covariate shift, where test distribution differs to train distribution, common when systems are deployed in practice. We show that when such a covariate shift occurs, correctly modeling uncertainty can keep us from giving overconfident and potentially harmful recommendations. We demonstrate our methodology with a range of state-of-the-art models. Under both covariate shift and lack of overlap, our uncertainty-equipped methods can alert decisions makers when predictions are not to be trusted while outperforming their uncertainty-oblivious counterparts.}
      \field{booktitle}{{NeurIPS}}
      \field{title}{{Identifying causal-effect inference failure with uncertainty-aware models}}
      \field{year}{2020}
      \verb{file}
      \verb Jesson, Mindermann et al. 01 07 2020 - Identifying Causal-Effect Inference Failure:Attachments/Jesson, Mindermann et al. 01 07 2020 - Identifying Causal-Effect Inference Failure.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/pdf/2007.00163
      \endverb
      \verb{url}
      \verb https://arxiv.org/pdf/2007.00163
      \endverb
    \endentry
    \entry{Jesson.2022}{inproceedings}{}
      \name{author}{7}{}{%
        {{hash=348c1b1b317f5fd0c0931b6b962db45c}{%
           family={Jesson},
           familyi={J\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod}}}%
        {{hash=0b7648f051095c4ee3dd89b87187b724}{%
           family={Douglas},
           familyi={D\bibinitperiod},
           given={Alyson},
           giveni={A\bibinitperiod}}}%
        {{hash=11aa2877395925958b5d800997588313}{%
           family={Manshausen},
           familyi={M\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod}}}%
        {{hash=ab9469dddb5d18ec039f709e2d7c4e00}{%
           family={Meinshausen},
           familyi={M\bibinitperiod},
           given={Nicolai},
           giveni={N\bibinitperiod}}}%
        {{hash=224f5d8ec228fd6672f933c9f8712be5}{%
           family={Stier},
           familyi={S\bibinitperiod},
           given={Philip},
           giveni={P\bibinitperiod}}}%
        {{hash=d4f394bd4030e20e7b1399e0abe7dc6a}{%
           family={Gal},
           familyi={G\bibinitperiod},
           given={Yarin},
           giveni={Y\bibinitperiod}}}%
        {{hash=c39ea9ea2b55e1753c555a453a610aec}{%
           family={Shalit},
           familyi={S\bibinitperiod},
           given={Uri},
           giveni={U\bibinitperiod}}}%
      }
      \strng{namehash}{489213ea994b011660f31bd0e177d369}
      \strng{fullhash}{adc214e6c9f3311fa0f51675e5d3aad4}
      \strng{bibnamehash}{489213ea994b011660f31bd0e177d369}
      \strng{authorbibnamehash}{489213ea994b011660f31bd0e177d369}
      \strng{authornamehash}{489213ea994b011660f31bd0e177d369}
      \strng{authorfullhash}{adc214e6c9f3311fa0f51675e5d3aad4}
      \field{extraname}{2}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Estimating the effects of continuous-valued interventions from observational data is critically important in fields such as climate science, healthcare, and economics. Recent work focuses on designing neural-network architectures and regularization functions to allow for scalable estimation of average and individual-level dose response curves from high-dimensional, large-sample data. Such methodologies assume ignorability (all confounding variables are observed) and positivity (all levels of treatment can be observed for every unit described by a given covariate value), which are especially challenged in the continuous treatment regime. Developing scalable sensitivity and uncertainty analyses that allow us to understand the ignorance induced in our estimates when these assumptions are relaxed receives less attention. Here, we develop a continuous treatment-effect marginal sensitivity model (CMSM) and derive bounds that agree with both the observed data and a researcher-defined level of hidden confounding. We introduce a scalable algorithm to derive the bounds and uncertainty-aware deep models to efficiently estimate these bounds for high-dimensional, large-sample observational data. We validate our methods using both synthetic and real-world experiments. For the latter, we work in concert with climate scientists interested in evaluating the climatological impacts of human emissions on cloud properties using satellite observations from the past 15 years: a finite-data problem known to be complicated by the presence of a multitude of unobserved confounders.}
      \field{booktitle}{{NeurIPS}}
      \field{title}{{Scalable sensitivity and uncertainty analysis for causal-effect estimates of continuous-valued interventions}}
      \field{year}{2022}
      \verb{file}
      \verb 2204.10022:Attachments/2204.10022.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/pdf/2204.10022v2
      \endverb
      \verb{url}
      \verb http://arxiv.org/pdf/2204.10022v2
      \endverb
      \keyw{causal effects;Climate;Clouds;Computer Science - Learning;ICML;Machine learning;Statistics - Machine Learning}
    \endentry
    \entry{Johansson.2016}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=477c381b77493d3455836688eb1f6f74}{%
           family={Johansson},
           familyi={J\bibinitperiod},
           given={Fredrik\bibnamedelima D.},
           giveni={F\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=c39ea9ea2b55e1753c555a453a610aec}{%
           family={Shalit},
           familyi={S\bibinitperiod},
           given={Uri},
           giveni={U\bibinitperiod}}}%
        {{hash=c46f3204e0c96caa89224fef576adf76}{%
           family={Sonntag},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{f781a850ee88619aacdb34266cfe31b6}
      \strng{fullhash}{f781a850ee88619aacdb34266cfe31b6}
      \strng{bibnamehash}{f781a850ee88619aacdb34266cfe31b6}
      \strng{authorbibnamehash}{f781a850ee88619aacdb34266cfe31b6}
      \strng{authornamehash}{f781a850ee88619aacdb34266cfe31b6}
      \strng{authorfullhash}{f781a850ee88619aacdb34266cfe31b6}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Proceedings of the International Conference on Machine Learning 2016}
      \field{booktitle}{{ICML}}
      \field{title}{{Learning representations for counterfactual inference}}
      \field{year}{2016}
      \verb{file}
      \verb Learning Representations for Counterfactual Inference:Attachments/Learning Representations for Counterfactual Inference.pdf:application/pdf
      \endverb
      \keyw{causal inference;domain adaptation;representation learning}
    \endentry
    \entry{Johnson.2016}{article}{}
      \name{author}{10}{}{%
        {{hash=97ddf9ef7b3f83671aa14334972e8186}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={Alistair\bibnamedelimb E.\bibnamedelimi W.},
           giveni={A\bibinitperiod\bibinitdelim E\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{hash=b1a10559d1345954860fcb71d58d644b}{%
           family={Pollard},
           familyi={P\bibinitperiod},
           given={Tom\bibnamedelima J.},
           giveni={T\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=905fd330076c29b21add0f3e7108629d}{%
           family={Shen},
           familyi={S\bibinitperiod},
           given={Lu},
           giveni={L\bibinitperiod}}}%
        {{hash=2ea8fc75e44631dccd4c8217117062f2}{%
           family={Lehman},
           familyi={L\bibinitperiod},
           given={Li-wei\bibnamedelima H.},
           giveni={L\bibinithyphendelim w\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{hash=6aa84d1af8a9f95dddedc1677244afbe}{%
           family={Feng},
           familyi={F\bibinitperiod},
           given={Mengling},
           giveni={M\bibinitperiod}}}%
        {{hash=b576d328e9b0f4401d1363e5a30441ac}{%
           family={Ghassemi},
           familyi={G\bibinitperiod},
           given={Mohammad},
           giveni={M\bibinitperiod}}}%
        {{hash=64d84f6b7d6b1cd1b82470cd4f4661b0}{%
           family={Moody},
           familyi={M\bibinitperiod},
           given={Benjamin},
           giveni={B\bibinitperiod}}}%
        {{hash=e4ec701f3e9b3400f41c7dcb84d2e88a}{%
           family={Szolovits},
           familyi={S\bibinitperiod},
           given={Peter},
           giveni={P\bibinitperiod}}}%
        {{hash=f0e3dac1adc983d78b53e594ecb6d1dc}{%
           family={Celi},
           familyi={C\bibinitperiod},
           given={Leo\bibnamedelima Anthony},
           giveni={L\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=2193bac90baddb616fc4dcd2f366de81}{%
           family={Mark},
           familyi={M\bibinitperiod},
           given={Roger\bibnamedelima G.},
           giveni={R\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
      }
      \strng{namehash}{2dc9d6f36765f978f5cd24a236e1c1e5}
      \strng{fullhash}{924ec116ee95765e276c886e99423344}
      \strng{bibnamehash}{2dc9d6f36765f978f5cd24a236e1c1e5}
      \strng{authorbibnamehash}{2dc9d6f36765f978f5cd24a236e1c1e5}
      \strng{authornamehash}{2dc9d6f36765f978f5cd24a236e1c1e5}
      \strng{authorfullhash}{924ec116ee95765e276c886e99423344}
      \field{extraname}{1}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{MIMIC-III ('Medical Information Mart for Intensive Care') is a large, single-center database comprising information relating to patients admitted to critical care units at a large tertiary care hospital. Data includes vital signs, medications, laboratory measurements, observations and notes charted by care providers, fluid balance, procedure codes, diagnostic codes, imaging reports, hospital length of stay, survival data, and more. The database supports applications including academic and industrial research, quality improvement initiatives, and higher education coursework.}
      \field{issn}{2052-4463}
      \field{journaltitle}{{Scientific Data}}
      \field{number}{1}
      \field{title}{{{MIMIC-III}, a freely accessible critical care database}}
      \field{volume}{3}
      \field{year}{2016}
      \field{pages}{160035}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1038/sdata.2016.35
      \endverb
      \verb{file}
      \verb Johnson, Pollard et al. 2016 - MIMIC-III, a freely accessible critical:Attachments/Johnson, Pollard et al. 2016 - MIMIC-III, a freely accessible critical.pdf:application/pdf
      \endverb
    \endentry
    \entry{Johnson.2023}{article}{}
      \name{author}{13}{}{%
        {{hash=97ddf9ef7b3f83671aa14334972e8186}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={Alistair\bibnamedelimb E.\bibnamedelimi W.},
           giveni={A\bibinitperiod\bibinitdelim E\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{hash=4865cfad55c3cc4636c254f8d974bcf9}{%
           family={Bulgarelli},
           familyi={B\bibinitperiod},
           given={Lucas},
           giveni={L\bibinitperiod}}}%
        {{hash=905fd330076c29b21add0f3e7108629d}{%
           family={Shen},
           familyi={S\bibinitperiod},
           given={Lu},
           giveni={L\bibinitperiod}}}%
        {{hash=d8c9fb0f13dae237b13fe4ab0580be34}{%
           family={Gayles},
           familyi={G\bibinitperiod},
           given={Alvin},
           giveni={A\bibinitperiod}}}%
        {{hash=20388491ae62f9181d25b841a0c164f5}{%
           family={Shammout},
           familyi={S\bibinitperiod},
           given={Ayad},
           giveni={A\bibinitperiod}}}%
        {{hash=03b6f097b77c1154db2d3b7a6094c7c8}{%
           family={Horng},
           familyi={H\bibinitperiod},
           given={Steven},
           giveni={S\bibinitperiod}}}%
        {{hash=b1a10559d1345954860fcb71d58d644b}{%
           family={Pollard},
           familyi={P\bibinitperiod},
           given={Tom\bibnamedelima J.},
           giveni={T\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=90cd8fd12c9af2478bb4b419ffdaabc9}{%
           family={Hao},
           familyi={H\bibinitperiod},
           given={Sicheng},
           giveni={S\bibinitperiod}}}%
        {{hash=64d84f6b7d6b1cd1b82470cd4f4661b0}{%
           family={Moody},
           familyi={M\bibinitperiod},
           given={Benjamin},
           giveni={B\bibinitperiod}}}%
        {{hash=4ee5ebdc5bce079199e41b66a01cfe72}{%
           family={Gow},
           familyi={G\bibinitperiod},
           given={Brian},
           giveni={B\bibinitperiod}}}%
        {{hash=2ea8fc75e44631dccd4c8217117062f2}{%
           family={Lehman},
           familyi={L\bibinitperiod},
           given={Li-wei\bibnamedelima H.},
           giveni={L\bibinithyphendelim w\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{hash=3f99086f25722fadcd3c7540baaa9e93}{%
           family={Celi},
           familyi={C\bibinitperiod},
           given={Leo\bibnamedelima A.},
           giveni={L\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=2193bac90baddb616fc4dcd2f366de81}{%
           family={Mark},
           familyi={M\bibinitperiod},
           given={Roger\bibnamedelima G.},
           giveni={R\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
      }
      \strng{namehash}{2dc9d6f36765f978f5cd24a236e1c1e5}
      \strng{fullhash}{fe096d36823710a537b6d9d94e0dabf7}
      \strng{bibnamehash}{2dc9d6f36765f978f5cd24a236e1c1e5}
      \strng{authorbibnamehash}{2dc9d6f36765f978f5cd24a236e1c1e5}
      \strng{authornamehash}{2dc9d6f36765f978f5cd24a236e1c1e5}
      \strng{authorfullhash}{fe096d36823710a537b6d9d94e0dabf7}
      \field{extraname}{2}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Digital data collection during routine clinical practice is now ubiquitous within hospitals. The data contains valuable information on the care of patients and their response to treatments, offering exciting opportunities for research. Typically, data are stored within archival systems that are not intended to support research. These systems are often inaccessible to researchers and structured for optimal storage, rather than interpretability and analysis. Here we present MIMIC-IV, a publicly available database sourced from the electronic health record of the Beth Israel Deaconess Medical Center. Information available includes patient measurements, orders, diagnoses, procedures, treatments, and deidentified free-text clinical notes. MIMIC-IV is intended to support a wide array of research studies and educational material, helping to reduce barriers to conducting clinical research.}
      \field{issn}{2052-4463}
      \field{journaltitle}{{Scientific Data}}
      \field{number}{1}
      \field{title}{{MIMIC-IV, a freely accessible electronic health record dataset}}
      \field{volume}{10}
      \field{year}{2023}
      \field{pages}{1}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1038/s41597-022-01899-x
      \endverb
      \verb{file}
      \verb s41597-022-01899-x:Attachments/s41597-022-01899-x.pdf:application/pdf
      \endverb
      \keyw{Databases,Factual;Electronic Health Records;Hospitals;Humans}
    \endentry
    \entry{Kaddour.2021}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=23a8ea9c6f25b1531cc38eb463c1d550}{%
           family={Kaddour},
           familyi={K\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
        {{hash=187dbb52f5972c38059c28bbc664dd78}{%
           family={Zhu},
           familyi={Z\bibinitperiod},
           given={Yuchen},
           giveni={Y\bibinitperiod}}}%
        {{hash=0b07af422f6616fac129405a8b4b1de4}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Qi},
           giveni={Q\bibinitperiod}}}%
        {{hash=37d0d7a3ba0cb7a7253c7b690ce4e8c6}{%
           family={Kusner},
           familyi={K\bibinitperiod},
           given={Matt\bibnamedelima J.},
           giveni={M\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=4047ee6235adca502c24f37317e79d8e}{%
           family={Silva},
           familyi={S\bibinitperiod},
           given={Ricardo},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{8461de2b18b0e7d589b8bfdc6fd07a40}
      \strng{fullhash}{c39a64368d5e8ae1f4d9e86deae0b401}
      \strng{bibnamehash}{8461de2b18b0e7d589b8bfdc6fd07a40}
      \strng{authorbibnamehash}{8461de2b18b0e7d589b8bfdc6fd07a40}
      \strng{authornamehash}{8461de2b18b0e7d589b8bfdc6fd07a40}
      \strng{authorfullhash}{c39a64368d5e8ae1f4d9e86deae0b401}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{{NeurIPS}}
      \field{title}{Causal effect inference for structured treatments}
      \field{year}{2021}
      \verb{file}
      \verb Kaddour, Zhu et al. 2021 - Causal Effect Inference for Structured:Attachments/Kaddour, Zhu et al. 2021 - Causal Effect Inference for Structured.pdf:application/pdf
      \endverb
    \endentry
    \entry{Kallus.2018}{inproceedings}{}
      \name{author}{1}{}{%
        {{hash=2db96cc54afe3fe8c684be53af54a7bf}{%
           family={Kallus},
           familyi={K\bibinitperiod},
           given={Nathan},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{fullhash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{bibnamehash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{authorbibnamehash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{authornamehash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{authorfullhash}{2db96cc54afe3fe8c684be53af54a7bf}
      \field{extraname}{1}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present a new approach to the problems of evaluating and learning personalized decision policies from observational data of past contexts, decisions, and outcomes. Only the outcome of the enacted decision is available and the historical policy is unknown. These problems arise in personalized medicine using electronic health records and in internet advertising. Existing approaches use inverse propensity weighting (or, doubly robust versions) to make historical outcome (or, residual) data look like it were generated by a new policy being evaluated or learned. But this relies on a plug-in approach that rejects data points with a decision that disagrees with the new policy, leading to high variance estimates and ineffective learning. We propose a new, balance-based approach that too makes the data look like the new policy but does so directly by finding weights that optimize for balance between the weighted data and the target policy in the given, finite sample, which is equivalent to minimizing worst-case or posterior conditional mean square error. Our policy learner proceeds as a two-level optimization problem over policies and weights. We demonstrate that this approach markedly outperforms existing ones both in evaluation and learning, which is unsurprising given the wider support of balance-based weights. We establish extensive theoretical consistency guarantees and regret bounds that support this empirical success.}
      \field{booktitle}{{NeurIPS}}
      \field{title}{{Balanced policy evaluation and learning}}
      \field{year}{2018}
      \verb{file}
      \verb Kallus 2018 - Balanced Policy Evaluation and Learning:Attachments/Kallus 2018 - Balanced Policy Evaluation and Learning.pdf:application/pdf
      \endverb
    \endentry
    \entry{Kallus.2020}{article}{}
      \name{author}{1}{}{%
        {{hash=2db96cc54afe3fe8c684be53af54a7bf}{%
           family={Kallus},
           familyi={K\bibinitperiod},
           given={Nathan},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{fullhash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{bibnamehash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{authorbibnamehash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{authornamehash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{authorfullhash}{2db96cc54afe3fe8c684be53af54a7bf}
      \field{extraname}{2}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{Journal of Machine Learning Research}}
      \field{title}{{Generalized optimal matching methods for causal inference}}
      \field{year}{2020}
      \verb{file}
      \verb Generalized optimal matching methods 2020:Attachments/Generalized optimal matching methods 2020.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://www.jmlr.org/papers/volume21/19-120/19-120.pdf
      \endverb
      \verb{url}
      \verb https://www.jmlr.org/papers/volume21/19-120/19-120.pdf
      \endverb
    \endentry
    \entry{Kallus.2021}{article}{}
      \name{author}{1}{}{%
        {{hash=2db96cc54afe3fe8c684be53af54a7bf}{%
           family={Kallus},
           familyi={K\bibinitperiod},
           given={Nathan},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{fullhash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{bibnamehash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{authorbibnamehash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{authornamehash}{2db96cc54afe3fe8c684be53af54a7bf}
      \strng{authorfullhash}{2db96cc54afe3fe8c684be53af54a7bf}
      \field{extraname}{3}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{Journal of the American Statistical Association}}
      \field{number}{534}
      \field{title}{{More efficient policy learning via optimal retargeting}}
      \field{volume}{116}
      \field{year}{2021}
      \field{pages}{646\bibrangedash 658}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1080/01621459.2020.1788948
      \endverb
      \verb{file}
      \verb 01621459.2020:Attachments/01621459.2020.pdf:application/pdf
      \endverb
      \keyw{Efficient policy learning;Individualized treatment regimes;Optimization;Overlap}
    \endentry
    \entry{Kallus.2022b}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=2db96cc54afe3fe8c684be53af54a7bf}{%
           family={Kallus},
           familyi={K\bibinitperiod},
           given={Nathan},
           giveni={N\bibinitperiod}}}%
        {{hash=b10cdb9d98802bebd36e9273775cd63d}{%
           family={Oprescu},
           familyi={O\bibinitperiod},
           given={Miruna},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{b541d56d0883d7d5f03b38fb63fe378f}
      \strng{fullhash}{b541d56d0883d7d5f03b38fb63fe378f}
      \strng{bibnamehash}{b541d56d0883d7d5f03b38fb63fe378f}
      \strng{authorbibnamehash}{b541d56d0883d7d5f03b38fb63fe378f}
      \strng{authornamehash}{b541d56d0883d7d5f03b38fb63fe378f}
      \strng{authorfullhash}{b541d56d0883d7d5f03b38fb63fe378f}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The conditional average treatment effect (CATE) is the best point prediction of individual causal effects given individual baseline covariates and can help personalize treatments. However, as CATE only reflects the (conditional) average, it can wash out potential risks and tail events, which are crucially relevant to treatment choice. In aggregate analyses, this is usually addressed by measuring distributional treatment effect (DTE), such as differences in quantiles or tail expectations between treatment groups. Hypothetically, one can similarly fit covariate-conditional quantile regressions in each treatment group and take their difference, but this would not be robust to misspecification or provide agnostic best-in-class predictions. We provide a new robust and model-agnostic methodology for learning the conditional DTE (CDTE) for a wide class of problems that includes conditional quantile treatment effects, conditional super-quantile treatment effects, and conditional treatment effects on coherent risk measures given by $f$-divergences. Our method is based on constructing a special pseudo-outcome and regressing it on baseline covariates using any given regression learner. Our method is model-agnostic in the sense that it can provide the best projection of CDTE onto the regression model class. Our method is robust in the sense that even if we learn these nuisances nonparametrically at very slow rates, we can still learn CDTEs at rates that depend on the class complexity and even conduct inferences on linear projections of CDTEs. We investigate the performance of our proposal in simulation studies, and we demonstrate its use in a case study of 401(k) eligibility effects on wealth.}
      \field{booktitle}{{AISTATS}}
      \field{title}{{Robust and agnostic learning of conditional distributional treatment effects}}
      \field{year}{2023}
      \verb{file}
      \verb 2205.11486:Attachments/2205.11486.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/pdf/2205.11486v1
      \endverb
      \verb{url}
      \verb http://arxiv.org/pdf/2205.11486v1
      \endverb
      \keyw{Computer Science - Learning;Statistics - Machine Learning;Statistics - Methodology}
    \endentry
    \entry{Kallus.2018e}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=2db96cc54afe3fe8c684be53af54a7bf}{%
           family={Kallus},
           familyi={K\bibinitperiod},
           given={Nathan},
           giveni={N\bibinitperiod}}}%
        {{hash=b9e1d7c17694696833a7f501d67143a4}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Angela},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{94ee67824833d351384c9ed9a46b9422}
      \strng{fullhash}{94ee67824833d351384c9ed9a46b9422}
      \strng{bibnamehash}{94ee67824833d351384c9ed9a46b9422}
      \strng{authorbibnamehash}{94ee67824833d351384c9ed9a46b9422}
      \strng{authornamehash}{94ee67824833d351384c9ed9a46b9422}
      \strng{authorfullhash}{94ee67824833d351384c9ed9a46b9422}
      \field{extraname}{1}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{{AISTATS}}
      \field{title}{{Policy evaluation and optimization with continuous treatments}}
      \field{year}{2018}
      \verb{file}
      \verb kallus18a:Attachments/kallus18a.pdf:application/pdf
      \endverb
    \endentry
    \entry{Kallus.2018f}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=2db96cc54afe3fe8c684be53af54a7bf}{%
           family={Kallus},
           familyi={K\bibinitperiod},
           given={Nathan},
           giveni={N\bibinitperiod}}}%
        {{hash=b9e1d7c17694696833a7f501d67143a4}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Angela},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{94ee67824833d351384c9ed9a46b9422}
      \strng{fullhash}{94ee67824833d351384c9ed9a46b9422}
      \strng{bibnamehash}{94ee67824833d351384c9ed9a46b9422}
      \strng{authorbibnamehash}{94ee67824833d351384c9ed9a46b9422}
      \strng{authornamehash}{94ee67824833d351384c9ed9a46b9422}
      \strng{authorfullhash}{94ee67824833d351384c9ed9a46b9422}
      \field{extraname}{2}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{{ICML}}
      \field{title}{{Residual unfairness in fair machine learning from prejudiced data}}
      \field{year}{2018}
      \verb{file}
      \verb kallus18a (2):Attachments/kallus18a (2).pdf:application/pdf
      \endverb
    \endentry
    \entry{Kingma.2015}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=b6fbd171848aad4edf3925543f1f1522}{%
           family={Kingma},
           familyi={K\bibinitperiod},
           given={Diederik\bibnamedelima P.},
           giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=8aa66e8231cc2fdbe67aa4f18ca970c6}{%
           family={Ba},
           familyi={B\bibinitperiod},
           given={Jimmy},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{fullhash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{bibnamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authorbibnamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authornamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authorfullhash}{a09df9f123146b8e2c7f1134c9496932}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.}
      \field{booktitle}{{ICLR}}
      \field{title}{{Adam: A method for stochastic optimization}}
      \field{year}{2015}
    \endentry
    \entry{AkshayKrishnamurthy.2020}{article}{}
      \name{author}{3}{}{%
        {{hash=a74f4a2865ebc48f45a2864eb8ae6abf}{%
           family={Krishnamurthy},
           familyi={K\bibinitperiod},
           given={Akshay},
           giveni={A\bibinitperiod}}}%
        {{hash=3b32f20ce03981cb315259a6fd0a3068}{%
           family={Langford},
           familyi={L\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod}}}%
        {{hash=00695c90c34e8e49d2426cba18bb719f}{%
           family={{Slivkins, Aleksandrs, Zhang, Chicheng}},
           familyi={S\bibinitperiod}}}%
      }
      \strng{namehash}{40a247c5675b4bf0a6b59f1960316f92}
      \strng{fullhash}{40a247c5675b4bf0a6b59f1960316f92}
      \strng{bibnamehash}{40a247c5675b4bf0a6b59f1960316f92}
      \strng{authorbibnamehash}{40a247c5675b4bf0a6b59f1960316f92}
      \strng{authornamehash}{40a247c5675b4bf0a6b59f1960316f92}
      \strng{authorfullhash}{40a247c5675b4bf0a6b59f1960316f92}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{Journal of Machine Learning Research}}
      \field{number}{137}
      \field{title}{{Contextual bandits with continuous actions: smoothing, zooming, and Aaapting}}
      \field{volume}{21}
      \field{year}{2020}
      \field{pages}{1\bibrangedash 45}
      \range{pages}{45}
      \verb{file}
      \verb Akshay Krishnamurthy, John Langford et al. 2020 - Contextual Bandits with Continuous Actions:Attachments/Akshay Krishnamurthy, John Langford et al. 2020 - Contextual Bandits with Continuous Actions.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://jmlr.org/papers/v21/19-650.html
      \endverb
      \verb{url}
      \verb https://jmlr.org/papers/v21/19-650.html
      \endverb
    \endentry
    \entry{kumar2020conservative}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=976765a796e51c8e6a84c5ea053dd59d}{%
           family={Kumar},
           familyi={K\bibinitperiod},
           given={Aviral},
           giveni={A\bibinitperiod}}}%
        {{hash=519033a7338e5ef684c77d4d04748a4a}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Aurick},
           giveni={A\bibinitperiod}}}%
        {{hash=641a3f5d5ce834c4b56fb672c5df0207}{%
           family={Tucker},
           familyi={T\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod}}}%
        {{hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{d8b33c389094e2e20e901a8a383192a7}
      \strng{fullhash}{ad0c8ab01480d4997f655bcb1d8fdc86}
      \strng{bibnamehash}{d8b33c389094e2e20e901a8a383192a7}
      \strng{authorbibnamehash}{d8b33c389094e2e20e901a8a383192a7}
      \strng{authornamehash}{d8b33c389094e2e20e901a8a383192a7}
      \strng{authorfullhash}{ad0c8ab01480d4997f655bcb1d8fdc86}
      \field{extraname}{1}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{NeurIPS}
      \field{title}{Conservative {Q}-learning for offline reinforcement learning}
      \field{year}{2020}
    \endentry
    \entry{kumar2019stabilizing}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=976765a796e51c8e6a84c5ea053dd59d}{%
           family={Kumar},
           familyi={K\bibinitperiod},
           given={Aviral},
           giveni={A\bibinitperiod}}}%
        {{hash=6a018be9fcf5a8ea4185688a73eefa56}{%
           family={Fu},
           familyi={F\bibinitperiod},
           given={Justin},
           giveni={J\bibinitperiod}}}%
        {{hash=a1a5cd27df20065f67ba7d60dbd8b2b4}{%
           family={Soh},
           familyi={S\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod}}}%
        {{hash=641a3f5d5ce834c4b56fb672c5df0207}{%
           family={Tucker},
           familyi={T\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod}}}%
        {{hash=c9545da54b33744da25943cdf66eadac}{%
           family={Levine},
           familyi={L\bibinitperiod},
           given={Sergey},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{d8b33c389094e2e20e901a8a383192a7}
      \strng{fullhash}{a318d17cd2f57045f1ca8ac7080a8903}
      \strng{bibnamehash}{d8b33c389094e2e20e901a8a383192a7}
      \strng{authorbibnamehash}{d8b33c389094e2e20e901a8a383192a7}
      \strng{authornamehash}{d8b33c389094e2e20e901a8a383192a7}
      \strng{authorfullhash}{a318d17cd2f57045f1ca8ac7080a8903}
      \field{extraname}{2}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{NeurIPS}
      \field{title}{Stabilizing off-policy {Q}-learning via bootstrapping error reduction}
      \field{year}{2019}
    \endentry
    \entry{Lin.2020}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=09b60b6814df777f905b455b955cb226}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Tianyi},
           giveni={T\bibinitperiod}}}%
        {{hash=4064724d3727232708e3ee2304afce0e}{%
           family={Jin},
           familyi={J\bibinitperiod},
           given={Chi},
           giveni={C\bibinitperiod}}}%
        {{hash=8a36116840c7ee55901618c95fd08a58}{%
           family={Jordan},
           familyi={J\bibinitperiod},
           given={Michael\bibnamedelima I.},
           giveni={M\bibinitperiod\bibinitdelim I\bibinitperiod}}}%
      }
      \strng{namehash}{06935131a5cd57f91d7f892a611c5273}
      \strng{fullhash}{06935131a5cd57f91d7f892a611c5273}
      \strng{bibnamehash}{06935131a5cd57f91d7f892a611c5273}
      \strng{authorbibnamehash}{06935131a5cd57f91d7f892a611c5273}
      \strng{authornamehash}{06935131a5cd57f91d7f892a611c5273}
      \strng{authorfullhash}{06935131a5cd57f91d7f892a611c5273}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We consider nonconvex-concave minimax problems, {\$}\min_{\mathbf{x}} \max_{\mathbf{y} $\backslash$in \mathcal{Y}} f(\mathbf{x}, \mathbf{y}){\$}, where $f$ is nonconvex in {\$}\mathbf{x}{\$} but concave in {\$}\mathbf{y}{\$} and {\$}\mathcal{Y}{\$} is a convex and bounded set. One of the most popular algorithms for solving this problem is the celebrated gradient descent ascent (GDA) algorithm, which has been widely used in machine learning, control theory and economics. Despite the extensive convergence results for the convex-concave setting, GDA with equal stepsize can converge to limit cycles or even diverge in a general setting. In this paper, we present the complexity results on two-time-scale GDA for solving nonconvex-concave minimax problems, showing that the algorithm can find a stationary point of the function {\$}$\backslash$Phi($\backslash$cdot) := \max_{\mathbf{y} $\backslash$in \mathcal{Y}} f($\backslash$cdot, \mathbf{y}){\$} efficiently. To the best our knowledge, this is the first nonasymptotic analysis for two-time-scale GDA in this setting, shedding light on its superior practical performance in training generative adversarial networks (GANs) and other real applications.}
      \field{booktitle}{{ICML}}
      \field{title}{{On gradient descent ascent for nonconvex-concave minimax problems}}
      \field{year}{2020}
      \verb{file}
      \verb lin20a:Attachments/lin20a.pdf:application/pdf
      \endverb
      \keyw{Computer Science - Learning;Mathematics - Optimization and Control;Statistics - Machine Learning}
    \endentry
    \entry{Lin.1999}{article}{}
      \name{author}{2}{}{%
        {{hash=715abbf13771af0330339351e0874aa3}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Xihong},
           giveni={X\bibinitperiod}}}%
        {{hash=7d36e0ed2acd42b944ee1eb5c6198c8d}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Daowen},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{5071e8ae90af22cd59112016fe92675c}
      \strng{fullhash}{5071e8ae90af22cd59112016fe92675c}
      \strng{bibnamehash}{5071e8ae90af22cd59112016fe92675c}
      \strng{authorbibnamehash}{5071e8ae90af22cd59112016fe92675c}
      \strng{authornamehash}{5071e8ae90af22cd59112016fe92675c}
      \strng{authorfullhash}{5071e8ae90af22cd59112016fe92675c}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{[Generalized additive mixed models are proposed for overdispersed and correlated data, which arise frequently in studies involving clustered, hierarchical and spatial designs. This class of models allows flexible functional dependence of an outcome variable on covariates by using nonparametric regression, while accounting for correlation between observations by using random effects. We estimate nonparametric functions by using smoothing splines and jointly estimate smoothing parameters and variance components by using marginal quasi-likelihood. Because numerical integration is often required by maximizing the objective functions, double penalized quasi-likelihood is proposed to make approximate inference. Frequentist and Bayesian inferences are compared. A key feature of the method proposed is that it allows us to make systematic inference on all model components within a unified parametric mixed model framework and can be easily implemented by fitting a working generalized linear mixed model by using existing statistical software. A bias correction procedure is also proposed to improve the performance of double penalized quasi-likelihood for sparse data. We illustrate the method with an application to infectious disease data and we evaluate its performance through simulation.]}
      \field{issn}{13697412}
      \field{journaltitle}{{Journal of the Royal Statistical Society. Series B (Statistical Methodology)}}
      \field{number}{2}
      \field{title}{{Inference in Generalized Additive Mixed Models by Using Smoothing Splines}}
      \field{volume}{61}
      \field{year}{1999}
      \field{pages}{381\bibrangedash 400}
      \range{pages}{20}
      \verb{file}
      \verb Lin, Zhang 1999 - Inference in Generalized Additive Mixed:Attachments/Lin, Zhang 1999 - Inference in Generalized Additive Mixed.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://www.jstor.org/stable/2680648
      \endverb
      \verb{url}
      \verb http://www.jstor.org/stable/2680648
      \endverb
    \endentry
    \entry{ma2022learning}{article}{}
      \name{author}{3}{}{%
        {{hash=cc29d24ffe0a98a02ad002da5a78e5e0}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Haixu},
           giveni={H\bibinitperiod}}}%
        {{hash=ce0a9ea17981f2299c47fe765bcb3837}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Donglin},
           giveni={D\bibinitperiod}}}%
        {{hash=2ed68a56bfd902e0756e8c08e314a25c}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Yufeng},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{360959de383e13ad11a17903dacf776b}
      \strng{fullhash}{360959de383e13ad11a17903dacf776b}
      \strng{bibnamehash}{360959de383e13ad11a17903dacf776b}
      \strng{authorbibnamehash}{360959de383e13ad11a17903dacf776b}
      \strng{authornamehash}{360959de383e13ad11a17903dacf776b}
      \strng{authorfullhash}{360959de383e13ad11a17903dacf776b}
      \field{extraname}{1}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{NeurIPS}
      \field{title}{Learning individualized treatment rules with many treatments: A supervised clustering approach using adaptive fusion}
      \field{year}{2022}
    \endentry
    \entry{ma2023learning}{article}{}
      \name{author}{3}{}{%
        {{hash=cc29d24ffe0a98a02ad002da5a78e5e0}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Haixu},
           giveni={H\bibinitperiod}}}%
        {{hash=ce0a9ea17981f2299c47fe765bcb3837}{%
           family={Zeng},
           familyi={Z\bibinitperiod},
           given={Donglin},
           giveni={D\bibinitperiod}}}%
        {{hash=2ed68a56bfd902e0756e8c08e314a25c}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Yufeng},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{360959de383e13ad11a17903dacf776b}
      \strng{fullhash}{360959de383e13ad11a17903dacf776b}
      \strng{bibnamehash}{360959de383e13ad11a17903dacf776b}
      \strng{authorbibnamehash}{360959de383e13ad11a17903dacf776b}
      \strng{authornamehash}{360959de383e13ad11a17903dacf776b}
      \strng{authorfullhash}{360959de383e13ad11a17903dacf776b}
      \field{extraname}{2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of Machine Learning Research}
      \field{number}{102}
      \field{title}{Learning optimal group-structured individualized treatment rules with many treatments}
      \field{volume}{24}
      \field{year}{2023}
      \field{pages}{1\bibrangedash 48}
      \range{pages}{48}
    \endentry
    \entry{Melnychuk.2022}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=39196972594bfb6c0ffb951c333ee25c}{%
           family={Melnychuk},
           familyi={M\bibinitperiod},
           given={Valentyn},
           giveni={V\bibinitperiod}}}%
        {{hash=3b64fc0fa23681b890b424e43960e051}{%
           family={Frauen},
           familyi={F\bibinitperiod},
           given={Dennis},
           giveni={D\bibinitperiod}}}%
        {{hash=d276dae900e4bb8a8a125633e0277484}{%
           family={Feuerriegel},
           familyi={F\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{582a3ec304aced4a773fe8ffd73a647d}
      \strng{fullhash}{582a3ec304aced4a773fe8ffd73a647d}
      \strng{bibnamehash}{582a3ec304aced4a773fe8ffd73a647d}
      \strng{authorbibnamehash}{582a3ec304aced4a773fe8ffd73a647d}
      \strng{authornamehash}{582a3ec304aced4a773fe8ffd73a647d}
      \strng{authorfullhash}{582a3ec304aced4a773fe8ffd73a647d}
      \field{extraname}{1}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Estimating counterfactual outcomes over time from observational data is relevant for many applications (e.g., personalized medicine). Yet, state-of-the-art methods build upon simple long short-term memory (LSTM) networks, thus rendering inferences for complex, long-range dependencies challenging. In this paper, we develop a novel Causal Transformer for estimating counterfactual outcomes over time. Our model is specifically designed to capture complex, long-range dependencies among time-varying confounders. For this, we combine three transformer subnetworks with separate inputs for time-varying covariates, previous treatments, and previous outcomes into a joint network with in-between cross-attentions. We further develop a custom, end-to-end training procedure for our Causal Transformer. Specifically, we propose a novel counterfactual domain confusion loss to address confounding bias: it aims to learn adversarial balanced representations, so that they are predictive of the next outcome but non-predictive of the current treatment assignment. We evaluate our Causal Transformer based on synthetic and real-world datasets, where it achieves superior performance over current baselines. To the best of our knowledge, this is the first work proposing transformer-based architecture for estimating counterfactual outcomes from longitudinal data.}
      \field{booktitle}{{ICML}}
      \field{title}{{Causal transformer for estimating counterfactual outcomes}}
      \field{year}{2022}
      \verb{file}
      \verb 2204.07258 (1):Attachments/2204.07258 (1).pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/pdf/2204.07258v2
      \endverb
      \verb{url}
      \verb http://arxiv.org/pdf/2204.07258v2
      \endverb
      \keyw{Computer Science - Learning;counterfactual inference;personalized medicine;Statistics - Machine Learning;transformer;treatment effect estimation}
    \endentry
    \entry{Melnychuk.2022b}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=39196972594bfb6c0ffb951c333ee25c}{%
           family={Melnychuk},
           familyi={M\bibinitperiod},
           given={Valentyn},
           giveni={V\bibinitperiod}}}%
        {{hash=3b64fc0fa23681b890b424e43960e051}{%
           family={Frauen},
           familyi={F\bibinitperiod},
           given={Dennis},
           giveni={D\bibinitperiod}}}%
        {{hash=d276dae900e4bb8a8a125633e0277484}{%
           family={Feuerriegel},
           familyi={F\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{582a3ec304aced4a773fe8ffd73a647d}
      \strng{fullhash}{582a3ec304aced4a773fe8ffd73a647d}
      \strng{bibnamehash}{582a3ec304aced4a773fe8ffd73a647d}
      \strng{authorbibnamehash}{582a3ec304aced4a773fe8ffd73a647d}
      \strng{authornamehash}{582a3ec304aced4a773fe8ffd73a647d}
      \strng{authorfullhash}{582a3ec304aced4a773fe8ffd73a647d}
      \field{extraname}{2}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Existing machine learning methods for causal inference usually estimate quantities expressed via the mean of potential outcomes (e.g., average treatment effect). However, such quantities do not capture the full information about the distribution of potential outcomes. In this work, we estimate the density of potential outcomes after Interventional Normalizing Flows. Specifically, we combine two normalizing flows, namely (i) a teacher flow for estimating nuisance parameters and (ii) a student flow for a parametric estimation of the density of potential outcomes. We further develop a tractable optimization objective via a one-step bias correction for an efficient and doubly robust estimation of the student flow parameters. As a result our Interventional Normalizing Flows offer a properly normalized density estimator. Across various experiments, we demonstrate that our Interventional Normalizing Flows are expressive and highly effective, and scale well with both sample size and high-dimensional confounding. To the best of our knowledge, our Interventional Normalizing Flows are the first fully-parametric, deep learning method for density estimation of potential outcomes.}
      \field{booktitle}{{ICML}}
      \field{title}{{Normalizing flows for interventional density estimation}}
      \field{year}{2023}
      \verb{file}
      \verb 2209.06203:Attachments/2209.06203.pdf:application/pdf
      \endverb
      \keyw{Computer Science - Artificial Intelligence;Computer Science - Learning;Statistics - Methodology}
    \endentry
    \entry{Kuzmanovic.2023}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=3c08712cc899a55c64c669c50b9f4027}{%
           family={{Milan Kuzmanovic}},
           familyi={M\bibinitperiod}}}%
        {{hash=1d058d64a3eabb2251dda02d63d21eb1}{%
           family={{Tobias Hatt}},
           familyi={T\bibinitperiod}}}%
        {{hash=6a61e932736c482932a7e00b17a9474b}{%
           family={{Stefan Feuerriegel}},
           familyi={S\bibinitperiod}}}%
      }
      \strng{namehash}{fc61b9f9c5ebb0267476835bd832604d}
      \strng{fullhash}{fc61b9f9c5ebb0267476835bd832604d}
      \strng{bibnamehash}{fc61b9f9c5ebb0267476835bd832604d}
      \strng{authorbibnamehash}{fc61b9f9c5ebb0267476835bd832604d}
      \strng{authornamehash}{fc61b9f9c5ebb0267476835bd832604d}
      \strng{authorfullhash}{fc61b9f9c5ebb0267476835bd832604d}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Estimating Conditional Average Treatment Effects with Missing Treatment InformationMilan Kuzmanovic,~Tobias Hatt,~Stefan FeuerriegelEstimating cond...}
      \field{booktitle}{{AISTATS}}
      \field{issn}{2640-3498}
      \field{title}{{Estimating conditional average treatment effects with missing treatment information}}
      \field{year}{2023}
      \verb{file}
      \verb Milan Kuzmanovic, Tobias Hatt et al. 2023 - Estimating Conditional Average Treatment Effects:Attachments/Milan Kuzmanovic, Tobias Hatt et al. 2023 - Estimating Conditional Average Treatment Effects.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://proceedings.mlr.press/v206/kuzmanovic23a.html
      \endverb
      \verb{url}
      \verb https://proceedings.mlr.press/v206/kuzmanovic23a.html
      \endverb
    \endentry
    \entry{Nabi.2022b}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=e6ff1dfef84fdabd7b82ff44ed3fc054}{%
           family={Nabi},
           familyi={N\bibinitperiod},
           given={Razieh},
           giveni={R\bibinitperiod}}}%
        {{hash=8f6e9cc23bf3599ff49f5d77d36edb9d}{%
           family={McNutt},
           familyi={M\bibinitperiod},
           given={Todd},
           giveni={T\bibinitperiod}}}%
        {{hash=9ebb753339d5d0ba2ebfe33a9c7bbb87}{%
           family={Shpitser},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod}}}%
      }
      \strng{namehash}{4404462008aba2404c2a5d330816e6aa}
      \strng{fullhash}{4404462008aba2404c2a5d330816e6aa}
      \strng{bibnamehash}{4404462008aba2404c2a5d330816e6aa}
      \strng{authorbibnamehash}{4404462008aba2404c2a5d330816e6aa}
      \strng{authornamehash}{4404462008aba2404c2a5d330816e6aa}
      \strng{authorfullhash}{4404462008aba2404c2a5d330816e6aa}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Cause-effect relationships are typically evaluated by comparing outcome responses to binary treatment values, representing two arms of a hypothetical randomized controlled trial. However, in certain applications, treatments of interest are continuous and multidimensional. For example, understanding the causal relationship between severity of radiation therapy, summarized by a multidimensional vector of radiation exposure values and post-treatment side effects is a problem of clinical interest in radiation oncology. An appropriate strategy for making interpretable causal conclusions is to reduce the dimension of treatment. If individual elements of a multidimensional treatment vector weakly affect the outcome, but the overall relationship between treatment and outcome is strong, careless approaches to dimension reduction may not preserve this relationship. Further, methods developed for regression problems do not directly transfer to causal inference due to confounding complications. In this paper, we use semiparametric inference theory for structural models to give a general approach to causal sufficient dimension reduction of a multidimensional treatment such that the cause-effect relationship between treatment and outcome is preserved. We illustrate the utility of our proposals through simulations and a real data application in radiation oncology.}
      \field{booktitle}{{UAI}}
      \field{title}{{Semiparametric causal cufficient dimension reduction of multidimensional treatments}}
      \field{year}{2022}
      \verb{file}
      \verb Razieh Nabi, Todd McNutt et al. 2022 - Semiparametric Causal Sufficient Dimension Reduction:Attachments/Razieh Nabi, Todd McNutt et al. 2022 - Semiparametric Causal Sufficient Dimension Reduction.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://openreview.net/forum?id=BFULBwUocxq
      \endverb
      \verb{url}
      \verb https://openreview.net/forum?id=BFULBwUocxq
      \endverb
    \endentry
    \entry{Nandy.2017}{article}{}
      \name{author}{3}{}{%
        {{hash=886a11a8868ea0bcd528ff9665afd02f}{%
           family={Nandy},
           familyi={N\bibinitperiod},
           given={Preetam},
           giveni={P\bibinitperiod}}}%
        {{hash=8f905a89e7bf1cc9d54e6934783ebb3f}{%
           family={Maathuis},
           familyi={M\bibinitperiod},
           given={Marloes\bibnamedelima H.},
           giveni={M\bibinitperiod\bibinitdelim H\bibinitperiod}}}%
        {{hash=eabf99a26b5a1ac7dd40719ea6e697e2}{%
           family={Richardson},
           familyi={R\bibinitperiod},
           given={Thomas\bibnamedelima S.},
           giveni={T\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
      }
      \strng{namehash}{bea6c6359333700d89f66c587fe22039}
      \strng{fullhash}{bea6c6359333700d89f66c587fe22039}
      \strng{bibnamehash}{bea6c6359333700d89f66c587fe22039}
      \strng{authorbibnamehash}{bea6c6359333700d89f66c587fe22039}
      \strng{authornamehash}{bea6c6359333700d89f66c587fe22039}
      \strng{authorfullhash}{bea6c6359333700d89f66c587fe22039}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The Annals of Statistics}
      \field{issn}{0090-5364}
      \field{journaltitle}{{The Annals of Statistics}}
      \field{number}{2}
      \field{title}{{Estimating the effect of joint interventions from observational data in sparse high-dimensional settings}}
      \field{volume}{45}
      \field{year}{2017}
      \field{pages}{647\bibrangedash 674}
      \range{pages}{28}
      \verb{doi}
      \verb 10.1214/16- AOS1462
      \endverb
      \verb{file}
      \verb Nandy, Maathuis et al. 2017 - Estimating the effect of joint:Attachments/Nandy, Maathuis et al. 2017 - Estimating the effect of joint.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://projecteuclid.org/journals/annals-of-statistics/volume-45/issue-2/Estimating-the-effect-of-joint-interventions-from-observational-data-in/10.1214/16- AOS1462.full
      \endverb
      \verb{url}
      \verb https://projecteuclid.org/journals/annals-of-statistics/volume-45/issue-2/Estimating-the-effect-of-joint-interventions-from-observational-data-in/10.1214/16-%20AOS1462.full
      \endverb
    \endentry
    \entry{Nie.2021}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=1a5574cd77820e544fed66f6919ecd57}{%
           family={Nie},
           familyi={N\bibinitperiod},
           given={Lizhen},
           giveni={L\bibinitperiod}}}%
        {{hash=40f8923944f9a0847ab6da9de1ba61c4}{%
           family={Ye},
           familyi={Y\bibinitperiod},
           given={Mao},
           giveni={M\bibinitperiod}}}%
        {{hash=e8c0010ab32e4255b70bd8d9fefdf5cd}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Qiang},
           giveni={Q\bibinitperiod}}}%
        {{hash=15ef236bce91028126d54f3616a0b3b1}{%
           family={Nicolae},
           familyi={N\bibinitperiod},
           given={Dan},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{86bffea753d22dd51ffe8b34827f8877}
      \strng{fullhash}{94bb44704b93e441657a2b1739426e8d}
      \strng{bibnamehash}{86bffea753d22dd51ffe8b34827f8877}
      \strng{authorbibnamehash}{86bffea753d22dd51ffe8b34827f8877}
      \strng{authornamehash}{86bffea753d22dd51ffe8b34827f8877}
      \strng{authorfullhash}{94bb44704b93e441657a2b1739426e8d}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Motivated by the rising abundance of observational data with continuous treatments, we investigate the problem of estimating the average dose-response curve (ADRF). Available parametric methods are limited in their model space, and previous attempts in leveraging neural network to enhance model expressiveness relied on partitioning continuous treatment into blocks and using separate heads for each block; this however produces in practice discontinuous ADRFs. Therefore, the question of how to adapt the structure and training of neural network to estimate ADRFs remains open. This paper makes two important contributions. First, we propose a novel varying coefficient neural network (VCNet) that improves model expressiveness while preserving continuity of the estimated ADRF. Second, to improve finite sample performance, we generalize targeted regularization to obtain a doubly robust estimator of the whole ADRF curve.}
      \field{booktitle}{{ICLR}}
      \field{title}{{VCNet and functional targeted regularization for learning causal effects of continuous treatments}}
      \field{year}{2021}
      \verb{file}
      \verb 2103.07861:Attachments/2103.07861.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/pdf/2103.07861v1
      \endverb
      \verb{url}
      \verb http://arxiv.org/pdf/2103.07861v1
      \endverb
      \keyw{Computer Science - Learning;Statistics - Machine Learning}
    \endentry
    \entry{Nie.2021b}{article}{}
      \name{author}{2}{}{%
        {{hash=5d7f65b7cbc98c0f42680d2152ed13c0}{%
           family={Nie},
           familyi={N\bibinitperiod},
           given={Xinkun},
           giveni={X\bibinitperiod}}}%
        {{hash=e22c2c3bb1bd12e43f46c07ea788b581}{%
           family={Wager},
           familyi={W\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{107119e30dba36dbb23cae173c2ad1c2}
      \strng{fullhash}{107119e30dba36dbb23cae173c2ad1c2}
      \strng{bibnamehash}{107119e30dba36dbb23cae173c2ad1c2}
      \strng{authorbibnamehash}{107119e30dba36dbb23cae173c2ad1c2}
      \strng{authornamehash}{107119e30dba36dbb23cae173c2ad1c2}
      \strng{authorfullhash}{107119e30dba36dbb23cae173c2ad1c2}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Flexible estimation of heterogeneous treatment effects lies at the heart of many statistical challenges, such as personalized medicine and optimal resource allocation. In this paper, we develop a general class of two-step algorithms for heterogeneous treatment effect estimation in observational studies. We first estimate marginal effects and treatment propensities in order to form an objective function that isolates the causal component of the signal. Then, we optimize this data-adaptive objective function. Our approach has several advantages over existing methods. From a practical perspective, our method is flexible and easy to use: In both steps, we can use any loss-minimization method, e.g., penalized regression, deep neural networks, or boosting; moreover, these methods can be fine-tuned by cross validation. Meanwhile, in the case of penalized kernel regression, we show that our method has a quasi-oracle property: Even if the pilot estimates for marginal effects and treatment propensities are not particularly accurate, we achieve the same error bounds as an oracle who has a priori knowledge of these two nuisance components. We implement variants of our approach based on penalized regression, kernel ridge regression, and boosting in a variety of simulation setups, and find promising performance relative to existing baselines.}
      \field{issn}{0006-3444}
      \field{journaltitle}{{Biometrika}}
      \field{number}{2}
      \field{title}{{Quasi-oracle estimation of heterogeneous treatment effects}}
      \field{volume}{108}
      \field{year}{2021}
      \field{pages}{299\bibrangedash 319}
      \range{pages}{21}
      \verb{file}
      \verb 1712.04912:Attachments/1712.04912.pdf:application/pdf
      \endverb
      \keyw{Mathematics - Statistics;Statistics - Machine Learning;Statistics - Theory}
    \endentry
    \entry{Parbhoo.2021}{article}{}
      \name{author}{3}{}{%
        {{hash=c6606e9570fb90f19818699b15a003e5}{%
           family={Parbhoo},
           familyi={P\bibinitperiod},
           given={Sonali},
           giveni={S\bibinitperiod}}}%
        {{hash=6e0afe0dd7f80126ec663a279b8d6212}{%
           family={Bauer},
           familyi={B\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
        {{hash=bec02dd8e56992bfefdc34946b3b871c}{%
           family={Schwab},
           familyi={S\bibinitperiod},
           given={Patrick},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{a1cdd4bfb6d860219283d34b59ba8efe}
      \strng{fullhash}{a1cdd4bfb6d860219283d34b59ba8efe}
      \strng{bibnamehash}{a1cdd4bfb6d860219283d34b59ba8efe}
      \strng{authorbibnamehash}{a1cdd4bfb6d860219283d34b59ba8efe}
      \strng{authornamehash}{a1cdd4bfb6d860219283d34b59ba8efe}
      \strng{authorfullhash}{a1cdd4bfb6d860219283d34b59ba8efe}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Estimating an individual's potential response to interventions from observational data is of high practical relevance for many domains, such as healthcare, public policy or economics. In this setting, it is often the case that combinations of interventions may be applied simultaneously, for example, multiple prescriptions in healthcare or different fiscal and monetary measures in economics. However, existing methods for counterfactual inference are limited to settings in which actions are not used simultaneously. Here, we present Neural Counterfactual Relation Estimation (NCoRE), a new method for learning counterfactual representations in the combination treatment setting that explicitly models cross-treatment interactions. NCoRE is based on a novel branched conditional neural representation that includes learnt treatment interaction modulators to infer the potential causal generative process underlying the combination of multiple treatments. Our experiments show that NCoRE significantly outperforms existing state-of-the-art methods for counterfactual treatment effect estimation that do not account for the effects of combining multiple treatments across several synthetic, semi-synthetic and real-world benchmarks.}
      \field{journaltitle}{{arXiv preprint}}
      \field{title}{{NCoRE: Neural Counterfactual Representation Learning for Combinations of Treatments}}
      \field{year}{2021}
      \verb{file}
      \verb 2103.11175:Attachments/2103.11175.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/pdf/2103.11175v1
      \endverb
      \verb{url}
      \verb http://arxiv.org/pdf/2103.11175v1
      \endverb
      \keyw{Combination Treatments;Computer Science - Learning;counterfactual inference;Healthcare;Statistics - Machine Learning;Statistics - Methodology}
    \endentry
    \entry{Qian.2021}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=7dfc43d0eaa1627f3c07c79898f4d2ad}{%
           family={Qian},
           familyi={Q\bibinitperiod},
           given={Zhaozhi},
           giveni={Z\bibinitperiod}}}%
        {{hash=be4caf6e3994dcbe4e11bc11c8a6a437}{%
           family={Curth},
           familyi={C\bibinitperiod},
           given={Alicia},
           giveni={A\bibinitperiod}}}%
        {{hash=d44f2d413b2e6dcde01be4d1392763dd}{%
           family={{van der Schaar}},
           familyi={v\bibinitperiod},
           given={Mihaela},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{0105cab2c9dc78ff8c6ad7209c89e7b7}
      \strng{fullhash}{0105cab2c9dc78ff8c6ad7209c89e7b7}
      \strng{bibnamehash}{0105cab2c9dc78ff8c6ad7209c89e7b7}
      \strng{authorbibnamehash}{0105cab2c9dc78ff8c6ad7209c89e7b7}
      \strng{authornamehash}{0105cab2c9dc78ff8c6ad7209c89e7b7}
      \strng{authorfullhash}{0105cab2c9dc78ff8c6ad7209c89e7b7}
      \field{sortinit}{Q}
      \field{sortinithash}{ce69a400a872ddd02ee7fdb3b38c6abd}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{{NeurIPS}}
      \field{title}{{Estimating multi-cause treatment effects via single cause perturbation}}
      \field{year}{2021}
      \verb{file}
      \verb NeurIPS-2021-estimating-multi-cause-treatment-effects-via-single-cause-perturbation-Paper:Attachments/NeurIPS-2021-estimating-multi-cause-treatment-effects-via-single-cause-perturbation-Paper.pdf:application/pdf
      \endverb
    \endentry
    \entry{rezende2015variational}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=9cc8aeb0de8b3e29d29d6aeaad3f7d9b}{%
           family={Rezende},
           familyi={R\bibinitperiod},
           given={Danilo},
           giveni={D\bibinitperiod}}}%
        {{hash=b520f2e46ec8803dd4c66bf1d6059482}{%
           family={Mohamed},
           familyi={M\bibinitperiod},
           given={Shakir},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{69cf0dc2f1e2704916090d834063b807}
      \strng{fullhash}{69cf0dc2f1e2704916090d834063b807}
      \strng{bibnamehash}{69cf0dc2f1e2704916090d834063b807}
      \strng{authorbibnamehash}{69cf0dc2f1e2704916090d834063b807}
      \strng{authornamehash}{69cf0dc2f1e2704916090d834063b807}
      \strng{authorfullhash}{69cf0dc2f1e2704916090d834063b807}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{ICML}
      \field{title}{Variational inference with normalizing flows}
      \field{year}{2015}
    \endentry
    \entry{Riechelmann.2007}{article}{}
      \name{author}{6}{}{%
        {{hash=621e534069d2e30629aadc2b39fdc8a7}{%
           family={Riechelmann},
           familyi={R\bibinitperiod},
           given={Rachel\bibnamedelima P.},
           giveni={R\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=12ffdc4de974dc5fae16159412a904e9}{%
           family={Tannock},
           familyi={T\bibinitperiod},
           given={Ian\bibnamedelima F.},
           giveni={I\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
        {{hash=c9e3554ba89b08176017242506dd3424}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Lisa},
           giveni={L\bibinitperiod}}}%
        {{hash=654dce830ca626b2f2a83029bfca34b9}{%
           family={Saad},
           familyi={S\bibinitperiod},
           given={Everardo\bibnamedelima D.},
           giveni={E\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=869c13d2d86ae16981f1964e2e6a022a}{%
           family={Taback},
           familyi={T\bibinitperiod},
           given={Nathan\bibnamedelima A.},
           giveni={N\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=984a5e962acb591920a07456659aad09}{%
           family={Krzyzanowska},
           familyi={K\bibinitperiod},
           given={Monika\bibnamedelima K.},
           giveni={M\bibinitperiod\bibinitdelim K\bibinitperiod}}}%
      }
      \strng{namehash}{0238ee4d3ef7e3a7eb16cfc299d560ab}
      \strng{fullhash}{631a17fffad564c7e402f4232a2b6a23}
      \strng{bibnamehash}{0238ee4d3ef7e3a7eb16cfc299d560ab}
      \strng{authorbibnamehash}{0238ee4d3ef7e3a7eb16cfc299d560ab}
      \strng{authornamehash}{0238ee4d3ef7e3a7eb16cfc299d560ab}
      \strng{authorfullhash}{631a17fffad564c7e402f4232a2b6a23}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{BACKGROUND Cancer patients receive numerous medications, including antineoplastic agents, drugs for supportive care, and medications for comorbid illnesses. Therefore, they are at risk for drug interactions and duplicate prescribing. METHODS A questionnaire eliciting information on demographics and medications taken in the previous 4 weeks was given to adult outpatients receiving systemic anticancer therapy for solid tumors. The Drug Interaction Facts software, version 4.0, was used to identify potential drug interactions and to classify them by level of severity (major, moderate, or minor) and the strength of scientific evidence for them (using categories [1-5] of decreasing certainty). Summary statistics and logistic regression were used to analyze the data. All statistical tests were two-sided. RESULTS The survey was completed by 405 patients. We observed 276 potential drug interactions, and at least one potential interaction was identified in 109 patients (27{\%}; 95{\%} confidence interval [CI] = 23{\%} to 31{\%}). Of the potential interactions, 25 (9{\%}) were classified as major and 211 (77{\%}) as moderate. Nearly half (49{\%}) of potential interactions were supported by level 1 or 2 scientific evidence. Most potential drug interactions (87{\%}) involved non-anticancer agents such as warfarin, antihypertensive drugs, corticosteroids, and anticonvulsants, but some (n = 36, 13{\%}) involved antineoplastic agents. In multivariable analysis, increased risk of receiving drug combinations in which there were potential drug interactions was associated with receipt of increasing numbers of drugs (odds ratio [OR] = 1.4 per additional drug, 95{\%} CI = 1.26 to 1.58, P{<}.001 from the Wald chi-square test), type of medication (drugs to treat comorbid conditions versus supportive care medications only; OR = 8.6, 95{\%} CI = 2.9 to 25, P{<}.001), and the presence of brain tumors. Thirty-two (8{\%}) patients were exposed to duplicate medications, most often corticosteroids, proton pump inhibitors, or benzodiazepines. CONCLUSION Potential drug interactions were common among cancer patients and most often involved medications to treat comorbid conditions. Duplicate medications were infrequent.}
      \field{journaltitle}{{Journal of the National Cancer Institute}}
      \field{number}{8}
      \field{title}{{Potential drug interactions and duplicate prescriptions among cancer patients}}
      \field{volume}{99}
      \field{year}{2007}
      \field{pages}{592\bibrangedash 600}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1093/jnci/djk130
      \endverb
    \endentry
    \entry{Robins.2000}{article}{}
      \name{author}{3}{}{%
        {{hash=7a2ba958c4a9112b1e74732b9c35f016}{%
           family={Robins},
           familyi={R\bibinitperiod},
           given={James\bibnamedelima M.},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=4bfbae7bd65c55b2dceaaa88a09d6acc}{%
           family={Hernán},
           familyi={H\bibinitperiod},
           given={Miguel\bibnamedelima A.},
           giveni={M\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=b4734534b3b9358f167f39a35ff189e1}{%
           family={Brumback},
           familyi={B\bibinitperiod},
           given={Babette},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{cbddcccbd1221417f125cb33d402c5ff}
      \strng{fullhash}{cbddcccbd1221417f125cb33d402c5ff}
      \strng{bibnamehash}{cbddcccbd1221417f125cb33d402c5ff}
      \strng{authorbibnamehash}{cbddcccbd1221417f125cb33d402c5ff}
      \strng{authornamehash}{cbddcccbd1221417f125cb33d402c5ff}
      \strng{authorfullhash}{cbddcccbd1221417f125cb33d402c5ff}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In observational studies with exposures or treatments that vary over time, standard approaches for adjustment of confounding are biased when there exist time-dependent confounders that are also affected by previous treatment. This paper introduces marginal structural models, a new class of causal models that allow for improved adjustment of confounding in those situations. The parameters of a marginal structural model can be consistently estimated using a new class of estimators, the inverse-probability-of-treatment weighted estimators.}
      \field{journaltitle}{{Epidemiology}}
      \field{number}{5}
      \field{title}{{Marginal structural models and causal inference in epidemiology}}
      \field{volume}{11}
      \field{year}{2000}
      \field{pages}{550\bibrangedash 560}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1097/00001648-200009000-00011
      \endverb
      \verb{file}
      \verb Marginal{\_}Structural{\_}Models{\_}and{\_}Causal{\_}Inference{\_}in.11:Attachments/Marginal{\_}Structural{\_}Models{\_}and{\_}Causal{\_}Inference{\_}in.11.pdf:application/pdf
      \endverb
      \keyw{Anti-HIV Agents/therapeutic use;Causality;Confounding Factors,Epidemiologic;Epidemiologic Methods;HIV Infections/drug therapy/mortality;Humans;Models,Statistical;Risk Factors;Time Factors;Zidovudine/therapeutic use}
    \endentry
    \entry{rosenbaum1987model}{article}{}
      \name{author}{1}{}{%
        {{hash=2619036f349e499ca578ec1a7ebb3a46}{%
           family={Rosenbaum},
           familyi={R\bibinitperiod},
           given={Paul\bibnamedelima R},
           giveni={P\bibinitperiod\bibinitdelim R\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Taylor \& Francis}%
      }
      \strng{namehash}{2619036f349e499ca578ec1a7ebb3a46}
      \strng{fullhash}{2619036f349e499ca578ec1a7ebb3a46}
      \strng{bibnamehash}{2619036f349e499ca578ec1a7ebb3a46}
      \strng{authorbibnamehash}{2619036f349e499ca578ec1a7ebb3a46}
      \strng{authornamehash}{2619036f349e499ca578ec1a7ebb3a46}
      \strng{authorfullhash}{2619036f349e499ca578ec1a7ebb3a46}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Journal of the American statistical Association}
      \field{number}{398}
      \field{title}{Model-based direct adjustment}
      \field{volume}{82}
      \field{year}{1987}
      \field{pages}{387\bibrangedash 394}
      \range{pages}{8}
    \endentry
    \entry{Rubin.1978}{article}{}
      \name{author}{1}{}{%
        {{hash=49a367b6280de8a239f8bbdd573f996f}{%
           family={Rubin},
           familyi={R\bibinitperiod},
           given={Donald\bibnamedelima B.},
           giveni={D\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
      }
      \strng{namehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{fullhash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{bibnamehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{authorbibnamehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{authornamehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{authorfullhash}{49a367b6280de8a239f8bbdd573f996f}
      \field{extraname}{1}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0090-5364}
      \field{journaltitle}{{Annals of Statistics}}
      \field{number}{1}
      \field{title}{{Bayesian inference for causal effects: The role of randomization}}
      \field{volume}{6}
      \field{year}{1978}
      \field{pages}{34\bibrangedash 58}
      \range{pages}{25}
      \verb{doi}
      \verb 10.1214/aos/1176344064
      \endverb
      \verb{file}
      \verb 1176344064:Attachments/1176344064.pdf:application/pdf
      \endverb
      \keyw{Potential outcomes}
    \endentry
    \entry{Rubin.1974}{article}{}
      \name{author}{1}{}{%
        {{hash=49a367b6280de8a239f8bbdd573f996f}{%
           family={Rubin},
           familyi={R\bibinitperiod},
           given={Donald\bibnamedelima B.},
           giveni={D\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
      }
      \strng{namehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{fullhash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{bibnamehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{authorbibnamehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{authornamehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{authorfullhash}{49a367b6280de8a239f8bbdd573f996f}
      \field{extraname}{2}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0022-0663}
      \field{journaltitle}{{Journal of Educational Psychology}}
      \field{number}{5}
      \field{title}{{Estimating causal effects of treatments in randomized and nonrandomized studies}}
      \field{volume}{66}
      \field{year}{1974}
      \field{pages}{688\bibrangedash 701}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1037/h0037350
      \endverb
    \endentry
    \entry{Rubin.2010}{article}{}
      \name{author}{1}{}{%
        {{hash=49a367b6280de8a239f8bbdd573f996f}{%
           family={Rubin},
           familyi={R\bibinitperiod},
           given={Donald\bibnamedelima B.},
           giveni={D\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
      }
      \strng{namehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{fullhash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{bibnamehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{authorbibnamehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{authornamehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{authorfullhash}{49a367b6280de8a239f8bbdd573f996f}
      \field{extraname}{3}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Click on the article title to read more.}
      \field{journaltitle}{{Statistics in Medicine}}
      \field{number}{19}
      \field{title}{{On the limitations of comparative effectiveness research}}
      \field{volume}{29}
      \field{year}{2010}
      \field{pages}{1991\bibrangedash 1995}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1002/sim.3960
      \endverb
      \verb{file}
      \verb Rubin 2010 - On the limitations of comparative:Attachments/Rubin 2010 - On the limitations of comparative.pdf:application/pdf
      \endverb
    \endentry
    \entry{Schwab.2020}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=bec02dd8e56992bfefdc34946b3b871c}{%
           family={Schwab},
           familyi={S\bibinitperiod},
           given={Patrick},
           giveni={P\bibinitperiod}}}%
        {{hash=c45ca8c24b653291900837d0fc19b2af}{%
           family={Linhardt},
           familyi={L\bibinitperiod},
           given={Lorenz},
           giveni={L\bibinitperiod}}}%
        {{hash=6e0afe0dd7f80126ec663a279b8d6212}{%
           family={Bauer},
           familyi={B\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
        {{hash=335c89d2252c8ad41635e8f3315696d1}{%
           family={Buhmann},
           familyi={B\bibinitperiod},
           given={Joachim\bibnamedelima M.},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=9c4c636dbe272e5b56e0e77059a9a5af}{%
           family={Karlen},
           familyi={K\bibinitperiod},
           given={Walter},
           giveni={W\bibinitperiod}}}%
      }
      \strng{namehash}{3ec3a7512666f74dbb7bab0dde9aa3e1}
      \strng{fullhash}{f88d0e0338f0277a377d6cc127dde55c}
      \strng{bibnamehash}{3ec3a7512666f74dbb7bab0dde9aa3e1}
      \strng{authorbibnamehash}{3ec3a7512666f74dbb7bab0dde9aa3e1}
      \strng{authornamehash}{3ec3a7512666f74dbb7bab0dde9aa3e1}
      \strng{authorfullhash}{f88d0e0338f0277a377d6cc127dde55c}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Estimating what would be an individual's potential response to varying levels of exposure to a treatment is of high practical relevance for several important fields, such as healthcare, economics and public policy. However, existing methods for learning to estimate counterfactual outcomes from observational data are either focused on estimating average dose-response curves, or limited to settings with only two treatments that do not have an associated dosage parameter. Here, we present a novel machine-learning approach towards learning counterfactual representations for estimating individual dose-response curves for any number of treatments with continuous dosage parameters with neural networks. Building on the established potential outcomes framework, we introduce performance metrics, model selection criteria, model architectures, and open benchmarks for estimating individual dose-response curves. Our experiments show that the methods developed in this work set a new state-of-the-art in estimating individual dose-response.}
      \field{booktitle}{{AAAI}}
      \field{title}{{Learning counterfactual representations for estimating individual dose-response curves}}
      \field{year}{2020}
      \field{pages}{5}
      \range{pages}{1}
      \verb{file}
      \verb 1902.00981:Attachments/1902.00981.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/pdf/1902.00981v3
      \endverb
      \verb{url}
      \verb http://arxiv.org/pdf/1902.00981v3
      \endverb
      \keyw{Computer Science - Learning;Statistics - Machine Learning}
    \endentry
    \entry{Shalit.2017}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=c39ea9ea2b55e1753c555a453a610aec}{%
           family={Shalit},
           familyi={S\bibinitperiod},
           given={Uri},
           giveni={U\bibinitperiod}}}%
        {{hash=477c381b77493d3455836688eb1f6f74}{%
           family={Johansson},
           familyi={J\bibinitperiod},
           given={Fredrik\bibnamedelima D.},
           giveni={F\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=e7482c3a6bf929dc430ae34c20757273}{%
           family={Sontag},
           familyi={S\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
      }
      \strng{namehash}{84c7618d3cd9ac0fd96c43ac116c9221}
      \strng{fullhash}{84c7618d3cd9ac0fd96c43ac116c9221}
      \strng{bibnamehash}{84c7618d3cd9ac0fd96c43ac116c9221}
      \strng{authorbibnamehash}{84c7618d3cd9ac0fd96c43ac116c9221}
      \strng{authornamehash}{84c7618d3cd9ac0fd96c43ac116c9221}
      \strng{authorfullhash}{84c7618d3cd9ac0fd96c43ac116c9221}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{There is intense interest in applying machine learning to problems of causal inference in fields such as healthcare, economics and education. In particular, individual-level causal inference has important applications such as precision medicine. We give a new theoretical analysis and family of algorithms for predicting individual treatment effect (ITE) from observational data, under the assumption known as strong ignorability. The algorithms learn a {"}balanced{"} representation such that the induced treated and control distributions look similar. We give a novel, simple and intuitive generalization-error bound showing that the expected ITE estimation error of a representation is bounded by a sum of the standard generalization-error of that representation and the distance between the treated and control distributions induced by the representation. We use Integral Probability Metrics to measure distances between distributions, deriving explicit bounds for the Wasserstein and Maximum Mean Discrepancy (MMD) distances. Experiments on real and simulated data show the new algorithms match or outperform the state-of-the-art.}
      \field{booktitle}{{ICML}}
      \field{title}{{Estimating individual treatment effect: Generalization bounds and algorithms}}
      \field{year}{2017}
      \verb{file}
      \verb Individual{\_}treatment{\_}generalization{\_}bounds:Attachments/Individual{\_}treatment{\_}generalization{\_}bounds.pdf:application/pdf
      \endverb
      \keyw{causal effects;Computer Science - Artificial Intelligence;Computer Science - Learning;counterfactual inference;Statistics - Machine Learning}
    \endentry
    \entry{Shi.2019}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=6d1aae8940286988940757c7947d1976}{%
           family={Shi},
           familyi={S\bibinitperiod},
           given={Claudia},
           giveni={C\bibinitperiod}}}%
        {{hash=108998f0d44d4dce8ccb93e4d78cd5c6}{%
           family={Blei},
           familyi={B\bibinitperiod},
           given={David\bibnamedelima M.},
           giveni={D\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=30db2f42d0dd8cf10ef82c5eae10096e}{%
           family={Veitch},
           familyi={V\bibinitperiod},
           given={Victor},
           giveni={V\bibinitperiod}}}%
      }
      \strng{namehash}{9b11fd87f70037129fce72060c17b3ca}
      \strng{fullhash}{9b11fd87f70037129fce72060c17b3ca}
      \strng{bibnamehash}{9b11fd87f70037129fce72060c17b3ca}
      \strng{authorbibnamehash}{9b11fd87f70037129fce72060c17b3ca}
      \strng{authornamehash}{9b11fd87f70037129fce72060c17b3ca}
      \strng{authorfullhash}{9b11fd87f70037129fce72060c17b3ca}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Neural Information Processing Systems http://nips.cc/}
      \field{booktitle}{{NeurIPS}}
      \field{title}{{Adapting neural networks for the estimation of treatment effects}}
      \field{year}{2019}
      \verb{file}
      \verb NeurIPS-2019-adapting-neural-networks-for-the-estimation-of-treatment-effects-Paper:Attachments/NeurIPS-2019-adapting-neural-networks-for-the-estimation-of-treatment-effects-Paper.pdf:application/pdf
      \endverb
    \endentry
    \entry{Swaminathan.2015}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=af7d0e4d0095cc3456e940883204919b}{%
           family={Swaminathan},
           familyi={S\bibinitperiod},
           given={Adith},
           giveni={A\bibinitperiod}}}%
        {{hash=0e5ae7e30da87e8ba62ced27d4e6f2aa}{%
           family={Joachims},
           familyi={J\bibinitperiod},
           given={Thorsten},
           giveni={T\bibinitperiod}}}%
      }
      \strng{namehash}{14ac1a73633b2698a092d5ed96ebf95b}
      \strng{fullhash}{14ac1a73633b2698a092d5ed96ebf95b}
      \strng{bibnamehash}{14ac1a73633b2698a092d5ed96ebf95b}
      \strng{authorbibnamehash}{14ac1a73633b2698a092d5ed96ebf95b}
      \strng{authornamehash}{14ac1a73633b2698a092d5ed96ebf95b}
      \strng{authorfullhash}{14ac1a73633b2698a092d5ed96ebf95b}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We develop a learning principle and an efficient algorithm for batch learning from logged bandit feedback. This learning setting is ubiquitous in online systems (e.g., ad placement, web search, recommendation), where an algorithm makes a prediction (e.g., ad ranking) for a given input (e.g., query) and observes bandit feedback (e.g., user clicks on presented ads). We first address the counterfactual nature of the learning problem through propensity scoring. Next, we prove generalization error bounds that account for the variance of the propensity-weighted empirical risk estimator. These constructive bounds give rise to the Counterfactual Risk Minimization (CRM) principle. We show how CRM can be used to derive a new learning method -- called Policy Optimizer for Exponential Models (POEM) -- for learning stochastic linear rules for structured output prediction. We present a decomposition of the POEM objective that enables efficient stochastic gradient optimization. POEM is evaluated on several multi-label classification problems showing substantially improved robustness and generalization performance compared to the state-of-the-art.}
      \field{booktitle}{{ICML}}
      \field{title}{{Counterfactual risk minimization: learning from logged bandit feedback}}
      \field{year}{2015}
      \verb{file}
      \verb Swaminathan, Joachims 09 02 2015 - Counterfactual Risk Minimization:Attachments/Swaminathan, Joachims 09 02 2015 - Counterfactual Risk Minimization.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/pdf/1502.02362
      \endverb
      \verb{url}
      \verb https://arxiv.org/pdf/1502.02362
      \endverb
    \endentry
    \entry{tabak2010density}{article}{}
      \name{author}{2}{}{%
        {{hash=1a093a86b284e2075d35666a56417c8c}{%
           family={Tabak},
           familyi={T\bibinitperiod},
           given={Esteban\bibnamedelima G.},
           giveni={E\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
        {{hash=3e3d82a14a02cda960c2d71e77f5453c}{%
           family={Vanden-Eijnden},
           familyi={V\bibinithyphendelim E\bibinitperiod},
           given={Eric},
           giveni={E\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {International Press of Boston}%
      }
      \strng{namehash}{52db3eee3ca600647a2b5dffe04474b7}
      \strng{fullhash}{52db3eee3ca600647a2b5dffe04474b7}
      \strng{bibnamehash}{52db3eee3ca600647a2b5dffe04474b7}
      \strng{authorbibnamehash}{52db3eee3ca600647a2b5dffe04474b7}
      \strng{authornamehash}{52db3eee3ca600647a2b5dffe04474b7}
      \strng{authorfullhash}{52db3eee3ca600647a2b5dffe04474b7}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Communications in Mathematical Sciences}
      \field{number}{1}
      \field{title}{Density estimation by dual ascent of the log-likelihood}
      \field{volume}{8}
      \field{year}{2010}
      \field{pages}{217\bibrangedash 233}
      \range{pages}{17}
    \endentry
    \entry{tang2022leveraging}{article}{}
      \name{author}{5}{}{%
        {{hash=50889f5aac8da12e1295e96762dd1062}{%
           family={Tang},
           familyi={T\bibinitperiod},
           given={Shengpu},
           giveni={S\bibinitperiod}}}%
        {{hash=a4b49a67c748fdc4b51f460a586cf03a}{%
           family={Makar},
           familyi={M\bibinitperiod},
           given={Maggie},
           giveni={M\bibinitperiod}}}%
        {{hash=cc627efb66a1bdfdb23b315bb7f81307}{%
           family={Sjoding},
           familyi={S\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=b01a5e92cd39a5551d74ab2393c7b9fd}{%
           family={Doshi-Velez},
           familyi={D\bibinithyphendelim V\bibinitperiod},
           given={Finale},
           giveni={F\bibinitperiod}}}%
        {{hash=cb8509d588fc0fc5f051b14ffed83827}{%
           family={Wiens},
           familyi={W\bibinitperiod},
           given={Jenna},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{ec0e2d0c31e46d780d872b19de5b6f0e}
      \strng{fullhash}{dd88f1ac625196840e4612d30a33094e}
      \strng{bibnamehash}{ec0e2d0c31e46d780d872b19de5b6f0e}
      \strng{authorbibnamehash}{ec0e2d0c31e46d780d872b19de5b6f0e}
      \strng{authornamehash}{ec0e2d0c31e46d780d872b19de5b6f0e}
      \strng{authorfullhash}{dd88f1ac625196840e4612d30a33094e}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{NeurIPS}
      \field{title}{Leveraging factored action spaces for efficient offline reinforcement learning in healthcare}
      \field{year}{2022}
    \endentry
    \entry{Tanimoto.2021}{inproceedings}{}
      \name{author}{4}{}{%
        {{hash=d6776528de1e122ff12bb1b2dd2a315f}{%
           family={Tanimoto},
           familyi={T\bibinitperiod},
           given={Akira},
           giveni={A\bibinitperiod}}}%
        {{hash=8e9dd109734c023fd3b4383387c05fb3}{%
           family={Sakai},
           familyi={S\bibinitperiod},
           given={Tomoya},
           giveni={T\bibinitperiod}}}%
        {{hash=d3bb74bf1540a6cfcc7e9470e03dbf4f}{%
           family={Takenouchi},
           familyi={T\bibinitperiod},
           given={Takashi},
           giveni={T\bibinitperiod}}}%
        {{hash=32fc6ae468e6012f7822868c12d9c044}{%
           family={Kashima},
           familyi={K\bibinitperiod},
           given={Hisashi},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{7d9864c858e774f96ff10e0a34657716}
      \strng{fullhash}{b95e1279239a2c740e937e52030bd38e}
      \strng{bibnamehash}{7d9864c858e774f96ff10e0a34657716}
      \strng{authorbibnamehash}{7d9864c858e774f96ff10e0a34657716}
      \strng{authornamehash}{7d9864c858e774f96ff10e0a34657716}
      \strng{authorfullhash}{b95e1279239a2c740e937e52030bd38e}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Predicting which action (treatment) will lead to a better outcome is a central task in decision support systems. To build a prediction model in real situations, learning from biased observational data is a critical issue due to the lack of randomized controlled trial (RCT) data. To handle such biased observational data, recent efforts in causal inference and counterfactual machine learning have focused on debiased estimation of the potential outcomes on a binary action space and the difference between them, namely, the individual treatment effect. When it comes to a large action space (e.g., selecting an appropriate combination of medicines for a patient), however, the regression accuracy of the potential outcomes is no longer sufficient in practical terms to achieve a good decision-making performance. This is because the mean accuracy on the large action space does not guarantee the nonexistence of a single potential outcome misestimation that might mislead the whole decision. Our proposed loss minimizes a classification error of whether or not the action is relatively good for the individual target among all feasible actions, which further improves the decision-making performance, as we prove. We also propose a network architecture and a regularizer that extracts a debiased representation not only from the individual feature but also from the biased action for better generalization in large action spaces. Extensive experiments on synthetic and semi-synthetic datasets demonstrate the superiority of our method for large combinatorial action spaces.}
      \field{booktitle}{{AISTATS}}
      \field{title}{{Regret Minimization for Causal Inference on Large Treatment Space}}
      \field{year}{2021}
      \verb{file}
      \verb Tanimoto, Sakai et al. 10 06 2020 - Regret Minimization for Causal Inference:Attachments/Tanimoto, Sakai et al. 10 06 2020 - Regret Minimization for Causal Inference.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/pdf/2006.05616
      \endverb
      \verb{url}
      \verb https://arxiv.org/pdf/2006.05616
      \endverb
    \endentry
    \entry{Thomas.2016}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=59807865ce69da5c4abf72570ae28284}{%
           family={Thomas},
           familyi={T\bibinitperiod},
           given={Phillip\bibnamedelima S.},
           giveni={P\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=d94fdf38ad71e8210b4505c8fbb7fa87}{%
           family={Brunskill},
           familyi={B\bibinitperiod},
           given={Emma},
           giveni={E\bibinitperiod}}}%
      }
      \strng{namehash}{1ab389068917a5ae596fb82af6e0f9fd}
      \strng{fullhash}{1ab389068917a5ae596fb82af6e0f9fd}
      \strng{bibnamehash}{1ab389068917a5ae596fb82af6e0f9fd}
      \strng{authorbibnamehash}{1ab389068917a5ae596fb82af6e0f9fd}
      \strng{authornamehash}{1ab389068917a5ae596fb82af6e0f9fd}
      \strng{authorfullhash}{1ab389068917a5ae596fb82af6e0f9fd}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Proceedings of the International Conference on Machine Learning 2016}
      \field{booktitle}{{ICML}}
      \field{title}{{Data-efficient off-Policy policy evaluation for reinforcement Learning}}
      \field{year}{2016}
      \verb{file}
      \verb thomasa16:Attachments/thomasa16.pdf:application/pdf
      \endverb
      \keyw{complex return;MAGIC estimator;MMSE return;off-policy;policy evaluation;Reinforcement Learning}
    \endentry
    \entry{trippe2018conditional}{article}{}
      \name{author}{2}{}{%
        {{hash=cb0c02f02b51e0664b454842f0fc8a12}{%
           family={Trippe},
           familyi={T\bibinitperiod},
           given={Brian\bibnamedelima L.},
           giveni={B\bibinitperiod\bibinitdelim L\bibinitperiod}}}%
        {{hash=50bb1da31125197be3166f9bee1ed0ef}{%
           family={Turner},
           familyi={T\bibinitperiod},
           given={Richard\bibnamedelima E.},
           giveni={R\bibinitperiod\bibinitdelim E\bibinitperiod}}}%
      }
      \strng{namehash}{9fe0b7ff714317e440b3ceb364d64746}
      \strng{fullhash}{9fe0b7ff714317e440b3ceb364d64746}
      \strng{bibnamehash}{9fe0b7ff714317e440b3ceb364d64746}
      \strng{authorbibnamehash}{9fe0b7ff714317e440b3ceb364d64746}
      \strng{authornamehash}{9fe0b7ff714317e440b3ceb364d64746}
      \strng{authorfullhash}{9fe0b7ff714317e440b3ceb364d64746}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{arXiv preprint arXiv:1802.04908}
      \field{title}{Conditional density estimation with {Bayesian} normalising flows}
      \field{year}{2018}
    \endentry
    \entry{Tschernutter.2022}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=896d2fff81615ea74a0e4a2856da8df6}{%
           family={Tschernutter},
           familyi={T\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=31caa17115fb0437a5cce78c102b1058}{%
           family={Hatt},
           familyi={H\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod}}}%
        {{hash=d276dae900e4bb8a8a125633e0277484}{%
           family={Feuerriegel},
           familyi={F\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{0dc8415162f45b51428912f138c93bed}
      \strng{fullhash}{0dc8415162f45b51428912f138c93bed}
      \strng{bibnamehash}{0dc8415162f45b51428912f138c93bed}
      \strng{authorbibnamehash}{0dc8415162f45b51428912f138c93bed}
      \strng{authornamehash}{0dc8415162f45b51428912f138c93bed}
      \strng{authorfullhash}{0dc8415162f45b51428912f138c93bed}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Personalized treatment decisions have become an integral part of modern medicine. Thereby, the aim is to make treatment decisions based on individual patient characteristics. Numerous methods have been developed for learning such policies from observational data that achieve the best outcome across a certain policy class. Yet these methods are rarely interpretable. However, interpretability is often a prerequisite for policy learning in clinical practice. In this paper, we propose an algorithm for interpretable off-policy learning via hyperbox search. In particular, our policies can be represented in disjunctive normal form (i.e., OR-of-ANDs) and are thus intelligible. We prove a universal approximation theorem that shows that our policy class is flexible enough to approximate any measurable function arbitrarily well. For optimization, we develop a tailored column generation procedure within a branch-and-bound framework. Using a simulation study, we demonstrate that our algorithm outperforms state-of-the-art methods from interpretable off-policy learning in terms of regret. Using real-word clinical data, we perform a user study with actual clinical experts, who rate our policies as highly interpretable.}
      \field{booktitle}{{ICML}}
      \field{title}{{Interpretable off-policy learning via hyperbox search}}
      \field{year}{2022}
      \verb{file}
      \verb 2203.02473:Attachments/2203.02473.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/pdf/2203.02473v1
      \endverb
      \verb{url}
      \verb http://arxiv.org/pdf/2203.02473v1
      \endverb
      \keyw{Computer Science - Learning;Statistics - Machine Learning}
    \endentry
    \entry{wang2022generalization}{inproceedings}{}
      \name{author}{5}{}{%
        {{hash=03d3e23852937fa39b0e34246c4ecd1d}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Xin},
           giveni={X\bibinitperiod}}}%
        {{hash=c0db666d405134a949d0ac886d8d99be}{%
           family={Lyu},
           familyi={L\bibinitperiod},
           given={Shengfei},
           giveni={S\bibinitperiod}}}%
        {{hash=088e53819b106c761df22b7d2457827e}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Xingyu},
           giveni={X\bibinitperiod}}}%
        {{hash=67026dda42a3f4e378c02a75ea2cca4d}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Tianhao},
           giveni={T\bibinitperiod}}}%
        {{hash=cd9aa9896cc4766d04243e238db91722}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Huanhuan},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{aeaae95a3851acdb0d7c761eee05b973}
      \strng{fullhash}{e94c96436f659e232cef981b4306bf30}
      \strng{bibnamehash}{aeaae95a3851acdb0d7c761eee05b973}
      \strng{authorbibnamehash}{aeaae95a3851acdb0d7c761eee05b973}
      \strng{authornamehash}{aeaae95a3851acdb0d7c761eee05b973}
      \strng{authorfullhash}{e94c96436f659e232cef981b4306bf30}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{NeurIPS}
      \field{title}{Generalization bounds for estimating causal effects of continuous treatments}
      \field{year}{2022}
    \endentry
    \entry{Wang.2019}{article}{}
      \name{author}{2}{}{%
        {{hash=b5179f4fd218803a34ae8dc7a90f2755}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yixin},
           giveni={Y\bibinitperiod}}}%
        {{hash=108998f0d44d4dce8ccb93e4d78cd5c6}{%
           family={Blei},
           familyi={B\bibinitperiod},
           given={David\bibnamedelima M.},
           giveni={D\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{c3d4ade29726f1a2a4480b1653636673}
      \strng{fullhash}{c3d4ade29726f1a2a4480b1653636673}
      \strng{bibnamehash}{c3d4ade29726f1a2a4480b1653636673}
      \strng{authorbibnamehash}{c3d4ade29726f1a2a4480b1653636673}
      \strng{authornamehash}{c3d4ade29726f1a2a4480b1653636673}
      \strng{authorfullhash}{c3d4ade29726f1a2a4480b1653636673}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Causal inference from observational data is a vital problem, but it comes with strong assumptions. Most methods assume that we observe all confounders, variables that affect both the causal variabl...}
      \field{journaltitle}{{Journal of the American Statistical Association}}
      \field{number}{528}
      \field{title}{{The blessings of multiple causes}}
      \field{volume}{114}
      \field{year}{2019}
      \field{pages}{1574\bibrangedash 1596}
      \range{pages}{23}
      \verb{doi}
      \verb 10.1080/01621459.2019.1686987
      \endverb
      \verb{file}
      \verb Wang, Blei 2019 - The Blessings of Multiple Causes:Attachments/Wang, Blei 2019 - The Blessings of Multiple Causes.pdf:application/pdf
      \endverb
    \endentry
    \entry{Weinstein.2013}{article}{}
      \name{author}{9}{}{%
        {{hash=bfb9fb87fdc1acda81be3972c94d2741}{%
           family={Weinstein},
           familyi={W\bibinitperiod},
           given={John\bibnamedelima N.},
           giveni={J\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=5a09409317ee17da361c1144b0e6766d}{%
           family={Collisson},
           familyi={C\bibinitperiod},
           given={Eric\bibnamedelima A.},
           giveni={E\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=9d783423e5e5cf74c5f3844bc1e22034}{%
           family={Mills},
           familyi={M\bibinitperiod},
           given={Gordon\bibnamedelima B.},
           giveni={G\bibinitperiod\bibinitdelim B\bibinitperiod}}}%
        {{hash=53f4d1ae2de08bf5c0f40f486c74d1bb}{%
           family={Shaw},
           familyi={S\bibinitperiod},
           given={Kenna\bibnamedelimb R.\bibnamedelimi Mills},
           giveni={K\bibinitperiod\bibinitdelim R\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=8daeacda23025641ce254c319c3125c3}{%
           family={Ozenberger},
           familyi={O\bibinitperiod},
           given={Brad\bibnamedelima A.},
           giveni={B\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=e0309c9be128cb6cb7b594e0671a94ed}{%
           family={Ellrott},
           familyi={E\bibinitperiod},
           given={Kyle},
           giveni={K\bibinitperiod}}}%
        {{hash=1c6fa0c8cdc26d21c367f71fa52d26ea}{%
           family={Shmulevich},
           familyi={S\bibinitperiod},
           given={Ilya},
           giveni={I\bibinitperiod}}}%
        {{hash=f99a580afe584be129acd1f9193dc0cd}{%
           family={Sander},
           familyi={S\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod}}}%
        {{hash=17bb8010dce01d3f67b41e65d65b714b}{%
           family={Stuart},
           familyi={S\bibinitperiod},
           given={Joshua\bibnamedelima M.},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
      }
      \strng{namehash}{54bda897414a877c3129ee2578a9a305}
      \strng{fullhash}{ccbe98ca591a55b11424c53b0097c016}
      \strng{bibnamehash}{54bda897414a877c3129ee2578a9a305}
      \strng{authorbibnamehash}{54bda897414a877c3129ee2578a9a305}
      \strng{authornamehash}{54bda897414a877c3129ee2578a9a305}
      \strng{authorfullhash}{ccbe98ca591a55b11424c53b0097c016}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The Cancer Genome Atlas (TCGA) Research Network has profiled and analyzed large numbers of human tumors to discover molecular aberrations at the DNA, RNA, protein and epigenetic levels. The resulting rich data provide a major opportunity to develop an integrated picture of commonalities, differences and emergent themes across tumor lineages. The Pan-Cancer initiative compares the first 12 tumor types profiled by TCGA. Analysis of the molecular aberrations and their functional roles across tumor types will teach us how to extend therapies effective in one cancer type to others with a similar genomic profile.}
      \field{journaltitle}{{Nature Genetics}}
      \field{number}{10}
      \field{title}{{The Cancer Genome Atlas Pan-Cancer analysis project}}
      \field{volume}{45}
      \field{year}{2013}
      \field{pages}{1113\bibrangedash 1120}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1038/ng.2764
      \endverb
      \verb{file}
      \verb Weinstein, Collisson et al. 2013 - The Cancer Genome Atlas Pan-Cancer (2):Attachments/Weinstein, Collisson et al. 2013 - The Cancer Genome Atlas Pan-Cancer (2).pdf:application/pdf;Weinstein, Collisson et al. 2013 - The Cancer Genome Atlas Pan-Cancer (3):Attachments/Weinstein, Collisson et al. 2013 - The Cancer Genome Atlas Pan-Cancer (3).pdf:application/pdf;Weinstein, Collisson et al. 2013 - The Cancer Genome Atlas Pan-Cancer:Attachments/Weinstein, Collisson et al. 2013 - The Cancer Genome Atlas Pan-Cancer.pdf:application/pdf
      \endverb
    \endentry
    \entry{winkler2019learning}{article}{}
      \name{author}{4}{}{%
        {{hash=ba81b56eedb73baf8d2bcd6b758dffd0}{%
           family={Winkler},
           familyi={W\bibinitperiod},
           given={Christina},
           giveni={C\bibinitperiod}}}%
        {{hash=3992d9b130c5891a53b5f0bb2a9b1992}{%
           family={Worrall},
           familyi={W\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod}}}%
        {{hash=3217062971cd751f410c7479cd9c280a}{%
           family={Hoogeboom},
           familyi={H\bibinitperiod},
           given={Emiel},
           giveni={E\bibinitperiod}}}%
        {{hash=53d2880ad8047b61cdae2c6b2803e763}{%
           family={Welling},
           familyi={W\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{9ce864eda6d319f1a35bcab18bdf4f5b}
      \strng{fullhash}{1c708e129c077faf75583150e58c0def}
      \strng{bibnamehash}{9ce864eda6d319f1a35bcab18bdf4f5b}
      \strng{authorbibnamehash}{9ce864eda6d319f1a35bcab18bdf4f5b}
      \strng{authornamehash}{9ce864eda6d319f1a35bcab18bdf4f5b}
      \strng{authorfullhash}{1c708e129c077faf75583150e58c0def}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{arXiv preprint arXiv:1912.00042}
      \field{title}{Learning likelihoods with conditional normalizing flows}
      \field{year}{2019}
    \endentry
    \entry{Wood.2006}{article}{}
      \name{author}{1}{}{%
        {{hash=4f816a96f8d000d6cb78dea6a1f2da1d}{%
           family={Wood},
           familyi={W\bibinitperiod},
           given={Simon\bibnamedelima N.},
           giveni={S\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
      }
      \strng{namehash}{4f816a96f8d000d6cb78dea6a1f2da1d}
      \strng{fullhash}{4f816a96f8d000d6cb78dea6a1f2da1d}
      \strng{bibnamehash}{4f816a96f8d000d6cb78dea6a1f2da1d}
      \strng{authorbibnamehash}{4f816a96f8d000d6cb78dea6a1f2da1d}
      \strng{authornamehash}{4f816a96f8d000d6cb78dea6a1f2da1d}
      \strng{authorfullhash}{4f816a96f8d000d6cb78dea6a1f2da1d}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A general method for constructing low-rank tensor product smooths for use as components of generalized additive models or generalized additive mixed models is presented. A penalized regression approach is adopted in which tensor product smooths of several variables are constructed from smooths of each variable separately, these {"}marginal{"} smooths being represented using a low-rank basis with an associated quadratic wiggliness penalty. The smooths offer several advantages: (i) they have one wiggliness penalty per covariate and are hence invariant to linear rescaling of covariates, making them useful when there is no {"}natural{"} way to scale covariates relative to each other; (ii) they have a useful tuneable range of smoothness, unlike single-penalty tensor product smooths that are scale invariant; (iii) the relatively low rank of the smooths means that they are computationally efficient; (iv) the penalties on the smooths are easily interpretable in terms of function shape; (v) the smooths can be generated completely automatically from any marginal smoothing bases and associated quadratic penalties, giving the modeler considerable flexibility to choose the basis penalty combination most appropriate to each modeling task; and (vi) the smooths can easily be written as components of a standard linear or generalized linear mixed model, allowing them to be used as components of the rich family of such models implemented in standard software, and to take advantage of the efficient and stable computational methods that have been developed for such models. A small simulation study shows that the methods can compare favorably with recently developed smoothing spline ANOVA methods.}
      \field{issn}{0006-341X}
      \field{journaltitle}{{Biometrics}}
      \field{number}{4}
      \field{title}{{Low-rank scale-invariant tensor product smooths for generalized additive mixed models}}
      \field{volume}{62}
      \field{year}{2006}
      \field{pages}{1025\bibrangedash 1036}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1111/j.1541-0420.2006.00574.x
      \endverb
      \verb{file}
      \verb Wood 2006 - Low-rank scale-invariant tensor product smooths:Attachments/Wood 2006 - Low-rank scale-invariant tensor product smooths.pdf:application/pdf
      \endverb
    \endentry
    \entry{Wu.2020b}{article}{}
      \name{author}{8}{}{%
        {{hash=ce0f3e0835eb0c449fc8c9411b76a30a}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Debra},
           giveni={D\bibinitperiod}}}%
        {{hash=315873e1d0ae30d5c03e978209f23ccb}{%
           family={Pusuluri},
           familyi={P\bibinitperiod},
           given={Anusha},
           giveni={A\bibinitperiod}}}%
        {{hash=d910a107b7a9a7fd6bc129f7fb9ff46d}{%
           family={Vogus},
           familyi={V\bibinitperiod},
           given={Douglas},
           giveni={D\bibinitperiod}}}%
        {{hash=147254597d8e055108a62045fac51df4}{%
           family={Krishnan},
           familyi={K\bibinitperiod},
           given={Vinu},
           giveni={V\bibinitperiod}}}%
        {{hash=0152cf808ed9e136222d07c00805f225}{%
           family={Shields},
           familyi={S\bibinitperiod},
           given={C.\bibnamedelimi Wyatt},
           giveni={C\bibinitperiod\bibinitdelim W\bibinitperiod}}}%
        {{hash=ec6aa8206b895fea12fba311632c018f}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Jayoung},
           giveni={J\bibinitperiod}}}%
        {{hash=d863839158980cdd2edbd2c620d1c22c}{%
           family={Razmi},
           familyi={R\bibinitperiod},
           given={Amaya},
           giveni={A\bibinitperiod}}}%
        {{hash=b544c80433815882f5782e911933412d}{%
           family={Mitragotri},
           familyi={M\bibinitperiod},
           given={Samir},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{385847ecdde0629eb32e462546c55748}
      \strng{fullhash}{90bb3a3e63a9ffada591460fa13a78a6}
      \strng{bibnamehash}{385847ecdde0629eb32e462546c55748}
      \strng{authorbibnamehash}{385847ecdde0629eb32e462546c55748}
      \strng{authornamehash}{385847ecdde0629eb32e462546c55748}
      \strng{authorfullhash}{90bb3a3e63a9ffada591460fa13a78a6}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Combination chemotherapy is the leading clinical option for cancer treatment. The current approach to designing drug combinations includes in vitro optimization to maximize drug cytotoxicity and/or synergistic drug interactions. However, in vivo translatability of drug combinations is complicated by the disparities in drug pharmacokinetics and activity. In vitro cellular assays also fail to represent the immune response that can be amplified by chemotherapy when dosed appropriately. Using three common chemotherapeutic drugs, gemcitabine (GEM), irinotecan (IRIN), and a prodrug form of 5-flurouracil (5FURW), paired with another common drug and immunogenic cell death inducing agent, doxorubicin (DOX), we sought to determine the in vitro parameters that predict the in vivo outcomes of drug combinations in the highly aggressive orthotopic 4T1 murine breast cancer model. With liposomal encapsulation of each drug pair, we enabled uniform drug pharmacokinetics across the drug combinations, thus allowing us to study the inherent benefits of the drug pairs and compare them to DOX liposomes representative of DOXIL{\circledR}. Surprisingly, the Hill coefficient (HC) of the in vitro dose-response Hill equation provided a better prediction of in vivo efficacy than drug IC50 or combination index. GEM/DOX liposomes exhibited a high HC in vitro and an increase in M1/M2 macrophage ratio in vivo. Hence, GEM/DOX liposomes were further investigated in a long-term survival study and compared against doxorubicin liposomes and gemcitabine liposomes. The GEM/DOX liposome-treated group had the longest median survival time, double that of the DOX liposome-treated group and 3.4-fold greater than that of the untreated controls. Our studies outline the development of a more efficacious formulation than clinically representative liposomal doxorubicin for breast cancer treatment and presents a novel strategy for designing cancer drug combinations.}
      \field{issn}{1873-4995}
      \field{journaltitle}{{Journal of Controlled Release}}
      \field{title}{{Design principles of drug combinations for chemotherapy}}
      \field{volume}{323}
      \field{year}{2020}
      \field{pages}{36\bibrangedash 46}
      \range{pages}{11}
      \verb{doi}
      \verb 10.1016/j. jconrel.2020.04.018
      \endverb
      \verb{urlraw}
      \verb https://pubmed.ncbi.nlm.nih.gov/32283210/
      \endverb
      \verb{url}
      \verb https://pubmed.ncbi.nlm.nih.gov/32283210/
      \endverb
    \endentry
    \entry{Xu.2021}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=84b93e60627709c126d74a9bea7c8c68}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Liyuan},
           giveni={L\bibinitperiod}}}%
        {{hash=5759ff4990bdd8c6f85835738834874a}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Yutian},
           giveni={Y\bibinitperiod}}}%
        {{hash=15fb6a4ca073a56053b2d24dcf72557b}{%
           family={Srinivasan},
           familyi={S\bibinitperiod},
           given={Siddarth},
           giveni={S\bibinitperiod}}}%
        {{hash=cf269f9a5106a41ad53847a68a27db1c}{%
           family={Freitas},
           familyi={F\bibinitperiod},
           given={Nando\bibnamedelima de},
           giveni={N\bibinitperiod\bibinitdelim d\bibinitperiod}}}%
        {{hash=aca5faad8b57b96b59c12fc59d0b6eb4}{%
           family={Doucet},
           familyi={D\bibinitperiod},
           given={Arnaud},
           giveni={A\bibinitperiod}}}%
        {{hash=1f42dc1a2d390bd84511cbccb6397013}{%
           family={Gretton},
           familyi={G\bibinitperiod},
           given={Arthur},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{b4743eae6392f3949844c5b390be7dba}
      \strng{fullhash}{075865a34aa50eb1b614476368e67cb0}
      \strng{bibnamehash}{b4743eae6392f3949844c5b390be7dba}
      \strng{authorbibnamehash}{b4743eae6392f3949844c5b390be7dba}
      \strng{authornamehash}{b4743eae6392f3949844c5b390be7dba}
      \strng{authorfullhash}{075865a34aa50eb1b614476368e67cb0}
      \field{sortinit}{X}
      \field{sortinithash}{1965c258adceecf23ce3d67b05113442}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Instrumental variable (IV) regression is a standard strategy for learning causal relationships between confounded treatment and outcome variables from observational data by utilizing an instrumental variable, which affects the outcome only through the treatment. In classical IV regression, learning proceeds in two stages: stage 1 performs linear regression from the instrument to the treatment; and stage 2 performs linear regression from the treatment to the outcome, conditioned on the instrument. We propose a novel method, deep feature instrumental variable regression (DFIV), to address the case where relations between instruments, treatments, and outcomes may be nonlinear. In this case, deep neural nets are trained to define informative nonlinear features on the instruments and treatments. We propose an alternating training regime for these features to ensure good end-to-end performance when composing stages 1 and 2, thus obtaining highly flexible feature maps in a computationally efficient manner. DFIV outperforms recent state-of-the-art methods on challenging IV benchmarks, including settings involving high dimensional image data. DFIV also exhibits competitive performance in off-policy policy evaluation for reinforcement learning, which can be understood as an IV regression task.}
      \field{booktitle}{{ICLR}}
      \field{title}{{Learning deep features in instrumental variable regression}}
      \field{year}{2021}
      \verb{file}
      \verb learning{\_}deep{\_}features{\_}in{\_}inst:Attachments/learning{\_}deep{\_}features{\_}in{\_}inst.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/pdf/2010.07154v3
      \endverb
      \verb{url}
      \verb http://arxiv.org/pdf/2010.07154v3
      \endverb
      \keyw{Computer Science - Learning;Statistics - Machine Learning}
    \endentry
    \entry{Zhang.2020}{inproceedings}{}
      \name{author}{3}{}{%
        {{hash=047f7de07364289ade5035d665f1c939}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Yao},
           giveni={Y\bibinitperiod}}}%
        {{hash=7b5fda20efafe886a32847418d6f7035}{%
           family={Bellot},
           familyi={B\bibinitperiod},
           given={Alexis},
           giveni={A\bibinitperiod}}}%
        {{hash=d44f2d413b2e6dcde01be4d1392763dd}{%
           family={{van der Schaar}},
           familyi={v\bibinitperiod},
           given={Mihaela},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{997c5f7a92f95a2faf9050195988f6a7}
      \strng{fullhash}{997c5f7a92f95a2faf9050195988f6a7}
      \strng{bibnamehash}{997c5f7a92f95a2faf9050195988f6a7}
      \strng{authorbibnamehash}{997c5f7a92f95a2faf9050195988f6a7}
      \strng{authornamehash}{997c5f7a92f95a2faf9050195988f6a7}
      \strng{authorfullhash}{997c5f7a92f95a2faf9050195988f6a7}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The choice of making an intervention depends on its potential benefit or harm in comparison to alternatives. Estimating the likely outcome of alternatives from observational data is a challenging problem as all outcomes are never observed, and selection bias precludes the direct comparison of differently intervened groups. Despite their empirical success, we show that algorithms that learn domain-invariant representations of inputs (on which to make predictions) are often inappropriate, and develop generalization bounds that demonstrate the dependence on domain overlap and highlight the need for invertible latent maps. Based on these results, we develop a deep kernel regression algorithm and posterior regularization framework that substantially outperforms the state-of-the-art on a variety of benchmarks data sets.}
      \field{booktitle}{{AISTATS}}
      \field{title}{{Learning overlapping representations for the estimation of individualized treatment effects}}
      \field{year}{2020}
      \verb{file}
      \verb Learning Overlapping Representations:Attachments/Learning Overlapping Representations.pdf:application/pdf
      \endverb
      \keyw{Computer Science - Learning;Statistics - Machine Learning}
    \endentry
    \entry{Zhou.2023}{article}{}
      \name{author}{3}{}{%
        {{hash=92bcf64f6a434d65d69d4718e65a964b}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Zhengyuan},
           giveni={Z\bibinitperiod}}}%
        {{hash=cab7b4f39472e6c01dc0fc30a32c6d89}{%
           family={Athey},
           familyi={A\bibinitperiod},
           given={Susan},
           giveni={S\bibinitperiod}}}%
        {{hash=e22c2c3bb1bd12e43f46c07ea788b581}{%
           family={Wager},
           familyi={W\bibinitperiod},
           given={Stefan},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{fc2692715a99bff142b0d4d94ca75c37}
      \strng{fullhash}{fc2692715a99bff142b0d4d94ca75c37}
      \strng{bibnamehash}{fc2692715a99bff142b0d4d94ca75c37}
      \strng{authorbibnamehash}{fc2692715a99bff142b0d4d94ca75c37}
      \strng{authornamehash}{fc2692715a99bff142b0d4d94ca75c37}
      \strng{authorfullhash}{fc2692715a99bff142b0d4d94ca75c37}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{{Operations Research}}
      \field{number}{1}
      \field{title}{{Offline Multi-Action Policy Learning: Generalization and Optimization}}
      \field{volume}{71}
      \field{year}{2023}
      \field{pages}{148\bibrangedash 183}
      \range{pages}{36}
      \verb{doi}
      \verb 10.1287/opre.2022.2271
      \endverb
      \verb{file}
      \verb Zhou, Athey et al. 2023 - Offline Multi-Action Policy Learning:Attachments/Zhou, Athey et al. 2023 - Offline Multi-Action Policy Learning.pdf:application/pdf
      \endverb
    \endentry
    \entry{Zou.2020}{inproceedings}{}
      \name{author}{7}{}{%
        {{hash=c540868e508473b686f56dced3df80d1}{%
           family={Zou},
           familyi={Z\bibinitperiod},
           given={Hao},
           giveni={H\bibinitperiod}}}%
        {{hash=a79e6a0454388fc3ede42ca69f997534}{%
           family={Cui},
           familyi={C\bibinitperiod},
           given={Peng},
           giveni={P\bibinitperiod}}}%
        {{hash=a9c8728e355996d027a7e56b60820a18}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Bo},
           giveni={B\bibinitperiod}}}%
        {{hash=5f94383059a327066beb096afeb94178}{%
           family={Shen},
           familyi={S\bibinitperiod},
           given={Zheyan},
           giveni={Z\bibinitperiod}}}%
        {{hash=189271c303cc0ae86ae56717bdff7b8e}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Jianxin},
           giveni={J\bibinitperiod}}}%
        {{hash=d6d4a344c3ae687de4e4e9f6be05c6ed}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Hongxia},
           giveni={H\bibinitperiod}}}%
        {{hash=f6648a93c3d6946f7060dcb19132404c}{%
           family={He},
           familyi={H\bibinitperiod},
           given={Yue},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{0922239116b2e6e16729600f92e838b8}
      \strng{fullhash}{315837f10da81f214d6b4f41c04bb748}
      \strng{bibnamehash}{0922239116b2e6e16729600f92e838b8}
      \strng{authorbibnamehash}{0922239116b2e6e16729600f92e838b8}
      \strng{authornamehash}{0922239116b2e6e16729600f92e838b8}
      \strng{authorfullhash}{315837f10da81f214d6b4f41c04bb748}
      \field{extraname}{1}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{{NeurIPS}}
      \field{title}{Counterfactual prediction for bundle treatment}
      \field{volume}{33}
      \field{year}{2020}
      \verb{file}
      \verb Zou, Cui et al. 2020 - Counterfactual Prediction for Bundle Treatment:Attachments/Zou, Cui et al. 2020 - Counterfactual Prediction for Bundle Treatment.pdf:application/pdf
      \endverb
    \endentry
    \entry{Zou.2022}{inproceedings}{}
      \name{author}{6}{}{%
        {{hash=c540868e508473b686f56dced3df80d1}{%
           family={Zou},
           familyi={Z\bibinitperiod},
           given={Hao},
           giveni={H\bibinitperiod}}}%
        {{hash=a9c8728e355996d027a7e56b60820a18}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Bo},
           giveni={B\bibinitperiod}}}%
        {{hash=18254247a377b817467b990f8e023567}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Jiangang},
           giveni={J\bibinitperiod}}}%
        {{hash=c654b42c9a41e666c02787745228bbd0}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Shuiping},
           giveni={S\bibinitperiod}}}%
        {{hash=918ece85faaac17dc93511a1cdc9de89}{%
           family={Ding},
           familyi={D\bibinitperiod},
           given={Xuetao},
           giveni={X\bibinitperiod}}}%
        {{hash=a79e6a0454388fc3ede42ca69f997534}{%
           family={Cui},
           familyi={C\bibinitperiod},
           given={Peng},
           giveni={P\bibinitperiod}}}%
      }
      \strng{namehash}{0922239116b2e6e16729600f92e838b8}
      \strng{fullhash}{c544bbc9aeb813ae94c1e020f9a12a49}
      \strng{bibnamehash}{0922239116b2e6e16729600f92e838b8}
      \strng{authorbibnamehash}{0922239116b2e6e16729600f92e838b8}
      \strng{authornamehash}{0922239116b2e6e16729600f92e838b8}
      \strng{authorfullhash}{c544bbc9aeb813ae94c1e020f9a12a49}
      \field{extraname}{2}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Proceedings of the International Conference on Machine Learning 2022}
      \field{booktitle}{{ICML}}
      \field{title}{{Counterfactual prediction for outcome-oriented treatments}}
      \field{year}{2022}
      \verb{file}
      \verb zou22a:Attachments/zou22a.pdf:application/pdf
      \endverb
    \endentry
  \enddatalist
\endrefsection
\endinput

