\begin{thebibliography}{10}

\bibitem{agarwal2021deep}
Rishabh Agarwal, Max Schwarzer, Pablo~Samuel Castro, Aaron~C Courville, and Marc Bellemare.
\newblock Deep reinforcement learning at the edge of the statistical precipice.
\newblock In {\em Advances in neural information processing systems}, 2021.

\bibitem{ajay2023is}
Anurag Ajay, Yilun Du, Abhi Gupta, Joshua~B. Tenenbaum, Tommi~S. Jaakkola, and Pulkit Agrawal.
\newblock Is conditional generative modeling all you need for decision making?
\newblock In {\em International Conference on Learning Representations}, 2023.

\bibitem{baker2022video}
Bowen Baker, Ilge Akkaya, Peter Zhokov, Joost Huizinga, Jie Tang, Adrien Ecoffet, Brandon Houghton, Raul Sampedro, and Jeff Clune.
\newblock Video pretraining (vpt): Learning to act by watching unlabeled online videos.
\newblock In {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{bao2021beit}
Hangbo Bao, Li~Dong, and Furu Wei.
\newblock Beit: Bert pre-training of image transformers.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{bellemare2013arcade}
Marc~G Bellemare, Yavar Naddaf, Joel Veness, and Michael Bowling.
\newblock The arcade learning environment: An evaluation platform for general agents.
\newblock {\em Journal of Artificial Intelligence Research}, 2013.

\bibitem{bhargava2023sequence}
Prajjwal Bhargava, Rohan Chitnis, Alborz Geramifard, Shagun Sodhani, and Amy Zhang.
\newblock Sequence modeling is a robust contender for offline reinforcement learning.
\newblock {\em arXiv preprint arXiv:2305.14550}, 2023.

\bibitem{brandfonbrener2022when}
David Brandfonbrener, Alberto Bietti, Jacob Buckman, Romain Laroche, and Joan Bruna.
\newblock When does return-conditioned supervised learning work for offline reinforcement learning?
\newblock In {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{gpt3}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock In {\em Advances in neural information processing systems}, 2020.

\bibitem{carroll2022unimask}
Micah Carroll, Orr Paradise, Jessy Lin, Raluca Georgescu, Mingfei Sun, David Bignell, Stephanie Milani, Katja Hofmann, Matthew Hausknecht, Anca Dragan, and Sam Devlin.
\newblock Uni[{MASK}]: Unified inference in sequential decision problems.
\newblock In {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{chen2021decisiontransformer}
Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock {\em arXiv preprint arXiv:2106.01345}, 2021.

\bibitem{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{ding2020mutual}
Yiming Ding, Ignasi Clavera, and Pieter Abbeel.
\newblock Mutual information maximization for robust plannable representations.
\newblock {\em arXiv preprint arXiv:2005.08114}, 2020.

\bibitem{ding2019goal}
Yiming Ding, Carlos Florensa, Pieter Abbeel, and Mariano Phielipp.
\newblock Goal-conditioned imitation learning.
\newblock In {\em Advances in neural information processing systems}, volume~32, 2019.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{emmons2022rvs}
Scott Emmons, Benjamin Eysenbach, Ilya Kostrikov, and Sergey Levine.
\newblock Rvs: What is essential for offline {RL} via supervised learning?
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{fu2020d4rl}
Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, and Sergey Levine.
\newblock D4rl: Datasets for deep data-driven reinforcement learning.
\newblock {\em arXiv preprint arXiv:2004.07219}, 2020.

\bibitem{fu2022a}
Yuwei Fu, Di~Wu, and Benoit Boulet.
\newblock A closer look at offline {RL} agents.
\newblock In {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{fujimoto2021a}
Scott Fujimoto and Shixiang Gu.
\newblock A minimalist approach to offline reinforcement learning.
\newblock In {\em Advances in Neural Information Processing Systems}, 2021.

\bibitem{furuta2021generalized}
Hiroki Furuta, Yutaka Matsuo, and Shixiang~Shane Gu.
\newblock Generalized decision transformer for offline hindsight information matching.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{ghosh2021learning}
Dibya Ghosh, Abhishek Gupta, Ashwin Reddy, Justin Fu, Coline~Manon Devin, Benjamin Eysenbach, and Sergey Levine.
\newblock Learning to reach goals via iterated supervised learning.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{ha2018world}
David Ha and J{\"u}rgen Schmidhuber.
\newblock World models.
\newblock {\em arXiv preprint arXiv:1803.10122}, 2018.

\bibitem{hafner2020mastering}
Danijar Hafner, Timothy Lillicrap, Mohammad Norouzi, and Jimmy Ba.
\newblock Mastering atari with discrete world models.
\newblock {\em arXiv preprint arXiv:2010.02193}, 2020.

\bibitem{hansen2022modem}
Nicklas Hansen, Yixin Lin, Hao Su, Xiaolong Wang, Vikash Kumar, and Aravind Rajeswaran.
\newblock Modem: Accelerating visual model-based reinforcement learning with demonstrations.
\newblock {\em arXiv preprint arXiv:2212.05698}, 2022.

\bibitem{he2022masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022.

\bibitem{pmlr-v202-hejna23a}
Joey Hejna, Jensen Gao, and Dorsa Sadigh.
\newblock Distance weighted supervised learning for offline interaction data.
\newblock In {\em Proceedings of the 40th International Conference on Machine Learning}, 2023.

\bibitem{pmlr-v162-janner22a}
Michael Janner, Yilun Du, Joshua Tenenbaum, and Sergey Levine.
\newblock Planning with diffusion for flexible behavior synthesis.
\newblock In {\em Proceedings of the 39th International Conference on Machine Learning}, 2022.

\bibitem{janner2021sequence}
Michael Janner, Qiyang Li, and Sergey Levine.
\newblock Offline reinforcement learning as one big sequence modeling problem.
\newblock In {\em Advances in Neural Information Processing Systems}, 2021.

\bibitem{jiang2023efficient}
Zhengyao jiang, Tianjun Zhang, Michael Janner, Yueying Li, Tim Rockt{\"a}schel, Edward Grefenstette, and Yuandong Tian.
\newblock Efficient planning in a compact latent action space.
\newblock In {\em International Conference on Learning Representations}, 2023.

\bibitem{kostrikov2021offline}
Ilya Kostrikov, Ashvin Nair, and Sergey Levine.
\newblock Offline reinforcement learning with implicit q-learning.
\newblock {\em arXiv preprint arXiv:2110.06169}, 2021.

\bibitem{kumar2022should}
Aviral Kumar, Joey Hong, Anikait Singh, and Sergey Levine.
\newblock Should i run offline reinforcement learning or behavioral cloning?
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{kumar2020conservative}
Aviral Kumar, Aurick Zhou, George Tucker, and Sergey Levine.
\newblock Conservative q-learning for offline reinforcement learning.
\newblock In {\em Advances in Neural Information Processing Systems}, 2020.

\bibitem{laskin2020curl}
Michael Laskin, Aravind Srinivas, and Pieter Abbeel.
\newblock Curl: Contrastive unsupervised representations for reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages 5639--5650. PMLR, 2020.

\bibitem{lee2022multigame}
Kuang-Huei Lee, Ofir Nachum, Sherry Yang, Lisa Lee, C.~Daniel Freeman, Sergio Guadarrama, Ian Fischer, Winnie Xu, Eric Jang, Henryk Michalewski, and Igor Mordatch.
\newblock Multi-game decision transformers.
\newblock In {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{liu2022masked}
Fangchen Liu, Hao Liu, Aditya Grover, and Pieter Abbeel.
\newblock Masked autoencoding for scalable and generalizable decision making.
\newblock In {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{liu2021swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted windows.
\newblock In {\em Proceedings of the IEEE/CVF international conference on computer vision}, 2021.

\bibitem{nair2022r3m}
Suraj Nair, Aravind Rajeswaran, Vikash Kumar, Chelsea Finn, and Abhinav Gupta.
\newblock R3m: A universal visual representation for robot manipulation.
\newblock {\em arXiv preprint arXiv:2203.12601}, 2022.

\bibitem{nguyen2021temporal}
Tung~D Nguyen, Rui Shu, Tuan Pham, Hung Bui, and Stefano Ermon.
\newblock Temporal predictive coding for model-based planning in latent space.
\newblock In {\em International Conference on Machine Learning}, pages 8130--8139. PMLR, 2021.

\bibitem{parisi2022unsurprising}
Simone Parisi, Aravind Rajeswaran, Senthil Purushwalkam, and Abhinav Gupta.
\newblock The unsurprising effectiveness of pre-trained vision models for control.
\newblock In {\em International Conference on Machine Learning}, pages 17359--17371. PMLR, 2022.

\bibitem{pashevich2021episodic}
Alexander Pashevich, Cordelia Schmid, and Chen Sun.
\newblock {Episodic Transformer for Vision-and-Language Navigation}.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, 2021.

\bibitem{radford2018improving}
Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et~al.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem{reed2022a}
Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio~G{\'o}mez Colmenarejo, Alexander Novikov, Gabriel Barth-maron, Mai Gim{\'e}nez, Yury Sulsky, Jackie Kay, Jost~Tobias Springenberg, Tom Eccles, Jake Bruce, Ali Razavi, Ashley Edwards, Nicolas Heess, Yutian Chen, Raia Hadsell, Oriol Vinyals, Mahyar Bordbar, and Nando de~Freitas.
\newblock A generalist agent.
\newblock {\em Transactions on Machine Learning Research}, 2022.
\newblock Featured Certification.

\bibitem{reid2022can}
Machel Reid, Yutaro Yamada, and Shixiang~Shane Gu.
\newblock Can wikipedia help offline reinforcement learning?
\newblock {\em arXiv preprint arXiv:2201.12122}, 2022.

\bibitem{ross2011reduction}
St{\'e}phane Ross, Geoffrey Gordon, and Drew Bagnell.
\newblock A reduction of imitation learning and structured prediction to no-regret online learning.
\newblock In {\em Proceedings of the fourteenth international conference on artificial intelligence and statistics}. JMLR Workshop and Conference Proceedings, 2011.

\bibitem{seo2023masked}
Younggyo Seo, Danijar Hafner, Hao Liu, Fangchen Liu, Stephen James, Kimin Lee, and Pieter Abbeel.
\newblock Masked world models for visual control.
\newblock In {\em Conference on Robot Learning}, pages 1332--1344. PMLR, 2023.

\bibitem{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em Advances in neural information processing systems}, volume~30, 2017.

\bibitem{wang2022bootstrapped}
Kerong Wang, Hanye Zhao, Xufang Luo, Kan Ren, Weinan Zhang, and Dongsheng Li.
\newblock Bootstrapped transformer for offline reinforcement learning.
\newblock In {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{wu2022supported}
Jialong Wu, Haixu Wu, Zihan Qiu, Jianmin Wang, and Mingsheng Long.
\newblock Supported policy optimization for offline reinforcement learning.
\newblock In {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{wu2023mtm}
Philipp Wu, Arjun Majumdar, Kevin Stone, Yixin Lin, Igor Mordatch, Pieter Abbeel, and Aravind Rajeswaran.
\newblock Masked trajectory models for prediction, representation, and control.
\newblock In {\em International Conference on Machine Learning}, 2023.

\bibitem{xiao2022masked}
Tete Xiao, Ilija Radosavovic, Trevor Darrell, and Jitendra Malik.
\newblock Masked visual pre-training for motor control.
\newblock {\em arXiv preprint arXiv:2203.06173}, 2022.

\bibitem{yang2021representation}
Mengjiao Yang and Ofir Nachum.
\newblock Representation matters: offline pretraining for sequential decision making.
\newblock In {\em International Conference on Machine Learning}. PMLR, 2021.

\bibitem{yang2022rethinking}
Rui Yang, Yiming Lu, Wenzhe Li, Hao Sun, Meng Fang, Yali Du, Xiu Li, Lei Han, and Chongjie Zhang.
\newblock Rethinking goal-conditioned supervised learning and its connection to offline {RL}.
\newblock In {\em International Conference on Learning Representations}, 2022.

\end{thebibliography}
