\begin{thebibliography}{25}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andrychowicz et~al.(2017)Andrychowicz, Wolski, Ray, Schneider, Fong,
  Welinder, McGrew, Tobin, Abbeel, and Zaremba]{andrychowicz2017hindsight}
Andrychowicz, Marcin, Wolski, Filip, Ray, Alex, Schneider, Jonas, Fong, Rachel,
  Welinder, Peter, McGrew, Bob, Tobin, Josh, Abbeel, OpenAI~Pieter, and
  Zaremba, Wojciech.
\newblock Hindsight experience replay.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  5048--5058, 2017.

\bibitem[Bellman(1957)]{bellman1957markovian}
Bellman, Richard.
\newblock A markovian decision process.
\newblock \emph{Journal of mathematics and mechanics}, pp.\  679--684, 1957.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{gym}
Brockman, Greg, Cheung, Vicki, Pettersson, Ludwig, Schneider, Jonas, Schulman,
  John, Tang, Jie, and Zaremba, Wojciech.
\newblock Openai gym, 2016.

\bibitem[Firoiu et~al.(2018)Firoiu, Ju, and Tenenbaum]{Firoiu2018AtHS}
Firoiu, Vlad, Ju, Tina, and Tenenbaum, Joshua~B.
\newblock At human speed: Deep reinforcement learning with action delay.
\newblock \emph{CoRR}, abs/1810.07286, 2018.

\bibitem[Fujimoto et~al.(2018)Fujimoto, van Hoof, and
  Meger]{fujimoto2018addressing}
Fujimoto, Scott, van Hoof, Herke, and Meger, David.
\newblock Addressing function approximation error in actor-critic methods.
\newblock \emph{arXiv preprint arXiv:1802.09477}, 2018.

\bibitem[Gu et~al.(2016)Gu, Lillicrap, Sutskever, and Levine]{gu2016continuous}
Gu, Shixiang, Lillicrap, Timothy, Sutskever, Ilya, and Levine, Sergey.
\newblock Continuous deep q-learning with model-based acceleration.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2829--2838, 2016.

\bibitem[Haarnoja et~al.(2018{\natexlab{a}})Haarnoja, Zhou, Abbeel, and
  Levine]{haarnoja2018soft}
Haarnoja, Tuomas, Zhou, Aurick, Abbeel, Pieter, and Levine, Sergey.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock \emph{arXiv preprint arXiv:1801.01290}, 2018{\natexlab{a}}.

\bibitem[Haarnoja et~al.(2018{\natexlab{b}})Haarnoja, Zhou, Hartikainen,
  Tucker, Ha, Tan, Kumar, Zhu, Gupta, Abbeel, et~al.]{haarnoja2018soft2}
Haarnoja, Tuomas, Zhou, Aurick, Hartikainen, Kristian, Tucker, George, Ha,
  Sehoon, Tan, Jie, Kumar, Vikash, Zhu, Henry, Gupta, Abhishek, Abbeel, Pieter,
  et~al.
\newblock Soft actor-critic algorithms and applications.
\newblock \emph{arXiv preprint arXiv:1812.05905}, 2018{\natexlab{b}}.

\bibitem[Heess et~al.(2015)Heess, Wayne, Silver, Lillicrap, Erez, and
  Tassa]{heess2015learning}
Heess, Nicolas, Wayne, Gregory, Silver, David, Lillicrap, Tim, Erez, Tom, and
  Tassa, Yuval.
\newblock Learning continuous control policies by stochastic value gradients.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2944--2952, 2015.

\bibitem[Hwangbo et~al.(2017)Hwangbo, Sa, Siegwart, and
  Hutter]{hwangbo2017control}
Hwangbo, Jemin, Sa, Inkyu, Siegwart, Roland, and Hutter, Marco.
\newblock Control of a quadrotor with reinforcement learning.
\newblock \emph{IEEE Robotics and Automation Letters}, 2\penalty0 (4):\penalty0
  2096--2103, 2017.

\bibitem[Hwangbo et~al.(2019)Hwangbo, Lee, Dosovitskiy, Bellicoso, Tsounis,
  Koltun, and Hutter]{hwangbo2019learning}
Hwangbo, Jemin, Lee, Joonho, Dosovitskiy, Alexey, Bellicoso, Dario, Tsounis,
  Vassilios, Koltun, Vladlen, and Hutter, Marco.
\newblock Learning agile and dynamic motor skills for legged robots.
\newblock \emph{Science Robotics}, 4\penalty0 (26):\penalty0 eaau5872, 2019.

\bibitem[Ibrahim et~al.(2019)Ibrahim, Ramstedt, and Pal]{ibrahim2019avenue}
Ibrahim, Cyril, Ramstedt, Simon, and Pal, Christopher.
\newblock Avenue.
\newblock \url{https://github.com/elementai/avenue}, 2019.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, Diederik~P and Ba, Jimmy.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Konda \& Tsitsiklis(2000)Konda and Tsitsiklis]{konda2000actor}
Konda, Vijay~R and Tsitsiklis, John~N.
\newblock Actor-critic algorithms.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1008--1014, 2000.

\bibitem[Lillicrap et~al.(2015)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap2015continuous}
Lillicrap, Timothy~P, Hunt, Jonathan~J, Pritzel, Alexander, Heess, Nicolas,
  Erez, Tom, Tassa, Yuval, Silver, David, and Wierstra, Daan.
\newblock Continuous control with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1509.02971}, 2015.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Mnih, Volodymyr, Kavukcuoglu, Koray, Silver, David, Rusu, Andrei~A, Veness,
  Joel, Bellemare, Marc~G, Graves, Alex, Riedmiller, Martin, Fidjeland,
  Andreas~K, Ostrovski, Georg, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529, 2015.

\bibitem[Schulman et~al.(2015)Schulman, Levine, Abbeel, Jordan, and
  Moritz]{schulman2015trust}
Schulman, John, Levine, Sergey, Abbeel, Pieter, Jordan, Michael, and Moritz,
  Philipp.
\newblock Trust region policy optimization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1889--1897, 2015.

\bibitem[Silver et~al.(2014)Silver, Lever, Heess, Degris, Wierstra, and
  Riedmiller]{silver2014deterministic}
Silver, David, Lever, Guy, Heess, Nicolas, Degris, Thomas, Wierstra, Daan, and
  Riedmiller, Martin.
\newblock Deterministic policy gradient algorithms.
\newblock In \emph{ICML}, 2014.

\bibitem[Silver et~al.(2017)Silver, Schrittwieser, Simonyan, Antonoglou, Huang,
  Guez, Hubert, Baker, Lai, Bolton, et~al.]{silver2017mastering}
Silver, David, Schrittwieser, Julian, Simonyan, Karen, Antonoglou, Ioannis,
  Huang, Aja, Guez, Arthur, Hubert, Thomas, Baker, Lucas, Lai, Matthew, Bolton,
  Adrian, et~al.
\newblock Mastering the game of go without human knowledge.
\newblock \emph{Nature}, 550\penalty0 (7676):\penalty0 354, 2017.

\bibitem[Tallec et~al.(2019)Tallec, Blier, and Ollivier]{tallec2019making}
Tallec, Corentin, Blier, L{\'e}onard, and Ollivier, Yann.
\newblock Making deep q-learning methods robust to time discretization.
\newblock \emph{arXiv preprint arXiv:1901.09732}, 2019.

\bibitem[Tesauro(1994)]{tesauro1994td}
Tesauro, Gerald.
\newblock Td-gammon, a self-teaching backgammon program, achieves master-level
  play.
\newblock \emph{Neural computation}, 6\penalty0 (2):\penalty0 215--219, 1994.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{todorovET12}
Todorov, Emanuel, Erez, Tom, and Tassa, Yuval.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{IROS}, pp.\  5026--5033. IEEE, 2012.
\newblock ISBN 978-1-4673-1737-5.
\newblock URL
  \url{http://dblp.uni-trier.de/db/conf/iros/iros2012.html#TodorovET12}.

\bibitem[Travnik et~al.(2018)Travnik, Mathewson, Sutton, and Pilarski]{travnik}
Travnik, Jaden~B., Mathewson, Kory~W., Sutton, Richard~S., and Pilarski,
  Patrick~M.
\newblock Reactive reinforcement learning in asynchronous environments.
\newblock \emph{Frontiers in Robotics and AI}, 5:\penalty0 79, 2018.
\newblock ISSN 2296-9144.
\newblock \doi{10.3389/frobt.2018.00079}.
\newblock URL
  \url{https://www.frontiersin.org/article/10.3389/frobt.2018.00079}.

\bibitem[van Hasselt et~al.(2016)van Hasselt, Guez, Hessel, Mnih, and
  Silver]{van2016learning}
van Hasselt, Hado~P, Guez, Arthur, Hessel, Matteo, Mnih, Volodymyr, and Silver,
  David.
\newblock Learning values across many orders of magnitude.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4287--4295, 2016.

\bibitem[Walsh et~al.(2008)Walsh, Nouri, Li, and Littman]{Walsh2008LearningAP}
Walsh, Thomas~J., Nouri, Ali, Li, Lihong, and Littman, Michael~L.
\newblock Learning and planning in environments with delayed feedback.
\newblock \emph{Autonomous Agents and Multi-Agent Systems}, 18:\penalty0
  83--105, 2008.

\end{thebibliography}
