@book{asmussen2007stochastic,
  title={Stochastic simulation: algorithms and analysis},
  author={Asmussen, S{\o}ren and Glynn, Peter W},
  volume={57},
  year={2007},
  publisher={Springer}
}

@article{MR1377542,
 ISSN = {01471937, 19301219},
 URL = {http://www.jstor.org/stable/44153921},
 abstract = {Let (X, d) be a separable metric space and M(X) the set of probability measures on the σ-algebra of Borel sets in X. In this paper we will show that a function f is almost everywhere continuous with respect to μ ϵ M(X) if and only if limn→∞ ∫x f dμn = ∫x f dμ, for all sequences {μn} in M(X) such that μn converges weakly to μ.},
 author = {Fernando Mazzone},
 journal = {Real Analysis Exchange},
 number = {1},
 pages = {317--319},
 publisher = {Michigan State University Press},
 title = {A CHARACTERIZATION OF ALMOST EVERYWHERE CONTINUOUS FUNCTIONS},
 urldate = {2022-12-26},
 volume = {21},
 year = {1995}
}

@book{devroye2006nonuniform,
  added-at = {2010-01-06T12:54:39.000+0100},
  author = {Devroye, Luc},
  biburl = {https://www.bibsonomy.org/bibtex/2e88b9f2888d9bcff53975ee61bf56d9c/vivion},
  date = {1986)},
  description = {Non-Uniform Random Variate Generation},
  interhash = {c728c5a049abb8424264f1095c992e20},
  intrahash = {e88b9f2888d9bcff53975ee61bf56d9c},
  keywords = {algorithms generation random simulation},
  location = {New York},
  publisher = {Springer-Verlag},
  timestamp = {2010-01-06T12:54:40.000+0100},
  title = {Non-Uniform Random Variate Generation},
  url = {http://cg.scs.carleton.ca/~luc/rnbookindex.html},
  year = 1986
}

@inproceedings{NIPS2010_ca8155f4,
 author = {Hazan, Tamir and Keshet, Joseph and McAllester, David},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Lafferty and C. Williams and J. Shawe-Taylor and R. Zemel and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Direct Loss Minimization for Structured Prediction},
 url = {https://proceedings.neurips.cc/paper/2010/file/ca8155f4d27f205953f9d3d7974bdd70-Paper.pdf},
 volume = {23},
 year = {2010}
}

@inproceedings{NEURIPS2020_d1e7b08b,
 author = {Lorberbom, Guy and Maddison, Chris J and Heess, Nicolas and Hazan, Tamir and Tarlow, Daniel},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {18076--18086},
 publisher = {Curran Associates, Inc.},
 title = {Direct Policy Gradients: Direct Optimization of Policies in Discrete Action Spaces},
 url = {https://proceedings.neurips.cc/paper/2020/file/d1e7b08bdb7783ed4fb10abe92c22ffd-Paper.pdf},
 volume = {33},
 year = {2020}
}


@article{chopra2022differentiable,
  title={Differentiable Agent-based Epidemiology},
  author={Chopra, Ayush and Rodr{\'\i}guez, Alexander and Subramanian, Jayakumar and Krishnamurthy, Balaji and Prakash, B Aditya and Raskar, Ramesh},
  journal={arXiv preprint arXiv:2207.09714},
  year={2022}
}


@article{mohamed2020monte,
  title={{M}onte {C}arlo Gradient Estimation in Machine Learning.},
  author={Mohamed, Shakir and Rosca, Mihaela and Figurnov, Michael and Mnih, Andriy},
  journal={J. Mach. Learn. Res.},
  volume={21},
  number={132},
  pages={1--62},
  year={2020}
}

@article{kleijnen1996optimization,
  title={Optimization and sensitivity analysis of computer simulation models by the score function method},
  author={Kleijnen, Jack PC and Rubinstein, Reuven Y},
  journal={European Journal of Operational Research},
  volume={88},
  number={3},
  pages={413--427},
  year={1996},
  publisher={Elsevier}
}

@article{glynn1990likelihood,
  title={Likelihood ratio gradient estimation for stochastic systems},
  author={Glynn, Peter W},
  journal={Communications of the ACM},
  volume={33},
  number={10},
  pages={75--84},
  year={1990},
  publisher={ACM New York, NY, USA}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{tucker2017rebar,
  title={{REBAR}: Low-variance, unbiased gradient estimates for discrete latent variable models},
  author={Tucker, George and Mnih, Andriy and Maddison, Chris J and Lawson, John and Sohl-Dickstein, Jascha},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{grathwohl2017backpropagation,
  title={Backpropagation through the void: Optimizing control variates for black-box gradient estimation},
  author={Grathwohl, Will and Choi, Dami and Wu, Yuhuai and Roeder, Geoffrey and Duvenaud, David},
  journal={arXiv:1711.00123},
  year={2017}
}

@incollection{glynn2002some,
  title={Some new perspectives on the method of control variates},
  author={Glynn, Peter W and Szechtman, Roberto},
  booktitle={Monte Carlo and Quasi-Monte Carlo Methods 2000},
  pages={27--49},
  year={2002},
  publisher={Springer}
}

@inproceedings{maddison2016concrete,
title={The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables},
author={Chris J. Maddison and Andriy Mnih and Yee Whye Teh},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=S1jE5L5gl}
}

@inproceedings{
jang2016categorical,
title={Categorical Reparameterization with {G}umbel-{S}oftmax},
author={Eric Jang and Shixiang Gu and Ben Poole},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=rkE3y85ee}
}

@article{kingma2013auto,
  title={Auto-encoding variational {B}ayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv:1312.6114},
  year={2013}
}


@book{glasserman1991gradient,
  title={Gradient estimation via perturbation analysis},
  author={Glasserman, Paul and Ho, Yu-Chi},
  volume={116},
  year={1991},
  publisher={Springer Science \& Business Media}
}

@article{heidergott2008measure,
  title={Measure-valued differentiation for {M}arkov chains},
  author={Heidergott, Bernd and V{\'a}zquez-Abad, FJ},
  journal={Journal of Optimization Theory and Applications},
  volume={136},
  number={2},
  pages={187--209},
  year={2008},
  publisher={Springer}
}

@article{pflug1989sampling,
  title={Sampling derivatives of probabilities},
  author={Pflug, G Ch},
  journal={Computing},
  volume={42},
  number={4},
  pages={315--328},
  year={1989},
  publisher={Springer}
}

@article{heidergott2008sensitivity,
  title={Sensitivity estimation for {G}aussian systems},
  author={Heidergott, Bernd and V{\'a}zquez-Abad, Felisa J and Volk-Makarewicz, Warren},
  journal={European Journal of Operational Research},
  volume={187},
  number={1},
  pages={193--207},
  year={2008},
  publisher={Elsevier}
}

@article{gong1987smoothed,
  title={Smoothed (conditional) perturbation analysis of discrete event dynamical systems},
  author={Gong, Wei-Bo and Ho, Yu-Chi},
  journal={IEEE Transactions on Automatic Control},
  volume={32},
  number={10},
  pages={858--866},
  year={1987},
  publisher={IEEE}
}

@article{glasserman1990smoothed,
  title={Smoothed perturbation analysis for a class of discrete-event systems},
  author={Glasserman, Paul and Gong, W-B},
  journal={IEEE Transactions on Automatic Control},
  volume={35},
  number={11},
  pages={1218--1230},
  year={1990},
  publisher={IEEE}
}

@inproceedings{
krieken2021storchastic,
title={Storchastic: A Framework for General Stochastic Automatic Differentiation},
author={Emile van Krieken and Jakub Mikolaj Tomczak and Annette Ten Teije},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=KAFyFabsK88}
}

@misc{StorchasticReview,
 author = {van Krieken, Emile and Tomczak, Jakub and Ten Teije, Annette},
 title = {OpenReview: Storchastic: A Framework for General Stochastic Automatic Differentiation},
 url={https://openreview.net/forum?id=KAFyFabsK88},
 urldate = {19/5/2022},
 originalyear = {2021},
 note = {URL \href{https://openreview.net/forum?id=KAFyFabsK88}{https://openreview.net/forum?id=KAFyFabsK88}}
}

@article{bengio,
  doi = {10.48550/ARXIV.1308.3432},
  
  url = {https://arxiv.org/abs/1308.3432},
  
  author = {Bengio, Yoshua and Léonard, Nicholas and Courville, Aaron},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation},
  
  journal = {arXiv:1308.3432},
  
  year = {2013},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{schulman2015gradient,
  title={Gradient estimation using stochastic computation graphs},
  author={Schulman, John and Heess, Nicolas and Weber, Theophane and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015}
}






@article{baydin2018automatic,
  title={Automatic differentiation in machine learning: a survey},
  author={Baydin, Atilim Gunes and Pearlmutter, Barak A and Radul, Alexey Andreyevich and Siskind, Jeffrey Mark},
  journal={Journal of Machine Learning Research},
  volume={18},
  pages={1--43},
  year={2018},
  publisher={Microtome Publishing}
}


@book{chopin2020introduction,
  title={An introduction to sequential Monte Carlo},
  author={Chopin, Nicolas and Papaspiliopoulos, Omiros},
  year={2020},
isbn = {978-3-030-47844-5},
  publisher={Springer},
doi = {10.1007/978-3-030-47845-2}
}

@article{doucet2009tutorial,
  title={A tutorial on particle filtering and smoothing: Fifteen years later},
  author={Doucet, Arnaud and Johansen, Adam M},
  journal={Oxford Handbook of nonlinear filtering},
  volume={12},
  number={656-704},
  year={2011}
}

@article{poyiadjis2011particle,
    author = {Poyiadjis, George and Doucet, Arnaud and Singh, Sumeetpal S.},
    title = "{Particle approximations of the score and observed information matrix in state space models with application to parameter estimation}",
    journal = {Biometrika},
    volume = {98},
    number = {1},
    pages = {65-80},
    year = {2011},
    month = {02},
    abstract = "{Particle methods are popular computational tools for Bayesian inference in nonlinear non-Gaussian state space models. For this class of models, we present two particle algorithms to compute the score vector and observed information matrix recursively. The first algorithm is implemented with computational complexity  and the second with complexity , where N is the number of particles. Although cheaper, the performance of the  method degrades quickly, as it relies on the approximation of a sequence of probability distributions whose dimension increases linearly with time. In particular, even under strong mixing assumptions, the variance of the estimates computed with the  method increases at least quadratically in time. The more expensive  method relies on a nonstandard particle implementation and does not suffer from this rapid degradation. It is shown how both methods can be used to perform batch and recursive parameter estimation.}",
    issn = {0006-3444},
    doi = {10.1093/biomet/asq062},
    url = {https://doi.org/10.1093/biomet/asq062},
    eprint = {https://academic.oup.com/biomet/article-pdf/98/1/65/591874/asq062.pdf},
}

@article{kalman1960new,
    author = {Kalman, R. E.},
    title = "{A New Approach to Linear Filtering and Prediction Problems}",
    journal = {Journal of Basic Engineering},
    volume = {82},
    number = {1},
    pages = {35-45},
    year = {1960},
    month = {03},
    abstract = "{The classical filtering and prediction problem is re-examined using the Bode-Shannon representation of random processes and the “state-transition” method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinite-memory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the co-efficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix.}",
    issn = {0021-9223},
    doi = {10.1115/1.3662552},
    url = {https://doi.org/10.1115/1.3662552},
    eprint = {https://asmedigitalcollection.asme.org/fluidsengineering/article-pdf/82/1/35/5518977/35\_1.pdf},
}

@ARTICLE{rosato2021efficient,
  author={Rosato, Conor and Devlin, Lee and Beraud, Vincent and Horridge, Paul and Schön, Thomas B. and Maskell, Simon},
  journal={IEEE Transactions on Signal Processing}, 
  title={Efficient Learning of the Parameters of Non-Linear Models Using Differentiable Resampling in Particle Filters}, 
  year={2022},
  volume={70},
  number={},
  pages={3676-3692},
  doi={10.1109/TSP.2022.3187868}}

@article{jonschkowski2018differentiable,
  title={Differentiable particle filters: End-to-end learning with algorithmic priors},
  author={Jonschkowski, Rico and Rastogi, Divyam and Brock, Oliver},
  journal={arXiv:1805.11122},
  year={2018}
}


@InProceedings{corenflos2021differentiable,
  title = 	 {Differentiable Particle Filtering via Entropy-Regularized Optimal Transport},
  author =       {Corenflos, Adrien and Thornton, James and Deligiannidis, George and Doucet, Arnaud},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {2100--2111},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/corenflos21a/corenflos21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/corenflos21a.html},
  abstract = 	 {Particle Filtering (PF) methods are an established class of procedures for performing inference in non-linear state-space models. Resampling is a key ingredient of PF necessary to obtain low variance likelihood and states estimates. However, traditional resampling methods result in PF-based loss functions being non-differentiable with respect to model and PF parameters. In a variational inference context, resampling also yields high variance gradient estimates of the PF-based evidence lower bound. By leveraging optimal transport ideas, we introduce a principled differentiable particle filter and provide convergence results. We demonstrate this novel method on a variety of applications.}
}


@article{scibior2021differentiable,
  title={Differentiable Particle Filtering without Modifying the Forward Pass},
  author={{\'S}cibior, Adam and Wood, Frank},
  journal={arXiv:2106.10314},
  year={2021}
}

@article{griewank1989automatic,
  title={On automatic differentiation},
  author={Griewank, Andreas},
  journal={Mathematical Programming: recent developments and applications},
  volume={6},
  number={6},
  pages={83--107},
  year={1989},
  publisher={Citeseer}
}



@book{corliss2002automatic,
  title={Automatic differentiation of algorithms: from simulation to optimization},
  author={Corliss, George and Faure, Christele and Griewank, Andreas and Hascoet, Laurent and Naumann, Uwe},
  year={2002},
  publisher={Springer Science \& Business Media}
}

@article{Julia-2017,
    title={Julia: A fresh approach to numerical computing},
    author={Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B},
    journal={SIAM {R}eview},
    volume={59},
    number={1},
    pages={65--98},
    year={2017},
    publisher={SIAM},
    doi={10.1137/141000671},
    url={https://epubs.siam.org/doi/10.1137/141000671}
}


@article{RevelsLubinPapamarkou2016,
    title = {Forward-Mode Automatic Differentiation in {J}ulia},
   author = {{Revels}, Jarrett and {Lubin}, Miles and {Papamarkou}, Theodore},
  journal = {arXiv:1607.07892 [cs.MS]},
     year = {2016},
      url = {https://arxiv.org/abs/1607.07892}
}







﻿@Article{silverman2021situating,
author={Silverman, Eric
and Gostoli, Umberto
and Picascia, Stefano
and Almagor, Jonatan
and McCann, Mark
and Shaw, Richard
and Angione, Claudio},
title={Situating agent-based modelling in population health research},
journal={Emerging Themes in Epidemiology},
year={2021},
month={Jul},
day={30},
volume={18},
number={1},
pages={10},
abstract={Today's most troublesome population health challenges are often driven by social and environmental determinants, which are difficult to model using traditional epidemiological methods. We agree with those who have argued for the wider adoption of agent-based modelling (ABM) in taking on these challenges. However, while ABM has been used occasionally in population health, we argue that for ABM to be most effective in the field it should be used as a means for answering questions normally inaccessible to the traditional epidemiological toolkit. In an effort to clearly illustrate the utility of ABM for population health research, and to clear up persistent misunderstandings regarding the method's conceptual underpinnings, we offer a detailed presentation of the core concepts of complex systems theory, and summarise why simulations are essential to the study of complex systems. We then examine the current state of the art in ABM for population health, and propose they are well-suited for the study of the `wicked' problems in population health, and could make significant contributions to theory and intervention development in these areas.},
issn={1742-7622},
doi={10.1186/s12982-021-00102-7},
url={https://doi.org/10.1186/s12982-021-00102-7}
}

@ARTICLE{chylek2014rule,
  title     = "Rule-based modeling: a computational approach for studying
               biomolecular site dynamics in cell signaling systems",
  author    = "Chylek, Lily A and Harris, Leonard A and Tung, Chang-Shung and
               Faeder, James R and Lopez, Carlos F and Hlavacek, William S",
  abstract  = "Rule-based modeling was developed to address the limitations of
               traditional approaches for modeling chemical kinetics in cell
               signaling systems. These systems consist of multiple interacting
               biomolecules (e.g., proteins), which themselves consist of
               multiple parts (e.g., domains, linear motifs, and sites of
               phosphorylation). Consequently, biomolecules that mediate
               information processing generally have the potential to interact
               in multiple ways, with the number of possible complexes and
               posttranslational modification states tending to grow
               exponentially with the number of binary interactions considered.
               As a result, only large reaction networks capture all possible
               consequences of the molecular interactions that occur in a cell
               signaling system, which is problematic because traditional
               modeling approaches for chemical kinetics (e.g., ordinary
               differential equations) require explicit network specification.
               This problem is circumvented through representation of
               interactions in terms of local rules. With this approach,
               network specification is implicit and model specification is
               concise. Concise representation results in a coarse graining of
               chemical kinetics, which is introduced because all reactions
               implied by a rule inherit the rate law associated with that
               rule. Coarse graining can be appropriate if interactions are
               modular, and the coarseness of a model can be adjusted as
               needed. Rules can be specified using specialized
               model-specification languages, and recently developed tools
               designed for specification of rule-based models allow one to
               leverage powerful software engineering capabilities. A
               rule-based model comprises a set of rules, which can be
               processed by general-purpose simulation and analysis tools to
               achieve different objectives (e.g., to perform either a
               deterministic or stochastic simulation).",
  journal   = "Wiley Interdiscip. Rev. Syst. Biol. Med.",
  publisher = "Wiley",
  volume    =  6,
  number    =  1,
  pages     = "13--36",
  month     =  jan,
  year      =  2014,
  copyright = "http://onlinelibrary.wiley.com/termsAndConditions\#vor",
  language  = "en"
}

@ARTICLE{faeder2009rule,
  title    = "Rule-based modeling of biochemical systems with {BioNetGen}",
  author   = "Faeder, James R and Blinov, Michael L and Hlavacek, William S",
  abstract = "Rule-based modeling involves the representation of molecules as
              structured objects and molecular interactions as rules for
              transforming the attributes of these objects. The approach is
              notable in that it allows one to systematically incorporate
              site-specific details about protein-protein interactions into a
              model for the dynamics of a signal-transduction system, but the
              method has other applications as well, such as following the
              fates of individual carbon atoms in metabolic reactions. The
              consequences of protein-protein interactions are difficult to
              specify and track with a conventional modeling approach because
              of the large number of protein phosphoforms and protein complexes
              that these interactions potentially generate. Here, we focus on
              how a rule-based model is specified in the BioNetGen language
              (BNGL) and how a model specification is analyzed using the
              BioNetGen software tool. We also discuss new developments in
              rule-based modeling that should enable the construction and
              analyses of comprehensive models for signal transduction pathways
              and similarly large-scale models for other biochemical systems.",
  journal  = "Methods Mol. Biol.",
  volume   =  500,
  pages    = "113--167",
  year     =  2009,
  language = "en"
}

@book{Fu1997,
  title={Conditional Monte Carlo: Gradient estimation and optimization applications},
  author={Fu, Michael C and Hu, Jian-Qiang},
  volume={392},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{anderson2012efficient,
  title={An efficient finite difference method for parameter sensitivities of continuous time Markov chains},
  author={Anderson, David F},
  journal={SIAM Journal on Numerical Analysis},
  volume={50},
  number={5},
  pages={2237--2258},
  year={2012},
  publisher={SIAM}
}

@article{thanh2018efficient,
  title={Efficient finite-difference method for computing sensitivities of biochemical reactions},
  author={Thanh, Vo Hong and Zunino, Roberto and Priami, Corrado},
  journal={Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume={474},
  number={2218},
  pages={20180303},
  year={2018},
  publisher={The Royal Society Publishing}
}

@article{glasserman1992some,
  title={Some guidelines and guarantees for common random numbers},
  author={Glasserman, Paul and Yao, David D},
  journal={Management Science},
  volume={38},
  number={6},
  pages={884--908},
  year={1992},
  publisher={INFORMS}
}

@article{lew2022adev,
  title={ADEV: Sound Automatic Differentiation of Expected Values of Probabilistic Programs},
  author={Lew, Alexander K and Huot, Mathieu and Staton, Sam and Mansinghka, Vikash K},
  journal={arXiv preprint arXiv:2212.06386},
  year={2022}
}