\begin{thebibliography}{49}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Albooyeh et~al.(2019)Albooyeh, Bertolini, and
  Ravanbakhsh]{albooyeh2019incidence}
Albooyeh, M., Bertolini, D., and Ravanbakhsh, S.
\newblock Incidence networks for geometric deep learning.
\newblock \emph{arXiv preprint arXiv:1905.11460}, 2019.

\bibitem[Arora et~al.(2019)Arora, Du, Hu, Li, and Wang]{arora2019fine}
Arora, S., Du, S., Hu, W., Li, Z., and Wang, R.
\newblock Fine-grained analysis of optimization and generalization for
  overparameterized two-layer neural networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  322--332. PMLR, 2019.

\bibitem[Azizian \& Lelarge(2020)Azizian and Lelarge]{azizian2020expressive}
Azizian, W. and Lelarge, M.
\newblock Expressive power of invariant and equivariant graph neural networks.
\newblock \emph{arXiv preprint arXiv:2006.15646}, 2020.

\bibitem[Belkin et~al.(2008)Belkin, Sun, and Wang]{belkin2008discrete}
Belkin, M., Sun, J., and Wang, Y.
\newblock Discrete laplace operator on meshed surfaces.
\newblock In \emph{Proceedings of the twenty-fourth annual symposium on
  Computational geometry}, pp.\  278--287, 2008.

\bibitem[Belkin et~al.(2009)Belkin, Sun, and Wang]{belkin2009constructing}
Belkin, M., Sun, J., and Wang, Y.
\newblock Constructing laplace operator from point clouds in $r^d$.
\newblock In \emph{Proceedings of the twentieth annual ACM-SIAM symposium on
  Discrete algorithms}, pp.\  1031--1040. SIAM, 2009.

\bibitem[Bevilacqua et~al.(2021)Bevilacqua, Frasca, Lim, Srinivasan, Cai,
  Balamurugan, Bronstein, and Maron]{bevilacqua2021equivariant}
Bevilacqua, B., Frasca, F., Lim, D., Srinivasan, B., Cai, C., Balamurugan, G.,
  Bronstein, M.~M., and Maron, H.
\newblock Equivariant subgraph aggregation networks.
\newblock \emph{arXiv preprint arXiv:2110.02910}, 2021.

\bibitem[Bruna et~al.(2013)Bruna, Zaremba, Szlam, and LeCun]{bruna2013spectral}
Bruna, J., Zaremba, W., Szlam, A., and LeCun, Y.
\newblock Spectral networks and locally connected networks on graphs.
\newblock \emph{arXiv preprint arXiv:1312.6203}, 2013.

\bibitem[Cai \& Wang(2020)Cai and Wang]{cai2020note}
Cai, C. and Wang, Y.
\newblock A note on over-smoothing for graph neural networks.
\newblock \emph{arXiv preprint arXiv:2006.13318}, 2020.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and
  Duvenaud]{chen2018neural}
Chen, R.~T., Rubanova, Y., Bettencourt, J., and Duvenaud, D.
\newblock Neural ordinary differential equations.
\newblock \emph{arXiv preprint arXiv:1806.07366}, 2018.

\bibitem[Cybenko(1989)]{cybenko1989approximation}
Cybenko, G.
\newblock Approximation by superpositions of a sigmoidal function.
\newblock \emph{Mathematics of control, signals and systems}, 2\penalty0
  (4):\penalty0 303--314, 1989.

\bibitem[Defferrard et~al.(2016)Defferrard, Bresson, and
  Vandergheynst]{defferrard2016convolutional}
Defferrard, M., Bresson, X., and Vandergheynst, P.
\newblock Convolutional neural networks on graphs with fast localized spectral
  filtering.
\newblock \emph{Advances in neural information processing systems},
  29:\penalty0 3844--3852, 2016.

\bibitem[Dey et~al.(2010)Dey, Ranjan, and Wang]{dey2010convergence}
Dey, T.~K., Ranjan, P., and Wang, Y.
\newblock Convergence, stability, and discrete approximation of laplace
  spectra.
\newblock In \emph{Proceedings of the Twenty-First Annual ACM-SIAM Symposium on
  Discrete Algorithms}, pp.\  650--663. SIAM, 2010.

\bibitem[Du et~al.(2019)Du, Lee, Li, Wang, and Zhai]{du2019gradient}
Du, S., Lee, J., Li, H., Wang, L., and Zhai, X.
\newblock Gradient descent finds global minima of deep neural networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1675--1685. PMLR, 2019.

\bibitem[Du et~al.(2018)Du, Zhai, Poczos, and Singh]{du2018gradient}
Du, S.~S., Zhai, X., Poczos, B., and Singh, A.
\newblock Gradient descent provably optimizes over-parameterized neural
  networks.
\newblock \emph{arXiv preprint arXiv:1810.02054}, 2018.

\bibitem[Eldridge et~al.(2016)Eldridge, Belkin, and Wang]{eldridge2016graphons}
Eldridge, J., Belkin, M., and Wang, Y.
\newblock Graphons, mergeons, and so on!
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2307--2315, 2016.

\bibitem[Finzi et~al.(2021)Finzi, Welling, and Wilson]{finzi2021practical}
Finzi, M., Welling, M., and Wilson, A.~G.
\newblock A practical method for constructing equivariant multilayer
  perceptrons for arbitrary matrix groups.
\newblock \emph{arXiv preprint arXiv:2104.09459}, 2021.

\bibitem[Gama et~al.(2020)Gama, Bruna, and Ribeiro]{gama2020stability}
Gama, F., Bruna, J., and Ribeiro, A.
\newblock Stability properties of graph neural networks.
\newblock \emph{IEEE Transactions on Signal Processing}, 68:\penalty0
  5680--5695, 2020.

\bibitem[Garg et~al.(2020)Garg, Jegelka, and Jaakkola]{garg2020generalization}
Garg, V., Jegelka, S., and Jaakkola, T.
\newblock Generalization and representational limits of graph neural networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3419--3430. PMLR, 2020.

\bibitem[Geerts(2020)]{geerts2020expressive}
Geerts, F.
\newblock The expressive power of kth-order invariant graph networks.
\newblock \emph{arXiv preprint arXiv:2007.12035}, 2020.

\bibitem[Gilmer et~al.(2017)Gilmer, Schoenholz, Riley, Vinyals, and
  Dahl]{gilmer2017neural}
Gilmer, J., Schoenholz, S.~S., Riley, P.~F., Vinyals, O., and Dahl, G.~E.
\newblock Neural message passing for quantum chemistry.
\newblock In \emph{International conference on machine learning}, pp.\
  1263--1272. PMLR, 2017.

\bibitem[Holst(1980)]{holst1980lengths}
Holst, L.
\newblock On the lengths of the pieces of a stick broken at random.
\newblock \emph{Journal of Applied Probability}, 17\penalty0 (3):\penalty0
  623--634, 1980.

\bibitem[Hornik et~al.(1989)Hornik, Stinchcombe, and
  White]{hornik1989multilayer}
Hornik, K., Stinchcombe, M., and White, H.
\newblock Multilayer feedforward networks are universal approximators.
\newblock \emph{Neural networks}, 2\penalty0 (5):\penalty0 359--366, 1989.

\bibitem[Jacot et~al.(2018)Jacot, Gabriel, and Hongler]{jacot2018neural}
Jacot, A., Gabriel, F., and Hongler, C.
\newblock Neural tangent kernel: Convergence and generalization in neural
  networks.
\newblock \emph{arXiv preprint arXiv:1806.07572}, 2018.

\bibitem[Keriven \& Peyr{\'e}(2019)Keriven and Peyr{\'e}]{keriven2019universal}
Keriven, N. and Peyr{\'e}, G.
\newblock Universal invariant and equivariant graph neural networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 7092--7101, 2019.

\bibitem[Keriven et~al.(2020)Keriven, Bietti, and
  Vaiter]{keriven2020convergence}
Keriven, N., Bietti, A., and Vaiter, S.
\newblock Convergence and stability of graph convolutional networks on large
  random graphs.
\newblock \emph{arXiv preprint arXiv:2006.01868}, 2020.

\bibitem[Keriven et~al.(2021)Keriven, Bietti, and
  Vaiter]{keriven2021universality}
Keriven, N., Bietti, A., and Vaiter, S.
\newblock On the universality of graph neural networks on large random graphs.
\newblock \emph{arXiv preprint arXiv:2105.13099}, 2021.

\bibitem[Kipf \& Welling(2016)Kipf and Welling]{kipf2016semi}
Kipf, T.~N. and Welling, M.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock \emph{arXiv preprint arXiv:1609.02907}, 2016.

\bibitem[Kostrikov et~al.(2018)Kostrikov, Jiang, Panozzo, Zorin, and
  Bruna]{kostrikov2018surface}
Kostrikov, I., Jiang, Z., Panozzo, D., Zorin, D., and Bruna, J.
\newblock Surface networks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  2540--2548, 2018.

\bibitem[Lee et~al.(2019)Lee, Xiao, Schoenholz, Bahri, Novak, Sohl-Dickstein,
  and Pennington]{lee2019wide}
Lee, J., Xiao, L., Schoenholz, S., Bahri, Y., Novak, R., Sohl-Dickstein, J.,
  and Pennington, J.
\newblock Wide neural networks of any depth evolve as linear models under
  gradient descent.
\newblock \emph{Advances in neural information processing systems},
  32:\penalty0 8572--8583, 2019.

\bibitem[Levie et~al.(2021)Levie, Huang, Bucci, Bronstein, and
  Kutyniok]{levie2021transferability}
Levie, R., Huang, W., Bucci, L., Bronstein, M., and Kutyniok, G.
\newblock Transferability of spectral graph convolutional neural networks.
\newblock \emph{Journal of Machine Learning Research}, 22\penalty0
  (272):\penalty0 1--59, 2021.

\bibitem[Li et~al.(2018)Li, Han, and Wu]{li2018deeper}
Li, Q., Han, Z., and Wu, X.-M.
\newblock Deeper insights into graph convolutional networks for semi-supervised
  learning.
\newblock In \emph{Thirty-Second AAAI conference on artificial intelligence},
  2018.

\bibitem[Lu et~al.(2018)Lu, Zhong, Li, and Dong]{lu2018beyond}
Lu, Y., Zhong, A., Li, Q., and Dong, B.
\newblock Beyond finite layer neural networks: Bridging deep architectures and
  numerical differential equations.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3276--3285. PMLR, 2018.

\bibitem[Maron et~al.(2018)Maron, Ben-Hamu, Shamir, and
  Lipman]{maron2018invariant}
Maron, H., Ben-Hamu, H., Shamir, N., and Lipman, Y.
\newblock Invariant and equivariant graph networks.
\newblock \emph{arXiv preprint arXiv:1812.09902}, 2018.

\bibitem[Maron et~al.(2019{\natexlab{a}})Maron, Ben-Hamu, Serviansky, and
  Lipman]{maron2019provably}
Maron, H., Ben-Hamu, H., Serviansky, H., and Lipman, Y.
\newblock Provably powerful graph networks.
\newblock \emph{arXiv preprint arXiv:1905.11136}, 2019{\natexlab{a}}.

\bibitem[Maron et~al.(2019{\natexlab{b}})Maron, Fetaya, Segol, and
  Lipman]{maron2019universality}
Maron, H., Fetaya, E., Segol, N., and Lipman, Y.
\newblock On the universality of invariant networks.
\newblock In \emph{International conference on machine learning}, pp.\
  4363--4371. PMLR, 2019{\natexlab{b}}.

\bibitem[Oono \& Suzuki(2019)Oono and Suzuki]{oono2019graph}
Oono, K. and Suzuki, T.
\newblock Graph neural networks exponentially lose expressive power for node
  classification.
\newblock \emph{arXiv preprint arXiv:1905.10947}, 2019.

\bibitem[Pyke(1965)]{pyke1965spacings}
Pyke, R.
\newblock Spacings.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 27\penalty0 (3):\penalty0 395--436, 1965.

\bibitem[R{\'e}nyi(1953)]{renyi1953theory}
R{\'e}nyi, A.
\newblock On the theory of order statistics.
\newblock \emph{Acta Mathematica Academiae Scientiarum Hungarica}, 4\penalty0
  (3-4):\penalty0 191--231, 1953.

\bibitem[Ruiz et~al.(2020)Ruiz, Chamon, and Ribeiro]{ruiz2020graphon}
Ruiz, L., Chamon, L., and Ribeiro, A.
\newblock Graphon neural networks and the transferability of graph neural
  networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Ruiz et~al.(2021)Ruiz, Gama, and Ribeiro]{ruiz2021graph}
Ruiz, L., Gama, F., and Ribeiro, A.
\newblock Graph neural networks: Architectures, stability, and transferability.
\newblock \emph{Proceedings of the IEEE}, 109\penalty0 (5):\penalty0 660--682,
  2021.

\bibitem[Ruthotto \& Haber(2020)Ruthotto and Haber]{ruthotto2020deep}
Ruthotto, L. and Haber, E.
\newblock Deep neural networks motivated by partial differential equations.
\newblock \emph{Journal of Mathematical Imaging and Vision}, 62\penalty0
  (3):\penalty0 352--364, 2020.

\bibitem[Wardetzky(2008)]{wardetzky2008convergence}
Wardetzky, M.
\newblock Convergence of the cotangent formula: An overview.
\newblock \emph{Discrete differential geometry}, pp.\  275--286, 2008.

\bibitem[Weinan(2017)]{weinan2017proposal}
Weinan, E.
\newblock A proposal on machine learning via dynamical systems.
\newblock \emph{Communications in Mathematics and Statistics}, 5\penalty0
  (1):\penalty0 1--11, 2017.

\bibitem[Wu et~al.(2020)Wu, Pan, Chen, Long, Zhang, and
  Philip]{wu2020comprehensive}
Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C., and Philip, S.~Y.
\newblock A comprehensive survey on graph neural networks.
\newblock \emph{IEEE transactions on neural networks and learning systems},
  32\penalty0 (1):\penalty0 4--24, 2020.

\bibitem[Xu(2004)]{xu2004discrete}
Xu, G.
\newblock Discrete laplace--beltrami operators and their convergence.
\newblock \emph{Computer aided geometric design}, 21\penalty0 (8):\penalty0
  767--784, 2004.

\bibitem[Xu et~al.(2018)Xu, Hu, Leskovec, and Jegelka]{xu2018powerful}
Xu, K., Hu, W., Leskovec, J., and Jegelka, S.
\newblock How powerful are graph neural networks?
\newblock \emph{arXiv preprint arXiv:1810.00826}, 2018.

\bibitem[Zhang et~al.(2015)Zhang, Levina, and Zhu]{zhang2015estimating}
Zhang, Y., Levina, E., and Zhu, J.
\newblock Estimating network edge probabilities by neighborhood smoothing.
\newblock \emph{arXiv preprint arXiv:1509.08588}, 2015.

\bibitem[Zhou et~al.(2020)Zhou, Cui, Hu, Zhang, Yang, Liu, Wang, Li, and
  Sun]{zhou2020graph}
Zhou, J., Cui, G., Hu, S., Zhang, Z., Yang, C., Liu, Z., Wang, L., Li, C., and
  Sun, M.
\newblock Graph neural networks: A review of methods and applications.
\newblock \emph{AI Open}, 1:\penalty0 57--81, 2020.

\bibitem[Zhou et~al.(2021)Zhou, Huang, Zha, Chen, Li, Choi, and
  Hu]{zhou2021dirichlet}
Zhou, K., Huang, X., Zha, D., Chen, R., Li, L., Choi, S.-H., and Hu, X.
\newblock Dirichlet energy constrained learning for deep graph neural networks.
\newblock In \emph{Thirty-Fifth Conference on Neural Information Processing
  Systems}, 2021.

\end{thebibliography}
