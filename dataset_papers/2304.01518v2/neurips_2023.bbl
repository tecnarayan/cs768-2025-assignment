\begin{thebibliography}{67}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Akbari et~al.(2021)Akbari, Yuan, Qian, Chuang, Chang, Cui, and
  Gong]{akbari2021vatt}
H.~Akbari, L.~Yuan, R.~Qian, W.-H. Chuang, S.-F. Chang, Y.~Cui, and B.~Gong.
\newblock Vatt: Transformers for multimodal self-supervised learning from raw
  video, audio and text.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.~Liang, and J.~W.
  Vaughan, editors, \emph{Advances in Neural Information Processing Systems},
  volume~34, pages 24206--24221. Curran Associates, Inc., 2021.

\bibitem[Andrew et~al.(2013)Andrew, Arora, Bilmes, and Livescu]{andrew2013deep}
G.~Andrew, R.~Arora, J.~Bilmes, and K.~Livescu.
\newblock Deep canonical correlation analysis.
\newblock In S.~Dasgupta and D.~McAllester, editors, \emph{Proceedings of the
  30th International Conference on Machine Learning}, volume~28 of
  \emph{Proceedings of Machine Learning Research}, pages 1247--1255, Atlanta,
  Georgia, USA, 17--19 Jun 2013. PMLR.

\bibitem[Baltrušaitis et~al.(2019)Baltrušaitis, Ahuja, and
  Morency]{baltruvsaitis2018multimodal}
T.~Baltrušaitis, C.~Ahuja, and L.-P. Morency.
\newblock Multimodal machine learning: A survey and taxonomy.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 41\penalty0 (2):\penalty0 423--443, 2019.
\newblock \doi{10.1109/TPAMI.2018.2798607}.

\bibitem[Bhatt et~al.(2019)Bhatt, Jha, and Raman]{bhatt2019representation}
G.~Bhatt, P.~Jha, and B.~Raman.
\newblock Representation learning using step-based deep multi-modal
  autoencoders.
\newblock \emph{Pattern Recognition}, 95:\penalty0 12--23, 2019.
\newblock ISSN 0031-3203.
\newblock \doi{https://doi.org/10.1016/j.patcog.2019.05.032}.

\bibitem[Cangea et~al.(2022)Cangea, Day, Jamasb, and Lio]{cangea2022message}
C.~Cangea, B.~Day, A.~R. Jamasb, and P.~Lio.
\newblock Message passing neural processes.
\newblock In \emph{ICLR 2022 Workshop on Geometrical and Topological
  Representation Learning}, 2022.

\bibitem[Dao et~al.(2023)Dao, Huynh, Zhao, Phung, and Cai]{dao2023open}
S.~D. Dao, D.~Huynh, H.~Zhao, D.~Phung, and J.~Cai.
\newblock Open-vocabulary multi-label image classification with pretrained
  vision-language model.
\newblock In \emph{2023 IEEE International Conference on Multimedia and Expo
  (ICME)}, pages 2135--2140. IEEE, 2023.

\bibitem[Dempster(1967)]{dempster1967upper}
A.~Dempster.
\newblock Upper and lower probabilities induced by a multi- valued mapping.
\newblock \emph{Annals of Mathematical Statistics}, 38:\penalty0 325--339,
  1967.

\bibitem[Dipnall et~al.(2021)Dipnall, Page, Du, Costa, Lyons, Cameron,
  de~Steiger, Hau, Bucknill, Oppy, Edwards, Varma, Jung, and
  Gabbe]{dipnall2021predicting}
J.~F. Dipnall, R.~Page, L.~Du, M.~Costa, R.~A. Lyons, P.~Cameron,
  R.~de~Steiger, R.~Hau, A.~Bucknill, A.~Oppy, E.~Edwards, D.~Varma, M.~C.
  Jung, and B.~J. Gabbe.
\newblock Predicting fracture outcomes from clinical registry data using
  artificial intelligence supplemented models for evidence-informed treatment
  (praise) study protocol.
\newblock \emph{PLOS ONE}, 16\penalty0 (9):\penalty0 1--12, 09 2021.
\newblock \doi{10.1371/journal.pone.0257361}.

\bibitem[Feng et~al.(2023)Feng, Hajimirsadeghi, Bengio, and
  Ahmed]{feng2023latent}
L.~Feng, H.~Hajimirsadeghi, Y.~Bengio, and M.~O. Ahmed.
\newblock Latent bottlenecked attentive neural processes.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem[Foong et~al.(2020)Foong, Bruinsma, Gordon, Dubois, Requeima, and
  Turner]{foong2020meta}
A.~Foong, W.~Bruinsma, J.~Gordon, Y.~Dubois, J.~Requeima, and R.~Turner.
\newblock Meta-learning stationary stochastic process prediction with
  convolutional neural processes.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 8284--8295. Curran Associates, Inc., 2020.

\bibitem[Gal and Ghahramani(2015)]{gal2015bayesian}
Y.~Gal and Z.~Ghahramani.
\newblock Bayesian convolutional neural networks with bernoulli approximate
  variational inference.
\newblock \emph{arXiv preprint arXiv:1506.02158}, 2015.

\bibitem[Gao et~al.(2019)Gao, Jiang, Zou, John, and Liu]{gao2019rgb}
M.~Gao, J.~Jiang, G.~Zou, V.~John, and Z.~Liu.
\newblock Rgb-d-based object recognition using multimodal convolutional neural
  networks: A survey.
\newblock \emph{IEEE Access}, 7:\penalty0 43110--43136, 2019.
\newblock \doi{10.1109/ACCESS.2019.2907071}.

\bibitem[Garnelo et~al.(2018{\natexlab{a}})Garnelo, Rosenbaum, Maddison,
  Ramalho, Saxton, Shanahan, Teh, Rezende, and Eslami]{garnelo18a}
M.~Garnelo, D.~Rosenbaum, C.~Maddison, T.~Ramalho, D.~Saxton, M.~Shanahan,
  Y.~W. Teh, D.~Rezende, and S.~M.~A. Eslami.
\newblock Conditional neural processes.
\newblock In J.~Dy and A.~Krause, editors, \emph{Proceedings of the 35th
  International Conference on Machine Learning}, volume~80 of \emph{Proceedings
  of Machine Learning Research}, pages 1704--1713. PMLR, 10--15 Jul
  2018{\natexlab{a}}.

\bibitem[Garnelo et~al.(2018{\natexlab{b}})Garnelo, Schwarz, Rosenbaum, Viola,
  Rezende, Eslami, and Teh]{garnelo2018neural}
M.~Garnelo, J.~Schwarz, D.~Rosenbaum, F.~Viola, D.~J. Rezende, S.~Eslami, and
  Y.~W. Teh.
\newblock Neural processes.
\newblock \emph{arXiv preprint arXiv:1807.01622}, 2018{\natexlab{b}}.

\bibitem[Gordon et~al.(2020)Gordon, Bruinsma, Foong, Requeima, Dubois, and
  Turner]{Gordon2020Convolutional}
J.~Gordon, W.~P. Bruinsma, A.~Y.~K. Foong, J.~Requeima, Y.~Dubois, and R.~E.
  Turner.
\newblock Convolutional conditional neural processes.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017on}
C.~Guo, G.~Pleiss, Y.~Sun, and K.~Q. Weinberger.
\newblock On calibration of modern neural networks.
\newblock In D.~Precup and Y.~W. Teh, editors, \emph{Proceedings of the 34th
  International Conference on Machine Learning}, volume~70 of \emph{Proceedings
  of Machine Learning Research}, pages 1321--1330. PMLR, 06--11 Aug 2017.

\bibitem[Han et~al.(2021)Han, Zhang, Fu, and Zhou]{han2021trusted}
Z.~Han, C.~Zhang, H.~Fu, and J.~T. Zhou.
\newblock Trusted multi-view classification.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Hendrycks and Dietterich(2019)]{hendrycks2019benchmarking}
D.~Hendrycks and T.~Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock \emph{Proceedings of the International Conference on Learning
  Representations}, 2019.

\bibitem[Hensman et~al.(2015)Hensman, Matthews, and
  Ghahramani]{hensman2015scalable}
J.~Hensman, A.~Matthews, and Z.~Ghahramani.
\newblock {Scalable Variational Gaussian Process Classification}.
\newblock In G.~Lebanon and S.~V.~N. Vishwanathan, editors, \emph{Proceedings
  of the Eighteenth International Conference on Artificial Intelligence and
  Statistics}, volume~38 of \emph{Proceedings of Machine Learning Research},
  pages 351--360, San Diego, California, USA, 09--12 May 2015. PMLR.

\bibitem[Holderrieth et~al.(2021)Holderrieth, Hutchinson, and
  Teh]{holderrieth2021equivalent}
P.~Holderrieth, M.~J. Hutchinson, and Y.~W. Teh.
\newblock Equivariant learning of stochastic fields: Gaussian processes and
  steerable conditional neural processes.
\newblock In M.~Meila and T.~Zhang, editors, \emph{Proceedings of the 38th
  International Conference on Machine Learning}, volume 139 of
  \emph{Proceedings of Machine Learning Research}, pages 4297--4307. PMLR,
  18--24 Jul 2021.

\bibitem[Hotelling(1936)]{hotelling1992relations}
H.~Hotelling.
\newblock Relations between two sets of variates.
\newblock \emph{Biometrika}, 28\penalty0 (3/4):\penalty0 321--377, 1936.
\newblock ISSN 00063444.

\bibitem[Jha et~al.(2023)Jha, Gong, Zhao, and Lina]{jha2023neural}
S.~Jha, D.~Gong, H.~Zhao, and Y.~Lina.
\newblock {NPCL}: Neural processes for uncertainty-aware continual learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2023.

\bibitem[J{\o}sang(2016)]{josang2016subjective}
A.~J{\o}sang.
\newblock Belief fusion.
\newblock In \emph{Subjective Logic}, volume~3, chapter~12, pages 207--236.
  Springer, 2016.

\bibitem[Jung et~al.(2022)Jung, Zhao, Dipnall, Gabbe, and
  Du]{jung2022uncertainty}
M.~C. Jung, H.~Zhao, J.~Dipnall, B.~Gabbe, and L.~Du.
\newblock Uncertainty estimation for multi-view data: The power of seeing the
  whole picture.
\newblock In A.~H. Oh, A.~Agarwal, D.~Belgrave, and K.~Cho, editors,
  \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Kandemir et~al.(2022)Kandemir, Akg{\"u}l, Haussmann, and
  Unal]{kandemir2022evidential}
M.~Kandemir, A.~Akg{\"u}l, M.~Haussmann, and G.~Unal.
\newblock Evidential turing processes.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Kawano et~al.(2021)Kawano, Kumagai, Sannai, Iwasawa, and
  Matsuo]{kawano2021group}
M.~Kawano, W.~Kumagai, A.~Sannai, Y.~Iwasawa, and Y.~Matsuo.
\newblock Group equivariant conditional neural processes.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Khosla et~al.(2020)Khosla, Teterwak, Wang, Sarna, Tian, Isola,
  Maschinot, Liu, and Krishnan]{khosla2020supervised}
P.~Khosla, P.~Teterwak, C.~Wang, A.~Sarna, Y.~Tian, P.~Isola, A.~Maschinot,
  C.~Liu, and D.~Krishnan.
\newblock Supervised contrastive learning.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 18661--18673. Curran Associates, Inc., 2020.

\bibitem[Kim et~al.(2019)Kim, Mnih, Schwarz, Garnelo, Eslami, Rosenbaum,
  Vinyals, and Teh]{kim2018attentive}
H.~Kim, A.~Mnih, J.~Schwarz, M.~Garnelo, A.~Eslami, D.~Rosenbaum, O.~Vinyals,
  and Y.~W. Teh.
\newblock Attentive neural processes.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Kim et~al.(2022)Kim, Go, and Yun]{kim2022neural}
M.~Kim, K.~R. Go, and S.-Y. Yun.
\newblock Neural processes with stochastic attention: Paying more attention to
  the context dataset.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Kingma and Ba(2015)]{kingma2015adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In Y.~Bengio and Y.~LeCun, editors, \emph{3rd International
  Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May
  7-9, 2015, Conference Track Proceedings}, 2015.

\bibitem[Krizhevsky and Hinton(2009)]{krizhevsky2009learning}
A.~Krizhevsky and G.~Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock \emph{Master's thesis, Department of Computer Science, University of
  Toronto}, 2009.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and
  Blundell]{lakshminarayanan2017simple}
B.~Lakshminarayanan, A.~Pritzel, and C.~Blundell.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock In \emph{Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, NIPS'17, page 6405–6416, Red Hook, NY,
  USA, 2017. Curran Associates Inc.
\newblock ISBN 9781510860964.

\bibitem[Lee et~al.(2020{\natexlab{a}})Lee, Hong, and Kim]{kim2020residual}
B.-J. Lee, S.~Hong, and K.-E. Kim.
\newblock Residual neural processes.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  34\penalty0 (04):\penalty0 4545--4552, Apr. 2020{\natexlab{a}}.
\newblock \doi{10.1609/aaai.v34i04.5883}.

\bibitem[Lee et~al.(2020{\natexlab{b}})Lee, Humt, Feng, and
  Triebel]{lee2020estimating}
J.~Lee, M.~Humt, J.~Feng, and R.~Triebel.
\newblock Estimating model uncertainty of neural networks in sparse information
  form.
\newblock In H.~D. III and A.~Singh, editors, \emph{Proceedings of the 37th
  International Conference on Machine Learning}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 5702--5713. PMLR,
  13--18 Jul 2020{\natexlab{b}}.

\bibitem[Liu et~al.(2020)Liu, Lin, Padhy, Tran, Bedrax~Weiss, and
  Lakshminarayanan]{liu2020simple}
J.~Liu, Z.~Lin, S.~Padhy, D.~Tran, T.~Bedrax~Weiss, and B.~Lakshminarayanan.
\newblock Simple and principled uncertainty estimation with deterministic deep
  learning via distance awareness.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 7498--7512. Curran Associates, Inc., 2020.

\bibitem[Lu et~al.(2019)Lu, Batra, Parikh, and Lee]{lu2019vilbert}
J.~Lu, D.~Batra, D.~Parikh, and S.~Lee.
\newblock Vilbert: Pretraining task-agnostic visiolinguistic representations
  for vision-and-language tasks.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.

\bibitem[Ma et~al.(2021)Ma, Han, Zhang, Fu, Zhou, and Hu]{ma2021trustworthy}
H.~Ma, Z.~Han, C.~Zhang, H.~Fu, J.~T. Zhou, and Q.~Hu.
\newblock Trustworthy multimodal regression with mixture of normal-inverse
  gamma distributions.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.~Liang, and J.~W.
  Vaughan, editors, \emph{Advances in Neural Information Processing Systems},
  volume~34, pages 6881--6893. Curran Associates, Inc., 2021.

\bibitem[Malinin and Gales(2018)]{malinin2018predictive}
A.~Malinin and M.~Gales.
\newblock Predictive uncertainty estimation via prior networks.
\newblock In \emph{Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, NIPS'18, page 7047–7058, Red Hook, NY,
  USA, 2018. Curran Associates Inc.

\bibitem[Martins and Astudillo(2016)]{martins2016from}
A.~Martins and R.~Astudillo.
\newblock From softmax to sparsemax: A sparse model of attention and
  multi-label classification.
\newblock In M.~F. Balcan and K.~Q. Weinberger, editors, \emph{Proceedings of
  The 33rd International Conference on Machine Learning}, volume~48 of
  \emph{Proceedings of Machine Learning Research}, pages 1614--1623, New York,
  New York, USA, 20--22 Jun 2016. PMLR.

\bibitem[Meronen et~al.(2020)Meronen, Irwanto, and
  Solin]{meronen2020stationary}
L.~Meronen, C.~Irwanto, and A.~Solin.
\newblock Stationary activations for uncertainty calibration in deep learning.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 2338--2350. Curran Associates, Inc., 2020.

\bibitem[Meronen et~al.(2021)Meronen, Trapp, and Solin]{meronen2021periodic}
L.~Meronen, M.~Trapp, and A.~Solin.
\newblock Periodic activation functions induce stationarity.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.~Liang, and J.~W.
  Vaughan, editors, \emph{Advances in Neural Information Processing Systems},
  volume~34, pages 1673--1685. Curran Associates, Inc., 2021.

\bibitem[Milios et~al.(2018)Milios, Camoriano, Michiardi, Rosasco, and
  Filippone]{milios2018dirichlet}
D.~Milios, R.~Camoriano, P.~Michiardi, L.~Rosasco, and M.~Filippone.
\newblock Dirichlet-based gaussian processes for large-scale calibrated
  classification.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, \emph{Advances in Neural Information Processing
  Systems}, volume~31. Curran Associates, Inc., 2018.

\bibitem[Minderer et~al.(2021)Minderer, Djolonga, Romijnders, Hubis, Zhai,
  Houlsby, Tran, and Lucic]{minderer2021revisiting}
M.~Minderer, J.~Djolonga, R.~Romijnders, F.~A. Hubis, X.~Zhai, N.~Houlsby,
  D.~Tran, and M.~Lucic.
\newblock Revisiting the calibration of modern neural networks.
\newblock In A.~Beygelzimer, Y.~Dauphin, P.~Liang, and J.~W. Vaughan, editors,
  \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Murphy(2022)]{murphy2022probabilistic}
K.~P. Murphy.
\newblock \emph{Probabilistic machine learning: an introduction}.
\newblock MIT press, 2022.

\bibitem[Nair et~al.(2020)Nair, Precup, Arnold, and Arbel]{nair2020exploring}
T.~Nair, D.~Precup, D.~L. Arnold, and T.~Arbel.
\newblock Exploring uncertainty measures in deep networks for multiple
  sclerosis lesion detection and segmentation.
\newblock \emph{Medical Image Analysis}, 59:\penalty0 101557, 2020.
\newblock ISSN 1361-8415.
\newblock \doi{https://doi.org/10.1016/j.media.2019.101557}.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Ng]{netzer2011reading}
Y.~Netzer, T.~Wang, A.~Coates, A.~Bissacco, B.~Wu, and A.~Y. Ng.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In \emph{NIPS Workshop on Deep Learning and Unsupervised Feature
  Learning}, 2011.

\bibitem[Nguyen and Grover(2022)]{nguyen2022transformer}
T.~Nguyen and A.~Grover.
\newblock Transformer neural processes: Uncertainty-aware meta learning via
  sequence modeling.
\newblock In K.~Chaudhuri, S.~Jegelka, L.~Song, C.~Szepesvari, G.~Niu, and
  S.~Sabato, editors, \emph{Proceedings of the 39th International Conference on
  Machine Learning}, volume 162 of \emph{Proceedings of Machine Learning
  Research}, pages 16569--16594. PMLR, 17--23 Jul 2022.

\bibitem[Requeima et~al.(2019)Requeima, Gordon, Bronskill, Nowozin, and
  Turner]{requeima2019fast}
J.~Requeima, J.~Gordon, J.~Bronskill, S.~Nowozin, and R.~E. Turner.
\newblock Fast and flexible multi-task classification using conditional neural
  adaptive processes.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.

\bibitem[Roy et~al.(2019)Roy, Conjeti, Navab, and Wachinger]{roy2019bayesian}
A.~G. Roy, S.~Conjeti, N.~Navab, and C.~Wachinger.
\newblock Bayesian quicknat: Model uncertainty in deep whole-brain segmentation
  for structure-wise quality control.
\newblock \emph{NeuroImage}, 195:\penalty0 11--22, 2019.
\newblock ISSN 1053-8119.
\newblock \doi{https://doi.org/10.1016/j.neuroimage.2019.03.042}.

\bibitem[Sensoy et~al.(2018)Sensoy, Kaplan, and Kandemir]{sensoy2018evidential}
M.~Sensoy, L.~Kaplan, and M.~Kandemir.
\newblock Evidential deep learning to quantify classification uncertainty.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, \emph{Advances in Neural Information Processing
  Systems}, volume~31. Curran Associates, Inc., 2018.

\bibitem[Singh et~al.(2019)Singh, Yoon, Son, and Ahn]{singh2019sequential}
G.~Singh, J.~Yoon, Y.~Son, and S.~Ahn.
\newblock Sequential neural processes.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.

\bibitem[Sun et~al.(2019)Sun, Myers, Vondrick, Murphy, and
  Schmid]{sun2019videobert}
C.~Sun, A.~Myers, C.~Vondrick, K.~Murphy, and C.~Schmid.
\newblock Videobert: A joint model for video and language representation
  learning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, October 2019.

\bibitem[Suresh and Srinivasan(2019)]{suresh2019improved}
A.~Suresh and S.~Srinivasan.
\newblock Improved attentive neural processes.
\newblock In \emph{Fourth Workshop on Bayesian Deep Learning at the Conference
  on Neural Information Processing Systems}, volume~14, page~17, 2019.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy2016rethinking}
C.~Szegedy, V.~Vanhoucke, S.~Ioffe, J.~Shlens, and Z.~Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2016.

\bibitem[Toriya et~al.(2019)Toriya, Dewan, and Kitahara]{toriya2019sar2}
H.~Toriya, A.~Dewan, and I.~Kitahara.
\newblock Sar2opt: Image alignment between multi-modal images using generative
  adversarial networks.
\newblock In \emph{IGARSS 2019 - 2019 IEEE International Geoscience and Remote
  Sensing Symposium}, pages 923--926, 2019.
\newblock \doi{10.1109/IGARSS.2019.8898605}.

\bibitem[Ulapane et~al.(2020)Ulapane, Thiyagarajan, and
  Kodagoda]{ulapane2020hyper}
N.~Ulapane, K.~Thiyagarajan, and S.~Kodagoda.
\newblock Hyper-parameter initialization for squared exponential kernel-based
  gaussian process regression.
\newblock In \emph{2020 15th IEEE Conference on Industrial Electronics and
  Applications (ICIEA)}, pages 1154--1159, 2020.
\newblock \doi{10.1109/ICIEA48937.2020.9248120}.

\bibitem[Valdenegro-Toro(2019)]{valdenegro2019deep}
M.~Valdenegro-Toro.
\newblock Deep sub-ensembles for fast uncertainty estimation in image
  classification.
\newblock \emph{arXiv preprint arXiv:1910.08168}, 2019.

\bibitem[Van~Amersfoort et~al.(2020)Van~Amersfoort, Smith, Teh, and
  Gal]{van2020uncertainty}
J.~Van~Amersfoort, L.~Smith, Y.~W. Teh, and Y.~Gal.
\newblock Uncertainty estimation using a single deep deterministic neural
  network.
\newblock In H.~D. III and A.~Singh, editors, \emph{Proceedings of the 37th
  International Conference on Machine Learning}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 9690--9700. PMLR,
  13--18 Jul 2020.

\bibitem[van Amersfoort et~al.(2021)van Amersfoort, Smith, Jesson, Key, and
  Gal]{van2021feature}
J.~van Amersfoort, L.~Smith, A.~Jesson, O.~Key, and Y.~Gal.
\newblock On feature collapse and deep kernel learning for single forward pass
  uncertainty.
\newblock \emph{arXiv preprint arXiv:2102.11409}, 2021.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, L.~u.
  Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock In I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.

\bibitem[Volpp et~al.(2021)Volpp, Fl{\"u}renbrock, Grossberger, Daniel, and
  Neumann]{volpp2021bayesian}
M.~Volpp, F.~Fl{\"u}renbrock, L.~Grossberger, C.~Daniel, and G.~Neumann.
\newblock Bayesian context aggregation for neural processes.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Wang et~al.(2022)Wang, Lukasiewicz, Massiceti, Hu, Pavlovic, and
  Neophytou]{wang2022NP}
J.~Wang, T.~Lukasiewicz, D.~Massiceti, X.~Hu, V.~Pavlovic, and A.~Neophytou.
\newblock {NP}-match: When neural processes meet semi-supervised learning.
\newblock In K.~Chaudhuri, S.~Jegelka, L.~Song, C.~Szepesvari, G.~Niu, and
  S.~Sabato, editors, \emph{Proceedings of the 39th International Conference on
  Machine Learning}, volume 162 of \emph{Proceedings of Machine Learning
  Research}, pages 22919--22934. PMLR, 17--23 Jul 2022.

\bibitem[Wen et~al.(2020)Wen, Tran, and Ba]{wen2020batchensemble}
Y.~Wen, D.~Tran, and J.~Ba.
\newblock Batchensemble: an alternative approach to efficient ensemble and
  lifelong learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Williams(1996)]{williams1996infitie}
C.~Williams.
\newblock Computing with infinite networks.
\newblock In M.~Mozer, M.~Jordan, and T.~Petsche, editors, \emph{Advances in
  Neural Information Processing Systems}, volume~9. MIT Press, 1996.

\bibitem[Williams and Rasmussen(2006)]{williams2006gaussian}
C.~K. Williams and C.~E. Rasmussen.
\newblock \emph{Gaussian Processes for Machine Learning}.
\newblock The MIT Press, 2006.

\bibitem[Xu et~al.(2015)Xu, Wang, Chen, and Li]{xu2015empirical}
B.~Xu, N.~Wang, T.~Chen, and M.~Li.
\newblock Empirical evaluation of rectified activations in convolutional
  network.
\newblock \emph{arXiv preprint arXiv:1505.00853}, 2015.

\bibitem[Yoon et~al.(2020)Yoon, Singh, and Ahn]{yoon2020robustifying}
J.~Yoon, G.~Singh, and S.~Ahn.
\newblock Robustifying sequential neural processes.
\newblock In H.~D. III and A.~Singh, editors, \emph{Proceedings of the 37th
  International Conference on Machine Learning}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 10861--10870. PMLR,
  13--18 Jul 2020.

\end{thebibliography}
