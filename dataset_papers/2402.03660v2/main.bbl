\begin{thebibliography}{66}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Adilova et~al.(2023)Adilova, Fischer, and Jaggi]{adilova2023layerwise}
Adilova, L., Fischer, A., and Jaggi, M.
\newblock Layerwise linear mode connectivity.
\newblock \emph{arXiv preprint arXiv:2307.06966}, 2023.

\bibitem[Ainsworth et~al.(2023)Ainsworth, Hayase, and Srinivasa]{ainsworth2023git}
Ainsworth, S., Hayase, J., and Srinivasa, S.
\newblock Git re-basin: Merging models modulo permutation symmetries.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=CQsmMYmlP5T}.

\bibitem[Bansal et~al.(2021)Bansal, Nakkiran, and Barak]{bansal2021revisiting}
Bansal, Y., Nakkiran, P., and Barak, B.
\newblock Revisiting model stitching to compare neural representations.
\newblock In Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan, J.~W. (eds.), \emph{Advances in Neural Information Processing Systems}, 2021.
\newblock URL \url{https://openreview.net/forum?id=ak06J5jNR4}.

\bibitem[Chen et~al.(2024)Chen, Zhou, and Yan]{chen2024going}
Chen, Y., Zhou, Z., and Yan, J.
\newblock Going beyond neural network feature similarity: The network feature complexity and its interpretation using category theory.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=4bSQ3lsfEV}.

\bibitem[Cheng et~al.(2017)Cheng, Han, and Lu]{cheng2017remote}
Cheng, G., Han, J., and Lu, X.
\newblock Remote sensing image scene classification: Benchmark and state of the art.
\newblock \emph{Proceedings of the IEEE}, 105\penalty0 (10):\penalty0 1865--1883, 2017.

\bibitem[Cimpoi et~al.(2014)Cimpoi, Maji, Kokkinos, Mohamed, and Vedaldi]{cimpoi2014describing}
Cimpoi, M., Maji, S., Kokkinos, I., Mohamed, S., and Vedaldi, A.
\newblock Describing textures in the wild.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  3606--3613, 2014.

\bibitem[contributors(2016)]{torchvision2016}
contributors, T.
\newblock Torchvision: Pytorch's computer vision library.
\newblock \url{https://github.com/pytorch/vision}, 2016.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE Conference on Computer Vision and Pattern Recognition}, pp.\  248--255, 2009.
\newblock \doi{10.1109/CVPR.2009.5206848}.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, et~al.]{dosovitskiy2020image}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Draxler et~al.(2018)Draxler, Veschgini, Salmhofer, and Hamprecht]{draxler2018essentially}
Draxler, F., Veschgini, K., Salmhofer, M., and Hamprecht, F.
\newblock Essentially no barriers in neural network energy landscape.
\newblock In \emph{International conference on machine learning}, pp.\  1309--1318. PMLR, 2018.

\bibitem[Elhage et~al.(2021)Elhage, Nanda, Olsson, Henighan, Joseph, Mann, Askell, Bai, Chen, Conerly, DasSarma, Drain, Ganguli, Hatfield-Dodds, Hernandez, Jones, Kernion, Lovitt, Ndousse, Amodei, Brown, Clark, Kaplan, McCandlish, and Olah]{elhage2021mathematical}
Elhage, N., Nanda, N., Olsson, C., Henighan, T., Joseph, N., Mann, B., Askell, A., Bai, Y., Chen, A., Conerly, T., DasSarma, N., Drain, D., Ganguli, D., Hatfield-Dodds, Z., Hernandez, D., Jones, A., Kernion, J., Lovitt, L., Ndousse, K., Amodei, D., Brown, T., Clark, J., Kaplan, J., McCandlish, S., and Olah, C.
\newblock A mathematical framework for transformer circuits.
\newblock \emph{Transformer Circuits Thread}, 2021.
\newblock https://transformer-circuits.pub/2021/framework/index.html.

\bibitem[Entezari et~al.(2022)Entezari, Sedghi, Saukh, and Neyshabur]{entezari2022the}
Entezari, R., Sedghi, H., Saukh, O., and Neyshabur, B.
\newblock The role of permutation invariance in linear mode connectivity of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=dNigytemkL}.

\bibitem[Fabbri et~al.(2019)Fabbri, Li, She, Li, and Radev]{fabbri2019multi}
Fabbri, A.~R., Li, I., She, T., Li, S., and Radev, D.~R.
\newblock Multi-news: A large-scale multi-document summarization dataset and abstractive hierarchical model.
\newblock \emph{arXiv preprint arXiv:1906.01749}, 2019.

\bibitem[Ferbach et~al.(2023)Ferbach, Goujaud, Gidel, and Dieuleveut]{ferbach2023proving}
Ferbach, D., Goujaud, B., Gidel, G., and Dieuleveut, A.
\newblock Proving linear mode connectivity of neural networks via optimal transport.
\newblock \emph{arXiv preprint arXiv:2310.19103}, 2023.

\bibitem[Fort et~al.(2020)Fort, Dziugaite, Paul, Kharaghani, Roy, and Ganguli]{fort2020deep}
Fort, S., Dziugaite, G.~K., Paul, M., Kharaghani, S., Roy, D.~M., and Ganguli, S.
\newblock Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the neural tangent kernel.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 5850--5861, 2020.

\bibitem[Frankle et~al.(2020)Frankle, Dziugaite, Roy, and Carbin]{frankle2020linear}
Frankle, J., Dziugaite, G.~K., Roy, D., and Carbin, M.
\newblock Linear mode connectivity and the lottery ticket hypothesis.
\newblock In \emph{International Conference on Machine Learning}, pp.\  3259--3269. PMLR, 2020.

\bibitem[Freeman \& Bruna(2017)Freeman and Bruna]{freeman2017topology}
Freeman, C.~D. and Bruna, J.
\newblock Topology and geometry of half-rectified network optimization.
\newblock In \emph{International Conference on Learning Representations}, 2017.
\newblock URL \url{https://openreview.net/forum?id=Bk0FWVcgx}.

\bibitem[Garipov et~al.(2018)Garipov, Izmailov, Podoprikhin, Vetrov, and Wilson]{garipov2018loss}
Garipov, T., Izmailov, P., Podoprikhin, D., Vetrov, D.~P., and Wilson, A.~G.
\newblock Loss surfaces, mode connectivity, and fast ensembling of dnns.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{kaiming2016residual}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  770--778, 2016.
\newblock \doi{10.1109/CVPR.2016.90}.

\bibitem[Helber et~al.(2019)Helber, Bischke, Dengel, and Borth]{helber2019eurosat}
Helber, P., Bischke, B., Dengel, A., and Borth, D.
\newblock Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification.
\newblock \emph{IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 12\penalty0 (7):\penalty0 2217--2226, 2019.

\bibitem[Ilharco et~al.(2022)Ilharco, Wortsman, Gadre, Song, Hajishirzi, Kornblith, Farhadi, and Schmidt]{ilharco2022patching}
Ilharco, G., Wortsman, M., Gadre, S.~Y., Song, S., Hajishirzi, H., Kornblith, S., Farhadi, A., and Schmidt, L.
\newblock Patching open-vocabulary models by interpolating weights.
\newblock In Oh, A.~H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=CZZFRxbOLC}.

\bibitem[Ilharco et~al.(2023)Ilharco, Ribeiro, Wortsman, Schmidt, Hajishirzi, and Farhadi]{ilharco2023editing}
Ilharco, G., Ribeiro, M.~T., Wortsman, M., Schmidt, L., Hajishirzi, H., and Farhadi, A.
\newblock Editing models with task arithmetic.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=6t0Kwf8-jrj}.

\bibitem[Izmailov et~al.(2018)Izmailov, Podoprikhin, Garipov, Vetrov, and Wilson]{DBLP:conf/uai/IzmailovPGVW18}
Izmailov, P., Podoprikhin, D., Garipov, T., Vetrov, D.~P., and Wilson, A.~G.
\newblock Averaging weights leads to wider optima and better generalization.
\newblock In Globerson, A. and Silva, R. (eds.), \emph{Proceedings of the Thirty-Fourth Conference on Uncertainty in Artificial Intelligence, {UAI} 2018, Monterey, California, USA, August 6-10, 2018}, pp.\  876--885. {AUAI} Press, 2018.
\newblock URL \url{http://auai.org/uai2018/proceedings/papers/313.pdf}.

\bibitem[Jin et~al.(2023)Jin, Ren, Preotiuc-Pietro, and Cheng]{jin2023dataless}
Jin, X., Ren, X., Preotiuc-Pietro, D., and Cheng, P.
\newblock Dataless knowledge fusion by merging weights of language models.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=FCnohuR6AnM}.

\bibitem[Juneja et~al.(2023)Juneja, Bansal, Cho, Sedoc, and Saphra]{juneja2023linear}
Juneja, J., Bansal, R., Cho, K., Sedoc, J., and Saphra, N.
\newblock Linear connectivity reveals generalization strategies.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=hY6M0JHl3uL}.

\bibitem[Khot et~al.(2020)Khot, Clark, Guerquin, Jansen, and Sabharwal]{khot2020qasc}
Khot, T., Clark, P., Guerquin, M., Jansen, P., and Sabharwal, A.
\newblock Qasc: A dataset for question answering via sentence composition.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~34, pp.\  8082--8090, 2020.

\bibitem[Krause et~al.(2013)Krause, Stark, Deng, and Fei-Fei]{Krause20133DOR}
Krause, J., Stark, M., Deng, J., and Fei-Fei, L.
\newblock 3d object representations for fine-grained categorization.
\newblock \emph{2013 IEEE International Conference on Computer Vision Workshops}, pp.\  554--561, 2013.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:14342571}.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton, et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Kuditipudi et~al.(2019)Kuditipudi, Wang, Lee, Zhang, Li, Hu, Ge, and Arora]{kuditipudi2019explaining}
Kuditipudi, R., Wang, X., Lee, H., Zhang, Y., Li, Z., Hu, W., Ge, R., and Arora, S.
\newblock Explaining landscape connectivity of low-cost solutions for multilayer nets.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Lai et~al.(2017)Lai, Xie, Liu, Yang, and Hovy]{lai2017race}
Lai, G., Xie, Q., Liu, H., Yang, Y., and Hovy, E.
\newblock Race: Large-scale reading comprehension dataset from examinations.
\newblock \emph{arXiv preprint arXiv:1704.04683}, 2017.

\bibitem[LeCun \& Cortes(2005)LeCun and Cortes]{LeCun2005TheMD}
LeCun, Y. and Cortes, C.
\newblock The mnist database of handwritten digits.
\newblock 2005.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:60282629}.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and Haffner]{lecun1998gradient}
LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0 2278--2324, 1998.

\bibitem[Lenc \& Vedaldi(2015)Lenc and Vedaldi]{lenc2015understanding}
Lenc, K. and Vedaldi, A.
\newblock Understanding image representations by measuring their equivariance and equivalence.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  991--999, 2015.

\bibitem[Li et~al.(2022)Li, Gururangan, Dettmers, Lewis, Althoff, Smith, and Zettlemoyer]{li2022branchtrainmerge}
Li, M., Gururangan, S., Dettmers, T., Lewis, M., Althoff, T., Smith, N.~A., and Zettlemoyer, L.
\newblock Branch-train-merge: Embarrassingly parallel training of expert language models.
\newblock In \emph{First Workshop on Interpolation Regularizers and Beyond at NeurIPS 2022}, 2022.
\newblock URL \url{https://openreview.net/forum?id=SQgVgE2Sq4}.

\bibitem[Liang et~al.(2018)Liang, Sun, Li, and Srikant]{liang2018understanding}
Liang, S., Sun, R., Li, Y., and Srikant, R.
\newblock Understanding the loss surface of neural networks for binary classification.
\newblock In \emph{International Conference on Machine Learning}, pp.\  2835--2843. PMLR, 2018.

\bibitem[Lin et~al.(2019)Lin, Zhou, Shen, Zhou, Bhagavatula, Choi, and Ren]{lin2019commongen}
Lin, B.~Y., Zhou, W., Shen, M., Zhou, P., Bhagavatula, C., Choi, Y., and Ren, X.
\newblock Commongen: A constrained text generation challenge for generative commonsense reasoning.
\newblock \emph{arXiv preprint arXiv:1911.03705}, 2019.

\bibitem[Liu et~al.(2022)Liu, Lou, Wang, Xi, Shen, and Yan]{pmlr-v162-liu22k}
Liu, C., Lou, C., Wang, R., Xi, A.~Y., Shen, L., and Yan, J.
\newblock Deep neural network fusion via graph matching with applications to model ensemble and federated learning.
\newblock In Chaudhuri, K., Jegelka, S., Song, L., Szepesvari, C., Niu, G., and Sabato, S. (eds.), \emph{Proceedings of the 39th International Conference on Machine Learning}, volume 162 of \emph{Proceedings of Machine Learning Research}, pp.\  13857--13869. PMLR, 17--23 Jul 2022.
\newblock URL \url{https://proceedings.mlr.press/v162/liu22k.html}.

\bibitem[Maas et~al.(2011)Maas, Daly, Pham, Huang, Ng, and Potts]{maas2011learning}
Maas, A., Daly, R.~E., Pham, P.~T., Huang, D., Ng, A.~Y., and Potts, C.
\newblock Learning word vectors for sentiment analysis.
\newblock In \emph{Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies}, pp.\  142--150, 2011.

\bibitem[Matena \& Raffel(2022)Matena and Raffel]{matena2022merging}
Matena, M.~S. and Raffel, C.
\newblock Merging models with fisher-weighted averaging.
\newblock In Oh, A.~H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=LSKlp_aceOC}.

\bibitem[McCloskey \& Cohen(1989)McCloskey and Cohen]{mccloskey1989catastrophic}
McCloskey, M. and Cohen, N.~J.
\newblock Catastrophic interference in connectionist networks: The sequential learning problem.
\newblock In \emph{Psychology of learning and motivation}, volume~24, pp.\  109--165. Elsevier, 1989.

\bibitem[Mirzadeh et~al.(2021)Mirzadeh, Farajtabar, Gorur, Pascanu, and Ghasemzadeh]{mirzadeh2021linear}
Mirzadeh, S.~I., Farajtabar, M., Gorur, D., Pascanu, R., and Ghasemzadeh, H.
\newblock Linear mode connectivity in multitask and continual learning.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=Fmg_fQYUejf}.

\bibitem[Nagarajan \& Kolter(2019)Nagarajan and Kolter]{nagarajan2019uniform}
Nagarajan, V. and Kolter, J.~Z.
\newblock Uniform convergence may be unable to explain generalization in deep learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and Ng]{netzer2011reading}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock 2011.

\bibitem[Nguyen(2019)]{nguyen2019connected}
Nguyen, Q.
\newblock On connected sublevel sets in deep learning.
\newblock In \emph{International conference on machine learning}, pp.\  4790--4799. PMLR, 2019.

\bibitem[Nguyen et~al.(2019)Nguyen, Mukkamala, and Hein]{nguyen2018loss}
Nguyen, Q., Mukkamala, M.~C., and Hein, M.
\newblock On the loss landscape of a class of deep neural networks with no bad local valleys.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=HJgXsjA5tQ}.

\bibitem[Ni et~al.(2021)Ni, {\'A}brego, Constant, Ma, Hall, Cer, and Yang]{ni2021sentence}
Ni, J., {\'A}brego, G.~H., Constant, N., Ma, J., Hall, K.~B., Cer, D., and Yang, Y.
\newblock Sentence-t5: Scalable sentence encoders from pre-trained text-to-text models.
\newblock \emph{arXiv preprint arXiv:2108.08877}, 2021.

\bibitem[Olsson et~al.(2022)Olsson, Elhage, Nanda, Joseph, DasSarma, Henighan, Mann, Askell, Bai, Chen, Conerly, Drain, Ganguli, Hatfield-Dodds, Hernandez, Johnston, Jones, Kernion, Lovitt, Ndousse, Amodei, Brown, Clark, Kaplan, McCandlish, and Olah]{olsson2022context}
Olsson, C., Elhage, N., Nanda, N., Joseph, N., DasSarma, N., Henighan, T., Mann, B., Askell, A., Bai, Y., Chen, A., Conerly, T., Drain, D., Ganguli, D., Hatfield-Dodds, Z., Hernandez, D., Johnston, S., Jones, A., Kernion, J., Lovitt, L., Ndousse, K., Amodei, D., Brown, T., Clark, J., Kaplan, J., McCandlish, S., and Olah, C.
\newblock In-context learning and induction heads.
\newblock \emph{Transformer Circuits Thread}, 2022.
\newblock https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html.

\bibitem[Ortiz-Jimenez et~al.(2023)Ortiz-Jimenez, Favero, and Frossard]{ortiz-jimenez2023task}
Ortiz-Jimenez, G., Favero, A., and Frossard, P.
\newblock Task arithmetic in the tangent space: Improved editing of pre-trained models.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=0A9f2jZDGW}.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin, Zhang, Agarwal, Slama, Gray, Schulman, Hilton, Kelton, Miller, Simens, Askell, Welinder, Christiano, Leike, and Lowe]{ouyang2022training}
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Gray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., and Lowe, R.
\newblock Training language models to follow instructions with human feedback.
\newblock In Oh, A.~H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=TG8KACxEON}.

\bibitem[Qin et~al.(2022)Qin, Qian, Yi, Chen, Lin, Han, Liu, Sun, and Zhou]{qin-etal-2022-exploring}
Qin, Y., Qian, C., Yi, J., Chen, W., Lin, Y., Han, X., Liu, Z., Sun, M., and Zhou, J.
\newblock Exploring mode connectivity for pre-trained language models.
\newblock In Goldberg, Y., Kozareva, Z., and Zhang, Y. (eds.), \emph{Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing}, pp.\  6726--6746, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2022.emnlp-main.451}.
\newblock URL \url{https://aclanthology.org/2022.emnlp-main.451}.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li, and Liu]{raffel2020exploring}
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P.~J.
\newblock Exploring the limits of transfer learning with a unified text-to-text transformer.
\newblock \emph{The Journal of Machine Learning Research}, 21\penalty0 (1):\penalty0 5485--5551, 2020.

\bibitem[Rajpurkar et~al.(2016)Rajpurkar, Zhang, Lopyrev, and Liang]{rajpurkar2016squad}
Rajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P.
\newblock Squad: 100,000+ questions for machine comprehension of text.
\newblock \emph{arXiv preprint arXiv:1606.05250}, 2016.

\bibitem[Rame et~al.(2022)Rame, Kirchmeyer, Rahier, Rakotomamonjy, patrick gallinari, and Cord]{rame2022diverse}
Rame, A., Kirchmeyer, M., Rahier, T., Rakotomamonjy, A., patrick gallinari, and Cord, M.
\newblock Diverse weight averaging for out-of-distribution generalization.
\newblock In Oh, A.~H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=tq_J_MqB3UB}.

\bibitem[Rame et~al.(2023)Rame, Ahuja, Zhang, Cord, Bottou, and Lopez-Paz]{pmlr-v202-rame23a}
Rame, A., Ahuja, K., Zhang, J., Cord, M., Bottou, L., and Lopez-Paz, D.
\newblock Model ratatouille: Recycling diverse models for out-of-distribution generalization.
\newblock In Krause, A., Brunskill, E., Cho, K., Engelhardt, B., Sabato, S., and Scarlett, J. (eds.), \emph{Proceedings of the 40th International Conference on Machine Learning}, volume 202 of \emph{Proceedings of Machine Learning Research}, pp.\  28656--28679. PMLR, 23--29 Jul 2023.
\newblock URL \url{https://proceedings.mlr.press/v202/rame23a.html}.

\bibitem[Singh \& Jaggi(2020)Singh and Jaggi]{singh2020model}
Singh, S.~P. and Jaggi, M.
\newblock Model fusion via optimal transport.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 22045--22055, 2020.

\bibitem[Stallkamp et~al.(2011)Stallkamp, Schlipsing, Salmen, and Igel]{stallkamp2011german}
Stallkamp, J., Schlipsing, M., Salmen, J., and Igel, C.
\newblock The german traffic sign recognition benchmark: a multi-class classification competition.
\newblock In \emph{The 2011 international joint conference on neural networks}, pp.\  1453--1460. IEEE, 2011.

\bibitem[Stoica et~al.(2023)Stoica, Bolya, Bjorner, Hearn, and Hoffman]{stoica2023zipit}
Stoica, G., Bolya, D., Bjorner, J., Hearn, T., and Hoffman, J.
\newblock Zipit! merging models from different tasks without training, 2023.

\bibitem[Venturi et~al.(2019)Venturi, Bandeira, and Bruna]{venturi2018spurious}
Venturi, L., Bandeira, A.~S., and Bruna, J.
\newblock Spurious valleys in one-hidden-layer neural network optimization landscapes.
\newblock \emph{J. Mach. Learn. Res.}, 20:\penalty0 133:1--133:34, 2019.
\newblock URL \url{http://jmlr.org/papers/v20/18-674.html}.

\bibitem[Weidinger et~al.(2021)Weidinger, Mellor, Rauh, Griffin, Uesato, Huang, Cheng, Glaese, Balle, Kasirzadeh, Kenton, Brown, Hawkins, Stepleton, Biles, Birhane, Haas, Rimell, Hendricks, Isaac, Legassick, Irving, and Gabriel]{weidinger2021ethical}
Weidinger, L., Mellor, J., Rauh, M., Griffin, C., Uesato, J., Huang, P.-S., Cheng, M., Glaese, M., Balle, B., Kasirzadeh, A., Kenton, Z., Brown, S., Hawkins, W., Stepleton, T., Biles, C., Birhane, A., Haas, J., Rimell, L., Hendricks, L.~A., Isaac, W., Legassick, S., Irving, G., and Gabriel, I.
\newblock Ethical and social risks of harm from language models, 2021.

\bibitem[Wortsman et~al.(2022{\natexlab{a}})Wortsman, Ilharco, Gadre, Roelofs, Gontijo-Lopes, Morcos, Namkoong, Farhadi, Carmon, Kornblith, et~al.]{wortsman2022model}
Wortsman, M., Ilharco, G., Gadre, S.~Y., Roelofs, R., Gontijo-Lopes, R., Morcos, A.~S., Namkoong, H., Farhadi, A., Carmon, Y., Kornblith, S., et~al.
\newblock Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time.
\newblock In \emph{International Conference on Machine Learning}, pp.\  23965--23998. PMLR, 2022{\natexlab{a}}.

\bibitem[Wortsman et~al.(2022{\natexlab{b}})Wortsman, Ilharco, Kim, Li, Kornblith, Roelofs, Lopes, Hajishirzi, Farhadi, Namkoong, and Schmidt]{Wortsman_2022_CVPR}
Wortsman, M., Ilharco, G., Kim, J.~W., Li, M., Kornblith, S., Roelofs, R., Lopes, R.~G., Hajishirzi, H., Farhadi, A., Namkoong, H., and Schmidt, L.
\newblock Robust fine-tuning of zero-shot models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  7959--7971, June 2022{\natexlab{b}}.

\bibitem[Xiao et~al.(2016)Xiao, Ehinger, Hays, Torralba, and Oliva]{xiao2016sun}
Xiao, J., Ehinger, K.~A., Hays, J., Torralba, A., and Oliva, A.
\newblock Sun database: Exploring a large collection of scene categories.
\newblock \emph{International Journal of Computer Vision}, 119:\penalty0 3--22, 2016.

\bibitem[Yadav et~al.(2023)Yadav, Tam, Choshen, Raffel, and Bansal]{yadav2023tiesmerging}
Yadav, P., Tam, D., Choshen, L., Raffel, C., and Bansal, M.
\newblock {TIES}-merging: Resolving interference when merging models.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=xtaX3WyCj1}.

\bibitem[Yu et~al.(2023)Yu, Yu, Yu, Huang, and Li]{yu2023language}
Yu, L., Yu, B., Yu, H., Huang, F., and Li, Y.
\newblock Language models are super mario: Absorbing abilities from homologous models as a free lunch, 2023.

\bibitem[Zhao et~al.(2023)Zhao, Dehmamy, Walters, and Yu]{zhao2023understanding}
Zhao, B., Dehmamy, N., Walters, R., and Yu, R.
\newblock Understanding mode connectivity via parameter space symmetry.
\newblock In \emph{UniReps: the First Workshop on Unifying Representations in Neural Models}, 2023.
\newblock URL \url{https://openreview.net/forum?id=aP2a5i1iUf}.

\bibitem[Zhou et~al.(2023)Zhou, Yang, Yang, Yan, and Hu]{zhou2023going}
Zhou, Z., Yang, Y., Yang, X., Yan, J., and Hu, W.
\newblock Going beyond linear mode connectivity: The layerwise linear feature connectivity.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=vORUHrVEnH}.

\end{thebibliography}
