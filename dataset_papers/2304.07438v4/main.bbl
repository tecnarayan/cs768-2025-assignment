\begin{thebibliography}{53}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahmed et~al.(2022)Ahmed, Teso, Chang, Van~den Broeck, and
  Vergari]{AhmedNeurIPS22}
Ahmed, K., Teso, S., Chang, K.-W., Van~den Broeck, G., and Vergari, A.
\newblock Semantic probabilistic layers for neuro-symbolic learning.
\newblock In \emph{Advances in Neural Information Processing Systems 35
  (NeurIPS)}, 2022.

\bibitem[Anderson et~al.(2016)Anderson, Fernando, Johnson, and
  Gould]{anderson2016spice}
Anderson, P., Fernando, B., Johnson, M., and Gould, S.
\newblock Spice: Semantic propositional image caption evaluation.
\newblock In \emph{European Conference on Computer Vision (ECCV)}. Springer,
  2016.

\bibitem[Bahdanau et~al.(2015)Bahdanau, Cho, and Bengio]{bahdanau2015neural}
Bahdanau, D., Cho, K.~H., and Bengio, Y.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock In \emph{Proceedings of the 3rd International Conference on Learning
  Representations (ICLR)}, 2015.

\bibitem[Bekker et~al.(2015)Bekker, Davis, Choi, Darwiche, and Van~den
  Broeck]{BekkerNIPS15}
Bekker, J., Davis, J., Choi, A., Darwiche, A., and Van~den Broeck, G.
\newblock Tractable learning for complex probability queries.
\newblock In \emph{Advances in Neural Information Processing Systems 28
  (NIPS)}, 2015.

\bibitem[Boyd et~al.(2022)Boyd, Showalter, Mandt, and Smyth]{boydpredictive}
Boyd, A.~J., Showalter, S., Mandt, S., and Smyth, P.
\newblock Predictive querying for autoregressive neural sequence models.
\newblock In \emph{Advances in Neural Information Processing Systems 35
  (NeurIPS)}, 2022.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in Neural Information Processing Systems 33
  (NeurIPS)}, 2020.

\bibitem[Chiu \& Rush(2020)Chiu and Rush]{chiu2020scaling}
Chiu, J. and Rush, A.~M.
\newblock Scaling hidden markov language models.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, 2020.

\bibitem[Cho et~al.(2019)Cho, Zhang, Zhang, Li, Galley, Brockett, Wang, and
  Gao]{cho-etal-2019-towards}
Cho, W.~S., Zhang, P., Zhang, Y., Li, X., Galley, M., Brockett, C., Wang, M.,
  and Gao, J.
\newblock Towards coherent and cohesive long-form text generation.
\newblock In \emph{Proceedings of the First Workshop on Narrative
  Understanding}, pp.\  1--11, Minneapolis, Minnesota, June 2019. Association
  for Computational Linguistics.
\newblock \doi{10.18653/v1/W19-2401}.
\newblock URL \url{https://aclanthology.org/W19-2401}.

\bibitem[Choi et~al.(2015)Choi, Van~den Broeck, and Darwiche]{ChoiKRR15}
Choi, A., Van~den Broeck, G., and Darwiche, A.
\newblock Probability distributions over structured spaces.
\newblock In \emph{Proceedings of the AAAI Spring Symposium on KRR}, 2015.

\bibitem[Choi et~al.(2020{\natexlab{a}})Choi, Farnadi, Babaki, and Van~den
  Broeck]{ChoiAAAI20}
Choi, Y., Farnadi, G., Babaki, B., and Van~den Broeck, G.
\newblock Learning fair naive bayes classifiers by discovering and eliminating
  discrimination patterns.
\newblock In \emph{Proceedings of the 34th AAAI Conference on Artificial
  Intelligence}, 2020{\natexlab{a}}.

\bibitem[Choi et~al.(2020{\natexlab{b}})Choi, Vergari, and Van~den
  Broeck]{ProbCirc20}
Choi, Y., Vergari, A., and Van~den Broeck, G.
\newblock Probabilistic circuits: A unifying framework for tractable
  probabilistic models.
\newblock 2020{\natexlab{b}}.

\bibitem[Choi et~al.(2021)Choi, Dang, and Van~den Broeck]{ChoiAAAI21}
Choi, Y., Dang, M., and Van~den Broeck, G.
\newblock Group fairness by probabilistic modeling with latent fair decisions.
\newblock In \emph{Proceedings of the 35th AAAI Conference on Artificial
  Intelligence}, 2021.

\bibitem[Correia et~al.(2020)Correia, Peharz, and de~Campos]{correia2020joints}
Correia, A., Peharz, R., and de~Campos, C.~P.
\newblock Joints in random forests.
\newblock In \emph{Advances in Neural Information Processing Systems 33
  (NeurIPS)}, 2020.

\bibitem[Dang et~al.(2021)Dang, Khosravi, Liang, Vergari, and Van~den
  Broeck]{DangAAAI21}
Dang, M., Khosravi, P., Liang, Y., Vergari, A., and Van~den Broeck, G.
\newblock Juice: A julia package for logic and probabilistic circuits.
\newblock In \emph{Proceedings of the 35th AAAI Conference on Artificial
  Intelligence (Demo Track)}, 2021.

\bibitem[Dang et~al.(2022{\natexlab{a}})Dang, Liu, and Van~den
  Broeck]{DangNeurIPS22}
Dang, M., Liu, A., and Van~den Broeck, G.
\newblock Sparse probabilistic circuits via pruning and growing.
\newblock In \emph{Advances in Neural Information Processing Systems 35
  (NeurIPS)}, 2022{\natexlab{a}}.

\bibitem[Dang et~al.(2022{\natexlab{b}})Dang, Liu, Wei, Sankararaman, and
  Van~den Broeck]{DangRECOMB22}
Dang, M., Liu, A., Wei, X., Sankararaman, S., and Van~den Broeck, G.
\newblock Tractable and expressive generative models of genetic variation data.
\newblock In \emph{Proceedings of the International Conference on Research in
  Computational Molecular Biology (RECOMB)}, 2022{\natexlab{b}}.
\newblock \doi{https://doi.org/10.1007/978-3-031-04749-7_26}.

\bibitem[Dang et~al.(2022{\natexlab{c}})Dang, Vergari, and Van~den
  Broeck]{DangIJAR22}
Dang, M., Vergari, A., and Van~den Broeck, G.
\newblock Strudel: A fast and accurate learner of structured-decomposable
  probabilistic circuits.
\newblock \emph{International Journal of Approximate Reasoning},
  2022{\natexlab{c}}.
\newblock ISSN 0888-613X.

\bibitem[Grover \& Ermon(2018)Grover and Ermon]{grover2018boosted}
Grover, A. and Ermon, S.
\newblock Boosted generative models.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2018.

\bibitem[Hinton(2002)]{hinton2002training}
Hinton, G.~E.
\newblock Training products of experts by minimizing contrastive divergence.
\newblock \emph{Neural Computation}, 2002.

\bibitem[Khosravi et~al.(2019)Khosravi, Choi, Liang, Vergari, and Van~den
  Broeck]{khosravi2019tractable}
Khosravi, P., Choi, Y., Liang, Y., Vergari, A., and Van~den Broeck, G.
\newblock On tractable computation of expected predictions.
\newblock In \emph{Advances in Neural Information Processing Systems 32
  (NeurIPS)}, 2019.

\bibitem[Kisa et~al.(2014)Kisa, Van~den Broeck, Choi, and
  Darwiche]{kisa2014probabilistic}
Kisa, D., Van~den Broeck, G., Choi, A., and Darwiche, A.
\newblock Probabilistic sentential decision diagrams.
\newblock In \emph{Proceedings of the 14th International Conference on the
  Principles of Knowledge Representation and Reasoning (KR)}, 2014.

\bibitem[Kulesza \& Taskar(2012)Kulesza and Taskar]{MAL-044}
Kulesza, A. and Taskar, B.
\newblock Determinantal point processes for machine learning.
\newblock \emph{Foundations and TrendsÂ® in Machine Learning}, 2012.

\bibitem[Lewis et~al.(2020)Lewis, Liu, Goyal, Ghazvininejad, Mohamed, Levy,
  Stoyanov, and Zettlemoyer]{lewis2020bart}
Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O.,
  Stoyanov, V., and Zettlemoyer, L.
\newblock Bart: Denoising sequence-to-sequence pre-training for natural
  language generation, translation, and comprehension.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics (ACL)}, 2020.

\bibitem[Li et~al.(2021)Li, Zeng, Vergari, and Van~den Broeck]{LiUAI21}
Li, W., Zeng, Z., Vergari, A., and Van~den Broeck, G.
\newblock Tractable computation of expected kernels.
\newblock In \emph{Proceedings of the 37th Conference on Uncertainty in
  Aritifical Intelligence (UAI)}, 2021.

\bibitem[Lin et~al.(2020)Lin, Zhou, Shen, Zhou, Bhagavatula, Choi, and
  Ren]{lin2020commongen}
Lin, B.~Y., Zhou, W., Shen, M., Zhou, P., Bhagavatula, C., Choi, Y., and Ren,
  X.
\newblock Commongen: A constrained text generation challenge for generative
  commonsense reasoning.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP}, 2020.

\bibitem[Lin \& Hovy(2003)Lin and Hovy]{lin2003automatic}
Lin, C.-Y. and Hovy, E.
\newblock Automatic evaluation of summaries using n-gram co-occurrence
  statistics.
\newblock In \emph{Proceedings of the 2003 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (NAACL)}, 2003.

\bibitem[Liu et~al.(2023)Liu, Zhang, and Van~den Broeck]{liu2022scaling}
Liu, A., Zhang, H., and Van~den Broeck, G.
\newblock Scaling up probabilistic circuits by latent variable distillation.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2023.

\bibitem[Liu et~al.(2015)Liu, Flanigan, Thomson, Sadeh, and
  Smith]{liu2015toward}
Liu, F., Flanigan, J., Thomson, S., Sadeh, N., and Smith, N.~A.
\newblock Toward abstractive summarization using semantic representations.
\newblock In \emph{Proceedings of the 2015 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (NAACL)}, 2015.

\bibitem[Lu et~al.(2022{\natexlab{a}})Lu, Meng, and Peng]{lu2022insnet}
Lu, S., Meng, T., and Peng, N.
\newblock Insnet: An efficient, flexible, and performant insertion-based text
  generation model.
\newblock In \emph{Advances in Neural Information Processing Systems 35
  (NeurIPS)}, 2022{\natexlab{a}}.

\bibitem[Lu et~al.(2021)Lu, West, Zellers, Le~Bras, Bhagavatula, and
  Choi]{lu2021neurologic}
Lu, X., West, P., Zellers, R., Le~Bras, R., Bhagavatula, C., and Choi, Y.
\newblock Neurologic decoding:(un) supervised neural text generation with
  predicate logic constraints.
\newblock In \emph{Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (NAACL)}, 2021.

\bibitem[Lu et~al.(2022{\natexlab{b}})Lu, Welleck, West, Jiang, Kasai,
  Khashabi, Le~Bras, Qin, Yu, Zellers, Smith, and Choi]{lu2022astar}
Lu, X., Welleck, S., West, P., Jiang, L., Kasai, J., Khashabi, D., Le~Bras, R.,
  Qin, L., Yu, Y., Zellers, R., Smith, N.~A., and Choi, Y.
\newblock {N}euro{L}ogic a*esque decoding: Constrained text generation with
  lookahead heuristics.
\newblock In \emph{Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (NAACL)}, 2022{\natexlab{b}}.

\bibitem[Luong et~al.(2015)Luong, Pham, and Manning]{luong2015effective}
Luong, M.-T., Pham, H., and Manning, C.~D.
\newblock Effective approaches to attention-based neural machine translation.
\newblock In \emph{Proceedings of the 2015 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, 2015.

\bibitem[Meila \& Jordan(2000)Meila and Jordan]{meila2000learning}
Meila, M. and Jordan, M.~I.
\newblock Learning with mixtures of trees.
\newblock \emph{Journal of Machine Learning Research}, \penalty0 (Oct), 2000.

\bibitem[Meng et~al.(2022)Meng, Lu, Peng, and Chang]{meng2022nado}
Meng, T., Lu, S., Peng, N., and Chang, K.-W.
\newblock Controllable text generation with neurally-decomposed oracle.
\newblock In \emph{Advances in Neural Information Processing Systems 35
  (NeurIPS)}, 2022.

\bibitem[Molina et~al.(2019)Molina, Vergari, Stelzner, Peharz, Subramani,
  Di~Mauro, Poupart, and Kersting]{molina2019spflow}
Molina, A., Vergari, A., Stelzner, K., Peharz, R., Subramani, P., Di~Mauro, N.,
  Poupart, P., and Kersting, K.
\newblock Spflow: An easy and extensible library for deep probabilistic
  learning using sum-product networks.
\newblock \emph{arXiv preprint arXiv:1901.03704}, 2019.

\bibitem[Papineni et~al.(2002)Papineni, Roukos, Ward, and
  Zhu]{papineni2002bleu}
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock In \emph{Proceedings of the 40th annual meeting of the Association
  for Computational Linguistics (ACL)}, 2002.

\bibitem[Pearl(1985)]{pearl1985bayesian}
Pearl, J.
\newblock Bayesian netwcrks: A model cf self-activated memory for evidential
  reasoning.
\newblock In \emph{Proceedings of the 7th conference of the Cognitive Science
  Society, University of California, Irvine, CA, USA}, 1985.

\bibitem[Peharz et~al.(2020)Peharz, Lang, Vergari, Stelzner, Molina, Trapp,
  Van~den Broeck, Kersting, and Ghahramani]{peharz2020einsum}
Peharz, R., Lang, S., Vergari, A., Stelzner, K., Molina, A., Trapp, M., Van~den
  Broeck, G., Kersting, K., and Ghahramani, Z.
\newblock Einsum networks: Fast and scalable learning of tractable
  probabilistic circuits.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning (ICML)}, 2020.

\bibitem[Poon \& Domingos(2011)Poon and Domingos]{poon2011sum}
Poon, H. and Domingos, P.
\newblock Sum-product networks: A new deep architecture.
\newblock In \emph{2011 IEEE International Conference on Computer Vision
  Workshops (ICCV Workshops)}. IEEE, 2011.

\bibitem[Post \& Vilar(2018)Post and Vilar]{post2018fast}
Post, M. and Vilar, D.
\newblock Fast lexically constrained decoding with dynamic beam allocation for
  neural machine translation.
\newblock In \emph{Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (NAACL) (Long Papers)}, 2018.

\bibitem[Rabiner \& Juang(1986)Rabiner and Juang]{rabiner1986introduction}
Rabiner, L. and Juang, B.
\newblock An introduction to hidden markov models.
\newblock \emph{IEEE ASSP Magazine}, \penalty0 (1), 1986.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever,
  et~al.]{radford2019language}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 2019.

\bibitem[Roth(1996)]{roth1996hardness}
Roth, D.
\newblock On the hardness of approximate reasoning.
\newblock \emph{Artificial Intelligence}, 1996.

\bibitem[Satop{\"a}{\"a} et~al.(2014)Satop{\"a}{\"a}, Baron, Foster, Mellers,
  Tetlock, and Ungar]{satopaa2014combining}
Satop{\"a}{\"a}, V.~A., Baron, J., Foster, D.~P., Mellers, B.~A., Tetlock,
  P.~E., and Ungar, L.~H.
\newblock Combining multiple probability predictions using a simple logit
  model.
\newblock \emph{International Journal of Forecasting}, 2014.

\bibitem[Susanto et~al.(2020)Susanto, Chollampatt, and
  Tan]{susanto2020lexically}
Susanto, R.~H., Chollampatt, S., and Tan, L.
\newblock Lexically constrained neural machine translation with levenshtein
  transformer.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics (ACL)}, 2020.

\bibitem[Tian \& Peng(2022)Tian and Peng]{tian2022zero}
Tian, Y. and Peng, N.
\newblock Zero-shot sonnet generation with discourse-level planning and
  aesthetics features.
\newblock In \emph{Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (NAACL)}, 2022.

\bibitem[Vedantam et~al.(2015)Vedantam, Lawrence~Zitnick, and
  Parikh]{vedantam2015cider}
Vedantam, R., Lawrence~Zitnick, C., and Parikh, D.
\newblock Cider: Consensus-based image description evaluation.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2015.

\bibitem[Xu \& Durrett(2019)Xu and Durrett]{xu2019neural}
Xu, J. and Durrett, G.
\newblock Neural extractive text summarization with syntactic compression.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, 2019.

\bibitem[Yang \& Klein(2021)Yang and Klein]{yang2021fudge}
Yang, K. and Klein, D.
\newblock Fudge: Controlled text generation with future discriminators.
\newblock In \emph{Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies (NAACL)}, 2021.

\bibitem[Yao et~al.(2019)Yao, Peng, Weischedel, Knight, Zhao, and
  Yan]{yao2019plan}
Yao, L., Peng, N., Weischedel, R., Knight, K., Zhao, D., and Yan, R.
\newblock Plan-and-write: Towards better automatic storytelling.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2019.

\bibitem[Zhang et~al.(2021)Zhang, Juba, and Van~den Broeck]{ZhangICML21}
Zhang, H., Juba, B., and Van~den Broeck, G.
\newblock Probabilistic generating circuits.
\newblock In \emph{Proceedings of the 38th International Conference on Machine
  Learning (ICML)}, 2021.

\bibitem[Zhang et~al.(2022)Zhang, Li, Meng, Chang, and Van~den
  Broeck]{zhang2022paradox}
Zhang, H., Li, L.~H., Meng, T., Chang, K.-W., and Van~den Broeck, G.
\newblock On the paradox of learning to reason from data.
\newblock \emph{arXiv preprint arXiv:2205.11502}, 2022.

\bibitem[Zhang et~al.(2020)Zhang, Wang, Li, Gan, Brockett, and
  Dolan]{zhang-etal-2020-pointer}
Zhang, Y., Wang, G., Li, C., Gan, Z., Brockett, C., and Dolan, B.
\newblock {POINTER}: Constrained progressive text generation via
  insertion-based generative pre-training.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pp.\  8649--8670, Online, November
  2020. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.emnlp-main.698}.
\newblock URL \url{https://aclanthology.org/2020.emnlp-main.698}.

\end{thebibliography}
