@article{chen2022sampling,
  title={Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions},
  author={Chen, Sitan and Chewi, Sinho and Li, Jerry and Li, Yuanzhi and Salim, Adil and Zhang, Anru},
  journal={ICLR},
  year={2022}
}

@article{benton2023linear,
  title={Linear convergence bounds for diffusion models via stochastic localization},
  author={Benton, Joe and De Bortoli, Valentin and Doucet, Arnaud and Deligiannidis, George},
  journal={ICLR},
  year={2024}
}

@article{dalalyan2019user,
  title={User-friendly guarantees for the Langevin Monte Carlo with inaccurate gradient},
  author={Dalalyan, Arnak S and Karagulyan, Avetik},
  journal={Stochastic Processes and their Applications},
  volume={129},
  number={12},
  pages={5278--5311},
  year={2019},
  publisher={Elsevier}
}

@article{neal2011mcmc,
  title={MCMC using Hamiltonian dynamics},
  author={Neal, Radford M and others},
  journal={Handbook of markov chain monte carlo},
  volume={2},
  number={11},
  pages={2},
  year={2011},
  publisher={Chapman and Hall/CRC}
}

@article{dwivedi2019log,
  title={Log-concave sampling: Metropolis-Hastings algorithms are fast},
  author={Dwivedi, Raaz and Chen, Yuansi and Wainwright, Martin J and Yu, Bin},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={183},
  pages={1--42},
  year={2019}
}

@article{shen2019randomized,
  title={The randomized midpoint method for log-concave sampling},
  author={Shen, Ruoqi and Lee, Yin Tat},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{he2020ergodicity,
  title={On the ergodicity, bias and asymptotic normality of randomized midpoint sampling method},
  author={He, Ye and Balasubramanian, Krishnakumar and Erdogdu, Murat A},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7366--7376},
  year={2020}
}


@article{dalalyan2020sampling,
  title={On sampling from a log-concave density using kinetic Langevin diffusions},
  author={Dalalyan, Arnack S and Riou-Durand, Lionel},
  journal={Bernoulli},
  volume={26},
  number={3},
  pages={1956--1988},
  year={2020}
}

@article{liu2017stein,
  title={Stein variational gradient descent as gradient flow},
  author={Liu, Qiang},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{chewi2020svgd,
  title={SVGD as a kernelized Wasserstein gradient flow of the chi-squared divergence},
  author={Chewi, Sinho and Le Gouic, Thibaut and Lu, Chen and Maunu, Tyler and Rigollet, Philippe},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2098--2109},
  year={2020}
}

@article{he2022regularized,
  title={Regularized Stein variational gradient flow},
  author={He, Ye and Balasubramanian, Krishnakumar and Sriperumbudur, Bharath K and Lu, Jianfeng},
  journal={arXiv preprint arXiv:2211.07861},
  year={2022}
}

@article{roy2022stochastic,
  title={Stochastic zeroth-order discretizations of Langevin diffusions for Bayesian inference},
  author={Roy, Abhishek and Shen, Lingqing and Balasubramanian, Krishnakumar and Ghadimi, Saeed},
  journal={Bernoulli},
  volume={28},
  number={3},
  pages={1810--1834},
  year={2022},
  publisher={Bernoulli Society for Mathematical Statistics and Probability}
}

@article{vempala2019rapid,
  title={Rapid convergence of the unadjusted Langevin algorithm: Isoperimetry suffices},
  author={Vempala, Santosh and Wibisono, Andre},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{chen2023simple,
  title={A Simple Proof of the Mixing of Metropolis-Adjusted Langevin Algorithm under Smoothness and Isoperimetry},
  author={Chen, Yuansi and Gatmiry, Khashayar},
  journal={arXiv preprint arXiv:2304.04095},
  year={2023}
}

@inproceedings{salim2022convergence,
  title={A convergence theory for SVGD in the population limit under Talagrandâ€™s inequality T1},
  author={Salim, Adil and Sun, Lukang and Richtarik, Peter},
  booktitle={International Conference on Machine Learning},
  pages={19139--19152},
  year={2022},
  organization={PMLR}
}

@article{vincent2011connection,
  title={A connection between score matching and denoising autoencoders},
  author={Vincent, Pascal},
  journal={Neural computation},
  volume={23},
  number={7},
  pages={1661--1674},
  year={2011},
  publisher={MIT Press}
}

@inproceedings{chen2023improved,
  title={Improved analysis of score-based generative modeling: User-friendly bounds under minimal smoothness assumptions},
  author={Chen, Hongrui and Lee, Holden and Lu, Jianfeng},
  booktitle={International Conference on Machine Learning},
  pages={4735--4763},
  year={2023},
  organization={PMLR}
}

@article{conforti2023score,
  title={Score diffusion models without early stopping: finite Fisher information is all you need},
  author={Conforti, Giovanni and Durmus, Alain and Silveri, Marta Gentiloni},
  journal={arXiv preprint arXiv:2308.12240},
  year={2023}
}


@article{he2023mean,
  title={Mean-square analysis of discretized It{\^o} diffusions for heavy-tailed sampling},
  author={He, Ye and Farghly, Tyler and Balasubramanian, Krishnakumar and Erdogdu, Murat A},
  journal={arXiv preprint arXiv:2303.00570},
  year={2023}
}

@article{mengersen1996rates,
  title={Rates of convergence of the Hastings and Metropolis algorithms},
  author={Mengersen, Kerrie L and Tweedie, Richard L},
  journal={The annals of Statistics},
  volume={24},
  number={1},
  pages={101--121},
  year={1996},
  publisher={Institute of Mathematical Statistics}
}

@article{roberts1996geometric,
  title={Geometric convergence and central limit theorems for multidimensional Hastings and Metropolis algorithms},
  author={Roberts, Gareth O and Tweedie, Richard L},
  journal={Biometrika},
  volume={83},
  number={1},
  pages={95--110},
  year={1996},
  publisher={Oxford University Press}
}

@inproceedings{lovasz1990mixing,
  title={The mixing rate of Markov chains, an isoperimetric inequality, and computing the volume},
  author={Lov{\'a}sz, L{\'a}szl{\'o} and Simonovits, Mikl{\'o}s},
  booktitle={Proceedings [1990] 31st annual symposium on foundations of computer science},
  pages={346--354},
  year={1990},
  organization={IEEE}
}

@article{dyer1991random,
  title={A random polynomial-time algorithm for approximating the volume of convex bodies},
  author={Dyer, Martin and Frieze, Alan and Kannan, Ravi},
  journal={Journal of the ACM (JACM)},
  volume={38},
  number={1},
  pages={1--17},
  year={1991},
  publisher={ACM New York, NY, USA}
}

@article{belisle1993hit,
  title={Hit-and-run algorithms for generating multivariate distributions},
  author={B{\'e}lisle, Claude JP and Romeijn, H Edwin and Smith, Robert L},
  journal={Mathematics of Operations Research},
  volume={18},
  number={2},
  pages={255--266},
  year={1993},
  publisher={INFORMS}
}

@article{lovasz1999hit,
  title={Hit-and-run mixes fast},
  author={Lov{\'a}sz, L{\'a}szl{\'o}},
  journal={Mathematical programming},
  volume={86},
  pages={443--461},
  year={1999},
  publisher={Springer}
}

@inproceedings{lovasz2004hit,
  title={Hit-and-run from a corner},
  author={Lov{\'a}sz, L{\'a}szl{\'o} and Vempala, Santosh},
  booktitle={Proceedings of the thirty-sixth annual ACM symposium on Theory of computing},
  pages={310--314},
  year={2004}
}

@article{chewi2021analysis,
  title={Analysis of Langevin Monte Carlo from Poincar$\backslash$'e to Log-Sobolev},
  author={Chewi, Sinho and Erdogdu, Murat A and Li, Mufan Bill and Shen, Ruoqi and Zhang, Matthew},
  journal={arXiv preprint arXiv:2112.12662},
  year={2021}
}

@article{mousavi2023towards,
  title={Towards a Complete Analysis of Langevin Monte Carlo: Beyond Poincar$\backslash$'e Inequality},
  author={Mousavi-Hosseini, Alireza and Farghly, Tyler and He, Ye and Balasubramanian, Krishnakumar and Erdogdu, Murat A},
  journal={arXiv preprint arXiv:2303.03589},
  year={2023}
}

@inproceedings{balasubramanian2022towards,
  title={Towards a theory of non-log-concave sampling: first-order stationarity guarantees for langevin monte carlo},
  author={Balasubramanian, Krishna and Chewi, Sinho and Erdogdu, Murat A and Salim, Adil and Zhang, Shunshi},
  booktitle={Conference on Learning Theory},
  pages={2896--2923},
  year={2022},
  organization={PMLR}
}

@article{huang2023monte,
  title={Reverse Diffusion Monte Carlo},
  author={Huang, Xunpeng and Dong, Hanze and Hao, Yifan and Ma, Yian and Zhang, Tong},
  journal={ICLR},
  year={2024}
}

@article{huang2024faster,
  title={Faster Sampling without Isoperimetry via Diffusion-based Monte Carlo},
  author={Huang, Xunpeng and Zou, Difan and Dong, Hanze and Ma, Yian and Zhang, Tong},
  journal={COLT},
  year={2024}
}

@article{liang2022proximal1,
  title={A proximal algorithm for sampling},
  author={Liang, Jiaming and Chen, Yongxin},
  journal={arXiv preprint arXiv:2202.13975},
  year={2022}
}
@article{li2024automated,
  title={Automated construction of effective potential via algorithmic implicit bias},
  author={Li, Xingjie Helen and Tao, Molei},
  journal={arXiv preprint arXiv:2401.03511},
  year={2024}
}


@InProceedings{pmlr-v134-lee21a,
  title = 	 {Structured Logconcave Sampling with a Restricted Gaussian Oracle},
  author =       {Lee, Yin Tat and Shen, Ruoqi and Tian, Kevin},
  booktitle = 	 {Proceedings of Thirty Fourth Conference on Learning Theory},
  pages = 	 {2993--3050},
  year = 	 {2021},
  editor = 	 {Belkin, Mikhail and Kpotufe, Samory},
  volume = 	 {134},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {15--19 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v134/lee21a/lee21a.pdf},
  url = 	 {https://proceedings.mlr.press/v134/lee21a.html},
}


@book {chewisamplingbook,
    AUTHOR = {Sinho Chewi},
     TITLE = {Log-concave sampling},
      NOTE = {Book draft available at \url{https://chewisinho.github.io/}},
      YEAR = {2023},
}


@book{pardo2018statistical,
  title={Statistical inference based on divergence measures},
  author={Pardo, Leandro},
  year={2018},
  publisher={CRC press}
}

@inproceedings{chen2022localization,
  title={Localization schemes: A framework for proving mixing bounds for markov chains},
  author={Chen, Yuansi and Eldan, Ronen},
  booktitle={2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS)},
  pages={110--122},
  year={2022},
  organization={IEEE}
}

@inproceedings{li2021sqrt,
  title={{Sqrt(d) Dimension Dependence of Langevin Monte Carlo}},
  author={Li, Ruilin and Zha, Hongyuan and Tao, Molei},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{li2022mirror,
  title={The mirror {L}angevin algorithm converges with vanishing bias},
  author={Li, Ruilin and Tao, Molei and Vempala, Santosh S and Wibisono, Andre},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={718--742},
  year={2022},
  organization={PMLR}
}


@inproceedings{song2021SGM,
title={Score-Based Generative Modeling through Stochastic Differential Equations},
author={Yang Song and Jascha Sohl-Dickstein and Diederik P Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=PxTIG12RRHS}
}

@article{Ho2020DenoisingDP,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{sohl2015deep,
 title={{Deep unsupervised learning using nonequilibrium thermodynamics}},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  journal={ICML},
  year={2015},
}

@inproceedings{lee2021structured,
  title={Structured logconcave sampling with a restricted Gaussian oracle},
  author={Lee, Yin Tat and Shen, Ruoqi and Tian, Kevin},
  booktitle={Conference on Learning Theory},
  pages={2993--3050},
  year={2021},
  organization={PMLR}
}

@inproceedings{chen2022improved,
  title={Improved analysis for a proximal algorithm for sampling},
  author={Chen, Yongxin and Chewi, Sinho and Salim, Adil and Wibisono, Andre},
  booktitle={Conference on Learning Theory},
  pages={2984--3014},
  year={2022},
  organization={PMLR}
}

@inproceedings{liang2022proximal2,
  title={A proximal algorithm for sampling from non-smooth potentials},
  author={Liang, Jiaming and Chen, Yongxin},
  booktitle={2022 Winter Simulation Conference (WSC)},
  pages={3229--3240},
  year={2022},
  organization={IEEE}
}

@article{schlichting2019poincare,
  title={Poincar{\'e} and log--sobolev inequalities for mixtures},
  author={Schlichting, Andr{\'e}},
  journal={Entropy},
  volume={21},
  number={1},
  pages={89},
  year={2019},
  publisher={MDPI}
}

@inproceedings{welling2011bayesian,
  title={Bayesian learning via {Stochastic Gradient Langevin Dynamics}},
  author={Welling, Max and Teh, Yee W},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={681--688},
  year={2011}
}

@article{de2022convergence,
  title={Convergence of denoising diffusion models under the manifold hypothesis},
  author={De Bortoli, Valentin},
  journal={TMLR},
  year={2022}
}

@inproceedings{lee2023convergence,
  title={Convergence of score-based generative modeling for general data distributions},
  author={Lee, Holden and Lu, Jianfeng and Tan, Yixin},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={946--985},
  year={2023},
  organization={PMLR}
}

@article{yingxi2022convergence,
  title={Convergence of the Inexact Langevin Algorithm and Score-based Generative Models in KL Divergence},
  author={Yingxi Yang, Kaylee and Wibisono, Andre},
  journal={arXiv e-prints},
  pages={arXiv--2211},
  year={2022}
}

@article{li2023towards,
  title={Towards Faster Non-Asymptotic Convergence for Diffusion-Based Generative Models},
  author={Li, Gen and Wei, Yuting and Chen, Yuxin and Chi, Yuejie},
  journal={ICLR},
  year={2024}
}

@incollection{robbins1992empirical,
  title={An empirical Bayes approach to statistics},
  author={Robbins, Herbert E},
  booktitle={Breakthroughs in Statistics: Foundations and basic theory},
  pages={388--394},
  year={1992},
  publisher={Springer}
}

@article{zhang2022path,
  title={Path integral sampler: a stochastic control approach for sampling},
  author={Zhang, Qinsheng and Chen, Yongxin},
  journal={ICLR},
  year={2022}
}

@article{richter2023improved,
  title={Improved sampling via learned diffusions},
  author={Richter, Lorenz and Berner, Julius and Liu, Guan-Horng},
  journal={ICLR},
  year={2024}
}

@article{lee2023improved,
  title={Improved Bound for Mixing Time of Parallel Tempering},
  author={Lee, Holden and Shen, Zeyu},
  journal={arXiv preprint arXiv:2304.01303},
  year={2023}
}

@article{ge2018simulated,
  title={Simulated tempering langevin monte carlo ii: An improved proof using soft markov chain decomposition},
  author={Ge, Rong and Lee, Holden and Risteski, Andrej},
  journal={arXiv preprint arXiv:1812.00793},
  year={2018}
}

@article{woodard2009conditions,
  title={Conditions for rapid mixing of parallel and simulated tempering on multimodal distributions},
  author={Woodard, Dawn B and Schmidler, Scott C and Huber, Mark},
  year={2009}
}

@inproceedings{raginsky2017non,
  title={Non-convex learning via stochastic gradient langevin dynamics: a nonasymptotic analysis},
  author={Raginsky, Maxim and Rakhlin, Alexander and Telgarsky, Matus},
  booktitle={Conference on Learning Theory},
  pages={1674--1703},
  year={2017},
  organization={PMLR}
}

@inproceedings{zou2019sampling,
  title={Sampling from non-log-concave distributions via variance-reduced gradient Langevin dynamics},
  author={Zou, Difan and Xu, Pan and Gu, Quanquan},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={2936--2945},
  year={2019},
  organization={PMLR}
}

@article{liang2022proximal,
  title={A proximal algorithm for sampling},
  author={Liang, Jiaming and Chen, Yongxin},
  journal={arXiv preprint arXiv:2202.13975},
  year={2022}
}

@inproceedings{fan2023improved,
  title={Improved dimension dependence of a proximal algorithm for sampling},
  author={Fan, Jiaojiao and Yuan, Bo and Chen, Yongxin},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={1473--1521},
  year={2023},
  organization={PMLR}
}


@article{vargas2023denoising,
  title={Denoising diffusion samplers},
  author={Vargas, Francisco and Grathwohl, Will and Doucet, Arnaud},
  journal={arXiv preprint arXiv:2302.13834},
  year={2023}
}

@article{vargas2023bayesian,
  title={Bayesian learning via neural Schr{\"o}dinger--F{\"o}llmer flows},
  author={Vargas, Francisco and Ovsianas, Andrius and Fernandes, David and Girolami, Mark and Lawrence, Neil D and N{\"u}sken, Nikolas},
  journal={Statistics and Computing},
  volume={33},
  number={1},
  pages={3},
  year={2023},
  publisher={Springer}
}

@inproceedings{vargas2024transport,
  title={Transport meets variational inference: Controlled monte carlo diffusions},
  author={Vargas, Francisco and Padhy, Shreyas and Blessing, Denis and N{\"u}sken, Nikolas},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{lee2023parallel,
  title={Improved Bound for Mixing Time of Parallel Tempering},
  author={Lee, Holden and Shen, Zeyu},
  journal={arXiv preprint arXiv:2304.01303},
  year={2023}
}

@article{iglesias2013ensemble,
  title={Ensemble Kalman methods for inverse problems},
  author={Iglesias, Marco A and Law, Kody JH and Stuart, Andrew M},
  journal={Inverse Problems},
  volume={29},
  number={4},
  pages={045001},
  year={2013},
  publisher={IOP Publishing}
}

@article{garbuno2020interacting,
  title={Interacting Langevin diffusions: Gradient structure and ensemble Kalman sampler},
  author={Garbuno-Inigo, Alfredo and Hoffmann, Franca and Li, Wuchen and Stuart, Andrew M},
  journal={SIAM Journal on Applied Dynamical Systems},
  volume={19},
  number={1},
  pages={412--441},
  year={2020},
  publisher={SIAM}
}

@article{holzmuller2023convergence,
  title={Convergence rates for non-log-concave sampling and log-partition estimation},
  author={Holzm{\"u}ller, David and Bach, Francis},
  journal={arXiv preprint arXiv:2303.03237},
  year={2023}
}



@article{he2024mean,
  title={Mean-square analysis of discretized It{\^o} diffusions for heavy-tailed sampling},
  author={He, Ye and Farghly, Tyler and Balasubramanian, Krishnakumar and Erdogdu, Murat A},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={43},
  pages={1--44},
  year={2024}
}


@InProceedings{pmlr-v235-grenioux24a,
  title = 	 {Stochastic Localization via Iterative Posterior Sampling},
  author =       {Grenioux, Louis and Noble, Maxence and Gabri\'{e}, Marylou and Oliviero Durmus, Alain},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {16337--16376},
  year = 	 {2024},
  volume = 	 {235},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/grenioux24a/grenioux24a.pdf},
  url = 	 {https://proceedings.mlr.press/v235/grenioux24a.html},
  abstract = 	 {Building upon score-based learning, new interest in stochastic localization techniques has recently emerged. In these models, one seeks to noise a sample from the data distribution through a stochastic process, called observation process, and progressively learns a denoiser associated to this dynamics. Apart from specific applications, the use of stochastic localization for the problem of sampling from an unnormalized target density has not been explored extensively. This work contributes to fill this gap. We consider a general stochastic localization framework and introduce an explicit class of observation processes, associated with flexible denoising schedules. We provide a complete methodology, <em>Stochastic Localization via Iterative Posterior Sampling</em> (<b>SLIPS</b>), to obtain approximate samples of these dynamics, and as a by-product, samples from the target distribution. Our scheme is based on a Markov chain Monte Carlo estimation of the denoiser and comes with detailed practical guidelines. We illustrate the benefits and applicability of <b>SLIPS</b> on several benchmarks of multi-modal distributions, including Gaussian mixtures in increasing dimensions, Bayesian logistic regression and a high-dimensional field system from statistical-mechanics.}
}

@article{neal2001annealed,
  title={Annealed importance sampling},
  author={Neal, Radford M},
  journal={Statistics and computing},
  volume={11},
  pages={125--139},
  year={2001},
  publisher={Springer}
}


@article{del2006sequential,
  title={Sequential monte carlo samplers},
  author={Del Moral, Pierre and Doucet, Arnaud and Jasra, Ajay},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume={68},
  number={3},
  pages={411--436},
  year={2006},
  publisher={Oxford University Press}
}
