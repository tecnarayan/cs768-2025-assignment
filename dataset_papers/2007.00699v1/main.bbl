\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Altschuler et~al.(2017)Altschuler, Weed, and
  Rigollet]{altschuler2017near}
Altschuler, J., Weed, J., and Rigollet, P.
\newblock Near-linear time approximation algorithms for optimal transport via
  sinkhorn iteration.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1964--1974, 2017.

\bibitem[Benamou et~al.(2015)Benamou, Carlier, Cuturi, Nenna, and
  Peyr{\'e}]{benamou2015iterative}
Benamou, J.-D., Carlier, G., Cuturi, M., Nenna, L., and Peyr{\'e}, G.
\newblock Iterative bregman projections for regularized transportation
  problems.
\newblock \emph{SIAM Journal on Scientific Computing}, 37\penalty0
  (2):\penalty0 A1111--A1138, 2015.

\bibitem[Cooper(1990)]{cooper1990computational}
Cooper, G.~F.
\newblock The computational complexity of probabilistic inference using
  bayesian belief networks.
\newblock \emph{Artificial intelligence}, 42\penalty0 (2-3):\penalty0 393--405,
  1990.

\bibitem[Cuturi(2013)]{cuturi2013sinkhorn}
Cuturi, M.
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2292--2300, 2013.

\bibitem[Dvurechensky et~al.(2018)Dvurechensky, Gasnikov, and
  Kroshnin]{dvurechensky2018computational}
Dvurechensky, P., Gasnikov, A., and Kroshnin, A.
\newblock Computational optimal transport: Complexity by accelerated gradient
  descent is better than by sinkhorn's algorithm.
\newblock In \emph{35th International Conference on Machine Learning, ICML
  2018}, pp.\  2196--2220, 2018.

\bibitem[Genevay et~al.(2016)Genevay, Cuturi, Peyr{\'e}, and
  Bach]{genevay2016stochastic}
Genevay, A., Cuturi, M., Peyr{\'e}, G., and Bach, F.
\newblock Stochastic optimization for large-scale optimal transport.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3440--3448, 2016.

\bibitem[Globerson \& Jaakkola(2008)Globerson and
  Jaakkola]{globerson2008fixing}
Globerson, A. and Jaakkola, T.~S.
\newblock Fixing max-product: Convergent message passing algorithms for map
  lp-relaxations.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  553--560, 2008.

\bibitem[Gondzio(2012)]{gondzio2012interior}
Gondzio, J.
\newblock Interior point methods 25 years later.
\newblock \emph{European Journal of Operational Research}, 218\penalty0
  (3):\penalty0 587--601, 2012.

\bibitem[Hazan \& Shashua(2008)Hazan and Shashua]{hazan2012convergent}
Hazan, T. and Shashua, A.
\newblock Convergent message-passing algorithms for inference over general
  graphs with convex free energies.
\newblock In \emph{Proceedings of the Twenty-Fourth Conference on Uncertainty
  in Artificial Intelligence}, pp.\  264--273, 2008.

\bibitem[Jegelka \& Bilmes(2011)Jegelka and Bilmes]{jegelka2011submodularity}
Jegelka, S. and Bilmes, J.
\newblock Submodularity beyond submodular energies: coupling edges in graph
  cuts.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition},
  pp.\  1897--1904. IEEE, 2011.

\bibitem[Jojic et~al.(2010)Jojic, Gould, and Koller]{jojic2010accelerated}
Jojic, V., Gould, S., and Koller, D.
\newblock Accelerated dual decomposition for map inference.
\newblock In \emph{Proceedings of the 27th International Conference on
  International Conference on Machine Learning}, pp.\  503--510, 2010.

\bibitem[Kappes et~al.(2013)Kappes, Andres, Hamprecht, Schnorr, Nowozin, Batra,
  Kim, Kausler, Lellmann, Komodakis, et~al.]{kappes2013comparative}
Kappes, J., Andres, B., Hamprecht, F., Schnorr, C., Nowozin, S., Batra, D.,
  Kim, S., Kausler, B., Lellmann, J., Komodakis, N., et~al.
\newblock A comparative study of modern inference techniques for discrete
  energy minimization problems.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition},
  pp.\  1328--1335, 2013.

\bibitem[Karmarkar(1984)]{karmarkar1984new}
Karmarkar, N.
\newblock A new polynomial-time algorithm for linear programming.
\newblock In \emph{Proceedings of the sixteenth annual ACM symposium on Theory
  of computing}, pp.\  302--311, 1984.

\bibitem[Kolmogorov(2006)]{kolmogorov2006convergent}
Kolmogorov, V.
\newblock Convergent tree-reweighted message passing for energy minimization.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 28\penalty0 (10):\penalty0 1568--1583, 2006.

\bibitem[Kolmogorov \& Zabin(2004)Kolmogorov and Zabin]{kolmogorov2004energy}
Kolmogorov, V. and Zabin, R.
\newblock What energy functions can be minimized via graph cuts?
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 26\penalty0 (2):\penalty0 147--159, 2004.

\bibitem[Lee et~al.(2020)Lee, Pacchiano, and Jordan]{lee2019approximate}
Lee, J., Pacchiano, A., and Jordan, M.
\newblock Convergence rates of smooth message passing with rounding in
  entropy-regularized map inference.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  3003--3014, 2020.

\bibitem[Lee \& Sidford(2013)Lee and Sidford]{lee2013efficient}
Lee, Y.~T. and Sidford, A.
\newblock Efficient accelerated coordinate descent methods and faster
  algorithms for solving linear systems.
\newblock In \emph{2013 IEEE 54th Annual Symposium on Foundations of Computer
  Science}, pp.\  147--156. IEEE, 2013.

\bibitem[Lee \& Sidford(2014)Lee and Sidford]{lee2014path}
Lee, Y.~T. and Sidford, A.
\newblock Path finding methods for linear programming: Solving linear programs
  in o (vrank) iterations and faster algorithms for maximum flow.
\newblock In \emph{2014 IEEE 55th Annual Symposium on Foundations of Computer
  Science}, pp.\  424--433. IEEE, 2014.

\bibitem[Lin et~al.(2019)Lin, Ho, and Jordan]{lin2019acceleration}
Lin, T., Ho, N., and Jordan, M.~I.
\newblock On the acceleration of the sinkhorn and greenkhorn algorithms for
  optimal transport.
\newblock \emph{arXiv preprint arXiv:1906.01437}, 2019.

\bibitem[Lu et~al.(2018)Lu, Freund, and Mirrokni]{lu2018accelerating}
Lu, H., Freund, R., and Mirrokni, V.
\newblock Accelerating greedy coordinate descent methods.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3257--3266, 2018.

\bibitem[Lu \& Xiao(2015)Lu and Xiao]{lu2015complexity}
Lu, Z. and Xiao, L.
\newblock On the complexity analysis of randomized block-coordinate descent
  methods.
\newblock \emph{Mathematical Programming}, 152\penalty0 (1-2):\penalty0
  615--642, 2015.

\bibitem[MacKay(2003)]{mackay2003information}
MacKay, D.~J.
\newblock \emph{Information theory, inference and learning algorithms}.
\newblock Cambridge university press, 2003.

\bibitem[Meshi et~al.(2012)Meshi, Globerson, and
  Jaakkola]{meshi2012convergence}
Meshi, O., Globerson, A., and Jaakkola, T.~S.
\newblock Convergence rate analysis of map coordinate minimization algorithms.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3014--3022, 2012.

\bibitem[Meshi et~al.(2015)Meshi, Mahdavi, and Schwing]{meshi2015smooth}
Meshi, O., Mahdavi, M., and Schwing, A.
\newblock Smooth and strong: Map inference with linear convergence.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  298--306, 2015.

\bibitem[Mezard \& Montanari(2009)Mezard and Montanari]{mezard2009information}
Mezard, M. and Montanari, A.
\newblock \emph{Information, physics, and computation}.
\newblock Oxford University Press, 2009.

\bibitem[Nesterov(2005)]{nesterov2005smooth}
Nesterov, Y.
\newblock Smooth minimization of non-smooth functions.
\newblock \emph{Mathematical programming}, 103\penalty0 (1):\penalty0 127--152,
  2005.

\bibitem[Nesterov(2012)]{nesterov2012efficiency}
Nesterov, Y.
\newblock Efficiency of coordinate descent methods on huge-scale optimization
  problems.
\newblock \emph{SIAM Journal on Optimization}, 22\penalty0 (2):\penalty0
  341--362, 2012.

\bibitem[Nesterov(2018)]{nesterov2018lectures}
Nesterov, Y.
\newblock \emph{Lectures on convex optimization}, volume 137.
\newblock Springer, 2018.

\bibitem[Ravikumar et~al.(2010)Ravikumar, Agarwal, and
  Wainwright]{ravikumar2010message}
Ravikumar, P., Agarwal, A., and Wainwright, M.~J.
\newblock Message-passing for graph-structured linear programs: Proximal
  methods and rounding schemes.
\newblock \emph{Journal of Machine Learning Research}, 11\penalty0
  (Mar):\penalty0 1043--1080, 2010.

\bibitem[Renegar(1988)]{renegar1988polynomial}
Renegar, J.
\newblock A polynomial-time algorithm, based on newton's method, for linear
  programming.
\newblock \emph{Mathematical programming}, 40\penalty0 (1-3):\penalty0 59--93,
  1988.

\bibitem[Savchynskyy et~al.(2011)Savchynskyy, Kappes, Schmidt, and
  Schn{\"o}rr]{savchynskyy2011study}
Savchynskyy, B., Kappes, J., Schmidt, S., and Schn{\"o}rr, C.
\newblock A study of nesterov's scheme for lagrangian decomposition and map
  labeling.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition},
  pp.\  1817--1823. IEEE, 2011.

\bibitem[Savchynskyy et~al.(2012)Savchynskyy, Schmidt, Kappes, and
  Schn{\"o}rr]{savchynskyy2012efficient}
Savchynskyy, B., Schmidt, S., Kappes, J., and Schn{\"o}rr, C.
\newblock Efficient mrf energy minimization via adaptive diminishing smoothing.
\newblock \emph{arXiv preprint arXiv:1210.4906}, 2012.

\bibitem[Schiex et~al.(1995)Schiex, Fargier, and Verfaillie]{schiex1995valued}
Schiex, T., Fargier, H., and Verfaillie, G.
\newblock Valued constraint satisfaction problems: hard and easy problems.
\newblock In \emph{Proceedings of the 14th International Joint Conference on
  Artificial Intelligence}, pp.\  631--637. Morgan Kaufmann Publishers Inc.,
  1995.

\bibitem[Sherali \& Adams(1990)Sherali and Adams]{sherali1990hierarchy}
Sherali, H.~D. and Adams, W.~P.
\newblock A hierarchy of relaxations between the continuous and convex hull
  representations for zero-one programming problems.
\newblock \emph{SIAM Journal on Discrete Mathematics}, 3\penalty0 (3):\penalty0
  411--430, 1990.

\bibitem[Sidford \& Tian(2018)Sidford and Tian]{sidford2018coordinate}
Sidford, A. and Tian, K.
\newblock Coordinate methods for accelerating $\ell_\infty$ regression and
  faster approximate maximum flow.
\newblock In \emph{2018 IEEE 59th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pp.\  922--933. IEEE, 2018.

\bibitem[Sontag et~al.(2011)Sontag, Globerson, and
  Jaakkola]{sontag2011introduction}
Sontag, D., Globerson, A., and Jaakkola, T.
\newblock Introduction to dual composition for inference.
\newblock In \emph{Optimization for Machine Learning}. MIT Press, 2011.

\bibitem[Torada et~al.(2019)Torada, Lorenzon, Beddis, Isildak, Pattini,
  Mathieson, and Fumagalli]{torada2019imagene}
Torada, L., Lorenzon, L., Beddis, A., Isildak, U., Pattini, L., Mathieson, S.,
  and Fumagalli, M.
\newblock Imagene: a convolutional neural network to quantify natural selection
  from genomic data.
\newblock \emph{BMC bioinformatics}, 20\penalty0 (9):\penalty0 337, 2019.

\bibitem[Wainwright \& Jordan(2008)Wainwright and
  Jordan]{wainwright2008graphical}
Wainwright, M.~J. and Jordan, M.~I.
\newblock Graphical models, exponential families, and variational inference.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  1\penalty0 (1--2):\penalty0 1--305, 2008.

\bibitem[Weed(2018)]{weed2018explicit}
Weed, J.
\newblock An explicit analysis of the entropic penalty in linear programming.
\newblock In \emph{Conference On Learning Theory}, pp.\  1841--1855, 2018.

\bibitem[Weiss et~al.(2007)Weiss, Yanover, and Meltzer]{weiss2012map}
Weiss, Y., Yanover, C., and Meltzer, T.
\newblock Map estimation, linear programming and belief propagation with convex
  free energies.
\newblock In \emph{Proceedings of the Twenty-Third Conference on Uncertainty in
  Artificial Intelligence}, pp.\  416--425, 2007.

\bibitem[Werner(2007)]{werner2007linear}
Werner, T.
\newblock A linear programming approach to max-sum problem: A review.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 29\penalty0 (7):\penalty0 1165--1179, 2007.

\bibitem[Werner(2009)]{werner2009revisiting}
Werner, T.
\newblock Revisiting the linear programming relaxation approach to gibbs energy
  minimization and weighted constraint satisfaction.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 32\penalty0 (8):\penalty0 1474--1488, 2009.

\bibitem[Yanover et~al.(2006)Yanover, Meltzer, and Weiss]{yanover2006linear}
Yanover, C., Meltzer, T., and Weiss, Y.
\newblock Linear programming relaxations and belief propagation--an empirical
  study.
\newblock \emph{Journal of Machine Learning Research}, 7\penalty0
  (Sep):\penalty0 1887--1907, 2006.

\end{thebibliography}
