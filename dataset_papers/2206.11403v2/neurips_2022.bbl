\begin{thebibliography}{53}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Loewenstein(1994)]{loewenstein1994psychology}
George Loewenstein.
\newblock The psychology of curiosity: A review and reinterpretation.
\newblock \emph{Psychological Bulletin}, 116\penalty0 (1):\penalty0 75--98,
  1994.
\newblock URL \url{https://doi.org/10.1037/0033-2909.116.1.75}.

\bibitem[Legare et~al.(2010)Legare, Gelman, and
  Wellman]{legare_inconsistency_2010}
Cristine~H. Legare, Susan~A. Gelman, and Henry~M. Wellman.
\newblock Inconsistency {With} {Prior} {Knowledge} {Triggers} {Children}’s
  {Causal} {Explanatory} {Reasoning}.
\newblock \emph{Child Development}, 81\penalty0 (3):\penalty0 929--944, 2010.
\newblock URL \url{https://doi.org/10.1111/j.1467-8624.2010.01443.x}.

\bibitem[Bonawitz et~al.(2012)Bonawitz, van Schijndel, Friel, and
  Schulz]{bonawitz_children_2012}
Elizabeth~Baraff Bonawitz, Tessa J.~P. van Schijndel, Daniel Friel, and Laura
  Schulz.
\newblock Children balance theories and evidence in exploration, explanation,
  and learning.
\newblock \emph{Cognitive Psychology}, 64\penalty0 (4):\penalty0 215--234, June
  2012.
\newblock URL \url{https://doi.org/10.1016/j.cogpsych.2011.12.002}.

\bibitem[Stahl and Feigenson(2015)]{stahl2015observing}
Aimee~E Stahl and Lisa Feigenson.
\newblock Observing the unexpected enhances infants’ learning and
  exploration.
\newblock \emph{Science}, 348\penalty0 (6230):\penalty0 91--94, 2015.
\newblock URL \url{https://doi.org/10.1126/science.aaa3799}.

\bibitem[Schmidhuber(1991)]{schmidhuber1991possibility}
J{\"u}rgen Schmidhuber.
\newblock A possibility for implementing curiosity and boredom in
  model-building neural controllers.
\newblock In \emph{Proceedings of the International Conference on Simulation of
  Adaptive Behavior: From Animals to Animats}, 1991.
\newblock URL \url{https://dl.acm.org/doi/10.5555/116517.116542}.

\bibitem[Pathak et~al.(2017)Pathak, Agrawal, Efros, and
  Darrell]{pathak2017curiosity}
Deepak Pathak, Pulkit Agrawal, Alexei~A. Efros, and Trevor Darrell.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2017.
\newblock URL \url{https://proceedings.mlr.press/v70/pathak17a.html}.

\bibitem[Dubey and Griffiths(2017)]{dubey2017rational}
Rachit Dubey and Thomas~L. Griffiths.
\newblock A rational analysis of curiosity.
\newblock In \emph{Proceedings of the 39th Annual Conference of the Cognitive
  Science Society}, pages 307--312, 2017.
\newblock URL
  \url{https://cogsci.mindmodeling.org/2017/papers/0068/index.html}.

\bibitem[Kidd and Hayden(2015)]{kidd2015psychology}
Celeste Kidd and Benjamin~Y Hayden.
\newblock The psychology and neuroscience of curiosity.
\newblock \emph{Neuron}, 88\penalty0 (3):\penalty0 449--460, 2015.
\newblock URL \url{https://doi.org/10.1016/j.neuron.2015.09.010}.

\bibitem[Poli et~al.(2020)Poli, Serino, Mars, and Hunnius]{poli2020infants}
F~Poli, G~Serino, RB~Mars, and S~Hunnius.
\newblock Infants tailor their attention to maximize learning.
\newblock \emph{Science Advances}, 6\penalty0 (39):\penalty0 eabb5053, 2020.
\newblock URL \url{https://www.science.org/doi/abs/10.1126/sciadv.abb5053}.

\bibitem[Haith(1980)]{haith1980rules}
Marshall~M Haith.
\newblock \emph{Rules that babies look by: The organization of newborn visual
  activity}.
\newblock Lawrence Erlbaum Associates, 1980.

\bibitem[Murphy and Medin(1985)]{murphy1985role}
Gregory~L Murphy and Douglas~L Medin.
\newblock The role of theories in conceptual coherence.
\newblock \emph{Psychological review}, 92\penalty0 (3):\penalty0 289, 1985.
\newblock URL \url{https://doi.org/10.1037/0033-295X.92.3.289}.

\bibitem[Tsividis et~al.(2021)Tsividis, Loula, Burga, Foss, Campero, Pouncy,
  Gershman, and Tenenbaum]{tsividis2021human}
Pedro~A. Tsividis, Joao Loula, Jake Burga, Nathan Foss, Andres Campero, Thomas
  Pouncy, Samuel~J. Gershman, and Joshua~B. Tenenbaum.
\newblock Human-level reinforcement learning through theory-based modeling,
  exploration, and planning.
\newblock \emph{arXiv:2107.12544}, 2021.
\newblock URL \url{https://arxiv.org/abs/2107.12544}.

\bibitem[Battaglia et~al.(2018)Battaglia, Hamrick, Bapst, Sanchez-Gonzalez,
  Zambaldi, Malinowski, Tacchetti, Raposo, Santoro, Faulkner, Gulcehre, Song,
  Ballard, Gilmer, Dahl, Vaswani, Allen, Nash, Langston, Dyer, Heess, Wierstra,
  Kohli, Botvinick, Vinyals, Li, and Pascanu]{battaglia2018relational}
Peter~W. Battaglia, Jessica~B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez,
  Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam
  Santoro, Ryan Faulkner, Caglar Gulcehre, Francis Song, Andrew Ballard, Justin
  Gilmer, George Dahl, Ashish Vaswani, Kelsey Allen, Charles Nash, Victoria
  Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, Pushmeet Kohli, Matt
  Botvinick, Oriol Vinyals, Yujia Li, and Razvan Pascanu.
\newblock Relational inductive biases, deep learning, and graph networks.
\newblock \emph{arXiv:1806.01261}, 2018.
\newblock URL \url{https://arxiv.org/abs/1806.01261}.

\bibitem[Pinneri et~al.(2020)Pinneri, Sawant, Blaes, Achterhold, Stueckler,
  Rolinek, and Martius]{pinneri2020:iCEM}
Cristina Pinneri, Shambhuraj Sawant, Sebastian Blaes, Jan Achterhold, Joerg
  Stueckler, Michal Rolinek, and Georg Martius.
\newblock Sample-efficient cross-entropy method for real-time planning.
\newblock In \emph{Conference on Robot Learning (CoRL)}, 2020.
\newblock URL \url{https://proceedings.mlr.press/v155/pinneri21a.html}.

\bibitem[Vlastelica et~al.(2021)Vlastelica, Blaes, Pinneri, and
  Martius]{VlastelicaBlaesEtal2021:riskaverse}
Marin Vlastelica, Sebastian Blaes, Cristina Pinneri, and Georg Martius.
\newblock Risk-averse zero-order trajectory optimization.
\newblock In \emph{Conference on Robot Learning (CoRL)}, 2021.
\newblock URL \url{https://openreview.net/forum?id=WqUl7sNkDre}.

\bibitem[Pathak et~al.(2019)Pathak, Gandhi, and Gupta]{pathak2019self}
Deepak Pathak, Dhiraj Gandhi, and Abhinav Gupta.
\newblock Self-supervised exploration via disagreement.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2019.
\newblock URL \url{https://proceedings.mlr.press/v97/pathak19a.html}.

\bibitem[Burda et~al.(2019)Burda, Edwards, Storkey, and
  Klimov]{burda2018exploration}
Yuri Burda, Harrison Edwards, Amos Storkey, and Oleg Klimov.
\newblock Exploration by random network distillation.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.
\newblock URL \url{https://openreview.net/forum?id=H1lJJnR5Ym}.

\bibitem[Sekar et~al.(2020)Sekar, Rybkin, Daniilidis, Abbeel, Hafner, and
  Pathak]{sekar2020planning}
Ramanan Sekar, Oleh Rybkin, Kostas Daniilidis, Pieter Abbeel, Danijar Hafner,
  and Deepak Pathak.
\newblock Planning to explore via self-supervised world models.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.
\newblock URL \url{https://proceedings.mlr.press/v119/sekar20a.html}.

\bibitem[Pfaffelhuber(1972)]{Pfaffelhuber1972:MissingInformation}
E.~Pfaffelhuber.
\newblock Learning and information theory.
\newblock \emph{International Journal of Neuroscience}, 3\penalty0
  (2):\penalty0 83--88, 1972.
\newblock URL \url{https://doi.org/10.3109/00207457209147016}.

\bibitem[Storck et~al.(1995)Storck, Hochreiter, and
  Schmidhuber]{Storck1995Reinforcement-Driven-Information}
J.~Storck, S.~Hochreiter, and J.~Schmidhuber.
\newblock Reinforcement driven information acquisition in non-deterministic
  environments.
\newblock In \emph{Proceedings of the International Conference on Artificial
  Neural Networks}, pages 159--164, Paris, 1995. EC2 \& Cie.
\newblock URL \url{https://people.idsia.ch/~juergen/icann95new.pdf}.

\bibitem[Cover and Thomas(2006)]{Cover2006Elements-of-Information}
T.~M. Cover and J.~A. Thomas.
\newblock \emph{Elements of Information Theory}, volume 2nd.
\newblock Wiley, Hoboken, New Jersey, USA, 2006.

\bibitem[Little and Sommer(2013)]{LittleSommer2013:PIG}
D.~Y. Little and F.~T. Sommer.
\newblock Learning and exploration in action-perception loops.
\newblock \emph{Frontiers in Neural Circuits}, 7\penalty0 (37), 2013.
\newblock URL \url{https://doi.org/10.3389/fncir.2013.00037}.

\bibitem[Plappert et~al.(2018)Plappert, Andrychowicz, Ray, McGrew, Baker,
  Powell, Schneider, Tobin, Chociej, Welinder, Kumar, and
  Zaremba]{Plappert2018MultiGoalRL}
Matthias Plappert, Marcin Andrychowicz, Alex Ray, Bob McGrew, Bowen Baker,
  Glenn Powell, J.~Schneider, Joshua Tobin, Maciek Chociej, P.~Welinder,
  V.~Kumar, and W.~Zaremba.
\newblock Multi-goal reinforcement learning: Challenging robotics environments
  and request for research.
\newblock \emph{arXiv preprint arXiv:1802.09464}, 2018.
\newblock URL \url{https://arxiv.org/abs/1802.09464}.

\bibitem[Li et~al.(2020)Li, Jabri, Darrell, and Agrawal]{li2020towards}
Richard Li, Allan Jabri, Trevor Darrell, and Pulkit Agrawal.
\newblock Towards practical multi-object manipulation using relational
  reinforcement learning.
\newblock In \emph{2020 IEEE International Conference on Robotics and
  Automation (ICRA)}, pages 4051--4058. IEEE, 2020.
\newblock URL \url{https://arxiv.org/abs/1912.11032}.

\bibitem[Laskin et~al.(2021)Laskin, Yarats, Liu, Lee, Zhan, Lu, Cang, Pinto,
  and Abbeel]{laskin2021urlb}
Michael Laskin, Denis Yarats, Hao Liu, Kimin Lee, Albert Zhan, Kevin Lu,
  Catherine Cang, Lerrel Pinto, and Pieter Abbeel.
\newblock {URLB}: Unsupervised reinforcement learning benchmark.
\newblock In \emph{NeurIPS 2021 Datasets and Benchmarks Track (Round 2)}, 2021.
\newblock URL \url{https://openreview.net/forum?id=lwrPkQP_is}.

\bibitem[Lillicrap et~al.(2016)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{Lillicrap2016DDPG}
T.~Lillicrap, Jonathan~J. Hunt, A.~Pritzel, N.~Heess, T.~Erez, Y.~Tassa,
  D.~Silver, and Daan Wierstra.
\newblock Continuous control with deep reinforcement learning.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2016.
\newblock URL \url{https://openreview.net/forum?id=tX_O8O-8Zl}.

\bibitem[Lambert et~al.(2022)Lambert, Wulfmeier, Whitney, Byravan, Bloesch,
  Dasagi, Hertweck, and Riedmiller]{Lambert2022:iMPC}
Nathan Lambert, Markus Wulfmeier, William~F. Whitney, Arunkumar Byravan,
  Michael Bloesch, Vibhavari Dasagi, Tim Hertweck, and Martin~A. Riedmiller.
\newblock The challenges of exploration for offline reinforcement learning.
\newblock \emph{arXiv:2201.11861}, 2022.
\newblock URL \url{https://arxiv.org/abs/2201.11861}.

\bibitem[Kumar et~al.(2020)Kumar, Zhou, Tucker, and
  Levine]{kumar2020conservative}
Aviral Kumar, Aurick Zhou, George Tucker, and Sergey Levine.
\newblock Conservative q-learning for offline reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2020.
\newblock URL \url{https://arxiv.org/abs/2006.04779}.

\bibitem[Takuma~Seno(2021)]{seno2021d3rlpy}
Michita~Imai Takuma~Seno.
\newblock d3rlpy: An offline deep reinforcement library.
\newblock In \emph{NeurIPS 2021 Offline Reinforcement Learning Workshop}, 2021.
\newblock URL \url{https://arxiv.org/abs/2111.03788}.

\bibitem[Andrychowicz et~al.(2017)Andrychowicz, Wolski, Ray, Schneider, Fong,
  Welinder, McGrew, Tobin, Pieter~Abbeel, and Zaremba]{NIPS2017_453fadbd}
Marcin Andrychowicz, Filip Wolski, Alex Ray, Jonas Schneider, Rachel Fong,
  Peter Welinder, Bob McGrew, Josh Tobin, OpenAI Pieter~Abbeel, and Wojciech
  Zaremba.
\newblock Hindsight experience replay.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2017/file/453fadbd8a1a3af50a9df4df899537b5-Paper.pdf}.

\bibitem[Kim et~al.(2020)Kim, Sano, De~Freitas, Haber, and
  Yamins]{Kim20:Active}
Kuno Kim, Megumi Sano, Julian De~Freitas, Nick Haber, and Daniel Yamins.
\newblock Active world model learning with progress curiosity.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.
\newblock URL \url{https://arxiv.org/abs/2007.07853}.

\bibitem[Blaes et~al.(2019)Blaes, Vlastelica, Zhu, and
  Martius]{BlaesVlastelicaZhuMartius2019:CWYC}
Sebastian Blaes, Marin Vlastelica, Jia-Jie Zhu, and Georg Martius.
\newblock Control {W}hat {Y}ou {C}an: {I}ntrinsically motivated task-planning
  agent.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/hash/b6f97e6f0fd175613910d613d574d0cb-Abstract.html}.

\bibitem[Paolo et~al.(2021)Paolo, Coninx, Doncieux, and
  Laflaqui\`{e}re]{PaoloEtAl2021:NoveltySearchSparseReward}
Giuseppe Paolo, Alexandre Coninx, Stephane Doncieux, and Alban Laflaqui\`{e}re.
\newblock Sparse reward exploration via novelty search and emitters.
\newblock In \emph{Proceedings of the Genetic and Evolutionary Computation
  Conference}, page 154–162, 2021.
\newblock URL \url{https://doi.org/10.1145/3449639.3459314}.

\bibitem[Colas et~al.(2019)Colas, Fournier, Chetouani, Sigaud, and
  Oudeyer]{Colas2019:CURIOUS}
C{\'e}dric Colas, Pierre Fournier, Mohamed Chetouani, Olivier Sigaud, and
  Pierre-Yves Oudeyer.
\newblock {CURIOUS}: Intrinsically motivated modular multi-goal reinforcement
  learning.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2019.
\newblock URL \url{https://proceedings.mlr.press/v97/colas19a.html}.

\bibitem[Klyubin et~al.(2005)Klyubin, Polani, and
  Nehaniv]{KlyubinPolani2005:Empowerment}
A.S. Klyubin, D.~Polani, and C.L. Nehaniv.
\newblock Empowerment: a universal agent-centric measure of control.
\newblock In \emph{IEEE Congress on Evolutionary Computation}, volume~1, pages
  128--135 Vol.1, 2005.
\newblock URL \url{https://ieeexplore.ieee.org/document/1554676}.

\bibitem[Mohamed and Jimenez~Rezende(2015)]{mohamed2015variational}
Shakir Mohamed and Danilo Jimenez~Rezende.
\newblock Variational information maximisation for intrinsically motivated
  reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2015.
\newblock URL \url{https://arxiv.org/abs/1509.08731}.

\bibitem[Yarats et~al.(2022)Yarats, Brandfonbrener, Liu, Laskin, Abbeel,
  Lazaric, and Pinto]{yarats2022don}
Denis Yarats, David Brandfonbrener, Hao Liu, Michael Laskin, Pieter Abbeel,
  Alessandro Lazaric, and Lerrel Pinto.
\newblock Don't change the algorithm, change the data: Exploratory data for
  offline reinforcement learning.
\newblock In \emph{ICLR 2022 Workshop on Generalizable Policy Learning in
  Physical World}, 2022.
\newblock URL \url{https://openreview.net/forum?id=Su-zh4a41Z5}.

\bibitem[Groth et~al.(2021)Groth, Wulfmeier, Vezzani, Dasagi, Hertweck, Hafner,
  Heess, and Riedmiller]{groth2021curiosity}
Oliver Groth, Markus Wulfmeier, Giulia Vezzani, Vibhavari Dasagi, Tim Hertweck,
  Roland Hafner, Nicolas Heess, and Martin Riedmiller.
\newblock Is curiosity all you need? on the utility of emergent behaviours from
  curious exploration.
\newblock \emph{arXiv preprint arXiv:2109.08603}, 2021.
\newblock URL \url{https://arxiv.org/abs/2109.08603}.

\bibitem[OpenAI et~al.(2021)OpenAI, Plappert, Sampedro, Xu, Akkaya, Kosaraju,
  Welinder, D'Sa, Petron, de~Oliveira~Pinto, Paino, Noh, Weng, Yuan, Chu, and
  Zaremba]{openai2021:assymmetric-selfplay}
OpenAI, Matthias Plappert, Raul Sampedro, Tao Xu, Ilge Akkaya, Vineet Kosaraju,
  Peter Welinder, Ruben D'Sa, Arthur Petron, Henrique~Ponde de~Oliveira~Pinto,
  Alex Paino, Hyeonwoo Noh, Lilian Weng, Qiming Yuan, Casey Chu, and Wojciech
  Zaremba.
\newblock Asymmetric self-play for automatic goal discovery in robotic
  manipulation.
\newblock \emph{arXiv:2101.04882}, 2021.
\newblock URL \url{https://arxiv.org/abs/2101.04882}.

\bibitem[Mendonca et~al.(2021)Mendonca, Rybkin, Daniilidis, Hafner, and
  Pathak]{Mendonca2021:LEXA}
Russell Mendonca, Oleh Rybkin, Kostas Daniilidis, Danijar Hafner, and Deepak
  Pathak.
\newblock Discovering and achieving goals via world models.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2021.
\newblock URL \url{https://openreview.net/forum?id=6vWuYzkp8d}.

\bibitem[Riedmiller et~al.(2018)Riedmiller, Hafner, Lampe, Neunert, Degrave,
  van~de Wiele, Mnih, Heess, and
  Springenberg]{Riedmiller2018:LearningByPlaying}
Martin Riedmiller, Roland Hafner, Thomas Lampe, Michael Neunert, Jonas Degrave,
  Tom van~de Wiele, Vlad Mnih, Nicolas Heess, and Jost~Tobias Springenberg.
\newblock Learning by playing solving sparse reward tasks from scratch.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2018.
\newblock URL \url{https://proceedings.mlr.press/v80/riedmiller18a.html}.

\bibitem[Haber et~al.(2018)Haber, Mrowca, Fei{-}Fei, and
  Yamins]{Huber18:Emergent}
Nick Haber, Damian Mrowca, Li~Fei{-}Fei, and Daniel L.~K. Yamins.
\newblock Emergence of structured behaviors from curiosity-based intrinsic
  motivation.
\newblock In \emph{Annual Meeting of the Cognitive Science Society (CogSci)},
  2018.
\newblock URL \url{https://arxiv.org/abs/1802.07461}.

\bibitem[Kipf et~al.(2020)Kipf, van~der Pol, and Welling]{kipf2019contrastive}
Thomas Kipf, Elise van~der Pol, and Max Welling.
\newblock Contrastive learning of structured world models.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.
\newblock URL \url{https://openreview.net/forum?id=H1gax6VtDB}.

\bibitem[Sanchez-Gonzalez et~al.(2020)Sanchez-Gonzalez, Godwin, Pfaff, Ying,
  Leskovec, and Battaglia]{sanchez2020learning}
Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure
  Leskovec, and Peter Battaglia.
\newblock Learning to simulate complex physics with graph networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.
\newblock URL
  \url{https://proceedings.mlr.press/v119/sanchez-gonzalez20a.html}.

\bibitem[Watters et~al.(2017)Watters, Zoran, Weber, Battaglia, Pascanu, and
  Tacchetti]{watters_NIPS2017}
Nicholas Watters, Daniel Zoran, Theophane Weber, Peter~W. Battaglia, Razvan
  Pascanu, and Andrea Tacchetti.
\newblock Visual interaction networks: Learning a physics simulator from video.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2017/hash/8cbd005a556ccd4211ce43f309bc0eac-Abstract.html}.

\bibitem[Driess et~al.(2022)Driess, Huang, Li, Tedrake, and
  Toussaint]{Driess2022:Nerf}
Danny Driess, Zhiao Huang, Yunzhu Li, Russ Tedrake, and Marc Toussaint.
\newblock Learning multi-object dynamics with compositional neural radiance
  fields.
\newblock \emph{arXiv preprint arXiv:2202.11855}, 2022.
\newblock URL \url{https://arxiv.org/abs/2202.11855}.

\bibitem[Biza et~al.(2022)Biza, Kipf, Klee, Platt, van~de Meent, and
  Wong]{biza2022factored}
Ondrej Biza, Thomas Kipf, David Klee, Robert Platt, Jan-Willem van~de Meent,
  and Lawson~LS Wong.
\newblock Factored world models for zero-shot generalization in robotic
  manipulation.
\newblock \emph{arXiv preprint arXiv:2202.05333}, 2022.
\newblock URL \url{https://arxiv.org/abs/2202.05333}.

\bibitem[Watters et~al.(2019)Watters, Matthey, Bosnjak, Burgess, and
  Lerchner]{watters2019cobra}
Nicholas Watters, Loic Matthey, Matko Bosnjak, Christopher~P Burgess, and
  Alexander Lerchner.
\newblock Cobra: Data-efficient model-based rl through unsupervised object
  discovery and curiosity-driven exploration.
\newblock \emph{arXiv preprint arXiv:1905.09275}, 2019.
\newblock URL \url{https://arxiv.org/abs/1905.09275}.

\bibitem[Seitzer et~al.(2021)Seitzer, Sch{\"o}lkopf, and
  Martius]{Seitzer2021CID}
Maximilian Seitzer, Bernhard Sch{\"o}lkopf, and Georg Martius.
\newblock Causal influence detection for improving efficiency in reinforcement
  learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2021.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2021/file/c1722a7941d61aad6e651a35b65a9c3e-Paper.pdf}.

\bibitem[Janner et~al.(2019)Janner, Fu, Zhang, and Levine]{janner2019trust}
Michael Janner, Justin Fu, Marvin Zhang, and Sergey Levine.
\newblock When to trust your model: Model-based policy optimization.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.
\newblock URL
  \url{https://papers.nips.cc/paper/2019/hash/5faf461eff3099671ad63c6f3f094f7f-Abstract.html}.

\bibitem[Jiang et~al.(2020)Jiang, Janghorbani, {de Melo}, and
  Ahn]{JiangJanghorbaniDeMeloAhn2020SCALOR}
Jindong Jiang, Sepehr Janghorbani, Gerard {de Melo}, and Sungjin Ahn.
\newblock Scalor: Generative world models with scalable object representations.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.
\newblock URL \url{https://openreview.net/pdf?id=SJxrKgStDH}.

\bibitem[Zadaianchuk et~al.(2021)Zadaianchuk, Martius, and
  Yang]{Zadaianchuk22:SMORL}
Andrii Zadaianchuk, Georg Martius, and Fanny Yang.
\newblock Self-supervised reinforcement learning with independently
  controllable subgoals.
\newblock In \emph{Conference on Robot Learning (CoRL)}, 2021.
\newblock URL
  \url{https://proceedings.mlr.press/v164/zadaianchuk22a/zadaianchuk22a.pdf}.

\bibitem[Kannan et~al.(2021)Kannan, Hafner, Finn, and
  Erhan]{kannan2021robodesk}
Harini Kannan, Danijar Hafner, Chelsea Finn, and Dumitru Erhan.
\newblock Robodesk: A multi-task reinforcement learning benchmark.
\newblock \url{https://github.com/google-research/robodesk}, 2021.

\end{thebibliography}
