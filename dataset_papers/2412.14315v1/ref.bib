@article{hll83,
title = {Stochastic blockmodels: First steps},
journal = {Social Networks},
volume = {5},
number = {2},
pages = {109-137},
year = {1983},
issn = {0378-8733},
doi = {https://doi.org/10.1016/0378-8733(83)90021-7},
url = {https://www.sciencedirect.com/science/article/pii/0378873383900217},
author = {Paul W. Holland and Kathryn Blackmond Laskey and Samuel Leinhardt},
abstract = {A stochastic model is proposed for social networks in which the actors in a network are partitioned into subgroups called blocks. The model provides a stochastic generalization of the blockmodel. Estimation techniques are developed for the special case of a single relation social network, with blocks specified a priori. An extension of the model allows for tendencies toward reciprocation of ties beyond those explained by the partition. The extended model provides a one degree-of-freedom test of the model. A numerical example from the social network literature is used to illustrate the methods.}
}

@Article{         numpy,
 title         = {Array programming with {NumPy}},
 author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
                 van der Walt and Ralf Gommers and Pauli Virtanen and David
                 Cournapeau and Eric Wieser and Julian Taylor and Sebastian
                 Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
                 and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
                 Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
                 R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
                 G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
                 Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
                 Travis E. Oliphant},
 year          = {2020},
 month         = sep,
 journal       = {Nature},
 volume        = {585},
 number        = {7825},
 pages         = {357--362},
 doi           = {10.1038/s41586-020-2649-2},
 publisher     = {Springer Science and Business Media {LLC}},
 url           = {https://doi.org/10.1038/s41586-020-2649-2}
}

@techreport{networkx,
  title={Exploring network structure, dynamics, and function using NetworkX},
  author={Hagberg, Aric and Swart, Pieter and S Chult, Daniel},
  year={2008},
  institution={Los Alamos National Lab.(LANL), Los Alamos, NM (United States)}
}

@ARTICLE{scipy,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@INPROCEEDINGS{boppana87,
  author={Boppana, Ravi B.},
  booktitle={28th Annual Symposium on Foundations of Computer Science (sfcs 1987)}, 
  title={Eigenvalues and graph bisection: An average-case analysis}, 
  year={1987},
  volume={},
  number={},
  pages={280-285},
  keywords={Eigenvalues and eigenfunctions;Probability distribution;Partitioning algorithms;Polynomials;Heuristic algorithms;Computer science;Very large scale integration;Mathematics;H infinity control;Algorithm design and analysis},
  doi={10.1109/SFCS.1987.22}}

@InProceedings{sl17,
  author =	{Schuster, Martin R. and Liskiewicz, Maciej},
  title =	{{New Abilities and Limitations of Spectral Graph Bisection}},
  booktitle =	{25th Annual European Symposium on Algorithms (ESA 2017)},
  pages =	{66:1--66:15},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-049-1},
  ISSN =	{1868-8969},
  year =	{2017},
  volume =	{87},
  editor =	{Pruhs, Kirk and Sohler, Christian},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ESA.2017.66},
  URN =		{urn:nbn:de:0030-drops-78658},
  doi =		{10.4230/LIPIcs.ESA.2017.66},
  annote =	{Keywords: Minimum Graph Bisection, Spectral Methods, Convex Programming}
}

@inbook{bv24,
author = {Abhinav Bhardwaj and Van Vu},
title = {Matrix Perturbation: Davis-Kahan in the Infinity Norm},
booktitle = {Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
chapter = {},
pages = {880-934},
year = {2024},
month = {01},
eprint={2304.00328},
      archivePrefix={arXiv},
      primaryClass={math.PR},
}

@InProceedings{gj23,
  title = 	 {Community Detection in the Hypergraph SBM: Exact Recovery Given the Similarity Matrix},
  author =       {Gaudio, Julia and Joshi, Nirmit},
  booktitle = 	 {Proceedings of Thirty Sixth Conference on Learning Theory},
  pages = 	 {469--510},
  year = 	 {2023},
  editor = 	 {Neu, Gergely and Rosasco, Lorenzo},
  volume = 	 {195},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {12--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v195/gaudio23a/gaudio23a.pdf},
  url = 	 {https://proceedings.mlr.press/v195/gaudio23a.html},
  abstract = 	 { Community detection is a fundamental problem in network science. In this paper, we consider community detection in hypergraphs drawn from the \emph{hypergraph stochastic block model} (HSBM), with a focus on exact community recovery. We study the performance of polynomial-time algorithms which operate on the \emph{similarity matrix} $W$, where $W_{ij}$ reports the number of hyperedges containing both $i$ and $j$. Under this information model, while the precise information-theoretic limit is unknown, Kim, Bandeira, and Goemans derived a sharp threshold up to which the natural min-bisection estimator on $W$ succeeds. As min-bisection is NP-hard in the worst case, they additionally proposed a semidefinite programming (SDP) relaxation and conjectured that it achieves the same recovery threshold as the min-bisection algorithm. In this paper, we confirm this conjecture. We also design a simple and highly efficient spectral algorithm with nearly linear runtime and show that it achieves the min-bisection threshold. Moreover, the spectral algorithm also succeeds in denser regimes and is considerably more efficient than previous approaches, establishing it as the method of choice. Our analysis of the spectral algorithm crucially relies on strong \emph{entrywise} bounds on the eigenvectors of $W$. Our bounds are inspired by the work of Abbe, Fan, Wang, and Zhong, who developed entrywise bounds for eigenvectors of symmetric matrices with independent entries. Despite the complex dependency structure in similarity matrices, we prove similar entrywise guarantees.},
eprint={2208.12227},
      archivePrefix={arXiv},
      primaryClass={cs.SI},
}


@ARTICLE{abh16,
  author={Abbe, Emmanuel and Bandeira, Afonso S. and Hall, Georgina},
  journal={IEEE Transactions on Information Theory}, 
  title={Exact Recovery in the Stochastic Block Model}, 
  year={2016},
  volume={62},
  number={1},
  pages={471-487},
  keywords={Stochastic processes;Clustering algorithms;Maximum likelihood decoding;Computational modeling;Machine learning algorithms;Maximum likelihood estimation;Computer science;Communities;clustering algorithms;detection algorithms;statistical learning;network theory (graphs);Communities;clustering algorithms;detection algorithms;statistical learning;network theory (graphs)},
  doi={10.1109/TIT.2015.2490670},
eprint={1405.3267},
      archivePrefix={arXiv},
      primaryClass={cs.SI},
}

@book{vershynin2018,
  title={High-dimensional probability: An introduction with applications in data science},
  author={Vershynin, Roman},
  volume={47},
  year={2018},
  publisher={Cambridge university press}
}

@InProceedings{kllst23,
  title = 	 {Semi-Random Sparse Recovery in Nearly-Linear Time},
  author =       {Kelner, Jonathan and Li, Jerry and Liu, Allen X. and Sidford, Aaron and Tian, Kevin},
  booktitle = 	 {Proceedings of Thirty Sixth Conference on Learning Theory},
  pages = 	 {2352--2398},
  year = 	 {2023},
  editor = 	 {Neu, Gergely and Rosasco, Lorenzo},
  volume = 	 {195},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {07},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v195/kelner23a/kelner23a.pdf},
  url = 	 {https://proceedings.mlr.press/v195/kelner23a.html},
  abstract = 	 {Sparse recovery is one of the most fundamental and well-studied inverse problems.Standard statistical formulations of the problem are provably solved by general convex programming techniques and more practical, fast (nearly-linear time) iterative methods. However, these latter “fast algorithms” have previously been observed to be brittle in various real-world settings.We investigate the brittleness of fast sparse recovery algorithms to generative model changes through the lens of studying their robustness to a “helpful” semi-random adversary, a framework for testing overfitting to input assumptions. We consider the following basic model: let $\mathbf{A} \in \mathbb{R}^{n \times d}$ be a measurement matrix containing an unknown subset of rows $\mathbf{G} \in \mathb{R}^{m \times d}$ which are bounded and satisfy the restricted isometry property (RIP), but is otherwise arbitrary. Letting $x^\star \in \mathbb{R}^d$ be $s$-sparse, and given either exact or noisy measurements, $b = \mathbf{A} x^\star$ or $b = \mathbf{A} x^\star + \xi$, we design algorithms recovering $x^\star$ information-theoretically optimally in nearly-linear time. We extend our algorithm to hold for weaker generative models relaxing our planted RIP row subset assumption to a natural weighted variant, and show that our method’s guarantees naturally interpolate the quality of the measurement matrix to, in some parameter regimes, run in sublinear time.Our approach differs from that of prior fast iterative methods with provable guarantees under semi-random generative models [CG18, LSTZ20], which typically separate the problem of learning the planted instance from the estimation problem, i.e. they attempt to first learn the planted “good” instance (in our case, the matrix $\mathbf{G}$). However, natural conditions on a submatrix which make sparse recovery tractable, such as RIP, are NP-hard to verify and hence first learning a sufficient row reweighting appears challenging. We eschew this approach and design a new iterative method, tailored to the geometry of sparse recovery, which is provably robust to our semi-random model. Our hope is that our approach opens the door to new robust, efficient algorithms for other natural statistical inverse problems.},
eprint={2203.04002},
      archivePrefix={arXiv},
      primaryClass={cs.DS},
}


@article{mn07,
   title={Risk bounds for statistical learning},
   volume={34},
   ISSN={0090-5364},
   url={http://dx.doi.org/10.1214/009053606000000786},
   DOI={10.1214/009053606000000786},
   number={5},
   journal={The Annals of Statistics},
   publisher={Institute of Mathematical Statistics},
   author={Massart, Pascal and Nédélec, Élodie},
   year={2006},
   month={10},
}


@InProceedings{ycom24,
  title = 	 {Top-$K$ ranking with a monotone adversary},
  author =       {Yang, Yuepeng and Chen, Antares and Orecchia, Lorenzo and Ma, Cong},
  booktitle = 	 {Proceedings of Thirty Seventh Conference on Learning Theory},
  pages = 	 {5123--5162},
  year = 	 {2024},
  editor = 	 {Agrawal, Shipra and Roth, Aaron},
  volume = 	 {247},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {07},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v247/yang24b/yang24b.pdf},
  url = 	 {https://proceedings.mlr.press/v247/yang24b.html},
  abstract = 	 {In this paper, we address the top-$K$ ranking problem with a monotone adversary. We consider the scenario where a comparison graph is randomly generated and the adversary is allowed to add arbitrary edges.  The statistician’s goal is then to accurately identify the top-$K$ preferred items based on pairwise comparisons derived from this semi-random comparison graph.  The main contribution of this paper is  to develop a weighted maximum likelihood estimator (MLE) that achieves near-optimal sample complexity, up to a $\log^2(n)$ factor, where $n$ denotes the number of items under comparison. This is made possible through a combination of analytical and algorithmic innovations.  On the analytical front, we provide a refined&nbsp;$\ell_\infty$ error analysis of the weighted MLE that is more explicit and tighter than existing analyses. It relates the&nbsp;$\ell_\infty$ error with the spectral properties of the weighted comparison graph. Motivated by this, our algorithmic innovation involves the development of an SDP-based approach to reweight the semi-random graph and meet specified spectral properties. Additionally, we propose a first-order method based on the Matrix Multiplicative Weight Update (MMWU) framework to solve the resulting SDP efficiently in nearly-linear time in the size of the semi-random comparison graph.},
    eprint={2402.07445},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{ls24,
      title={Spectral clustering in the Gaussian mixture block model}, 
      author={Shuangping Li and Tselil Schramm},
      year={2024},
      eprint={2305.00979},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inbook{gnw24,
author = {Julia Gaudio and Xiaochun Niu and Ermin Wei},
title = {Exact Community Recovery in the Geometric SBM},
booktitle = {Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
chapter = {},
pages = {2158-2184},
doi = {10.1137/1.9781611977912.78},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977912.78},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977912.78},
    abstract = { Abstract We study the problem of exact community recovery in the Geometric Stochastic Block Model (GSBM), where each vertex has an unknown community label as well as a known position, generated according to a Poisson point process in ℝd. Edges are formed independently conditioned on the community labels and positions, where vertices may only be connected by an edge if they are within a prescribed distance of each other. The GSBM thus favors the formation of dense local subgraphs, which commonly occur in real-world networks, a property that makes the GSBM qualitatively very different from the standard Stochastic Block Model (SBM). We propose a linear-time algorithm for exact community recovery, which succeeds down to the information-theoretic threshold, confirming a conjecture of Abbe, Baccelli, and Sankararaman. The algorithm involves two phases. The first phase exploits the density of local subgraphs to propagate estimated community labels among sufficiently occupied subregions, and produces an almost-exact vertex labeling. The second phase then refines the initial labels using a Poisson testing procedure. Thus, the GSBM enjoys local to global amplification just as the SBM, with the advantage of admitting an information-theoretically optimal, linear-time algorithm. },
year={2024},
eprint={2307.11196},
      archivePrefix={arXiv},
      primaryClass={cs.SI},
}

@article{abbe_survey,
  author  = {Emmanuel Abbe},
  title   = {Community Detection and Stochastic Block Models: Recent Developments},
  journal = {Journal of Machine Learning Research},
  year    = {2018},
  volume  = {18},
  number  = {177},
  pages   = {1--86},
  url     = {http://jmlr.org/papers/v18/16-480.html},
eprint={1703.10146},
      archivePrefix={arXiv},
      primaryClass={math.PR},
}

@inbook{moitra_sbm_2021, place={Cambridge}, title={Semirandom Stochastic Block Models}, DOI={10.1017/9781108637435.014}, booktitle={Beyond the Worst-Case Analysis of Algorithms}, publisher={Cambridge University Press}, author={Moitra, Ankur}, editor={Roughgarden, Tim}, year={2021}, pages={212–233}}

@article{gv15,
  title={Community detection in sparse networks via Grothendieck’s inequality},
  author={Gu{\'e}don, Olivier and Vershynin, Roman},
  journal={Probability Theory and Related Fields},
  volume={165},
  number={3},
  pages={1025--1049},
  year={2016},
  publisher={Springer},
eprint={1411.4686},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}

@inproceedings{mpw16,
author = {Moitra, Ankur and Perry, William and Wein, Alexander S.},
title = {How robust are reconstruction thresholds for community detection?},
year = {2016},
isbn = {9781450341325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2897518.2897573},
doi = {10.1145/2897518.2897573},
abstract = {The stochastic block model is one of the oldest and most ubiquitous models for studying clustering and community detection. In an exciting sequence of developments, motivated by deep but non-rigorous ideas from statistical physics, Decelle et al. conjectured a sharp threshold for when community detection is possible in the sparse regime. Mossel, Neeman and Sly and Massoulie proved the conjecture and gave matching algorithms and lower bounds.  Here we revisit the stochastic block model from the perspective of semirandom models where we allow an adversary to make `helpful' changes that strengthen ties within each community and break ties between them. We show a surprising result that these `helpful' changes can shift the information-theoretic threshold, making the community detection problem strictly harder. We complement this by showing that an algorithm based on semidefinite programming (which was known to get close to the threshold) continues to work in the semirandom model (even for partial recovery). This suggests that algorithms based on semidefinite programming are robust in ways that any algorithm meeting the information-theoretic threshold cannot be.  These results point to an interesting new direction: Can we find robust, semirandom analogues to some of the classical, average-case thresholds in statistics? We also explore this question in the broadcast tree model, and we show that the viewpoint of semirandom models can help explain why some algorithms are preferred to others in practice, in spite of the gaps in their statistical performance on random models.},
booktitle = {Proceedings of the Forty-Eighth Annual ACM Symposium on Theory of Computing},
pages = {828–841},
numpages = {14},
keywords = {Community detection, broadcast tree model, semidefinite programming, semirandom models, stochastic block model},
location = {Cambridge, MA, USA},
series = {STOC '16},
eprint={1511.01473},
      archivePrefix={arXiv},
      primaryClass={cs.DS},
}

@article{vl07,
  title={A tutorial on spectral clustering},
  author={Von Luxburg, Ulrike},
  journal={Statistics and computing},
  volume={17},
  pages={395--416},
  year={2007},
  publisher={Springer},
eprint={0711.0189},
      archivePrefix={arXiv},
      primaryClass={cs.DS},
}

@article{cr11,
  title={On the spectra of general random graphs},
  author={Chung, Fan and Radcliffe, Mary},
  journal={the electronic journal of combinatorics},
  pages={P215--P215},
  year={2011}
}

@article{sb15,
   title={Role of normalization in spectral clustering for stochastic blockmodels},
   volume={43},
   ISSN={0090-5364},
   url={http://dx.doi.org/10.1214/14-AOS1285},
   DOI={10.1214/14-aos1285},
   number={3},
   journal={The Annals of Statistics},
   publisher={Institute of Mathematical Statistics},
   author={Sarkar, Purnamrita and Bickel, Peter J.},
   year={2015},
   month={06},
eprint={1310.1495},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
}

@article{afwz17,
  title={Entrywise eigenvector analysis of random matrices with low expected rank},
  author={Abbe, Emmanuel and Fan, Jianqing and Wang, Kaizheng and Zhong, Yiqiao},
  journal={Annals of statistics},
  volume={48},
  number={3},
  pages={1452},
  year={2020},
  publisher={NIH Public Access},
eprint={1709.09565},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}

@article{fk01,
author = {Feige, Uriel and Kilian, Joe},
title = {Heuristics for Semirandom Graph Problems},
year = {2001},
issue_date = {December 2001},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {63},
number = {4},
issn = {0022-0000},
url = {https://doi.org/10.1006/jcss.2001.1773},
doi = {10.1006/jcss.2001.1773},
abstract = {We consider semirandom graph models for finding large independent sets, colorings, and bisections in graphs. These models generate problem instances by blending random and adversarial decisions. To generate semirandom independent set problems, an independent set S of n vertices is randomly chosen. Each edge connecting S with S is chosen with probability p, and an adversary is then allowed to add new edges arbitrarily, provided that S remains an independent set. The smaller p is, the greater the control the adversary has over the semirandom graph. We give a heuristic that with high probability recovers an independent set of size n whenever p&gt; (1+ )lnn/ n, for any constant &gt;0. We show that when p&lt;(1 )lnn / n, an independent set of size |S| cannot be recovered, unless NP BPP. We use our result for maximum independent sets to obtain greatly improved heuristics for the model of k-colorable semirandom graphs introduced by Blum and Spencer. For constant k, our results are optimal up to constant factors in the edge probabilities. In the semirandom model for graph bisection, a random bisection (S, S) of the vertices is chosen. Each edge (u, v) S S is independently chosen with probability q and each edge (u, v) S S is independently chosen with probability pq. The adversary may then arbitrarily remove edges in S S and add edges not in S S. Extending the work of Boppana, we give a heuristic that recovers this bisection with high probability when p q cplogn/n, for c a sufficiently large constant.},
journal = {J. Comput. Syst. Sci.},
month = {12},
pages = {639–671},
numpages = {33}
}

@inproceedings{mmv12,
author = {Makarychev, Konstantin and Makarychev, Yury and Vijayaraghavan, Aravindan},
title = {Approximation algorithms for semi-random partitioning problems},
year = {2012},
isbn = {9781450312455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
booktitle = {Proceedings of the Forty-Fourth Annual ACM Symposium on Theory of Computing},
pages = {367–384},
numpages = {18},
keywords = {semi-random model, random planted model, graph partitioning, average-case analysis, approximation algorithm},
location = {New York, New York, USA},
series = {STOC '12},
eprint={1205.2234},
archivePrefix={arXiv},
primaryClass={cs.DS}
}

@article{llv16,
  title={Concentration and regularization of random graphs},
  author={Le, Can M and Levina, Elizaveta and Vershynin, Roman},
  journal={Random Structures \& Algorithms},
  volume={51},
  number={3},
  pages={538--561},
  year={2017},
  publisher={Wiley Online Library},
eprint={1506.00669},
      archivePrefix={arXiv},
      primaryClass={math.PR}
}

@article{dls20,
  title={Strong consistency, graph laplacians, and the stochastic block model},
  author={Deng, Shaofeng and Ling, Shuyang and Strohmer, Thomas},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={117},
  pages={1--44},
  year={2021},
eprint={2004.09780},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{mmt20,
author = {Theo McKenzie and Hermish Mehta and Luca Trevisan},
title = {A new algorithm for the robust semi-random independent set problem},
year = {2020},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
abstract = {We study the independent set problem in a semi-random model proposed by Feige and Kilian. This model selects a graph with a planted independent set of size k and then allows an adversary to modify a large fraction of edges: the subgraph induced by the complement of the independent set can be modified arbitrarily, and the adversary may add (but not delete) edges from the independent set to its complement. In particular, the adversary can create a graph in which the initial planted independent set is not the largest independent set. Feige and Kilian presented a randomized algorithm, which with high probability recovers an independent set of size at least k (which may not be the planted one) when k = αn where α is a constant, and the probability of a random edge p > (1 + ϵ) ln n/αn. We give a new deterministic algorithm in the Feige-Kilian model that finds an independent set of size at least .99k provided that the planted set has size k = Ω(n2/3/p1/3), and finds a list of independent sets, one of which is the planted one provided that k = Ω(n2/3/p). This improves on the algorithm of Feige and Kilian by working for smaller k if p = Ω(1/n1/3), and improves on an algorithm of Steinhardt by working for slightly smaller k and by working against a stronger adversarial model. The ability to find a good approximation of the largest independent set is new when p < ln n/k.},
booktitle = {Proceedings of the Thirty-First Annual ACM-SIAM Symposium on Discrete Algorithms},
pages = {738–746},
numpages = {9},
location = {Salt Lake City, Utah},
series = {SODA '20},
eprint={1808.03633},
      archivePrefix={arXiv},
      primaryClass={cs.DS},
}

@inproceedings{csv17,
author = {Charikar, Moses and Steinhardt, Jacob and Valiant, Gregory},
title = {Learning from untrusted data},
year = {2017},
isbn = {9781450345286},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The vast majority of theoretical results in machine learning and statistics assume that the training data is a reliable reflection of the phenomena to be learned. Similarly, most learning techniques used in practice are brittle to the presence of large amounts of biased or malicious data. Motivated by this, we consider two frameworks for studying estimation, learning, and optimization in the presence of significant fractions of arbitrary data. The first framework, list-decodable learning, asks whether it is possible to return a list of answers such that at least one is accurate. For example, given a dataset of n points for which an unknown subset of αn points are drawn from a distribution of interest, and no assumptions are made about the remaining (1 - α)n points, is it possible to return a list of poly(1/α) answers? The second framework, which we term the semi-verified model, asks whether a small dataset of trusted data (drawn from the distribution in question) can be used to extract accurate information from a much larger but untrusted dataset (of which only an α-fraction is drawn from the distribution). We show strong positive results in both settings, and provide an algorithm for robust learning in a very general stochastic optimization setting. This result has immediate implications for robustly estimating the mean of distributions with bounded second moments, robustly learning mixtures of such distributions, and robustly finding planted partitions in random graphs in which significant portions of the graph have been perturbed by an adversary.},
booktitle = {Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing},
pages = {47–60},
numpages = {14},
keywords = {robust learning, outlier removal, high-dimensional statistics},
location = {Montreal, Canada},
series = {STOC 2017},
eprint={1611.02315},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}

@article{KVV, author = {Kannan, Ravi and Vempala, Santosh and Vetta, Adrian}, title = {On clusterings: Good, bad and spectral}, year = {2004}, issue_date = {May 2004}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, volume = {51}, number = {3}, issn = {0004-5411}, url = {https://doi.org/10.1145/990308.990313}, doi = {10.1145/990308.990313}, abstract = {We motivate and develop a natural bicriteria measure for assessing the quality of a clustering that avoids the drawbacks of existing measures. A simple recursive heuristic is shown to have poly-logarithmic worst-case guarantees under the new measure. The main result of the article is the analysis of a popular spectral algorithm. One variant of spectral clustering turns out to have effective worst-case guarantees; another finds a "good" clustering, if one exists.}, journal = {J. ACM}, month = {may}, pages = {497–515}, numpages = {19}, keywords = {Clustering, graph algorithms, spectral methods} }


@article{BS95,
title = {Coloring Random and Semi-Random k-Colorable Graphs},
journal = {Journal of Algorithms},
volume = {19},
number = {2},
pages = {204-234},
year = {1995},
issn = {0196-6774},
doi = {https://doi.org/10.1006/jagm.1995.1034},
url = {https://www.sciencedirect.com/science/article/pii/S0196677485710346},
author = {Avrim Blum and Joel Spencer},
abstract = {The problem of coloring a graph with the minimum number of colors is well known to be NP-hard, even restricted to k-colorable graphs for constant k ≥ 3. On the other hand, it is known that random k-colorable graphs are easy to k-color. The algorithms for coloring random k-colorable graphs require fairly high edge densities, however. In this paper we present algorithms that color randomly generated k-colorable graphs for much lower edge densities than previous approaches. In addition, to study a wider variety of graph distributions, we also present a model of graphs generated by the semi-random source of Santha and Vazirani (M. Santha and U. V. Vazirani, J. Comput. System Sci.33 (1986), 75-87) that provides a smooth transition between the worst-case and random models. In this model, the graph is generated by a "noisy adversary"-an adversary whose decisions (whether or not to insert a particular edge) have some small (random) probability of being reversed. We show that even for quite low noise rates, semi-random k-colorable graphs can be optimally colored with high probability.}
}

@INPROCEEDINGS{BS17,
  author={Sankararaman, Abishek and Baccelli, François},
  booktitle={2017 55th Annual Allerton Conference on Communication, Control, and Computing (Allerton)}, 
  title={Community detection on euclidean random graphs}, 
  year={2017},
  volume={},
  number={},
  pages={510-517},
  keywords={Geometry;Image edge detection;Social network services;Mathematical model;Stochastic processes;Partitioning algorithms;Estimation},
  doi={10.1109/ALLERTON.2017.8262780}
}

@article{ABARS20,
author = {Abbe, Emmanuel and Boix-Adser\`{a}, Enric and Ralli, Peter and Sandon, Colin},
title = {Graph Powering and Spectral Robustness},
journal = {SIAM Journal on Mathematics of Data Science},
volume = {2},
number = {1},
pages = {132-157},
year = {2020},
doi = {10.1137/19M1257135},

URL = {
        https://doi.org/10.1137/19M1257135
},
eprint = { 
        https://doi.org/10.1137/19M1257135
}
,
    abstract = { Spectral algorithms, such as principal component analysis and spectral clustering, rely on the extremal eigenpairs of a matrix \$A\$. However, these may be uninformative without preprocessing \$A\$ with a proper transformation. The reason is that the spectrum of \$A\$ may be contaminated by top eigenvalues resulting from scale variations in the data, such as high-degree nodes. Designing a good \$\psi\$ and establishing what good means is often challenging and model dependent. This paper proposes a simple and generic construction for sparse graphs, \$\psi(A) = \mathbb{1}((I+A)^r \ge 1)\$, where \$A\$ denotes the adjacency matrix, \$r\$ is an integer, and the indicator function is applied entrywise. We support this “graph powering” construction with the following regularization properties: (i) if the graph is drawn from the sparse Erdös--Rényi ensemble, which has no spectral gap, then graph powering produces a “maximal” spectral gap, comparable to that obtained when powering a random regular graph; (ii) if the graph is drawn from the sparse stochastic block model, graph powering achieves the fundamental limit for weak recovery (the Kesten--Stigum threshold), settling at the same time a related conjecture by Massoulié in 2013; (iii) we also demonstrate that graph powering is significantly more robust to tangles and cliques than previous spectral algorithms based on self-avoiding or nonbacktracking walk counts, using a geometric block model as our benchmark and introducing new conjectures for this model. },
    archivePrefix={arXiv},
    eprint={1809.04818},
    primaryClass={cs.DS}
}

@INPROCEEDINGS{GMPS18,
  author={Galhotra, Sainyam and Pal, Soumyabrata and Mazumdar, Arya and Saha, Barna},
  booktitle={2018 56th Annual Allerton Conference on Communication, Control, and Computing (Allerton)}, 
  title={The Geometric Block Model and Applications}, 
  year={2018},
  volume={},
  number={},
  pages={1147-1150},
  keywords={Clustering algorithms;Image edge detection;Blogs;Computational modeling;Random variables;DVD;Artificial neural networks},
  doi={10.1109/ALLERTON.2018.8635938}}

@InProceedings{GMPS20,
  author =	{Galhotra, Sainyam and Mazumdar, Arya and Pal, Soumyabrata and Saha, Barna},
  title =	{{Connectivity of Random Annulus Graphs and the Geometric Block Model}},
  booktitle =	{Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques (APPROX/RANDOM 2019)},
  pages =	{53:1--53:23},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-125-2},
  ISSN =	{1868-8969},
  year =	{2019},
  volume =	{145},
  editor =	{Achlioptas, Dimitris and V\'{e}gh, L\'{a}szl\'{o} A.},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
eprint={1804.05013},
      archivePrefix={arXiv},
      primaryClass={cs.DM}
}

@article{ABD21,
	abstract = {The present paper is devoted to clustering geometric graphs. While the standard spectral clustering is often not effective for geometric graphs, we present an effective generalization, which we call higher-order spectral clustering. It resembles in concept the classical spectral clustering method but uses for partitioning the eigenvector associated with a higher-order eigenvalue. We establish the weak consistency of this algorithm for a wide class of geometric graphs which we call Soft Geometric Block Model. A small adjustment of the algorithm provides strong consistency. We also show that our method is effective in numerical experiments even for graphs of modest size.},
	author = {Avrachenkov, Konstantin and Bobu, Andrei and Dreveton, Maximilien},
        year = {2021},
        month = {03},
	doi = {10.1007/s00041-021-09825-2},
	id = {Avrachenkov2021},
	journal = {Journal of Fourier Analysis and Applications},
	number = {2},
	pages = {22},
	title = {Higher-Order Spectral Clustering for Geometric Graphs},
	url = {https://doi.org/10.1007/s00041-021-09825-2},
	volume = {27},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1007/s00041-021-09825-2},
archivePrefix={arXiv},
      primaryClass={cs.LG},
      eprint={2009.11353},
}

@article{BHK16,
  title={A nearly tight sum-of-squares lower bound for the planted clique problem},
  author={Barak, Boaz and Hopkins, Samuel and Kelner, Jonathan and Kothari, Pravesh K and Moitra, Ankur and Potechin, Aaron},
  journal={SIAM Journal on Computing},
  volume={48},
  number={2},
  pages={687--735},
  year={2019},
  publisher={SIAM},
eprint={1604.03084},
      archivePrefix={arXiv},
      primaryClass={cs.CC},
}

@article{Jerrum92,
  author       = {Mark Jerrum},
  title        = {Large Cliques Elude the Metropolis Process},
  journal      = {Random Struct. Algorithms},
  volume       = {3},
  number       = {4},
  pages        = {347--360},
  year         = {1992},
  url          = {https://doi.org/10.1002/rsa.3240030402},
  doi          = {10.1002/RSA.3240030402},
  timestamp    = {Wed, 14 Nov 2018 10:13:53 +0100},
  biburl       = {https://dblp.org/rec/journals/rsa/Jerrum92.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{Kuc95,
	abstract = {We study the expected time complexity of two graph partitioning problems: the graph coloring and the cut into equal parts. If k = o(√nlog n), we can test whether two vertices of a k-colorable graph can be k-colored by the same color in time O(k log n) per pair of vertices with O(k4 log3 n)-time preprocessing in such a way that for almost all k-colorable graphs the answer is correct for all pairs of vertices. From this we obtain a sublinear (with respect to the number of edges) expected time algorithm for k-coloring of k-colorable graphs (assuming the uniform input distribution). Similarly, if c ⩽ (18 − ε)n2, ε > 0 is a constant, and G is a graph having a cut of the vertex set into two equal parts with at most c cross-edges, we can test whether two vertices belong to the same class of some c-cut in time O(log n) per vertex with O(log3 n)-time preprocessing in such a way that for almost all graphs having a c-cut the answer is correct for all pairs of vertices. The methods presented in the paper can also be used for other graph partitioning problems, e.g. the largest clique or independent subset.},
	author = {Lud{\v e}k Ku{\v c}era},
	doi = {https://doi.org/10.1016/0166-218X(94)00103-K},
	issn = {0166-218X},
	journal = {Discrete Applied Mathematics},
	note = {Combinatorial optimization 1992},
	number = {2},
	pages = {193-212},
	title = {Expected complexity of graph partitioning problems},
	url = {https://www.sciencedirect.com/science/article/pii/0166218X9400103K},
	volume = {57},
	year = {1995},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/0166218X9400103K},
	bdsk-url-2 = {https://doi.org/10.1016/0166-218X(94)00103-K}
}

@inproceedings{BKS23,
author = {Buhai, Rares-Darius and Kothari, Pravesh K. and Steurer, David},
title = {Algorithms Approaching the Threshold for Semi-random Planted Clique},
year = {2023},
isbn = {9781450399135},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We design new polynomial-time algorithms for recovering planted cliques in the semi-random graph model introduced by Feige and Kilian. The previous best algorithms for this model succeed if the planted clique has size at least n2/3 in a graph with n vertices. Our algorithms work for planted-clique sizes approaching n1/2 — the information-theoretic threshold in the semi-random model and a conjectured computational threshold even in the easier fully-random model. This result comes close to resolving open questions by Feige and Steinhardt. To generate a graph in the semi-random planted-clique model, we first 1) plant a clique of size k in an n-vertex –graph with edge probability 1/2 and then adversarially add or delete an arbitrary number edges not touching the planted clique and delete any subset of edges going out of the planted clique. For every є>0, we give an nO(1/є)-time algorithm that recovers a clique of size k in this model whenever k ≥ n1/2+є. In fact, our algorithm computes, with high probability, a list of about n/k cliques of size k that contains the planted clique. Our algorithms also extend to arbitrary edge probabilities p and improve on the previous best guarantee whenever p ≤ 1−n−0.001. Our algorithms rely on a new conceptual connection that translates certificates of upper bounds on biclique numbers in unbalanced bipartite –random graphs into algorithms for semi-random planted clique. Analogous to the (conjecturally) optimal algorithms for the fully-random model, the previous best guarantees for semi-random planted clique correspond to spectral relaxations of biclique numbers based on eigenvalues of adjacency matrices. We construct an SDP lower bound that shows that the n2/3 threshold in prior works is an inherent limitation of these spectral relaxations. We go beyond this limitation by using higher-order sum-of-squares relaxations for biclique numbers. We also provide some evidence that the information-computation trade-off of our current algorithms may be inherent by proving an average-case lower bound for unbalanced bicliques in the low-degree polynomial model.},
booktitle = {Proceedings of the 55th Annual ACM Symposium on Theory of Computing},
pages = {1918–1926},
numpages = {9},
keywords = {planted clique, semi-random, semidefinite programming, sum-of-squares hierarchy},
location = {Orlando, FL, USA},
series = {STOC 2023},
eprint={2212.05619},
      archivePrefix={arXiv},
      primaryClass={cs.DS}
}

@InProceedings{bglmsy23,
      title={Dueling Optimization with a Monotone Adversary}, 
      author={Avrim Blum and Meghal Gupta and Gene Li and Naren Sarayu Manoj and Aadirupa Saha and Yuanyuan Yang},
      year={2024},
      month={02},
      booktitle = {Proceedings of Thirty Fifth Conference on Algorithmic Learning Theory (ALT)},
      archivePrefix={arXiv},
      primaryClass={cs.DS},
      eprint={2311.11185},
}


@InProceedings{AV18,
  title = 	 {Clustering Semi-Random Mixtures of {G}aussians},
  author =       {Vijayaraghavan, Aravindan and Awasthi, Pranjal},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {5055--5064},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {07},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/vijayaraghavan18a/vijayaraghavan18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/vijayaraghavan18a.html},
  abstract = 	 {Gaussian mixture models (GMM) are the most widely used statistical model for the k-means clustering problem and form a popular framework for clustering in machine learning and data analysis. In this paper, we propose a natural robust model for k-means clustering that generalizes the Gaussian mixture model, and that we believe will be useful in identifying robust algorithms. Our first contribution is a polynomial time algorithm that provably recovers the ground-truth up to small classification error w.h.p., assuming certain separation between the components. Perhaps surprisingly, the algorithm we analyze is the popular Lloyd’s algorithm for k-means clustering that is the method-of-choice in practice. Our second result complements the upper bound by giving a nearly matching lower bound on the number of misclassified points incurred by any k-means clustering algorithm on the semi-random model.},
eprint={1711.08841},
      archivePrefix={arXiv},
      primaryClass={cs.DS},
}

@inproceedings{
GC23,
title={Robust Matrix Sensing in the Semi-Random Model},
author={Xing Gao and Yu Cheng},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=nSr2epejn2}
}

@inproceedings{
cdm24,
title={A Near-Linear Time Approximation Algorithm for Beyond-Worst-Case Graph Clustering},
author={Vincent Cohen-Addad and Tommaso d'Orsi and Aida Mousavifar},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=MSFxOMM0gK},
eprint={2406.04857},
      archivePrefix={arXiv},
      primaryClass={cs.DS},
}