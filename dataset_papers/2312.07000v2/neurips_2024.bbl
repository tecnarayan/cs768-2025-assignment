\begin{thebibliography}{}

\bibitem[Allen{-}Zhu and Li, 2023]{DBLP:journals/corr/abs-2309-14402}
Allen{-}Zhu, Z. and Li, Y. (2023).
\newblock Physics of language models: Part 3.2, knowledge manipulation.
\newblock {\em CoRR}, abs/2309.14402.

\bibitem[Amayuelas et~al., 2023]{DBLP:journals/corr/abs-2305-13712}
Amayuelas, A., Pan, L., Chen, W., and Wang, W.~Y. (2023).
\newblock Knowledge of knowledge: Exploring known-unknowns uncertainty with large language models.
\newblock {\em CoRR}, abs/2305.13712.

\bibitem[Anil et~al., 2023]{DBLP:journals/corr/abs-2305-10403}
Anil, R., Dai, A.~M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri, S., Taropa, E., Bailey, P., Chen, Z., Chu, E., Clark, J.~H., Shafey, L.~E., Huang, Y., Meier{-}Hellstern, K., Mishra, G., Moreira, E., Omernick, M., Robinson, K., Ruder, S., Tay, Y., Xiao, K., Xu, Y., Zhang, Y., {\'{A}}brego, G.~H., Ahn, J., Austin, J., Barham, P., Botha, J.~A., Bradbury, J., Brahma, S., Brooks, K., Catasta, M., Cheng, Y., Cherry, C., Choquette{-}Choo, C.~A., Chowdhery, A., Crepy, C., Dave, S., Dehghani, M., Dev, S., Devlin, J., D{\'{\i}}az, M., Du, N., Dyer, E., Feinberg, V., Feng, F., Fienber, V., Freitag, M., Garcia, X., Gehrmann, S., Gonzalez, L., and et~al. (2023).
\newblock Palm 2 technical report.
\newblock {\em CoRR}, abs/2305.10403.

\bibitem[Askell et~al., 2021]{DBLP:journals/corr/abs-2112-00861}
Askell, A., Bai, Y., Chen, A., Drain, D., Ganguli, D., Henighan, T., Jones, A., Joseph, N., Mann, B., DasSarma, N., Elhage, N., Hatfield{-}Dodds, Z., Hernandez, D., Kernion, J., Ndousse, K., Olsson, C., Amodei, D., Brown, T.~B., Clark, J., McCandlish, S., Olah, C., and Kaplan, J. (2021).
\newblock A general language assistant as a laboratory for alignment.
\newblock {\em CoRR}, abs/2112.00861.

\bibitem[Bai et~al., 2023]{qwen}
Bai, J., Bai, S., Chu, Y., Cui, Z., Dang, K., Deng, X., Fan, Y., Ge, W., Han, Y., Huang, F., Hui, B., Ji, L., Li, M., Lin, J., Lin, R., Liu, D., Liu, G., Lu, C., Lu, K., Ma, J., Men, R., Ren, X., Ren, X., Tan, C., Tan, S., Tu, J., Wang, P., Wang, S., Wang, W., Wu, S., Xu, B., Xu, J., Yang, A., Yang, H., Yang, J., Yang, S., Yao, Y., Yu, B., Yuan, H., Yuan, Z., Zhang, J., Zhang, X., Zhang, Y., Zhang, Z., Zhou, C., Zhou, J., Zhou, X., and Zhu, T. (2023).
\newblock Qwen technical report.
\newblock {\em arXiv preprint arXiv:2309.16609}.

\bibitem[Bai et~al., 2022a]{DBLP:journals/corr/abs-2204-05862}
Bai, Y., Jones, A., Ndousse, K., Askell, A., Chen, A., DasSarma, N., Drain, D., Fort, S., Ganguli, D., Henighan, T., Joseph, N., Kadavath, S., Kernion, J., Conerly, T., Showk, S.~E., Elhage, N., Hatfield{-}Dodds, Z., Hernandez, D., Hume, T., Johnston, S., Kravec, S., Lovitt, L., Nanda, N., Olsson, C., Amodei, D., Brown, T.~B., Clark, J., McCandlish, S., Olah, C., Mann, B., and Kaplan, J. (2022a).
\newblock Training a helpful and harmless assistant with reinforcement learning from human feedback.
\newblock {\em CoRR}, abs/2204.05862.

\bibitem[Bai et~al., 2022b]{DBLP:journals/corr/abs-2212-08073}
Bai, Y., Kadavath, S., Kundu, S., Askell, A., Kernion, J., Jones, A., Chen, A., Goldie, A., Mirhoseini, A., McKinnon, C., Chen, C., Olsson, C., Olah, C., Hernandez, D., Drain, D., Ganguli, D., Li, D., Tran{-}Johnson, E., Perez, E., Kerr, J., Mueller, J., Ladish, J., Landau, J., Ndousse, K., Lukosiute, K., Lovitt, L., Sellitto, M., Elhage, N., Schiefer, N., Mercado, N., DasSarma, N., Lasenby, R., Larson, R., Ringer, S., Johnston, S., Kravec, S., Showk, S.~E., Fort, S., Lanham, T., Telleen{-}Lawton, T., Conerly, T., Henighan, T., Hume, T., Bowman, S.~R., Hatfield{-}Dodds, Z., Mann, B., Amodei, D., Joseph, N., McCandlish, S., Brown, T., and Kaplan, J. (2022b).
\newblock Constitutional {AI:} harmlessness from {AI} feedback.
\newblock {\em CoRR}, abs/2212.08073.

\bibitem[Baichuan, 2023]{baichuan2023baichuan2}
Baichuan (2023).
\newblock Baichuan 2: Open large-scale language models.
\newblock {\em arXiv preprint arXiv:2309.10305}.

\bibitem[Brown et~al., 2020]{DBLP:conf/nips/BrownMRSKDNSSAA20}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert{-}Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D.~M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. (2020).
\newblock Language models are few-shot learners.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H., editors, {\em Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual}.

\bibitem[Burns et~al., 2023]{DBLP:conf/iclr/BurnsYKS23}
Burns, C., Ye, H., Klein, D., and Steinhardt, J. (2023).
\newblock Discovering latent knowledge in language models without supervision.
\newblock In {\em The Eleventh International Conference on Learning Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net.

\bibitem[Carlini et~al., 2023]{DBLP:conf/iclr/CarliniIJLTZ23}
Carlini, N., Ippolito, D., Jagielski, M., Lee, K., Tram{\`{e}}r, F., and Zhang, C. (2023).
\newblock Quantifying memorization across neural language models.
\newblock In {\em The Eleventh International Conference on Learning Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net.

\bibitem[Carlini et~al., 2021]{DBLP:conf/uss/CarliniTWJHLRBS21}
Carlini, N., Tram{\`{e}}r, F., Wallace, E., Jagielski, M., Herbert{-}Voss, A., Lee, K., Roberts, A., Brown, T.~B., Song, D., Erlingsson, {\'{U}}., Oprea, A., and Raffel, C. (2021).
\newblock Extracting training data from large language models.
\newblock In Bailey, M.~D. and Greenstadt, R., editors, {\em 30th {USENIX} Security Symposium, {USENIX} Security 2021, August 11-13, 2021}, pages 2633--2650. {USENIX} Association.

\bibitem[Chern et~al., 2023]{DBLP:journals/corr/abs-2307-13528}
Chern, I., Chern, S., Chen, S., Yuan, W., Feng, K., Zhou, C., He, J., Neubig, G., and Liu, P. (2023).
\newblock Factool: Factuality detection in generative {AI} - {A} tool augmented framework for multi-task and multi-domain scenarios.
\newblock {\em CoRR}, abs/2307.13528.

\bibitem[Chung et~al., 2022]{DBLP:journals/corr/abs-2210-11416}
Chung, H.~W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., Webson, A., Gu, S.~S., Dai, Z., Suzgun, M., Chen, X., Chowdhery, A., Narang, S., Mishra, G., Yu, A., Zhao, V.~Y., Huang, Y., Dai, A.~M., Yu, H., Petrov, S., Chi, E.~H., Dean, J., Devlin, J., Roberts, A., Zhou, D., Le, Q.~V., and Wei, J. (2022).
\newblock Scaling instruction-finetuned language models.
\newblock {\em CoRR}, abs/2210.11416.

\bibitem[Cole et~al., 2023]{DBLP:journals/corr/abs-2305-14613}
Cole, J.~R., Zhang, M. J.~Q., Gillick, D., Eisenschlos, J.~M., Dhingra, B., and Eisenstein, J. (2023).
\newblock Selectively answering ambiguous questions.
\newblock {\em CoRR}, abs/2305.14613.

\bibitem[Confucius and Disciple, 1 BC]{confucius221}
Confucius and Disciple (221 BC).
\newblock The analects of confucius.

\bibitem[Cui et~al., 2023]{DBLP:journals/corr/abs-2310-01377}
Cui, G., Yuan, L., Ding, N., Yao, G., Zhu, W., Ni, Y., Xie, G., Liu, Z., and Sun, M. (2023).
\newblock Ultrafeedback: Boosting language models with high-quality feedback.
\newblock {\em CoRR}, abs/2310.01377.

\bibitem[Ding et~al., 2023]{DBLP:journals/corr/abs-2305-14233}
Ding, N., Chen, Y., Xu, B., Qin, Y., Zheng, Z., Hu, S., Liu, Z., Sun, M., and Zhou, B. (2023).
\newblock Enhancing chat language models by scaling high-quality instructional conversations.
\newblock {\em CoRR}, abs/2305.14233.

\bibitem[Dong et~al., 2023]{DBLP:journals/corr/abs-2304-06767}
Dong, H., Xiong, W., Goyal, D., Pan, R., Diao, S., Zhang, J., Shum, K., and Zhang, T. (2023).
\newblock {RAFT:} reward ranked finetuning for generative foundation model alignment.
\newblock {\em CoRR}, abs/2304.06767.

\bibitem[Evans et~al., 2021]{DBLP:journals/corr/abs-2110-06674}
Evans, O., Cotton{-}Barratt, O., Finnveden, L., Bales, A., Balwit, A., Wills, P., Righetti, L., and Saunders, W. (2021).
\newblock Truthful {AI:} developing and governing {AI} that does not lie.
\newblock {\em CoRR}, abs/2110.06674.

\bibitem[Gao et~al., 2023]{gao2023scaling}
Gao, L., Schulman, J., and Hilton, J. (2023).
\newblock Scaling laws for reward model overoptimization.
\newblock In {\em International Conference on Machine Learning}, pages 10835--10866. PMLR.

\bibitem[Gekhman et~al., 2024]{DBLP:journals/corr/abs-2405-05904}
Gekhman, Z., Yona, G., Aharoni, R., Eyal, M., Feder, A., Reichart, R., and Herzig, J. (2024).
\newblock Does fine-tuning llms on new knowledge encourage hallucinations?
\newblock {\em CoRR}, abs/2405.05904.

\bibitem[Glaese et~al., 2022]{DBLP:journals/corr/abs-2209-14375}
Glaese, A., McAleese, N., Trebacz, M., Aslanides, J., Firoiu, V., Ewalds, T., Rauh, M., Weidinger, L., Chadwick, M.~J., Thacker, P., Campbell{-}Gillingham, L., Uesato, J., Huang, P., Comanescu, R., Yang, F., See, A., Dathathri, S., Greig, R., Chen, C., Fritz, D., Elias, J.~S., Green, R., Mokr{\'{a}}, S., Fernando, N., Wu, B., Foley, R., Young, S., Gabriel, I., Isaac, W., Mellor, J., Hassabis, D., Kavukcuoglu, K., Hendricks, L.~A., and Irving, G. (2022).
\newblock Improving alignment of dialogue agents via targeted human judgements.
\newblock {\em CoRR}, abs/2209.14375.

\bibitem[Hendrycks et~al., 2021]{DBLP:conf/iclr/HendrycksBBZMSS21}
Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J. (2021).
\newblock Measuring massive multitask language understanding.
\newblock In {\em 9th International Conference on Learning Representations, {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021}. OpenReview.net.

\bibitem[InternLM, 2023]{2023internlm}
InternLM (2023).
\newblock Internlm: A multilingual language model with progressively enhanced capabilities.
\newblock \url{https://github.com/InternLM/InternLM}.

\bibitem[Ji et~al., 2023a]{DBLP:journals/corr/abs-2307-04657}
Ji, J., Liu, M., Dai, J., Pan, X., Zhang, C., Bian, C., Zhang, B., Sun, R., Wang, Y., and Yang, Y. (2023a).
\newblock Beavertails: Towards improved safety alignment of {LLM} via a human-preference dataset.
\newblock {\em CoRR}, abs/2307.04657.

\bibitem[Ji et~al., 2023b]{beavertails}
Ji, J., Liu, M., Dai, J., Pan, X., Zhang, C., Bian, C., Zhang, C., Sun, R., Wang, Y., and Yang, Y. (2023b).
\newblock Beavertails: Towards improved safety alignment of llm via a human-preference dataset.
\newblock {\em arXiv preprint arXiv:2307.04657}.

\bibitem[Ji et~al., 2023c]{DBLP:journals/csur/JiLFYSXIBMF23}
Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y., Madotto, A., and Fung, P. (2023c).
\newblock Survey of hallucination in natural language generation.
\newblock {\em {ACM} Comput. Surv.}, 55(12):248:1--248:38.

\bibitem[Jiang et~al., 2021]{DBLP:journals/tacl/JiangADN21}
Jiang, Z., Araki, J., Ding, H., and Neubig, G. (2021).
\newblock How can we know \emph{When} language models know? on the calibration of language models for question answering.
\newblock {\em Trans. Assoc. Comput. Linguistics}, 9:962--977.

\bibitem[Joshi et~al., 2017]{DBLP:conf/acl/JoshiCWZ17}
Joshi, M., Choi, E., Weld, D.~S., and Zettlemoyer, L. (2017).
\newblock Triviaqa: {A} large scale distantly supervised challenge dataset for reading comprehension.
\newblock In Barzilay, R. and Kan, M., editors, {\em Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, {ACL} 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers}, pages 1601--1611. Association for Computational Linguistics.

\bibitem[Joshi et~al., 2023]{DBLP:journals/corr/abs-2310-18168}
Joshi, N., Rando, J., Saparov, A., Kim, N., and He, H. (2023).
\newblock Personas as a way to model truthfulness in language models.
\newblock {\em CoRR}, abs/2310.18168.

\bibitem[Kadavath et~al., 2022]{DBLP:journals/corr/abs-2207-05221}
Kadavath, S., Conerly, T., Askell, A., Henighan, T., Drain, D., Perez, E., Schiefer, N., Hatfield{-}Dodds, Z., DasSarma, N., Tran{-}Johnson, E., Johnston, S., Showk, S.~E., Jones, A., Elhage, N., Hume, T., Chen, A., Bai, Y., Bowman, S., Fort, S., Ganguli, D., Hernandez, D., Jacobson, J., Kernion, J., Kravec, S., Lovitt, L., Ndousse, K., Olsson, C., Ringer, S., Amodei, D., Brown, T., Clark, J., Joseph, N., Mann, B., McCandlish, S., Olah, C., and Kaplan, J. (2022).
\newblock Language models (mostly) know what they know.
\newblock {\em CoRR}, abs/2207.05221.

\bibitem[Kaddour et~al., 2023]{DBLP:journals/corr/abs-2307-10169}
Kaddour, J., Harris, J., Mozes, M., Bradley, H., Raileanu, R., and McHardy, R. (2023).
\newblock Challenges and applications of large language models.
\newblock {\em CoRR}, abs/2307.10169.

\bibitem[Kenton et~al., 2021]{DBLP:journals/corr/abs-2103-14659}
Kenton, Z., Everitt, T., Weidinger, L., Gabriel, I., Mikulik, V., and Irving, G. (2021).
\newblock Alignment of language agents.
\newblock {\em CoRR}, abs/2103.14659.

\bibitem[Kwiatkowski et~al., 2019]{DBLP:journals/tacl/KwiatkowskiPRCP19}
Kwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A.~P., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., Toutanova, K., Jones, L., Kelcey, M., Chang, M., Dai, A.~M., Uszkoreit, J., Le, Q., and Petrov, S. (2019).
\newblock Natural questions: a benchmark for question answering research.
\newblock {\em Trans. Assoc. Comput. Linguistics}, 7:452--466.

\bibitem[Lee et~al., 2022]{DBLP:conf/nips/LeePXPFSC22}
Lee, N., Ping, W., Xu, P., Patwary, M., Fung, P., Shoeybi, M., and Catanzaro, B. (2022).
\newblock Factuality enhanced language models for open-ended text generation.
\newblock In {\em NeurIPS}.

\bibitem[Li et~al., 2023a]{DBLP:journals/corr/abs-2310-05470}
Li, J., Sun, S., Yuan, W., Fan, R., Zhao, H., and Liu, P. (2023a).
\newblock Generative judge for evaluating alignment.
\newblock {\em CoRR}, abs/2310.05470.

\bibitem[Li et~al., 2023b]{DBLP:journals/corr/abs-2306-03341}
Li, K., Patel, O., Vi{\'{e}}gas, F.~B., Pfister, H., and Wattenberg, M. (2023b).
\newblock Inference-time intervention: Eliciting truthful answers from a language model.
\newblock {\em CoRR}, abs/2306.03341.

\bibitem[Li et~al., 2023c]{li2023self}
Li, X., Yu, P., Zhou, C., Schick, T., Zettlemoyer, L., Levy, O., Weston, J., and Lewis, M. (2023c).
\newblock Self-alignment with instruction backtranslation.
\newblock {\em arXiv preprint arXiv:2308.06259}.

\bibitem[Lin and Och, 2004]{DBLP:conf/acl/LinO04}
Lin, C. and Och, F.~J. (2004).
\newblock Automatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics.
\newblock In Scott, D., Daelemans, W., and Walker, M.~A., editors, {\em Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, 21-26 July, 2004, Barcelona, Spain}, pages 605--612. {ACL}.

\bibitem[Lin et~al., 2022a]{DBLP:journals/tmlr/LinHE22}
Lin, S., Hilton, J., and Evans, O. (2022a).
\newblock Teaching models to express their uncertainty in words.
\newblock {\em Trans. Mach. Learn. Res.}, 2022.

\bibitem[Lin et~al., 2022b]{DBLP:conf/acl/LinHE22}
Lin, S., Hilton, J., and Evans, O. (2022b).
\newblock Truthfulqa: Measuring how models mimic human falsehoods.
\newblock In Muresan, S., Nakov, P., and Villavicencio, A., editors, {\em Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), {ACL} 2022, Dublin, Ireland, May 22-27, 2022}, pages 3214--3252. Association for Computational Linguistics.

\bibitem[Lin et~al., 2024]{lin2024mitigating}
Lin, Y., Lin, H., Xiong, W., Diao, S., Liu, J., Zhang, J., Pan, R., Wang, H., Hu, W., Zhang, H., Dong, H., Pi, R., Zhao, H., Jiang, N., Ji, H., Yao, Y., and Zhang, T. (2024).
\newblock Mitigating the alignment tax of rlhf.

\bibitem[Liu et~al., 2023]{DBLP:journals/corr/abs-2308-05374}
Liu, Y., Yao, Y., Ton, J., Zhang, X., Guo, R., Cheng, H., Klochkov, Y., Taufiq, M.~F., and Li, H. (2023).
\newblock Trustworthy llms: a survey and guideline for evaluating large language models' alignment.
\newblock {\em CoRR}, abs/2308.05374.

\bibitem[Loshchilov and Hutter, 2019]{DBLP:conf/iclr/LoshchilovH19}
Loshchilov, I. and Hutter, F. (2019).
\newblock Decoupled weight decay regularization.
\newblock In {\em 7th International Conference on Learning Representations, {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019}. OpenReview.net.

\bibitem[Lv et~al., 2023]{DBLP:conf/emnlp/LvZGXHCL0GLSGYQ23}
Lv, K., Zhang, S., Gu, T., Xing, S., Hong, J., Chen, K., Liu, X., Yang, Y., Guo, H., Liu, T., Sun, Y., Guo, Q., Yan, H., and Qiu, X. (2023).
\newblock Collie: Collaborative training of large language models in an efficient way.
\newblock In Feng, Y. and Lefever, E., editors, {\em Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, {EMNLP} 2023 - System Demonstrations, Singapore, December 6-10, 2023}, pages 527--542. Association for Computational Linguistics.

\bibitem[Mahon, 2015]{Mahon2015TheDO}
Mahon, J.~E. (2015).
\newblock The definition of lying and deception.

\bibitem[Mallen et~al., 2023]{DBLP:conf/acl/MallenAZDKH23}
Mallen, A., Asai, A., Zhong, V., Das, R., Khashabi, D., and Hajishirzi, H. (2023).
\newblock When not to trust language models: Investigating effectiveness of parametric and non-parametric memories.
\newblock In Rogers, A., Boyd{-}Graber, J.~L., and Okazaki, N., editors, {\em Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), {ACL} 2023, Toronto, Canada, July 9-14, 2023}, pages 9802--9822. Association for Computational Linguistics.

\bibitem[Min et~al., 2023]{DBLP:journals/corr/abs-2305-14251}
Min, S., Krishna, K., Lyu, X., Lewis, M., Yih, W., Koh, P.~W., Iyyer, M., Zettlemoyer, L., and Hajishirzi, H. (2023).
\newblock Factscore: Fine-grained atomic evaluation of factual precision in long form text generation.
\newblock {\em CoRR}, abs/2305.14251.

\bibitem[Min et~al., 2020]{DBLP:conf/emnlp/MinMHZ20}
Min, S., Michael, J., Hajishirzi, H., and Zettlemoyer, L. (2020).
\newblock Ambigqa: Answering ambiguous open-domain questions.
\newblock In Webber, B., Cohn, T., He, Y., and Liu, Y., editors, {\em Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, {EMNLP} 2020, Online, November 16-20, 2020}, pages 5783--5797. Association for Computational Linguistics.

\bibitem[Nakano et~al., 2021]{DBLP:journals/corr/abs-2112-09332}
Nakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim, C., Hesse, C., Jain, S., Kosaraju, V., Saunders, W., Jiang, X., Cobbe, K., Eloundou, T., Krueger, G., Button, K., Knight, M., Chess, B., and Schulman, J. (2021).
\newblock Webgpt: Browser-assisted question-answering with human feedback.
\newblock {\em CoRR}, abs/2112.09332.

\bibitem[OpenAI, 2023a]{DBLP:journals/corr/abs-2303-08774}
OpenAI (2023a).
\newblock {GPT-4} technical report.
\newblock {\em CoRR}, abs/2303.08774.

\bibitem[OpenAI, 2023b]{chatgpt}
OpenAI (2023b).
\newblock Introducing chatgpt.

\bibitem[{OpenAI}, 2024]{gpt-4o}
{OpenAI} (2024).
\newblock Hello gpt-4o.

\bibitem[Ouyang et~al., 2022]{DBLP:conf/nips/Ouyang0JAWMZASR22}
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.~L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P.~F., Leike, J., and Lowe, R. (2022).
\newblock Training language models to follow instructions with human feedback.
\newblock In {\em NeurIPS}.

\bibitem[Pacchiardi et~al., 2023]{DBLP:journals/corr/abs-2309-15840}
Pacchiardi, L., Chan, A.~J., Mindermann, S., Moscovitz, I., Pan, A.~Y., Gal, Y., Evans, O., and Brauner, J. (2023).
\newblock How to catch an {AI} liar: Lie detection in black-box llms by asking unrelated questions.
\newblock {\em CoRR}, abs/2309.15840.

\bibitem[Park et~al., 2023]{DBLP:journals/corr/abs-2308-14752}
Park, P.~S., Goldstein, S., O'Gara, A., Chen, M., and Hendrycks, D. (2023).
\newblock {AI} deception: {A} survey of examples, risks, and potential solutions.
\newblock {\em CoRR}, abs/2308.14752.

\bibitem[Peng et~al., 2023]{DBLP:journals/corr/abs-2302-12813}
Peng, B., Galley, M., He, P., Cheng, H., Xie, Y., Hu, Y., Huang, Q., Liden, L., Yu, Z., Chen, W., and Gao, J. (2023).
\newblock Check your facts and try again: Improving large language models with external knowledge and automated feedback.
\newblock {\em CoRR}, abs/2302.12813.

\bibitem[Scheurer et~al., 2023]{DBLP:journals/corr/abs-2311-07590}
Scheurer, J., Balesni, M., and Hobbhahn, M. (2023).
\newblock Technical report: Large language models can strategically deceive their users when put under pressure.
\newblock {\em CoRR}, abs/2311.07590.

\bibitem[Schulman, 2023]{schulman}
Schulman, J. (2023).
\newblock Reinforcement learning from human feedback: Progress and challenges.

\bibitem[Sharma et~al., 2023]{DBLP:journals/corr/abs-2310-13548}
Sharma, M., Tong, M., Korbak, T., Duvenaud, D., Askell, A., Bowman, S.~R., Cheng, N., Durmus, E., Hatfield{-}Dodds, Z., Johnston, S.~R., Kravec, S., Maxwell, T., McCandlish, S., Ndousse, K., Rausch, O., Schiefer, N., Yan, D., Zhang, M., and Perez, E. (2023).
\newblock Towards understanding sycophancy in language models.
\newblock {\em CoRR}, abs/2310.13548.

\bibitem[Shumailov et~al., 2023]{DBLP:journals/corr/abs-2305-17493}
Shumailov, I., Shumaylov, Z., Zhao, Y., Gal, Y., Papernot, N., and Anderson, R.~J. (2023).
\newblock The curse of recursion: Training on generated data makes models forget.
\newblock {\em CoRR}, abs/2305.17493.

\bibitem[Taori et~al., 2023]{alpaca}
Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li, X., Guestrin, C., Liang, P., and Hashimoto, T.~B. (2023).
\newblock Stanford alpaca: An instruction-following llama model.
\newblock \url{https://github.com/tatsu-lab/stanford_alpaca}.

\bibitem[Tian et~al., 2023]{DBLP:journals/corr/abs-2305-14975}
Tian, K., Mitchell, E., Zhou, A., Sharma, A., Rafailov, R., Yao, H., Finn, C., and Manning, C.~D. (2023).
\newblock Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback.
\newblock {\em CoRR}, abs/2305.14975.

\bibitem[Touvron et~al., 2023]{DBLP:journals/corr/abs-2307-09288}
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Canton{-}Ferrer, C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn, A., Hosseini, S., Hou, R., Inan, H., Kardas, M., Kerkez, V., Khabsa, M., Kloumann, I., Korenev, A., Koura, P.~S., Lachaux, M., Lavril, T., Lee, J., Liskovich, D., Lu, Y., Mao, Y., Martinet, X., Mihaylov, T., Mishra, P., Molybog, I., Nie, Y., Poulton, A., Reizenstein, J., Rungta, R., Saladi, K., Schelten, A., Silva, R., Smith, E.~M., Subramanian, R., Tan, X.~E., Tang, B., Taylor, R., Williams, A., Kuan, J.~X., Xu, P., Yan, Z., Zarov, I., Zhang, Y., Fan, A., Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S., and Scialom, T. (2023).
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock {\em CoRR}, abs/2307.09288.

\bibitem[Wang et~al., 2023a]{DBLP:conf/iclr/0002WSLCNCZ23}
Wang, X., Wei, J., Schuurmans, D., Le, Q.~V., Chi, E.~H., Narang, S., Chowdhery, A., and Zhou, D. (2023a).
\newblock Self-consistency improves chain of thought reasoning in language models.
\newblock In {\em The Eleventh International Conference on Learning Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net.

\bibitem[Wang et~al., 2023b]{DBLP:conf/acl/WangKMLSKH23}
Wang, Y., Kordi, Y., Mishra, S., Liu, A., Smith, N.~A., Khashabi, D., and Hajishirzi, H. (2023b).
\newblock Self-instruct: Aligning language models with self-generated instructions.
\newblock In Rogers, A., Boyd{-}Graber, J.~L., and Okazaki, N., editors, {\em Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), {ACL} 2023, Toronto, Canada, July 9-14, 2023}, pages 13484--13508. Association for Computational Linguistics.

\bibitem[Wei et~al., 2023]{DBLP:journals/corr/abs-2308-03958}
Wei, J.~W., Huang, D., Lu, Y., Zhou, D., and Le, Q.~V. (2023).
\newblock Simple synthetic data reduces sycophancy in large language models.
\newblock {\em CoRR}, abs/2308.03958.

\bibitem[Xiong et~al., 2023]{DBLP:journals/corr/abs-2306-13063}
Xiong, M., Hu, Z., Lu, X., Li, Y., Fu, J., He, J., and Hooi, B. (2023).
\newblock Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms.
\newblock {\em CoRR}, abs/2306.13063.

\bibitem[Xu et~al., 2023]{DBLP:journals/corr/abs-2304-12244}
Xu, C., Sun, Q., Zheng, K., Geng, X., Zhao, P., Feng, J., Tao, C., and Jiang, D. (2023).
\newblock Wizardlm: Empowering large language models to follow complex instructions.
\newblock {\em CoRR}, abs/2304.12244.

\bibitem[Yin et~al., 2023]{DBLP:conf/acl/YinSGWQH23}
Yin, Z., Sun, Q., Guo, Q., Wu, J., Qiu, X., and Huang, X. (2023).
\newblock Do large language models know what they don't know?
\newblock In Rogers, A., Boyd{-}Graber, J.~L., and Okazaki, N., editors, {\em Findings of the Association for Computational Linguistics: {ACL} 2023, Toronto, Canada, July 9-14, 2023}, pages 8653--8665. Association for Computational Linguistics.

\bibitem[Yu et~al., 2023]{DBLP:journals/corr/abs-2305-14002}
Yu, W., Zhang, Z., Liang, Z., Jiang, M., and Sabharwal, A. (2023).
\newblock Improving language models via plug-and-play retrieval feedback.
\newblock {\em CoRR}, abs/2305.14002.

\bibitem[Yuan et~al., 2023]{DBLP:journals/corr/abs-2304-05302}
Yuan, Z., Yuan, H., Tan, C., Wang, W., Huang, S., and Huang, F. (2023).
\newblock {RRHF:} rank responses to align language models with human feedback without tears.
\newblock {\em CoRR}, abs/2304.05302.

\bibitem[Yudkowsky, 2018]{meta-honesty}
Yudkowsky, E. (2018).
\newblock Meta-honesty: Firming up honesty around its edge-cases.

\bibitem[Zhang et~al., 2023]{DBLP:journals/corr/abs-2309-01219}
Zhang, Y., Li, Y., Cui, L., Cai, D., Liu, L., Fu, T., Huang, X., Zhao, E., Zhang, Y., Chen, Y., Wang, L., Luu, A.~T., Bi, W., Shi, F., and Shi, S. (2023).
\newblock Siren's song in the {AI} ocean: {A} survey on hallucination in large language models.
\newblock {\em CoRR}, abs/2309.01219.

\bibitem[Zhang et~al., 2024]{zhang2024shieldlm}
Zhang, Z., Lu, Y., Ma, J., Zhang, D., Li, R., Ke, P., Sun, H., Sha, L., Sui, Z., Wang, H., and Huang, M. (2024).
\newblock Shieldlm: Empowering llms as aligned, customizable and explainable safety detectors.
\newblock {\em arXiv preprint}.

\bibitem[Zheng et~al., 2023a]{DBLP:journals/corr/abs-2306-05685}
Zheng, L., Chiang, W., Sheng, Y., Zhuang, S., Wu, Z., Zhuang, Y., Lin, Z., Li, Z., Li, D., Xing, E.~P., Zhang, H., Gonzalez, J.~E., and Stoica, I. (2023a).
\newblock Judging llm-as-a-judge with mt-bench and chatbot arena.
\newblock {\em CoRR}, abs/2306.05685.

\bibitem[Zheng et~al., 2023b]{zheng2023does}
Zheng, S., Huang, J., and Chang, K. C.-C. (2023b).
\newblock Why does chatgpt fall short in providing truthful answers?

\bibitem[Zhou et~al., 2023a]{DBLP:journals/corr/abs-2305-11206}
Zhou, C., Liu, P., Xu, P., Iyer, S., Sun, J., Mao, Y., Ma, X., Efrat, A., Yu, P., Yu, L., Zhang, S., Ghosh, G., Lewis, M., Zettlemoyer, L., and Levy, O. (2023a).
\newblock {LIMA:} less is more for alignment.
\newblock {\em CoRR}, abs/2305.11206.

\bibitem[Zhou et~al., 2023b]{DBLP:journals/corr/abs-2302-13439}
Zhou, K., Jurafsky, D., and Hashimoto, T. (2023b).
\newblock Navigating the grey area: Expressions of overconfidence and uncertainty in language models.
\newblock {\em CoRR}, abs/2302.13439.

\bibitem[Zhu and Li, 2023]{DBLP:journals/corr/abs-2309-14316}
Zhu, Z.~A. and Li, Y. (2023).
\newblock Physics of language models: Part 3.1, knowledge storage and extraction.
\newblock {\em CoRR}, abs/2309.14316.

\bibitem[Zou et~al., 2023]{DBLP:journals/corr/abs-2310-01405}
Zou, A., Phan, L., Chen, S., Campbell, J., Guo, P., Ren, R., Pan, A., Yin, X., Mazeika, M., Dombrowski, A., Goel, S., Li, N., Byun, M.~J., Wang, Z., Mallen, A., Basart, S., Koyejo, S., Song, D., Fredrikson, M., Kolter, J.~Z., and Hendrycks, D. (2023).
\newblock Representation engineering: {A} top-down approach to {AI} transparency.
\newblock {\em CoRR}, abs/2310.01405.

\end{thebibliography}
