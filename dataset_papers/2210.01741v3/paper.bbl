\begin{thebibliography}{68}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Almgren et~al.(1998)Almgren, Bell, Colella, Howell, and
  Welcome]{almgren_conservative_1998}
A.~S. Almgren, J.~B. Bell, P.~Colella, L.~H. Howell, and M.~L. Welcome.
\newblock A {Conservative} {Adaptive} {Projection} {Method} for the {Variable}
  {Density} {Incompressible} {Navier}–{Stokes} {Equations}.
\newblock \emph{Journal of Computational Physics}, 142\penalty0 (1):\penalty0
  1--46, May 1998.
\newblock ISSN 00219991.
\newblock \doi{10.1006/jcph.1998.5890}.
\newblock URL
  \url{https://linkinghub.elsevier.com/retrieve/pii/S0021999198958909}.

\bibitem[Amos and Kolter(2017)]{amos2017optnet}
B.~Amos and J.~Z. Kolter.
\newblock Optnet: Differentiable optimization as a layer in neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  136--145. PMLR, 2017.

\bibitem[Amos et~al.(2017)Amos, Xu, and Kolter]{amos2017input}
B.~Amos, L.~Xu, and J.~Z. Kolter.
\newblock Input convex neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  146--155. PMLR, 2017.

\bibitem[Andrychowicz et~al.(2016)Andrychowicz, Denil, Gomez, Hoffman, Pfau,
  Schaul, Shillingford, and De~Freitas]{andrychowicz2016learning}
M.~Andrychowicz, M.~Denil, S.~Gomez, M.~W. Hoffman, D.~Pfau, T.~Schaul,
  B.~Shillingford, and N.~De~Freitas.
\newblock Learning to learn by gradient descent by gradient descent.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
M.~Arjovsky, S.~Chintala, and L.~Bottou.
\newblock Wasserstein generative adversarial networks.
\newblock In \emph{International conference on machine learning}, pages
  214--223. PMLR, 2017.

\bibitem[Arvanitidis et~al.(2021)Arvanitidis, Hansen, and
  Hauberg]{arvanitidis_latent_2021}
G.~Arvanitidis, L.~K. Hansen, and S.~Hauberg.
\newblock Latent {Space} {Oddity}: on the {Curvature} of {Deep} {Generative}
  {Models}, Dec. 2021.
\newblock URL \url{http://arxiv.org/abs/1710.11379}.
\newblock Number: arXiv:1710.11379 arXiv:1710.11379 [stat].

\bibitem[Bai et~al.(2019)Bai, Kolter, and Koltun]{bai2019deep}
S.~Bai, J.~Z. Kolter, and V.~Koltun.
\newblock Deep equilibrium models.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Barbarosie(2011)]{barbarosie2011representation}
C.~Barbarosie.
\newblock Representation of divergence-free vector fields.
\newblock \emph{Quarterly of applied mathematics}, 69\penalty0 (2):\penalty0
  309--316, 2011.

\bibitem[Benamou and Brenier(2000)]{benamou2000computational}
J.-D. Benamou and Y.~Brenier.
\newblock A computational fluid mechanics solution to the monge-kantorovich
  mass transfer problem.
\newblock \emph{Numerische Mathematik}, 84\penalty0 (3):\penalty0 375--393,
  2000.

\bibitem[Berger(2003)]{berger2003panoramic}
M.~Berger.
\newblock A panoramic view of riemannian geometry.
\newblock 2003.

\bibitem[Bhatia et~al.(2013)Bhatia, Norgard, Pascucci, and
  Bremer]{Bhatia2013survey}
H.~Bhatia, G.~Norgard, V.~Pascucci, and P.-T. Bremer.
\newblock The helmholtz-hodge decomposition—a survey.
\newblock \emph{IEEE Transactions on Visualization and Computer Graphics},
  19\penalty0 (8):\penalty0 1386--1404, 2013.
\newblock \doi{10.1109/TVCG.2012.316}.

\bibitem[Bonneel et~al.(2011)Bonneel, Van De~Panne, Paris, and
  Heidrich]{bonneel2011displacement}
N.~Bonneel, M.~Van De~Panne, S.~Paris, and W.~Heidrich.
\newblock Displacement interpolation using lagrangian mass transport.
\newblock In \emph{Proceedings of the 2011 SIGGRAPH Asia conference}, pages
  1--12, 2011.

\bibitem[Bradbury et~al.(2018)Bradbury, Frostig, Hawkins, Johnson, Leary,
  Maclaurin, Necula, Paszke, Vander{P}las, Wanderman-{M}ilne, and
  Zhang]{jax2018github}
J.~Bradbury, R.~Frostig, P.~Hawkins, M.~J. Johnson, C.~Leary, D.~Maclaurin,
  G.~Necula, A.~Paszke, J.~Vander{P}las, S.~Wanderman-{M}ilne, and Q.~Zhang.
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs,
  2018.
\newblock URL \url{http://github.com/google/jax}.

\bibitem[Bronstein et~al.(2017)Bronstein, Bruna, LeCun, Szlam, and
  Vandergheynst]{bronstein2017geometric}
M.~M. Bronstein, J.~Bruna, Y.~LeCun, A.~Szlam, and P.~Vandergheynst.
\newblock Geometric deep learning: going beyond euclidean data.
\newblock \emph{IEEE Signal Processing Magazine}, 34\penalty0 (4):\penalty0
  18--42, 2017.

\bibitem[Cartan(1899)]{cartan1899some}
{\'E}.~Cartan.
\newblock On certain differential expressions and the pfaff problem.
\newblock In \emph{Scientific Annals of the {\'School}Normal Superior},
  volume~16, pages 239--332, 1899.

\bibitem[Che et~al.(2017)Che, Li, Jacob, Bengio, and Li]{che2016mode}
T.~Che, Y.~Li, A.~P. Jacob, Y.~Bengio, and W.~Li.
\newblock Mode regularized generative adversarial networks.
\newblock \emph{International Conference on Learning Representations}, 2017.

\bibitem[Chen(2018)]{torchdiffeq}
R.~T.~Q. Chen.
\newblock torchdiffeq, 2018.
\newblock URL \url{https://github.com/rtqichen/torchdiffeq}.

\bibitem[Chen and Duvenaud(2019)]{chen2019neural}
R.~T.~Q. Chen and D.~K. Duvenaud.
\newblock Neural networks with cheap differential operators.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and
  Duvenaud]{chen2018neural}
R.~T.~Q. Chen, Y.~Rubanova, J.~Bettencourt, and D.~K. Duvenaud.
\newblock Neural ordinary differential equations.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Chen et~al.(2019)Chen, Behrmann, Duvenaud, and
  Jacobsen]{chen2019residual}
R.~T.~Q. Chen, J.~Behrmann, D.~K. Duvenaud, and J.-H. Jacobsen.
\newblock Residual flows for invertible generative modeling.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Do~Carmo(1998)]{do1998differential}
M.~P. Do~Carmo.
\newblock \emph{Differential forms and applications}.
\newblock Springer Science \& Business Media, 1998.

\bibitem[Eisenberger et~al.(2018)Eisenberger, Lähner, and
  Cremers]{eisenberger_divergence-free_2018}
M.~Eisenberger, Z.~Lähner, and D.~Cremers.
\newblock Divergence-{Free} {Shape} {Interpolation} and {Correspondence}, Oct.
  2018.
\newblock URL \url{http://arxiv.org/abs/1806.10417}.
\newblock Number: arXiv:1806.10417 arXiv:1806.10417 [cs].

\bibitem[Feynman et~al.(1989)Feynman, Leighton, and Sands]{feynman_1989}
R.~Feynman, R.~Leighton, and M.~Sands.
\newblock \emph{The {Feynman} {Lectures} on {Physics}: {Commemorative}
  {Issue}}.
\newblock Advanced book program. Addison-Wesley, 1989.
\newblock ISBN 978-0-201-50064-6.
\newblock URL \url{https://books.google.ca/books?id=UHp1AQAACAAJ}.

\bibitem[Finlay et~al.(2020)Finlay, Jacobsen, Nurbekyan, and
  Oberman]{finlay2020train}
C.~Finlay, J.-H. Jacobsen, L.~Nurbekyan, and A.~M. Oberman.
\newblock How to train your neural ode.
\newblock \emph{arXiv preprint arXiv:2002.02798}, 2020.

\bibitem[Flamary et~al.(2021)Flamary, Courty, Gramfort, Alaya, Boisbunon,
  Chambon, Chapel, Corenflos, Fatras, Fournier, Gautheron, Gayraud, Janati,
  Rakotomamonjy, Redko, Rolet, Schutz, Seguy, Sutherland, Tavenard, Tong, and
  Vayer]{flamary2021pot}
R.~Flamary, N.~Courty, A.~Gramfort, M.~Z. Alaya, A.~Boisbunon, S.~Chambon,
  L.~Chapel, A.~Corenflos, K.~Fatras, N.~Fournier, L.~Gautheron, N.~T. Gayraud,
  H.~Janati, A.~Rakotomamonjy, I.~Redko, A.~Rolet, A.~Schutz, V.~Seguy, D.~J.
  Sutherland, R.~Tavenard, A.~Tong, and T.~Vayer.
\newblock Pot: Python optimal transport.
\newblock \emph{Journal of Machine Learning Research}, 22\penalty0
  (78):\penalty0 1--8, 2021.
\newblock URL \url{http://jmlr.org/papers/v22/20-451.html}.

\bibitem[Gerken et~al.(2021)Gerken, Aronsson, Carlsson, Linander, Ohlsson,
  Petersson, and Persson]{Gerken2021invariance}
J.~E. Gerken, J.~Aronsson, O.~Carlsson, H.~Linander, F.~Ohlsson, C.~Petersson,
  and D.~Persson.
\newblock Geometric deep learning and equivariant neural networks, 2021.
\newblock URL \url{https://arxiv.org/abs/2105.13926}.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, and
  Courville]{goodfellow2016deep}
I.~Goodfellow, Y.~Bengio, and A.~Courville.
\newblock \emph{Deep learning}.
\newblock MIT press, 2016.

\bibitem[Guermond and Quartapelle(2000)]{guermond_projection_2000}
J.-L. Guermond and L.~Quartapelle.
\newblock A {Projection} {FEM} for {Variable} {Density} {Incompressible}
  {Flows}.
\newblock \emph{Journal of Computational Physics}, 165\penalty0 (1):\penalty0
  167--188, Nov. 2000.
\newblock ISSN 00219991.
\newblock \doi{10.1006/jcph.2000.6609}.
\newblock URL
  \url{https://linkinghub.elsevier.com/retrieve/pii/S0021999100966099}.

\bibitem[Heek et~al.(2020)Heek, Levskaya, Oliver, Ritter, Rondepierre, Steiner,
  and van {Z}ee]{flax2020github}
J.~Heek, A.~Levskaya, A.~Oliver, M.~Ritter, B.~Rondepierre, A.~Steiner, and
  M.~van {Z}ee.
\newblock {F}lax: A neural network library and ecosystem for {JAX}, 2020.
\newblock URL \url{http://github.com/google/flax}.

\bibitem[Horace~He(2021)]{functorch2021}
R.~Z. Horace~He.
\newblock functorch: Jax-like composable function transforms for pytorch.
\newblock \url{https://github.com/pytorch/functorch}, 2021.

\bibitem[Hornik et~al.(1989)Hornik, Stinchcombe, and
  White]{hornik1989multilayer}
K.~Hornik, M.~Stinchcombe, and H.~White.
\newblock Multilayer feedforward networks are universal approximators.
\newblock \emph{Neural networks}, 2\penalty0 (5):\penalty0 359--366, 1989.

\bibitem[Huang et~al.(2020)Huang, Chen, Tsirigotis, and
  Courville]{huang2020convex}
C.-W. Huang, R.~T.~Q. Chen, C.~Tsirigotis, and A.~Courville.
\newblock Convex potential flows: Universal probability distributions with
  optimal transport and convex optimization.
\newblock \emph{arXiv preprint arXiv:2012.05942}, 2020.

\bibitem[Hunter(2007)]{hunter2007matplotlib}
J.~D. Hunter.
\newblock Matplotlib: A 2d graphics environment.
\newblock \emph{Computing in science \& engineering}, 9\penalty0 (3):\penalty0
  90, 2007.

\bibitem[Hurault et~al.(2022)Hurault, Leclaire, and
  Papadakis]{hurault2021gradient}
S.~Hurault, A.~Leclaire, and N.~Papadakis.
\newblock Gradient step denoiser for convergent plug-and-play.
\newblock \emph{International Conference on Learning Representations}, 2022.

\bibitem[Jagtap et~al.(2020)Jagtap, Kharazmi, and
  Karniadakis]{jagtap_conservative_2020}
A.~D. Jagtap, E.~Kharazmi, and G.~E. Karniadakis.
\newblock Conservative physics-informed neural networks on discrete domains for
  conservation laws: {Applications} to forward and inverse problems.
\newblock \emph{Computer Methods in Applied Mechanics and Engineering},
  365:\penalty0 113028, June 2020.
\newblock ISSN 00457825.
\newblock \doi{10.1016/j.cma.2020.113028}.
\newblock URL
  \url{https://linkinghub.elsevier.com/retrieve/pii/S0045782520302127}.

\bibitem[Jin et~al.(2021)Jin, Cai, Li, and Karniadakis]{jin_nsfnets_2021}
X.~Jin, S.~Cai, H.~Li, and G.~E. Karniadakis.
\newblock {NSFnets} ({Navier}-{Stokes} {Flow} nets): {Physics}-informed neural
  networks for the incompressible {Navier}-{Stokes} equations.
\newblock \emph{Journal of Computational Physics}, 426:\penalty0 109951, Feb.
  2021.
\newblock ISSN 00219991.
\newblock \doi{10.1016/j.jcp.2020.109951}.
\newblock URL \url{http://arxiv.org/abs/2003.06496}.
\newblock arXiv: 2003.06496.

\bibitem[Jones et~al.(2014)Jones, Oliphant, and Peterson]{jones2014scipy}
E.~Jones, T.~Oliphant, and P.~Peterson.
\newblock $\{$SciPy$\}$: Open source scientific tools for $\{$Python$\}$.
\newblock 2014.

\bibitem[Kelliher(2021)]{kelliher2021stream}
J.~Kelliher.
\newblock Stream functions for divergence-free vector fields.
\newblock \emph{Quarterly of Applied Mathematics}, 79\penalty0 (1):\penalty0
  163--174, 2021.

\bibitem[Kluyver et~al.(2016)Kluyver, Ragan-Kelley, P{\'{e}}rez, Granger,
  Bussonnier, Frederic, Kelley, Hamrick, Grout, Corlay,
  et~al.]{kluyver2016jupyter}
T.~Kluyver, B.~Ragan-Kelley, F.~P{\'{e}}rez, B.~E. Granger, M.~Bussonnier,
  J.~Frederic, K.~Kelley, J.~B. Hamrick, J.~Grout, S.~Corlay, et~al.
\newblock Jupyter notebooks-a publishing format for reproducible computational
  workflows.
\newblock In \emph{ELPUB}, pages 87--90, 2016.

\bibitem[Lagaris et~al.(1998)Lagaris, Likas, and
  Fotiadis]{lagaris1998artificial}
I.~E. Lagaris, A.~Likas, and D.~I. Fotiadis.
\newblock Artificial neural networks for solving ordinary and partial
  differential equations.
\newblock \emph{IEEE transactions on neural networks}, 9\penalty0 (5):\penalty0
  987--1000, 1998.

\bibitem[Li et~al.(2021)Li, Wei, Li, Yao, Zeng, and Lv]{li20213dmol}
C.~Li, W.~Wei, J.~Li, J.~Yao, X.~Zeng, and Z.~Lv.
\newblock 3dmol-net: learn 3d molecular representation using adaptive graph
  convolutional network based on rotation invariance.
\newblock \emph{IEEE Journal of Biomedical and Health Informatics}, 2021.

\bibitem[Lu et~al.(2021)Lu, Chen, Li, Wang, and Zhu]{lu2021implicit}
C.~Lu, J.~Chen, C.~Li, Q.~Wang, and J.~Zhu.
\newblock Implicit normalizing flows.
\newblock \emph{arXiv preprint arXiv:2103.09527}, 2021.

\bibitem[Makkuva et~al.(2020)Makkuva, Taghvaei, Oh, and
  Lee]{makkuva2020optimal}
A.~Makkuva, A.~Taghvaei, S.~Oh, and J.~Lee.
\newblock Optimal transport mapping via input convex neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  6672--6681. PMLR, 2020.

\bibitem[Mao et~al.(2020)Mao, Jagtap, and
  Karniadakis]{mao_physics-informed_2020}
Z.~Mao, A.~D. Jagtap, and G.~E. Karniadakis.
\newblock Physics-informed neural networks for high-speed flows.
\newblock \emph{Computer Methods in Applied Mechanics and Engineering},
  360:\penalty0 112789, Mar. 2020.
\newblock ISSN 00457825.
\newblock \doi{10.1016/j.cma.2019.112789}.
\newblock URL
  \url{https://linkinghub.elsevier.com/retrieve/pii/S0045782519306814}.

\bibitem[Miyato et~al.(2018)Miyato, Kataoka, Koyama, and
  Yoshida]{miyato2018spectral}
T.~Miyato, T.~Kataoka, M.~Koyama, and Y.~Yoshida.
\newblock Spectral normalization for generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1802.05957}, 2018.

\bibitem[Morita(2001)]{morita2001geometry}
S.~Morita.
\newblock \emph{Geometry of differential forms}.
\newblock Number 201. American Mathematical Soc., 2001.

\bibitem[Müller(2022)]{muller2022noetherconservation}
E.~H. Müller.
\newblock Exact conservation laws for neural network integrators of dynamical
  systems, 2022.
\newblock URL \url{https://arxiv.org/abs/2209.11661}.

\bibitem[Oliphant(2006)]{oliphant2006guide}
T.~E. Oliphant.
\newblock \emph{A guide to NumPy}, volume~1.
\newblock Trelgol Publishing USA, 2006.

\bibitem[Oliphant(2007)]{oliphant2007python}
T.~E. Oliphant.
\newblock Python for scientific computing.
\newblock \emph{Computing in Science \& Engineering}, 9\penalty0 (3):\penalty0
  10--20, 2007.

\bibitem[Onken et~al.(2021)Onken, Wu~Fung, Li, and Ruthotto]{onken2021ot}
D.~Onken, S.~Wu~Fung, X.~Li, and L.~Ruthotto.
\newblock Ot-flow: Fast and accurate continuous normalizing flows via optimal
  transport.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, 2021.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen,
  Z.~Lin, N.~Gimelshein, L.~Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Advances in neural information processing systems}, pages
  8026--8037, 2019.

\bibitem[Radford et~al.(2016)Radford, Metz, and
  Chintala]{radford2015unsupervised}
A.~Radford, L.~Metz, and S.~Chintala.
\newblock Unsupervised representation learning with deep convolutional
  generative adversarial networks.
\newblock \emph{International Conference on Learning Representations}, 2016.

\bibitem[Raissi et~al.(2017)Raissi, Perdikaris, and
  Karniadakis]{raissi_physics_2017}
M.~Raissi, P.~Perdikaris, and G.~E. Karniadakis.
\newblock Physics {Informed} {Deep} {Learning} ({Part} {I}): {Data}-driven
  {Solutions} of {Nonlinear} {Partial} {Differential} {Equations}, Nov. 2017.
\newblock URL \url{http://arxiv.org/abs/1711.10561}.
\newblock Number: arXiv:1711.10561 arXiv:1711.10561 [cs, math, stat].

\bibitem[Raissi et~al.(2019)Raissi, Perdikaris, and
  Karniadakis]{raissi_physics-informed_2019}
M.~Raissi, P.~Perdikaris, and G.~E. Karniadakis.
\newblock Physics-informed neural networks: {A} deep learning framework for
  solving forward and inverse problems involving nonlinear partial differential
  equations.
\newblock \emph{Journal of Computational Physics}, 378:\penalty0 686--707,
  2019.
\newblock ISSN 0021-9991.
\newblock \doi{https://doi.org/10.1016/j.jcp.2018.10.045}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S0021999118307125}.

\bibitem[Rao et~al.(2020)Rao, Sun, and Liu]{rao2020physics}
C.~Rao, H.~Sun, and Y.~Liu.
\newblock Physics-informed deep learning for incompressible laminar flows.
\newblock \emph{Theoretical and Applied Mechanics Letters}, 10\penalty0
  (3):\penalty0 207--212, 2020.

\bibitem[Rout et~al.(2021)Rout, Korotin, and Burnaev]{rout2021generative}
L.~Rout, A.~Korotin, and E.~Burnaev.
\newblock Generative modeling with optimal transport maps.
\newblock \emph{arXiv preprint arXiv:2110.02999}, 2021.

\bibitem[Rozen et~al.(2021)Rozen, Grover, Nickel, and Lipman]{rozen2021moser}
N.~Rozen, A.~Grover, M.~Nickel, and Y.~Lipman.
\newblock Moser flow: Divergence-based generative modeling on manifolds.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Salimans et~al.(2016)Salimans, Goodfellow, Zaremba, Cheung, Radford,
  and Chen]{salimans2016improved}
T.~Salimans, I.~Goodfellow, W.~Zaremba, V.~Cheung, A.~Radford, and X.~Chen.
\newblock Improved techniques for training gans.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Schroeder and Lube(2017)]{Schroeder_2017}
P.~W. Schroeder and G.~Lube.
\newblock Pressure-robust analysis of divergence-free and conforming {FEM} for
  evolutionary incompressible navier{\textendash}stokes flows.
\newblock \emph{Journal of Numerical Mathematics}, 25\penalty0 (4), dec 2017.
\newblock \doi{10.1515/jnma-2016-1101}.
\newblock URL \url{https://doi.org/10.1515%2Fjnma-2016-1101}.

\bibitem[Song and Ermon(2019)]{song2019generative}
Y.~Song and S.~Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Srivastava et~al.(2017)Srivastava, Valkov, Russell, Gutmann, and
  Sutton]{srivastava2017veegan}
A.~Srivastava, L.~Valkov, C.~Russell, M.~U. Gutmann, and C.~Sutton.
\newblock Veegan: Reducing mode collapse in gans using implicit variational
  learning.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Sturm and Wexler(2022)]{sturm2022discreteconservation}
P.~O. Sturm and A.~S. Wexler.
\newblock Conservation laws in a neural network architecture: enforcing the
  atom balance of a julia-based photochemical model (v0.2.0).
\newblock \emph{Geoscientific Model Development}, 15\penalty0 (8):\penalty0
  3417--3431, 2022.
\newblock \doi{10.5194/gmd-15-3417-2022}.
\newblock URL \url{https://gmd.copernicus.org/articles/15/3417/2022/}.

\bibitem[Tong et~al.(2020)Tong, Huang, Wolf, Van~Dijk, and
  Krishnaswamy]{tong2020trajectorynet}
A.~Tong, J.~Huang, G.~Wolf, D.~Van~Dijk, and S.~Krishnaswamy.
\newblock Trajectorynet: A dynamic optimal transport network for modeling
  cellular dynamics.
\newblock In \emph{International Conference on Machine Learning}, pages
  9526--9536. PMLR, 2020.

\bibitem[Van Der~Walt et~al.(2011)Van Der~Walt, Colbert, and
  Varoquaux]{van2011numpy}
S.~Van Der~Walt, S.~C. Colbert, and G.~Varoquaux.
\newblock The numpy array: a structure for efficient numerical computation.
\newblock \emph{Computing in Science \& Engineering}, 13\penalty0 (2):\penalty0
  22, 2011.

\bibitem[Van~Rossum and Drake~Jr(1995)]{van1995python}
G.~Van~Rossum and F.~L. Drake~Jr.
\newblock \emph{Python reference manual}.
\newblock Centrum voor Wiskunde en Informatica Amsterdam, 1995.

\bibitem[Warner(1983)]{warner1983foundations}
F.~Warner.
\newblock \emph{Foundations of Differentiable Manifolds and Lie Groups}.
\newblock Graduate Texts in Mathematics. Springer, 1983.
\newblock ISBN 9780387908946.
\newblock URL \url{https://books.google.ca/books?id=iaeUqc2yQVQC}.

\bibitem[Xue et~al.(2020)Xue, Beatson, Adriaenssens, and Adams]{xue20a}
T.~Xue, A.~Beatson, S.~Adriaenssens, and R.~Adams.
\newblock Amortized finite element analysis for fast {PDE}-constrained
  optimization.
\newblock In H.~D. III and A.~Singh, editors, \emph{Proceedings of the 37th
  International Conference on Machine Learning}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 10638--10647. PMLR,
  13--18 Jul 2020.

\bibitem[Yadan(2019)]{Yadan2019Hydra}
O.~Yadan.
\newblock Hydra - a framework for elegantly configuring complex applications.
\newblock Github, 2019.
\newblock URL \url{https://github.com/facebookresearch/hydra}.

\end{thebibliography}
