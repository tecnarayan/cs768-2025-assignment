\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Balduzzi(2016)]{balduzzi2016deep}
Balduzzi, D.
\newblock Deep online convex optimization with gated games.
\newblock \emph{arXiv preprint arXiv:1604.01952}, 2016.

\bibitem[Balduzzi et~al.(2018)Balduzzi, Racaniere, Martens, Foerster, Tuyls,
  and Graepel]{balduzzi2018mechanics}
Balduzzi, D., Racaniere, S., Martens, J., Foerster, J., Tuyls, K., and Graepel,
  T.
\newblock The mechanics of n-player differentiable games.
\newblock \emph{arXiv preprint arXiv:1802.05642}, 2018.

\bibitem[Bellman(1954)]{bellman1954theory}
Bellman, R.
\newblock The theory of dynamic programming.
\newblock Technical report, Rand corp santa monica ca, 1954.

\bibitem[Chang et~al.(2018)Chang, Meng, Haber, Ruthotto, Begert, and
  Holtham]{chang2018reversible}
Chang, B., Meng, L., Haber, E., Ruthotto, L., Begert, D., and Holtham, E.
\newblock Reversible architectures for arbitrarily deep residual neural
  networks.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and
  Duvenaud]{chen2018neural}
Chen, T.~Q., Rubanova, Y., Bettencourt, J., and Duvenaud, D.~K.
\newblock Neural ordinary differential equations.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6572--6583, 2018.

\bibitem[George et~al.(2018)George, Laurent, Bouthillier, Ballas, and
  Vincent]{george2018fast}
George, T., Laurent, C., Bouthillier, X., Ballas, N., and Vincent, P.
\newblock Fast approximate natural gradient descent in a kronecker factored
  eigenbasis.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  9550--9560, 2018.

\bibitem[Ghorbani \& Zou(2020)Ghorbani and Zou]{ghorbani2020neuron}
Ghorbani, A. and Zou, J.
\newblock Neuron shapley: Discovering the responsible neurons.
\newblock \emph{arXiv preprint arXiv:2002.09815}, 2020.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2672--2680, 2014.

\bibitem[Greydanus et~al.(2019)Greydanus, Dzamba, and
  Yosinski]{greydanus2019hamiltonian}
Greydanus, S., Dzamba, M., and Yosinski, J.
\newblock Hamiltonian neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  15353--15363, 2019.

\bibitem[Gunther et~al.(2020)Gunther, Ruthotto, Schroder, Cyr, and
  Gauger]{gunther2020layer}
Gunther, S., Ruthotto, L., Schroder, J.~B., Cyr, E.~C., and Gauger, N.~R.
\newblock Layer-parallel training of deep residual neural networks.
\newblock \emph{SIAM Journal on Mathematics of Data Science}, 2\penalty0
  (1):\penalty0 1--23, 2020.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Hinton et~al.(2012)Hinton, Srivastava, and Swersky]{hinton2012neural}
Hinton, G., Srivastava, N., and Swersky, K.
\newblock Neural networks for machine learning lecture 6a overview of
  mini-batch gradient descent.
\newblock 2012.

\bibitem[Hu et~al.(2019)Hu, Kazeykina, and Ren]{hu2019mean}
Hu, K., Kazeykina, A., and Ren, Z.
\newblock Mean-field langevin system, optimal control and deep neural networks.
\newblock \emph{arXiv preprint arXiv:1909.07278}, 2019.

\bibitem[Jaderberg et~al.(2016)Jaderberg, Mnih, Czarnecki, Schaul, Leibo,
  Silver, and Kavukcuoglu]{jaderberg2016reinforcement}
Jaderberg, M., Mnih, V., Czarnecki, W.~M., Schaul, T., Leibo, J.~Z., Silver,
  D., and Kavukcuoglu, K.
\newblock Reinforcement learning with unsupervised auxiliary tasks.
\newblock \emph{arXiv preprint arXiv:1611.05397}, 2016.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Li \& Hao(2018)Li and Hao]{li2018optimal}
Li, Q. and Hao, S.
\newblock An optimal control approach to deep learning and applications to
  discrete-weight neural networks.
\newblock \emph{arXiv preprint arXiv:1803.01299}, 2018.

\bibitem[Li et~al.(2017{\natexlab{a}})Li, Chen, Tai, and Weinan]{li2017maximum}
Li, Q., Chen, L., Tai, C., and Weinan, E.
\newblock Maximum principle based algorithms for deep learning.
\newblock \emph{The Journal of Machine Learning Research}, 18\penalty0
  (1):\penalty0 5998--6026, 2017{\natexlab{a}}.

\bibitem[Li et~al.(2017{\natexlab{b}})Li, Tai, and E]{li2017stochastic}
Li, Q., Tai, C., and E, W.
\newblock Stochastic modified equations and adaptive stochastic gradient
  algorithms.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  2101--2110. JMLR. org, 2017{\natexlab{b}}.

\bibitem[Liu \& Theodorou(2019)Liu and Theodorou]{liu2019deep}
Liu, G.-H. and Theodorou, E.~A.
\newblock Deep learning theory review: An optimal control and dynamical systems
  perspective.
\newblock \emph{arXiv preprint arXiv:1908.10920}, 2019.

\bibitem[Liu et~al.(2021)Liu, Chen, and Theodorou]{liu2021differential}
Liu, G.-H., Chen, T., and Theodorou, E.~A.
\newblock Ddpnopt: Differential dynamic programming neural optimizer.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Lu et~al.(2017)Lu, Zhong, Li, and Dong]{lu2017beyond}
Lu, Y., Zhong, A., Li, Q., and Dong, B.
\newblock Beyond finite layer neural networks: Bridging deep architectures and
  numerical differential equations.
\newblock \emph{arXiv preprint arXiv:1710.10121}, 2017.

\bibitem[Lu et~al.(2020)Lu, Ma, Lu, Lu, and Ying]{lu2020mean}
Lu, Y., Ma, C., Lu, Y., Lu, J., and Ying, L.
\newblock A mean-field analysis of deep resnet and beyond: Towards provable
  optimization via overparameterization from depth.
\newblock \emph{arXiv preprint arXiv:2003.05508}, 2020.

\bibitem[Martens \& Grosse(2015)Martens and Grosse]{martens2015optimizing}
Martens, J. and Grosse, R.
\newblock Optimizing neural networks with kronecker-factored approximate
  curvature.
\newblock In \emph{International conference on machine learning}, pp.\
  2408--2417, 2015.

\bibitem[Murray \& Yakowitz(1984)Murray and Yakowitz]{murray1984differential}
Murray, D. and Yakowitz, S.
\newblock Differential dynamic programming and newton's method for discrete
  optimal control problems.
\newblock \emph{Journal of Optimization Theory and Applications}, 43\penalty0
  (3):\penalty0 395--414, 1984.

\bibitem[Pan et~al.(2015)Pan, Theodorou, and Bakshi]{pan2015robust}
Pan, Y., Theodorou, E., and Bakshi, K.
\newblock Robust trajectory optimization: A cooperative stochastic game
  theoretic approach.
\newblock In \emph{Robotics: Science and Systems}, 2015.

\bibitem[Pantoja(1988)]{de1988differential}
Pantoja, J. F.~A.
\newblock Differential dynamic programming and newton's method.
\newblock \emph{International Journal of Control}, 47\penalty0 (5):\penalty0
  1539--1553, 1988.

\bibitem[Papyan(2019)]{papyan2019measurements}
Papyan, V.
\newblock Measurements of three-level hierarchical structure in the outliers in
  the spectrum of deepnet hessians.
\newblock \emph{arXiv preprint arXiv:1901.08244}, 2019.

\bibitem[Pardalos et~al.(2008)Pardalos, Migdalas, and
  Pitsoulis]{pardalos2008pareto}
Pardalos, P.~M., Migdalas, A., and Pitsoulis, L.
\newblock \emph{Pareto optimality, game theory and equilibria}, volume~17.
\newblock Springer Science \& Business Media, 2008.

\bibitem[Petrosjan(2005)]{petrosjan2005cooperative}
Petrosjan, L.~A.
\newblock Cooperative differential games.
\newblock In \emph{Advances in dynamic games}, pp.\  183--200. Springer, 2005.

\bibitem[Pontryagin et~al.(1962)Pontryagin, Mishchenko, Boltyanskii, and
  Gamkrelidze]{pontryagin1962mathematical}
Pontryagin, L.~S., Mishchenko, E., Boltyanskii, V., and Gamkrelidze, R.
\newblock The mathematical theory of optimal processes.
\newblock 1962.

\bibitem[Sagun et~al.(2017)Sagun, Evci, Guney, Dauphin, and
  Bottou]{sagun2017empirical}
Sagun, L., Evci, U., Guney, V.~U., Dauphin, Y., and Bottou, L.
\newblock Empirical analysis of the hessian of over-parametrized neural
  networks.
\newblock \emph{arXiv preprint arXiv:1706.04454}, 2017.

\bibitem[Seldin \& Slivkins(2014)Seldin and Slivkins]{seldin2014one}
Seldin, Y. and Slivkins, A.
\newblock One practical algorithm for both stochastic and adversarial bandits.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1287--1295. PMLR, 2014.

\bibitem[Stier et~al.(2018)Stier, Gianini, Granitzer, and
  Ziegler]{stier2018analysing}
Stier, J., Gianini, G., Granitzer, M., and Ziegler, K.
\newblock Analysing neural network topologies: a game theoretic approach.
\newblock \emph{Procedia Computer Science}, 126:\penalty0 234--243, 2018.

\bibitem[Sun et~al.(2018)Sun, Pan, Lim, Theodorou, and Tsiotras]{sun2018min}
Sun, W., Pan, Y., Lim, J., Theodorou, E.~A., and Tsiotras, P.
\newblock Min-max differential dynamic programming: Continuous and discrete
  time formulations.
\newblock \emph{Journal of Guidance, Control, and Dynamics}, 41\penalty0
  (12):\penalty0 2568--2580, 2018.

\bibitem[Tassa et~al.(2012)Tassa, Erez, and Todorov]{tassa2012synthesis}
Tassa, Y., Erez, T., and Todorov, E.
\newblock Synthesis and stabilization of complex behaviors through online
  trajectory optimization.
\newblock In \emph{2012 IEEE/RSJ International Conference on Intelligent Robots
  and Systems}, pp.\  4906--4913. IEEE, 2012.

\bibitem[Tassa et~al.(2014)Tassa, Mansard, and Todorov]{tassa2014control}
Tassa, Y., Mansard, N., and Todorov, E.
\newblock Control-limited differential dynamic programming.
\newblock In \emph{2014 IEEE International Conference on Robotics and
  Automation (ICRA)}, pp.\  1168--1175. IEEE, 2014.

\bibitem[Weinan(2017)]{weinan2017proposal}
Weinan, E.
\newblock A proposal on machine learning via dynamical systems.
\newblock \emph{Communications in Mathematics and Statistics}, 5\penalty0
  (1):\penalty0 1--11, 2017.

\bibitem[Weinan et~al.(2018)Weinan, Han, and Li]{han2018mean}
Weinan, E., Han, J., and Li, Q.
\newblock A mean-field optimal control formulation of deep learning.
\newblock \emph{arXiv preprint arXiv:1807.01083}, 2018.

\bibitem[Wu et~al.(2020)Wu, Zhu, Wu, Wang, and Ge]{wu2020dissecting}
Wu, Y., Zhu, X., Wu, C., Wang, A., and Ge, R.
\newblock Dissecting hessian: Understanding common structure of hessian in
  neural networks.
\newblock \emph{arXiv preprint arXiv:2010.04261}, 2020.

\bibitem[Yeung \& Petrosjan(2006)Yeung and Petrosjan]{yeung2006cooperative}
Yeung, D.~W. and Petrosjan, L.~A.
\newblock \emph{Cooperative stochastic differential games}.
\newblock Springer Science \& Business Media, 2006.

\bibitem[Zhang et~al.(2019)Zhang, Zhang, Lu, Zhu, and Dong]{zhang2019you}
Zhang, D., Zhang, T., Lu, Y., Zhu, Z., and Dong, B.
\newblock You only propagate once: Accelerating adversarial training via
  maximal principle.
\newblock \emph{arXiv preprint arXiv:1905.00877}, 2019.

\end{thebibliography}
