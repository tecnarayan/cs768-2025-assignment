@book{shafarevich2012linear,
  title={Linear algebra and geometry},
  author={Shafarevich, Igor R and Remizov, Alexey O},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{osband2013more,
  title={(More) efficient reinforcement learning via posterior sampling},
  author={Osband, Ian and Russo, Daniel and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  year={2013}
}

@article{strehl2008analysis,
  title={An analysis of model-based interval estimation for Markov decision processes},
  author={Strehl, Alexander L and Littman, Michael L},
  journal={Journal of Computer and System Sciences},
  volume={74},
  number={8},
  pages={1309--1331},
  year={2008},
  publisher={Elsevier}
}

@inproceedings{zhou2020neural,
  title={Neural contextual bandits with ucb-based exploration},
  author={Zhou, Dongruo and Li, Lihong and Gu, Quanquan},
  booktitle={International Conference on Machine Learning},
  pages={11492--11502},
  year={2020},
  organization={PMLR}
}

@article{dani2008stochastic,
  title={Stochastic linear optimization under bandit feedback},
  author={Dani, Varsha and Hayes, Thomas P and Kakade, Sham M},
  year={2008}
}

@article{auer2002finite,
  title={Finite-time analysis of the multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
  journal={Machine learning},
  volume={47},
  number={2},
  pages={235--256},
  year={2002},
  publisher={Springer}
}

@article{auer2002using,
  title={Using confidence bounds for exploitation-exploration trade-offs},
  author={Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Nov},
  pages={397--422},
  year={2002}
}

@article{bradtke1996linear,
  title={Linear least-squares algorithms for temporal difference learning},
  author={Bradtke, Steven J and Barto, Andrew G},
  journal={Machine learning},
  volume={22},
  number={1},
  pages={33--57},
  year={1996},
  publisher={Springer}
}


@inproceedings{oh2021multinomial,
  title={Multinomial logit contextual bandits: Provable optimality and practicality},
  author={Oh, Min-hwan and Iyengar, Garud},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={10},
  pages={9205--9213},
  year={2021}
}

@article{oh2019thompson,
  title={Thompson sampling for multinomial logit contextual bandits},
  author={Oh, Min-hwan and Iyengar, Garud},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{desir2014near,
  title={Near-optimal algorithms for capacity constrained assortment optimization},
  author={D{\'e}sir, Antoine and Goyal, Vineet and Zhang, Jiawei},
  journal={Available at SSRN},
  volume={2543309},
  year={2014},
  publisher={Working paper}
}

% 구글 스칼라 양식 \cite{저자20xx제목}
% 구글 스칼라 양식 \cite{저자20xx제목}

@article{russo2019worst,
  title={Worst-case regret bounds for exploration via randomized value functions},
  author={Russo, Daniel},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{agrawal2013further,
  title={Further optimal regret bounds for thompson sampling},
  author={Agrawal, Shipra and Goyal, Navin},
  booktitle={Artificial intelligence and statistics},
  pages={99--107},
  year={2013},
  organization={PMLR}
}

@inproceedings{zanette2020frequentist,
  title={Frequentist regret bounds for randomized least-squares value iteration},
  author={Zanette, Andrea and Brandfonbrener, David and Brunskill, Emma and Pirotta, Matteo and Lazaric, Alessandro},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1954--1964},
  year={2020},
  organization={PMLR}
}

@article{russac2020algorithms,
  title={Algorithms for non-stationary generalized linear bandits},
  author={Russac, Yoan and Capp{\'e}, Olivier and Garivier, Aur{\'e}lien},
  journal={arXiv preprint arXiv:2003.10113},
  year={2020}
}

@inproceedings{kveton2020randomized,
  title={Randomized exploration in generalized linear bandits},
  author={Kveton, Branislav and Zaheer, Manzil and Szepesvari, Csaba and Li, Lihong and Ghavamzadeh, Mohammad and Boutilier, Craig},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2066--2076},
  year={2020},
  organization={PMLR}
}

@article{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  journal={Advances in neural information processing systems},
  volume={24},
  pages={2312--2320},
  year={2011}
}

@inproceedings{li2017provably,
  title={Provably optimal algorithms for generalized linear contextual bandits},
  author={Li, Lihong and Lu, Yu and Zhou, Dengyong},
  booktitle={International Conference on Machine Learning},
  pages={2071--2080},
  year={2017},
  organization={PMLR}
}

% filippi2010parametric
@inproceedings{filippi2010parametric,
author = {Filippi, Sarah and Capp\'{e}, Olivier and Garivier, Aur\'{e}lien and Szepesv\'{a}ri, Csaba},
title = {Parametric Bandits: The Generalized Linear Case},
year = {2010},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 23rd International Conference on Neural Information Processing Systems - Volume 1},
pages = {586–594},
numpages = {9},
keywords = {parametric bandits, generalized linear models, regret minimization, multi-armed bandit, UCB},
location = {Vancouver, British Columbia, Canada},
series = {NIPS'10}
}

@InProceedings{abeille2017Linear,
  title = 	 {{Linear Thompson Sampling Revisited}},
  author = 	 {Abeille, Marc and Lazaric, Alessandro},
  booktitle = 	 {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {176--184},
  year = 	 {2017},
  editor = 	 {Singh, Aarti and Zhu, Jerry},
  volume = 	 {54},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {20--22 Apr},
  publisher =    {PMLR}
}


@inproceedings{yang2019sample,
  title={Sample-optimal parametric Q-learning using linearly additive features},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={6995--7004},
  year={2019},
  organization={PMLR}
}

@inproceedings{yang2020reinforcement,
  title={Reinforcement learning in feature space: Matrix bandit, kernels, and regret bound},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={10746--10756},
  year={2020},
  organization={PMLR}
}

@Article{freedman1975tail,
  title={On tail probabilities for martingales},
  author={Freedman, David A},
  journal={the Annals of Probability},
  pages={100--118},
  year={1975},
  publisher={JSTOR}
}


@inproceedings{ayoub2020model,
  title={Model-based reinforcement learning with value-targeted regression},
  author={Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin},
  booktitle={International Conference on Machine Learning},
  pages={463--474},
  year={2020},
  organization={PMLR}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}

@inproceedings{modi2020sample,
  title={Sample complexity of reinforcement learning using linearly combined model ensembles},
  author={Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2010--2020},
  year={2020},
  organization={PMLR}
}

@inproceedings{jiang2017contextual,
  title={Contextual decision processes with low Bellman rank are PAC-learnable},
  author={Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
  booktitle={International Conference on Machine Learning},
  pages={1704--1713},
  year={2017},
  organization={PMLR}
}


@inproceedings{wang2021glmRL,
  author    = {Yining Wang and
               Ruosong Wang and
               Simon Shaolei Du and
               Akshay Krishnamurthy},
  title     = {Optimism in Reinforcement Learning with Generalized Linear Function
               Approximation},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  year      = {2021},
}


@inproceedings{du2020is,
  author    = {Simon S. Du and
               Sham M. Kakade and
               Ruosong Wang and
               Lin F. Yang},
  title     = {Is a Good Representation Sufficient for Sample Efficient Reinforcement
               Learning?},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  year      = {2020},
}


@inproceedings{zhou2021provably,
  title={Provably efficient reinforcement learning for discounted mdps with feature mapping},
  author={Zhou, Dongruo and He, Jiafan and Gu, Quanquan},
  booktitle={International Conference on Machine Learning},
  pages={12793--12802},
  year={2021},
  organization={PMLR}
}

@inproceedings{he2021logarithmic,
  title={Logarithmic regret for reinforcement learning with linear function approximation},
  author={He, Jiafan and Zhou, Dongruo and Gu, Quanquan},
  booktitle={International Conference on Machine Learning},
  pages={4171--4180},
  year={2021},
  organization={PMLR}
}

@article{jaksch2010near,
  title={Near-optimal Regret Bounds for Reinforcement Learning.},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={4},
  year={2010}
}

@inproceedings{osband2014modelbased,
  author    = {Ian Osband and
               Benjamin Van Roy},
  title     = {Model-based Reinforcement Learning and the Eluder Dimension},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {1466--1474},
  year      = {2014},
}

@inproceedings{agrawal2017posterior,
  title={Posterior sampling for reinforcement learning: worst-case regret bounds},
  author={Agrawal, Shipra and Jia, Randy},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1184--1194},
  year={2017}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@inproceedings{dann2017unifying,
 author = {Dann, Christoph and Lattimore, Tor and Brunskill, Emma},
 booktitle = {Advances in Neural Information Processing Systems},
 pages     = {5713--5723},
 title = {Unifying PAC and Regret: Uniform PAC Bounds for Episodic Reinforcement Learning},
 volume = {30},
 year = {2017}
}

@inproceedings{jin2018qlearning,
 author = {Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {4868--4878},
 title = {Is Q-Learning Provably Efficient?},
 volume = {31},
 year = {2018}
}

@inproceedings{ouyang2017learning,
  author    = {Yi Ouyang and
               Mukul Gagrani and
               Ashutosh Nayyar and
               Rahul Jain},
  title     = {Learning Unknown Markov Decision Processes: {A} Thompson Sampling
               Approach},
  booktitle = {Advances in Neural Information Processing Systems},
  pages     = {1333--1342},
  year      = {2017},
}

@article{osband2019deep,
  title={Deep Exploration via Randomized Value Functions.},
  author={Osband, Ian and Van Roy, Benjamin and Russo, Daniel J and Wen, Zheng and others},
  journal={Journal of Machine Learning Research},
  volume={20},
  number={124},
  pages={1--62},
  year={2019}
}

@inproceedings{zhang2020almostoptimal,
 author = {Zhang, Zihan and Zhou, Yuan and Ji, Xiangyang},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {15198--15207},
 title = {Almost Optimal Model-Free Reinforcement Learningvia Reference-Advantage Decomposition},
 volume = {33},
 year = {2020}
}

@inproceedings{kearns1999finite,
  title={Finite-sample convergence rates for Q-learning and indirect algorithms},
  author={Kearns, Michael and Singh, Satinder},
  booktitle = {Advances in Neural Information Processing Systems},
  pages={996--1002},
  year={1999},
  volume = {13},
}

@book{kakade2003sample,
  title={On the sample complexity of reinforcement learning},
  author={Kakade, Sham Machandranath},
  year={2003},
  publisher={University of London, University College London (United Kingdom)}
}


@inproceedings{cai2020provably,
  title={Provably efficient exploration in policy optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={1283--1294},
  year={2020},
  organization={PMLR}
}

@inproceedings{weisz2021exponential,
  title={Exponential lower bounds for planning in mdps with linearly-realizable optimal action-value functions},
  author={Weisz, Gell{\'e}rt and Amortila, Philip and Szepesv{\'a}ri, Csaba},
  booktitle={Algorithmic Learning Theory},
  pages={1237--1264},
  year={2021},
  organization={PMLR}
}

@inproceedings{zhang2021modelfree,
  title={Model-free reinforcement learning: from clipped pseudo-regret to sample complexity},
  author={Zhang, Zihan and Zhou, Yuan and Ji, Xiangyang},
  booktitle={International Conference on Machine Learning},
  pages={12653--12662},
  year={2021},
  organization={PMLR}
}


@inproceedings{zhou2021nearly,
  title={Nearly minimax optimal reinforcement learning for linear mixture markov decision processes},
  author={Zhou, Dongruo and Gu, Quanquan and Szepesvari, Csaba},
  booktitle={Conference on Learning Theory},
  pages={4532--4576},
  year={2021},
  organization={PMLR}
}

@inproceedings{osband2016generalization,
  title={Generalization and exploration via randomized value functions},
  author={Osband, Ian and Van Roy, Benjamin and Wen, Zheng},
  booktitle={International Conference on Machine Learning},
  pages={2377--2386},
  year={2016},
  organization={PMLR}
}

@inproceedings{jia2020model,
  title={Model-based reinforcement learning with value-targeted regression},
  author={Jia, Zeyu and Yang, Lin and Szepesvari, Csaba and Wang, Mengdi},
  booktitle={Learning for Dynamics and Control},
  pages={666--686},
  year={2020},
  organization={PMLR}
}

@article{wang2020reinforcement_eluder,
  title={Reinforcement Learning with General Value Function Approximation: Provably Efficient Approach via Bounded Eluder Dimension},
  author={Wang, Ruosong and Salakhutdinov, Russ R and Yang, Lin},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}


@InProceedings{ishfaq2021randomized,
  title = 	 {Randomized Exploration in Reinforcement Learning with General Value Function Approximation},
  author =       {Ishfaq, Haque and Cui, Qiwen and Nguyen, Viet and Ayoub, Alex and Yang, Zhuoran and Wang, Zhaoran and Precup, Doina and Yang, Lin},
  booktitle = 	 {International Conference on Machine Learning},
  pages = 	 {4607--4616},
  year = 	 {2021},
  volume = 	 {139},
  publisher =    {PMLR},
}

@inproceedings{russo2013eluder,
  title={Eluder Dimension and the Sample Complexity of Optimistic Exploration.},
  author={Russo, Daniel and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2256--2264},
  year={2013},
}

@inproceedings{agrawal2013thompson,
  title={Thompson sampling for contextual bandits with linear payoffs},
  author={Agrawal, Shipra and Goyal, Navin},
  booktitle={International Conference on Machine Learning},
  pages={127--135},
  year={2013},
  organization={PMLR}
}


@inproceedings{chu2011contextual,
  title={Contextual bandits with linear payoff functions},
  author={Chu, Wei and Li, Lihong and Reyzin, Lev and Schapire, Robert},
  booktitle={Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages={208--214},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{oh2021sparsity,
  title={Sparsity-agnostic lasso bandit},
  author={Oh, Min-hwan and Iyengar, Garud and Zeevi, Assaf},
  booktitle={International Conference on Machine Learning},
  pages={8271--8280},
  year={2021},
  organization={PMLR}
}


@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{silver2018general,
  title={A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{kveton2020perturbed,
  title={Perturbed-History Exploration in Stochastic Linear Bandits},
  author={Kveton, Branislav and Szepesv{\'a}ri, Csaba and Ghavamzadeh, Mohammad and Boutilier, Craig},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={530--540},
  year={2020},
  organization={PMLR}
}

@article{krishnamurthy2016pac,
  title={PAC Reinforcement Learning with Rich Observations},
  author={Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  pages={1840--1848},
  year={2016}
}

@inproceedings{dann2018oracle,
 author = {Dann, Christoph and Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 title = {On Oracle-Efficient PAC RL with Rich Observations},
 volume = {31},
 year = {2018}
}

@inproceedings{du2019provably,
  title={Provably efficient RL with rich observations via latent state decoding},
  author={Du, Simon and Krishnamurthy, Akshay and Jiang, Nan and Agarwal, Alekh and Dudik, Miroslav and Langford, John},
  booktitle={International Conference on Machine Learning},
  pages={1665--1674},
  year={2019},
  organization={PMLR}
}

@inproceedings{jun2017glm,
 author = {Jun, Kwang-Sung and Bhargava, Aniruddha and Nowak, Robert and Willett, Rebecca},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 title = {Scalable Generalized Linear Bandits: Online Computation and Hashing},
 volume = {30},
 year = {2017}
}

@article{wen2020efficiency,
  title={On efficiency in hierarchical reinforcement learning},
  author={Wen, Zheng and Precup, Doina and Ibrahimi, Morteza and Barreto, Andre and Van Roy, Benjamin and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6708--6718},
  year={2020}
}

@inproceedings{pollard1990empirical,
  title={Empirical processes: theory and applications},
  author={Pollard, David},
  year={1990},
  organization={Ims}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@article{mcgovern2001automatic,
  title={Automatic discovery of subgoals in reinforcement learning using diverse density},
  author={McGovern, Amy and Barto, Andrew G},
  year={2001}
}

@inproceedings{stolle2002learning,
  title={Learning options in reinforcement learning},
  author={Stolle, Martin and Precup, Doina},
  booktitle={International Symposium on abstraction, reformulation, and approximation},
  pages={212--223},
  year={2002},
  organization={Springer}
}

@article{csimcsek2008skill,
  title={Skill characterization based on betweenness},
  author={{\c{S}}im{\c{s}}ek, {\"O}zg{\"u}r and Barto, Andrew},
  journal={Advances in neural information processing systems},
  volume={21},
  year={2008}
}

@article{solway2014optimal,
  title={Optimal behavioral hierarchy},
  author={Solway, Alec and Diuk, Carlos and C{\'o}rdova, Natalia and Yee, Debbie and Barto, Andrew G and Niv, Yael and Botvinick, Matthew M},
  journal={PLoS computational biology},
  volume={10},
  number={8},
  pages={e1003779},
  year={2014},
  publisher={Public Library of Science San Francisco, USA}
}

%% Regaring HRL %%
@inproceedings{dean1995decomposition,
  title={Decomposition techniques for planning in stochastic domains},
  author={Dean, Thomas and Lin, Shieu-Hong},
  booktitle={IJCAI},
  volume={2},
  pages={3},
  year={1995},
  organization={Citeseer}
}

@article{singh1997dynamically,
  title={How to dynamically merge Markov decision processes},
  author={Singh, Satinder and Cohn, David},
  journal={Advances in neural information processing systems},
  volume={10},
  year={1997}
}

@inproceedings{meuleau1998solving,
  title={Solving very large weakly coupled Markov decision processes},
  author={Meuleau, Nicolas and Hauskrecht, Milos and Kim, Kee-Eung and Peshkin, Leonid and Kaelbling, Leslie Pack and Dean, Thomas L and Boutilier, Craig},
  booktitle={AAAI/IAAI},
  pages={165--172},
  year={1998}
}
@article{barto2003recent,
  title={Recent advances in hierarchical reinforcement learning},
  author={Barto, Andrew G and Mahadevan, Sridhar},
  journal={Discrete event dynamic systems},
  volume={13},
  number={1},
  pages={41--77},
  year={2003},
  publisher={Springer}
}

@article{fruit2017regret,
  title={Regret minimization in mdps with options without prior knowledge},
  author={Fruit, Ronan and Pirotta, Matteo and Lazaric, Alessandro and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{mann2015approximate,
  title={Approximate value iteration with temporally extended actions},
  author={Mann, Timothy A and Mannor, Shie and Precup, Doina},
  journal={Journal of Artificial Intelligence Research},
  volume={53},
  pages={375--438},
  year={2015}
}


%%% HRL empirical studies %%%
@article{jaderberg2019human,
  title={Human-level performance in 3D multiplayer games with population-based reinforcement learning},
  author={Jaderberg, Max and Czarnecki, Wojciech M and Dunning, Iain and Marris, Luke and Lever, Guy and Castaneda, Antonio Garcia and Beattie, Charles and Rabinowitz, Neil C and Morcos, Ari S and Ruderman, Avraham and others},
  journal={Science},
  volume={364},
  number={6443},
  pages={859--865},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@article{kulkarni2016hierarchical,
  title={Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation},
  author={Kulkarni, Tejas D and Narasimhan, Karthik and Saeedi, Ardavan and Tenenbaum, Josh},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{pertsch2020long,
  title={Long-horizon visual planning with goal-conditioned hierarchical predictors},
  author={Pertsch, Karl and Rybkin, Oleh and Ebert, Frederik and Zhou, Shenghao and Jayaraman, Dinesh and Finn, Chelsea and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17321--17333},
  year={2020}
}

@article{levy2017learning,
  title={Learning multi-level hierarchies with hindsight},
  author={Levy, Andrew and Konidaris, George and Platt, Robert and Saenko, Kate},
  journal={arXiv preprint arXiv:1712.00948},
  year={2017}
}

@article{hwang2022model,
  title={Model-Based Reinforcement Learning with Multinomial Logistic Function Approximation},
  author={Hwang, Taehyun and Oh, Min-hwan},
  journal={arXiv preprint arXiv:2212.13540},
  year={2022}
}

@article{chapelle2011empirical,
  title={An empirical evaluation of thompson sampling},
  author={Chapelle, Olivier and Li, Lihong},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@article{thompson1933likelihood,
  title={On the likelihood that one unknown probability exceeds another in view of the evidence of two samples},
  author={Thompson, William R},
  journal={Biometrika},
  volume={25},
  number={3-4},
  pages={285--294},
  year={1933},
  publisher={Oxford University Press}
}

@article{zhang2021reward,
  title={Reward-free model-based reinforcement learning with linear function approximation},
  author={Zhang, Weitong and Zhou, Dongruo and Gu, Quanquan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1582--1593},
  year={2021}
}

% State Abstraction
@article{singh1994reinforcement,
  title={Reinforcement learning with soft state aggregation},
  author={Singh, Satinder and Jaakkola, Tommi and Jordan, Michael},
  journal={Advances in neural information processing systems},
  volume={7},
  year={1994}
}

@inproceedings{li2006towards,
  title={Towards a unified theory of state abstraction for MDPs.},
  author={Li, Lihong and Walsh, Thomas J and Littman, Michael L},
  booktitle={AI\&M},
  year={2006}
}

@article{wen2017efficient,
  title={Efficient reinforcement learning in deterministic systems with value function generalization},
  author={Wen, Zheng and Van Roy, Benjamin},
  journal={Mathematics of Operations Research},
  volume={42},
  number={3},
  pages={762--782},
  year={2017},
  publisher={INFORMS}
}

@article{dong2019provably,
  title={Provably efficient reinforcement learning with aggregated states},
  author={Dong, Shi and Van Roy, Benjamin and Zhou, Zhengyuan},
  journal={arXiv preprint arXiv:1912.06366},
  year={2019}
}

@article{van2006performance,
  title={Performance loss bounds for approximate value iteration with state aggregation},
  author={Van Roy, Benjamin},
  journal={Mathematics of Operations Research},
  volume={31},
  number={2},
  pages={234--244},
  year={2006},
  publisher={INFORMS}
}

@inproceedings{abel2020value,
  title={Value preserving state-action abstractions},
  author={Abel, David and Umbanhowar, Nate and Khetarpal, Khimya and Arumugam, Dilip and Precup, Doina and Littman, Michael},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1639--1650},
  year={2020},
  organization={PMLR}
}

@article{fox1973discretizing,
  title={Discretizing dynamic programs},
  author={Fox, Bennett L},
  journal={Journal of Optimization Theory and Applications},
  volume={11},
  pages={228--234},
  year={1973},
  publisher={Springer}
}

@article{whitt1978approximations,
  title={Approximations of dynamic programs, I},
  author={Whitt, Ward},
  journal={Mathematics of Operations Research},
  volume={3},
  number={3},
  pages={231--243},
  year={1978},
  publisher={INFORMS}
}

@article{bean1987aggregation,
  title={Aggregation in dynamic programming},
  author={Bean, James C and Birge, John R and Smith, Robert L},
  journal={Operations Research},
  volume={35},
  number={2},
  pages={215--220},
  year={1987},
  publisher={INFORMS}
}

@article{bertsekas1988adaptive,
  title={Adaptive aggregation methods for infinite horizon dynamic programming},
  author={Bertsekas, Dimitri P and Castanon, David A and others},
  year={1988},
  publisher={Dept. of Electrical Engineering and Computer Science, Laboratory for~…}
}

@inproceedings{dean1997model,
  title={Model minimization in Markov decision processes},
  author={Dean, Thomas and Givan, Robert},
  booktitle={AAAI/IAAI},
  pages={106--111},
  year={1997}
}

% Deep RL
% Chain MDP
@article{osband2016deep,
  title={Deep exploration via bootstrapped DQN},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

% General
@inproceedings{dong2020root,
  title={Root-n-regret for learning in markov decision processes with function approximation and low bellman rank},
  author={Dong, Kefan and Peng, Jian and Wang, Yining and Zhou, Yuan},
  booktitle={Conference on Learning Theory},
  pages={1554--1557},
  year={2020},
  organization={PMLR}
}

@inproceedings{sun2019model,
  title={Model-based rl in contextual decision processes: Pac bounds and exponential improvements over model-free approaches},
  author={Sun, Wen and Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  booktitle={Conference on learning theory},
  pages={2898--2933},
  year={2019},
  organization={PMLR}
}

@article{jin2021bellman,
  title={Bellman eluder dimension: New rich classes of rl problems, and sample-efficient algorithms},
  author={Jin, Chi and Liu, Qinghua and Miryoosefi, Sobhan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13406--13418},
  year={2021}
}

@inproceedings{du2021bilinear,
  title={Bilinear classes: A structural framework for provable generalization in rl},
  author={Du, Simon and Kakade, Sham and Lee, Jason and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={2826--2836},
  year={2021},
  organization={PMLR}
}

@article{foster2021statistical,
  title={The statistical complexity of interactive decision making},
  author={Foster, Dylan J and Kakade, Sham M and Qian, Jian and Rakhlin, Alexander},
  journal={arXiv preprint arXiv:2112.13487},
  year={2021}
}

@article{chen2022general,
  title={A General Framework for Sample-Efficient Function Approximation in Reinforcement Learning},
  author={Chen, Zixiang and Li, Chris Junchi and Yuan, Angela and Gu, Quanquan and Jordan, Michael I},
  journal={arXiv preprint arXiv:2209.15634},
  year={2022}
}

@inproceedings{hu2022nearly,
  title={Nearly minimax optimal reinforcement learning with linear function approximation},
  author={Hu, Pihe and Chen, Yu and Huang, Longbo},
  booktitle={International Conference on Machine Learning},
  pages={8971--9019},
  year={2022},
  organization={PMLR}
}

% MNL
@article{mcfadden1977modelling,
  title={Modelling the choice of residential location},
  author={McFadden, Daniel},
  year={1977}
}

@article{agrawal2019mnl,
  title={Mnl-bandit: A dynamic learning approach to assortment selection},
  author={Agrawal, Shipra and Avadhanula, Vashist and Goyal, Vineet and Zeevi, Assaf},
  journal={Operations Research},
  volume={67},
  number={5},
  pages={1453--1485},
  year={2019},
  publisher={INFORMS}
}

@article{chen2020dynamic,
  title={Dynamic assortment optimization with changing contextual information},
  author={Chen, Xi and Wang, Yining and Zhou, Yuan},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={8918--8961},
  year={2020},
  publisher={JMLRORG}
}

@article{chen2018note,
  title={A note on a tight lower bound for capacitated MNL-bandit assortment selection models},
  author={Chen, Xi and Wang, Yining},
  journal={Operations Research Letters},
  volume={46},
  number={5},
  pages={534--537},
  year={2018},
  publisher={Elsevier}
}


@article{perivier2022dynamic,
  title={Dynamic pricing and assortment under a contextual MNL demand},
  author={Perivier, Noemie and Goyal, Vineet},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={3461--3474},
  year={2022}
}

@article{agrawal2023tractable,
  title={A tractable online learning algorithm for the multinomial logit contextual bandit},
  author={Agrawal, Priyank and Tulabandhula, Theja and Avadhanula, Vashist},
  journal={European Journal of Operational Research},
  volume={310},
  number={2},
  pages={737--750},
  year={2023},
  publisher={Elsevier}
}

@article{zhang2024online,
  title={Online (Multinomial) Logistic Bandit: Improved Regret and Constant Computation Cost},
  author={Zhang, Yu-Jie and Sugiyama, Masashi},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{tran2015composite,
  title={Composite convex minimization involving self-concordant-like cost functions},
  author={Tran-Dinh, Quoc and Li, Yen-Huan and Cevher, Volkan},
  booktitle={Modelling, Computation and Optimization in Information Systems and Management Sciences: Proceedings of the 3rd International Conference on Modelling, Computation and Optimization in Information Systems and Management Sciences-MCO 2015-Part I},
  pages={155--168},
  year={2015},
  organization={Springer}
}

@article{orabona2019modern,
  title={A modern introduction to online learning},
  author={Orabona, Francesco},
  journal={arXiv preprint arXiv:1912.13213},
  year={2019}
}

@inproceedings{mhammedi2019lipschitz,
  title={Lipschitz adaptivity with multiple learning rates in online learning},
  author={Mhammedi, Zakaria and Koolen, Wouter M and Van Erven, Tim},
  booktitle={Conference on Learning Theory},
  pages={2490--2511},
  year={2019},
  organization={PMLR}
}

@article{campolongo2020temporal,
  title={Temporal variability in implicit online learning},
  author={Campolongo, Nicolo and Orabona, Francesco},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={12377--12387},
  year={2020}
}

@inproceedings{faury2022jointly,
  title={Jointly efficient and optimal algorithms for logistic bandits},
  author={Faury, Louis and Abeille, Marc and Jun, Kwang-Sung and Calauz{\`e}nes, Cl{\'e}ment},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={546--580},
  year={2022},
  organization={PMLR}
}

@inproceedings{faury2020improved,
  title={Improved optimistic algorithms for logistic bandits},
  author={Faury, Louis and Abeille, Marc and Calauz{\`e}nes, Cl{\'e}ment and Fercoq, Olivier},
  booktitle={International Conference on Machine Learning},
  pages={3052--3060},
  year={2020},
  organization={PMLR}
}

@inproceedings{foster2018logistic,
  title={Logistic regression: The importance of being improper},
  author={Foster, Dylan J and Kale, Satyen and Luo, Haipeng and Mohri, Mehryar and Sridharan, Karthik},
  booktitle={Conference on learning theory},
  pages={167--208},
  year={2018},
  organization={PMLR}
}

@article{hazan2016introduction,
  title={Introduction to online convex optimization},
  author={Hazan, Elad and others},
  journal={Foundations and Trends{\textregistered} in Optimization},
  volume={2},
  number={3-4},
  pages={157--325},
  year={2016},
  publisher={Now Publishers, Inc.}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@article{rusmevichientong2010dynamic,
  title={Dynamic assortment optimization with a multinomial logit choice model and capacity constraint},
  author={Rusmevichientong, Paat and Shen, Zuo-Jun Max and Shmoys, David B},
  journal={Operations research},
  volume={58},
  number={6},
  pages={1666--1680},
  year={2010},
  publisher={INFORMS}
}

@article{davis2014assortment,
  title={Assortment optimization under variants of the nested logit model},
  author={Davis, James M and Gallego, Guillermo and Topaloglu, Huseyin},
  journal={Operations Research},
  volume={62},
  number={2},
  pages={250--273},
  year={2014},
  publisher={INFORMS}
}

@inproceedings{abeille2021instance,
  title={Instance-wise minimax-optimal algorithms for logistic bandits},
  author={Abeille, Marc and Faury, Louis and Calauz{\`e}nes, Cl{\'e}ment},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3691--3699},
  year={2021},
  organization={PMLR}
}

@article{saure2013optimal,
  title={Optimal dynamic assortment planning with demand learning},
  author={Saur{\'e}, Denis and Zeevi, Assaf},
  journal={Manufacturing \& Service Operations Management},
  volume={15},
  number={3},
  pages={387--404},
  year={2013},
  publisher={INFORMS}
}

@inproceedings{agrawal2017thompson,
  title={Thompson sampling for the mnl-bandit},
  author={Agrawal, Shipra and Avadhanula, Vashist and Goyal, Vineet and Zeevi, Assaf},
  booktitle={Conference on learning theory},
  pages={76--78},
  year={2017},
  organization={PMLR}
}

@inproceedings{ou2018multinomial,
  title     = {Multinomial Logit Bandit with Linear Utility Functions},
  author    = {Mingdong Ou and Nan Li and Shenghuo Zhu and Rong Jin},
  booktitle = {Proceedings of the Twenty-Seventh International Joint Conference on
               Artificial Intelligence, {IJCAI-18}},
  year={2018},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  pages     = {2602--2608},
}


@article{zhang2024contextual,
  title={Contextual Multinomial Logit Bandits with General Value Functions},
  author={Zhang, Mengxiao and Luo, Haipeng},
  journal={arXiv preprint arXiv:2402.08126},
  year={2024}
}

@article{miao2021dynamic,
  title={Dynamic joint assortment and pricing optimization with demand learning},
  author={Miao, Sentao and Chao, Xiuli},
  journal={Manufacturing \& Service Operations Management},
  volume={23},
  number={2},
  pages={525--545},
  year={2021},
  publisher={INFORMS}
}

@article{chen2021optimal,
  title={Optimal policy for dynamic assortment planning under multinomial logit models},
  author={Chen, Xi and Wang, Yining and Zhou, Yuan},
  journal={Mathematics of Operations Research},
  volume={46},
  number={4},
  pages={1639--1657},
  year={2021},
  publisher={INFORMS}
}

@article{caro2007dynamic,
  title={Dynamic assortment with demand learning for seasonal consumer goods},
  author={Caro, Felipe and Gallien, J{\'e}r{\'e}mie},
  journal={Management science},
  volume={53},
  number={2},
  pages={276--292},
  year={2007},
  publisher={INFORMS}
}

@article{aouad2018greedy,
  title={Greedy-like algorithms for dynamic assortment planning under multinomial logit preferences},
  author={Aouad, Ali and Levi, Retsef and Segev, Danny},
  journal={Operations Research},
  volume={66},
  number={5},
  pages={1321--1345},
  year={2018},
  publisher={INFORMS}
}

@inproceedings{abe1999associative,
  title={Associative reinforcement learning using linear probabilistic concepts},
  author={Abe, Naoki and Long, Philip M},
  booktitle={ICML},
  pages={3--11},
  year={1999},
  organization={Citeseer}
}

@article{amani2021ucb,
  title={Ucb-based algorithms for multinomial logistic regression bandits},
  author={Amani, Sanae and Thrampoulidis, Christos},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={2913--2924},
  year={2021}
}

@article{cheung2017thompson,
  title={Thompson sampling for online personalized assortment optimization problems with multinomial logit choice models},
  author={Cheung, Wang Chi and Simchi-Levi, David},
  journal={Available at SSRN 3075658},
  year={2017}
}

@inproceedings{lee2024improved,
  title={Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion},
  author={Lee, Junghyun and Yun, Se-Young and Jun, Kwang-Sung},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4474--4482},
  year={2024},
  organization={PMLR}
}

@inproceedings{zhang2016online,
  title={Online stochastic linear optimization under one-bit feedback},
  author={Zhang, Lijun and Yang, Tianbao and Jin, Rong and Xiao, Yichi and Zhou, Zhi-Hua},
  booktitle={International Conference on Machine Learning},
  pages={392--401},
  year={2016},
  organization={PMLR}
}

@article{jun2017scalable,
  title={Scalable generalized linear bandits: Online computation and hashing},
  author={Jun, Kwang-Sung and Bhargava, Aniruddha and Nowak, Robert and Willett, Rebecca},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{kim2023double,
  title={Double doubly robust thompson sampling for generalized linear contextual bandits},
  author={Kim, Wonyoung and Lee, Kyungbok and Paik, Myunghee Cho},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={7},
  pages={8300--8307},
  year={2023}
}

@article{kazerouni2021best,
  title={Best arm identification in generalized linear bandits},
  author={Kazerouni, Abbas and Wein, Lawrence M},
  journal={Operations Research Letters},
  volume={49},
  number={3},
  pages={365--371},
  year={2021},
  publisher={Elsevier}
}

@article{rejwan2019combinatorial,
  title={Combinatorial bandits with full-bandit feedback: Sample complexity and regret minimization},
  author={Rejwan, Idan and Mansour, Yishay},
  journal={arXiv preprint arXiv:1905.12624},
  year={2019}
}


@InProceedings{pmlr-v117-rejwan20a,
  title = 	 {Top-$k$ Combinatorial Bandits with Full-Bandit Feedback},
  author =       {Rejwan, Idan and Mansour, Yishay},
  booktitle = 	 {Proceedings of the 31st International Conference  on Algorithmic Learning Theory},
  pages = 	 {752--776},
  year = 	 {2020},
  editor = 	 {Kontorovich, Aryeh and Neu, Gergely},
  volume = 	 {117},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {08 Feb--11 Feb},
  publisher =    {PMLR},
}


@inproceedings{chen2013combinatorial,
  title={Combinatorial multi-armed bandit: General framework and applications},
  author={Chen, Wei and Wang, Yajun and Yuan, Yang},
  booktitle={International conference on machine learning},
  pages={151--159},
  year={2013},
  organization={PMLR}
}

@inproceedings{kveton2015tight,
  title={Tight regret bounds for stochastic combinatorial semi-bandits},
  author={Kveton, Branislav and Wen, Zheng and Ashkan, Azin and Szepesvari, Csaba},
  booktitle={Artificial Intelligence and Statistics},
  pages={535--543},
  year={2015},
  organization={PMLR}
}

@inproceedings{qin2014contextual,
  title={Contextual combinatorial bandit and its application on diversified online recommendation},
  author={Qin, Lijing and Chen, Shouyuan and Zhu, Xiaoyan},
  booktitle={Proceedings of the 2014 SIAM International Conference on Data Mining},
  pages={461--469},
  year={2014},
  organization={SIAM}
}

@inproceedings{liu2023contextual,
  title={Contextual combinatorial bandits with probabilistically triggered arms},
  author={Liu, Xutong and Zuo, Jinhang and Wang, Siwei and Lui, John CS and Hajiesmaili, Mohammad and Wierman, Adam and Chen, Wei},
  booktitle={International Conference on Machine Learning},
  pages={22559--22593},
  year={2023},
  organization={PMLR}
}

@inproceedings{zong2016cascading,
author = {Zong, Shi and Ni, Hao and Sung, Kenny and Ke, Nan Rosemary and Wen, Zheng and Kveton, Branislav},
title = {Cascading bandits for large-scale recommendation problems},
year = {2016},
publisher = {AUAI Press},
booktitle = {Proceedings of the Thirty-Second Conference on Uncertainty in Artificial Intelligence},
pages = {835–844},
}

@article{lee2024unified,
  title={A Unified Confidence Sequence for Generalized Linear Models, with Applications to Bandits},
  author={Lee, Junghyun and Yun, Se-Young and Jun, Kwang-Sung},
  journal={arXiv preprint arXiv:2407.13977},
  year={2024}
}

@book{tsybakov2008nonparametric,
  title={Introduction to Nonparametric Estimation},
  author={Alexandre B Tsybakov},
  year={2008},
  publisher={Springer Science \& Business Media},
  doi={https://doi.org/10.1007/b13794},
}

@article{choi2024cascading,
  title={Cascading Contextual Assortment Bandits},
  author={Choi, Hyun-jun and Udwani, Rajan and Oh, Min-hwan},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{cao2024tiered,
  title={Tiered Assortment: Optimization and Online Learning},
  author={Cao, Junyu and Sun, Wei},
  journal={Management Science},
  volume={70},
  number={8},
  pages={5481--5501},
  year={2024},
  publisher={INFORMS}
}

