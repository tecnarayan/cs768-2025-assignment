\begin{thebibliography}{10}

\bibitem{beck2009fast}
A.~Beck and M.~Teboulle.
\newblock A fast iterative shrinkage-thresholding algorithm for linear inverse
  problems.
\newblock {\em SIAM Journal on Imaging Sciences}, 2(1):183--202, 2009.

\bibitem{nesterov2007gradient}
Y.~Nesterov.
\newblock Gradient methods for minimizing composite objective function.
\newblock {\em CORE Discussion Papers}, (2007/76), 2007.

\bibitem{tibshirani1996regression}
R.~Tibshirani.
\newblock {Regression shrinkage and selection via the Lasso}.
\newblock {\em Journal of the Royal Statistical Society: Series B},
  58(1):267--288, 1996.

\bibitem{chen2001atomic}
S.S. Chen, D.L. Donoho, and M.A. Saunders.
\newblock {Atomic decomposition by basis pursuit}.
\newblock {\em SIAM Journal on Scientific Computing}, 20(1):33--61, 1998.

\bibitem{wright2009sparse}
S.J. Wright, R.D. Nowak, and M.A.T. Figueiredo.
\newblock Sparse reconstruction by separable approximation.
\newblock {\em IEEE Transactions on Signal Processing}, 57(7):2479--2493, 2009.

\bibitem{back_convex_sparsity_11}
F.~Bach, R.~Jenatton, J.~Mairal, and G.~Obozinski.
\newblock {Convex optimization with sparsity-inducing norms}.
\newblock In S.~Sra, S.~Nowozin, and S.J. Wright, editors, {\em Optimization
  for Machine Learning}. MIT Press, 2011.

\bibitem{fadili-tip-10-tv}
J.~Fadili and G.~Peyr{\'e}.
\newblock Total variation projection with first order schemes.
\newblock {\em IEEE Transactions on Image Processing}, 20(3):657--669, 2011.

\bibitem{chen2010graph}
X.~Chen, S.~Kim, Q.~Lin, J.G. Carbonell, and E.P. Xing.
\newblock Graph-structured multi-task regression and an efficient optimization
  method for general fused {L}asso.
\newblock {\em arXiv:1005.3579v1}, 2010.

\bibitem{cai2008singular}
J.-F. Cai, E.J. Cand{\`e}s, and Z.~Shen.
\newblock A singular value thresholding algorithm for matrix completion.
\newblock {\em SIAM Journal on Optimization}, 20(4), 2010.

\bibitem{ma2009fixed}
S.~Ma, D.~Goldfarb, and L.~Chen.
\newblock Fixed point and {B}regman iterative methods for matrix rank
  minimization.
\newblock {\em Mathematical Programming}, 128(1):321--353, 2011.

\bibitem{jacob2009group}
L.~Jacob, G.~Obozinski, and J.-P. Vert.
\newblock Group {L}asso with overlap and graph {L}asso.
\newblock {\em ICML}, 2009.

\bibitem{jenatton2010proximal}
R.~Jenatton, J.~Mairal, G.~Obozinski, and F.~Bach.
\newblock Proximal methods for sparse hierarchical dictionary learning.
\newblock {\em JMLR}, 12:2297--2334, 2011.

\bibitem{barbero2011Newton}
A.~Barbero and S.~Sra.
\newblock Fast {N}ewton-type methods for total variation regularization.
\newblock {\em ICML}, 2011.

\bibitem{liu2010fast}
J.~Liu and J.~Ye.
\newblock Fast overlapping group {L}asso.
\newblock {\em arXiv:1009.0306v1}, 2010.

\bibitem{schmidt2010convex}
M.~Schmidt and K.~Murphy.
\newblock Convex structure learning in log-linear models: Beyond pairwise
  potentials.
\newblock {\em AISTATS}, 2010.

\bibitem{patriksson1999nonlinear}
M.~Patriksson.
\newblock {\em A unified framework of descent algorithms for nonlinear programs
  and variational inequalities}.
\newblock PhD thesis, Department of Mathematics, Link{\"o}ping University,
  Sweden, 1995.

\bibitem{combettes2004solving}
P.L. Combettes.
\newblock Solving monotone inclusions via compositions of nonexpansive averaged
  operators.
\newblock {\em Optimization}, 53(5-6):475--504, 2004.

\bibitem{duchi2009efficient}
J.~Duchi and Y.~Singer.
\newblock Efficient online and batch learning using forward backward splitting.
\newblock {\em JMLR}, 10:2873--2898, 2009.

\bibitem{langford2009sparse}
J.~Langford, L.~Li, and T.~Zhang.
\newblock Sparse online learning via truncated gradient.
\newblock {\em JMLR}, 10:777--801, 2009.

\bibitem{d2005smooth}
A.~{d'Aspremont}.
\newblock Smooth optimization with approximate gradient.
\newblock {\em SIAM Journal on Optimization}, 19(3):1171--1183, 2008.

\bibitem{baes2009estimate}
M.~Baes.
\newblock Estimate sequence methods: extensions and approximations.
\newblock {IFOR} internal report, ETH Zurich, 2009.

\bibitem{devolder2010first}
O.~Devolder, F.~Glineur, and Y.~Nesterov.
\newblock First-order methods of smooth convex optimization with inexact
  oracle.
\newblock {\em CORE Discussion Papers}, (2011/02), 2011.

\bibitem{nedic2000convergence}
A.~Nedic and D.~Bertsekas.
\newblock Convergence rate of incremental subgradient algorithms.
\newblock {\em Stochastic Optimization: Algorithms and Applications}, pages
  263--304, 2000.

\bibitem{luo1993error}
Z.-Q. Luo and P.~Tseng.
\newblock Error bounds and convergence analysis of feasible descent methods: A
  general approach.
\newblock {\em Annals of Operations Research}, 46-47(1):157--178, 1993.

\bibitem{friedlander2011hybrid}
M.P. Friedlander and M.~Schmidt.
\newblock Hybrid deterministic-stochastic methods for data fitting.
\newblock {\em arXiv:1104.2373}, 2011.

\bibitem{rockafellar1976monotone}
R.T. Rockafellar.
\newblock Monotone operators and the proximal point algorithm.
\newblock {\em SIAM Journal on Control and Optimization}, 14(5):877--898, 1976.

\bibitem{guler1992new}
O.~G{\"u}ler.
\newblock New proximal point algorithms for convex minimization.
\newblock {\em SIAM Journal on Optimization}, 2(4):649--664, 1992.

\bibitem{villa2011accelerated}
S.~Villa, S.~Salzo, L.~Baldassarre, and A.~Verri.
\newblock Accelerated and inexact forward-backward algorithms.
\newblock {\em Optimization Online}, 2011.

\bibitem{jianginexact}
K.~Jiang, D.~Sun, and K.C. Toh.
\newblock An inexact accelerated proximal gradient method for large scale
  linearly constrained convex {SDP}.
\newblock {\em Optimization Online}, 2011.

\bibitem{nesterov2004introductory}
Y.~Nesterov.
\newblock {\em {Introductory Lectures on Convex Optimization: A Basic Course}}.
\newblock Springer, 2004.

\bibitem{bertsekas2009convex}
D.P. Bertsekas.
\newblock {\em Convex optimization theory}.
\newblock Athena Scientific, 2009.

\bibitem{tseng2008accelerated}
P.~Tseng.
\newblock On accelerated proximal gradient methods for convex-concave
  optimization, 2008.

\bibitem{mairal2011convex}
J.~Mairal, R.~Jenatton, G.~Obozinski, and F.~Bach.
\newblock Convex and network flow optimization for structured sparsity.
\newblock {\em JMLR}, 12:2681--2720, 2011.

\bibitem{bauschke2008dykstra}
H.H. Bauschke and P.L. Combettes.
\newblock A {D}ykstra-like algorithm for two monotone operators.
\newblock {\em Pacific Journal of Optimization}, 4(3):383--391, 2008.

\bibitem{nesterov2005smooth}
Y.~Nesterov.
\newblock Smooth minimization of non-smooth functions.
\newblock {\em Math. Prog.}, 103(1):127--152, 2005.

\bibitem{combettes2009proximal}
P.L. Combettes and J.-C. Pesquet.
\newblock Proximal splitting methods in signal processing.
\newblock In H.H. Bauschke, R.S. Burachik, P.L. Combettes, V.~Elser, D.R. Luke,
  and H.~Wolkowicz, editors, {\em Fixed-Point Algorithms for Inverse Problems
  in Science and Engineering}, pages 185--212. Springer, 2011.

\bibitem{wainwright2003tree}
M.J. Wainwright, T.S. Jaakkola, and A.S. Willsky.
\newblock Tree-reweighted belief propagation algorithms and approximate {ML}
  estimation by pseudo-moment matching.
\newblock {\em AISTATS}, 2003.

\bibitem{kivinen2004online}
J.~Kivinen, A.J. Smola, and R.C. Williamson.
\newblock Online learning with kernels.
\newblock {\em IEEE Transactions on Signal Processing}, 52(8):2165--2176, 2004.

\bibitem{alexandre2009subsampling}
A.~{d'Aspremont}.
\newblock Subsampling algorithms for semidefinite programming.
\newblock {\em arXiv:0803.1990v5}, 2009.

\bibitem{schmidt2011newtonlike}
M.~Schmidt, D.~Kim, and S.~Sra.
\newblock Projected {N}ewton-type methods in machine learning.
\newblock In S.~Sra, S.~Nowozin, and S.~Wright, editors, {\em Optimization for
  Machine Learning}. MIT Press, 2011.

\bibitem{bertsekas2003convex}
D.P. Bertsekas, A.~Nedi{\'c}, and A.E. Ozdaglar.
\newblock {\em {Convex Analysis and Optimization}}.
\newblock Athena Scientific, 2003.

\end{thebibliography}
