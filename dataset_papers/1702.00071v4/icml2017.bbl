\begin{thebibliography}{23}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Arjovsky et~al.(2015)Arjovsky, Shah, and Bengio]{arjovsky2015unitary}
M~Arjovsky, A~Shah,, Y~Bengio.
\newblock Unitary evolution recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1511.06464}, 2015.

\bibitem[Chernodub \& Nowicki(2016)Chernodub and Nowicki]{chernodub2016norm}
A~Chernodub, D~Nowicki.
\newblock Norm-preserving orthogonal permutation linear unit activation
  functions (oplu).
\newblock \emph{arXiv preprint arXiv:1604.02313}, 2016.

\bibitem[Glorot \& Bengio(2010)Glorot and Bengio]{glorot2010understanding}
X~Glorot, Y~Bengio.
\newblock Understanding the difficulty of training deep feedforward neural
  networks.
\newblock In \emph{Aistats}, volume~9, pp.\  249--256, 2010.

\bibitem[Harandi \& Fernando(2016)Harandi and Fernando]{harandi2016generalized}
M~Harandi, B~Fernando.
\newblock Generalized backpropagation, {\'e}tude de cas: orthogonality.
\newblock \emph{arXiv preprint arXiv:1611.05927}, 2016.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{he2015delving}
K~He, X~Zhang, S~Ren,, J~Sun.
\newblock Delving deep into rectifiers: Surpassing human-level performance on
  imagenet classification.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  1026--1034, 2015.

\bibitem[Henaff et~al.(2016)Henaff, Szlam, and LeCun]{henaff2016orthogonal}
M~Henaff, A~Szlam,, Y~LeCun.
\newblock Orthogonal rnns and long-memory tasks.
\newblock \emph{arXiv preprint arXiv:1602.06662}, 2016.

\bibitem[Hochreiter \& Schmidhuber(1997)Hochreiter and
  Schmidhuber]{hochreiter1997long}
S~Hochreiter, J~Schmidhuber.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Hyland \& R{\"a}tsch(2017)Hyland and R{\"a}tsch]{hyland2017learning}
S.~L Hyland, G~R{\"a}tsch.
\newblock Learning unitary operators with help from u (n).
\newblock In \emph{AAAI}, pp.\  2050--2058, 2017.

\bibitem[Jing et~al.(2016)Jing, Shen, Dub{\v{c}}ek, Peurifoy, Skirlo, Tegmark,
  and Solja{\v{c}}i{\'c}]{jing2016tunable}
L~Jing, Y~Shen, T~Dub{\v{c}}ek, J~Peurifoy, S~Skirlo, M~Tegmark,,
  M~Solja{\v{c}}i{\'c}.
\newblock Tunable efficient unitary neural networks (eunn) and their
  application to rnn.
\newblock \emph{arXiv preprint arXiv:1612.05231}, 2016.

\bibitem[Jing et~al.(2017)Jing, Gulcehre, Peurifoy, Shen, Tegmark,
  Solja{\v{c}}i{\'c}, and Bengio]{jing2017gated}
L~Jing, C~Gulcehre, J~Peurifoy, Y~Shen, M~Tegmark, M~Solja{\v{c}}i{\'c},,
  Y~Bengio.
\newblock Gated orthogonal recurrent units: On learning to forget.
\newblock \emph{arXiv preprint arXiv:1706.02761}, 2017.

\bibitem[Krueger \& Memisevic(2015)Krueger and
  Memisevic]{krueger2015regularizing}
D~Krueger, R~Memisevic.
\newblock Regularizing rnns by stabilizing activations.
\newblock \emph{arXiv preprint arXiv:1511.08400}, 2015.

\bibitem[Le et~al.(2015)Le, Jaitly, and Hinton]{le2015simple}
Q.~V Le, N~Jaitly,, G.~E Hinton.
\newblock A simple way to initialize recurrent networks of rectified linear
  units.
\newblock \emph{arXiv preprint arXiv:1504.00941}, 2015.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
Y~LeCun, L~Bottou, Y~Bengio,, P~Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Marcus et~al.(1993)Marcus, Marcinkiewicz, and
  Santorini]{marcus1993building}
M.~P Marcus, M.~A Marcinkiewicz,, B~Santorini.
\newblock Building a large annotated corpus of english: The penn treebank.
\newblock \emph{Computational linguistics}, 19\penalty0 (2):\penalty0 313--330,
  1993.

\bibitem[Mhammedi et~al.(2016)Mhammedi, Hellicar, Rahman, and
  Bailey]{mhammedi2016efficient}
Z~Mhammedi, A~Hellicar, A~Rahman,, J~Bailey.
\newblock Efficient orthogonal parametrisation of recurrent neural networks
  using householder reflections.
\newblock \emph{arXiv preprint arXiv:1612.00188}, 2016.

\bibitem[Nair \& Hinton(2010)Nair and Hinton]{nair2010rectified}
V~Nair, G.~E Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In \emph{Proceedings of the 27th International Conference on Machine
  Learning (ICML-10)}, pp.\  807--814, 2010.

\bibitem[Nishimori(2005)]{nishimori2005note}
Y~Nishimori.
\newblock A note on riemannian optimization methods on the stiefel and the
  grassmann manifolds.
\newblock \emph{dim}, 1:\penalty0 2, 2005.

\bibitem[Pascanu et~al.(2013)Pascanu, Mikolov, and
  Bengio]{pascanu2013difficulty}
R~Pascanu, T~Mikolov,, Y~Bengio.
\newblock On the difficulty of training recurrent neural networks.
\newblock \emph{ICML (3)}, 28:\penalty0 1310--1318, 2013.

\bibitem[Saxe et~al.(2013)Saxe, McClelland, and Ganguli]{saxe2013exact}
A.~M Saxe, J.~L McClelland,, S~Ganguli.
\newblock Exact solutions to the nonlinear dynamics of learning in deep linear
  neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6120}, 2013.

\bibitem[Tagare(2011)]{tagare2011notes}
H.~D Tagare.
\newblock Notes on optimization on stiefel manifolds.
\newblock Technical report, Tech. Rep., Yale University, 2011.

\bibitem[{Theano Development Team}(2016)]{2016arXiv160502688short}
{Theano Development Team}.
\newblock {Theano: A {Python} framework for fast computation of mathematical
  expressions}.
\newblock \emph{arXiv e-prints}, abs/1605.02688, May 2016.
\newblock URL \url{http://arxiv.org/abs/1605.02688}.

\bibitem[Tieleman \& Hinton(2012)Tieleman and Hinton]{Tieleman2012}
T~Tieleman, G~Hinton.
\newblock {Lecture 6.5---RmsProp: Divide the gradient by a running average of
  its recent magnitude}.
\newblock COURSERA: Neural Networks for Machine Learning, 2012.

\bibitem[Wisdom et~al.(2016)Wisdom, Powers, Hershey, Le~Roux, and
  Atlas]{wisdom2016fullcap}
S~Wisdom, T~Powers, J~Hershey, J~Le~Roux,, L~Atlas.
\newblock Full-capacity unitary recurrent neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4880--4888, 2016.

\end{thebibliography}
