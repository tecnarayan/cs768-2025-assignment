@incollection{bottou98,
  author = {Bottou, L\'{e}on},
  title = {Online Algorithms and Stochastic Approximations},
  booktitle = {Online Learning and Neural Networks},
  editor = {Saad, David},
  publisher = {Cambridge University Press},
  address = {Cambridge, UK},
  year = {1998},
  url = {http://leon.bottou.org/papers/bottou-98x},
  note = {revised, oct 2012}
}

@inproceedings{wilson2017marginal,
  title={The marginal value of adaptive gradient methods in machine learning},
  author={Wilson, Ashia C and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nati and Recht, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4148--4158},
  year={2017}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}


@article{matthew12,
  author    = {Matthew D. Zeiler},
  title     = {{ADADELTA:} An Adaptive Learning Rate Method},
  journal   = {CoRR},
  volume    = {abs/1212.5701},
  year      = {2012},
  url       = {http://arxiv.org/abs/1212.5701},
  archivePrefix = {arXiv},
  eprint    = {1212.5701},
  timestamp = {Mon, 13 Aug 2018 16:45:57 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1212-5701},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={12},
  number={Jul},
  pages={2121--2159},
  year={2011}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@ARTICLE{yaida18,
       author = {{Yaida}, Sho},
        title = "{Fluctuation-dissipation relations for stochastic gradient descent}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning, Computer Science - Machine Learning},
         year = "2018",
        month = "Sep",
          eid = {arXiv:1810.00004},
        pages = {arXiv:1810.00004},
archivePrefix = {arXiv},
       eprint = {1810.00004},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv181000004Y},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@inproceedings{LoshchilovH17,
  author    = {Ilya Loshchilov and
               Frank Hutter},
  title     = {{SGDR:} Stochastic Gradient Descent with Warm Restarts},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  year      = {2017},
  crossref  = {DBLP:conf/iclr/2017},
  url       = {https://openreview.net/forum?id=Skq89Scxx},
  timestamp = {Thu, 25 Jul 2019 14:25:58 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/iclr/LoshchilovH17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{smith2017cyclical,
  title={Cyclical learning rates for training neural networks},
  author={Smith, Leslie N},
  booktitle={2017 IEEE Winter Conference on Applications of Computer Vision (WACV)},
  pages={464--472},
  year={2017},
  organization={IEEE}
}

@inproceedings{Ravaut2017,
  title={Faster gradient descent via an adaptive learning rate},
  author={Mathieu Ravaut},
  year={2017}
}


@inproceedings{schaul2013no,
  title={No more pesky learning rates},
  author={Schaul, Tom and Zhang, Sixin and LeCun, Yann},
  booktitle={International Conference on Machine Learning},
  pages={343--351},
  year={2013}
}

@article{Loshchilov2016,
  author    = {Ilya Loshchilov and
               Frank Hutter},
  title     = {{SGDR:} Stochastic Gradient Descent with Restarts},
  journal   = {CoRR},
  volume    = {abs/1608.03983},
  year      = {2016},
  url       = {http://arxiv.org/abs/1608.03983},
  archivePrefix = {arXiv},
  eprint    = {1608.03983},
  timestamp = {Mon, 13 Aug 2018 16:48:29 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LoshchilovH16a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{moulines2011non,
  title={Non-asymptotic analysis of stochastic approximation algorithms for machine learning},
  author={Bach, F. and Moulines, E.},
  booktitle={Advances in Neural Information Processing Systems},
  pages={451--459},
  year={2011}
}


@inproceedings{lang2019using,
  title={Using statistics to automate stochastic optimization},
  author={Lang, Hunter and Xiao, Lin and Zhang, Pengchuan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9536--9546},
  year={2019}
}

@inproceedings{nguyen2019tight,
  title={Tight Dimension Independent Lower Bound on the Expected Convergence Rate for Diminishing Step Sizes in SGD},
  author={Nguyen, PHUONG\_HA and Nguyen, Lam and van Dijk, Marten},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3665--3674},
  year={2019}
}



@inproceedings{needell2014stochastic,
  title={Stochastic gradient descent, weighted sampling, and the randomized kaczmarz algorithm},
  author={Needell, Deanna and Ward, Rachel and Srebro, Nati},
  booktitle={Advances in neural information processing systems},
  pages={1017--1025},
  year={2014}
}

@article{sordello2019robust,
  title={Robust Learning Rate Selection for Stochastic Optimization via Splitting Diagnostic},
  author={Sordello, Matteo and Su, Weijie},
  journal={arXiv preprint arXiv:1910.08597},
  year={2019}
}



@article{dieuleveut2017bridging,
  title={Bridging the gap between constant step size stochastic gradient descent and markov chains},
  author={Dieuleveut, Aymeric and Durmus, Alain and Bach, Francis},
  journal={arXiv preprint arXiv:1707.06386},
  year={2017}
}


@techreport{pflug1983determination,
  title={On the determination of the step size in stochastic quasigradient methods},
  author={Pflug, Georg Ch},
  year={1983},
  institution= {IIASA Collaborative Paper}
}


@article{lacoste2012simpler,
  title={A simpler approach to obtaining an O (1/t) convergence rate for the projected stochastic subgradient method},
  author={Lacoste-Julien, Simon and Schmidt, Mark and Bach, Francis},
  journal={arXiv preprint arXiv:1212.2002},
  year={2012}
}


@inproceedings{chee2018convergence,
  title={Convergence diagnostics for stochastic gradient descent with constant learning rate},
  author={Chee, Jerry and Toulis, Panos},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1476--1485},
  year={2018}
}


@incollection{bottou2010large,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}


@inproceedings{bach2013non,
  title={Non-strongly-convex smooth stochastic approximation with convergence rate O (1/n)},
  author={Bach, Francis and Moulines, Eric},
  booktitle={Advances in neural information processing systems},
  pages={773--781},
  year={2013}
}

@article{nemirovski2009robust,
  title={Robust stochastic approximation approach to stochastic programming},
  author={Nemirovski, Arkadi and Juditsky, Anatoli and Lan, Guanghui and Shapiro, Alexander},
  journal={SIAM Journal on optimization},
  volume={19},
  number={4},
  pages={1574--1609},
  year={2009},
  publisher={SIAM}
}

@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@article{pflug1988adaptive,
  title={Adaptive Stepsize Control in Stochastic Approximation Algorithms},
  author={Pflug, G Ch},
  journal={IFAC Proceedings Volumes},
  volume={21},
  number={9},
  pages={787--792},
  year={1988},
  publisher={Elsevier}
}

@article{pflug1988stepsize,
  title={Stepsize rules, stopping times and their implementation in stochastic quasi-gradient algorithms},
  author={Pflug, G Ch},
  journal={numerical techniques for stochastic optimization},
  pages={353--372},
  year={1988},
  publisher={New York: Springer-Verlag}
}


@article{juditsky2014deterministic,
  title={Deterministic and stochastic primal-dual subgradient algorithms for uniformly convex minimization},
  author={Juditsky, Anatoli and Nesterov, Yuri},
  journal={Stochastic Systems},
  volume={4},
  number={1},
  pages={44--80},
  year={2014},
  publisher={INFORMS}
}

@book{kushner2003stochastic,
  title={Stochastic approximation and recursive algorithms and applications},
  author={Kushner, Harold and Yin, G George},
  volume={35},
  year={2003},
  publisher={Springer Science \& Business Media}
}

@article{bottou2018optimization,
  title={Optimization methods for large-scale machine learning},
  author={Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
  journal={Siam Review},
  volume={60},
  number={2},
  pages={223--311},
  year={2018},
  publisher={SIAM}
}


@article{polyak1992acceleration,
  title={Acceleration of stochastic approximation by averaging},
  author={Polyak, Boris T and Juditsky, Anatoli B},
  journal={SIAM Journal on Control and Optimization},
  volume={30},
  number={4},
  pages={838--855},
  year={1992},
  publisher={SIAM}
}

@techreport{ruppert1988efficient,
  title={Efficient estimations from a slowly convergent Robbins-Monro process},
  author={Ruppert, David},
  year={1988},
  institution={Cornell University Operations Research and Industrial Engineering}
}



@inproceedings{roulet2017sharpness,
  title={Sharpness, restart and acceleration},
  author={Roulet, Vincent and d'Aspremont, Alexandre},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1119--1129},
  year={2017}
}








@incollection{bottou2010large,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}





@inproceedings{shamir2013stochastic,
  title={Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes},
  author={Shamir, Ohad and Zhang, Tong},
  booktitle={International Conference on Machine Learning},
  pages={71--79},
  year={2013}
}



@INPROCEEDINGS{graves2013speech, 
author={Graves, A. and Mohamed, A. and Hinton, G.}, 
booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
title={Speech recognition with deep recurrent neural networks}, 
year={2013}, 
volume={}, 
number={}, 
pages={6645-6649},
}

@INPROCEEDINGS{he2016deep, 
author={{He}, K. and {Zhang}, X. and  {Ren}, S. and {Sun}, J.}, 
booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
title={Deep Residual Learning for Image Recognition}, 
year={2016}, 
volume={}, 
number={}, 
pages={770-778}
}

@inproceedings{sutton1992adapting,
  title={Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta},
  author={Sutton, R. S},
  booktitle={AAAI},
  year={1992}
}

@INPROCEEDINGS{schraudolph1999local,
    author = {Schraudolph, N. N},
    title = {Local Gain Adaptation in Stochastic Gradient Descent},
    booktitle = {In Proc. Intl. Conf. Artificial Neural Networks},
    year = {1999},
    pages = {569--574}
}

@ARTICLE{kushner1995analysis, 
author={{Kushner}, H. J. and  {Yang}, J.}, 
journal={IEEE Transactions on Automatic Control}, 
title={Analysis of adaptive step-size SA algorithms for parameter tracking}, 
year={1995}, 
volume={40}, 
number={8}, 
pages={1403-1410}
}

@article{jacob1988increased,
title = "Increased rates of convergence through learning rate adaptation",
journal = "Neural Networks",
volume = "1",
number = "4",
pages = "295 - 307",
year = "1988",
author =" Jacobs, R. A"
}

@book{benveniste1990adaptive,
author = {Benveniste, A. and Priouret, P. and M\'{e}tivier, M.}, 
title = {Adaptive Algorithms and Stochastic Approximations}, 
year = {1990},
publisher = {Springer-Verlag}
}

@inbook{almeida1999parameter, 
author = {Almeida, L.  B. and Langlois, T. and Amaral, J. D. and Plakhov, A.}, 
title = {Parameter Adaptation in Stochastic Optimization},
year = {1999}, 
publisher = {Cambridge University Press},
booktitle = {On-Line Learning in Neural Networks}, 
pages = {111–134}
}


@inproceedings{sutton1981adaption,
     title = {Adaptation of learning rate parameters},
     author = {Sutton, R.S.},
     booktitle= {In: Goal Seeking Components for Adaptive Intelligence: An Initial Assessment, by A. G. Barto and R. S. Sutton.},
     year = {1981},
     publisher= {Air Force Wright Aeronautical Laboratories Technical Report AFWAL-TR-81-1070. Wright-Patterson Air Force Base, Ohio 45433.}
}

@article{kesten1958accelerated,
author = "Kesten, H.",
fjournal = "The Annals of Mathematical Statistics",
journal = "Ann. Math. Statist.",
month = "03",
number = "1",
pages = "41--59",
publisher = "The Institute of Mathematical Statistics",
title = "Accelerated Stochastic Approximation",
volume = "29",
year = "1958"
}

@article{delyon1993accelerated,
author = {Delyon, B. and Juditsky, A.},
title = {Accelerated Stochastic Approximation},
journal = {SIAM Journal on Optimization},
volume = {3},
number = {4},
pages = {868-881},
year = {1993}
}

@incollection{ge2019step,
title = {The Step Decay Schedule: A Near Optimal, Geometrically Decaying Learning Rate Procedure For Least Squares},
author = {Ge, R. and Kakade, S. M and Kidambi, R. and Netrapalli, P.},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {14951--14962},
year = {2019},
publisher = {Curran Associates, Inc.}
}

@book{NemYud83,
	author = "Nemirovsky, A. S. and Yudin, D. B.",
	publisher = "John Wiley \&\ Sons",
	series = "Wiley-Interscience Series in Discrete Mathematics",
	title = "{Problem Complexity and Method Efficiency in Optimization}",
	year = "1983"
}

@article{hazan2014optimal,
  author  = {Hazan, E. and  Kale, S.},
  title   = {Beyond the Regret Minimization Barrier: Optimal Algorithms for Stochastic Strongly-Convex Optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  pages   = {2489-2512}
}

@article{bach2014adaptivity,
  author  = {Bach, F.},
  title   = {Adaptivity of Averaged Stochastic Gradient Descent to Local Strong Convexity for Logistic Regression},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  pages   = {595-627}
}

@article{kushner1981asymptotic,
author = {Kushner, H. J. and Huang, H;.},
title = {Asymptotic Properties of Stochastic Approximations with Constant Coefficients},
journal = {SIAM Journal on Control and Optimization},
volume = {19},
number = {1},
pages = {87-105},
year = {1981}
}

@article{pflug1986stochastic,
author = {Pflug, G. C.},
title = {Stochastic Minimization with Constant Step-Size: Asymptotic Laws},
journal = {SIAM Journal on Control and Optimization},
volume = {24},
number = {4},
pages = {655-666},
year = {1986}
}

@inproceedings{zhang2004solving,
author = {Zhang, T.},
title = {Solving Large Scale Linear Prediction Problems Using Stochastic Gradient Descent Algorithms},
year = {2004}, 
booktitle = {Proceedings of the Twenty-First International Conference on Machine Learning},
pages = {116}, numpages = {8},
series = {ICML ’04} 
}

@inproceedings{RakShaSri12,
  author    = {Rakhlin, A. and
               Shamir, O. and
               Sridharan, K.},
  title     = {Making Gradient Descent Optimal for Strongly Convex Stochastic Optimization},
	booktitle = "{Proceedings of the Conference on Machine Learning (ICML)}",
  year      = {2012}
}


@TECHREPORT{Krizhevsky09learningmultiple,
    author = {Krizhevsky, A.},
    title = {Learning multiple layers of features from tiny images},
    institution = {University of Toronto},
    year = {2009}
}


@article{paley1932series,
title={On some series of functions, (3)},
volume={28}, 
number={2},
journal={Mathematical Proceedings of the Cambridge Philosophical Society}, 
publisher={Cambridge University Press},
author={Paley, R. E. A. C. and Zygmund, A.}, 
year={1932},
pages={190–205}
}

@article{BecTeb09,
	author = "Beck, A. and Teboulle, M.",
	fjournal = "SIAM Journal on Imaging Sciences",
	journal = "SIAM J. Imaging Sci.",
	number = "1",
	pages = "183--202",
	title = "A fast iterative shrinkage-thresholding algorithm for linear inverse problems",
	volume = "2",
	year = "2009"
}
