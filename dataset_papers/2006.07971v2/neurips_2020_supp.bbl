\begin{thebibliography}{10}

\bibitem{costa_2004_38676}
J.~Costa and A.~Hero.
\newblock Learning intrinsic dimension and intrinsic entropy of
  high-dimensional datasets.
\newblock In {\em European Signal Processing Conference (EUSIPCO), Vienna,
  Austria, 2004}. Zenodo, sep 2004.

\bibitem{AudibertHein2005}
M.~Hein and J.-Y. Audibert.
\newblock Intrinsic dimensionality estimation of submanifolds in rd.

\bibitem{Mallat_book_1999}
S.~Mallat.
\newblock {\em A Wavelet Tour of Signal Processing (Third Edition): The Sparse
  Way}.
\newblock Academic Press, Boston, third edition, 2009.

\bibitem{CandesRombergTao_2006}
E.~J. Cand\`es, J.~K. Romberg, and T.~Tao.
\newblock Stable signal recovery from incomplete and inaccurate measurements.
\newblock {\em Communications on Pure and Applied Mathematics},
  59(8):1207--1223, 2006.

\bibitem{Donoho_CompressedSensing2006}
D.~L. {Donoho}.
\newblock Compressed sensing.
\newblock {\em IEEE Transactions on Information Theory}, 52(4):1289--1306,
  2006.

\bibitem{candes2009exact}
E.~Cand{\`e}s and B.~Recht.
\newblock Exact matrix completion via convex optimization.
\newblock {\em Foundations of Computational mathematics}, 9(6):717--772, 2009.

\bibitem{hastie_09_elements-of.statistical-learning}
T.~Hastie, R.~Tibshirani, and J.~Friedman.
\newblock {\em The elements of statistical learning: data mining, inference and
  prediction}.
\newblock Springer, 2 edition, 2009.

\bibitem{RishGrabarnik2014}
I.~Rish and G.~Grabarnik.
\newblock {\em Sparse Modeling: Theory, Algorithms, and Applications}.
\newblock CRC Press, Inc., USA, 1st edition, 2014.

\bibitem{HastieTibshiraniWainwright}
T.~Hastie, R.~Tibshirani, and M.~Wainwright.
\newblock {\em Statistical Learning with Sparsity: The Lasso and
  Generalizations}.
\newblock Chapman and Hall/CRC, 2015.

\bibitem{wainwright2019high}
M.~Wainwright.
\newblock {\em High-Dimensional Statistics: A Non-Asymptotic Viewpoint}.
\newblock Cambridge Series in Statistical and Probabilistic Mathematics.
  Cambridge University Press, 2019.

\bibitem{Zdeborov2016}
L.~Zdeborov{\'a} and F.~Krzakala.
\newblock Statistical physics of inference: thresholds and algorithms.
\newblock {\em Advances in Physics}, 65(5), Aug 2016.

\bibitem{barbier_allerton_RLE}
J.~Barbier, M.~Dia, N.~Macris, and F.~Krzakala.
\newblock {The Mutual Information in Random Linear Estimation}.
\newblock In {\em 54th Annual Allerton Conference on Communication, Control,
  and Computing}, September 2016.

\bibitem{9079920}
J.~{Barbier}, N.~{Macris}, M.~{Dia}, and F.~{Krzakala}.
\newblock Mutual information and optimality of approximate message-passing in
  random linear estimation.
\newblock {\em IEEE Transactions on Information Theory}, 2020.

\bibitem{private}
G.~Reeves and H.~D. Pfister.
\newblock The replica-symmetric prediction for compressed sensing with gaussian
  matrices is exact.
\newblock In {\em 2016 IEEE International Symposium on Information Theory
  (ISIT)}, July 2016.

\bibitem{barbier2017phase}
J.~Barbier, F.~Krzakala, N.~Macris, L.~Miolane, and L.~Zdeborov{\'a}.
\newblock Optimal errors and phase transitions in high-dimensional generalized
  linear models.
\newblock {\em Proceedings of the National Academy of Sciences},
  116(12):5451--5460, 2019.

\bibitem{2016arXiv161103888L}
M.~Lelarge and L.~Miolane.
\newblock Fundamental limits of symmetric low-rank matrix estimation.
\newblock {\em Probability Theory and Related Fields}, 173(3-4):859--929, 2018.

\bibitem{2017arXiv170200473M}
L.~{Miolane}.
\newblock {Fundamental limits of low-rank matrix estimation: The non-symmetric
  case}.
\newblock {\em ArXiv e-prints}, February 2017.

\bibitem{XXT}
J.~Barbier, M.~Dia, N.~Macris, F.~Krzakala, T.~Lesieur, and L.~Zdeborov\'{a}.
\newblock Mutual information for symmetric rank-one matrix estimation: A proof
  of the replica formula.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS) 29},
  pages 424--432. 2016.

\bibitem{BarbierM17a}
J.~Barbier and N.~Macris.
\newblock The adaptive interpolation method: a simple scheme to prove replica
  formulas in bayesian inference.
\newblock {\em Probability Theory and Related Fields}, Oct 2018.

\bibitem{BarbierMacris2019}
J.~Barbier and N.~Macris.
\newblock The adaptive interpolation method for proving replica formulas.
  applications to the curie{\textendash}weiss and wigner spike models.
\newblock {\em Journal of Physics A: Mathematical and Theoretical},
  52(29):294002, jun 2019.

\bibitem{2017arXiv170108010L}
T.~{Lesieur}, L.~{Miolane}, M.~{Lelarge}, F.~{Krzakala}, and
  L.~{Zdeborov{\'a}}.
\newblock {Statistical and computational phase transitions in spiked tensor
  estimation}.
\newblock In {\em IEEE International Symposium on Information Theory (ISIT),
  2017}.

\bibitem{2017arXiv170910368B}
J.~{Barbier}, N.~{Macris}, and L.~{Miolane}.
\newblock {The Layered Structure of Tensor Estimation and its Mutual
  Information}.
\newblock In {\em 55th Annual Allerton Conference on Communication, Control,
  and Computing (Allerton)}, September 2017.

\bibitem{mourrat2019hamilton}
J.-C. Mourrat.
\newblock Hamilton-jacobi equations for finite-rank matrix inference.
\newblock {\em arXiv preprint arXiv:1904.05294}, 2019.

\bibitem{david2017high}
D.~Gamarnik and I.~Zadik.
\newblock High dimensional regression with binary coefficients. estimating
  squared error and a phase transtition.
\newblock In {\em Conference on Learning Theory}, pages 948--953, 2017.

\bibitem{reeves2019all}
G.~Reeves, J.~Xu, and I.~Zadik.
\newblock The all-or-nothing phenomenon in sparse linear regression.
\newblock In {\em Proceedings of the Thirty-Second Conference on Learning
  Theory}, volume~99 of {\em Proceedings of Machine Learning Research}, pages
  2652--2663. PMLR, 25--28 Jun 2019.

\bibitem{Kabashima_2003}
Y.~Kabashima.
\newblock A {CDMA} multiuser detection algorithm on the basis of belief
  propagation.
\newblock {\em Journal of Physics A: Mathematical and General},
  36(43):11111--11121, oct 2003.

\bibitem{bayati2011dynamics}
M.~Bayati and A.~Montanari.
\newblock The dynamics of message passing on dense graphs, with applications to
  compressed sensing.
\newblock {\em IEEE Trans. on Information Theory}, 2011.

\bibitem{Donoho10112009}
D.~L. Donoho, A.~Maleki, and A.~Montanari.
\newblock Message-passing algorithms for compressed sensing.
\newblock {\em Proceedings of the National Academy of Sciences},
  106(45):18914--18919, 2009.

\bibitem{krz12}
F.~Krzakala, M.~M{\'e}zard, F.~Sausset, Y.~Sun, and L.~Zdeborov{\'a}.
\newblock Probabilistic reconstruction in compressed sensing: algorithms, phase
  diagrams, and threshold achieving matrices.
\newblock {\em J. Stat. Mech. Theory Exp.}, (8), 2012.

\bibitem{MontChap11}
A.~Montanari.
\newblock Graphical models concepts in compressed sensing.
\newblock In Y.~C. Eldar and G.~Kutyniok, editors, {\em Compressed Sensing},
  pages 394--438. Cambridge University Press, 2012.

\bibitem{Rangan11}
S.~Rangan.
\newblock Generalized approximate message passing for estimation with random
  linear mixing.
\newblock In {\em Proc. IEEE Int. Symp. Inf. Theory}, pages 2168--2172, 2011.

\bibitem{deshpande2015finding}
Y.~Deshpande and A.~Montanari.
\newblock Finding hidden cliques of size $\sqrt{N/e}$ in nearly linear time.
\newblock {\em Foundations of Computational Mathematics}, 15(4):1069--1128,
  2015.

\bibitem{deshpande2014information}
Y.~Deshpande and A.~Montanari.
\newblock Information-theoretically optimal sparse pca.
\newblock In {\em 2014 IEEE International Symposium on Information Theory},
  pages 2197--2201. IEEE, 2014.

\bibitem{montanari2017estimation}
A.~Montanari and R.~Venkataramanan.
\newblock Estimation of low-rank matrices via approximate message passing.
\newblock {\em arXiv preprint arXiv:1711.01682}, 2017.

\bibitem{vila2015hyperspectral}
J.~Vila, P.~Schniter, and J.~Meola.
\newblock Hyperspectral unmixing via turbo bilinear approximate message
  passing.
\newblock {\em IEEE Transactions on Computational Imaging}, 1(3):143--158,
  2015.

\bibitem{fletcher2018iterative}
A.~K. Fletcher and S.~Rangan.
\newblock Iterative reconstruction of rank-one matrices in noise.
\newblock {\em Information and Inference: A Journal of the IMA}, 7(3):531--562,
  2018.

\bibitem{parker2014bilinear}
J.~T. Parker, P.~Schniter, and V.~Cevher.
\newblock Bilinear generalized approximate message passing. part i: Derivation.
\newblock {\em IEEE Transactions on Signal Processing}, 62(22):5839--5853,
  2014.

\bibitem{montanari2015non}
A.~Montanari and E.~Richard.
\newblock Non-negative principal component analysis: Message passing algorithms
  and sharp asymptotics.
\newblock {\em IEEE Transactions on Information Theory}, 62(3):1458--1484,
  2015.

\bibitem{baik2005phase}
J.~Baik, G.~B. Arous, and S.~P{\'e}ch{\'e}.
\newblock Phase transition of the largest eigenvalue for nonnull complex sample
  covariance matrices.
\newblock {\em Annals of Probability}, page 1643, 2005.

\bibitem{peche2006largest}
S.~P{\'e}ch{\'e}.
\newblock The largest eigenvalue of small rank perturbations of hermitian
  random matrices.
\newblock {\em Probability Theory and Related Fields}, 134(1):127--173, 2006.

\bibitem{feral2007largest}
D.~F{\'e}ral and S.~P{\'e}ch{\'e}.
\newblock The largest eigenvalue of rank one deformation of large wigner
  matrices.
\newblock {\em Communications in mathematical physics}, 272(1):185--228, 2007.

\bibitem{amini2009}
A.~A. Amini and M.~J. Wainwright.
\newblock High-dimensional analysis of semidefinite relaxations for sparse
  principal components.
\newblock {\em Ann. Statist.}, 37(5B):2877--2921, 10 2009.

\bibitem{pmlr-v75-brennan18a}
M.~Brennan, G.~Bresler, and W.~Huleihel.
\newblock Reducibility and computational lower bounds for problems with planted
  sparse structure.
\newblock In {\em Proceedings of the 31st Conference On Learning Theory},
  volume~75 of {\em Proceedings of Machine Learning Research}, pages 48--166.
  PMLR, 06--09 Jul 2018.

\bibitem{gamarnik2019overlap}
D.~Gamarnik, A.~Jagannath, and S.~Sen.
\newblock The overlap gap property in principal submatrix recovery.
\newblock {\em arXiv preprint arXiv:1908.09959}, 2019.

\bibitem{Cai2015}
T.~Cai, Z.~Ma, and Y.~Wu.
\newblock Optimal estimation and rank detection for sparse spiked covariance
  matrices.
\newblock {\em Probability Theory and Related Fields}, 161(3):781--815, Apr
  2015.

\bibitem{krauthgamer2015}
R.~Krauthgamer, B.~Nadler, and D.~Vilenchik.
\newblock Do semidefinite relaxations solve sparse pca up to the information
  limit?
\newblock {\em Ann. Statist.}, 43(3):1300--1322, 06 2015.

\bibitem{JMLR:v17:15-160}
Y.~Deshpande and A.~Montanari.
\newblock Sparse pca via covariance thresholding.
\newblock {\em Journal of Machine Learning Research}, 17(141):1--41, 2016.

\bibitem{wang2016}
T.~Wang, Q.~Berthet, and R.~J. Samworth.
\newblock Statistical and computational trade-offs in estimation of sparse
  principal components.
\newblock {\em Ann. Statist.}, 44(5):1896--1930, 10 2016.

\bibitem{pmlr-v30-Berthet13}
Q.~Berthet and P.~Rigollet.
\newblock Complexity theoretic lower bounds for sparse principal component
  detection.
\newblock In {\em Proceedings of the 26th Annual Conference on Learning
  Theory}, volume~30 of {\em Proceedings of Machine Learning Research}, pages
  1046--1066, Princeton, NJ, USA, 12--14 Jun 2013. PMLR.

\bibitem{Ma:2015:SLB:2969239.2969419}
T.~Ma and A.~Wigderson.
\newblock Sum-of-squares lower bounds for sparse pca.
\newblock In {\em Proceedings of the 28th International Conference on Neural
  Information Processing Systems - Volume 1}, NIPS'15, pages 1612--1620,
  Cambridge, MA, USA, 2015. MIT Press.

\bibitem{mezard2009information}
M.~Mezard and A.~Montanari.
\newblock {\em Information, physics and computation}.
\newblock Oxford University Press, 2009.

\bibitem{2017arXiv170100858L}
T.~Lesieur, F.~Krzakala, and L.~Zdeborov{\'{a}}.
\newblock Constrained low-rank matrix estimation: phase transitions,
  approximate message passing and applications.
\newblock {\em Journal of Statistical Mechanics: Theory and Experiment},
  2017(7):073403, jul 2017.

\bibitem{bolthausen2014iterative}
E.~Bolthausen.
\newblock An iterative construction of solutions of the tap equations for the
  sherrington--kirkpatrick model.
\newblock {\em Communications in Mathematical Physics}, 325(1):333--366, 2014.

\bibitem{korada2009exact}
S.~B. Korada and N.~Macris.
\newblock Exact solution of the gauge symmetric p-spin glass model on a
  complete graph.
\newblock {\em Journal of Statistical Physics}, 136(2):205--230, 2009.

\bibitem{krzakala2016mutual}
F.~Krzakala, J.~Xu, and L.~Zdeborov{\'a}.
\newblock Mutual information in rank-one matrix estimation.
\newblock In {\em 2016 IEEE Information Theory Workshop (ITW)}, pages 71--75.
  IEEE, 2016.

\bibitem{el2018estimation}
A.~El~Alaoui and F.~Krzakala.
\newblock Estimation in the spiked wigner model: a short proof of the replica
  formula.
\newblock In {\em 2018 IEEE International Symposium on Information Theory
  (ISIT)}, pages 1874--1878. IEEE, 2018.

\bibitem{barbier2019mutual}
J.~Barbier, C.~Luneau, and N.~Macris.
\newblock Mutual information for low-rank even-order symmetric tensor
  factorization.
\newblock {\em arXiv preprint arXiv:1904.04565}, 2019.

\bibitem{GuoShamaiVerdu_IMMSE}
D.~Guo, S.~Shamai, and S.~Verdu.
\newblock Mutual information and minimum mean-square error in gaussian
  channels.
\newblock {\em IEEE Trans. on Information Theory}, 51(4):1261--1282, April
  2005.

\bibitem{guo2011estimation}
D.~Guo, Y.~Wu, S.~S. Shitz, and S.~Verd{\'u}.
\newblock Estimation in gaussian noise: Properties of the minimum mean-square
  error.
\newblock {\em IEEE Transactions on Information Theory}, 57(4):2371--2385,
  2011.

\bibitem{perry2018optimality}
A.~Perry, A.~S. Wein, A.~S. Bandeira, A.~Moitra, et~al.
\newblock Optimality and sub-optimality of pca i: Spiked random matrix models.
\newblock {\em The Annals of Statistics}, 46(5):2416--2451, 2018.

\bibitem{alaoui2017finite}
A.~E. Alaoui, F.~Krzakala, and M.~I. Jordan.
\newblock Finite size corrections and likelihood ratio fluctuations in the
  spiked wigner model.
\newblock {\em arXiv preprint arXiv:1710.02903}, 2017.

\bibitem{alaoui2018detection}
A.~E. Alaoui and M.~I. Jordan.
\newblock Detection limits in the high-dimensional spiked rectangular model.
\newblock In {\em Conference On Learning Theory, {COLT} 2018, Stockholm,
  Sweden, 6-9 July 2018.}, pages 410--438, 2018.

\bibitem{RushVenkataramanan}
C.~Rush and R.~Venkataramanan.
\newblock Finite sample analysis of approximate message passing algorithms.
\newblock {\em {IEEE} Trans. Information Theory}, 64(11):7264--7286, 2018.

\bibitem{montanari2015finding}
A.~Montanari.
\newblock Finding one community in a sparse graph.
\newblock {\em Journal of Statistical Physics}, 161(2):273--299, 2015.

\bibitem{milgrom2002envelope}
P.~Milgrom and I.~Segal.
\newblock Envelope theorems for arbitrary choice sets.
\newblock {\em Econometrica}, 70(2):583--601, 2002.

\bibitem{Montanari-Javanmard}
A.~Javanmard and A.~Montanari.
\newblock State evolution for general approximate message passing algorithms,
  with applications to spatial coupling.
\newblock {\em J. Infor. \& Inference}, 2:115, 2013.

\bibitem{BLMConc}
S.~Boucheron, G.~Lugosi, and P.~Massart.
\newblock {\em Concentration inequalities: A nonasymptotic theory of
  independence}.
\newblock Oxford University Press, 2013.

\end{thebibliography}
