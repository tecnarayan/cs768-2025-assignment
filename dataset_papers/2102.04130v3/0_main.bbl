\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Adiwardana et~al.(2020)Adiwardana, Luong, So, Hall, Fiedel, Thoppilan,
  Yang, Kulshreshtha, Nemade, Lu, and Le]{Adiwardana2020TowardsAH}
D.~Adiwardana, Minh-Thang Luong, D.~So, J.~Hall, Noah Fiedel, R.~Thoppilan,
  Z.~Yang, Apoorv Kulshreshtha, G.~Nemade, Yifeng Lu, and Quoc~V. Le.
\newblock Towards a human-like open-domain chatbot.
\newblock \emph{ArXiv}, abs/2001.09977, 2020.

\bibitem[Antoniak and Mimno(2021)]{Antoniak2021BadSE}
Maria Antoniak and David Mimno.
\newblock Bad seeds: Evaluating lexical methods for bias measurement.
\newblock In \emph{ACL/IJCNLP}, 2021.

\bibitem[Barbulescu and Bidwell(2013)]{Barbulescu2013}
Roxana Barbulescu and Matthew Bidwell.
\newblock Do women choose different jobs from men? mechanisms of application
  segregation in the market for managerial workers.
\newblock \emph{Organization Science}, 24\penalty0 (3):\penalty0 737--756,
  2013.

\bibitem[Barocas and Selbst(2016)]{Barocas2016BigDD}
Solon Barocas and Andrew~D. Selbst.
\newblock Big data's disparate impact.
\newblock \emph{California Law Review}, 104:\penalty0 671, 2016.

\bibitem[Beller(1982)]{Beller1982}
Andrea~H Beller.
\newblock Occupational segregation by sex: Determinants and changes.
\newblock \emph{Journal of Human Resources}, pages 371--392, 1982.

\bibitem[Bender and Koller(2020)]{Bender2020}
Emily~M Bender and Alexander Koller.
\newblock Climbing towards nlu: On meaning, form, and understanding in the age
  of data.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 5185--5198, 2020.

\bibitem[Bender et~al.(2021)Bender, Gebru, McMillan-Major, and
  Shmitchell]{Bender2021}
Emily~M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret
  Shmitchell.
\newblock On the dangers of stochastic parrots: Can language models be too
  big?\raisebox{-5pt}{\includegraphics[scale=0.075]{parrot.png}}.
\newblock In \emph{Conference on Fairness, Accountability, and Transparency
  (FAccT â€™21)}. ACM, New York, NY, USA, 2021.

\bibitem[Bhardwaj et~al.(2020)Bhardwaj, Majumder, and
  Poria]{Bhardwaj2020InvestigatingGB}
Rishabh Bhardwaj, Navonil Majumder, and Soujanya Poria.
\newblock Investigating gender bias in bert.
\newblock \emph{ArXiv}, abs/2009.05021, 2020.

\bibitem[Blodgett et~al.(2020)Blodgett, Barocas, Daum'e, and
  Wallach]{Blodgett2020LanguageI}
Su~Lin Blodgett, Solon Barocas, Hal Daum'e, and H.~Wallach.
\newblock Language (technology) is power: A critical survey of "bias" in nlp.
\newblock In \emph{ACL}, 2020.

\bibitem[Blodgett et~al.(2021)Blodgett, Lopez, Olteanu, Sim, and
  Wallach]{Blodgett2021StereotypingNS}
Su~Lin Blodgett, Gilsinia Lopez, Alexandra Olteanu, Robert Sim, and Hanna~M.
  Wallach.
\newblock Stereotyping norwegian salmon: An inventory of pitfalls in fairness
  benchmark datasets.
\newblock In \emph{ACL/IJCNLP}, 2021.

\bibitem[Bolukbasi et~al.(2016)Bolukbasi, Chang, Zou, Saligrama, and
  Kalai]{Bolukbasi2016ManIT}
Tolga Bolukbasi, Kai-Wei Chang, James~Y. Zou, Venkatesh Saligrama, and
  A.~Kalai.
\newblock Man is to computer programmer as woman is to homemaker? debiasing
  word embeddings.
\newblock In \emph{NeurIPS}, 2016.

\bibitem[Borghans and Groot(1999)]{Borghans1999}
Lex Borghans and Loek Groot.
\newblock Educational presorting and occupational segregation.
\newblock \emph{Labour Economics}, 6\penalty0 (3):\penalty0 375--395, 1999.

\bibitem[Caliskan et~al.(2017)Caliskan, Bryson, and
  Narayanan]{Caliskan2017SemanticsDA}
A.~Caliskan, J.~Bryson, and A.~Narayanan.
\newblock Semantics derived automatically from language corpora contain
  human-like biases.
\newblock \emph{Science}, 356:\penalty0 183 -- 186, 2017.

\bibitem[Crenshaw(1989)]{Crenshaw1989DemarginalizingTI}
K.~Crenshaw.
\newblock Demarginalizing the intersection of race and sex: A black feminist
  critique of antidiscrimination doctrine, feminist theory and antiracist
  politics.
\newblock 1989.

\bibitem[Diaz et~al.(2018)Diaz, Johnson, Lazar, Piper, and
  Gergle]{Diaz2018AddressingAB}
Mark Diaz, I.~Johnson, Amanda Lazar, A.~Piper, and Darren Gergle.
\newblock Addressing age-related bias in sentiment analysis.
\newblock \emph{Proceedings of the 2018 CHI Conference on Human Factors in
  Computing Systems}, 2018.

\bibitem[England(1992)]{England1992}
Paula England.
\newblock \emph{Comparable worth: Theories and evidence}.
\newblock Routledge, 1992.

\bibitem[Foulds and Pan(2020)]{Foulds2020AnID}
J.~Foulds and Shimei Pan.
\newblock An intersectional definition of fairness.
\newblock \emph{2020 IEEE 36th International Conference on Data Engineering
  (ICDE)}, pages 1918--1921, 2020.

\bibitem[Glynn(2014)]{Glynn2014}
Sarah~Jane Glynn.
\newblock {Explaining the Gender Wage Gap}, may 2014.
\newblock URL
  \url{https://www.americanprogress.org/issues/economy/reports/2014/05/19/90039/explaining-the-gender-wage-gap/}.

\bibitem[Gonen and Goldberg(2019)]{Gonen2019LipstickOA}
H.~Gonen and Y.~Goldberg.
\newblock Lipstick on a pig: Debiasing methods cover up systematic gender
  biases in word embeddings but do not remove them.
\newblock \emph{ArXiv}, abs/1903.03862, 2019.

\bibitem[Gonz{\'a}lez~L{\'o}pez et~al.(2019)Gonz{\'a}lez~L{\'o}pez,
  Cortina~Trilla, and Rodr{\'\i}guez]{Gonzalez2019}
Mar{\'\i}a~Jos{\'e} Gonz{\'a}lez~L{\'o}pez, Clara Cortina~Trilla, and Jorge
  Rodr{\'\i}guez.
\newblock The role of gender stereotypes in hiring: a field experiment.
\newblock \emph{European Sociological Review. 2019; 35 (2): 187-204}, 2019.

\bibitem[Gr{\"o}nlund and Magnusson(2016)]{Gronlund2016}
Anne Gr{\"o}nlund and Charlotta Magnusson.
\newblock Family-friendly policies and women's wages--is there a trade-off?
  skill investments, occupational segregation and the gender pay gap in
  germany, sweden and the uk.
\newblock \emph{European Societies}, 18\penalty0 (1):\penalty0 91--113, 2016.

\bibitem[He et~al.(2020)He, Liu, Gao, and Chen]{He2020DeBERTaDB}
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and W.~Chen.
\newblock Deberta: Decoding-enhanced bert with disentangled attention.
\newblock \emph{ArXiv}, abs/2006.03654, 2020.

\bibitem[{Institute for Genealogical Studies}(2020)]{genealogical}
{Institute for Genealogical Studies}.
\newblock {US: Religious Records-Part 2}, 2020.
\newblock URL
  \url{https://www.genealogicalstudies.com/eng/courses.asp?courseID=209}.

\bibitem[Kendall(1938)]{Kendall1938}
M.~G. Kendall.
\newblock {A New Measure of Rank Correlation}.
\newblock \emph{Biometrika}, 30\penalty0 (1-2):\penalty0 81--93, 06 1938.
\newblock ISSN 0006-3444.
\newblock \doi{10.1093/biomet/30.1-2.81}.
\newblock URL \url{https://doi.org/10.1093/biomet/30.1-2.81}.

\bibitem[Kiritchenko and Mohammad(2018)]{Kiritchenko2018ExaminingGA}
Svetlana Kiritchenko and Saif~M. Mohammad.
\newblock Examining gender and race bias in two hundred sentiment analysis
  systems.
\newblock In \emph{*SEM@NAACL-HLT}, 2018.

\bibitem[Kurita et~al.(2019)Kurita, Vyas, Pareek, Black, and
  Tsvetkov]{Kurita2019MeasuringBI}
Keita Kurita, N.~Vyas, Ayush Pareek, A.~Black, and Yulia Tsvetkov.
\newblock Measuring bias in contextualized word representations.
\newblock \emph{ArXiv}, abs/1906.07337, 2019.

\bibitem[Manning et~al.(2014)Manning, Surdeanu, Bauer, Finkel, Bethard, and
  McClosky]{ManningSBFBM14}
Christopher~D. Manning, Mihai Surdeanu, John Bauer, Jenny~Rose Finkel, Steven
  Bethard, and David McClosky.
\newblock The stanford corenlp natural language processing toolkit.
\newblock In \emph{ACL (System Demonstrations)}, pages 55--60. The Association
  for Computer Linguistics, 2014.
\newblock ISBN 978-1-941643-00-6.

\bibitem[Nadeem et~al.(2020)Nadeem, Bethke, and Reddy]{Nadeem2020StereoSetMS}
Moin Nadeem, Anna Bethke, and Siva Reddy.
\newblock Stereoset: Measuring stereotypical bias in pretrained language
  models.
\newblock \emph{ArXiv}, abs/2004.09456, 2020.

\bibitem[{Pew Research}(2020)]{pew}
{Pew Research}.
\newblock {Religious Landscape Study}, 2020.
\newblock URL
  \url{https://www.pewforum.org/religious-landscape-study/religious-tradition/buddhist/}.

\bibitem[Purohit et~al.(2019)Purohit, Bagwe, Mehta, Mangaonkar, and
  George]{Purohit2019Jaro}
Jitendra Purohit, Aditya Bagwe, Rishabh Mehta, Ojaswini Mangaonkar, and
  Elizabeth George.
\newblock Natural language processing based jaro-the interviewing chatbot.
\newblock In \emph{2019 3rd International Conference on Computing Methodologies
  and Communication (ICCMC)}, pages 134--136, 2019.
\newblock \doi{10.1109/ICCMC.2019.8819708}.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{radford2019language}
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.

\bibitem[Rudinger et~al.(2017)Rudinger, May, and Durme]{Rudinger2017SocialBI}
Rachel Rudinger, Chandler May, and Benjamin~Van Durme.
\newblock Social bias in elicited natural language inferences.
\newblock In \emph{EthNLP@EACL}, 2017.

\bibitem[Sheng et~al.(2019)Sheng, Chang, Natarajan, and Peng]{Sheng2019TheWW}
Emily Sheng, Kai-Wei Chang, P.~Natarajan, and Nanyun Peng.
\newblock The woman worked as a babysitter: On biases in language generation.
\newblock \emph{ArXiv}, abs/1909.01326, 2019.

\bibitem[Similarweb()]{similarweb}
Similarweb.
\newblock Reddit.com traffic, ranking \& marketing analytics.
\newblock URL \url{https://www.similarweb.com/website/reddit.com/}.

\bibitem[Solaiman et~al.(2019)Solaiman, Brundage, Clark, Askell, Herbert-Voss,
  Wu, Radford, and Wang]{Solaiman2019ReleaseSA}
Irene Solaiman, Miles Brundage, J.~Clark, Amanda Askell, Ariel Herbert-Voss,
  Jeff Wu, Alec Radford, and J.~Wang.
\newblock Release strategies and the social impacts of language models.
\newblock \emph{ArXiv}, abs/1908.09203, 2019.

\bibitem[Tan and Celis(2019)]{Tan2019AssessingSA}
Y.~Tan and L.~Celis.
\newblock Assessing social and intersectional biases in contextualized word
  representations.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[{US Labor Bureau of Statistics}(2019)]{BLS}
{US Labor Bureau of Statistics}.
\newblock {Employed peons by detailed occupation, sex, race, and Hispanic or
  Latino ethnicity}, 2019.
\newblock URL \url{https://www.bls.gov/cps/cpsaat11.htm}.

\bibitem[Waldman and McEaddy(1974)]{Waldman1974}
Elizabeth Waldman and Beverly~J McEaddy.
\newblock Where women work-an analysis by industry and occupation.
\newblock \emph{Monthly Lab. Rev.}, 97:\penalty0 3, 1974.

\bibitem[Wang et~al.(2018)Wang, Singh, Michael, Hill, Levy, and
  Bowman]{Wang2018GLUEAM}
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and
  Samuel~R. Bowman.
\newblock Glue: A multi-task benchmark and analysis platform for natural
  language understanding.
\newblock In \emph{BlackboxNLP@EMNLP}, 2018.

\bibitem[Wang et~al.(2019)Wang, Pruksachatkun, Nangia, Singh, Michael, Hill,
  Levy, and Bowman]{Wang2019SuperGLUEAS}
Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael,
  Felix Hill, Omer Levy, and Samuel~R. Bowman.
\newblock Superglue: A stickier benchmark for general-purpose language
  understanding systems.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[{Wikipedia}(2021)]{wikipedia}
{Wikipedia}.
\newblock {List of most popular names}, 2021.
\newblock URL
  \url{https://en.wikipedia.org/wiki/List_of_most_popular_given_names}.

\bibitem[Yang et~al.(2019)Yang, Dai, Yang, Carbonell, Salakhutdinov, and
  Le]{Yang2019XLNetGA}
Z.~Yang, Zihang Dai, Yiming Yang, J.~Carbonell, R.~Salakhutdinov, and Quoc~V.
  Le.
\newblock Xlnet: Generalized autoregressive pretraining for language
  understanding.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Zhao et~al.(2018)Zhao, Zhou, Li, Wang, and Chang]{Zhao2018LearningGW}
Jieyu Zhao, Yichao Zhou, Z.~Li, W.~Wang, and Kai-Wei Chang.
\newblock Learning gender-neutral word embeddings.
\newblock In \emph{EMNLP}, 2018.

\bibitem[Zhao et~al.(2019)Zhao, Wang, Yatskar, Cotterell, Ordonez, and
  Chang]{Zhao2019GenderBI}
Jieyu Zhao, Tianlu Wang, Mark Yatskar, Ryan Cotterell, Vicente Ordonez, and
  Kai-Wei Chang.
\newblock Gender bias in contextualized word embeddings.
\newblock \emph{ArXiv}, abs/1904.03310, 2019.

\end{thebibliography}
