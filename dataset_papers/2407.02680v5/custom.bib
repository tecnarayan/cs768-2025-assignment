@misc{chen2021evaluating,
      title={Evaluating Large Language Models Trained on Code}, 
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
      year={2021},
      eprint={2107.03374},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{bm25,
author = {Robertson, Stephen and Walker, Steve and Jones, Susan and Hancock-Beaulieu, Micheline and Gatford, Mike},
year = {1994},
month = {01},
pages = {0-},
title = {Okapi at TREC-3.}
}

@misc{Syzkaller,
  title = {Syzkaller},
  howpublished = {\url{https://github.com/google/syzkaller}},
}

@misc{Linux,
  title = {Linux},
  howpublished = {\url{https://github.com/torvalds/linux}},
}

@misc{BugLink,
  title = {Syzkaller KASAN use-after-free Bug},
  howpublished = {\url{https://syzkaller.appspot.com/bug?extid=822d1359297e2694f873}},
}


@misc{amazon-2023-codewhisperer,
  author = {Amazon},
  title = {Amazon CodeWhisperer: Build applications faster and more securely with your AI coding companion},
  howpublished = "\url{https://aws.amazon.com/codewhisperer/}",
  year = {2023}
}

@misc{github-2021-copilot,
  author = {GitHub},
  title = {GitHub Copilot: Your AI Pair Programmer},
  howpublished = "\url{https://copilot.github.com/}",
  year = {2021}
}


@inproceedings{Schumilo2017kAFLHF,
  title={kAFL: Hardware-Assisted Feedback Fuzzing for OS Kernels},
  author={Sergej Schumilo and Cornelius Aschermann and Robert Gawlik and Sebastian Schinzel and Thorsten Holz},
  booktitle={USENIX Security Symposium},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:12778185}
}

@misc{CVEDetails,
  title = {CVEDetails},
  howpublished = {\url{https://www.cvedetails.com/product/47/Linux-Linux-Kernel.html?vendor_id=33}},
}


@article{Kim2020HFLHF,
  title={HFL: Hybrid Fuzzing on the Linux Kernel},
  author={Kyungtae Kim and Dae R. Jeong and Chung Hwan Kim and Yeongjin Jang and Insik Shin and Byoungyoung Lee},
  journal={Proceedings 2020 Network and Distributed System Security Symposium},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:211267895}
}

@misc{tian2024debugbench,
      title={DebugBench: Evaluating Debugging Capability of Large Language Models}, 
      author={Runchu Tian and Yining Ye and Yujia Qin and Xin Cong and Yankai Lin and Yinxu Pan and Yesai Wu and Zhiyuan Liu and Maosong Sun},
      year={2024},
      eprint={2401.04621},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@article{Ott_2022,
   title={Mapping global dynamics of benchmark creation and saturation in artificial intelligence},
   volume={13},
   ISSN={2041-1723},
   url={http://dx.doi.org/10.1038/s41467-022-34591-0},
   DOI={10.1038/s41467-022-34591-0},
   number={1},
   journal={Nature Communications},
   publisher={Springer Science and Business Media LLC},
   author={Ott, Simon and Barbosa-Silva, Adriano and Blagec, Kathrin and Brauner, Jan and Samwald, Matthias},
   year={2022},
   month=nov }


@article{hendrycksapps2021,
  title={Measuring Coding Challenge Competence With APPS},
  author={Dan Hendrycks and Steven Basart and Saurav Kadavath and Mantas Mazeika and Akul Arora and Ethan Guo and Collin Burns and Samir Puranik and Horace He and Dawn Song and Jacob Steinhardt},
  journal={NeurIPS},
  year={2021}
}

@misc{liu2023code,
      title={Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation}, 
      author={Jiawei Liu and Chunqiu Steven Xia and Yuyao Wang and Lingming Zhang},
      year={2023},
      eprint={2305.01210},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{Android,
  title = {Android},
  howpublished = {\url{https://blog.google/products/android/io22-multideviceworld}}
}

@misc{jimenez2024swebench,
      title={SWE-bench: Can Language Models Resolve Real-World GitHub Issues?}, 
      author={Carlos E. Jimenez and John Yang and Alexander Wettig and Shunyu Yao and Kexin Pei and Ofir Press and Karthik Narasimhan},
      year={2024},
      eprint={2310.06770},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{chakraborty2018entropy,
      title={Entropy Guided Spectrum Based Bug Localization Using Statistical Language Model}, 
      author={Saikat Chakraborty and Yujian Li and Matt Irvine and Ripon Saha and Baishakhi Ray},
      year={2018},
      eprint={1802.06947},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{li2022automating,
      title={Automating Code Review Activities by Large-Scale Pre-training}, 
      author={Zhiyu Li and Shuai Lu and Daya Guo and Nan Duan and Shailesh Jannu and Grant Jenks and Deep Majumder and Jared Green and Alexey Svyatkovskiy and Shengyu Fu and Neel Sundaresan},
      year={2022},
      eprint={2203.09095},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{kang2023large,
      title={Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction}, 
      author={Sungmin Kang and Juyeon Yoon and Shin Yoo},
      year={2023},
      eprint={2209.11515},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{xia2024fuzz4all,
      title={Fuzz4All: Universal Fuzzing with Large Language Models}, 
      author={Chunqiu Steven Xia and Matteo Paltenghi and Jia Le Tian and Michael Pradel and Lingming Zhang},
      year={2024},
      eprint={2308.04748},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{wang2024software,
      title={Software Testing with Large Language Models: Survey, Landscape, and Vision}, 
      author={Junjie Wang and Yuchao Huang and Chunyang Chen and Zhe Liu and Song Wang and Qing Wang},
      year={2024},
      eprint={2307.07221},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{liu2023commitbart,
      title={CommitBART: A Large Pre-trained Model for GitHub Commits}, 
      author={Shangqing Liu and Yanzhou Li and Xiaofei Xie and Yang Liu},
      year={2023},
      eprint={2208.08100},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{gao2022program,
      title={Program Repair}, 
      author={Xiang Gao and Yannic Noller and Abhik Roychoudhury},
      year={2022},
      eprint={2211.12787},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{motwani2023better,
      title={Better Automatic Program Repair by Using Bug Reports and Tests Together}, 
      author={Manish Motwani and Yuriy Brun},
      year={2023},
      eprint={2011.08340},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{allamanis2018learning,
      title={Learning to Represent Programs with Graphs}, 
      author={Miltiadis Allamanis and Marc Brockschmidt and Mahmoud Khademi},
      year={2018},
      eprint={1711.00740},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{dinh2023large,
      title={Large Language Models of Code Fail at Completing Code with Potential Bugs}, 
      author={Tuan Dinh and Jinman Zhao and Samson Tan and Renato Negrinho and Leonard Lausen and Sheng Zha and George Karypis},
      year={2023},
      eprint={2306.03438},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Monperrus_2018,
   title={Automatic Software Repair: A Bibliography},
   volume={51},
   ISSN={1557-7341},
   url={http://dx.doi.org/10.1145/3105906},
   DOI={10.1145/3105906},
   number={1},
   journal={ACM Computing Surveys},
   publisher={Association for Computing Machinery (ACM)},
   author={Monperrus, Martin},
   year={2018},
   month=jan, pages={1–24} }

@article{Gupta_Pal_Kanade_Shevade_2017, title={DeepFix: Fixing Common C Language Errors by Deep Learning}, volume={31}, url={https://ojs.aaai.org/index.php/AAAI/article/view/10742}, DOI={10.1609/aaai.v31i1.10742}, abstractNote={ &lt;p&gt; The problem of automatically fixing programming errors is a very active research topic in software engineering. This is a challenging problem as fixing even a single error may require analysis of the entire program. In practice, a number of errors arise due to programmer’s inexperience with the programming language or lack of attention to detail. We call these common programming errors. These are analogous to grammatical errors in natural languages. Compilers detect such errors, but their error messages are usually inaccurate. In this work, we present an end-to-end solution, called DeepFix, that can fix multiple such errors in a program without relying on any external tool to locate or fix them. At the heart of DeepFix is a multi-layered sequence-to-sequence neural network with attention which is trained to predict erroneous program locations along with the required correct statements. On a set of 6971 erroneous C programs written by students for 93 programming tasks, DeepFix could fix 1881 (27%) programs completely and 1338 (19%) programs partially. &lt;/p&gt; }, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Gupta, Rahul and Pal, Soham and Kanade, Aditya and Shevade, Shirish}, year={2017}, month={Feb.} }

@article{10.1145/3345628,
author = {Kim, Yunho and Mun, Seokhyeon and Yoo, Shin and Kim, Moonzoo},
title = {Precise Learn-to-Rank Fault Localization Using Dynamic and Static Features of Target Programs},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3345628},
doi = {10.1145/3345628},
abstract = {Finding the root cause of a bug requires a significant effort from developers. Automated fault localization techniques seek to reduce this cost by computing the suspiciousness scores (i.e., the likelihood of program entities being faulty). Existing techniques have been developed by utilizing input features of specific types for the computation of suspiciousness scores, such as program spectrum or mutation analysis results. This article presents a novel learn-to-rank fault localization technique called PRecise machINe-learning-based fault loCalization tEchnique (PRINCE). PRINCE uses genetic programming (GP) to combine multiple sets of localization input features that have been studied separately until now. For dynamic features, PRINCE encompasses both Spectrum Based Fault Localization (SBFL) and Mutation Based Fault Localization (MBFL) techniques. It also uses static features, such as dependency information and structural complexity of program entities. All such information is used by GP to train a ranking model for fault localization. The empirical evaluation on 65 real-world faults from CoREBench, 84 artificial faults from SIR, and 310 real-world faults from Defects4J shows that PRINCE outperforms the state-of-the-art SBFL, MBFL, and learn-to-rank techniques significantly. PRINCE localizes a fault after reviewing 2.4\% of the executed statements on average (4.2 and 3.0 times more precise than the best of the compared SBFL and MBFL techniques, respectively). Also, PRINCE ranks 52.9\% of the target faults within the top ten suspicious statements.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {oct},
articleno = {23},
numpages = {34},
keywords = {Fault localization, machine learning, mutation analysis, source file characteristics}
}

@inproceedings{inproceedings,
author = {Mu, Dongliang and Wu, Yuhang and Chen, Yueqi and Lin, Zhenpeng and Yu, Chensheng and Xing, Xinyu and Wang, Gang},
year = {2022},
month = {01},
pages = {},
title = {An In-depth Analysis of Duplicated Linux Kernel Bug Reports},
doi = {10.14722/ndss.2022.24159}
}

@misc{WannaCry,
  title = {WannaCry},
  howpublished = {\url{https://en.wikipedia.org/wiki/WannaCry_ransomware_attack}},
}

@misc{llama3,
  title = {Llama3},
  howpublished = {\url{https://github.com/meta-llama/llama3}},
}

@misc{DirtyCOW,
  title = {Dirty COW (CVE-2016-5195)},
  howpublished = {\url{https://dirtycow.ninja}},
}

@misc{BleedingTooth,
  title = {Google researcher found bleedingtooth flaws in linux bluetooth},
  howpublished = {\url{https://securityaffairs.co/wordpress/109500/hacking/bluetooth-bleedingtooth-vulnerabilities.html}},
}

@misc{Trinity,
  title = {Trinity: Linux system call fuzzer.},
  howpublished = {\url{https://github.com/kernelslacker/trinity}},
}

@inproceedings{a4a3ef9169b9420dbccf36e3ddb42b7a,
title = "An In-depth Analysis of Duplicated Linux Kernel Bug Reports",
author = "Dongliang Mu and Yuhang Wu and Yueqi Chen and Zhenpeng Lin and Chensheng Yu and Xinyu Xing and Gang Wang",
note = "Publisher Copyright: {\textcopyright} 2022 29th Annual Network and Distributed System Security Symposium, NDSS 2022. All Rights Reserved.; 29th Annual Network and Distributed System Security Symposium, NDSS 2022 ; Conference date: 24-04-2022 Through 28-04-2022",
year = "2022",
doi = "10.14722/ndss.2022.24159",
language = "English (US)",
series = "29th Annual Network and Distributed System Security Symposium, NDSS 2022",
publisher = "The Internet Society",
booktitle = "29th Annual Network and Distributed System Security Symposium, NDSS 2022",
}

@inproceedings{10.5555/3489212.3489226,
author = {Blazytko, Tim and Schl\"{o}gel, Moritz and Aschermann, Cornelius and Abbasi, Ali and Frank, Joel and W\"{o}rner, Simon and Holz, Thorsten},
title = {AURORA: statistical crash analysis for automated root cause explanation},
year = {2020},
isbn = {978-1-939133-17-5},
publisher = {USENIX Association},
address = {USA},
booktitle = {Proceedings of the 29th USENIX Conference on Security Symposium},
articleno = {14},
numpages = {18},
series = {SEC'20}
}

@misc{FaultInjection,
  title = {FaultInjection},
  howpublished = {\url{https://www.kernel.org/doc/html/latest/fault-injection/fault-injection.html}}
}

@misc{AddressSanitizer,
  title = {Kernel address sanitizer},
  howpublished = {\url{https://www.kernel.org/doc/html/latest/dev-tools/kasan.html}}
}


@misc{RV63,
  title = {Linux 6.3},
  howpublished = {\url{https://lwn.net/Articles/929582/}}
}


@misc{ConcurrencySanitizer,
  title = {The kernel concurrency sanitizer (kcsan)},
  howpublished = {\url{https://www.kernel.org/doc/html/latest/dev-tools/kcsan.html}},
}

@inproceedings{Serebryany2012AddressSanitizerAF,
  title={AddressSanitizer: A Fast Address Sanity Checker},
  author={Kostya Serebryany and Derek Bruening and Alexander Potapenko and Dmitriy Vyukov},
  booktitle={USENIX Annual Technical Conference},
  year={2012},
  url={https://api.semanticscholar.org/CorpusID:11024896}
}

@INPROCEEDINGS{7054186,
  author={Stepanov, Evgeniy and Serebryany, Konstantin},
  booktitle={2015 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)}, 
  title={MemorySanitizer: Fast detector of uninitialized memory use in C++}, 
  year={2015},
  volume={},
  number={},
  pages={46-55},
  keywords={Instruments;Computer bugs;Detectors;Optimization;Vectors;Instruction sets;Google},
  doi={10.1109/CGO.2015.7054186}}

@inproceedings{feng-etal-2020-codebert,
    title = "{C}ode{BERT}: A Pre-Trained Model for Programming and Natural Languages",
    author = "Feng, Zhangyin  and
      Guo, Daya  and
      Tang, Duyu  and
      Duan, Nan  and
      Feng, Xiaocheng  and
      Gong, Ming  and
      Shou, Linjun  and
      Qin, Bing  and
      Liu, Ting  and
      Jiang, Daxin  and
      Zhou, Ming",
    editor = "Cohn, Trevor  and
      He, Yulan  and
      Liu, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.139",
    doi = "10.18653/v1/2020.findings-emnlp.139",
    pages = "1536--1547",
    abstract = "We present CodeBERT, a bimodal pre-trained model for programming language (PL) and natural language (NL). CodeBERT learns general-purpose representations that support downstream NL-PL applications such as natural language code search, code documentation generation, etc. We develop CodeBERT with Transformer-based neural architecture, and train it with a hybrid objective function that incorporates the pre-training task of replaced token detection, which is to detect plausible alternatives sampled from generators. This enables us to utilize both {``}bimodal{''} data of NL-PL pairs and {``}unimodal data, where the former provides input tokens for model training while the latter helps to learn better generators. We evaluate CodeBERT on two NL-PL applications by fine-tuning model parameters. Results show that CodeBERT achieves state-of-the-art performance on both natural language code search and code documentation generation. Furthermore, to investigate what type of knowledge is learned in CodeBERT, we construct a dataset for NL-PL probing, and evaluate in a zero-shot setting where parameters of pre-trained models are fixed. Results show that CodeBERT performs better than previous pre-trained models on NLPL probing.",
}

@inproceedings{hindle-2012-naturalness,
 author = {Hindle, Abram and Barr, Earl T. and Su, Zhendong and Gabel, Mark and Devanbu, Premkumar},
 booktitle = {Proceedings of the 34th International Conference on Software Engineering},
 isbn = {9781467310673},
 location = {Zurich, Switzerland},
 numpages = {11},
 pages = {837–847},
 publisher = {IEEE Press},
 series = {ICSE '12},
 title = {On the Naturalness of Software},
 year = {2012}
}

@article{bavarian2022efficient,
  title={Efficient training of language models to fill in the middle},
  author={Bavarian, Mohammad and Jun, Heewoo and Tezak, Nikolas and Schulman, John and McLeavey, Christine and Tworek, Jerry and Chen, Mark},
  journal={arXiv preprint arXiv:2207.14255},
  url={https://arxiv.org/abs/2207.14255},
  year={2022}
}

@article{robertson2009probabilistic,
  title={The probabilistic relevance framework: BM25 and beyond},
  author={Robertson, Stephen and Zaragoza, Hugo and others},
  journal={Foundations and Trends{\textregistered} in Information Retrieval},
  volume={3},
  number={4},
  pages={333--389},
  year={2009},
  publisher={Now Publishers, Inc.}
}

@article{kocetkov2022stack,
  title={The Stack: 3 TB of permissively licensed source code},
  author={Kocetkov, Denis and Li, Raymond and Allal, Loubna Ben and Li, Jia and Mou, Chenghao and Ferrandis, Carlos Mu{\~n}oz and Jernite, Yacine and Mitchell, Margaret and Hughes, Sean and Wolf, Thomas and others},
  journal={arXiv preprint arXiv:2211.15533},
  url={https://arxiv.org/abs/2211.15533},
  year={2022}
}

@inproceedings{xu2022systematic,
author = {Xu, Frank F. and Alon, Uri and Neubig, Graham and Hellendoorn, Vincent Josua},
title = {A Systematic Evaluation of Large Language Models of Code},
year = {2022},
isbn = {9781450392730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3520312.3534862},
doi = {10.1145/3520312.3534862},
booktitle = {Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming},
pages = {1–10},
numpages = {10},
keywords = {evaluation, pretraining, code generation, code language model, open-source},
location = {San Diego, CA, USA},
series = {MAPS 2022}
}



@article{zhang2023repocoder,
  title={Repocoder: Repository-level code completion through iterative retrieval and generation},
  author={Zhang, Fengji and Chen, Bei and Zhang, Yue and Liu, Jin and Zan, Daoguang and Mao, Yi and Lou, Jian-Guang and Chen, Weizhu},
  journal={arXiv preprint arXiv:2303.12570},
  url={https://arxiv.org/abs/2303.12570},
  year={2023}
}

@article{li2023starcoder,
  title={StarCoder: may the source be with you!},
  author={Li, Raymond and Allal, Loubna Ben and Zi, Yangtian and Muennighoff, Niklas and Kocetkov, Denis and Mou, Chenghao and Marone, Marc and Akiki, Christopher and Li, Jia and Chim, Jenny and others},
  journal={arXiv preprint arXiv:2305.06161},
  url={https://arxiv.org/abs/2305.06161},
  year={2023}
}

@article{jaccard1912distribution,
  title={The distribution of the flora in the alpine zone. 1},
  author={Jaccard, Paul},
  journal={New phytologist},
  volume={11},
  number={2},
  pages={37--50},
  year={1912},
  publisher={Wiley Online Library}
}

@article{nijkamp2023codegen2,
  title={CodeGen2: Lessons for Training LLMs on Programming and Natural Languages},
  author={Nijkamp, Erik and Hayashi, Hiroaki and Xiong, Caiming and Savarese, Silvio and Zhou, Yingbo},
  journal={arXiv preprint arXiv:2305.02309},
  url = {https://arxiv.org/abs/2305.02309},
  year={2023}
}

@article{allal2023santacoder,
  title={SantaCoder: don't reach for the stars!},
  author={Allal, Loubna Ben and Li, Raymond and Kocetkov, Denis and Mou, Chenghao and Akiki, Christopher and Ferrandis, Carlos Munoz and Muennighoff, Niklas and Mishra, Mayank and Gu, Alex and Dey, Manan and others},
  journal={arXiv preprint arXiv:2301.03988},
  url = {https://arxiv.org/abs/2301.03988},
  year={2023}
}

@inproceedings{nijkamp2022codegen,
title={CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis},
author={Erik Nijkamp and Bo Pang and Hiroaki Hayashi and Lifu Tu and Huan Wang and Yingbo Zhou and Silvio Savarese and Caiming Xiong},
booktitle={International Conference on Learning Representations},
year={2023},
url={https://openreview.net/forum?id=iaYcJKpY2B_}
}

@inproceedings{pei2023better,
author = {Pei, Hengzhi and Zhao, Jinman and Lausen, Leonard and Zha, Sheng and Karypis, George},
title = {Better Context Makes Better Code Language Models: A Case Study on Function Call Argument Completion},
year = {2023},
isbn = {978-1-57735-880-0},
publisher = {AAAI Press},
url = {https://doi.org/10.1609/aaai.v37i4.25653},
doi = {10.1609/aaai.v37i4.25653},
booktitle = {Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence},
articleno = {584},
numpages = {9},
series = {AAAI'23/IAAI'23/EAAI'23}
}



@article{li2022competition,
 author = {Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{\'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Lago, Agustin Dal and others},
 journal = {ArXiv preprint},
 title = {Competition-level code generation with alphacode},
 url = {https://arxiv.org/abs/2203.07814},
 volume = {abs/2203.07814},
 year = {2022}
}

@article{austin2021program,
 author = {Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
 journal = {ArXiv preprint},
 title = {Program synthesis with large language models},
 url = {https://arxiv.org/abs/2108.07732},
 volume = {abs/2108.07732},
 year = {2021}
}


@inproceedings{
fried2022incoder,
title={InCoder: A Generative Model for Code Infilling and Synthesis},
author={Daniel Fried and Armen Aghajanyan and Jessy Lin and Sida Wang and Eric Wallace and Freda Shi and Ruiqi Zhong and Scott Yih and Luke Zettlemoyer and Mike Lewis},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=hQwb-lbM6EL}
}

@article{barke2022grounded,
 author = {Barke, Shraddha and James, Michael B and Polikarpova, Nadia},
 journal = {ArXiv preprint},
 title = {Grounded Copilot: How Programmers Interact with Code-Generating Models},
 url = {https://arxiv.org/abs/2206.15000},
 volume = {abs/2206.15000},
 year = {2022}
}

@article{radford2019gpt2,
 author = {Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
journal = {OpenAI preprint},
 title = {Language Models are Unsupervised Multitask Learners},
 url = {https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf},
 year = {2019}
}

@inproceedings{brown2020gpt3,
 author = {Tom B. Brown and
Benjamin Mann and
Nick Ryder and
Melanie Subbiah and
Jared Kaplan and
Prafulla Dhariwal and
Arvind Neelakantan and
Pranav Shyam and
Girish Sastry and
Amanda Askell and
Sandhini Agarwal and
Ariel Herbert{-}Voss and
Gretchen Krueger and
Tom Henighan and
Rewon Child and
Aditya Ramesh and
Daniel M. Ziegler and
Jeffrey Wu and
Clemens Winter and
Christopher Hesse and
Mark Chen and
Eric Sigler and
Mateusz Litwin and
Scott Gray and
Benjamin Chess and
Jack Clark and
Christopher Berner and
Sam McCandlish and
Alec Radford and
Ilya Sutskever and
Dario Amodei},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/nips/BrownMRSKDNSSAA20.bib},
 booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
on Neural Information Processing Systems 2020, NeurIPS 2020, December
6-12, 2020, virtual},
 editor = {Hugo Larochelle and
Marc'Aurelio Ranzato and
Raia Hadsell and
Maria{-}Florina Balcan and
Hsuan{-}Tien Lin},
 timestamp = {Tue, 19 Jan 2021 00:00:00 +0100},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
 year = {2020}
}

@software{gpt-neo,
 author = {Black, Sid and
Gao, Leo and
Wang, Phil and
Leahy, Connor and
Biderman, Stella},
 doi = {10.5281/zenodo.5297715},
 publisher = {Zenodo},
 title = {{GPT-Neo: Large Scale Autoregressive Language
Modeling with Mesh-Tensorflow}},
 url = {https://doi.org/10.5281/zenodo.5297715},
 version = {1.0},
 year = {2021}
}

@misc{gpt-j,
 author = {Wang, Ben and Komatsuzaki, Aran},
 howpublished = {\url{https://github.com/kingoflolz/mesh-transformer-jax}},
 title = {{GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model}},
 year = {2021}
}

@article{wang2021cocosum,
 author = {Wang, Yanlin and Shi, Ensheng and Du, Lun and Yang, Xiaodi and Hu, Yuxuan and Han, Shi and Zhang, Hongyu and Zhang, Dongmei},
 journal = {ArXiv preprint},
 title = {CoCoSum: Contextual Code Summarization with Multi-Relational Graph Neural Network},
 url = {https://arxiv.org/abs/2107.01933},
 volume = {abs/2107.01933},
 year = {2021}
}

@inproceedings{haque2020improved,
 author = {Haque, Sakib and LeClair, Alexander and Wu, Lingfei and McMillan, Collin},
 booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
 pages = {300--310},
 title = {Improved automatic summarization of subroutines via attention to file context},
 year = {2020}
}

@inproceedings{holmes2005using,
 author = {Holmes, Reid and Murphy, Gail C},
 booktitle = {Proceedings of the 27th international conference on Software engineering},
 pages = {117--125},
 title = {Using structural context to recommend source code examples},
 year = {2005}
}

@article{black2021gpt,
    author = {Black, Sid and
    Gao, Leo and
    Wang, Phil and
    Leahy, Connor and
    Biderman, Stella},
    doi = {10.5281/zenodo.5297715},
    publisher = {Zenodo},
    title = {{GPT-Neo: Large Scale Autoregressive Language
              Modeling with Mesh-Tensorflow}},
    url = {https://doi.org/10.5281/zenodo.5297715},
    version = {1.0},
    year = {2021}
}

@inproceedings{black2022gpt,
 address = {virtual+Dublin},
 author = {Black, Sidney  and
Biderman, Stella  and
Hallahan, Eric  and
Anthony, Quentin  and
Gao, Leo  and
Golding, Laurence  and
He, Horace  and
Leahy, Connor  and
McDonell, Kyle  and
Phang, Jason  and
Pieler, Michael  and
Prashanth, Usvsn Sai  and
Purohit, Shivanshu  and
Reynolds, Laria  and
Tow, Jonathan  and
Wang, Ben  and
Weinbach, Samuel},
 booktitle = {Proceedings of BigScience Episode {\#}5 -- Workshop on Challenges {\&} Perspectives in Creating Large Language Models},
 doi = {10.18653/v1/2022.bigscience-1.9},
 pages = {95--136},
 publisher = {Association for Computational Linguistics},
 title = {{GPT}-{N}eo{X}-20{B}: An Open-Source Autoregressive Language Model},
 url = {https://aclanthology.org/2022.bigscience-1.9},
 year = {2022}
}

@article{zhou2022doccoder,
 author = {Zhou, Shuyan and Alon, Uri and Xu, Frank F and JIang, Zhengbao and Neubig, Graham},
 journal = {ArXiv preprint},
 title = {DocCoder: Generating Code by Retrieving and Reading Docs},
 url = {https://arxiv.org/abs/2207.05987},
 volume = {abs/2207.05987},
 year = {2022}
}

@inproceedings{shrivastava2022repository,
  title = 	 {Repository-Level Prompt Generation for Large Language Models of Code},
  author =       {Shrivastava, Disha and Larochelle, Hugo and Tarlow, Daniel},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {31693--31715},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/shrivastava23a/shrivastava23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/shrivastava23a.html},
}

@article{lherondelle2022topical,
 author = {Lherondelle, Agathe and Satsangi, Yash and Silavong, Fran and Eloul, Shaltiel and Moran, Sean},
 journal = {ArXiv preprint},
 title = {Topical: Learning Repository Embeddings from Source Code using Attention},
 url = {https://arxiv.org/abs/2208.09495},
 volume = {abs/2208.09495},
 year = {2022}
}

@article{rosson1996reuse,
 author = {Rosson, Mary Beth and Carroll, John M},
 journal = {ACM Transactions on Computer-Human Interaction (TOCHI)},
 number = {3},
 pages = {219--253},
 publisher = {ACM New York, NY, USA},
 title = {The reuse of uses in Smalltalk programming},
 volume = {3},
 year = {1996}
}

@inproceedings{ye2002supporting,
 author = {Ye, Yunwen and Fischer, Gerhard},
 booktitle = {Proceedings of the 24th international conference on Software engineering},
 pages = {513--523},
 title = {Supporting reuse by delivering task-relevant and personalized information},
 year = {2002}
}

@article{ye2000integrating,
 author = {Ye, Yunwen and Fischer, Gerhard and Reeves, Brent},
 journal = {ACM SIGSOFT Software Engineering Notes},
 number = {6},
 pages = {60--68},
 publisher = {ACM New York, NY, USA},
 title = {Integrating active information delivery and reuse repository systems},
 volume = {25},
 year = {2000}
}

@inproceedings{henninger1991retrieving,
 author = {Henninger, Scott},
 booktitle = {Proceedings of the 14th annual international ACM SIGIR conference on Research and development in information retrieval},
 pages = {251--260},
 title = {Retrieving software objects in an example-based programming environment},
 year = {1991}
}

@inproceedings{hill2004automatic,
 author = {Hill, Rosco and Rideout, Joe},
 booktitle = {Proceedings. 19th International Conference on Automated Software Engineering, 2004.},
 organization = {IEEE},
 pages = {228--235},
 title = {Automatic method completion},
 year = {2004}
}

@inproceedings{cubranic2003hipikat,
 author = {Cubranic, Davor and Murphy, Gail C},
 booktitle = {25th International Conference on Software Engineering, 2003. Proceedings.},
 organization = {IEEE},
 pages = {408--418},
 title = {Hipikat: Recommending pertinent software development artifacts},
 year = {2003}
}

@inproceedings{inoue2003component,
 author = {Inoue, Katsuro and Yokomori, Reishi and Fujiwara, Hikaru and Yamamoto, Tetsuo and Matsushita, Makoto and Kusumoto, Shinji},
 booktitle = {25th International Conference on Software Engineering, 2003. Proceedings.},
 organization = {IEEE},
 pages = {14--24},
 title = {Component rank: Relative significance rank for software component search},
 year = {2003}
}

@inproceedings{michail2001codeweb,
 author = {Michail, Amir},
 booktitle = {Proceedings of the 23rd International Conference on Software Engineering. ICSE 2001},
 organization = {IEEE},
 pages = {827--828},
 title = {CodeWeb: Data mining library reuse patterns},
 year = {2001}
}

@misc{modular_programming_wiki,
 author = {Wikipedia},
 howpublished = {\url{https://en.wikipedia.org/wiki/Modular_programming}},
 title = {Modular Programming},
 year = {2022}
}

@article{knuth1984literate,
 address = {USA},
 author = {Knuth, Donald E.},
 doi = {10.1093/comjnl/27.2.97},
 issn = {0010-4620},
 issue_date = {May 1984},
 journal = {Comput. J.},
 number = {2},
 numpages = {15},
 pages = {97–111},
 publisher = {Oxford University Press, Inc.},
 title = {Literate Programming},
 url = {https://doi.org/10.1093/comjnl/27.2.97},
 volume = {27},
 year = {1984}
}

@article{abdelaziz2021graph4code,
 author = {Abdelaziz, Ibrahim and Dolby, Julian and  McCusker, James P and Srinivas, Kavitha},
 journal = {The Eleventh International Conference on Knowledge Capture (K-CAP)},
 title = {A Toolkit for Generating Code Knowledge Graphs},
 year = {2021}
}

@inproceedings{abdelaziz2022blanca,
 author = {Ibrahim Abdelaziz and Julian Dolby and Jamie McCusker and Kavitha Srinivas},
 booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2022)},
 title = {Can Machines Read Coding Manuals Yet? -- A Benchmark for Building Better Language Models for Code Understanding},
 year = {2022}
}

@article{ferrante1987pdg,
 address = {New York, NY, USA},
 author = {Ferrante, Jeanne and Ottenstein, Karl J. and Warren, Joe D.},
 doi = {10.1145/24039.24041},
 issn = {0164-0925},
 issue_date = {July 1987},
 journal = {ACM Trans. Program. Lang. Syst.},
 number = {3},
 numpages = {31},
 pages = {319–349},
 publisher = {Association for Computing Machinery},
 title = {The Program Dependence Graph and Its Use in Optimization},
 url = {https://doi.org/10.1145/24039.24041},
 volume = {9},
 year = {1987}
}

@inproceedings{yamaguchi2014cpg,
 author = {Yamaguchi, Fabian and Golde, Nico and Arp, Daniel and Rieck, Konrad},
 booktitle = {2014 IEEE Symposium on Security and Privacy},
 doi = {10.1109/SP.2014.44},
 number = {},
 pages = {590-604},
 title = {Modeling and Discovering Vulnerabilities with Code Property Graphs},
 volume = {},
 year = {2014}
}
@inproceedings{zhou2019devign,
     author = {Zhou, Yaqin and Liu, Shangqing and Siow, Jingkai and Du, Xiaoning and Liu, Yang},
     booktitle = {Advances in Neural Information Processing Systems},
     editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
     pages = {10197--10207},
     publisher = {Curran Associates, Inc.},
     title = {Devign: Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks},
     url = {https://proceedings.neurips.cc/paper/2019/file/49265d2447bc3bbfe9e76306ce40a31f-Paper.pdf},
     volume = {32},
     year = {2019}
}
@article{tufano2019empirical,
  title={An empirical study on learning bug-fixing patches in the wild via neural machine translation},
  author={Tufano, Michele and Watson, Cody and Bavota, Gabriele and Penta, Massimiliano Di and White, Martin and Poshyvanyk, Denys},
  journal={ACM Transactions on Software Engineering and Methodology (TOSEM)},
  volume={28},
  number={4},
  pages={1--29},
  year={2019},
  publisher={ACM New York, NY, USA},
  url = {https://doi.org/10.1145/3340544},
  doi = {10.1145/3340544},
}
@article{husain2019codesearchnet,
  title={Codesearchnet challenge: Evaluating the state of semantic code search},
  author={Husain, Hamel and Wu, Ho-Hsiang and Gazit, Tiferet and Allamanis, Miltiadis and Brockschmidt, Marc},
  journal={arXiv preprint arXiv:1909.09436},
  year={2019},
  url={https://arxiv.org/abs/1909.09436},
}
@inproceedings{guo2020graphcodebert,
  title={GraphCodeBERT: Pre-training Code Representations with Data Flow},
  author={Guo, Daya and Ren, Shuo and Lu, Shuai and Feng, Zhangyin and Tang, Duyu and Liu, Shujie and Zhou, Long and Duan, Nan and Yin, Jian and Jiang, Daxin and others},
  booktitle = {International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=jLoC4ez43PZ},
}
@article{parnas1972module,
 address = {New York, NY, USA},
 author = {Parnas, D. L.},
 doi = {10.1145/361598.361623},
 issn = {0001-0782},
 issue_date = {Dec. 1972},
 journal = {Commun. ACM},
 keywords = {software, modules, software engineering, modularity, KWIC index, software design},
 number = {12},
 numpages = {6},
 pages = {1053–1058},
 publisher = {Association for Computing Machinery},
 title = {On the Criteria to Be Used in Decomposing Systems into Modules},
 url = {https://doi.org/10.1145/361598.361623},
 volume = {15},
 year = {1972}
}

@inproceedings{sullivan2001modularity,
 address = {New York, NY, USA},
 author = {Sullivan, Kevin J. and Griswold, William G. and Cai, Yuanfang and Hallen, Ben},
 doi = {10.1145/503209.503224},
 isbn = {1581133901},
 keywords = {modularity, design structure matrix, software, real options},
 location = {Vienna, Austria},
 numpages = {10},
 pages = {99–108},
 publisher = {Association for Computing Machinery},
 series = {ESEC/FSE-9},
 title = {The Structure and Value of Modularity in Software Design},
 url = {https://doi.org/10.1145/503209.503224},
 year = {2001}
}

@article{parnas1985modular,
 author = {Parnas, D.L. and Clements, P.C. and Weiss, D.M.},
 doi = {10.1109/TSE.1985.232209},
 journal = {IEEE Transactions on Software Engineering},
 number = {3},
 pages = {259-266},
 title = {The Modular Structure of Complex Systems},
 volume = {SE-11},
 year = {1985}
}

@misc{importlab,
 author = {Importlab},
 howpublished = {\url{https://github.com/google/importlab}},
 title = {importlab: A library for Python that automatically infers dependencies and calculates a dependency graph},
 year = {2018}
}

@misc{pydeps,
 author = {Pydeps},
 howpublished = {\url{https://github.com/thebjorn/pydeps}},
 title = {Python Module Dependency Graphs},
 year = {2021}
}

@inproceedings{Khandelwal2020Generalization,
 author = {Urvashi Khandelwal and
Omer Levy and
Dan Jurafsky and
Luke Zettlemoyer and
Mike Lewis},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/iclr/KhandelwalLJZL20.bib},
 booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
Addis Ababa, Ethiopia, April 26-30, 2020},
 publisher = {OpenReview.net},
 timestamp = {Thu, 07 May 2020 01:00:00 +0200},
 title = {Generalization through Memorization: Nearest Neighbor Language Models},
 url = {https://openreview.net/forum?id=HklBjCEKvH},
 year = {2020}
}

@inproceedings{meng2022gnnlm,
 author = {Yuxian Meng and Shi Zong and Xiaoya Li and Xiaofei Sun and Tianwei Zhang and Fei Wu and Jiwei Li},
 booktitle = {International Conference on Learning Representations},
 title = {{GNN}-{LM}: Language Modeling based on Global Contexts via {GNN}},
 url = {https://openreview.net/forum?id=BS49l-B5Bql},
 year = {2022}
}

@inproceedings{veličković2018graph,
 author = {Petar Velickovic and
Guillem Cucurull and
Arantxa Casanova and
Adriana Romero and
Pietro Li{\`{o}} and
Yoshua Bengio},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/iclr/VelickovicCCRLB18.bib},
 booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
 publisher = {OpenReview.net},
 timestamp = {Thu, 25 Jul 2019 01:00:00 +0200},
 title = {Graph Attention Networks},
 url = {https://openreview.net/forum?id=rJXMpikCZ},
 year = {2018}
}

@inproceedings{ding-2022-towards,
    title = "Towards Learning (Dis)-Similarity of Source Code from Program Contrasts",
    author = "Ding, Yangruibo  and
      Buratti, Luca  and
      Pujar, Saurabh  and
      Morari, Alessandro  and
      Ray, Baishakhi  and
      Chakraborty, Saikat",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.436",
    doi = "10.18653/v1/2022.acl-long.436",
    pages = "6300--6312",
    abstract = "Understanding the functional (dis)-similarity of source code is significant for code modeling tasks such as software vulnerability and code clone detection. We present DISCO (DIS-similarity of COde), a novel self-supervised model focusing on identifying (dis)similar functionalities of source code. Different from existing works, our approach does not require a huge amount of randomly collected datasets. Rather, we design structure-guided code transformation algorithms to generate synthetic code clones and inject real-world security bugs, augmenting the collected datasets in a targeted way. We propose to pre-train the Transformer model with such automatically generated program contrasts to better identify similar code in the wild and differentiate vulnerable programs from benign ones. To better capture the structural features of source code, we propose a new cloze objective to encode the local tree-based context (e.g., parents or sibling nodes). We pre-train our model with a much smaller dataset, the size of which is only 5{\%} of the state-of-the-art models{'} training datasets, to illustrate the effectiveness of our data augmentation and the pre-training approach. The evaluation shows that, even with much less data, DISCO can still outperform the state-of-the-art models in vulnerability and code clone detection tasks.",
}

@inproceedings{raychev2016probabilistic,
author = {Raychev, Veselin and Bielik, Pavol and Vechev, Martin},
title = {Probabilistic Model for Code with Decision Trees},
year = {2016},
isbn = {9781450344449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2983990.2984041},
doi = {10.1145/2983990.2984041},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
pages = {731–747},
numpages = {17},
keywords = {Decision Trees, Code Completion, Probabilistic Models of Code},
location = {Amsterdam, Netherlands},
series = {OOPSLA 2016}
}

@inproceedings{ding2023crosscodeeval,
    title={CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code Completion}, 
    author={Yangruibo Ding and Zijian Wang and Wasi Uddin Ahmad and Hantian Ding and Ming Tan and Nihal Jain and Murali Krishna Ramanathan and Ramesh Nallapati and Parminder Bhatia and Dan Roth and Bing Xiang},
    year={2023},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
    url={https://arxiv.org/pdf/2310.11248.pdf}
}

@inproceedings{allamanis2013mining,
author = {Allamanis, Miltiadis and Sutton, Charles},
title = {Mining Source Code Repositories at Massive Scale Using Language Modeling},
year = {2013},
isbn = {9781467329361},
publisher = {IEEE Press},
booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
pages = {207–216},
numpages = {10},
location = {San Francisco, CA, USA},
series = {MSR '13},
url = {https://dl.acm.org/doi/pdf/10.5555/2487085.2487127}
}

@inproceedings{
athiwaratkun2022multi,
title={Multi-lingual Evaluation of Code Generation Models},
author={Ben Athiwaratkun and Sanjay Krishna Gouda and Zijian Wang and Xiaopeng Li and Yuchen Tian and Ming Tan and Wasi Uddin Ahmad and Shiqi Wang and Qing Sun and Mingyue Shang and Sujan Kumar Gonugondla and Hantian Ding and Varun Kumar and Nathan Fulton and Arash Farahani and Siddhartha Jain and Robert Giaquinto and Haifeng Qian and Murali Krishna Ramanathan and Ramesh Nallapati and Baishakhi Ray and Parminder Bhatia and Sudipta Sengupta and Dan Roth and Bing Xiang},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=Bo7eeXm6An8}
}

@article{ren2020codebleu,
  title={Codebleu: a method for automatic evaluation of code synthesis},
  author={Ren, Shuo and Guo, Daya and Lu, Shuai and Zhou, Long and Liu, Shujie and Tang, Duyu and Sundaresan, Neel and Zhou, Ming and Blanco, Ambrosio and Ma, Shuai},
  journal={arXiv preprint arXiv:2009.10297},
  year={2020}
}

@inproceedings{
hendrycks2021measuring,
    title={Measuring Coding Challenge Competence With {APPS}},
    author={Dan Hendrycks and Steven Basart and Saurav Kadavath and Mantas Mazeika and Akul Arora and Ethan Guo and Collin Burns and Samir Puranik and Horace He and Dawn Song and Jacob Steinhardt},
    booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
    year={2021},
    url={https://openreview.net/forum?id=sD93GOzH3i5}
}

@article{ding2022cocomic,
  title={CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file Context},
  author={Ding, Yangruibo and Wang, Zijian and Ahmad, Wasi Uddin and Ramanathan, Murali Krishna and Nallapati, Ramesh and Bhatia, Parminder and Roth, Dan and Xiang, Bing},
  journal={arXiv preprint arXiv:2212.10007},
  url={https://arxiv.org/abs/2212.10007},
  year={2022}
}

@misc{humaneval_x,
    author = {CodeGeeX},
    note = {\url{https://github.com/THUDM/CodeGeeX}},
    year = {2022}
}

@inproceedings{svyatkovskiy2020intellicode,
  title={Intellicode compose: Code generation using transformer},
  author={Svyatkovskiy, Alexey and Deng, Shao Kun and Fu, Shengyu and Sundaresan, Neel},
  booktitle={Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
  pages={1433--1443},
  url = {https://doi.org/10.1145/3368089.3417058},
  year={2020}
}

@inproceedings{
    puri2021codenet,
    title={CodeNet: A Large-Scale {AI} for Code Dataset for Learning a Diversity of Coding Tasks},
    author={Ruchir Puri and David S Kung and Geert Janssen and Wei Zhang and Giacomo Domeniconi and Vladimir Zolotov and Julian Dolby and Jie Chen and Mihir Choudhury and Lindsey Decker and Veronika Thost and Luca Buratti and Saurabh Pujar and Shyam Ramji and Ulrich Finkler and Susan Malaika and Frederick Reiss},
    booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
    year={2021},
    url={https://openreview.net/forum?id=6vZVBkCDrHT}
}

@inproceedings{
    lu2021codexglue,
    title={Code{XGLUE}: A Machine Learning Benchmark Dataset for Code Understanding and Generation},
    author={Shuai Lu and Daya Guo and Shuo Ren and Junjie Huang and Alexey Svyatkovskiy and Ambrosio Blanco and Colin Clement and Dawn Drain and Daxin Jiang and Duyu Tang and Ge Li and Lidong Zhou and Linjun Shou and Long Zhou and Michele Tufano and MING GONG and Ming Zhou and Nan Duan and Neel Sundaresan and Shao Kun Deng and Shengyu Fu and Shujie LIU},
    booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},
    year={2021},
    url={https://openreview.net/forum?id=6lE4dQXaUcb}
}
@article{scao2022bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  journal={arXiv preprint arXiv:2211.05100},
  year={2022}
}

@article{ji2022survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Yejin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  year={2022},
  publisher={ACM New York, NY}
}

@inproceedings{kishore2002bleu,
author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
title = {BLEU: A Method for Automatic Evaluation of Machine Translation},
year = {2002},
publisher = {Association for Computational Linguistics},
address = {USA},
url = {https://doi.org/10.3115/1073083.1073135},
doi = {10.3115/1073083.1073135},
booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
pages = {311–318},
numpages = {8},
location = {Philadelphia, Pennsylvania},
series = {ACL '02}
}

@inproceedings{lee2022deduplicating,
    title = "Deduplicating Training Data Makes Language Models Better",
    author = "Lee, Katherine  and
      Ippolito, Daphne  and
      Nystrom, Andrew  and
      Zhang, Chiyuan  and
      Eck, Douglas  and
      Callison-Burch, Chris  and
      Carlini, Nicholas",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.577",
    doi = "10.18653/v1/2022.acl-long.577",
    pages = "8424--8445"
}

@inproceedings{lewis2020retrieval,
 author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K\"{u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt\"{a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {9459--9474},
 publisher = {Curran Associates, Inc.},
 title = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/6b493230205f780e1bc26945df7481e5-Paper.pdf},
 volume = {33},
 year = {2020}
}


@article{gebru2021datasheets,
  title={Datasheets for datasets},
  author={Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Iii, Hal Daum{\'e} and Crawford, Kate},
  journal={Communications of the ACM},
  volume={64},
  number={12},
  pages={86--92},
  url={https://www.microsoft.com/en-us/research/uploads/prod/2019/01/1803.09010.pdf},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{legoues2012genprog,
author = {Le Goues, Claire and Nguyen, ThanhVu and Forrest, Stephanie and Weimer, Westley},
title = {GenProg: A Generic Method for Automatic Software Repair},
year = {2012},
issue_date = {January 2012},
publisher = {IEEE Press},
volume = {38},
number = {1},
issn = {0098-5589},
url = {https://doi.org/10.1109/TSE.2011.104},
doi = {10.1109/TSE.2011.104},
journal = {IEEE Trans. Softw. Eng.},
month = {jan},
pages = {54–72},
numpages = {19},
keywords = {corrections, Automatic programming, testing and debugging.}
}

@inproceedings{barr2014plastic,
author = {Barr, Earl T. and Brun, Yuriy and Devanbu, Premkumar and Harman, Mark and Sarro, Federica},
title = {The Plastic Surgery Hypothesis},
year = {2014},
isbn = {9781450330565},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2635868.2635898},
doi = {10.1145/2635868.2635898},
booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
pages = {306–317},
numpages = {12},
keywords = {automated program repair, mining software repositories, Software graftability, code reuse, empirical software engineering},
location = {Hong Kong, China},
series = {FSE 2014}
}

@ARTICLE{cassano2023multiple,
  author={Cassano, Federico and Gouwar, John and Nguyen, Daniel and Nguyen, Sydney and Phipps-Costin, Luna and Pinckney, Donald and Yee, Ming-Ho and Zi, Yangtian and Anderson, Carolyn Jane and Feldman, Molly Q and Guha, Arjun and Greenberg, Michael and Jangda, Abhinav},
  journal={IEEE Transactions on Software Engineering}, 
  title={MultiPL-E: A Scalable and Polyglot Approach to Benchmarking Neural Code Generation}, 
  year={2023},
  volume={49},
  number={7},
  pages={3675-3691},
  doi={10.1109/TSE.2023.3267446}}

@inproceedings{Ouyang2022instructgpt,
 author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {27730--27744},
 publisher = {Curran Associates, Inc.},
 title = {Training language models to follow instructions with human feedback},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}
@inproceedings{
Holtzman2020The,
title={The Curious Case of Neural Text Degeneration},
author={Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rygGQyrFvH}
}


@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}
@inproceedings{guo2022unixcoder,
  title={UniXcoder: Unified Cross-Modal Pre-training for Code Representation},
  author={Guo, Daya and Lu, Shuai and Duan, Nan and Wang, Yanlin and Zhou, Ming and Yin, Jian},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={7212--7225},
  year={2022}
}


@inproceedings{wang-etal-2021-codet5,
    title = "{C}ode{T}5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation",
    author = "Wang, Yue  and
      Wang, Weishi  and
      Joty, Shafiq  and
      Hoi, Steven C.H.",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.685",
    doi = "10.18653/v1/2021.emnlp-main.685",
    pages = "8696--8708",
}

@inproceedings{ahmad-etal-2021-unified,
    title = "Unified Pre-training for Program Understanding and Generation",
    author = "Ahmad, Wasi  and
      Chakraborty, Saikat  and
      Ray, Baishakhi  and
      Chang, Kai-Wei",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.211",
    doi = "10.18653/v1/2021.naacl-main.211",
    pages = "2655--2668"
}

@inproceedings{clement-etal-2021-long,
    title = "Long-Range Modeling of Source Code Files with e{WASH}: Extended Window Access by Syntax Hierarchy",
    author = "Clement, Colin  and
      Lu, Shuai  and
      Liu, Xiaoyu  and
      Tufano, Michele  and
      Drain, Dawn  and
      Duan, Nan  and
      Sundaresan, Neel  and
      Svyatkovskiy, Alexey",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.387",
    doi = "10.18653/v1/2021.emnlp-main.387",
    pages = "4713--4722"
}

@inproceedings{lu-etal-2022-reacc,
    title = "{R}e{ACC}: A Retrieval-Augmented Code Completion Framework",
    author = "Lu, Shuai  and
      Duan, Nan  and
      Han, Hojae  and
      Guo, Daya  and
      Hwang, Seung-won  and
      Svyatkovskiy, Alexey",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.431",
    doi = "10.18653/v1/2022.acl-long.431",
    pages = "6227--6240"
}

@inproceedings{hossain-etal-2020-simple,
    title = "Simple and Effective Retrieve-Edit-Rerank Text Generation",
    author = "Hossain, Nabil  and
      Ghazvininejad, Marjan  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.228",
    doi = "10.18653/v1/2020.acl-main.228",
    pages = "2532--2538"
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Wolf, Thomas  and
      Debut, Lysandre  and
      Sanh, Victor  and
      Chaumond, Julien  and
      Delangue, Clement  and
      Moi, Anthony  and
      Cistac, Pierric  and
      Rault, Tim  and
      Louf, Remi  and
      Funtowicz, Morgan  and
      Davison, Joe  and
      Shleifer, Sam  and
      von Platen, Patrick  and
      Ma, Clara  and
      Jernite, Yacine  and
      Plu, Julien  and
      Xu, Canwen  and
      Le Scao, Teven  and
      Gugger, Sylvain  and
      Drame, Mariama  and
      Lhoest, Quentin  and
      Rush, Alexander",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-demos.6",
    doi = "10.18653/v1/2020.emnlp-demos.6",
    pages = "38--45",
}

@article{ding2023static,
  title={A static evaluation of code completion by large language models},
  author={Ding, Hantian and Kumar, Varun and Tian, Yuchen and Wang, Zijian and Kwiatkowski, Rob and Li, Xiaopeng and Ramanathan, Murali Krishna and Ray, Baishakhi and Bhatia, Parminder and Sengupta, Sudipta and others},
  journal={arXiv preprint arXiv:2306.03203},
  year={2023}
}
@inproceedings{wang2023recode,
    title = "{R}e{C}ode: Robustness Evaluation of Code Generation Models",
    author = "Wang, Shiqi  and
      Li, Zheng  and
      Qian, Haifeng  and
      Yang, Chenghao  and
      Wang, Zijian  and
      Shang, Mingyue  and
      Kumar, Varun  and
      Tan, Samson  and
      Ray, Baishakhi  and
      Bhatia, Parminder  and
      Nallapati, Ramesh  and
      Ramanathan, Murali Krishna  and
      Roth, Dan  and
      Xiang, Bing",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.773",
    doi = "10.18653/v1/2023.acl-long.773",
    pages = "13818--13843",
    abstract = "Code generation models have achieved impressive performance. However, they tend to be brittle as slight edits to a prompt could lead to very different generations; these robustness properties, critical for user experience when deployed in real-life applications, are not well understood. Most existing works on robustness in text or code tasks have focused on classification, while robustness in generation tasks is an uncharted area and to date there is no comprehensive benchmark for robustness in code generation. In this paper, we propose ReCode, a comprehensive robustness evaluation benchmark for code generation models. We customize over 30 transformations specifically for code on docstrings, function and variable names, code syntax, and code format. They are carefully designed to be natural in real-life coding practice, preserve the original semantic meaning, and thus provide multifaceted assessments of a model{'}s robustness performance. With human annotators, we verified that over 90{\%} of the perturbed prompts do not alter the semantic meaning of the original prompt. In addition, we define robustness metrics for code generation models considering the worst-case behavior under each type of perturbation, taking advantage of the fact that executing the generated code can serve as objective evaluation. We demonstrate ReCode on SOTA models using HumanEval, MBPP, as well as function completion tasks derived from them. Interesting observations include: better robustness for CodeGen over InCoder and GPT-J; models are most sensitive to syntax perturbations; more challenging robustness evaluation on MBPP over HumanEval.",
}

@misc{rozière2024code,
      title={Code Llama: Open Foundation Models for Code}, 
      author={Baptiste Rozière and Jonas Gehring and Fabian Gloeckle and Sten Sootla and Itai Gat and Xiaoqing Ellen Tan and Yossi Adi and Jingyu Liu and Romain Sauvestre and Tal Remez and Jérémy Rapin and Artyom Kozhevnikov and Ivan Evtimov and Joanna Bitton and Manish Bhatt and Cristian Canton Ferrer and Aaron Grattafiori and Wenhan Xiong and Alexandre Défossez and Jade Copet and Faisal Azhar and Hugo Touvron and Louis Martin and Nicolas Usunier and Thomas Scialom and Gabriel Synnaeve},
      year={2024},
      eprint={2308.12950},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}