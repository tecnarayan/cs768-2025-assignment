\begin{thebibliography}{38}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Beck \& Teboulle(2009)Beck and Teboulle]{beck2009fast}
Beck, A. and Teboulle, M.
\newblock A fast iterative shrinkage-thresholding algorithm for linear inverse
  problems.
\newblock \emph{SIAM Journal on Imaging Sciences}, 2\penalty0 (1):\penalty0
  183--202, 2009.

\bibitem[Blumensath \& Davies(2008)Blumensath and
  Davies]{blumensath2008iterative}
Blumensath, T. and Davies, M.~E.
\newblock Iterative thresholding for sparse approximations.
\newblock \emph{Journal of Fourier analysis and Applications}, 14\penalty0
  (5-6):\penalty0 629--654, 2008.

\bibitem[Bot \& Nguyen(2018)Bot and Nguyen]{bot2018proximal}
Bot, R.~I. and Nguyen, D.-K.
\newblock The proximal alternating direction method of multipliers in the
  nonconvex setting: convergence analysis and rates.
\newblock \emph{arXiv preprint arXiv:1801.01994}, 2018.

\bibitem[Chen et~al.(2018)Chen, Liu, Wang, and Yin]{chen2018theoretical}
Chen, X., Liu, J., Wang, Z., and Yin, W.
\newblock Theoretical linear convergence of unfolded {ISTA} and its practical
  weights and thresholds.
\newblock \emph{arXiv preprint arXiv:1808.10038}, 2018.

\bibitem[Chen \& Pock(2017)Chen and Pock]{chen2017trainable}
Chen, Y. and Pock, T.
\newblock Trainable nonlinear reaction diffusion: A flexible framework for fast
  and effective image restoration.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 39\penalty0 (6):\penalty0 1256--1272, 2017.

\bibitem[Diamond et~al.(2017)Diamond, Sitzmann, Heide, and
  Wetzstein]{diamond2017unrolled}
Diamond, S., Sitzmann, V., Heide, F., and Wetzstein, G.
\newblock Unrolled optimization with deep priors.
\newblock \emph{arXiv preprint arXiv:1705.08041}, 2017.

\bibitem[Gregor \& LeCun(2010)Gregor and LeCun]{gregor2010learning}
Gregor, K. and LeCun, Y.
\newblock Learning fast approximations of sparse coding.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, pp.\  399--406, 2010.

\bibitem[Han \& Yuan(2013)Han and Yuan]{han2013local}
Han, D. and Yuan, X.
\newblock Local linear convergence of the alternating direction method of
  multipliers for quadratic programs.
\newblock \emph{SIAM Journal on Numerical Analysis}, 51\penalty0 (6):\penalty0
  3446--3457, 2013.

\bibitem[Han et~al.(2015)Han, Sun, and Zhang]{han2015linear}
Han, D., Sun, D., and Zhang, L.
\newblock Linear rate convergence of the alternating direction method of
  multipliers for convex composite quadratic and semi-definite programming.
\newblock \emph{arXiv preprint arXiv:1508.02134}, 2015.

\bibitem[He \& Yuan(2015)He and Yuan]{he2015non}
He, B. and Yuan, X.
\newblock On non-ergodic convergence rate of {Douglas--Rachford} alternating
  direction method of multipliers.
\newblock \emph{Numerische Mathematik}, 130\penalty0 (3):\penalty0 567--577,
  2015.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  770--778, 2016.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and
  Weinberger]{huang2017densely}
Huang, G., Liu, Z., Van Der~Maaten, L., and Weinberger, K.~Q.
\newblock Densely connected convolutional networks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  2261--2269, 2017.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Li et~al.(2018)Li, Yang, Chen, and Lin]{li2018optimization}
Li, H., Yang, Y., Chen, D., and Lin, Z.
\newblock Optimization algorithm inspired deep neural network structure design.
\newblock \emph{arXiv preprint arXiv:1810.01638}, 2018.

\bibitem[Li et~al.(2019)Li, Fang, and Lin]{li2018lifted}
Li, J., Fang, C., and Lin, Z.
\newblock Lifted proximal operator machines.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2019.

\bibitem[Lin et~al.(2011)Lin, Liu, and Su]{lin2011linearized}
Lin, Z., Liu, R., and Su, Z.
\newblock Linearized alternating direction method with adaptive penalty for
  low-rank representation.
\newblock In \emph{Proceedings of the Advances in Neural Information Processing
  Systems}, pp.\  612--620, 2011.

\bibitem[Liu \& Li(2016)Liu and Li]{liu2016low}
Liu, G. and Li, P.
\newblock Low-rank matrix completion in the presence of high coherence.
\newblock \emph{IEEE Transactions on Signal Processing}, 64\penalty0
  (21):\penalty0 5623--5633, 2016.

\bibitem[Liu et~al.(2013)Liu, Lin, Yan, Sun, Yu, and Ma]{liu2013robust}
Liu, G., Lin, Z., Yan, S., Sun, J., Yu, Y., and Ma, Y.
\newblock Robust recovery of subspace structures by low-rank representation.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 35\penalty0 (1):\penalty0 171--184, 2013.

\bibitem[Liu et~al.(2014)Liu, Chang, and Ma]{liu:tip:2014}
Liu, G., Chang, S., and Ma, Y.
\newblock Blind image deblurring using spectral properties of convolution
  operators.
\newblock \emph{IEEE Transactions on Image Processing}, 23\penalty0
  (12):\penalty0 5047--5056, 2014.

\bibitem[Liu et~al.(2017)Liu, Liu, and Li]{liu2017blessing}
Liu, G., Liu, Q., and Li, P.
\newblock Blessing of dimensionality: Recovering mixture data via dictionary
  pursuit.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 39\penalty0 (1):\penalty0 47--60, 2017.

\bibitem[Liu et~al.(2019)Liu, Chen, Wang, and Yin]{liu2018alista}
Liu, J., Chen, X., Wang, Z., and Yin, W.
\newblock {ALISTA}: Analytic weights are as good as learned weights in {LISTA}.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Liu et~al.(2018{\natexlab{a}})Liu, Liu, Li, Yuan, Wang, and
  Liu]{liu2018reversed}
Liu, Q., Liu, G., Li, L., Yuan, X.-T., Wang, M., and Liu, W.
\newblock Reversed spectral hashing.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  29\penalty0 (6):\penalty0 2441--2449, 2018{\natexlab{a}}.

\bibitem[Liu et~al.(2016)Liu, Zhong, Cao, Lin, Shan, and Luo]{liu2016learning}
Liu, R., Zhong, G., Cao, J., Lin, Z., Shan, S., and Luo, Z.
\newblock Learning to diffuse: A new perspective to design pdes for visual
  analysis.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 38\penalty0 (12):\penalty0 2457--2471, 2016.

\bibitem[Liu et~al.(2018{\natexlab{b}})Liu, Yuan, Zeng, and
  Zhang]{liu2018partial}
Liu, Y., Yuan, X., Zeng, S., and Zhang, J.
\newblock Partial error bound conditions and the linear convergence rate of the
  alternating direction method of multipliers.
\newblock \emph{SIAM Journal on Numerical Analysis}, 56\penalty0 (4):\penalty0
  2095--2123, 2018{\natexlab{b}}.

\bibitem[Peng et~al.(2018)Peng, Zhou, and Zhu]{peng2018k}
Peng, X., Zhou, J.~T., and Zhu, H.
\newblock {K-meansNet}: When k-means meets differentiable programming.
\newblock \emph{arXiv preprint arXiv:1808.07292}, 2018.

\bibitem[Sprechmann et~al.(2015)Sprechmann, Bronstein, and
  Sapiro]{sprechmann2015learning}
Sprechmann, P., Bronstein, A.~M., and Sapiro, G.
\newblock Learning efficient sparse and low rank models.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 37\penalty0 (9):\penalty0 1821--1833, 2015.

\bibitem[Ulyanov et~al.(2018)Ulyanov, Vedaldi, and Lempitsky]{ulyanov2018deep}
Ulyanov, D., Vedaldi, A., and Lempitsky, V.
\newblock Deep image prior.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  9446--9454, 2018.

\bibitem[Wang et~al.(2016)Wang, Liu, Chang, Ling, Yang, and Huang]{wang2016d3}
Wang, Z., Liu, D., Chang, S., Ling, Q., Yang, Y., and Huang, T.~S.
\newblock D3: Deep dual-domain based fast restoration of jpeg-compressed
  images.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  2764--2772, 2016.

\bibitem[Xu \& Yin(2014)Xu and Yin]{xu2014fast}
Xu, Y. and Yin, W.
\newblock A fast patch-dictionary method for whole image recovery.
\newblock \emph{arXiv preprint arXiv:1408.3740}, 2014.

\bibitem[Yang \& Han(2016)Yang and Han]{yang2016linear}
Yang, W.~H. and Han, D.
\newblock Linear convergence of the alternating direction method of multipliers
  for a class of convex optimization problems.
\newblock \emph{SIAM Journal on Numerical Analysis}, 54\penalty0 (2):\penalty0
  625--640, 2016.

\bibitem[Yang et~al.(2016)Yang, Sun, Li, and Xu]{sun2016deep}
Yang, Y., Sun, J., Li, H., and Xu, Z.
\newblock Deep {ADMM-Net} for compressive sensing {MRI}.
\newblock In \emph{Proceedings of the Advances in Neural Information Processing
  Systems}, pp.\  10--18, 2016.

\bibitem[You et~al.(2016)You, Robinson, and Vidal]{you2016scalable}
You, C., Robinson, D., and Vidal, R.
\newblock Scalable sparse subspace clustering by orthogonal matching pursuit.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  3918--3927, 2016.

\bibitem[Zeiler(2012)]{zeiler2012adadelta}
Zeiler, M.~D.
\newblock Adadelta: an adaptive learning rate method.
\newblock \emph{arXiv preprint arXiv:1212.5701}, 2012.

\bibitem[Zhang et~al.(2015)Zhang, Lin, Zhang, and Chang]{zhang2015exact}
Zhang, H., Lin, Z., Zhang, C., and Chang, E.~Y.
\newblock Exact recoverability of robust {PCA} via outlier pursuit with tight
  recovery bounds.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pp.\  3143--3149, 2015.

\bibitem[Zhang et~al.(2017)Zhang, Zuo, Gu, and Zhang]{zhang2017learning}
Zhang, K., Zuo, W., Gu, S., and Zhang, L.
\newblock Learning deep cnn denoiser prior for image restoration.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, volume~2, 2017.

\bibitem[Zhang et~al.(2010)Zhang, Burger, Bresson, and
  Osher]{zhang2010bregmanized}
Zhang, X., Burger, M., Bresson, X., and Osher, S.
\newblock Bregmanized nonlocal regularization for deconvolution and sparse
  reconstruction.
\newblock \emph{SIAM Journal on Imaging Sciences}, 3\penalty0 (3):\penalty0
  253--276, 2010.

\bibitem[Zhang et~al.(2018)Zhang, Wang, Yu, and Gu]{zhang2018primal}
Zhang, X., Wang, L., Yu, Y., and Gu, Q.
\newblock A primal-dual analysis of global optimality in nonconvex low-rank
  matrix recovery.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, pp.\  5857--5866, 2018.

\bibitem[Zhou et~al.(2018)Zhou, Di, Du, Peng, Yang, Pan, Tsang, Liu, Qin, and
  Goh]{zhou2018sc2net}
Zhou, J.~T., Di, K., Du, J., Peng, X., Yang, H., Pan, S.~J., Tsang, I.~W., Liu,
  Y., Qin, Z., and Goh, R. S.~M.
\newblock {SC2Net}: Sparse {LSTM}s for sparse coding.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2018.

\end{thebibliography}
