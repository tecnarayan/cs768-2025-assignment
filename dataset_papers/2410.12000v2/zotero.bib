
@book{santambrogio_optimal_2015,
	address = {Cham},
	series = {Progress in {Nonlinear} {Differential} {Equations} and {Their} {Applications}},
	title = {Optimal {Transport} for {Applied} {Mathematicians}},
	volume = {87},
	isbn = {978-3-319-20828-2},
	url = {http://link.springer.com/10.1007/978-3-319-20828-2},
	language = {en},
	urldate = {2022-11-18},
	publisher = {Springer International Publishing},
	author = {Santambrogio, Filippo},
	year = {2015},
	doi = {10.1007/978-3-319-20828-2},
	file = {Santambrogio2015 - Optimal Transport for Applied Mathematicians.pdf:/Users/tobias/Documents/References/Santambrogio2015 - Optimal Transport for Applied Mathematicians.pdf:application/pdf;Santambrogio2015 - Optimal Transport for Applied Mathematicians.pdf:/Users/tobias/Zotero/storage/I7FULML9/Santambrogio2015 - Optimal Transport for Applied Mathematicians.pdf:application/pdf},
}

@book{villani_optimal_2009,
	address = {Berlin},
	series = {Grundlehren der mathematischen {Wissenschaften}},
	title = {Optimal transport: old and new},
	isbn = {978-3-540-71049-3},
	shorttitle = {Optimal transport},
	language = {en},
	number = {338},
	publisher = {Springer},
	author = {Villani, Cédric},
	year = {2009},
	keywords = {Dynamics, Dynamique, Géométrie différentielle, Geometry, Differential, Mathematical optimization, Optimisation mathématique, Probabilités, Probabilities, Problèmes de transport (Programmation), Transportation problems (Programming), Differential, Geometry},
	file = {Villani2009 - Optimal Transport.pdf:/Users/tobias/Documents/References/Villani2009 - Optimal Transport.pdf:application/pdf;Villani2009 - Optimal Transport.pdf:/Users/tobias/Zotero/storage/ZVDMY7B2/Villani2009 - Optimal Transport.pdf:application/pdf},
}

@article{otto_geometry_2001,
	title = {The geometry of dissipative evolution equations: the porous medium equation},
	volume = {26},
	issn = {0360-5302, 1532-4133},
	shorttitle = {The geometry of dissipative evolution equations},
	url = {http://www.tandfonline.com/doi/abs/10.1081/PDE-100002243},
	doi = {10.1081/PDE-100002243},
	abstract = {We show that the porous medium equation has a gradient ﬂow structure which is both physically and mathematically natural. In order to convince the reader that it is mathematically natural, we show that the time asymptotic behavior can be easily understood in this framework. We use the intuition and the calculus of Riemannian geometry to quantify this asymptotic behavior.},
	language = {en},
	number = {1-2},
	urldate = {2023-03-15},
	journal = {Communications in Partial Differential Equations},
	author = {Otto, Felix},
	month = jan,
	year = {2001},
	pages = {101--174},
	file = {Otto2001 - The geometry of dissipative evolution equations_ the porous medium equation.pdf:/Users/tobias/Documents/References/Otto2001 - The geometry of dissipative evolution equations_ the porous medium equation.pdf:application/pdf;Otto2001 - The geometry of dissipative evolution equations_ the porous medium equation.pdf:/Users/tobias/Zotero/storage/E4UXAWXC/Otto2001 - The geometry of dissipative evolution equations_ the porous medium equation.pdf:application/pdf},
}

@book{villani_topics_2016,
	address = {Providence, Rhode Island},
	edition = {Reprinted with corrections},
	series = {Graduate studies in mathematics},
	title = {Topics in optimal transportation},
	isbn = {978-0-8218-3312-4},
	language = {eng},
	number = {58},
	publisher = {American Mathematical Society},
	author = {Villani, Cédric},
	year = {2016},
	annote = {Hier auch später erschienene, unveränderte Nachdrucke. - Includes bibliographical references and index},
	annote = {Hier auch später erschienene, unveränderte Nachdrucke. - Includes bibliographical references and index},
}

@incollection{ambrosio_users_2013,
	address = {Berlin, Heidelberg},
	title = {A {User}’s {Guide} to {Optimal} {Transport}},
	volume = {2062},
	isbn = {978-3-642-32159-7 978-3-642-32160-3},
	url = {http://link.springer.com/10.1007/978-3-642-32160-3_1},
	abstract = {This text is an expanded version of the lectures given by the ﬁrst author in the 2009 CIME summer school of Cetraro. It provides a quick and reasonably account of the classical theory of optimal mass transportation and of its more recent developments, including the metric theory of gradient ﬂows, geometric and functional inequalities related to optimal transportation, the ﬁrst and second order differential calculus in the Wasserstein space and the synthetic theory of metric measure spaces with Ricci curvature bounded from below.},
	language = {en},
	urldate = {2023-03-29},
	booktitle = {Modelling and {Optimisation} of {Flows} on {Networks}},
	publisher = {Springer Berlin Heidelberg},
	author = {Ambrosio, Luigi and Gigli, Nicola},
	collaborator = {Ambrosio, Luigi and Bressan, Alberto and Helbing, Dirk and Klar, Axel and Zuazua, Enrique},
	year = {2013},
	doi = {10.1007/978-3-642-32160-3_1},
	note = {Series Title: Lecture Notes in Mathematics},
	pages = {1--155},
	annote = {Series Title: Lecture Notes in Mathematics},
	file = {Ambrosio2013 - A User's Guide to Optimal Transport.pdf:/Users/tobias/Documents/References/Ambrosio2013 - A User's Guide to Optimal Transport.pdf:application/pdf;Ambrosio2013 - A User's Guide to Optimal Transport.pdf:/Users/tobias/Zotero/storage/59J9F6Z7/Ambrosio2013 - A User's Guide to Optimal Transport.pdf:application/pdf},
}

@article{leonard_survey_2014,
	title = {A survey of the {Schrödinger} problem and some of its connections with optimal transport},
	volume = {34},
	issn = {1553-5231},
	url = {http://aimsciences.org//article/doi/10.3934/dcds.2014.34.1533},
	doi = {10.3934/dcds.2014.34.1533},
	language = {en},
	number = {4},
	urldate = {2023-04-21},
	journal = {Discrete \& Continuous Dynamical Systems - A},
	author = {Léonard, Christian},
	year = {2014},
	pages = {1533--1574},
	file = {Submitted Version:/Users/tobias/Zotero/storage/HQ2DU6EK/Léonard and ,Modal-X. Université Paris Ouest, Bât. G, 200 av. de la République. 92001 Nanterre - 2014 - A survey of the Schrödinger problem and some of it.pdf:application/pdf},
}

@book{ambrosio_gradient_2005,
	address = {Basel},
	series = {Lectures in {Mathematics} {ETH} {Zürich}},
	title = {Gradient {Flows}},
	isbn = {978-3-7643-2428-5},
	url = {http://link.springer.com/10.1007/b137080},
	language = {en},
	urldate = {2023-04-28},
	publisher = {Birkhäuser-Verlag},
	author = {Ambrosio, Luigi and Gigli, Nicola and Savaré, Guiseppe},
	year = {2005},
	doi = {10.1007/b137080},
	file = {b137080-1.pdf:/Users/tobias/Downloads/b137080-1.pdf:application/pdf},
}

@book{benner_model_2017,
	address = {Philadelphia, PA},
	title = {Model {Reduction} and {Approximation}: {Theory} and {Algorithms}},
	isbn = {978-1-61197-481-2 978-1-61197-482-9},
	shorttitle = {Model {Reduction} and {Approximation}},
	url = {http://epubs.siam.org/doi/book/10.1137/1.9781611974829},
	language = {en},
	urldate = {2023-09-29},
	publisher = {Society for Industrial and Applied Mathematics},
	editor = {Benner, Peter and Ohlberger, Mario and Cohen, Albert and Willcox, Karen},
	month = jul,
	year = {2017},
	doi = {10.1137/1.9781611974829},
	file = {Devore2017 - The Theoretical Foundation of Reduced Basis Methods.pdf:/Users/tobias/Documents/References/Devore2017 - The Theoretical Foundation of Reduced Basis Methods.pdf:application/pdf;Full Text:/Users/tobias/Zotero/storage/B9I8N7F8/Benner et al. - 2017 - Model Reduction and Approximation Theory and Algo.pdf:application/pdf},
}

@article{brenier_polar_1991,
	title = {Polar factorization and monotone rearrangement of vector-valued functions},
	volume = {44},
	issn = {00103640, 10970312},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/cpa.3160440402},
	doi = {10.1002/cpa.3160440402},
	language = {en},
	number = {4},
	urldate = {2023-10-01},
	journal = {Communications on Pure and Applied Mathematics},
	author = {Brenier, Yann},
	month = jun,
	year = {1991},
	pages = {375--417},
}

@article{arnold_sur_1966,
	title = {Sur la géométrie différentielle des groupes de {Lie} de dimension infinie et ses applications à l'hydrodynamique des fluides parfaits},
	volume = {16},
	issn = {0373-0956},
	url = {https://aif.centre-mersenne.org/item/AIF_1966__16_1_319_0/},
	doi = {10.5802/aif.233},
	language = {fr},
	number = {1},
	urldate = {2023-10-06},
	journal = {Annales de l’institut Fourier},
	author = {Arnold, Vladimir},
	year = {1966},
	pages = {319--361},
	file = {Arnold1966 - Sur la g_'eom_'etrie diff_'erentielle des groupes de Lie de dimension infinie et ses applications _`a l'hydrodynamique des fluides parfaits.pdf:/Users/tobias/Documents/References/Arnold1966 - Sur la g_'eom_'etrie diff_'erentielle des groupes de Lie de dimension infinie et ses applications _`a l'hydrodynamique des fluides parfaits.pdf:application/pdf;Arnold1966 - Sur la g_'eom_'etrie diff_'erentielle des groupes de Lie de dimension infinie et ses applications _`a l'hydrodynamique des fluides parfaits.pdf:/Users/tobias/Zotero/storage/QMXB2ABJ/Arnold1966 - Sur la g_'eom_'etrie diff_'erentielle des groupes de Lie de dimension infinie et ses applications _`a l'hydrodynamique des fluides parfaits.pdf:application/pdf},
}

@unpublished{sullivan_bayesian_2019,
	address = {Munich},
	title = {Bayesian inverse problems in function spaces},
	author = {Sullivan, Tim J},
	month = sep,
	year = {2019},
	note = {IGDK 1754 Compact Course Lecture notes},
	file = {2019-09-23_TUM.pdf:/Users/tobias/Downloads/2019-09-23_TUM.pdf:application/pdf;NIPS-2016-supervised-word-movers-distance-Bibtex.bib:/Users/tobias/Zotero/storage/M35FN9JG/NIPS-2016-supervised-word-movers-distance-Bibtex.bib:text/plain},
}

@article{benamou_optimal_2021,
	title = {Optimal transportation, modelling and numerical simulation},
	volume = {30},
	issn = {0962-4929, 1474-0508},
	url = {https://www.cambridge.org/core/product/identifier/S0962492921000040/type/journal_article},
	doi = {10.1017/S0962492921000040},
	abstract = {We present an overviewof the basic theory, modern optimal transportation extensions and recent algorithmic advances. Selected modelling and numerical applications illustrate the impact of optimal transportation in numerical analysis.},
	language = {en},
	urldate = {2023-11-05},
	journal = {Acta Numerica},
	author = {Benamou, Jean-David},
	month = may,
	year = {2021},
	pages = {249--325},
	file = {Submitted Version:/Users/tobias/Zotero/storage/DGHGDVD7/Benamou - 2021 - Optimal transportation, modelling and numerical si.pdf:application/pdf;Submitted Version:/Users/tobias/Zotero/storage/QQR77T32/Benamou - 2021 - Optimal transportation, modelling and numerical si.pdf:application/pdf},
}

@book{boffi_mixed_2013,
	address = {Berlin, Heidelberg},
	series = {Springer {Series} in {Computational} {Mathematics}},
	title = {Mixed {Finite} {Element} {Methods} and {Applications}},
	volume = {44},
	isbn = {978-3-642-36518-8 978-3-642-36519-5},
	url = {https://link.springer.com/10.1007/978-3-642-36519-5},
	language = {en},
	urldate = {2023-11-07},
	publisher = {Springer Berlin Heidelberg},
	author = {Boffi, Daniele and Brezzi, Franco and Fortin, Michel},
	year = {2013},
	doi = {10.1007/978-3-642-36519-5},
	file = {Boffi2013 - Mixed Finite Element Methods and Applications.pdf:/Users/tobias/Documents/References/Boffi2013 - Mixed Finite Element Methods and Applications.pdf:application/pdf},
}

@article{brenier_least_nodate,
	title = {The least action principle and the related concept of generalized flows for incompressible perfect fluids},
	language = {en},
	author = {Brenier, Yann},
	file = {Brenier1989 - The least action principle and the related concept of generalized flows for incompressible perfect fluids.pdf:/Users/tobias/Documents/References/Brenier1989 - The least action principle and the related concept of generalized flows for incompressible perfect fluids.pdf:application/pdf},
}

@book{lagrange_analytical_1997,
	address = {Dordrecht},
	title = {Analytical {Mechanics}},
	isbn = {978-90-481-4779-3 978-94-015-8903-1},
	url = {http://link.springer.com/10.1007/978-94-015-8903-1},
	urldate = {2024-01-18},
	publisher = {Springer Netherlands},
	author = {Lagrange, J. L.},
	editor = {Boissonnade, Auguste and Vagliente, Victor N.},
	year = {1997},
	doi = {10.1007/978-94-015-8903-1},
	file = {Full Text:/Users/tobias/Zotero/storage/J4N3AR4F/Lagrange - 1997 - Analytical Mechanics.pdf:application/pdf},
}

@article{gunzburger_stochastic_2014,
	title = {Stochastic finite element methods for partial differential equations with random input data},
	volume = {23},
	issn = {0962-4929, 1474-0508},
	url = {https://www.cambridge.org/core/product/identifier/S0962492914000075/type/journal_article},
	doi = {10.1017/S0962492914000075},
	abstract = {The quantification of probabilistic uncertainties in the outputs of physical, biological, and social systems governed by partial differential equations with random inputs require, in practice, the discretization of those equations. Stochastic finite element methods refer to an extensive class of algorithms for the approximate solution of partial differential equations having random input data, for which spatial discretization is effected by a finite element method. Fully discrete approximations require further discretization with respect to solution dependences on the random variables. For this purpose several approaches have been developed, including intrusive approaches such as stochastic Galerkin methods, for which the physical and probabilistic degrees of freedom are coupled, and non-intrusive approaches such as stochastic sampling and interpolatory-type stochastic collocation methods, for which the physical and probabilistic degrees of freedom are uncoupled. All these method classes are surveyed in this article, including some novel recent developments. Details about the construction of the various algorithms and about theoretical error estimates and complexity analyses of the algorithms are provided. Throughout, numerical examples are used to illustrate the theoretical results and to provide further insights into the methodologies.},
	language = {en},
	urldate = {2024-02-01},
	journal = {Acta Numerica},
	author = {Gunzburger, Max D. and Webster, Clayton G. and Zhang, Guannan},
	month = may,
	year = {2014},
	pages = {521--650},
	file = {Full Text:/Users/tobias/Zotero/storage/UKCLN779/Gunzburger et al. - 2014 - Stochastic finite element methods for partial diff.pdf:application/pdf},
}

@article{mou_efficient_2023,
	title = {An efficient data-driven multiscale stochastic reduced order modeling framework for complex systems},
	volume = {493},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999123005454},
	doi = {10.1016/j.jcp.2023.112450},
	language = {en},
	urldate = {2024-02-01},
	journal = {Journal of Computational Physics},
	author = {Mou, Changhong and Chen, Nan and Iliescu, Traian},
	month = nov,
	year = {2023},
	pages = {112450},
	file = {Submitted Version:/Users/tobias/Zotero/storage/V5GARNCV/Mou et al. - 2023 - An efficient data-driven multiscale stochastic red.pdf:application/pdf},
}

@article{kida_asymptotic_1979,
	title = {Asymptotic properties of {Burgers} turbulence},
	volume = {93},
	issn = {0022-1120, 1469-7645},
	url = {http://www.journals.cambridge.org/abstract_S0022112079001932},
	doi = {10.1017/S0022112079001932},
	language = {en},
	number = {02},
	urldate = {2024-02-01},
	journal = {Journal of Fluid Mechanics},
	author = {Kida, Shigeo},
	month = jul,
	year = {1979},
	pages = {337},
	file = {Full Text:/Users/tobias/Zotero/storage/WCPSJ7YN/Kida - 1979 - Asymptotic properties of Burgers turbulence.pdf:application/pdf},
}

@article{sinai_statistics_1992,
	title = {Statistics of shocks in solutions of inviscid {Burgers} equation},
	volume = {148},
	issn = {0010-3616, 1432-0916},
	url = {http://link.springer.com/10.1007/BF02096550},
	doi = {10.1007/BF02096550},
	language = {en},
	number = {3},
	urldate = {2024-02-01},
	journal = {Communications in Mathematical Physics},
	author = {Sinai, Ya. G.},
	month = sep,
	year = {1992},
	pages = {601--621},
	file = {Full Text:/Users/tobias/Zotero/storage/XWNU8K49/Sinai - 1992 - Statistics of shocks in solutions of inviscid Burg.pdf:application/pdf},
}

@article{lin_data-driven_2021,
	title = {Data-driven model reduction, {Wiener} projections, and the {Koopman}-{Mori}-{Zwanzig} formalism},
	volume = {424},
	issn = {00219991},
	url = {http://arxiv.org/abs/1908.07725},
	doi = {10.1016/j.jcp.2020.109864},
	abstract = {Model reduction methods aim to describe complex dynamic phenomena using only relevant dynamical variables, decreasing computational cost, and potentially highlighting key dynamical mechanisms. In the absence of special dynamical features such as scale separation or symmetries, the time evolution of these variables typically exhibits memory effects. Recent work has found a variety of data-driven model reduction methods to be effective for representing such non-Markovian dynamics, but their scope and dynamical underpinning remain incompletely understood. Here, we study data-driven model reduction from a dynamical systems perspective. For both chaotic and randomly-forced systems, we show the problem can be naturally formulated within the framework of Koopman operators and the Mori-Zwanzig projection operator formalism. We give a heuristic derivation of a NARMAX (Nonlinear Auto-Regressive Moving Average with eXogenous input) model from an underlying dynamical model. The derivation is based on a simple construction we call Wiener projection, which links Mori-Zwanzig theory to both NARMAX and to classical Wiener filtering. We apply these ideas to the Kuramoto-Sivashinsky model of spatiotemporal chaos and a viscous Burgers equation with stochastic forcing.},
	urldate = {2024-02-01},
	journal = {Journal of Computational Physics},
	author = {Lin, Kevin K. and Lu, Fei},
	month = jan,
	year = {2021},
	note = {arXiv:1908.07725 [physics, stat]},
	keywords = {Statistics - Machine Learning, Physics - Computational Physics, Mathematics - Numerical Analysis},
	pages = {109864},
	annote = {Comment: Substantial revisions, including additional references. To appear in Journal of Computational Physics},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/SXK4QQPF/Lin and Lu - 2021 - Data-driven model reduction, Wiener projections, a.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/CTQ4J3PC/1908.html:text/html},
}

@article{she_inviscid_1992,
	title = {The inviscid {Burgers} equation with initial data of {Brownian} type},
	volume = {148},
	issn = {0010-3616, 1432-0916},
	url = {http://link.springer.com/10.1007/BF02096551},
	doi = {10.1007/BF02096551},
	language = {en},
	number = {3},
	urldate = {2024-02-01},
	journal = {Communications in Mathematical Physics},
	author = {She, Zhen-Su and Aurell, Erik and Frisch, Uriel},
	month = sep,
	year = {1992},
	pages = {623--641},
	file = {Submitted Version:/Users/tobias/Zotero/storage/7TLZ3EPV/She et al. - 1992 - The inviscid Burgers equation with initial data of.pdf:application/pdf},
}

@misc{iliescu_regularized_2017,
	title = {Regularized {Reduced} {Order} {Models} for a {Stochastic} {Burgers} {Equation}},
	url = {http://arxiv.org/abs/1701.01155},
	abstract = {In this paper, we study the numerical stability of reduced order models for convection-dominated stochastic systems in a relatively simple setting: a stochastic Burgers equation with linear multiplicative noise. Our preliminary results suggest that, in a convection-dominated regime, standard reduced order models yield inaccurate results in the form of spurious numerical oscillations. To alleviate these oscillations, we use the Leray reduced order model, which increases the numerical stability of the standard model by smoothing (regularizing) the convective term with an explicit spatial filter. The Leray reduced order model yields significantly better results than the standard reduced order model and is more robust with respect to changes in the strength of the noise.},
	urldate = {2024-02-01},
	publisher = {arXiv},
	author = {Iliescu, Traian and Liu, Honghu and Xie, Xuping},
	month = jan,
	year = {2017},
	note = {arXiv:1701.01155 [physics]},
	keywords = {Physics - Fluid Dynamics},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/5PFK7KM8/Iliescu et al. - 2017 - Regularized Reduced Order Models for a Stochastic .pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/EBL3KMEN/1701.html:text/html},
}

@article{xie_evolve_2018,
	title = {Evolve {Filter} {Stabilization} {Reduced}-{Order} {Model} for {Stochastic} {Burgers} {Equation}},
	volume = {3},
	issn = {2311-5521},
	url = {http://www.mdpi.com/2311-5521/3/4/84},
	doi = {10.3390/fluids3040084},
	abstract = {In this paper, we introduce the evolve-then-filter (EF) regularization method for reduced order modeling of convection-dominated stochastic systems. The standard Galerkin projection reduced order model (G-ROM) yield numerical oscillations in a convection-dominated regime. The evolve-then-filter reduced order model (EF-ROM) aims at the numerical stabilization of the standard G-ROM, which uses explicit ROM spatial filter to regularize various terms in the reduced order model (ROM). Our numerical results are based on a stochastic Burgers equation with linear multiplicative noise. The numerical result shows that the EF-ROM is significantly better than G-ROM.},
	language = {en},
	number = {4},
	urldate = {2024-02-01},
	journal = {Fluids},
	author = {Xie, Xuping and Bao, Feng and Webster, Clayton},
	month = oct,
	year = {2018},
	pages = {84},
	file = {Full Text:/Users/tobias/Zotero/storage/VSJS4GDY/Xie et al. - 2018 - Evolve Filter Stabilization Reduced-Order Model fo.pdf:application/pdf},
}

@misc{lu_stochastic_2022,
	title = {Stochastic {Data}-{Driven} {Variational} {Multiscale} {Reduced} {Order} {Models}},
	url = {http://arxiv.org/abs/2209.02739},
	abstract = {Trajectory-wise data-driven reduced order models (ROMs) tend to be sensitive to training data, and thus lack robustness. We propose to construct a robust stochastic ROM closure (S-ROM) from data consisting of multiple trajectories from random initial conditions. The S-ROM is a low-dimensional time series model for the coefficients of the dominating proper orthogonal decomposition (POD) modes inferred from data. Thus, it achieves reduction both space and time, leading to simulations orders of magnitude faster than the full order model. We show that both the estimated POD modes and parameters in the S-ROM converge when the number of trajectories increases. Thus, the S-ROM is robust when the training data size increases. We demonstrate the S-ROM on a 1D Burgers equation with a viscosity \${\textbackslash}nu= 0.002\$ and with random initial conditions. The numerical results verify the convergence. Furthermore, the S-ROM makes accurate trajectory-wise predictions from new initial conditions and with a prediction time far beyond the training range, and it quantifies the spread of uncertainties due to the unresolved scales.},
	urldate = {2024-02-01},
	publisher = {arXiv},
	author = {Lu, Fei and Mou, Changhong and Liu, Honghu and Iliescu, Traian},
	month = sep,
	year = {2022},
	note = {arXiv:2209.02739 [cs, math, stat]},
	keywords = {Mathematics - Numerical Analysis, Statistics - Computation},
	annote = {Comment: 22 pages, 7 figures},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/4HLRZAAH/Lu et al. - 2022 - Stochastic Data-Driven Variational Multiscale Redu.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/ADIXECMS/2209.html:text/html},
}

@article{lu_data-driven_2020,
	title = {Data-{Driven} {Model} {Reduction} for {Stochastic} {Burgers} {Equations}},
	volume = {22},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/22/12/1360},
	doi = {10.3390/e22121360},
	abstract = {We present a class of efficient parametric closure models for 1D stochastic Burgers equations. Casting it as statistical learning of the flow map, we derive the parametric form by representing the unresolved high wavenumber Fourier modes as functionals of the resolved variable’s trajectory. The reduced models are nonlinear autoregression (NAR) time series models, with coefficients estimated from data by least squares. The NAR models can accurately reproduce the energy spectrum, the invariant densities, and the autocorrelations. Taking advantage of the simplicity of the NAR models, we investigate maximal space-time reduction. Reduction in space dimension is unlimited, and NAR models with two Fourier modes can perform well. The NAR model’s stability limits time reduction, with a maximal time step smaller than that of the K-mode Galerkin system. We report a potential criterion for optimal space-time reduction: the NAR models achieve minimal relative error in the energy spectrum at the time step, where the K-mode Galerkin system’s mean Courant–Friedrichs–Lewy (CFL) number agrees with that of the full model.},
	language = {en},
	number = {12},
	urldate = {2024-02-01},
	journal = {Entropy},
	author = {Lu, Fei},
	month = nov,
	year = {2020},
	pages = {1360},
	file = {Full Text:/Users/tobias/Zotero/storage/YNTJC8KL/Lu - 2020 - Data-Driven Model Reduction for Stochastic Burgers.pdf:application/pdf},
}

@misc{li_scalable_2020,
	title = {Scalable {Gradients} for {Stochastic} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2001.01328},
	abstract = {The adjoint sensitivity method scalably computes gradients of solutions to ordinary differential equations. We generalize this method to stochastic differential equations, allowing time-efficient and constant-memory computation of gradients with high-order adaptive solvers. Specifically, we derive a stochastic differential equation whose solution is the gradient, a memory-efficient algorithm for caching noise, and conditions under which numerical solutions converge. In addition, we combine our method with gradient-based stochastic variational inference for latent stochastic differential equations. We use our method to fit stochastic dynamics defined by neural networks, achieving competitive performance on a 50-dimensional motion capture dataset.},
	urldate = {2024-02-01},
	publisher = {arXiv},
	author = {Li, Xuechen and Wong, Ting-Kam Leonard and Chen, Ricky T. Q. and Duvenaud, David},
	month = oct,
	year = {2020},
	note = {arXiv:2001.01328 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Numerical Analysis},
	annote = {Comment: AISTATS 2020; 25 pages, 6 figures in main text; clarify notation in appendix},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/T4538XHN/Li et al. - 2020 - Scalable Gradients for Stochastic Differential Equ.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/VDQ6HK68/2001.html:text/html},
}

@misc{frisch_burgulence_2001,
	title = {Burgulence},
	url = {http://arxiv.org/abs/nlin/0012033},
	abstract = {This is a review of selected work on the one- and multi-dimensional random Burgers equation (burgulence) with emphasis on questions generally asked for incompressible Navier--Stokes turbulence, such as the law of decay of the energy and the pdf of velocity gradients. Most of the material is devoted to decaying (unforced) burgulence. For more details see the Table of Contents.},
	urldate = {2024-02-01},
	publisher = {arXiv},
	author = {Frisch, U. and Bec, J.},
	month = mar,
	year = {2001},
	note = {arXiv:nlin/0012033},
	keywords = {Astrophysics, Condensed Matter, Nonlinear Sciences - Chaotic Dynamics},
	annote = {Comment: 41 pages, 33 figures, to appear in Proceedings Les Houches 2000 "New Trends in Turbulence"},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/FCDSBRHF/Frisch and Bec - 2001 - Burgulence.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/H62EP69P/0012033.html:text/html},
}

@article{rubinstein_uncertainty_2005,
	title = {Uncertainty {Quantification} for {Systems} with {Random} {Initial} {Conditions} {Using} {Wiener}–{Hermite} {Expansions}},
	volume = {114},
	issn = {0022-2526, 1467-9590},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.0022-2526.2005.01543.x},
	doi = {10.1111/j.0022-2526.2005.01543.x},
	abstract = {A number of engineering problems, including laminar‐turbulent transition in convectively unstable flows, require predicting the evolution of a nonlinear dynamical system under uncertain initial conditions. The method of Wiener–Hermite expansion is an attractive alternative to modeling methods, which solve for the joint probability density function of the stochastic amplitudes. These problems include the “curse of dimensionality” and closure problems. In this paper, we apply truncated Wiener–Hermite expansions with both fixed and time‐varying bases to a model stochastic system with three degrees of freedom. The model problem represents the combined effects of quadratic nonlinearity and stochastic initial conditions in a generic setting and occurs in related forms in both classical dynamics, turbulence theory, and the nonlinear theory of hydrodynamic stability. In this problem, the truncated Wiener–Hermite expansions give a good account of short‐time behavior, but not of the long‐time relaxation characteristic of this system. It is concluded that successful application of truncated Wiener–Hermite expansions may require special adaptations for each physical problem.},
	language = {en},
	number = {2},
	urldate = {2024-02-01},
	journal = {Studies in Applied Mathematics},
	author = {Rubinstein, Robert and Choudhari, Meelan},
	month = feb,
	year = {2005},
	pages = {167--188},
}

@article{bulinskii_asymptotical_1992,
	title = {Asymptotical {Normality} of a {Solution} of {Burgers}’ {Equation} with {Random} {Initial} {Data}},
	volume = {36},
	issn = {0040-585X, 1095-7219},
	url = {http://epubs.siam.org/doi/10.1137/1136027},
	doi = {10.1137/1136027},
	language = {en},
	number = {2},
	urldate = {2024-02-01},
	journal = {Theory of Probability \& Its Applications},
	author = {Bulinskii, A. V. and Molchanov, S. A.},
	month = jan,
	year = {1992},
	pages = {217--236},
	file = {1136027.pdf:/Users/tobias/Downloads/1136027.pdf:application/pdf},
}

@article{cho_statistical_2014,
	title = {Statistical analysis and simulation of random shocks in stochastic {Burgers} equation},
	volume = {470},
	issn = {1364-5021, 1471-2946},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspa.2014.0080},
	doi = {10.1098/rspa.2014.0080},
	abstract = {We study the statistical properties of random shock waves in stochastic Burgers equation subject to random space–time perturbations and random initial conditions. By using the response–excitation probability density function (PDF) method and the Mori–Zwanzig (MZ) formulation of irreversible statistical mechanics, we derive exact reduced-order equations for the one-point and two-point PDFs of the solution field. In particular, we compute the statistical properties of random shock waves in the inviscid limit by using an adaptive (shock-capturing) discontinuous Galerkin method in both physical and probability spaces. We consider stochastic flows generated by high-dimensional random initial conditions and random additive forcing terms, yielding multiple interacting shock waves collapsing into clusters and settling down to a similarity state. We also address the question of how random shock waves in space and time manifest themselves in probability space. The proposed new mathematical framework can be applied to different conservation laws, potentially leading to new insights into high-dimensional stochastic dynamical systems and more efficient computational algorithms.},
	language = {en},
	number = {2171},
	urldate = {2024-02-01},
	journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Cho, Heyrim and Venturi, Daniele and Karniadakis, George E},
	month = nov,
	year = {2014},
	pages = {20140080},
	file = {Full Text:/Users/tobias/Zotero/storage/JJ998W7X/Cho et al. - 2014 - Statistical analysis and simulation of random shoc.pdf:application/pdf},
}

@article{chabanol_markovian_2004,
	title = {Markovian {Solutions} of {Inviscid} {Burgers} {Equation}},
	volume = {114},
	issn = {0022-4715},
	url = {http://link.springer.com/10.1023/B:JOSS.0000003120.32992.a9},
	doi = {10.1023/B:JOSS.0000003120.32992.a9},
	language = {en},
	number = {1/2},
	urldate = {2024-02-01},
	journal = {Journal of Statistical Physics},
	author = {Chabanol, Marie-Line and Duchon, Jean},
	month = jan,
	year = {2004},
	pages = {525--534},
	file = {Submitted Version:/Users/tobias/Zotero/storage/D4UD5CRD/Chabanol and Duchon - 2004 - Markovian Solutions of Inviscid Burgers Equation.pdf:application/pdf},
}

@article{vergassola_burgers_1994,
	title = {Burgers' equation, {Devil}'s staircases and the mass distribution for large-scale structures},
	volume = {289},
	url = {https://ui.adsabs.harvard.edu/abs/1994A%26A...289..325V/abstract},
	abstract = {Work initiated by Zeldovich (Astron. \& Astrophys. 5, 84, 1970) and the Russian school indicates that the formation of large-scale structures in the Universe can be analyzed via the adhesion model, a multi-dimensional form of the Burgers equation. Initial conditions frequently considered for the cosmological problem are Gaussian with a power-law spectrum (fractional Brownian motion). Already in the simpler one-dimensional case, with ordinary Brownian motion as initial condition, numerically supported conjectures by She et al. (Comm. Math. Phys. 148, 623, 1992) have led to a proof by Sinai (ibidem, p. 601) of the following result: there is a Devil's staircase of dimension 1/2 in the Lagrangian map for the solution of the Burgers equation in the limit of vanishing viscosity. The Lagrangian map is the correspondence between initial (Lagrangian) position and present (Eulerian) position. A Devil's staircase is a non-decreasing function which varies only on a set of zero measure and fractal dimension D. Such a Devil's staircase is not directly observable on Eulerian data, but its signature is a power-law in the mass function (distribution of masses) at small masses, with an exponent related to the fractal dimension D. After critical examination of the steps leading from the microscopic Jeans-Vlasov-Poisson for self-gravitating dust to the adhesion model, the main goal of this paper is to give a comprehensive introduction to these recent theoretical developments and to extend them to initial power-law spectra with a wide range of exponents and to more than one dimension. The necessary geometric and probabilistic tools, due mostly to Sinai, are here presented in a detailed but rather elementary way, intended for a readership of general physicists. The extensions of Sinai's theory presented here often include heuristic elements. Most of the predictions are however tested by accurate numerical experiments in one and two dimensions, using a new "Fast Legendre Transform" algorithm which exploits a monotonicity property and has very low storage requirements. Predictions of the present theory for the mass function are compared to those of Press and Schechter (Ap. J. 187, 425, 1974). Their expression for the mass function is found to agree with the adhesion model at large masses in any dimension. At small masses, there are discrepancies in dimensions higher than one. In one dimension the scaling behavior at small masses is correctly given by the Press-Schechter theory. This may however be fortuitous: Sinai's theory, recast in the language of gravitational collapse, tells us that the scaling originates not from the condition of collapse of a given region of small size, but from a condition of non-collapse of an extended halo around that region.},
	journal = {Astronomy and Astrophysics},
	author = {Vergassola, M and Dubrulle, B and Frisch, U and Noullez, A},
	year = {1994},
	pages = {325--356},
	file = {document.pdf:/Users/tobias/Downloads/document.pdf:application/pdf},
}

@misc{albergo_learning_2023,
	title = {Learning to {Sample} {Better}},
	url = {http://arxiv.org/abs/2310.11232},
	abstract = {These lecture notes provide an introduction to recent advances in generative modeling methods based on the dynamical transportation of measures, by means of which samples from a simple base measure are mapped to samples from a target measure of interest. Special emphasis is put on the applications of these methods to Monte-Carlo (MC) sampling techniques, such as importance sampling and Markov Chain Monte-Carlo (MCMC) schemes. In this context, it is shown how the maps can be learned variationally using data generated by MC sampling, and how they can in turn be used to improve such sampling in a positive feedback loop.},
	urldate = {2024-02-02},
	publisher = {arXiv},
	author = {Albergo, Michael S. and Vanden-Eijnden, Eric},
	month = oct,
	year = {2023},
	note = {arXiv:2310.11232 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Les Houches 2022 Summer School on Statistical Physics and Machine Learning},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/T65WQKXW/Albergo and Vanden-Eijnden - 2023 - Learning to Sample Better.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/2MWZGWN9/2310.html:text/html},
}

@article{gurbatov_decay_1997,
	title = {On the decay of {Burgers} turbulence},
	volume = {344},
	issn = {0022-1120, 1469-7645},
	url = {http://arxiv.org/abs/physics/9709002},
	doi = {10.1017/S0022112097006241},
	abstract = {This work is devoted to the decay ofrandom solutions of the unforced Burgers equation in one dimension in the limit of vanishing viscosity. The initial velocity is homogeneous and Gaussian with a spectrum proportional to \$k{\textasciicircum}n\$ at small wavenumbers \$k\$ and falling off quickly at large wavenumbers. In physical space, at sufficiently large distances, there is an ``outer region'', where the velocity correlation function preserves exactly its initial form (a power law) when \$n\$ is not an even integer. When \$1{\textless}n{\textless}2\$ the spectrum, at long times, has three scaling regions : first, a \${\textbar}k{\textbar}{\textasciicircum}n\$ region at very small \$k\${\textbackslash}ms1 with a time-independent constant, stemming from this outer region, in which the initial conditions are essentially frozen; second, a \$k{\textasciicircum}2\$ region at intermediate wavenumbers, related to a self-similarly evolving ``inner region'' in physical space and, finally, the usual \$k{\textasciicircum}\{-2\}\$ region, associated to the shocks. The switching from the \${\textbar}k{\textbar}{\textasciicircum}n\$ to the \$k{\textasciicircum}2\$ region occurs around a wave number \$k\_s(t) {\textbackslash}propto t{\textasciicircum}\{-1/[2(2-n)]\}\$, while the switching from \$k{\textasciicircum}2\$ to \$k{\textasciicircum}\{-2\}\$ occurs around \$k\_L(t){\textbackslash}propto t{\textasciicircum}\{-1/2\}\$ (ignoring logarithmic corrections in both instances). The key element in the derivation of the results is an extension of the Kida (1979) log-corrected \$1/t\$ law for the energy decay when \$n=2\$ to the case of arbitrary integer or non-integer \$n{\textgreater}1\$. A systematic derivation is given in which both the leading term and estimates of higher order corrections can be obtained. High-resolution numerical simulations are presented which support our findings.},
	urldate = {2024-02-02},
	journal = {Journal of Fluid Mechanics},
	author = {Gurbatov, S. N. and Simdyankin, S. I. and Aurell, E. and Frisch, U. and Tóth, G.},
	month = aug,
	year = {1997},
	note = {arXiv:physics/9709002},
	keywords = {Physics - Fluid Dynamics, Nonlinear Sciences - Chaotic Dynamics, Condensed Matter - Statistical Mechanics},
	pages = {339--374},
	annote = {Comment: In LaTeX with 11 PostScript figures. 56 pages. One figure contributed by Alain Noullez (Observatoire de Nice, France)},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/5MJ4LLSA/Gurbatov et al. - 1997 - On the decay of Burgers turbulence.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/4XMQIGHH/9709002.html:text/html},
}

@misc{papamakarios_normalizing_2021,
	title = {Normalizing {Flows} for {Probabilistic} {Modeling} and {Inference}},
	url = {http://arxiv.org/abs/1912.02762},
	abstract = {Normalizing flows provide a general mechanism for defining expressive probability distributions, only requiring the specification of a (usually simple) base distribution and a series of bijective transformations. There has been much recent work on normalizing flows, ranging from improving their expressive power to expanding their application. We believe the field has now matured and is in need of a unified perspective. In this review, we attempt to provide such a perspective by describing flows through the lens of probabilistic modeling and inference. We place special emphasis on the fundamental principles of flow design, and discuss foundational topics such as expressive power and computational trade-offs. We also broaden the conceptual framing of flows by relating them to more general probability transformations. Lastly, we summarize the use of flows for tasks such as generative modeling, approximate inference, and supervised learning.},
	urldate = {2024-02-02},
	publisher = {arXiv},
	author = {Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
	month = apr,
	year = {2021},
	note = {arXiv:1912.02762 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Review article, 64 pages, 9 figures. Published in the Journal of Machine Learning Research (see https://jmlr.org/papers/v22/19-1028.html)},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/S3JFIWJF/Papamakarios et al. - 2021 - Normalizing Flows for Probabilistic Modeling and I.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/6WKLE3IU/1912.html:text/html},
}

@misc{rezende_variational_2016,
	title = {Variational {Inference} with {Normalizing} {Flows}},
	url = {http://arxiv.org/abs/1505.05770},
	abstract = {The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.},
	urldate = {2024-02-02},
	publisher = {arXiv},
	author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
	month = jun,
	year = {2016},
	note = {arXiv:1505.05770 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Computation, Computer Science - Artificial Intelligence, Statistics - Methodology},
	annote = {Comment: Proceedings of the 32nd International Conference on Machine Learning},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/S3I94GNL/Rezende and Mohamed - 2016 - Variational Inference with Normalizing Flows.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/3R9C2MTI/1505.html:text/html},
}

@misc{li_fourier_2021,
	title = {Fourier {Neural} {Operator} for {Parametric} {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2010.08895},
	abstract = {The classical development of neural networks has primarily focused on learning mappings between finite-dimensional Euclidean spaces. Recently, this has been generalized to neural operators that learn mappings between function spaces. For partial differential equations (PDEs), neural operators directly learn the mapping from any functional parametric dependence to the solution. Thus, they learn an entire family of PDEs, in contrast to classical methods which solve one instance of the equation. In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. We perform experiments on Burgers' equation, Darcy flow, and Navier-Stokes equation. The Fourier neural operator is the first ML-based method to successfully model turbulent flows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional PDE solvers. Additionally, it achieves superior accuracy compared to previous learning-based solvers under fixed resolution.},
	urldate = {2024-02-05},
	publisher = {arXiv},
	author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
	month = may,
	year = {2021},
	note = {arXiv:2010.08895 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/DUMS8Y4E/Li et al. - 2021 - Fourier Neural Operator for Parametric Partial Dif.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/X2Q6EDGV/2010.html:text/html},
}

@misc{tong_improving_2023,
	title = {Improving and generalizing flow-based generative models with minibatch optimal transport},
	url = {http://arxiv.org/abs/2302.00482},
	abstract = {Continuous normalizing flows (CNFs) are an attractive generative modeling technique, but they have been held back by limitations in their simulation-based maximum likelihood training. We introduce the generalized conditional flow matching (CFM) technique, a family of simulation-free training objectives for CNFs. CFM features a stable regression objective like that used to train the stochastic flow in diffusion models but enjoys the efficient inference of deterministic flow models. In contrast to both diffusion models and prior CNF training algorithms, CFM does not require the source distribution to be Gaussian or require evaluation of its density. A variant of our objective is optimal transport CFM (OT-CFM), which creates simpler flows that are more stable to train and lead to faster inference, as evaluated in our experiments. Furthermore, OT-CFM is the first method to compute dynamic OT in a simulation-free way. Training CNFs with CFM improves results on a variety of conditional and unconditional generation tasks, such as inferring single cell dynamics, unsupervised image translation, and Schr{\textbackslash}"odinger bridge inference.},
	urldate = {2024-02-05},
	publisher = {arXiv},
	author = {Tong, Alexander and Malkin, Nikolay and Huguet, Guillaume and Zhang, Yanlei and Rector-Brooks, Jarrid and Fatras, Kilian and Wolf, Guy and Bengio, Yoshua},
	month = oct,
	year = {2023},
	note = {arXiv:2302.00482 [cs]},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: An earlier version of this paper appeared in the New Frontiers in Learning, Control, and Dynamical Systems workshop at ICML 2023. Code: https://github.com/atong01/conditional-flow-matching},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/X9T9TVNP/Tong et al. - 2023 - Improving and generalizing flow-based generative m.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/HY97QALC/2302.html:text/html},
}

@misc{pooladian_multisample_2023,
	title = {Multisample {Flow} {Matching}: {Straightening} {Flows} with {Minibatch} {Couplings}},
	shorttitle = {Multisample {Flow} {Matching}},
	url = {http://arxiv.org/abs/2304.14772},
	abstract = {Simulation-free methods for training continuous-time generative models construct probability paths that go between noise distributions and individual data samples. Recent works, such as Flow Matching, derived paths that are optimal for each data sample. However, these algorithms rely on independent data and noise samples, and do not exploit underlying structure in the data distribution for constructing probability paths. We propose Multisample Flow Matching, a more general framework that uses non-trivial couplings between data and noise samples while satisfying the correct marginal constraints. At very small overhead costs, this generalization allows us to (i) reduce gradient variance during training, (ii) obtain straighter flows for the learned vector field, which allows us to generate high-quality samples using fewer function evaluations, and (iii) obtain transport maps with lower cost in high dimensions, which has applications beyond generative modeling. Importantly, we do so in a completely simulation-free manner with a simple minimization objective. We show that our proposed methods improve sample consistency on downsampled ImageNet data sets, and lead to better low-cost sample generation.},
	urldate = {2024-02-05},
	publisher = {arXiv},
	author = {Pooladian, Aram-Alexandre and Ben-Hamu, Heli and Domingo-Enrich, Carles and Amos, Brandon and Lipman, Yaron and Chen, Ricky T. Q.},
	month = may,
	year = {2023},
	note = {arXiv:2304.14772 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/2UFKK2RJ/Pooladian et al. - 2023 - Multisample Flow Matching Straightening Flows wit.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/2ARIKZNH/2304.html:text/html},
}

@misc{albergo_stochastic_2023,
	title = {Stochastic {Interpolants}: {A} {Unifying} {Framework} for {Flows} and {Diffusions}},
	shorttitle = {Stochastic {Interpolants}},
	url = {http://arxiv.org/abs/2303.08797},
	abstract = {A class of generative models that unifies flow-based and diffusion-based methods is introduced. These models extend the framework proposed in Albergo \& Vanden-Eijnden (2023), enabling the use of a broad class of continuous-time stochastic processes called `stochastic interpolants' to bridge any two arbitrary probability density functions exactly in finite time. These interpolants are built by combining data from the two prescribed densities with an additional latent variable that shapes the bridge in a flexible way. The time-dependent probability density function of the stochastic interpolant is shown to satisfy a first-order transport equation as well as a family of forward and backward Fokker-Planck equations with tunable diffusion coefficient. Upon consideration of the time evolution of an individual sample, this viewpoint immediately leads to both deterministic and stochastic generative models based on probability flow equations or stochastic differential equations with an adjustable level of noise. The drift coefficients entering these models are time-dependent velocity fields characterized as the unique minimizers of simple quadratic objective functions, one of which is a new objective for the score of the interpolant density. We show that minimization of these quadratic objectives leads to control of the likelihood for generative models built upon stochastic dynamics, while likelihood control for deterministic dynamics is more stringent. We also discuss connections with other methods such as score-based diffusion models, stochastic localization processes, probabilistic denoising techniques, and rectifying flows. In addition, we demonstrate that stochastic interpolants recover the Schr{\textbackslash}"odinger bridge between the two target densities when explicitly optimizing over the interpolant. Finally, algorithmic aspects are discussed and the approach is illustrated on numerical examples.},
	urldate = {2024-02-05},
	publisher = {arXiv},
	author = {Albergo, Michael S. and Boffi, Nicholas M. and Vanden-Eijnden, Eric},
	month = nov,
	year = {2023},
	note = {arXiv:2303.08797 [cond-mat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Probability, Condensed Matter - Disordered Systems and Neural Networks},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/PY5MJ4CY/Albergo et al. - 2023 - Stochastic Interpolants A Unifying Framework for .pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/33NY2PAD/2303.html:text/html},
}

@misc{liu_rectified_2022,
	title = {Rectified {Flow}: {A} {Marginal} {Preserving} {Approach} to {Optimal} {Transport}},
	shorttitle = {Rectified {Flow}},
	url = {http://arxiv.org/abs/2209.14577},
	abstract = {We present a flow-based approach to the optimal transport (OT) problem between two continuous distributions \${\textbackslash}pi\_0,{\textbackslash}pi\_1\$ on \${\textbackslash}mathbb\{R\}{\textasciicircum}d\$, of minimizing a transport cost \${\textbackslash}mathbb\{E\}[c(X\_1-X\_0)]\$ in the set of couplings \$(X\_0,X\_1)\$ whose marginal distributions on \$X\_0,X\_1\$ equals \${\textbackslash}pi\_0,{\textbackslash}pi\_1\$, respectively, where \$c\$ is a cost function. Our method iteratively constructs a sequence of neural ordinary differentiable equations (ODE), each learned by solving a simple unconstrained regression problem, which monotonically reduce the transport cost while automatically preserving the marginal constraints. This yields a monotonic interior approach that traverses inside the set of valid couplings to decrease the transport cost, which distinguishes itself from most existing approaches that enforce the coupling constraints from the outside. The main idea of the method draws from rectified flow, a recent approach that simultaneously decreases the whole family of transport costs induced by convex functions \$c\$ (and is hence multi-objective in nature), but is not tailored to minimize a specific transport cost. Our method is a single-object variant of rectified flow that guarantees to solve the OT problem for a fixed, user-specified convex cost function \$c\$.},
	urldate = {2024-02-13},
	publisher = {arXiv},
	author = {Liu, Qiang},
	month = sep,
	year = {2022},
	note = {arXiv:2209.14577 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/ZAGB33DU/Liu - 2022 - Rectified Flow A Marginal Preserving Approach to .pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/26NR7NHB/2209.html:text/html},
}

@misc{song_score-based_2021,
	title = {Score-{Based} {Generative} {Modeling} through {Stochastic} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2011.13456},
	abstract = {Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reverse-time SDE depends only on the time-dependent gradient field ({\textbackslash}aka, score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in score-based generative modeling and diffusion probabilistic modeling, allowing for new sampling procedures and new modeling capabilities. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, but additionally enables exact likelihood computation, and improved sampling efficiency. In addition, we provide a new way to solve inverse problems with score-based models, as demonstrated with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model.},
	urldate = {2024-02-14},
	publisher = {arXiv},
	author = {Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P. and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
	month = feb,
	year = {2021},
	note = {arXiv:2011.13456 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: ICLR 2021 (Oral)},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/8YI4IP7U/Song et al. - 2021 - Score-Based Generative Modeling through Stochastic.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/Z4A3YVYI/2011.html:text/html},
}

@misc{onken_ot-flow_2021,
	title = {{OT}-{Flow}: {Fast} and {Accurate} {Continuous} {Normalizing} {Flows} via {Optimal} {Transport}},
	shorttitle = {{OT}-{Flow}},
	url = {http://arxiv.org/abs/2006.00104},
	abstract = {A normalizing flow is an invertible mapping between an arbitrary probability distribution and a standard normal distribution; it can be used for density estimation and statistical inference. Computing the flow follows the change of variables formula and thus requires invertibility of the mapping and an efficient way to compute the determinant of its Jacobian. To satisfy these requirements, normalizing flows typically consist of carefully chosen components. Continuous normalizing flows (CNFs) are mappings obtained by solving a neural ordinary differential equation (ODE). The neural ODE's dynamics can be chosen almost arbitrarily while ensuring invertibility. Moreover, the log-determinant of the flow's Jacobian can be obtained by integrating the trace of the dynamics' Jacobian along the flow. Our proposed OT-Flow approach tackles two critical computational challenges that limit a more widespread use of CNFs. First, OT-Flow leverages optimal transport (OT) theory to regularize the CNF and enforce straight trajectories that are easier to integrate. Second, OT-Flow features exact trace computation with time complexity equal to trace estimators used in existing CNFs. On five high-dimensional density estimation and generative modeling tasks, OT-Flow performs competitively to state-of-the-art CNFs while on average requiring one-fourth of the number of weights with an 8x speedup in training time and 24x speedup in inference.},
	urldate = {2024-02-16},
	publisher = {arXiv},
	author = {Onken, Derek and Fung, Samy Wu and Li, Xingjian and Ruthotto, Lars},
	month = mar,
	year = {2021},
	note = {arXiv:2006.00104 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 10 pages, 7 figures},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/V5EBWX4H/Onken et al. - 2021 - OT-Flow Fast and Accurate Continuous Normalizing .pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/W2ES9SIX/2006.html:text/html},
}

@misc{wang_generative_2023,
	title = {Generative diffusion learning for parametric partial differential equations},
	url = {http://arxiv.org/abs/2305.14703},
	abstract = {We develop a class of data-driven generative models that approximate the solution operator for parameter-dependent partial differential equations (PDE). We propose a novel probabilistic formulation of the operator learning problem based on recently developed generative denoising diffusion probabilistic models (DDPM) in order to learn the input-to-output mapping between problem parameters and solutions of the PDE. To achieve this goal we modify DDPM to supervised learning in which the solution operator for the PDE is represented by a class of conditional distributions. The probabilistic formulation combined with DDPM allows for an automatic quantification of confidence intervals for the learned solutions. Furthermore, the framework is directly applicable for learning from a noisy data set. We compare computational performance of the developed method with the Fourier Network Operators (FNO). Our results show that our method achieves comparable accuracy and recovers the noise magnitude when applied to data sets with outputs corrupted by additive noise.},
	urldate = {2024-02-22},
	publisher = {arXiv},
	author = {Wang, Ting and Plechac, Petr and Knap, Jaroslaw},
	month = may,
	year = {2023},
	note = {arXiv:2305.14703 [cs, math]},
	keywords = {Mathematics - Numerical Analysis},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/NWUSLB9C/Wang et al. - 2023 - Generative diffusion learning for parametric parti.pdf:application/pdf},
}

@misc{xu_normalizing_2024,
	title = {Normalizing flow neural networks by {JKO} scheme},
	url = {http://arxiv.org/abs/2212.14424},
	abstract = {Normalizing flow is a class of deep generative models for efficient sampling and likelihood estimation, which achieves attractive performance, particularly in high dimensions. The flow is often implemented using a sequence of invertible residual blocks. Existing works adopt special network architectures and regularization of flow trajectories. In this paper, we develop a neural ODE flow network called JKO-iFlow, inspired by the Jordan-Kinderleherer-Otto (JKO) scheme, which unfolds the discrete-time dynamic of the Wasserstein gradient flow. The proposed method stacks residual blocks one after another, allowing efficient block-wise training of the residual blocks, avoiding sampling SDE trajectories and score matching or variational learning, thus reducing the memory load and difficulty in end-to-end training. We also develop adaptive time reparameterization of the flow network with a progressive refinement of the induced trajectory in probability space to improve the model accuracy further. Experiments with synthetic and real data show that the proposed JKO-iFlow network achieves competitive performance compared with existing flow and diffusion models at a significantly reduced computational and memory cost.},
	urldate = {2024-02-23},
	publisher = {arXiv},
	author = {Xu, Chen and Cheng, Xiuyuan and Xie, Yao},
	month = feb,
	year = {2024},
	note = {arXiv:2212.14424 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: NeurIPS 2023 spotlight},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/8K8U4KBY/Xu et al. - 2024 - Normalizing flow neural networks by JKO scheme.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/QQAF35Q9/2212.html:text/html},
}

@misc{fan_variational_2022,
	title = {Variational {Wasserstein} gradient flow},
	url = {http://arxiv.org/abs/2112.02424},
	abstract = {Wasserstein gradient flow has emerged as a promising approach to solve optimization problems over the space of probability distributions. A recent trend is to use the well-known JKO scheme in combination with input convex neural networks to numerically implement the proximal step. The most challenging step, in this setup, is to evaluate functions involving density explicitly, such as entropy, in terms of samples. This paper builds on the recent works with a slight but crucial difference: we propose to utilize a variational formulation of the objective function formulated as maximization over a parametric class of functions. Theoretically, the proposed variational formulation allows the construction of gradient flows directly for empirical distributions with a well-defined and meaningful objective function. Computationally, this approach replaces the computationally expensive step in existing methods, to handle objective functions involving density, with inner loop updates that only require a small batch of samples and scale well with the dimension. The performance and scalability of the proposed method are illustrated with the aid of several numerical experiments involving high-dimensional synthetic and real datasets.},
	urldate = {2024-02-23},
	publisher = {arXiv},
	author = {Fan, Jiaojiao and Zhang, Qinsheng and Taghvaei, Amirhossein and Chen, Yongxin},
	month = jul,
	year = {2022},
	note = {arXiv:2112.02424 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/NFNPWS8K/Fan et al. - 2022 - Variational Wasserstein gradient flow.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/GQXGEZXM/2112.html:text/html},
}

@misc{cheng_convergence_2023,
	title = {Convergence of flow-based generative models via proximal gradient descent in {Wasserstein} space},
	url = {http://arxiv.org/abs/2310.17582},
	abstract = {Flow-based generative models enjoy certain advantages in computing the data generation and the likelihood, and have recently shown competitive empirical performance. Compared to the accumulating theoretical studies on related score-based diffusion models, analysis of flow-based models, which are deterministic in both forward (data-to-noise) and reverse (noise-to-data) directions, remain sparse. In this paper, we provide a theoretical guarantee of generating data distribution by a progressive flow model, the so-called JKO flow model, which implements the Jordan-Kinderleherer-Otto (JKO) scheme in a normalizing flow network. Leveraging the exponential convergence of the proximal gradient descent (GD) in Wasserstein space, we prove the Kullback-Leibler (KL) guarantee of data generation by a JKO flow model to be \$O({\textbackslash}varepsilon{\textasciicircum}2)\$ when using \$N {\textbackslash}lesssim {\textbackslash}log (1/{\textbackslash}varepsilon)\$ many JKO steps (\$N\$ Residual Blocks in the flow) where \${\textbackslash}varepsilon \$ is the error in the per-step first-order condition. The assumption on data density is merely a finite second moment, and the theory extends to data distributions without density and when there are inversion errors in the reverse process where we obtain KL-\$W\_2\$ mixed error guarantees. The non-asymptotic convergence rate of the JKO-type \$W\_2\$-proximal GD is proved for a general class of convex objective functionals that includes the KL divergence as a special case, which can be of independent interest.},
	urldate = {2024-02-23},
	publisher = {arXiv},
	author = {Cheng, Xiuyuan and Lu, Jianfeng and Tan, Yixin and Xie, Yao},
	month = oct,
	year = {2023},
	note = {arXiv:2310.17582 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning, Mathematics - Statistics Theory},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/WFUW42WB/Cheng et al. - 2023 - Convergence of flow-based generative models via pr.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/9LE5E8HZ/2310.html:text/html},
}

@article{lu_pde_nodate,
	title = {{PDE} analysis for sampling dynamics and generative models},
	language = {en},
	author = {Lu, Jianfeng},
	file = {hjws2_16259.pdf:/Users/tobias/Downloads/hjws2_16259.pdf:application/pdf},
}

@article{kim_numerical_2007,
	title = {Numerical solutions of {Burgers}’ equation with random initial conditions using the {Wiener} chaos expansion and the {Lax}–{Wendroff} scheme},
	volume = {20},
	issn = {08939659},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893965906002217},
	doi = {10.1016/j.aml.2006.07.001},
	language = {en},
	number = {5},
	urldate = {2024-02-23},
	journal = {Applied Mathematics Letters},
	author = {Kim, Hongjoong},
	month = may,
	year = {2007},
	pages = {545--550},
	file = {1-s2.0-S0893965906002217-main.pdf:/Users/tobias/Downloads/1-s2.0-S0893965906002217-main.pdf:application/pdf},
}

@misc{neklyudov_computational_2023,
	title = {A {Computational} {Framework} for {Solving} {Wasserstein} {Lagrangian} {Flows}},
	url = {http://arxiv.org/abs/2310.10649},
	abstract = {The dynamical formulation of the optimal transport can be extended through various choices of the underlying geometry (\${\textbackslash}textit\{kinetic energy\}\$), and the regularization of density paths (\${\textbackslash}textit\{potential energy\}\$). These combinations yield different variational problems (\${\textbackslash}textit\{Lagrangians\}\$), encompassing many variations of the optimal transport problem such as the Schr{\textbackslash}"odinger bridge, unbalanced optimal transport, and optimal transport with physical constraints, among others. In general, the optimal density path is unknown, and solving these variational problems can be computationally challenging. Leveraging the dual formulation of the Lagrangians, we propose a novel deep learning based framework approaching all of these problems from a unified perspective. Our method does not require simulating or backpropagating through the trajectories of the learned dynamics, and does not need access to optimal couplings. We showcase the versatility of the proposed framework by outperforming previous approaches for the single-cell trajectory inference, where incorporating prior knowledge into the dynamics is crucial for correct predictions.},
	urldate = {2024-03-27},
	publisher = {arXiv},
	author = {Neklyudov, Kirill and Brekelmans, Rob and Tong, Alexander and Atanackovic, Lazar and Liu, Qiang and Makhzani, Alireza},
	month = oct,
	year = {2023},
	note = {arXiv:2310.10649 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/IN3CH585/Neklyudov et al. - 2023 - A Computational Framework for Solving Wasserstein .pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/TGMYAHIH/2310.html:text/html},
}

@misc{lim_score-based_2023,
	title = {Score-based {Diffusion} {Models} in {Function} {Space}},
	url = {http://arxiv.org/abs/2302.07400},
	abstract = {Diffusion models have recently emerged as a powerful framework for generative modeling. They consist of a forward process that perturbs input data with Gaussian white noise and a reverse process that learns a score function to generate samples by denoising. Despite their tremendous success, they are mostly formulated on finite-dimensional spaces, e.g. Euclidean, limiting their applications to many domains where the data has a functional form such as in scientific computing and 3D geometric data analysis. In this work, we introduce a mathematically rigorous framework called Denoising Diffusion Operators (DDOs) for training diffusion models in function space. In DDOs, the forward process perturbs input functions gradually using a Gaussian process. The generative process is formulated by integrating a function-valued Langevin dynamic. Our approach requires an appropriate notion of the score for the perturbed data distribution, which we obtain by generalizing denoising score matching to function spaces that can be infinite-dimensional. We show that the corresponding discretized algorithm generates accurate samples at a fixed cost that is independent of the data resolution. We theoretically and numerically verify the applicability of our approach on a set of problems, including generating solutions to the Navier-Stokes equation viewed as the push-forward distribution of forcings from a Gaussian Random Field (GRF).},
	urldate = {2024-03-27},
	publisher = {arXiv},
	author = {Lim, Jae Hyun and Kovachki, Nikola B. and Baptista, Ricardo and Beckham, Christopher and Azizzadenesheli, Kamyar and Kossaifi, Jean and Voleti, Vikram and Song, Jiaming and Kreis, Karsten and Kautz, Jan and Pal, Christopher and Vahdat, Arash and Anandkumar, Anima},
	month = nov,
	year = {2023},
	note = {arXiv:2302.07400 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Functional Analysis, 46B09 (Primary), 60J22 (Secondary), I.2.6, J.2},
	annote = {Comment: 52 pages},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/TX6MA8VA/Lim et al. - 2023 - Score-based Diffusion Models in Function Space.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/BNQCF6E5/2302.html:text/html},
}

@article{stuart_inverse_2010,
	title = {Inverse problems: {A} {Bayesian} perspective},
	volume = {19},
	copyright = {https://www.cambridge.org/core/terms},
	issn = {0962-4929, 1474-0508},
	shorttitle = {Inverse problems},
	url = {https://www.cambridge.org/core/product/identifier/S0962492910000061/type/journal_article},
	doi = {10.1017/S0962492910000061},
	abstract = {The subject of inverse problems in differential equations is of enormous practical importance, and has also generated substantial mathematical and computational innovation. Typically some form of regularization is required to ameliorate ill-posed behaviour. In this article we review the Bayesian approach to regularization, developing a function space viewpoint on the subject. This approach allows for a full characterization of all possible solutions, and their relative probabilities, whilst simultaneously forcing significant modelling issues to be addressed in a clear and precise fashion. Although expensive to implement, this approach is starting to lie within the range of the available computational resources in many application areas. It also allows for the quantification of uncertainty and risk, something which is increasingly demanded by these applications. Furthermore, the approach is conceptually important for the understanding of simpler, computationally expedient approaches to inverse problems.},
	language = {en},
	urldate = {2024-03-27},
	journal = {Acta Numerica},
	author = {Stuart, A. M.},
	month = may,
	year = {2010},
	pages = {451--559},
	file = {Accepted Version:/Users/tobias/Zotero/storage/9G54TM6Y/Stuart - 2010 - Inverse problems A Bayesian perspective.pdf:application/pdf},
}

@misc{lienen_zero_2024,
	title = {From {Zero} to {Turbulence}: {Generative} {Modeling} for {3D} {Flow} {Simulation}},
	shorttitle = {From {Zero} to {Turbulence}},
	url = {http://arxiv.org/abs/2306.01776},
	abstract = {Simulations of turbulent flows in 3D are one of the most expensive simulations in computational fluid dynamics (CFD). Many works have been written on surrogate models to replace numerical solvers for fluid flows with faster, learned, autoregressive models. However, the intricacies of turbulence in three dimensions necessitate training these models with very small time steps, while generating realistic flow states requires either long roll-outs with many steps and significant error accumulation or starting from a known, realistic flow state - something we aimed to avoid in the first place. Instead, we propose to approach turbulent flow simulation as a generative task directly learning the manifold of all possible turbulent flow states without relying on any initial flow state. For our experiments, we introduce a challenging 3D turbulence dataset of high-resolution flows and detailed vortex structures caused by various objects and derive two novel sample evaluation metrics for turbulent flows. On this dataset, we show that our generative model captures the distribution of turbulent flows caused by unseen objects and generates high-quality, realistic samples amenable for downstream applications without access to any initial state.},
	urldate = {2024-03-27},
	publisher = {arXiv},
	author = {Lienen, Marten and Lüdke, David and Hansen-Palmus, Jan and Günnemann, Stephan},
	month = mar,
	year = {2024},
	note = {arXiv:2306.01776 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Fluid Dynamics},
	annote = {Comment: Published at ICLR 2024},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/66NECV2A/Lienen et al. - 2024 - From Zero to Turbulence Generative Modeling for 3.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/V6DB5TTQ/2306.html:text/html},
}

@misc{cachay_dyffusion_2023,
	title = {{DYffusion}: {A} {Dynamics}-informed {Diffusion} {Model} for {Spatiotemporal} {Forecasting}},
	shorttitle = {{DYffusion}},
	url = {http://arxiv.org/abs/2306.01984},
	abstract = {While diffusion models can successfully generate data and make predictions, they are predominantly designed for static images. We propose an approach for efficiently training diffusion models for probabilistic spatiotemporal forecasting, where generating stable and accurate rollout forecasts remains challenging, Our method, DYffusion, leverages the temporal dynamics in the data, directly coupling it with the diffusion steps in the model. We train a stochastic, time-conditioned interpolator and a forecaster network that mimic the forward and reverse processes of standard diffusion models, respectively. DYffusion naturally facilitates multi-step and long-range forecasting, allowing for highly flexible, continuous-time sampling trajectories and the ability to trade-off performance with accelerated sampling at inference time. In addition, the dynamics-informed diffusion process in DYffusion imposes a strong inductive bias and significantly improves computational efficiency compared to traditional Gaussian noise-based diffusion models. Our approach performs competitively on probabilistic forecasting of complex dynamics in sea surface temperatures, Navier-Stokes flows, and spring mesh systems.},
	urldate = {2024-03-27},
	publisher = {arXiv},
	author = {Cachay, Salva Rühling and Zhao, Bo and Joren, Hailey and Yu, Rose},
	month = oct,
	year = {2023},
	note = {arXiv:2306.01984 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: Accepted to NeurIPS 2023; Code is available at: https://github.com/Rose-STL-Lab/dyffusion},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/647CHRU9/Cachay et al. - 2023 - DYffusion A Dynamics-informed Diffusion Model for.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/LUFR4LYK/2306.html:text/html},
}

@misc{chen_probabilistic_2024,
	title = {Probabilistic {Forecasting} with {Stochastic} {Interpolants} and {F}{\textbackslash}"ollmer {Processes}},
	url = {http://arxiv.org/abs/2403.13724},
	abstract = {We propose a framework for probabilistic forecasting of dynamical systems based on generative modeling. Given observations of the system state over time, we formulate the forecasting problem as sampling from the conditional distribution of the future system state given its current state. To this end, we leverage the framework of stochastic interpolants, which facilitates the construction of a generative model between an arbitrary base distribution and the target. We design a fictitious, non-physical stochastic dynamics that takes as initial condition the current system state and produces as output a sample from the target conditional distribution in finite time and without bias. This process therefore maps a point mass centered at the current state onto a probabilistic ensemble of forecasts. We prove that the drift coefficient entering the stochastic differential equation (SDE) achieving this task is non-singular, and that it can be learned efficiently by square loss regression over the time-series data. We show that the drift and the diffusion coefficients of this SDE can be adjusted after training, and that a specific choice that minimizes the impact of the estimation error gives a F{\textbackslash}"ollmer process. We highlight the utility of our approach on several complex, high-dimensional forecasting problems, including stochastically forced Navier-Stokes and video prediction on the KTH and CLEVRER datasets.},
	urldate = {2024-03-27},
	publisher = {arXiv},
	author = {Chen, Yifan and Goldstein, Mark and Hua, Mengjian and Albergo, Michael S. and Boffi, Nicholas M. and Vanden-Eijnden, Eric},
	month = mar,
	year = {2024},
	note = {arXiv:2403.13724 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/U45RRIDZ/Chen et al. - 2024 - Probabilistic Forecasting with Stochastic Interpol.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/DZ4TQFEK/2403.html:text/html},
}

@article{lott_geometric_2007,
	title = {Some {Geometric} {Calculations} on {Wasserstein} {Space}},
	volume = {277},
	copyright = {http://www.springer.com/tdm},
	issn = {0010-3616, 1432-0916},
	url = {http://link.springer.com/10.1007/s00220-007-0367-3},
	doi = {10.1007/s00220-007-0367-3},
	language = {en},
	number = {2},
	urldate = {2024-03-27},
	journal = {Communications in Mathematical Physics},
	author = {Lott, John},
	month = nov,
	year = {2007},
	pages = {423--437},
	file = {Submitted Version:/Users/tobias/Zotero/storage/LRYMX727/Lott - 2007 - Some Geometric Calculations on Wasserstein Space.pdf:application/pdf},
}

@article{bonnet_pontryagin_2019,
	title = {The {Pontryagin} {Maximum} {Principle} in the {Wasserstein} {Space}},
	volume = {58},
	issn = {0944-2669, 1432-0835},
	url = {http://arxiv.org/abs/1711.07667},
	doi = {10.1007/s00526-018-1447-2},
	abstract = {We prove a Pontryagin Maximum Principle for optimal control problems in the space of probability measures, where the dynamics is given by a transport equation with non-local velocity. We formulate this first-order optimality condition using the formalism of subdifferential calculus in Wasserstein spaces. We show that the geometric approach based on needle variations and on the evolution of the covector (here replaced by the evolution of a mesure on the dual space) can be translated into this formalism.},
	number = {1},
	urldate = {2024-03-27},
	journal = {Calculus of Variations and Partial Differential Equations},
	author = {Bonnet, Benoît and Rossi, Francesco},
	month = feb,
	year = {2019},
	note = {arXiv:1711.07667 [math]},
	keywords = {Mathematics - Optimization and Control},
	pages = {11},
	annote = {Comment: 31 pages, 1 figure},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/3C2XCCWG/Bonnet and Rossi - 2019 - The Pontryagin Maximum Principle in the Wasserstei.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/NIY96DJ5/1711.html:text/html},
}

@article{cui_stochastic_2023,
	title = {Stochastic {Wasserstein} {Hamiltonian} {Flows}},
	issn = {1040-7294, 1572-9222},
	url = {https://link.springer.com/10.1007/s10884-023-10264-4},
	doi = {10.1007/s10884-023-10264-4},
	language = {en},
	urldate = {2024-03-27},
	journal = {Journal of Dynamics and Differential Equations},
	author = {Cui, Jianbo and Liu, Shu and Zhou, Haomin},
	month = apr,
	year = {2023},
	file = {Submitted Version:/Users/tobias/Zotero/storage/P2YKL2NQ/Cui et al. - 2023 - Stochastic Wasserstein Hamiltonian Flows.pdf:application/pdf},
}

@article{gangbo_optimal_2014,
	title = {Optimal transport and large number of particles},
	volume = {34},
	issn = {1553-5231},
	url = {http://aimsciences.org//article/doi/10.3934/dcds.2014.34.1397},
	doi = {10.3934/dcds.2014.34.1397},
	language = {en},
	number = {4},
	urldate = {2024-03-27},
	journal = {Discrete \& Continuous Dynamical Systems - A},
	author = {Gangbo, Wilfrid and Świech, Andrzej and {,School of Mathematics, Georgia Institute of Technology, 686 Cherry Street, Atlanta, GA 30332-0160}},
	year = {2014},
	pages = {1397--1441},
	file = {Gan-Swi-2012.pdf:/Users/tobias/Downloads/Gan-Swi-2012.pdf:application/pdf},
}

@article{ambrosio_hamiltonian_2008,
	title = {Hamiltonian {ODEs} in the {Wasserstein} space of probability measures},
	volume = {61},
	issn = {0010-3640, 1097-0312},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/cpa.20188},
	doi = {10.1002/cpa.20188},
	abstract = {Abstract
            
              In this paper we consider a Hamiltonian
              H
              on 𝒫
              2
              (ℝ
              
                2
                d
              
              ), the set of probability measures with finite quadratic moments on the phase space ℝ
              
                2
                d
              
              = ℝ
              
                d
              
              × ℝ
              
                d
              
              , which is a metric space when endowed with the Wasserstein distance
              W
              2
              . We study the initial value problem
              d
              μ
              
                t
              
              /
              dt
              + ∇ · (𝕁
              
                d
              
              v
              
                t
              
              μ
              
                t
              
              ) = 0, where 𝕁
              
                d
              
              is the canonical symplectic matrix, μ
              0
              is prescribed, and
              v
              
                t
              
              is a tangent vector to 𝒫
              2
              (ℝ
              
                2
                d
              
              ) at μ
              
                t
              
              , belonging to ∂
              H
              (μ
              
                t
              
              ), the subdifferential of
              H
              at μ
              
                t
              
              . Two methods for constructing solutions of the evolutive system are provided. The first one concerns only the case where μ
              0
              is absolutely continuous. It ensures that μ
              
                t
              
              remains absolutely continuous and
              v
              
                t
              
              = ∇
              H
              (μ
              
                t
              
              ) is the element of minimal norm in ∂
              H
              (μ
              
                t
              
              ). The second method handles any initial measure μ
              0
              . If we further assume that
              H
              is λ‐convex, proper, and lower‐semicontinuous on 𝒫
              2
              (ℝ
              
                2
                d
              
              ), we prove that the Hamiltonian is preserved along any solution of our evolutive system,
              H
              (μ
              
                t
              
              ) =
              H
              (μ
              0
              ). © 2007 Wiley Periodicals, Inc.},
	language = {en},
	number = {1},
	urldate = {2024-03-27},
	journal = {Communications on Pure and Applied Mathematics},
	author = {Ambrosio, Luigi and Gangbo, Wilfrid},
	month = jan,
	year = {2008},
	pages = {18--53},
	file = {Submitted Version:/Users/tobias/Zotero/storage/XPGPN4GQ/Ambrosio and Gangbo - 2008 - Hamiltonian ODEs in the Wasserstein space of proba.pdf:application/pdf},
}

@article{bonnet_pontryagin_2019-1,
	title = {A {Pontryagin} {Maximum} {Principle} in {Wasserstein} spaces for constrained optimal control problems},
	volume = {25},
	copyright = {http://creativecommons.org/licenses/by/4.0},
	issn = {1292-8119, 1262-3377},
	url = {https://www.esaim-cocv.org/10.1051/cocv/2019044},
	doi = {10.1051/cocv/2019044},
	abstract = {In this paper, we prove a Pontryagin Maximum Principle for constrained optimal control problems in the Wasserstein space of probability measures. The dynamics is described by a transport equation with non-local velocities which are affine in the control, and is subject to end-point and running state constraints. Building on our previous work, we combine the classical method of needle-variations from geometric control theory and the metric differential structure of the Wasserstein spaces to obtain a maximum principle formulated in the so-called Gamkrelidze form.},
	urldate = {2024-03-27},
	journal = {ESAIM: Control, Optimisation and Calculus of Variations},
	author = {Bonnet, Benoît},
	year = {2019},
	pages = {52},
	file = {Full Text:/Users/tobias/Zotero/storage/5Z2QNWDR/Bonnet - 2019 - A Pontryagin Maximum Principle in Wasserstein spac.pdf:application/pdf},
}

@article{yang_generative_2022,
	title = {Generative {Ensemble} {Regression}: {Learning} {Particle} {Dynamics} from {Observations} of {Ensembles} with {Physics}-informed {Deep} {Generative} {Models}},
	volume = {44},
	issn = {1064-8275, 1095-7197},
	shorttitle = {Generative {Ensemble} {Regression}},
	url = {https://epubs.siam.org/doi/10.1137/21M1413018},
	doi = {10.1137/21M1413018},
	language = {en},
	number = {1},
	urldate = {2024-03-27},
	journal = {SIAM Journal on Scientific Computing},
	author = {Yang, Liu and Daskalakis, Constantinos and Karniadakis, George E.},
	month = feb,
	year = {2022},
	pages = {B80--B99},
	file = {Submitted Version:/Users/tobias/Zotero/storage/NK6B99K8/Yang et al. - 2022 - Generative Ensemble Regression Learning Particle .pdf:application/pdf},
}

@article{cui_time_2022,
	title = {Time discretizations of {Wasserstein}–{Hamiltonian} flows},
	copyright = {https://www.ams.org/publications/copyright-and-permissions},
	issn = {0025-5718, 1088-6842},
	url = {https://www.ams.org/mcom/0000-000-00/S0025-5718-2022-03726-1/},
	doi = {10.1090/mcom/3726},
	abstract = {We study discretizations of Hamiltonian systems on the probability density manifold equipped with the
              
                
                  
                    
                      L
                      2
                    
                    L{\textasciicircum}2
                  
                
              
              -Wasserstein metric. Based on discrete optimal transport theory, several Hamiltonian systems on a graph (lattice) with different weights are derived, which can be viewed as spatial discretizations of the original Hamiltonian systems. We prove consistency of these discretizations. Furthermore, by regularizing the system using the Fisher information, we deduce an explicit lower bound for the density function, which guarantees that symplectic schemes can be used to discretize in time. Moreover, we show desirable long time behavior of these symplectic schemes, and demonstrate their performance on several numerical examples. Finally, we compare the present approach with the standard viscosity methodology.},
	language = {en},
	urldate = {2024-03-27},
	journal = {Mathematics of Computation},
	author = {Cui, Jianbo and Dieci, Luca and Zhou, Haomin},
	month = mar,
	year = {2022},
	file = {Full Text:/Users/tobias/Zotero/storage/GVFVU2HU/Cui et al. - 2022 - Time discretizations of Wasserstein–Hamiltonian fl.pdf:application/pdf},
}

@article{feng_optimal_2013,
	title = {Optimal control for a mixed flow of {Hamiltonian} and gradient type in space of probability measures},
	volume = {365},
	issn = {0002-9947, 1088-6850},
	url = {http://www.ams.org/jourcgi/jour-getitem?pii=S0002-9947-2013-05634-6},
	doi = {10.1090/S0002-9947-2013-05634-6},
	language = {en},
	number = {8},
	urldate = {2024-03-27},
	journal = {Transactions of the American Mathematical Society},
	author = {Feng, Jin and Święch, Andrzej},
	month = mar,
	year = {2013},
	pages = {3987--4039},
	file = {Full Text:/Users/tobias/Zotero/storage/F5TUBM75/Feng and Święch - 2013 - Optimal control for a mixed flow of Hamiltonian an.pdf:application/pdf},
}

@article{jordan_variational_1998,
	title = {The {Variational} {Formulation} of the {Fokker}--{Planck} {Equation}},
	volume = {29},
	issn = {0036-1410, 1095-7154},
	url = {http://epubs.siam.org/doi/10.1137/S0036141096303359},
	doi = {10.1137/S0036141096303359},
	language = {en},
	number = {1},
	urldate = {2024-03-27},
	journal = {SIAM Journal on Mathematical Analysis},
	author = {Jordan, Richard and Kinderlehrer, David and Otto, Felix},
	month = jan,
	year = {1998},
	pages = {1--17},
	file = {s0036141096303359.pdf:/Users/tobias/Downloads/s0036141096303359.pdf:application/pdf},
}

@misc{dao_flow_2023,
	title = {Flow {Matching} in {Latent} {Space}},
	url = {http://arxiv.org/abs/2307.08698},
	abstract = {Flow matching is a recent framework to train generative models that exhibits impressive empirical performance while being relatively easier to train compared with diffusion-based models. Despite its advantageous properties, prior methods still face the challenges of expensive computing and a large number of function evaluations of off-the-shelf solvers in the pixel space. Furthermore, although latent-based generative methods have shown great success in recent years, this particular model type remains underexplored in this area. In this work, we propose to apply flow matching in the latent spaces of pretrained autoencoders, which offers improved computational efficiency and scalability for high-resolution image synthesis. This enables flow-matching training on constrained computational resources while maintaining their quality and flexibility. Additionally, our work stands as a pioneering contribution in the integration of various conditions into flow matching for conditional generation tasks, including label-conditioned image generation, image inpainting, and semantic-to-image generation. Through extensive experiments, our approach demonstrates its effectiveness in both quantitative and qualitative results on various datasets, such as CelebA-HQ, FFHQ, LSUN Church \& Bedroom, and ImageNet. We also provide a theoretical control of the Wasserstein-2 distance between the reconstructed latent flow distribution and true data distribution, showing it is upper-bounded by the latent flow matching objective. Our code will be available at https://github.com/VinAIResearch/LFM.git.},
	urldate = {2024-03-27},
	publisher = {arXiv},
	author = {Dao, Quan and Phung, Hao and Nguyen, Binh and Tran, Anh},
	month = jul,
	year = {2023},
	note = {arXiv:2307.08698 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Project Page: https://vinairesearch.github.io/LFM/},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/PZIDTV2N/Dao et al. - 2023 - Flow Matching in Latent Space.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/NX234VXI/2307.html:text/html;Full Text:/Users/tobias/Zotero/storage/D78KCLH4/Dao et al. - 2023 - Flow Matching in Latent Space.pdf:application/pdf},
}

@misc{liu_generalized_2023,
	title = {Generalized {Schrodinger} {Bridge} {Matching}},
	url = {http://arxiv.org/abs/2310.02233},
	abstract = {Modern distribution matching algorithms for training diffusion or flow models directly prescribe the time evolution of the marginal distributions between two boundary distributions. In this work, we consider a generalized distribution matching setup, where these marginals are only implicitly described as a solution to some task-specific objective function. The problem setup, known as the Generalized Schr{\textbackslash}"odinger Bridge (GSB), appears prevalently in many scientific areas both within and without machine learning. We propose Generalized Schr{\textbackslash}"odinger Bridge Matching (GSBM), a new matching algorithm inspired by recent advances, generalizing them beyond kinetic energy minimization and to account for task-specific state costs. We show that such a generalization can be cast as solving conditional stochastic optimal control, for which efficient variational approximations can be used, and further debiased with the aid of path integral theory. Compared to prior methods for solving GSB problems, our GSBM algorithm always preserves a feasible transport map between the boundary distributions throughout training, thereby enabling stable convergence and significantly improved scalability. We empirically validate our claims on an extensive suite of experimental setups, including crowd navigation, opinion depolarization, LiDAR manifolds, and image domain transfer. Our work brings new algorithmic opportunities for training diffusion models enhanced with task-specific optimality structures.},
	urldate = {2024-03-27},
	publisher = {arXiv},
	author = {Liu, Guan-Horng and Lipman, Yaron and Nickel, Maximilian and Karrer, Brian and Theodorou, Evangelos A. and Chen, Ricky T. Q.},
	month = oct,
	year = {2023},
	note = {arXiv:2310.02233 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/SD9MW6TD/Liu et al. - 2023 - Generalized Schrodinger Bridge Matching.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/D5TLDS45/2310.html:text/html},
}

@misc{portwood_turbulence_2019,
	title = {Turbulence forecasting via {Neural} {ODE}},
	url = {http://arxiv.org/abs/1911.05180},
	abstract = {Fluid turbulence is characterized by strong coupling across a broad range of scales. Furthermore, besides the usual local cascades, such coupling may extend to interactions that are non-local in scale-space. As such the computational demands associated with explicitly resolving the full set of scales and their interactions, as in the Direct Numerical Simulation (DNS) of the Navier-Stokes equations, in most problems of practical interest are so high that reduced modeling of scales and interactions is required before further progress can be made. While popular reduced models are typically based on phenomenological modeling of relevant turbulent processes, recent advances in machine learning techniques have energized efforts to further improve the accuracy of such reduced models. In contrast to such efforts that seek to improve an existing turbulence model, we propose a machine learning(ML) methodology that captures, de novo, underlying turbulence phenomenology without a pre-specified model form. To illustrate the approach, we consider transient modeling of the dissipation of turbulent kinetic energy, a fundamental turbulent process that is central to a wide range of turbulence models using a Neural ODE approach. After presenting details of the methodology, we show that this approach outperforms state-of-the-art approaches.},
	urldate = {2024-03-27},
	publisher = {arXiv},
	author = {Portwood, Gavin D. and Mitra, Peetak P. and Ribeiro, Mateus Dias and Nguyen, Tan Minh and Nadiga, Balasubramanya T. and Saenz, Juan A. and Chertkov, Michael and Garg, Animesh and Anandkumar, Anima and Dengel, Andreas and Baraniuk, Richard and Schmidt, David P.},
	month = nov,
	year = {2019},
	note = {arXiv:1911.05180 [physics]},
	keywords = {Physics - Computational Physics},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/34SUXERX/Portwood et al. - 2019 - Turbulence forecasting via Neural ODE.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/FWJEGNKE/1911.html:text/html},
}

@misc{scarvelis_riemannian_2023,
	title = {Riemannian {Metric} {Learning} via {Optimal} {Transport}},
	url = {http://arxiv.org/abs/2205.09244},
	abstract = {We introduce an optimal transport-based model for learning a metric tensor from cross-sectional samples of evolving probability measures on a common Riemannian manifold. We neurally parametrize the metric as a spatially-varying matrix field and efficiently optimize our model's objective using a simple alternating scheme. Using this learned metric, we can nonlinearly interpolate between probability measures and compute geodesics on the manifold. We show that metrics learned using our method improve the quality of trajectory inference on scRNA and bird migration data at the cost of little additional cross-sectional data.},
	urldate = {2024-04-03},
	publisher = {arXiv},
	author = {Scarvelis, Christopher and Solomon, Justin},
	month = mar,
	year = {2023},
	note = {arXiv:2205.09244 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: ICLR 2023},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/32WKYKNF/Scarvelis and Solomon - 2023 - Riemannian Metric Learning via Optimal Transport.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/T5DQUHTQ/2205.html:text/html},
}

@book{arnold_lectures_2004,
	address = {Berlin, Heidelberg},
	series = {Universitext},
	title = {Lectures on {Partial} {Differential} {Equations}},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-540-40448-4 978-3-662-05441-3},
	url = {http://link.springer.com/10.1007/978-3-662-05441-3},
	urldate = {2024-04-11},
	publisher = {Springer Berlin Heidelberg},
	author = {Arnold, Vladimir I.},
	year = {2004},
	doi = {10.1007/978-3-662-05441-3},
	file = {Submitted Version:/Users/tobias/Zotero/storage/TTG8DIIT/Arnold - 2004 - Lectures on Partial Differential Equations.pdf:application/pdf},
}

@book{arnold_mathematical_1978,
	address = {New York, NY},
	series = {Graduate {Texts} in {Mathematics}},
	title = {Mathematical {Methods} of {Classical} {Mechanics}},
	volume = {60},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-1-4757-1695-5 978-1-4757-1693-1},
	url = {http://link.springer.com/10.1007/978-1-4757-1693-1},
	urldate = {2024-04-11},
	publisher = {Springer New York},
	author = {Arnold, V. I.},
	editor = {Moore, C. C.},
	year = {1978},
	doi = {10.1007/978-1-4757-1693-1},
	file = {978-1-4757-1693-1.pdf:/Users/tobias/Downloads/978-1-4757-1693-1.pdf:application/pdf},
}

@article{otto_generalization_2000,
	title = {Generalization of an {Inequality} by {Talagrand} and {Links} with the {Logarithmic} {Sobolev} {Inequality}},
	volume = {173},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {00221236},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022123699935577},
	doi = {10.1006/jfan.1999.3557},
	language = {en},
	number = {2},
	urldate = {2024-04-11},
	journal = {Journal of Functional Analysis},
	author = {Otto, F. and Villani, C.},
	month = jun,
	year = {2000},
	pages = {361--400},
	file = {1-s2.0-S0022123699935577-main.pdf:/Users/tobias/Downloads/1-s2.0-S0022123699935577-main.pdf:application/pdf},
}

@article{mielke_nonsmooth_2013,
	title = {Nonsmooth analysis of doubly nonlinear evolution equations},
	volume = {46},
	copyright = {http://www.springer.com/tdm},
	issn = {0944-2669, 1432-0835},
	url = {http://link.springer.com/10.1007/s00526-011-0482-z},
	doi = {10.1007/s00526-011-0482-z},
	language = {en},
	number = {1-2},
	urldate = {2024-04-12},
	journal = {Calculus of Variations and Partial Differential Equations},
	author = {Mielke, Alexander and Rossi, Riccarda and Savaré, Giuseppe},
	month = jan,
	year = {2013},
	pages = {253--310},
	file = {Submitted Version:/Users/tobias/Zotero/storage/W7D2TJ3V/Mielke et al. - 2013 - Nonsmooth analysis of doubly nonlinear evolution e.pdf:application/pdf},
}

@article{benamou_entropic_2024,
	title = {Entropic optimal transport solutions of the semigeostrophic equations},
	volume = {500},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999123008410},
	doi = {10.1016/j.jcp.2023.112745},
	language = {en},
	urldate = {2024-04-12},
	journal = {Journal of Computational Physics},
	author = {Benamou, J.-D. and Cotter, C.J. and Malamut, H.},
	month = mar,
	year = {2024},
	pages = {112745},
	file = {Full Text:/Users/tobias/Zotero/storage/6EGV362J/Benamou et al. - 2024 - Entropic optimal transport solutions of the semige.pdf:application/pdf},
}

@article{buttazzo_path_2006,
	title = {Path {Functionals} over {Wasserstein} {Spaces}},
	volume = {8},
	issn = {1435-9855, 1435-9863},
	url = {https://ems.press/doi/10.4171/jems/61},
	doi = {10.4171/jems/61},
	number = {3},
	urldate = {2024-04-12},
	journal = {Journal of the European Mathematical Society},
	author = {Buttazzo, Giuseppe and Brancolini, Alessio and Santambrogio, Filippo},
	month = sep,
	year = {2006},
	pages = {415--434},
	file = {Full Text:/Users/tobias/Zotero/storage/IKACG82T/Buttazzo et al. - 2006 - Path Functionals over Wasserstein Spaces.pdf:application/pdf},
}

@incollection{faris_chapter_2006,
	title = {Chapter {Five}. {Stochastic} {Mechanics}: {A} {Look} {Back} and a {Look} {Ahead}},
	isbn = {978-1-4008-6525-3},
	shorttitle = {Chapter {Five}. {Stochastic} {Mechanics}},
	url = {https://www.degruyter.com/document/doi/10.1515/9781400865253.117/html},
	urldate = {2024-04-12},
	booktitle = {Diffusion, {Quantum} {Theory}, and {Radically} {Elementary} {Mathematics}},
	publisher = {Princeton University Press},
	author = {Carlen, Eric},
	editor = {Faris, William G.},
	month = dec,
	year = {2006},
	doi = {10.1515/9781400865253.117},
	pages = {117--140},
	file = {Carlen-StochasticMechanics-2006.pdf:/Users/tobias/Downloads/Carlen-StochasticMechanics-2006.pdf:application/pdf},
}

@book{nelson_dynamical_1967,
	title = {Dynamical {Theories} of {Brownian} {Motion}},
	isbn = {978-0-691-07950-9},
	url = {http://www.jstor.org/stable/j.ctv15r57jg},
	abstract = {These notes are based on a course of lectures given by Professor Nelson at Princeton during the spring term of 1966. The subject of Brownian motion has long been of interest in mathematical
probability. In these lectures, Professor Nelson traces the history of earlier work in Brownian motion, both the mathematical theory, and the natural phenomenon with its physical interpretations. He
continues through recent dynamical theories of Brownian motion, and concludes with a discussion of the relevance of these theories to quantum field theory and quantum statistical mechanics.},
	urldate = {2024-04-12},
	publisher = {Princeton University Press},
	author = {Nelson, Edward},
	year = {1967},
	doi = {10.2307/j.ctv15r57jg},
	file = {bmotion.pdf:/Users/tobias/Downloads/bmotion.pdf:application/pdf},
}

@techreport{schrodinger_uber_1931,
	address = {Berlin},
	title = {Über die {Umkehrung} der {Naturgesetze}},
	language = {German},
	number = {1931 IX},
	institution = {Akademie der Wissenschaften},
	author = {Schrödinger, Erwin},
	year = {1931},
	pages = {12},
	file = {1931-Schroedinger-Ueber die Umkehrung der Naturgesetze.pdf:/Users/tobias/Downloads/1931-Schroedinger-Ueber die Umkehrung der Naturgesetze.pdf:application/pdf},
}

@misc{lavenant_towards_2023,
	title = {Towards a mathematical theory of trajectory inference},
	url = {http://arxiv.org/abs/2102.09204},
	abstract = {We devise a theoretical framework and a numerical method to infer trajectories of a stochastic process from samples of its temporal marginals. This problem arises in the analysis of single cell RNA-sequencing data, which provide high dimensional measurements of cell states but cannot track the trajectories of the cells over time. We prove that for a class of stochastic processes it is possible to recover the ground truth trajectories from limited samples of the temporal marginals at each time-point, and provide an efficient algorithm to do so in practice. The method we develop, Global Waddington-OT (gWOT), boils down to a smooth convex optimization problem posed globally over all time-points involving entropy-regularized optimal transport. We demonstrate that this problem can be solved efficiently in practice and yields good reconstructions, as we show on several synthetic and real datasets.},
	urldate = {2024-04-23},
	publisher = {arXiv},
	author = {Lavenant, Hugo and Zhang, Stephen and Kim, Young-Heon and Schiebinger, Geoffrey},
	month = apr,
	year = {2023},
	note = {arXiv:2102.09204 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning, Mathematics - Statistics Theory, Mathematics - Probability, 62M20 (Primary) 62G99, 49M29, 92C15 (Secondary)},
	annote = {Comment: The first two authors contributed equally to this work; 76 pages},
	file = {arXiv Fulltext PDF:/Users/tobias/Zotero/storage/WUT9CT3E/Lavenant et al. - 2023 - Towards a mathematical theory of trajectory infere.pdf:application/pdf;arXiv.org Snapshot:/Users/tobias/Zotero/storage/J6CFX3XE/2102.html:text/html},
}

@book{hesthaven_certified_2016,
	address = {Cham},
	series = {{SpringerBriefs} in {Mathematics}},
	title = {Certified {Reduced} {Basis} {Methods} for {Parametrized} {Partial} {Differential} {Equations}},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-319-22469-5 978-3-319-22470-1},
	url = {https://link.springer.com/10.1007/978-3-319-22470-1},
	language = {en},
	urldate = {2024-05-12},
	publisher = {Springer International Publishing},
	author = {Hesthaven, Jan S and Rozza, Gianluigi and Stamm, Benjamin},
	year = {2016},
	doi = {10.1007/978-3-319-22470-1},
	file = {Submitted Version:/Users/tobias/Zotero/storage/P3JJG4US/Hesthaven et al. - 2016 - Certified Reduced Basis Methods for Parametrized P.pdf:application/pdf},
}

@article{cohen_approximation_2015,
	title = {Approximation of high-dimensional parametric {PDEs}},
	volume = {24},
	copyright = {https://www.cambridge.org/core/terms},
	issn = {0962-4929, 1474-0508},
	url = {https://www.cambridge.org/core/product/identifier/S0962492915000033/type/journal_article},
	doi = {10.1017/S0962492915000033},
	abstract = {Parametrized families of PDEs arise in various contexts such as inverse problems, control and optimization, risk assessment, and uncertainty quantification. In most of these applications, the number of parameters is large or perhaps even infinite. Thus, the development of numerical methods for these parametric problems is faced with the possible curse of dimensionality. This article is directed at (i) identifying and understanding which properties of parametric equations allow one to avoid this curse and (ii) developing and analysing effective numerical methods which fully exploit these properties and, in turn, are immune to the growth in dimensionality.
            
              Part I of this article studies the smoothness and approximability of the solution map, that is, the map
              
                
                  
                  \$a{\textbackslash}mapsto u(a)\$
                
              
              , where
              
                
                  
                  \$a\$
                
              
              is the parameter value and
              
                
                  
                  \$u(a)\$
                
              
              is the corresponding solution to the PDE. It is shown that for many relevant parametric PDEs, the parametric smoothness of this map is typically holomorphic and also highly anisotropic, in that the relevant parameters are of widely varying importance in describing the solution. These two properties are then exploited to establish convergence rates of
              
                
                  
                  \$n\$
                
              
              -term approximations to the solution map, for which each term is separable in the parametric and physical variables. These results reveal that, at least on a theoretical level, the solution map can be well approximated by discretizations of moderate complexity, thereby showing how the curse of dimensionality is broken. This theoretical analysis is carried out through concepts of approximation theory such as best
              
                
                  
                  \$n\$
                
              
              -term approximation, sparsity, and
              
                
                  
                  \$n\$
                
              
              -widths. These notions determine
              a priori
              the best possible performance of numerical methods and thus serve as a benchmark for concrete algorithms.
            
            
              Part II of this article turns to the development of numerical algorithms based on the theoretically established sparse separable approximations. The numerical methods studied fall into two general categories. The first uses polynomial expansions in terms of the parameters to approximate the solution map. The second one searches for suitable low-dimensional spaces for simultaneously approximating all members of the parametric family. The numerical implementation of these approaches is carried out through adaptive and greedy algorithms. An
              a priori
              analysis of the performance of these algorithms establishes how well they meet the theoretical benchmarks.},
	language = {en},
	urldate = {2024-05-12},
	journal = {Acta Numerica},
	author = {Cohen, Albert and DeVore, Ronald},
	month = may,
	year = {2015},
	pages = {1--159},
	file = {Submitted Version:/Users/tobias/Zotero/storage/KD8BJPQW/Cohen and DeVore - 2015 - Approximation of high-dimensional parametric PDEs.pdf:application/pdf},
}

@book{ern_theory_2004,
	address = {New York, NY},
	series = {Applied {Mathematical} {Sciences}},
	title = {Theory and {Practice} of {Finite} {Elements}},
	volume = {159},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-1-4419-1918-2 978-1-4757-4355-5},
	url = {http://link.springer.com/10.1007/978-1-4757-4355-5},
	language = {en},
	urldate = {2024-05-12},
	publisher = {Springer New York},
	author = {Ern, Alexandre and Guermond, Jean-Luc},
	year = {2004},
	doi = {10.1007/978-1-4757-4355-5},
	file = {Full Text:/Users/tobias/Zotero/storage/D6TVVSGZ/Ern and Guermond - 2004 - Theory and Practice of Finite Elements.pdf:application/pdf},
}

@article{cea_approximation_1964,
	title = {Approximation variationnelle des problèmes aux limites},
	volume = {14},
	issn = {0373-0956},
	url = {https://aif.centre-mersenne.org/item/AIF_1964__14_2_345_0/},
	doi = {10.5802/aif.181},
	number = {2},
	urldate = {2024-05-12},
	journal = {Annales de l’institut Fourier},
	author = {Cea, Jean},
	year = {1964},
	pages = {345--444},
	file = {Full Text:/Users/tobias/Zotero/storage/TSECEWK4/Cea - 1964 - Approximation variationnelle des problèmes aux lim.pdf:application/pdf},
}

@article{ramgraber_ensemble_2023,
	title = {Ensemble transport smoothing. {Part} {I}: {Unified} framework},
	volume = {17},
	issn = {25900552},
	shorttitle = {Ensemble transport smoothing. {Part} {I}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2590055223000124},
	doi = {10.1016/j.jcpx.2023.100134},
	language = {en},
	urldate = {2024-05-13},
	journal = {Journal of Computational Physics: X},
	author = {Ramgraber, Maximilian and Baptista, Ricardo and McLaughlin, Dennis and Marzouk, Youssef},
	month = nov,
	year = {2023},
	pages = {100134},
	file = {Submitted Version:/Users/tobias/Zotero/storage/YGJQHM2J/Ramgraber et al. - 2023 - Ensemble transport smoothing. Part I Unified fram.pdf:application/pdf},
}

@article{el_moselhy_bayesian_2012,
	title = {Bayesian inference with optimal maps},
	volume = {231},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999112003956},
	doi = {10.1016/j.jcp.2012.07.022},
	language = {en},
	number = {23},
	urldate = {2024-05-13},
	journal = {Journal of Computational Physics},
	author = {El Moselhy, Tarek A. and Marzouk, Youssef M.},
	month = oct,
	year = {2012},
	pages = {7815--7850},
	file = {Submitted Version:/Users/tobias/Zotero/storage/SCW7GEGF/El Moselhy and Marzouk - 2012 - Bayesian inference with optimal maps.pdf:application/pdf},
}

@article{benamou_computational_2000,
	title = {A computational fluid mechanics solution to the {Monge}-{Kantorovich} mass transfer problem},
	volume = {84},
	copyright = {http://www.springer.com/tdm},
	issn = {0029-599X, 0945-3245},
	url = {http://link.springer.com/10.1007/s002110050002},
	doi = {10.1007/s002110050002},
	number = {3},
	urldate = {2024-05-13},
	journal = {Numerische Mathematik},
	author = {Benamou, Jean-David and Brenier, Yann},
	month = jan,
	year = {2000},
	pages = {375--393},
}

@article{tyranowski_stochastic_2021,
	title = {Stochastic variational principles for the collisional {Vlasov}–{Maxwell} and {Vlasov}–{Poisson} equations},
	volume = {477},
	issn = {1364-5021, 1471-2946},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspa.2021.0167},
	doi = {10.1098/rspa.2021.0167},
	abstract = {In this work, we recast the collisional Vlasov–Maxwell and Vlasov–Poisson equations as systems of coupled stochastic and partial differential equations, and we derive stochastic variational principles which underlie such reformulations. We also propose a stochastic particle method for the collisional Vlasov–Maxwell equations and provide a variational characterization of it, which can be used as a basis for a further development of stochastic structure-preserving particle-in-cell integrators.},
	language = {en},
	number = {2252},
	urldate = {2024-05-13},
	journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Tyranowski, Tomasz M.},
	month = aug,
	year = {2021},
	pages = {20210167},
	file = {Full Text:/Users/tobias/Zotero/storage/N965W8LZ/Tyranowski - 2021 - Stochastic variational principles for the collisio.pdf:application/pdf},
}

@article{lenard_plasma_1958,
	title = {Plasma {Oscillations} with {Diffusion} in {Velocity} {Space}},
	volume = {112},
	copyright = {http://link.aps.org/licenses/aps-default-license},
	issn = {0031-899X},
	url = {https://link.aps.org/doi/10.1103/PhysRev.112.1456},
	doi = {10.1103/PhysRev.112.1456},
	language = {en},
	number = {5},
	urldate = {2024-05-13},
	journal = {Physical Review},
	author = {Lenard, A. and Bernstein, Ira B.},
	month = dec,
	year = {1958},
	pages = {1456--1459},
}

@article{chow_wasserstein_2020,
	title = {Wasserstein {Hamiltonian} flows},
	volume = {268},
	issn = {00220396},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022039619303882},
	doi = {10.1016/j.jde.2019.08.046},
	language = {en},
	number = {3},
	urldate = {2024-05-13},
	journal = {Journal of Differential Equations},
	author = {Chow, Shui-Nee and Li, Wuchen and Zhou, Haomin},
	month = jan,
	year = {2020},
	pages = {1205--1219},
	file = {Submitted Version:/Users/tobias/Zotero/storage/NNPUYHB8/Chow et al. - 2020 - Wasserstein Hamiltonian flows.pdf:application/pdf},
}

@article{gentil_dynamical_2020,
	title = {Dynamical aspects of the generalized {Schrödinger} problem via {Otto} calculus – {A} heuristic point of view},
	volume = {36},
	issn = {0213-2230, 2235-0616},
	url = {https://ems.press/doi/10.4171/rmi/1159},
	doi = {10.4171/rmi/1159},
	number = {4},
	urldate = {2024-05-13},
	journal = {Revista Matemática Iberoamericana},
	author = {Gentil, Ivan and Léonard, Christian and Ripani, Luigia},
	month = jan,
	year = {2020},
	pages = {1071--1112},
	file = {Submitted Version:/Users/tobias/Zotero/storage/GI3BBB3M/Gentil et al. - 2020 - Dynamical aspects of the generalized Schrödinger p.pdf:application/pdf},
}

@inproceedings{koshizuka_neural_2023,
	title = {Neural {Lagrangian} {Schrödinger} {Bridge}: {Diffusion} {Modeling} for {Population} {Dynamics}},
	url = {https://openreview.net/forum?id=d3QNWD_pcFv},
	booktitle = {The {Eleventh} {International} {Conference} on {Learning} {Representations}},
	author = {Koshizuka, Takeshi and Sato, Issei},
	year = {2023},
}

@inproceedings{lipman_flow_2023,
	title = {Flow {Matching} for {Generative} {Modeling}},
	url = {https://openreview.net/forum?id=PqvMRDCJT9t},
	booktitle = {The {Eleventh} {International} {Conference} on {Learning} {Representations}},
	author = {Lipman, Yaron and Chen, Ricky T. Q. and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matthew},
	year = {2023},
}

@inproceedings{liu_flow_2023,
	title = {Flow {Straight} and {Fast}: {Learning} to {Generate} and {Transfer} {Data} with {Rectified} {Flow}},
	url = {https://openreview.net/forum?id=XVjTT1nw5z},
	booktitle = {The {Eleventh} {International} {Conference} on {Learning} {Representations}},
	author = {Liu, Xingchao and Gong, Chengyue and liu, qiang},
	year = {2023},
}

@inproceedings{neklyudov_action_2023,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Action {Matching}: {Learning} {Stochastic} {Dynamics} from {Samples}},
	volume = {202},
	url = {https://proceedings.mlr.press/v202/neklyudov23a.html},
	abstract = {Learning the continuous dynamics of a system from snapshots of its temporal marginals is a problem which appears throughout natural sciences and machine learning, including in quantum systems, single-cell biological data, and generative modeling. In these settings, we assume access to cross-sectional samples that are uncorrelated over time, rather than full trajectories of samples. In order to better understand the systems under observation, we would like to learn a model of the underlying process that allows us to propagate samples in time and thereby simulate entire individual trajectories. In this work, we propose Action Matching, a method for learning a rich family of dynamics using only independent samples from its time evolution. We derive a tractable training objective, which does not rely on explicit assumptions about the underlying dynamics and does not require back-propagation through differential equations or optimal transport solvers. Inspired by connections with optimal transport, we derive extensions of Action Matching to learn stochastic differential equations and dynamics involving creation and destruction of probability mass. Finally, we showcase applications of Action Matching by achieving competitive performance in a diverse set of experiments from biology, physics, and generative modeling.},
	booktitle = {Proceedings of the 40th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Neklyudov, Kirill and Brekelmans, Rob and Severo, Daniel and Makhzani, Alireza},
	editor = {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
	month = jul,
	year = {2023},
	pages = {25858--25889},
}

@inproceedings{song_generative_2019,
	title = {Generative {Modeling} by {Estimating} {Gradients} of the {Data} {Distribution}},
	volume = {32},
	url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/3001ef257407d5a371a96dcd947c7d93-Paper.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Song, Yang and Ermon, Stefano},
	editor = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alché-Buc, F. d' and Fox, E. and Garnett, R.},
	year = {2019},
}

@article{weinreb_fundamental_2018,
	title = {Fundamental limits on dynamic inference from single-cell snapshots},
	volume = {115},
	issn = {0027-8424, 1091-6490},
	url = {https://pnas.org/doi/full/10.1073/pnas.1714723115},
	doi = {10.1073/pnas.1714723115},
	abstract = {Significance
            Seeing a snapshot of individuals at different stages of a dynamic process can reveal what the process would look like for a single individual over time. Biologists apply this principle to infer temporal sequences of gene expression states in cells from measurements made at a single moment in time. However, the sparsity and high dimensionality of single-cell data have made inference difficult using formal approaches. Here, we apply recent innovations in spectral graph theory to devise a simple and asymptotically exact algorithm for inferring the unique dynamic solution under defined approximations and apply it to data from bone marrow stem cells.
          , 
            Single-cell expression profiling reveals the molecular states of individual cells with unprecedented detail. Because these methods destroy cells in the process of analysis, they cannot measure how gene expression changes over time. However, some information on dynamics is present in the data: the continuum of molecular states in the population can reflect the trajectory of a typical cell. Many methods for extracting single-cell dynamics from population data have been proposed. However, all such attempts face a common limitation: for any measured distribution of cell states, there are multiple dynamics that could give rise to it, and by extension, multiple possibilities for underlying mechanisms of gene regulation. Here, we describe the aspects of gene expression dynamics that cannot be inferred from a static snapshot alone and identify assumptions necessary to constrain a unique solution for cell dynamics from static snapshots. We translate these constraints into a practical algorithmic approach, population balance analysis (PBA), which makes use of a method from spectral graph theory to solve a class of high-dimensional differential equations. We use simulations to show the strengths and limitations of PBA, and then apply it to single-cell profiles of hematopoietic progenitor cells (HPCs). Cell state predictions from this analysis agree with HPC fate assays reported in several papers over the past two decades. By highlighting the fundamental limits on dynamic inference faced by any method, our framework provides a rigorous basis for dynamic interpretation of a gene expression continuum and clarifies best experimental designs for trajectory reconstruction from static snapshot measurements.},
	language = {en},
	number = {10},
	urldate = {2024-05-14},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Weinreb, Caleb and Wolock, Samuel and Tusi, Betsabeh K. and Socolovsky, Merav and Klein, Allon M.},
	month = mar,
	year = {2018},
	file = {Full Text:/Users/tobias/Zotero/storage/E6LSFNZH/Weinreb et al. - 2018 - Fundamental limits on dynamic inference from singl.pdf:application/pdf},
}

@article{trapnell_dynamics_2014,
	title = {The dynamics and regulators of cell fate decisions are revealed by pseudotemporal ordering of single cells},
	volume = {32},
	copyright = {http://www.springer.com/tdm},
	issn = {1087-0156, 1546-1696},
	url = {https://www.nature.com/articles/nbt.2859},
	doi = {10.1038/nbt.2859},
	language = {en},
	number = {4},
	urldate = {2024-05-14},
	journal = {Nature Biotechnology},
	author = {Trapnell, Cole and Cacchiarelli, Davide and Grimsby, Jonna and Pokharel, Prapti and Li, Shuqiang and Morse, Michael and Lennon, Niall J and Livak, Kenneth J and Mikkelsen, Tarjei S and Rinn, John L},
	month = apr,
	year = {2014},
	pages = {381--386},
	file = {Accepted Version:/Users/tobias/Zotero/storage/DRY2VM33/Trapnell et al. - 2014 - The dynamics and regulators of cell fate decisions.pdf:application/pdf},
}

@article{farrell_single-cell_2018,
	title = {Single-cell reconstruction of developmental trajectories during zebrafish embryogenesis},
	volume = {360},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.aar3131},
	doi = {10.1126/science.aar3131},
	abstract = {Mapping the vertebrate developmental landscape
            
              As embryos develop, numerous cell types with distinct functions and morphologies arise from pluripotent cells. Three research groups have used single-cell RNA sequencing to analyze the transcriptional changes accompanying development of vertebrate embryos (see the Perspective by Harland). Wagner
              et al.
              sequenced the transcriptomes of more than 90,000 cells throughout zebrafish development to reveal how cells differentiate during axis patterning, germ layer formation, and early organogenesis. Farrell
              et al.
              profiled the transcriptomes of tens of thousands of embryonic cells and applied a computational approach to construct a branching tree describing the transcriptional trajectories that lead to 25 distinct zebrafish cell types. The branching tree revealed how cells change their gene expression as they become more and more specialized. Briggs
              et al.
              examined whole frog embryos, spanning zygotic genome activation through early organogenesis, to map cell states and differentiation across all cell lineages over time. These data and approaches pave the way for the comprehensive reconstruction of transcriptional trajectories during development.
            
            
              Science
              , this issue p.
              981
              , p.
              eaar3131
              , p.
              eaar5780
              ; see also p.
              967
            
          , 
            Single-cell RNA sequencing and a computational technique reveal cell trajectories that form the complex body plan of the zebrafish embryo.
          , 
            
              INTRODUCTION
              During embryogenesis, pluripotent cells gradually become specialized and acquire distinct functions and morphologies. Because much of the specification process is controlled through changes in gene expression, the identification of the transcriptional trajectories underlying cell fate acquisition is paramount to understanding and manipulating development.
            
            
              RATIONALE
              Traditional approaches have studied specific fate decisions by analyzing the transcription of a few selected marker genes or by profiling isolated, predefined cell populations. The advent of large-scale single-cell RNA sequencing (scRNA-seq) provides the means to comprehensively define the gene expression states of all embryonic cells as they acquire their fates. This technology raises the possibility of identifying the molecular trajectories that describe cell fate specification by sampling densely during embryogenesis and connecting the transcriptomes of cells that have similar gene expression profiles. However, the numerous transcriptional states and branch points, as well as the asynchrony in developmental processes, pose major challenges to the computational reconstruction of developmental trajectories from scRNA-seq data.
            
            
              RESULTS
              We generated single-cell transcriptomes from 38,731 cells during early zebrafish embryogenesis at high temporal resolution, spanning 12 stages from the onset of zygotic transcription through early somitogenesis. We took two complementary approaches to identify the transcriptional trajectories in the data. First, we developed a simulated diffusion-based computational approach, URD, which identified the trajectories describing the specification of 25 cell types in the form of a branching tree. Second, we identified modules of coexpressed genes and connected them across developmental time. Combining the reconstructed developmental trajectories with differential gene expression analysis uncovered gene expression cascades leading to each cell type, including previously unidentified markers and candidate regulators. Combining these trajectories with Seurat, which infers the spatial positions of cells on the basis of their transcriptomes, connected the earlier spatial position of progenitors to the later fate of their descendants.
              Inspection of the developmental tree led to new insights about molecular specification in zebrafish. For example, the first branch point in the tree indicated that the first molecular specification event may not only separate the germ layers but also define the axial versus nonaxial mesendoderm. Additionally, some developmental branch points contained intermediate cells that expressed genes characteristic of multiple downstream cell fates. Gene expression analysis at one such branch point (the axial mesoderm) suggested that the intermediate cells switch their specification from one fate (notochord) to another (prechordal plate). Last, analysis of single-cell transcriptomes from a Nodal-signaling mutant revealed that even at the whole-transcriptome level, mutant cells were canalized into a subset of wild-type states and did not adopt any transcriptional states not observed in wild type, despite abnormal developmental signaling.
            
            
              CONCLUSION
              These findings reconstruct the gene expression trajectories during the embryogenesis of a vertebrate and highlight the concurrent canalization and plasticity of cell type specification. The scRNA-seq data and developmental tree provide a rich resource for future studies in zebrafish: The raw and processed data and the URD software are available for download, and the data can be browsed interactively online. Last, this approach provides a broadly applicable framework with which to reconstruct complex developmental trajectories from single-cell transcriptomes.
              
                
                  Developmental tree of early zebrafish embryogenesis.
                  Single-cell transcriptomes were generated from zebrafish embryos at 12 developmental stages (six of which are shown). The transcriptional trajectories that describe the fate specification of 25 cell types were reconstructed from the data. Molecular specification is visualized with a force-directed layout, in which each cell is represented by a point (colored by developmental stage), proceeding from pluripotent cells (at the bottom center) outward to 25 distinct cell types. A subset of the identified trajectories are labeled in groups.
                
                
              
            
          , 
            During embryogenesis, cells acquire distinct fates by transitioning through transcriptional states. To uncover these transcriptional trajectories during zebrafish embryogenesis, we sequenced 38,731 cells and developed URD, a simulated diffusion-based computational reconstruction method. URD identified the trajectories of 25 cell types through early somitogenesis, gene expression along them, and their spatial origin in the blastula. Analysis of Nodal signaling mutants revealed that their transcriptomes were canalized into a subset of wild-type transcriptional trajectories. Some wild-type developmental branch points contained cells that express genes characteristic of multiple fates. These cells appeared to trans-specify from one fate to another. These findings reconstruct the transcriptional trajectories of a vertebrate embryo, highlight the concurrent canalization and plasticity of embryonic specification, and provide a framework with which to reconstruct complex developmental trees from single-cell transcriptomes.},
	language = {en},
	number = {6392},
	urldate = {2024-05-14},
	journal = {Science},
	author = {Farrell, Jeffrey A. and Wang, Yiqun and Riesenfeld, Samantha J. and Shekhar, Karthik and Regev, Aviv and Schier, Alexander F.},
	month = jun,
	year = {2018},
	pages = {eaar3131},
	file = {Full Text:/Users/tobias/Zotero/storage/2Q7BGYCN/Farrell et al. - 2018 - Single-cell reconstruction of developmental trajec.pdf:application/pdf},
}

@article{wolf_paga_2019,
	title = {{PAGA}: graph abstraction reconciles clustering with trajectory inference through a topology preserving map of single cells},
	volume = {20},
	issn = {1474-760X},
	shorttitle = {{PAGA}},
	url = {https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1663-x},
	doi = {10.1186/s13059-019-1663-x},
	language = {en},
	number = {1},
	urldate = {2024-05-14},
	journal = {Genome Biology},
	author = {Wolf, F. Alexander and Hamey, Fiona K. and Plass, Mireya and Solana, Jordi and Dahlin, Joakim S. and Göttgens, Berthold and Rajewsky, Nikolaus and Simon, Lukas and Theis, Fabian J.},
	month = dec,
	year = {2019},
	pages = {59},
	file = {Full Text:/Users/tobias/Zotero/storage/HHESMEI5/Wolf et al. - 2019 - PAGA graph abstraction reconciles clustering with.pdf:application/pdf},
}

@article{schiebinger_optimal-transport_2019,
	title = {Optimal-{Transport} {Analysis} of {Single}-{Cell} {Gene} {Expression} {Identifies} {Developmental} {Trajectories} in {Reprogramming}},
	volume = {176},
	issn = {00928674},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S009286741930039X},
	doi = {10.1016/j.cell.2019.01.006},
	language = {en},
	number = {4},
	urldate = {2024-05-14},
	journal = {Cell},
	author = {Schiebinger, Geoffrey and Shu, Jian and Tabaka, Marcin and Cleary, Brian and Subramanian, Vidya and Solomon, Aryeh and Gould, Joshua and Liu, Siyan and Lin, Stacie and Berube, Peter and Lee, Lia and Chen, Jenny and Brumbaugh, Justin and Rigollet, Philippe and Hochedlinger, Konrad and Jaenisch, Rudolf and Regev, Aviv and Lander, Eric S.},
	month = feb,
	year = {2019},
	pages = {928--943.e22},
	file = {Full Text:/Users/tobias/Zotero/storage/D8C3WYWD/Schiebinger et al. - 2019 - Optimal-Transport Analysis of Single-Cell Gene Exp.pdf:application/pdf},
}

@inproceedings{chewi_fast_2021,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Fast and {Smooth} {Interpolation} on {Wasserstein} {Space}},
	volume = {130},
	url = {https://proceedings.mlr.press/v130/chewi21a.html},
	abstract = {We propose a new method for smoothly interpolating probability measures using the geometry of optimal transport. To that end, we reduce this problem to the classical Euclidean setting, allowing us to directly leverage the extensive toolbox of spline interpolation. Unlike previous approaches to measure-valued splines, our interpolated curves (i) have a clear interpretation as governing particle flows, which is natural for applications, and (ii) come with the first approximation guarantees on Wasserstein space. Finally, we demonstrate the broad applicability of our interpolation methodology by fitting surfaces of measures using thin-plate splines.},
	booktitle = {Proceedings of {The} 24th {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Chewi, Sinho and Clancy, Julien and Le Gouic, Thibaut and Rigollet, Philippe and Stepaniants, George and Stromme, Austin},
	editor = {Banerjee, Arindam and Fukumizu, Kenji},
	month = apr,
	year = {2021},
	pages = {3061--3069},
}

@article{benamou_second-order_2019,
	title = {Second-{Order} {Models} for {Optimal} {Transport} and {Cubic} {Splines} on the {Wasserstein} {Space}},
	volume = {19},
	issn = {1615-3375, 1615-3383},
	url = {http://link.springer.com/10.1007/s10208-019-09425-z},
	doi = {10.1007/s10208-019-09425-z},
	language = {en},
	number = {5},
	urldate = {2024-05-15},
	journal = {Foundations of Computational Mathematics},
	author = {Benamou, Jean-David and Gallouët, Thomas O. and Vialard, François-Xavier},
	month = oct,
	year = {2019},
	pages = {1113--1143},
	file = {Submitted Version:/Users/tobias/Zotero/storage/K2PNIX7I/Benamou et al. - 2019 - Second-Order Models for Optimal Transport and Cubi.pdf:application/pdf},
}

@incollection{lifshitz_chapter_1981,
	address = {Amsterdam},
	series = {Course of {Theoretical} {Physics}},
	title = {Chapter {III} - {Collisionless} {Plasmas}},
	volume = {10},
	isbn = {978-0-08-026480-6},
	url = {https://www.sciencedirect.com/science/article/pii/B9780080264806500084},
	urldate = {2024-05-15},
	booktitle = {Physical {Kinetics}},
	publisher = {Pergamon},
	author = {Lifshitz, E. M. and Pitaevski, L. P.},
	editor = {Lifshitz, E. M. and Pitaevski, L. P.},
	month = jan,
	year = {1981},
	doi = {10.1016/B978-0-08-026480-6.50008-4},
	pages = {115--167},
	file = {ScienceDirect Snapshot:/Users/tobias/Zotero/storage/L9NBFQTK/B9780080264806500084.html:text/html},
}

@article{mouhot_landau_2011,
	title = {On {Landau} damping},
	volume = {207},
	issn = {0001-5962},
	url = {http://projecteuclid.org/euclid.acta/1485892568},
	doi = {10.1007/s11511-011-0068-9},
	language = {en},
	number = {1},
	urldate = {2024-05-15},
	journal = {Acta Mathematica},
	author = {Mouhot, Clément and Villani, Cédric},
	year = {2011},
	pages = {29--201},
	file = {Full Text:/Users/tobias/Zotero/storage/IFAQRIQE/Mouhot and Villani - 2011 - On Landau damping.pdf:application/pdf},
}

@book{muntean_macroscopic_2016,
	address = {Cham},
	series = {Lecture {Notes} in {Applied} {Mathematics} and {Mechanics}},
	title = {Macroscopic and {Large} {Scale} {Phenomena}: {Coarse} {Graining}, {Mean} {Field} {Limits} and {Ergodicity}},
	volume = {3},
	copyright = {http://www.springer.com/tdm},
	isbn = {978-3-319-26882-8 978-3-319-26883-5},
	shorttitle = {Macroscopic and {Large} {Scale} {Phenomena}},
	url = {http://link.springer.com/10.1007/978-3-319-26883-5},
	urldate = {2024-05-15},
	publisher = {Springer International Publishing},
	editor = {Muntean, Adrian and Rademacher, Jens and Zagaris, Antonios},
	year = {2016},
	doi = {10.1007/978-3-319-26883-5},
}

@book{melrose_instabilities_1986,
	title = {Instabilities in {Space} and {Laboratory} {Plasmas}},
	url = {https://ui.adsabs.harvard.edu/abs/1986islp.book.....M},
	abstract = {This introductory account of instabilities in plasmas concentrates on laboratory plasmas, such as those encountered in fusion research, and the space plasmas studied in physics of the magnetosphere and solar atmosphere. This account bridges the gap between a graduate textbook on plasma physics, and specialized similarities between astrophysical and laboratory plasmas that are traditionally regarded as quite separate. The author, an expert in plasma astrophysics who has written a two-volume book on the subject, treats the material naturally, lending a broader perspective to the subject. This is an instructional text for graduate students and professionals in magnetospheric and mathematical physics, radiophysics, solar and theoretical astrophysics and radio astronomy.},
	urldate = {2024-05-15},
	author = {Melrose, D. B.},
	month = aug,
	year = {1986},
	publisher = {Cambridge University Press},
	note = {Publication Title: Instabilities in Space and Laboratory Plasmas
ADS Bibcode: 1986islp.book.....M},
}

@article{sonnendrucker_split_2015,
	title = {A split control variate scheme for {PIC} simulations with collisions},
	volume = {295},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999115002442},
	doi = {10.1016/j.jcp.2015.04.004},
	language = {en},
	urldate = {2024-05-15},
	journal = {Journal of Computational Physics},
	author = {Sonnendrücker, Eric and Wacher, Abigail and Hatzky, Roman and Kleiber, Ralf},
	month = aug,
	year = {2015},
	pages = {402--419},
	file = {Submitted Version:/Users/tobias/Zotero/storage/RVI84IRI/Sonnendrücker et al. - 2015 - A split control variate scheme for PIC simulations.pdf:application/pdf},
}

@article{kormann_generalized_2021,
	title = {A generalized {Fourier}–{Hermite} method for the {Vlasov}–{Poisson} system},
	volume = {61},
	issn = {0006-3835, 1572-9125},
	url = {https://link.springer.com/10.1007/s10543-021-00853-4},
	doi = {10.1007/s10543-021-00853-4},
	abstract = {Abstract
            
              A generalized Fourier–Hermite semi-discretization for the Vlasov–Poisson equation is introduced. The formulation of the method includes as special cases the symmetrically-weighted and asymmetrically-weighted Fourier–Hermite methods from the literature. The numerical scheme is formulated as a weighted Galerkin method with two separate scaling parameters for the Hermite polynomial and the exponential part of the new basis functions. Exact formulas for the error in mass, momentum, and energy conservation of the method depending on the parameters are devised and
              
                
                  \$\$L{\textasciicircum}2\$\$
                  
                    
                      L
                      2
                    
                  
                
              
              stability is discussed. The numerical experiments show that an optimal choice of the additional parameter in the generalized method can yield improved accuracy compared to the existing methods, but also reveal the distinct stability properties of the symmetrically-weighted method.},
	language = {en},
	number = {3},
	urldate = {2024-05-15},
	journal = {BIT Numerical Mathematics},
	author = {Kormann, Katharina and Yurova, Anna},
	month = sep,
	year = {2021},
	pages = {881--909},
	file = {Full Text:/Users/tobias/Zotero/storage/59REFJFN/Kormann and Yurova - 2021 - A generalized Fourier–Hermite method for the Vlaso.pdf:application/pdf},
}

@incollection{papadrakakis_numerical_2013,
	address = {Dordrecht},
	title = {Numerical {Solution} of the {Fokker}–{Planck} {Equation} by {Finite} {Difference} and {Finite} {Element} {Methods}—{A} {Comparative} {Study}},
	volume = {26},
	isbn = {978-94-007-5133-0 978-94-007-5134-7},
	url = {http://link.springer.com/10.1007/978-94-007-5134-7_5},
	urldate = {2024-05-15},
	booktitle = {Computational {Methods} in {Stochastic} {Dynamics}},
	publisher = {Springer Netherlands},
	author = {Pichler, L. and Masud, A. and Bergman, L. A.},
	editor = {Papadrakakis, Manolis and Stefanou, George and Papadopoulos, Vissarion},
	year = {2013},
	doi = {10.1007/978-94-007-5134-7_5},
	note = {Series Title: Computational Methods in Applied Sciences},
	pages = {69--85},
}

@book{harlow_machine_1955,
	series = {{LAMS} ({Los} {Alamos} {Scientific} {Laboratory})},
	title = {A {Machine} {Calculation} {Method} for {Hydrodynamic} {Problems}},
	url = {https://books.google.com/books?id=rvM5zQEACAAJ},
	publisher = {Los Alamos Scientific Laboratory of the University of California},
	author = {Harlow, F.H. and Evans, M. and Richtmyer, R.D.},
	year = {1955},
}

@article{monaghan_introduction_1988,
	title = {An introduction to {SPH}},
	volume = {48},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {00104655},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0010465588900264},
	doi = {10.1016/0010-4655(88)90026-4},
	language = {en},
	number = {1},
	urldate = {2024-05-15},
	journal = {Computer Physics Communications},
	author = {Monaghan, J.J.},
	month = jan,
	year = {1988},
	pages = {89--96},
}

@article{liu_reproducing_1995,
	title = {Reproducing kernel particle methods},
	volume = {20},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {0271-2091, 1097-0363},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/fld.1650200824},
	doi = {10.1002/fld.1650200824},
	abstract = {Abstract
            
              A new continuous reproducing kernel interpolation function which explores the attractive features of the flexible time‐frequency and space‐wave number localization of a window function is developed. This method is motivated by the theory of wavelets and also has the desirable attributes of the recently proposed smooth particle hydrodynamics (SPH) methods, moving least squares methods (MLSM), diffuse element methods (DEM) and element‐free Galerkin methods (EFGM). The proposed method maintains the advantages of the free Lagrange or SPH methods; however, because of the addition of a correction function, it gives much more accurate results. Therefore it is called the reproducing kernel particle method (RKPM). In computer implementation RKPM is shown to be more efficient than DEM and EFGM. Moreover, if the window function is
              C
              ∞
              , the solution and its derivatives are also
              C
              ∞
              in the entire domain. Theoretical analysis and numerical experiments on the 1D diffusion equation reveal the stability conditions and the effect of the dilation parameter on the unusually high convergence rates of the proposed method. Two‐dimensional examples of advection‐diffusion equations and compressible Euler equations are also presented together with 2D multiple‐scale decompositions.},
	language = {en},
	number = {8-9},
	urldate = {2024-05-15},
	journal = {International Journal for Numerical Methods in Fluids},
	author = {Liu, Wing Kam and Jun, Sukky and Zhang, Yi Fei},
	month = apr,
	year = {1995},
	pages = {1081--1106},
}

@incollection{nielsen_high-order_2023,
	address = {Cham},
	title = {High-{Order} {Structure}-{Preserving} {Algorithms} for {Plasma} {Hybrid} {Models}},
	volume = {14072},
	isbn = {978-3-031-38298-7 978-3-031-38299-4},
	url = {https://link.springer.com/10.1007/978-3-031-38299-4_28},
	language = {en},
	urldate = {2024-05-16},
	booktitle = {Geometric {Science} of {Information}},
	publisher = {Springer Nature Switzerland},
	author = {Possanner, Stefan and Holderied, Florian and Li, Yingzhe and Na, Byung Kyu and Bell, Dominik and Hadjout, Said and Güçlü, Yaman},
	editor = {Nielsen, Frank and Barbaresco, Frédéric},
	year = {2023},
	doi = {10.1007/978-3-031-38299-4_28},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {263--271},
}
