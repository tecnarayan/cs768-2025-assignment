\begin{thebibliography}{56}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bellemare et~al.(2013)Bellemare, Naddaf, Veness, and
  Bowling]{bellemare2013arcade}
Marc~G. Bellemare, Yavar Naddaf, Joel Veness, and Michael Bowling.
\newblock The arcade learning environment: An evaluation platform for general
  agents.
\newblock \emph{Journal of Artificial Intelligence Research}, 2013.

\bibitem[Bellemare et~al.(2017)Bellemare, Dabney, and
  Munos]{bellemare2017distributional}
Marc~G. Bellemare, Will Dabney, and Rémi Munos.
\newblock A distributional perspective on reinforcement learning.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, 2017.

\bibitem[Bellemare et~al.(2020)Bellemare, Candido, Castro, Gong, Machado,
  Moitra, Ponda, and Wang]{bellemare2020autonomous}
Marc~G. Bellemare, Salvatore Candido, Pablo~Samuel Castro, Jun Gong, Marlos~C.
  Machado, Subhodeep Moitra, Sameera~S. Ponda, and Ziyu Wang.
\newblock Autonomous navigation of stratospheric balloons using reinforcement
  learning.
\newblock \emph{Nature}, 588\penalty0 (7836):\penalty0 77--82, 2020.

\bibitem[Bellemare et~al.(2023)Bellemare, Dabney, and Rowland]{bdr2023}
Marc~G. Bellemare, Will Dabney, and Mark Rowland.
\newblock \emph{Distributional Reinforcement Learning}.
\newblock MIT Press, 2023.
\newblock \url{http://www.distributional-rl.org}.

\bibitem[Berlinet \& Thomas-Agnan(2011)Berlinet and
  Thomas-Agnan]{berlinet2011reproducing}
Alain Berlinet and Christine Thomas-Agnan.
\newblock \emph{Reproducing kernel {H}ilbert spaces in probability and
  statistics}.
\newblock Springer Science \& Business Media, 2011.

\bibitem[Bertsekas \& Tsitsiklis(1996)Bertsekas and
  Tsitsiklis]{bertsekas1996neuro}
Dimitri Bertsekas and John~N. Tsitsiklis.
\newblock \emph{Neuro-dynamic programming}.
\newblock Athena Scientific, 1996.

\bibitem[Bodnar et~al.(2020)Bodnar, Li, Hausman, Pastor, and
  Kalakrishnan]{bodnar2020quantile}
Cristian Bodnar, Adrian Li, Karol Hausman, Peter Pastor, and Mrinal
  Kalakrishnan.
\newblock Quantile {QT-Opt} for risk-aware vision-based robotic grasping.
\newblock In \emph{Robotics: Science and Systems}, 2020.

\bibitem[Bondanelli \& Ostojic(2020)Bondanelli and
  Ostojic]{bondanelli2020coding}
Giulio Bondanelli and Srdjan Ostojic.
\newblock Coding with transient trajectories in recurrent neural networks.
\newblock \emph{PLoS computational biology}, 16\penalty0 (2):\penalty0
  e1007655, 2020.

\bibitem[Boots et~al.(2013)Boots, Gretton, and Gordon]{BooGreGeo13}
Byron Boots, Arthur Gretton, and Geoffry~J. Gordon.
\newblock Hilbert space embeddings of predictive state representations.
\newblock In \emph{Proceedings of the Conference on Uncertainty in Artificial
  Intelligence}, 2013.

\bibitem[Chowdhury \& Oliveira(2023)Chowdhury and Oliveira]{ChoRaf23}
Sayak~Ray Chowdhury and Rafael Oliveira.
\newblock Value function approximations via kernel embeddings for no-regret
  reinforcement learning.
\newblock In \emph{Proceedings of The Asian Conference on Machine Learning},
  2023.

\bibitem[Chung \& Sobel(1987)Chung and Sobel]{chung87discounted}
Kun-Jen Chung and Matthew~J. Sobel.
\newblock Discounted {MDP}s: Distribution functions and exponential utility
  maximization.
\newblock \emph{SIAM Journal on Control and Optimization}, 25\penalty0
  (1):\penalty0 49--62, 1987.

\bibitem[Dabney et~al.(2018{\natexlab{a}})Dabney, Ostrovski, Silver, and
  Munos]{dabney2018implicit}
Will Dabney, Georg Ostrovski, David Silver, and Rémi Munos.
\newblock Implicit quantile networks for distributional reinforcement learning.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, 2018{\natexlab{a}}.

\bibitem[Dabney et~al.(2018{\natexlab{b}})Dabney, Rowland, Bellemare, and
  Munos]{dabney2018distributional}
Will Dabney, Mark Rowland, Marc~G. Bellemare, and Rémi Munos.
\newblock Distributional reinforcement learning with quantile regression.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2018{\natexlab{b}}.

\bibitem[Dabney et~al.(2020)Dabney, Kurth-Nelson, Uchida, Starkweather,
  Hassabis, Munos, and Botvinick]{dabney2020distributional}
Will Dabney, Zeb Kurth-Nelson, Naoshige Uchida, Clara~Kwon Starkweather, Demis
  Hassabis, R{\'e}mi Munos, and Matthew Botvinick.
\newblock A distributional code for value in dopamine-based reinforcement
  learning.
\newblock \emph{Nature}, 577\penalty0 (7792):\penalty0 671--675, 2020.

\bibitem[Doan et~al.(2018)Doan, Mazoure, and Lyle]{doan2018gan}
Thang Doan, Bogdan Mazoure, and Clare Lyle.
\newblock {GAN} {Q}-learning.
\newblock \emph{arXiv}, 2018.

\bibitem[Farahmand(2019)]{farahmand2019value}
Amir-massoud Farahmand.
\newblock Value function in frequency domain and the characteristic value
  iteration algorithm.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Fawzi et~al.(2022)Fawzi, Balog, Huang, Hubert, Romera-Paredes,
  Barekatain, Novikov, Ruiz, Schrittwieser, Swirszcz, Silver, Hassabis, and
  Kohli]{fawzi2022discovering}
Alhussein Fawzi, Matej Balog, Aja Huang, Thomas Hubert, Bernardino
  Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Francisco J.~R.
  Ruiz, Julian Schrittwieser, Grzegorz Swirszcz, David Silver, Demis Hassabis,
  and Pushmeet Kohli.
\newblock Discovering faster matrix multiplication algorithms with
  reinforcement learning.
\newblock \emph{Nature}, 610\penalty0 (7930):\penalty0 47--53, 2022.

\bibitem[Freirich et~al.(2019)Freirich, Shimkin, Meir, and
  Tamar]{freirich2019distributional}
Dror Freirich, Tzahi Shimkin, Ron Meir, and Aviv Tamar.
\newblock Distributional multivariate policy evaluation and exploration with
  the {B}ellman {GAN}.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, 2019.

\bibitem[Gretton et~al.(2012)Gretton, Borgwardt, Rasch, Sch{\"o}lkopf, and
  Smola]{gretton2012kernel}
Arthur Gretton, Karsten~M Borgwardt, Malte~J Rasch, Bernhard Sch{\"o}lkopf, and
  Alexander Smola.
\newblock A kernel two-sample test.
\newblock \emph{The Journal of Machine Learning Research}, 13\penalty0
  (1):\penalty0 723--773, 2012.

\bibitem[Gr{\"u}new{\"a}lder et~al.(2012)Gr{\"u}new{\"a}lder, Lever,
  Baldassarre, Pontil, and Gretton]{GruLevBalPonetal12}
Steffen Gr{\"u}new{\"a}lder, Guy Lever, Luca Baldassarre, Massi Pontil, and
  Arthur Gretton.
\newblock Modelling transition dynamics in {MDP}s with {RKHS} embeddings.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, 2012.

\bibitem[Hennequin et~al.(2012)Hennequin, Vogels, and
  Gerstner]{hennequin2012non}
Guillaume Hennequin, Tim~P Vogels, and Wulfram Gerstner.
\newblock Non-normal amplification in random balanced neuronal networks.
\newblock \emph{Physical Review E}, 86\penalty0 (1):\penalty0 011909, 2012.

\bibitem[Jaquette(1973)]{jaquette1973markov}
Stratton~C. Jaquette.
\newblock Markov decision processes with a new optimality criterion: Discrete
  time.
\newblock \emph{The Annals of Statistics}, 1\penalty0 (3):\penalty0 496--505,
  1973.

\bibitem[Kushner \& Yin(1997)Kushner and Yin]{kushner1997stochastic}
Harold~J. Kushner and George Yin.
\newblock \emph{Stochastic approximation and recursive algorithm and
  applications}.
\newblock Springer, 1997.

\bibitem[Lattimore \& Hutter(2014)Lattimore and Hutter]{lattimore2014near}
Tor Lattimore and Marcus Hutter.
\newblock Near-optimal {PAC} bounds for discounted {MDP}s.
\newblock \emph{Theoretical Computer Science}, 558:\penalty0 125--143, 2014.

\bibitem[Lever et~al.(2016)Lever, Shawe-Taylor, Stafford, and
  Szepesvari]{LevShaStaSze16}
Guy Lever, John Shawe-Taylor, Ronnie Stafford, and Csaba Szepesvari.
\newblock Compressed conditional mean embeddings for model-based reinforcement
  learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2016.

\bibitem[Lowet et~al.(2020)Lowet, Zheng, Matias, Drugowitsch, and
  Uchida]{lowet2020distributional}
Adam~S. Lowet, Qiao Zheng, Sara Matias, Jan Drugowitsch, and Naoshige Uchida.
\newblock Distributional reinforcement learning in the brain.
\newblock \emph{Trends in neurosciences}, 43\penalty0 (12):\penalty0 980--997,
  2020.

\bibitem[Mallat(1999)]{mallat1999wavelet}
St{\'e}phane Mallat.
\newblock \emph{A wavelet tour of signal processing}.
\newblock Elsevier, 1999.

\bibitem[Mandl(1971)]{mandl1971variance}
Petr Mandl.
\newblock On the variance in controlled {M}arkov chains.
\newblock \emph{Kybernetika}, 7\penalty0 (1):\penalty0 1--12, 1971.

\bibitem[Marthe et~al.(2023)Marthe, Garivier, and Vernade]{marthe2023beyond}
Alexandre Marthe, Aur{\'e}lien Garivier, and Claire Vernade.
\newblock Beyond average return in markov decision processes.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2023.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, Stig Petersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou,
  Helen King, Dharshan Kumaran, Daan Wierstra, Shane Legg, and Demis Hassabis.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 2015.

\bibitem[Morimura et~al.(2010{\natexlab{a}})Morimura, Sugiyama, Kashima,
  Hachiya, and Tanaka]{morimura2010nonparametric}
Tetsuro Morimura, Masashi Sugiyama, Hisashi Kashima, Hirotaka Hachiya, and
  Toshiyuki Tanaka.
\newblock Nonparametric return distribution approximation for reinforcement
  learning.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, 2010{\natexlab{a}}.

\bibitem[Morimura et~al.(2010{\natexlab{b}})Morimura, Sugiyama, Kashima,
  Hachiya, and Tanaka]{morimura2010parameteric}
Tetsuro Morimura, Masashi Sugiyama, Hisashi Kashima, Hirotaka Hachiya, and
  Toshiyuki Tanaka.
\newblock Parametric return density estimation for reinforcement learning.
\newblock In \emph{Proceedings of the Conference on Uncertainty in Artificial
  Intelligence}, 2010{\natexlab{b}}.

\bibitem[Munos(2003)]{munos2003error}
R{\'e}mi Munos.
\newblock Error bounds for approximate policy iteration.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, 2003.

\bibitem[Newey \& Powell(1987)Newey and Powell]{newey1987asymmetric}
Whitney~K. Newey and James~L. Powell.
\newblock Asymmetric least squares estimation and testing.
\newblock \emph{Econometrica: Journal of the Econometric Society}, pp.\
  819--847, 1987.

\bibitem[Nguyen-Tang et~al.(2021)Nguyen-Tang, Gupta, and
  Venkatesh]{nguyen2020distributional}
Thanh Nguyen-Tang, Sunil Gupta, and Svetha Venkatesh.
\newblock Distributional reinforcement learning via moment matching.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2021.

\bibitem[Rowland et~al.(2018)Rowland, Bellemare, Dabney, Munos, and
  Teh]{rowland2018analysis}
Mark Rowland, Marc Bellemare, Will Dabney, R{\'e}mi Munos, and Yee~Whye Teh.
\newblock An analysis of categorical distributional reinforcement learning.
\newblock In \emph{Proceedings of the International Conference on Artificial
  Intelligence and Statistics}, 2018.

\bibitem[Rowland et~al.(2019)Rowland, Dadashi, Kumar, Munos, Bellemare, and
  Dabney]{rowland2019statistics}
Mark Rowland, Robert Dadashi, Saurabh Kumar, R{\'e}mi Munos, Marc~G. Bellemare,
  and Will Dabney.
\newblock Statistics and samples in distributional reinforcement learning.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, 2019.

\bibitem[Rowland et~al.(2023)Rowland, Munos, Azar, Tang, Ostrovski,
  Harutyunyan, Tuyls, Bellemare, and Dabney]{rowland2023analysis}
Mark Rowland, R{\'e}mi Munos, Mohammad~Gheshlaghi Azar, Yunhao Tang, Georg
  Ostrovski, Anna Harutyunyan, Karl Tuyls, Marc~G Bellemare, and Will Dabney.
\newblock An analysis of quantile temporal-difference learning.
\newblock \emph{arXiv}, 2023.

\bibitem[Sahani \& Dayan(2003)Sahani and Dayan]{sahani2003doubly}
Maneesh Sahani and Peter Dayan.
\newblock Doubly distributional population codes: Simultaneous representation
  of uncertainty and multiplicity.
\newblock \emph{Neural Computation}, 2003.

\bibitem[Smola et~al.(2007)Smola, Gretton, Song, and
  Sch{\"o}lkopf]{SmoGreSonSch07}
Alex Smola, Arthur Gretton, Le~Song, and Bernhard Sch{\"o}lkopf.
\newblock A {H}ilbert space embedding for distributions.
\newblock In \emph{Proceedings of the International Conference on Algorithmic
  Learning Theory}, 2007.

\bibitem[Sobel(1982)]{sobel1982variance}
Matthew~J. Sobel.
\newblock The variance of discounted {M}arkov decision processes.
\newblock \emph{Journal of Applied Probability}, 19\penalty0 (4):\penalty0
  794--802, 1982.

\bibitem[Song et~al.(2008)Song, Zhang, Smola, Gretton, and
  Sch{\"o}lkopf]{song2008tailoring}
Le~Song, Xinhua Zhang, Alex Smola, Arthur Gretton, and Bernhard Sch{\"o}lkopf.
\newblock Tailoring density estimation via reproducing kernel moment matching.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, 2008.

\bibitem[Sriperumbudur et~al.(2010)Sriperumbudur, Gretton, Fukumizu,
  Sch{\"o}lkopf, and Lanckriet]{SriGreFukLanetal10}
Bharath~K. Sriperumbudur, Arthur Gretton, Kenji Fukumizu, Bernhard
  Sch{\"o}lkopf, and Gert R.~G. Lanckriet.
\newblock Hilbert space embeddings and metrics on probability measures.
\newblock \emph{Journal of Machine Learning Research}, 11:\penalty0 1517--1561,
  2010.

\bibitem[Sun et~al.(2022)Sun, Zhao, Liu, Liu, Jiang, and
  Kong]{sun2022distributional}
Ke~Sun, Yingnan Zhao, Yi~Liu, Wulong Liu, Bei Jiang, and Linglong Kong.
\newblock Distributional reinforcement learning via {S}inkhorn iterations.
\newblock \emph{arXiv}, 2022.

\bibitem[Sutton \& Barto(2018)Sutton and Barto]{sutton2018reinforcement}
Richard~S. Sutton and Andrew~G. Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT Press, 2nd edition, 2018.

\bibitem[Tamar et~al.(2013)Tamar, Di~Castro, and Mannor]{tamar2013temporal}
Aviv Tamar, Dotan Di~Castro, and Shie Mannor.
\newblock Temporal difference methods for the variance of the reward to go.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, 2013.

\bibitem[Tamar et~al.(2016)Tamar, Di~Castro, and Mannor]{tamar2016learning}
Aviv Tamar, Dotan Di~Castro, and Shie Mannor.
\newblock Learning the variance of the reward-to-go.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 361--396, 2016.

\bibitem[Tano et~al.(2020)Tano, Dayan, and Pouget]{tano2020local}
Pablo Tano, Peter Dayan, and Alexandre Pouget.
\newblock A local temporal difference code for distributional reinforcement
  learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[V{\'e}rtes \& Sahani(2018)V{\'e}rtes and Sahani]{vertes2018flexible}
Eszter V{\'e}rtes and Maneesh Sahani.
\newblock Flexible and accurate inference and learning for deep generative
  models.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[V{\'e}rtes \& Sahani(2019)V{\'e}rtes and Sahani]{vertes2019neurally}
Eszter V{\'e}rtes and Maneesh Sahani.
\newblock A neurally plausible model learns successor representations in
  partially observable environments.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Virtanen et~al.(2020)Virtanen, Gommers, Oliphant, Haberland, Reddy,
  Cournapeau, Burovski, Peterson, Weckesser, Bright, {van der Walt}, Brett,
  Wilson, Millman, Mayorov, Nelson, Jones, Kern, Larson, Carey, Polat, Feng,
  Moore, {VanderPlas}, Laxalde, Perktold, Cimrman, Henriksen, Quintero, Harris,
  Archibald, Ribeiro, Pedregosa, {van Mulbregt}, and {SciPy 1.0
  Contributors}]{2020SciPy-NMeth}
Pauli Virtanen, Ralf Gommers, Travis~E. Oliphant, Matt Haberland, Tyler Reddy,
  David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan
  Bright, St{\'e}fan~J. {van der Walt}, Matthew Brett, Joshua Wilson, K.~Jarrod
  Millman, Nikolay Mayorov, Andrew R.~J. Nelson, Eric Jones, Robert Kern, Eric
  Larson, C~J Carey, {\.I}lhan Polat, Yu~Feng, Eric~W. Moore, Jake
  {VanderPlas}, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen,
  E.~A. Quintero, Charles~R. Harris, Anne~M. Archibald, Ant{\^o}nio~H. Ribeiro,
  Fabian Pedregosa, Paul {van Mulbregt}, and {SciPy 1.0 Contributors}.
\newblock {{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in
  Python}.
\newblock \emph{Nature Methods}, 17:\penalty0 261--272, 2020.

\bibitem[Wenliang \& Sahani(2019)Wenliang and Sahani]{wenliang2019neurally}
Li~Kevin Wenliang and Maneesh Sahani.
\newblock A neurally plausible model for online recognition and postdiction in
  a dynamical environment.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Wu et~al.(2023)Wu, Uehara, and Sun]{wu2023distributional}
Runzhe Wu, Masatoshi Uehara, and Wen Sun.
\newblock Distributional offline policy evaluation with predictive error
  guarantees.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, 2023.

\bibitem[Wurman et~al.(2022)Wurman, Barrett, Kawamoto, MacGlashan, Subramanian,
  Walsh, Capobianco, Devlic, Eckert, Fuchs, Gilpin, Khandelwal, Kompella, Lin,
  MacAlpine, Oller, Seno, Sherstan, Thomure, Aghabozorgi, Barrett, Douglas,
  Whitehead, D{\"u}rr, Stone, Spranger, and Kitano]{wurman2022outracing}
Peter~R. Wurman, Samuel Barrett, Kenta Kawamoto, James MacGlashan, Kaushik
  Subramanian, Thomas~J. Walsh, Roberto Capobianco, Alisa Devlic, Franziska
  Eckert, Florian Fuchs, Leilani Gilpin, Piyush Khandelwal, Varun Kompella,
  HaoChih Lin, Patrick MacAlpine, Declan Oller, Takuma Seno, Craig Sherstan,
  Michael~D. Thomure, Houmehr Aghabozorgi, Leon Barrett, Rory Douglas, Dion
  Whitehead, Peter D{\"u}rr, Peter Stone, Michael Spranger, and Hiroaki Kitano.
\newblock Outracing champion {G}ran {T}urismo drivers with deep reinforcement
  learning.
\newblock \emph{Nature}, 602\penalty0 (7896):\penalty0 223--228, 2022.

\bibitem[Yang et~al.(2019)Yang, Zhao, Lin, Qin, Bian, and Liu]{yang2019fully}
Derek Yang, Li~Zhao, Zichuan Lin, Tao Qin, Jiang Bian, and Tie-Yan Liu.
\newblock Fully parameterized quantile function for distributional
  reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Zhang et~al.(2021)Zhang, Chen, Zhao, Xiong, Qin, and
  Liu]{zhang2021distributional}
Pushi Zhang, Xiaoyu Chen, Li~Zhao, Wei Xiong, Tao Qin, and Tie-Yan Liu.
\newblock Distributional reinforcement learning for multi-dimensional reward
  functions.
\newblock \emph{Advances in Neural Information Processing Systems}, 2021.

\end{thebibliography}
