@article{yu2019deep,
  title={Deep modular co-attention networks for visual question answering},
  author={Yu, Zhou and Yu, Jun and Cui, Yuhao and Tao, Dacheng and Tian, Qi},
  journal={Computer Vision and Pattern Recognition (CVPR)},
  year={2019}
}

@article{park2016analysis,
  title={Analysis on the dropout effect in convolutional neural networks},
  author={Park, Sungheon and Kwak, Nojun},
  journal={Asian Conference on Computer Vision},
  year={2016},
}

@article{yang2020rx,
  title={Rx equalization for a high-speed channel based on bayesian active learning using dropout},
  author={Yang, Xianbo and Tang, Junyan and Torun, Hakki M and Becker, Wiren D and Hejase, Jose A and Swaminathan, Madhavan},
  journal={Electrical Performance of Electronic Packaging and Systems (EPEPS)},
  year={2020},
}

@article{pollard2018eicu,
  title={The {eICU Collaborative Research Database}, a freely available multi-center database for critical care research},
  author={Pollard, Tom J and Johnson, Alistair EW and Raffa, Jesse D and Celi, Leo A and Mark, Roger G and Badawi, Omar},
  journal={Scientific data},
  volume={5},
  number={1},
  pages={1--13},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{Pan2022GenerativeAF,
  title={Generative Augmented Flow Networks},
  author={Ling Pan and Dinghuai Zhang and Aaron C. Courville and Longbo Huang and Yoshua Bengio},
  journal={International Conference on Learning Representations (ICLR)},
  year={2023}
}

@article{gleave2022uncertainty,
  title={Uncertainty Estimation for Language Reward Models},
  author={Gleave, Adam and Irving, Geoffrey},
  journal={arXiv preprint arXiv:2203.07472},
  year={2022}
}

@article{osband2013more,
  title={(More) efficient reinforcement learning via posterior sampling},
  author={Osband, Ian and Russo, Daniel and Van Roy, Benjamin},
  journal={Neural Information Processing Systems (NIPS)},
  year={2013}
}
@article{kuleshov2018accurate,
  title={Accurate uncertainties for deep learning using calibrated regression},
  author={Kuleshov, Volodymyr and Fenner, Nathan and Ermon, Stefano},
  journal={International Conference on Machine Learning (ICML)},
  year={2018}
}

@article{goyal2020variational,
  title={The variational bandwidth bottleneck: Stochastic evaluation on an information budget},
  author={Goyal, Anirudh and Bengio, Yoshua and Botvinick, Matthew and Levine, Sergey},
  journal={International Conference on Learning Representations (ICLR)},
  year={2020}
}
@article{le2021mc,
  title={Is {MC} Dropout Bayesian?},
  author={Le Folgoc, Loic and Baltatzis, Vasileios and Desai, Sujal and Devaraj, Anand and Ellis, Sam and Manzanera, Octavio E Martinez and Nair, Arjun and Qiu, Huaqi and Schnabel, Julia and Glocker, Ben},
  journal={arXiv preprint arXiv:2110.04286},
  year={2021}
}


@article{ba2013adaptive,
  title={Adaptive dropout for training deep neural networks},
  author={Ba, Jimmy and Frey, Brendan},
  journal={Neural Information Processing Systems (NIPS)},
  year={2013}
}


@article{ghiasi2018dropblock,
  title={Dropblock: A regularization method for convolutional networks},
  author={Ghiasi, Golnaz and Lin, Tsung-Yi and Le, Quoc V},
journal={Neural Information Processing Systems (NeurIPS)},
  year={2018}
}

@article{pham2021autodropout,
  title={Autodropout: Learning dropout patterns to regularize deep networks},
  author={Pham, Hieu and Le, Quoc},
  journal={Association for the Advancement of Artificial Intelligence (AAAI)},
  year={2021}
}

@article{fan2021contextual,
  title={Contextual dropout: An efficient sample-dependent dropout module},
  author={Fan, Xinjie and Zhang, Shujian and Tanwisuth, Korawat and Qian, Xiaoning and Zhou, Mingyuan},
  journal={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{foong2020expressiveness,
  title={On the expressiveness of approximate inference in {Bayesian} neural networks},
  author={Foong, Andrew and Burt, David and Li, Yingzhen and Turner, Richard},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}
@article{fort2019deep,
  title={Deep ensembles: A loss landscape perspective},
  author={Fort, Stanislav and Hu, Huiyi and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1912.02757},
  year={2019}
}

@article{ovadia2019can,
  title={Can you trust your model's uncertainty? Evaluating predictive uncertainty under dataset shift},
  author={Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, David and Nowozin, Sebastian and Dillon, Joshua and Lakshminarayanan, Balaji and Snoek, Jasper},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@inproceedings{bhatt2021uncertainty,
  title={Uncertainty as a form of transparency: Measuring, communicating, and using uncertainty},
  author={Bhatt, Umang and Antor{\'a}n, Javier and Zhang, Yunfeng and Liao, Q Vera and Sattigeri, Prasanna and Fogliato, Riccardo and Melan{\c{c}}on, Gabrielle and Krishnan, Ranganath and Stanley, Jason and Tickoo, Omesh and others},
  booktitle={Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={401--413},
  year={2021}
}

@article{guo2017calibration,
  title={On calibration of modern neural networks},
  author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
  journal={International Conference on Machine Learning (ICML)},
  year={2017},
}


@article{nguyen2015deep,
  title={Deep neural networks are easily fooled: High confidence predictions for unrecognizable images},
  author={Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
  journal={Computer Vision and Pattern Recognition (CVPR)},
  year={2015}
}

@article{daxberger2021bayesian,
  title={Bayesian deep learning via subnetwork inference},
  author={Daxberger, Erik and Nalisnick, Eric and Allingham, James U and Antor{\'a}n, Javier and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel},
  journal={International Conference on Machine Learning (ICML)},
  year={2021},
}


@article{hinton2012improving,
  title={Improving neural networks by preventing co-adaptation of feature detectors},
  author={Hinton, Geoffrey E and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R},
  journal={arXiv preprint arXiv:1207.0580},
  year={2012}
}


@article{xie2019soft,
  title={Soft dropout and its variational Bayes approximation},
  author={Xie, Jiyang and Ma, Zhanyu and Zhang, Guoqiang and Xue, Jing-Hao and Tan, Zheng-Hua and Guo, Jun},
  journal={Machine Learning for Signal Processing (MLSP)},
  year={2019},
}

@article{hendrycks2019benchmarking,
  title={Benchmarking neural network robustness to common corruptions and perturbations},
  author={Hendrycks, Dan and Dietterich, Thomas},
  journal={International Conference on Learning Representations (ICLR)},
  year={2019}
}

@article{jain2021deup,
  title={{DEUP}: Direct epistemic uncertainty prediction},
  author={Jain, Moksh and Lahlou, Salem and Nekoei, Hadi and Butoi, Victor and Bertin, Paul and Rector-Brooks, Jarrid and Korablyov, Maksym and Bengio, Yoshua},
  journal={Transactions on Machine Learning Research (TMLR)},
  year={2023}
}

@book{ackley2012connectionist,
  title={A connectionist machine for genetic hillclimbing},
  author={Ackley, David},
  volume={28},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{deleu2022bayesian,
  title={Bayesian Structure Learning with Generative Flow Networks},
  author={Deleu, Tristan and G{\'o}is, Ant{\'o}nio and Emezue, Chris and Rankawat, Mansi and Lacoste-Julien, Simon and Bauer, Stefan and Bengio, Yoshua},
  journal={Uncertainty in Artificial Intelligence (UAI)},
  year={2022}
}

@article{nica2022evaluating,
  title={Evaluating Generalization in GFlowNets for Molecule Design},
  author={Nica, Andrei Cristian and Jain, Moksh and Bengio, Emmanuel and Liu, Cheng-Hao and Korablyov, Maksym and Bronstein, Michael M and Bengio, Yoshua},
  journal={ICLR 2022 Machine Learning for Drug Discovery workshop},
  year={2022}
}


@article{jain2022biological,
  title={Biological Sequence Design with GFlowNets},
  author={Jain, Moksh and Bengio, Emmanuel and Hernandez-Garcia, Alex and Rector-Brooks, Jarrid and Dossou, Bonaventure FP and Ekbote, Chanakya Ajit and Fu, Jie and Zhang, Tianyu and Kilgour, Michael and Zhang, Dinghuai and Lena Simine and Payel Das and Yoshua Bengio},
  journal={International Conference on Machine Learning (ICML)},
  year={2022},
}

@article{zhang2022unifying,
  title={Unifying Generative Models with GFlowNets},
  author={Zhang, Dinghuai and Chen, Ricky TQ and Malkin, Nikolay and Bengio, Yoshua},
  journal={arXiv preprint arXiv:2209.02606},
  year={2022}
}

@article{zhang2022generative,
  title={Generative Flow Networks for Discrete Probabilistic Modeling},
  author={Zhang, Dinghuai and Malkin, Nikolay and Liu, Zhen and Volokhova, Alexandra and Courville, Aaron and Bengio, Yoshua},
  journal={International Conference on Machine Learning (ICML)},
  year={2022}
}


@article{madan2022learning,
  title={Learning {GFlowNets} from partial episodes for improved convergence and stability},
  author={Madan, Kanika and Rector-Brooks, Jarrid and Korablyov, Maksym and Bengio, Emmanuel and Jain, Moksh and Nica, Andrei and Bosc, Tom and Bengio, Yoshua and Malkin, Nikolay},
  journal={International Conference on Machine Learning (ICML)},
  year={2023}
}


@article{bengio2021gflownet,
  title={Gflownet foundations},
  author={Bengio, Yoshua and Deleu, Tristan and Hu, Edward J and Lahlou, Salem and Tiwari, Mo and Bengio, Emmanuel},
  journal={arXiv preprint arXiv:2111.09266},
  year={2021}
}


@article{malkin2022trajectory,
  title={Trajectory Balance: Improved Credit Assignment in {GFlowNets}},
  author={Malkin, Nikolay and Jain, Moksh and Bengio, Emmanuel and Sun, Chen and Bengio, Yoshua},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2022}
}


@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{bengio2021flow,
  title={Flow network based generative models for non-iterative diverse candidate generation},
  author={Bengio, Emmanuel and Jain, Moksh and Korablyov, Maksym and Precup, Doina and Bengio, Yoshua},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2021}
}


@article{lee2020meta,
  title={Meta dropout: Learning to perturb latent features for generalization},
  author={Lee, Hae Beom and Nam, Taewook and Yang, Eunho and Hwang, Sung Ju},
  journal = {International Conference on Learning Representations (ICLR)},
  year={2020}
}

@article{boluki2020learnable,
  title={Learnable {Bernoulli} dropout for {Bayesian} deep learning},
  author={Boluki, Shahin and Ardywibowo, Randy and Dadaneh, Siamak Zamani and Zhou, Mingyuan and Qian, Xiaoning},
  journal={Artificial Intelligence and Statistics (AISTATS)},
  year={2020},
}

@article{wu2021r,
  title={R-drop: Regularized dropout for neural networks},
  author={Wu, Lijun and Li, Juntao and Wang, Yue and Meng, Qi and Qin, Tao and Chen, Wei and Zhang, Min and Liu, Tie-Yan and others},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2021}
}


@article{nguyen2021structured,
  title={Structured Dropout Variational Inference for {Bayesian} Neural Networks},
  author={Nguyen, Son and Nguyen, Duong and Nguyen, Khai and Than, Khoat and Bui, Hung and Ho, Nhat},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2021}
}



@article{gal2017concrete,
  title={Concrete dropout},
  author={Gal, Yarin and Hron, Jiri and Kendall, Alex},
  journal={Neural Information Processing Systems (NIPS)},
  volume={30},
  year={2017}
}




@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
}

@article{mianjy2019dropout,
  title={On dropout and nuclear norm regularization},
  author={Mianjy, Poorya and Arora, Raman},
  journal={International Conference on Machine Learning (ICML)},
  year={2019},
}

@article{xu2012robustness,
  title={Robustness and generalization},
  author={Xu, Huan and Mannor, Shie},
  journal={Machine learning},
  volume={86},
  number={3},
  pages={391--423},
  year={2012},
  publisher={Springer}
}



@article{kingma2015variational,
  title={Variational dropout and the local reparameterization trick},
  author={Kingma, Durk P and Salimans, Tim and Welling, Max},
  journal={Neural Information Processing Systems (NIPS)},
  year={2015}
}


@inproceedings{rennie2014annealed,
  title={Annealed dropout training of deep networks},
  author={Rennie, Steven J and Goel, Vaibhava and Thomas, Samuel},
  booktitle={2014 IEEE Spoken Language Technology Workshop (SLT)},
  pages={159--164},
  year={2014},
  organization={IEEE}
}


@article{gal2016dropout,
  title={Dropout as a {Bayesian} approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  journal={International Conference on Machine Learning (ICML)},
  year={2016}
}










@article{wan2013regularization,
  title={Regularization of neural networks using dropconnect},
  author={Wan, Li and Zeiler, Matthew and Zhang, Sixin and Le Cun, Yann and Fergus, Rob},
journal={International Conference on Machine Learning (ICML)},
  year={2013},
}

@article{wang2013fast,
  title={Fast dropout training},
  author={Wang, Sida and Manning, Christopher},
  journal={International Conference on Machine Learning (ICML)},
  year={2013},
}

@article{molchanov2017variational,
  title={Variational dropout sparsifies deep neural networks},
  author={Molchanov, Dmitry and Ashukha, Arsenii and Vetrov, Dmitry},
journal={International Conference on Machine Learning (ICML)},
  year={2017},
}

@article{nado2021uncertainty,
  author = {Zachary Nado and Neil Band and Mark Collier and Josip Djolonga and Michael Dusenberry and Sebastian Farquhar and Angelos Filos and Marton Havasi and Rodolphe Jenatton and Ghassen Jerfel and Jeremiah Liu and Zelda Mariet and Jeremy Nixon and Shreyas Padhy and Jie Ren and Tim Rudner and Yeming Wen and Florian Wenzel and Kevin Murphy and D. Sculley and Balaji Lakshminarayanan and Jasper Snoek and Yarin Gal and Dustin Tran},
  title = {{Uncertainty Baselines}:  Benchmarks for Uncertainty \& Robustness in Deep Learning},
  journal = {arXiv preprint arXiv:2106.04015},
  year = {2021},
}

@article{malkin2022gflownets,
  title={{GFlowNets} and variational inference},
  author={Malkin, Nikolay and Lahlou, Salem and Deleu, Tristan and Ji, Xu and Hu, Edward and Everett, Katie and Zhang, Dinghuai and Bengio, Yoshua},
  journal={International Conference on Learning Representations (ICLR)},
  year={2023}
}

@article{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  journal={Computer Vision and Pattern Recognition (CVPR)},
  year={2016}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009}
}

@article{sensoy2018evidential,
  title={Evidential deep learning to quantify classification uncertainty},
  author={Sensoy, Murat and Kaplan, Lance and Kandemir, Melih},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2018}
}


@article{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
journal={Neural Information Processing Systems (NIPS)},
  year={2017}
}

@article{mackay1992practical,
  title={A practical {Bayesian} framework for backpropagation networks},
  author={MacKay, David JC},
  journal={Neural Computation},
  volume={4},
  number={3},
  pages={448--472},
  year={1992},
  publisher={MIT Press}
}


@article{wilson2020bayesian,
  title={Bayesian deep learning and a probabilistic perspective of generalization},
  author={Wilson, Andrew G and Izmailov, Pavel},
journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{lotfi2022bayesian,
  title={Bayesian Model Selection, the Marginal Likelihood, and Generalization},
  author={Lotfi, Sanae and Izmailov, Pavel and Benton, Gregory and Goldblum, Micah and Wilson, Andrew Gordon},
  journal={International Conference on Machine Learning (ICML)},
  year={2022}
}


@article{damianou2013deep,
  title={Deep {Gaussian} processes},
  author={Damianou, Andreas and Lawrence, Neil D},
  journal={Artificial Intelligence and Statistics (AISTATS)},
  year={2013},
}

@book{neal2012bayesian,
  title={Bayesian learning for neural networks},
  author={Neal, Radford M},
  volume={118},
  year={2012},
  publisher={Springer Science \& Business Media}
}


@article{vaswani2017attention,
  title   = {Attention is all you need},
  author  = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
 journal = {Neural Information Processing Systems (NIPS)},
  year    = {2017}
}